Authors,Title,Year,Source title,Cited by,Link,Abstract,Author Keywords,Index Keywords,EID
"Feng Z., Tomimatsu K.","A study of digital media art utilizing 2D animation: Digital video expression using projection mapping and multi screen techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021392491&doi=10.1007%2f978-3-319-60591-3_40&partnerID=40&md5=dffbe67218a2f2039e5bec9344f36bba","This paper is about the research of the combination of PM technique with traditional animation. It can help designers create a more authentic experience exceeding to traditional animation technique. In PM concrete practicing, designers can shadow movie on an object on regular and irregular surfaces. In recent years, PM technology is applied by more and more film productions, and prevails in many advertisement and art festivals. In the concrete design steps, firstly, makes a cube, two of these cubes’ corner has been cut off to create the irregular projection. Two regular projection cubes represent spring and summer, using the bamboo and Lotus character as projected content. The other two irregular cubes represent autumn and winter, using the chrysanthemum and plum character as projected content. And then the second step, the production of projected content, author applied ink painting style to make these four plants animation. © Springer International Publishing AG 2018.","Animation; Information; Multi screen techniques; Projection mapping (PM); Special vision","Animation; Concretes; Digital storage; Geometry; Human engineering; Mapping; Multimedia systems; Concrete design; Digital videos; Film production; Information; Irregular surface; Multi screens; Projection mapping (PM); Traditional animations; Computer graphics",2-s2.0-85021392491
"Lin E.C.-H.","A research on multi-attribute sequence query processing techniques for motion databases",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031425192&doi=10.1007%2f978-981-10-3187-8_67&partnerID=40&md5=ea368762cec4bc7eb2a2ac9ceb79724d","Due to the development of computer technology and the mature development of motion capture technology, the applications of motion databases become more and more important. How to analysis the huge data stored in the database and efficiently retrieved the matched data is an important research issue. 3D animation design is one of the important applications of motion databases. Based on our teaching experience, the bottleneck of the students’ learning of animation is the motion animation of the 3D characters. Therefore, the motion database can be used to assist the design of the motions for 3D characters. However, it is still a difficult problem because of the high complexity of the matching mechanism and the difficult of user interface design. In this paper, the motion data can be represented as multi-attribute multi-dimensional sequences while the corresponding index structures and query processing mechanism are proposed for efficiently processing the motion queries. Moreover, Microsoft Kinect is used in this paper as the user interface. The captured data can be used as the user query and the further comparison will be performed to find the matched motion data. © Springer Nature Singapore Pte Ltd. 2018.","Index structure; Kinect; Motion database; Query processing","Animation; Database systems; Education; User interfaces; Computer technology; Index structure; Kinect; Matching mechanisms; Motion database; Multi dimensional; Teaching experience; User interface designs; Query processing",2-s2.0-85031425192
"Yong B., Shen J., Sun H., Xu Z., Liu J., Zhou Q.","GPU based simulation of collision detection of irregular vessel walls",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031406424&doi=10.1007%2f978-981-10-3187-8_42&partnerID=40&md5=be1c729e77a98e20b5a5748f03cf0f8c","Collision detection is a commonly used technique in the fields of computer games, physical simulation, virtual technology, computing and animation. When simulating the process of particle collision of ADS (Accelerator Driven Sub-Critical) system, complex and irregular vessel walls need to be considered. Generally, an irregular vessel wall is a curve surface, which cannot be defined as an exact mathematical function, and it is difficult to calculate the distance between particles and the wall directly. In this paper, we present an algorithm to perform collision detection between particles and irregular wall. When the number of particles reaches the level of 106, our algorithm implements a considerable improvement in performance if running on GPU, nearly 10 times faster than running on CPU. Results have demonstrated that our algorithm is promising. © Springer Nature Singapore Pte Ltd. 2018.","Collision detection; GPU; Irregular vessel; Physical simulating","Animation; Computation theory; Functions; Graphics processing unit; Collision detection; Curve surface; Irregular vessel; Mathematical functions; Particle collision; Physical simulating; Physical simulation; Virtual technology; Computer games",2-s2.0-85031406424
"Abu-Nabah B.A., ElSoussi A.O., Al Alami A.E.K.","Virtual laser vision sensor environment assessment for surface profiling applications",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028995161&doi=10.1016%2fj.measurement.2017.08.052&partnerID=40&md5=3dd3caa3d5f3ed8a5c2a2afeaf5791f9","Due to its potential accuracy and speed, the use of laser vision sensor (LVS) surface profiling systems has been rising at original equipment manufacturer levels in the Oil and Gas industry. The assessment of large structures mandates the deviation from commercially available LVS systems, and the implementation of custom-designed surface profiling capabilities. This effort assesses the use of 3ds Max, a three dimensional (3D) animation software, as a virtual environment to evaluate potential capabilities and limitations of any custom-designed LVS systems. An LVS experimental setup is simulated using the proposed virtual environment. A combination of two known calibration techniques is implemented virtually and experimentally to deliver a calibrated LVS system in both environments. Imported CAD model and its 3D-printed sample as known input profiles are scanned virtually and experimentally, respectively. Scanned data is inverted and compared with the input CAD model to validate the virtual environment for LVS surface profiling applications and preliminarily assess the measurement technique for weld profiling applications. More importantly, this effort facilitates the assessment of custom-designed LVS systems and brings 3D scanning capabilities a step closer towards robust quality control applications in the Oil and Gas industry. © 2017 Elsevier Ltd","Laser vision sensor; Surface profiling; Virtual scanning; Visual testing","3D printers; Calibration; Gas industry; Quality control; Virtual reality; Environment assessments; Laser vision sensors; Original equipment manufacturers; Quality control applications; Surface profiling; Three dimensional (3D) animation; Virtual scanning; Visual testing; Computer aided design",2-s2.0-85028995161
"Peng X., Chen H., Wang L., Wang H.","Evaluating a 3-D virtual talking head on pronunciation learning",2018,"International Journal of Human Computer Studies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027848470&doi=10.1016%2fj.ijhcs.2017.08.001&partnerID=40&md5=b10c8073400ccce976a525e3add5222f","We evaluate a 3-D virtual talking head on non-native Mandarin speaker pronunciation learning under three language presentation conditions – audio only (AU), human face video (HF) and audio-visual animation of a three-dimensional talking head (3-D). An auto language tutor (ALT) configured with AU, HF and 3-D is developed as the computer-aided pronunciation training system. We apply both subjective and objective methods to study user acceptance of the 3-D talking head, user comparative impressions and pronunciation performance under different conditions. The subjective ratings show that the 3-D talking head achieved a high level of user acceptance, and both 3-D and HF were preferred to AU. The objective pronunciation learning improvements show that 3-D was more beneficial than AU with respect to blade-alveolar, blade-palatal, lingua-palatal, open-mouth, open-mouth(-i) and round-mouth. Learning with 3-D was better than learning with HF with respect to blade-alveolar, lingua-palatal and round-mouth, and the tones of falling-rising and falling. Learning with AU was better than learning with HF with respect to the falling-rising tone. Neither HF nor AU was superior to 3-D with respect to any of the initials, finals and tones. © 2017 Elsevier Ltd","3-D talking head; Computer-aided pronunciation training; Evaluation","E-learning; Virtual reality; Audio-visual; Computer-aided pronunciation trainings; Evaluation; Mandarin speakers; Objective methods; Subjective rating; Talking heads; User acceptance; Visual languages",2-s2.0-85027848470
"Larsen L.B., Jensen S.S., Baunstrup M.","Directing untrained users’ attention using simple sound patterns",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029489259&doi=10.1007%2f978-3-319-60477-0_2&partnerID=40&md5=1f672efc0b0159712925aeb917b43904","In this work, we show how simple sound patterns can be used to direct a person’s attention towards specific locations, when the sound is emitted from a single, fixed position. In interaction design, this is an effect most often achieved using visual ques, such as animations or flashing lights. Using sound instead is useful in situations where visual ques are undesirable or unfeasible. We designed two experiments with a total of n = 45 respondents. 10 different sound patterns were composed with inspiration from previous studies and used as stimuli. The results showed significant differences (p = 0.05) for directing the gaze upwards and downwards and trends for left-right. The composed sounds require no prior training, or knowledge of cultural references (contrary to e.g. earcons and auditory icons) by the respondents and can thus be regarded as universal in nature. © Springer International Publishing AG 2018.","Auditory displays; Directing attention; Human factors; Interaction design; Sound design","Computer programming; Computer science; Auditory display; Directing attention; Earcons; Flashing lights; Interaction design; Sound designs; Specific location; Human engineering",2-s2.0-85029489259
"Jadhav S., Pawar J.","Bharatanatyam dance classification with rough set tools",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031404857&doi=10.1007%2f978-981-10-6602-3_8&partnerID=40&md5=c493823784505319408b66262b17f37b","BharataNatyam (BN) Choreography is known to be an intuitive domain. We have attempted to aid the choreographer for this creative domain of choreography for pure dance movements (used for aesthetics) called Nritta with our ArtToSMart (System Modeled art) system. Various automated techniques have been used for Western dance notations, its animation as well as for choreographic skills; but we have not been able to find enough on BN. We have used rough set tools to build a classifier for the dance poses, since manual methods are subjective and time-consuming. Thirty attributes have been used to define the human body. We obtained eight reducts from among these 30, and also decision rules which frame the grammar of a BN pose. The results are promising and have higher accuracy for about 500 instances. A comparative study has been done with two different tools namely WEKA (Waikato Environment for Knowledge Analysis) 3.6.11 and RSES (Rough Set Exploration System) 2.2.2 which has given 87.42% and about 76.8% classifier accuracy, respectively. © 2018, Springer Nature Singapore Pte Ltd.","BharataNatyam; Classification; Dance choreography; Dimension reduction; Grammar; Rough set theory","Classification (of information); Computer programming; Computer science; Automated techniques; BharataNatyam; Comparative studies; Dance choreography; Dimension reduction; Exploration systems; Grammar; Knowledge analysis; Rough set theory",2-s2.0-85031404857
"Baskar A., Gireesh Kumar T.","Facial expression classification using machine learning approach: A review",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021196620&doi=10.1007%2f978-981-10-3223-3_32&partnerID=40&md5=727dc17b597d349e1c68b6485f0bcce1","Automatic Facial Expression analysis has enthralled increasing attention in the research community in excess of two decades and its expedient in many application like, face animation, customer satisfaction studies, human-computer interaction and video conferencing. The precisely classifying different emotion is an essential problem in facial expression recognition research. There are several machine learning algorithms applied to facial expression recognition expedition. In this paper, we surveyed three different machine learning algorithms such as Bayesian Network, Hidden Markov Model and Support Vector machine and we attempt to answer following questions: How classification algorithm used its characteristics for emotion recognition? How various parameters in learning algorithm is devoted for better classification? What are the robust features used for training? Finally, we examined how advances in machine learning technique used for facial expression recognition?. © Springer Nature Singapore Pte Ltd. 2018.","Bayesian network; Deep belief network; Facial expression; Hidden markov model; Machine learning; Support vector machine","Artificial intelligence; Bayesian networks; Customer satisfaction; Deep learning; Education; Face recognition; Hidden Markov models; Human computer interaction; Intelligent computing; Learning systems; Markov processes; Support vector machines; Video conferencing; Automatic facial expression analysis; Classification algorithm; Deep belief networks; Facial expression classification; Facial expression recognition; Facial Expressions; Machine learning approaches; Machine learning techniques; Learning algorithms",2-s2.0-85021196620
"Castro-Alonso J.C., Ayres P., Wong M., Paas F.","Learning symbols from permanent and transient visual presentations: Don't overplay the hand",2018,"Computers and Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028988076&doi=10.1016%2fj.compedu.2017.08.011&partnerID=40&md5=ee10ff13675c49b677c671be05728a3e","Instructional dynamic pictures (animations and videos) contain transient visual information. Consequently, when learning from dynamic pictures, students must process in working memory the current images while trying to remember the images that left the screen. This additional activity in working memory may lead dynamic pictures to be less suitable instructional materials than comparable static pictures, which are more permanent. In order to directly show the influence of transient visual information on dynamic learning environments, we designed a well-matched comparison between a permanent and a transient presentation of an abstract-symbol memory task on the computer. In the task, 104 university students (50% females) had to memorize the type, color, and position of the symbols in a rectangular configuration. In addition, an embodied cognition factor was included where the symbols in the task were either shown with a precision grasping static hand or not. We also assessed how individual characteristics (spatial ability, spatial memory span, and gender) influenced performance. Results showed that (a) permanent outperformed transient presentations, (b) observing hands hindered learning, and (c) high spatial ability and high spatial memory span were beneficial, but gender did not affect performance. © 2017 Elsevier Ltd","Applications in subject areas; Gender studies; Interactive learning environments; Media in education; Multimedia/hypermedia systems","Computer aided instruction; Applications in subject areas; Gender studies; Interactive learning environment; Media in education; Multimedia/hypermedia systems; Education",2-s2.0-85028988076
"Kovács Z.","Real-time Animated Dynamic Geometry in the Classrooms by Using Fast Gröbner Basis Computations",2017,"Mathematics in Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018829687&doi=10.1007%2fs11786-017-0308-2&partnerID=40&md5=8e0342edbaf7a99581a09f075f827dce","Real-time animation of loci and envelopes in dynamic geometry software may be challenging because of the high amount of heavy symbolic computations being performed continuously. This paper reports on reaching 30 frames per second (FPS) in the desktop application GeoGebra for non-trivial examples for immediate use in classrooms—also 13 FPS is reached in a modern web browser. © 2017, Springer International Publishing.","Animation; Computer graphics; Envelope; Gröbner bases; Locus; Mathematics education",,2-s2.0-85018829687
"Yildiz Z.C., Capin T.","A perceptual quality metric for dynamic triangle meshes",2017,"Eurasip Journal on Image and Video Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010931122&doi=10.1186%2fs13640-016-0157-y&partnerID=40&md5=1b92b6d46b7dc22c5b9b2bd72cf88a4b","A measure for assessing the quality of a 3D mesh is necessary in order to determine whether an operation on the mesh, such as watermarking or compression, affects the perceived quality. The studies on this field are limited when compared to the studies for 2D. In this work, we aim a full-reference perceptual quality metric for animated meshes to predict the visibility of local distortions on the mesh surface. The proposed visual quality metric is independent of connectivity and material attributes. Thus, it is not associated to a specific application and can be used for evaluating the effect of an arbitrary mesh processing method. We use a bottom-up approach incorporating both the spatial and temporal sensitivity of the human visual system. In this approach, the mesh sequences go through a pipeline which models the contrast sensitivity and channel decomposition mechanisms of the HVS. As the output of the method, a 3D probability map representing the visibility of distortions is generated. We have validated our method by a formal user experiment and obtained a promising correlation between the user responses and the proposed metric. Finally, we provide a dataset consisting of subjective user evaluation of the quality of public animation datasets. © 2017, The Author(s).","Animation; Geometry; VDP CSF; Visual quality assessment","Animation; Decomposition; Geometry; Human computer interaction; Visibility; Channel decomposition; Contrast sensitivity; Human Visual System; Perceptual quality; Temporal sensitivity; VDP CSF; Visual quality assessment; Visual quality metrics; Mesh generation",2-s2.0-85010931122
"Morse P., Reading A., Lueg C.","Animated analysis of geoscientific datasets: An interactive graphical application",2017,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027585807&doi=10.1016%2fj.cageo.2017.07.006&partnerID=40&md5=70281a71f55a7c760e948abf127a3141","Geoscientists are required to analyze and draw conclusions from increasingly large volumes of data. There is a need to recognise and characterise features and changing patterns of Earth observables within such large datasets. It is also necessary to identify significant subsets of the data for more detailed analysis. We present an innovative, interactive software tool and workflow to visualise, characterise, sample and tag large geoscientific datasets from both local and cloud-based repositories. It uses an animated interface and human-computer interaction to utilise the capacity of human expert observers to identify features via enhanced visual analytics. ‘Tagger’ enables users to analyze datasets that are too large in volume to be drawn legibly on a reasonable number of single static plots. Users interact with the moving graphical display, tagging data ranges of interest for subsequent attention. The tool provides a rapid pre-pass process using fast GPU-based OpenGL graphics and data-handling and is coded in the Quartz Composer visual programing language (VPL) on Mac OSX. It makes use of interoperable data formats, and cloud-based (or local) data storage and compute. In a case study, Tagger was used to characterise a decade (2000–2009) of data recorded by the Cape Sorell Waverider Buoy, located approximately 10 km off the west coast of Tasmania, Australia. These data serve as a proxy for the understanding of Southern Ocean storminess, which has both local and global implications. This example shows use of the tool to identify and characterise 4 different types of storm and non-storm events during this time. Events characterised in this way are compared with conventional analysis, noting advantages and limitations of data analysis using animation and human interaction. Tagger provides a new ability to make use of humans as feature detectors in computer-based analysis of large-volume geosciences and other data. © 2017 The Authors","Animated; Interactive; Time series analysis; Visual analytics","Application programming interfaces (API); Computational linguistics; Computer aided analysis; Computer aided software engineering; Computer graphics; Digital storage; Feature extraction; Human computer interaction; Storms; Time series analysis; Visual languages; Visualization; Animated; Computer-based analysis; Graphical applications; Graphical displays; Interactive; Interactive software tool; Tasmania , Australia; Visual analytics; Data handling",2-s2.0-85027585807
"Lewandowska (Tomaszewska) A., Jankowski J.","The negative impact of visual web advertising content on cognitive process: towards quantitative evaluation",2017,"International Journal of Human Computer Studies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023629744&doi=10.1016%2fj.ijhcs.2017.07.002&partnerID=40&md5=47ba96ef2d3ec567f8af55753e131b99","Web user experience is an important relatively new field of study. The impact of marketing content and its visual characteristics on perceived intrusiveness is one sub-field which remains under-explored. Effects such as vividness and intensive call-to-action messages are interrupting the cognitive processes and influence web user attitudes towards online environment. Our research contributes to the field of consumer responses to visual intrusive elements in advertising, using real and synthetic advertising content. The technical and quantitative characteristics considered in the current study include: flickering frequency rate, active area and animations. The results revealed an increased influence of connecting animations with other techniques, and identified its influence on cognitive process. The existence of a threshold of flickering frequency and active area size beyond which the content is perceived as intrusive was confirmed. Finally, we use experimental data to propose an objective metrics to evaluate the intrusiveness level of the elements analyzed. The approach can be used to evaluate the negative effect on web users’ cognitive processes by quantifying certain characteristics of the content. Moreover, it can be used as a reference for similar studies or as an aid for the design of visual content intended to attract web user attention. © 2017 Elsevier Ltd","Cognitive process; Human-computer interaction; Intrusiveness; Online advertisement; User experience","Flickering; Human computer interaction; Marketing; Websites; Cognitive process; Consumer Response; Intrusiveness; Online advertisements; Online environments; Quantitative characteristics; Quantitative evaluation; User experience; Cognitive systems",2-s2.0-85023629744
"Landhäußer M., Weigelt S., Tichy W.F.","NLCI: a natural language command interpreter",2017,"Automated Software Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982947800&doi=10.1007%2fs10515-016-0202-1&partnerID=40&md5=7cda30337a63d20f1cbe8c23ac7be327","Natural language interfaces are becoming more and more common, because they are powerful and easy to use. Examples of such interfaces are voice controlled navigation devices, Apple’s personal assistant Siri, Google Voice Search, and translation services. However, such interfaces are extremely difficult to build, to maintain, and to port to new domains. We present an approach for building and porting such interfaces quickly. NLCI is a natural language command interpreter that accepts action commands in English and translates them into executable code. The core component is an ontology that models an API. Once the API is “ontologized”, NLCI translates input sentences into sequences of API calls that implement the intended actions. Two radically different APIs were ontologized: openHAB for home automation and Alice for building 3D animations. Construction of the ontology can be automated if the API uses descriptive names for its components. In that case, the language interface can be generated completely automatically. Recall and precision of NLCI on a benchmark of 50 input scripts are 67 and 78 %, resp. Though not yet acceptable for practical use, the results indicate that the approach is feasible. NLCI accepts typed input only. Future work will use a speech front-end to test spoken input. © 2016, Springer Science+Business Media New York.","End-user programming; Knowledge-based software engineering; Natural language processing for software engineering; Program synthesis; Programming in natural language","Computational linguistics; Computer programming; Human computer interaction; Knowledge based systems; Natural language processing systems; Software engineering; End user programming; Knowledge-based softwares; NAtural language processing; Natural languages; Program synthesis; Translation (languages)",2-s2.0-84982947800
"Huang L.","iQIST v0.7: An open source continuous-time quantum Monte Carlo impurity solver toolkit",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029706452&doi=10.1016%2fj.cpc.2017.08.026&partnerID=40&md5=921e138ee94c394f536cec7083a1f463","In this paper, we present a new version of the iQIST software package, which is capable of solving various quantum impurity models by using the hybridization expansion (or strong coupling expansion) continuous-time quantum Monte Carlo algorithm. In the revised version, the software architecture is completely redesigned. New basis (intermediate representation or singular value decomposition representation) for the single-particle and two-particle Green's functions is introduced. A lot of useful physical observables are added, such as the charge susceptibility, fidelity susceptibility, Binder cumulant, and autocorrelation time. Especially, we optimize measurement for the two-particle Green's functions. Both the particle–hole and particle–particle channels are supported. In addition, the block structure of the two-particle Green's functions is exploited to accelerate the calculation. Finally, we fix some known bugs and limitations. The computational efficiency of the code is greatly enhanced. New version program summary Program Title:iQIST Program Files doi: http://dx.doi.org/10.17632/mvz87z5w3t.1 Licensing provisions: GPLv3 Programming language: Fortran 90, Python, Bash shell Journal reference of previous version: Computer Physics Communications 195, 140 (2015) Does the new version supersede the previous version?: Yes Reasons for the new version: Since the release of iQIST v0.5 in 2015 [1], we keep improving this code. The new version incorporates many new features, optimizations, and bug-fixes, which will be detailed below. Summary of revisions: • In the revised version, only the narcissus component and the hibiscus component are retained. The former implements a hybridization expansion continuous-time quantum Monte Carlo impurity solver for density–density type interaction. The latter includes many auxiliary tools and useful scripts. The two components are carefully benchmarked and verified.• New representation (intermediate representation or singular value decomposition representation) for the single-particle and two-particle Green's functions is implemented [2]. It is better than the Legendre orthogonal polynomial representation.• Now many physical observables can be measured, including the spin susceptibility, charge susceptibility, fidelity susceptibility, kinetic energy fluctuation, kurtosis and skewness of perturbation expansion order, and Binder cumulant [3]. The fidelity susceptibility can be used to detect the quantum phase transition efficiently.• The measurement of two-particle Green's functions is reimplemented. Both the particle–hole and particle–particle channels are supported on the same footing. The block structure and symmetry of the two-particle Green's functions are also utilized to reduce the CPU burden and memory requirement. The iQIST software package usually acts as a computational engine (i.e, quantum impurity solver) in the calculations of the dynamical mean-field theory and its diagrammatic extensions, such as the dual fermions, dual bosons, and dynamical vertex approximation [4]. The essential inputs for these diagrammatic extensions are the two-particle Green's functions. We design the data structure and file format for the two-particle Green's functions carefully, so that they can be easily accessed by the open source dual fermions code opendf [5].• Now the code can output the standard deviations (error bars) for all of the physical observables.• Now the code can measure the autocorrelation function/time for the total occupation number, and then use it to adjust automatically the interval between two successive measurements.• Usually we have to perform analytical continuations for the single-particle Green's function, spin susceptibility, and self-energy function, and convert them from imaginary time or Matsubara frequency space to real-frequency space. These tasks are extremely non-trivial. Some scripts are provided to deal with the output data. They are converted into column-wise files, so that some external codes, such as SpM [6] and ΩMaxEnt [7], can be used to do the analytical continuations.• We also provide some scripts to generate initial hybridization function and retarded interaction function, and make animation movie for the random walk in the Monte Carlo configuration space.• In the previous version of iQIST [1], once the Coulomb interaction U is dynamic and the improved estimator for the self-energy function [8] is employed, the real-part of Matsubara self-energy function is wrong. In the revised version, we fix this severe bug.• We maintain a comprehensive online manual for the code. The users can read the newest iQIST's documentation in the following website: www.gitbook.com/book/huangli712/iqist/.• Now the code repository is transferred to Github. The users can download the newest version of iQIST from the following website: www.github.com/huangli712/iqist. Nature of problem: In the dynamical mean-field theory and its diagrammatic extensions, the bottleneck is to solve a quantum impurity model self-consistently [4,9]. The quantum impurity model is a Hamiltonian that is used to describe quantum impurities embedded in bath environment or metallic hosts. The goal of the iQIST software package is to provide highly effective quantum impurity solvers. Solution method: In the iQIST software package, we only implement the hybridization expansion continuous-time quantum Monte Carlo algorithm [10]. Additional comments including Restrictions and Unusual features: In the revised version, the manjushaka component which implements a hybridization expansion continuous-time quantum Monte Carlo impurity solver for general Coulomb interaction is removed temporally due to numerical unstable problem. The application programming interfaces for Python and Fortran languages are also disabled. They will be released in the next version. [1] Li Huang, Yilin Wang, Zi Yang Meng, Liang Du, Philipp Werner, and Xi Dai, iQIST: An open source continuous-time quantum Monte Carlo impurity solver toolkit, Computer Physics Communications 195 (2015), 140.[2] Hiroshi Shinaoka, Junya Otsuki, Masayuki Ohzeki, and Kazuyoshi Yoshimi, Compressing Green's function using intermediate representation between imaginary-time and real-frequency domains, Phys. Rev. B 96 (2017), 035147.[3] Li Huang, Yilin Wang, Lei Wang and Philipp Werner, Detecting phase transitions and crossovers in Hubbard models using the fidelity susceptibility, Phys. Rev. B 94 (2016), 235110.[4] G. Rohringer, H. Hafermann, A. Toschi, A. A. Katanin, A. E. Antipov, M. I. Katsnelson, A. I. Lichtenstein, A. N. Rubtsov, and K. Held, Diagrammatic routes to non-local correlations beyond dynamical mean field theory, arXiv:1705.00024.[5] Andrey E. Antipov, James P.F. LeBlanc, and Emanuel Gull, opendf - an implementation of the dual fermion method for strongly correlated systems, Phys. Procedia 68 (2015), 43.[6] Junya Otsuki, Masayuki Ohzeki, Hiroshi Shinaoka, and Kazuyoshi Yoshimi, Sparse modeling approach to analytical continuation of imaginary-time quantum Monte Carlo data, Phys. Rev. E 95 (2017), 061302.[7] Dominic Bergeron and A.-M. S. Tremblay, Algorithms for optimized maximum entropy and diagnostic tools for analytic continuation, Phys. Rev. E 94 (2016), 023303.[8] Hartmut Hafermann, Self-energy and vertex functions from hybridization-expansion continuous-time quantum Monte Carlo for impurity models with retarded interaction, Phys. Rev. B 89 (2014), 235128.[9] Antoine Georges, Gabriel Kotliar, Werner Krauth, and Marcelo J. Rozenberg, Dynamical mean-field theory of strongly correlated fermion systems and the limit of infinite dimensions, Rev. Mod. Phys. 68 (1996), 13.[10] Emanuel Gull, Andrew J. Millis, Alexander I. Lichtenstein, Alexey N. Rubtsov, Matthias Troyer, and Philipp Werner, Continuous-time Monte Carlo methods for quantum impurity models, Rev. Mod. Phys. 83 (2011), 349. © 2017 Elsevier B.V.","Continuous-time quantum Monte Carlo; Quantum impurity solver; Two-particle Green's function","Application programming interfaces (API); Autocorrelation; Binders; Bins; Codes (symbols); Computation theory; Computational efficiency; Computer programming; Computer software; Continuous time systems; Correlation detectors; Coulomb interactions; Dynamical systems; FORTRAN (programming language); Green computing; High level languages; Higher order statistics; Impurities; Kinetic energy; Kinetics; Magnetic susceptibility; Mean field theory; Monte Carlo methods; Open source software; Open systems; Optimization; Phase transitions; Preforming; Problem oriented languages; Quantum theory; Singular value decomposition; Software packages; Space time codes; Statistical methods; Websites; Continuous time Monte Carlo methods; Continuous-time; Dynamical mean-field theory; Intermediate representations; Quantum impurity; Strongly correlated fermion system; Strongly correlated systems; Two particles; Quantum efficiency",2-s2.0-85029706452
"Zhang X., Liu S.","SPH haptic interaction with multiple-fluid simulation",2017,"Virtual Reality",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011620441&doi=10.1007%2fs10055-017-0308-1&partnerID=40&md5=53c03d3cd278812914565326fd90d644","Physics-based fluid interaction plays an important role in computer animation, with wide applications in virtual reality, computer games, digital entertainment, etc. For example, in virtual reality education and games, we often need fluid interactions like acting as an alchemist to create a potion by stirring fluid in a crucible. The traditional input devices such as a mouse and keyboard can basically input 2D information without feedback. In recent years, the continuous development of haptic device not only can achieve six degrees-of-freedom input, but also can calculate the force in virtual scenes and feedback to the user to make a better virtual experience. How to use haptic device in different kinds of virtual fluid scenarios to provide better experience is an important issue in the field of virtual reality. On the other hand, the researches on multiple-fluid interaction especially based on smoothed particle hydrodynamics (SPH) method are very lacking. Therefore, we study the key techniques of haptic interaction with SPH multiple-fluid to compensate this defect in computer graphics community. Different from the single-phase flow, interaction with multiple-fluid flow has difficulties in the realization of properties of different phases. After adding the multiple-fluid simulation, it is also important to keep haptic interaction real time. Our research is based on the mixture model. We guarantee the authenticity of multiple-fluid mixing effect while changing the drift velocity solver to improve efficiency. We employ a unified particle model to achieve rigid body–liquid coupling, and use FIR filter to smooth feedback force to the haptic device. Our novel multiple-fluid haptic simulation can provide an interactive experience for mixing liquid in virtual reality. © 2017, Springer-Verlag London.","Haptics; Multiple fluid; Real time; Virtual reality","Animation; Computer games; Computer graphics; Degrees of freedom (mechanics); FIR filters; Haptic interfaces; Hydrodynamics; Mixing; Virtual reality; Continuous development; Digital entertainment; Haptic interactions; Haptics; Multiple fluids; Real time; Six degrees of freedom; Smoothed particle hydrodynamics methods; Flow of fluids",2-s2.0-85011620441
"Kyriazis I., Liatsikos E., Sopilidis O., Kallidonis P., Skolarikos A., the European Section of Urotechnology (ESUT)","European Section of Urotechnology educational video on fluoroscopic-guided puncture in percutaneous nephrolithotomy: all techniques step by step",2017,"BJU International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019899087&doi=10.1111%2fbju.13894&partnerID=40&md5=ad5d327240da3efb40f761c16355870b","Objective: To describe the most common fluoroscopic-guided access techniques during percutaneous nephrolithotomy (PCNL) in a step-by-step manner and to assist in the standardisation of their technique and terminology. Methods: A high-quality animation video was created for each of the respective fluoroscopic techniques, focusing into the parallel projection of external surgical manoeuvres and their effect in the three-dimensional space of the kidney. Results: Four predominant fluoroscopic-guided percutaneous access techniques are available, each with different advantages and limitations. Monoplanar access is used when a stable single-axis fluoroscopic generator is available and is mostly based on surgeons’ experience. Biplanar access uses a second fluoroscopy axis to assess puncture depth. The ‘bull's eye’ technique follows a coaxial to fluoroscopy puncture path and is associated with a shorter learning curve at the cost of increased hand radiation exposure. Hybrid and conventional triangulate techniques use target projection by two fluoroscopic planes to define the exact localisation of the target in space and access it through a third puncture site. Conclusions: Fluoroscopic guidance during PCNL puncture is a very efficient method for access establishment. The percutaneous surgeon should be familiar with all available variations of fluoroscopic approach in order to be prepared to adapt puncture technique for any given scenario. © 2017 The Authors BJU International © 2017 BJU International Published by John Wiley & Sons Ltd","fluoroscopy; kidney; percutaneous nephrolithotripsy; puncture; stones","Article; clinical competence; fluoroscopic generator; fluoroscopic guided puncture; fluoroscopy; human; learning curve; percutaneous nephrolithotomy; perioperative period; priority journal; puncture; radiation exposure; standardization; surgical approach; surgical technique; surgical training; three dimensional imaging; urologist; videorecording; computer assisted surgery; diagnostic imaging; education; Europe; fluoroscopy; kidney; Kidney Calculi; medical education; percutaneous nephrostomy; procedures; puncture; urology; Education, Medical, Continuing; Europe; Fluoroscopy; Humans; Kidney; Kidney Calculi; Nephrostomy, Percutaneous; Punctures; Surgery, Computer-Assisted; Urology; Video Recording",2-s2.0-85019899087
"Cat J.","Epistemology, aesthetics and pragmatics of scientific and other images: Visualization, representation and reasoning",2017,"Studies in Fuzziness and Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997270889&doi=10.1007%2f978-3-319-47190-7_5&partnerID=40&md5=30207d14261ce2879f125fcb6128dba5","Vagueness of appearance and depiction is a property of the categorization of images. Through categorization, whatever pictures do, they may do approximately and vaguely. And what images can do, that is, what they do for us and we can do with them, depends on what we think their roles are. In general, pictures play a role in ordinary and scientific argument and in cognition more broadly. They are key to identifying, documenting, tracking and exploring visible properties of empirical systems and phenomena, also and to visualizing and communicating empirical and theoretical information; they can be emotionally compelling, aesthetically powerful, and exhibit and enforce values and biases. This is no less relevant in the study of systems, individual or generic, whose relevant properties are spatial, chromatic or structural. Relevant examples differ widely in medium, mode of production and use; they include photographs, drawings, data charts, diagrams, animations, film recordings, computer generated images, etc. Pictures in many such cases are meant to support inferences, recognition processes and carry heuristic and evidence value. We think with them and through them. © Springer International Publishing AG 2017.",,,2-s2.0-84997270889
"CHEN Y.J., Ascher U., Pai D.","Exponential Rosenbrock-Euler Integrators for Elastodynamic Simulation",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032735062&doi=10.1109%2fTVCG.2017.2768532&partnerID=40&md5=4209be63bff80aaaf37028ba313d5ecc","High quality simulations of the dynamics of soft flexible objects can be rather costly, because the assembly of internal forces through an often nonlinear stiffness at each time step is expensive. Many standard implicit integrators introduce significant, time-step dependent artificial damping. Here we propose and demonstrate the effectiveness of an exponential Rosenbrock-Euler (ERE) method which avoids discretization-dependent artificial damping. The method is relatively inexpensive and works well with the large time steps used in computer graphics. It retains correct qualitative behaviour even in challenging circumstances involving non-convex elastic energies. Our integrator is designed to handle and perform well even in the important cases where the symmetric stiffness matrix is not positive definite at all times. Thus we are able to address a wider range of practical situations than other related solvers. We show that our system performs efficiently for a wide range of soft materials. IEEE","Computational modeling; Computer graphics; computer graphics; Damping; deformable models; Elastodynamics; exponential integrators; Numerical stability; physically based animation; Stability analysis; Symmetric matrices; time integration","Convergence of numerical methods; Damping; Stiffness; Stiffness matrix; Computational model; Deformable models; Elasto-dynamics; Exponential integrators; Physically-based animation; Stability analysis; Symmetric matrices; Time integration; Computer graphics",2-s2.0-85032735062
"Zhang Y., Zhu Z., Cui H., Dong X., Chen H.","Small files storing and computing optimization in Hadoop parallel rendering",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973316234&doi=10.1002%2fcpe.3847&partnerID=40&md5=4076172ea0cb8970e50b65d0091f3be2","Hadoop framework has been widely used in animation industries to build a large scale, high performance parallel rendering system. However, Hadoop Distributed File System (HDFS) and the MapReduce programming model are designed to manage large files and suffer performance penalty while rendering and storing small files in a rendering system. Therefore, a method that merges small files based on two intelligent algorithms is proposed to solve the problem. The method uses Particle Swarm Optimization (PSO) to select the optimal merge values for multiple sets of scenes and then uses Support Vector Machine (SVM) to generate a general SVM model which can be used to get the optimal merge value for any scene, by mainly considering the rendering time, memory limitation and other indicators. Then, the method takes advantage of frame-to-frame coherence to merge files in the same scene in an interval-based way with the optimal merge value. Finally, the proposed method is compared with the naive method under three different render scenes. Experimental results show that the proposed method significantly reduces the number of small files and render tasks, and improves the storage efficiency and computing efficiency. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","Hadoop; PSO; rendering system; small files; SVM","Distributed computer systems; Efficiency; File organization; Mergers and acquisitions; Particle swarm optimization (PSO); Support vector machines; Frame-to-frame coherence; Hadoop; Hadoop distributed file system (HDFS); Intelligent Algorithms; Map-reduce programming; Parallel rendering systems; Rendering system; Small files; Rendering (computer graphics)",2-s2.0-84973316234
"Bazarov S.E., Kholodilin I.Y., Nesterov A.S., Sokhina A.V.","Applying Augmented Reality in practical classes for engineering students",2017,"IOP Conference Series: Earth and Environmental Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032445989&doi=10.1088%2f1755-1315%2f87%2f3%2f032004&partnerID=40&md5=b2e2ef45b1b200d35da90b478cb3bfdd","In this article the Augmented Reality application for teaching engineering students of electrical and technological specialties is introduced. In order to increase the motivation for learning and the independence of students, new practical guidelines on Augmented Reality were developed in the application to practical classes. During the application development, the authors used software such as Unity 3D and Vuforia. The Augmented Reality content consists of 3D-models, images and animations, which are superimposed on real objects, helping students to study specific tasks. A user who has a smartphone, a tablet PC, or Augmented Reality glasses can visualize on-screen virtual objects added to a real environment. Having analyzed the current situation in higher education: the learner's interest in studying, their satisfaction with the educational process, and the impact of the Augmented Reality application on students, a questionnaire was developed and offered to students; the study involved 24 learners. © Published under licence by IOP Publishing Ltd.",,"Application programs; Augmented reality; Education; Education computing; Electric power systems; Mining machinery; Personal computers; Application development; Augmented reality applications; Augmented reality content; Current situation; Educational process; Motivation for learning; Practical guidelines; Real environments; Students",2-s2.0-85032445989
"Cheetham M.","Editorial: The uncanny valley hypothesis and beyond",2017,"Frontiers in Psychology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031493691&doi=10.3389%2ffpsyg.2017.01738&partnerID=40&md5=b9da8bdb4e030bf41a94a6ec92a82471",[No abstract available],"Anthropomorphic design; Computer animation; Computer graphics; Human likeness; Robotics; Uncanny valley hypothesis; Virtual reality",,2-s2.0-85031493691
"Wilkerson M.H., Shareff R., Laina V., Gravel B.","Epistemic gameplay and discovery in computational model-based inquiry activities",2017,"Instructional Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031915479&doi=10.1007%2fs11251-017-9430-4&partnerID=40&md5=1f61ce95c6081d755ae9e61a7e5c34a9","In computational modeling activities, learners are expected to discover the inner workings of scientific and mathematical systems: First elaborating their understandings of a given system through constructing a computer model, then “debugging” that knowledge by testing and refining the model. While such activities have been shown to support science learning, difficulties building and using computational models are common and reduce learning benefits. Drawing from Collins and Ferguson (Educ Psychol 28(1):25–42, 1993), we conjecture that a major cause for such difficulties is a misalignment between the epistemic games (modeling strategies) learners play, and the epistemic forms (model types) a given modeling environment is designed to support. To investigate, we analyzed data from a study in which ten groups of U. S. fifth graders (n = 28) worked to create stop motion animations and agent-based computational models (ABMs) to discover the particulate nature of matter. Content analyses revealed that (1) groups that made progress—that is, that developed increasingly mechanistic, explanatory models—focused on elements, movement, and interactions when developing their models, a strategy well-aligned with both animation and ABM; (2) groups that did not make progress focused on sequences of phases, a strategy well-aligned with animation but not with ABM; and (3) struggling groups progressed when they received guidance about modeling strategies, but not when they received guidance about model content. We present summary analyses and three vignettes to illustrate these findings, and share implications for research and curricular design. © 2017 Springer Science+Business Media B.V.","Epistemic games; Middle school; Model-based inquiry; Scientific modeling; Simulation",,2-s2.0-85031915479
"Taylor M., Baskett M., Allen M., Francis H., Kifayat K.","Animation as an aid to support the teaching of cyber security concepts",2017,"Innovations in Education and Teaching International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031427267&doi=10.1080%2f14703297.2017.1389653&partnerID=40&md5=7dd3e948d3ddcf7432c6c619f6a5074e","Animated learning materials have the potential to support the teaching and learning process. In this paper, we examine the comparative usefulness of animated and static learning materials for teaching cyber security concepts to a group of UK undergraduate computer science students. The animated cyber security learning materials appeared to be viewed by the undergraduate computer science participants overall as being slightly more informative than the equivalent static learning materials for learning some cyber security concepts. © 2017 Informa UK Limited, trading as Taylor & Francis Group","Animation; education; higher; learning; teaching",,2-s2.0-85031427267
"Wang S., Wang J., Gao Y.","Development and use of an open-source, user-friendly package to simulate voltammetry experiments",2017,"Journal of Chemical Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030978620&doi=10.1021%2facs.jchemed.6b00986&partnerID=40&md5=86a0b615ee70bc59da3f5a7e7764dab7","An open-source electrochemistry simulation package has been developed that simulates the electrode processes of four reaction mechanisms and two typical electroanalysis techniques: cyclic voltammetry and chronoamperometry. Unlike other open-source simulation software, this package balances the features with ease of learning and implementation and can run on mainstream operating systems. In an elctroanalysis lecture for graduate students, we have simulated the cyclic voltammetry of an electron transfer reaction with varied scan rates. The dynamical concentration profiles were demonstrated in an animation to help students understand the relation between currents and evolving concentration profiles, and the relations between peak currents and scan rates were also discussed. © 2017 The American Chemical Society and Division of Chemical Education, Inc.","Chemical Engineering; Computer-Based Learning; Electrochemistry; Graduate Education/Research; Kinetics; Upper-Division Undergraduate",,2-s2.0-85030978620
"Othman M.F., Senan N., Suparjoh S., Keay-Bright W.","User-centred design and experience prototyping: Design and implementation of pre-handwriting intervention to children with coordination difficulties/dyspraxia",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031277883&doi=10.1063%2f1.5005445&partnerID=40&md5=2f1b65d6b8a9bd81e47e40eae6ec602b","We have proposed a method to assist children with coordination difficulties or dyspraxia to improve their pre-handwriting skills. We have chosen an animation technique called 'Rotoscopy', a method that normally been used in animation and film production and adapted it to Rotoscopy Pre-handwriting Interface (RPI) prototypes using the interactive whiteboard (IWB) as interaction device. The motivation of this research is to discover how efficient if Rotoscopy is used beyond its normal purposes; and how it gives benefits in terms of behavioural and motivational aspects rather than commercial and profit point of view. Implementation of RPI prototypes has taken place through series of workshops with a teacher and a group of children with handwriting difficulties at a special education school in Caerphilly, Cardiff, United Kingdom. In the workshops children were given pre-handwriting activities in two different environments. They have been trained to use RPI prototypes and IWB, as well as pen and paper tasks. Their activities and action have been observed and recorded using video camera. Evaluation method is based-on video analysis of children's pre-handwriting result and their reaction and motivation during the workshop. It was learnt that majority of children who used RPI prototypes and IWB have produced better results in terms of accuracy of the drawing as compared to results of pen and paper activities. Furthermore the children were more motivated to use the prototypes and IWB rather than using pen and paper. The study's contribution to knowledge includes offering a new way to improve children's pre-handwriting skills using computer animation technique and touch-based devices. © 2017 Author(s).",,,2-s2.0-85031277883
"Sanna A., Valpreda F.","An assessment of the impact of a collaborative didactic approach and students' background in teaching computer animation",2017,"International Journal of Information and Communication Technology Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028769056&doi=10.4018%2fIJICTE.2017100101&partnerID=40&md5=e89d84345d6b871b282f9c6d0590622b","The purpose of this study was to compare different students' backgrounds and two different didactic methodologies to profitably teach computer animation in Italian schools of design and engineering. Teachers and instructors have long been engaged in discussions to define effective curricula for teaching computer animation. Various multidisciplinary and collaborative methodologies have been proposed. This manuscript assesses both the impact of a collaborative teaching approach and the curriculum. Two equivalent learning paths are compared; both of them encompass courses of photography, storytelling and computer animation and require prerequisites in 3D modeling and rendering. The learning path of the ""Systemic Design"" degree is taught by the collaborative Open Space Technology (OST) approach, whereas the path of ""Cinema and Media Engineering"" is taught more conventionally (independent courses). The results clearly show how effective teaching methodologies cannot completely compensate for a nontechnical background; on the other hand, as expected, students appreciate and can take advantage of collaborative forms of teaching. Copyright © 2017, IGI Global.","Computer Animation Curricula; Knowledge Sharing; Open Source; Teaching Computer Animation","Animation; Curricula; Education; Engineering education; Students; Three dimensional computer graphics; Collaborative methodologies; Collaborative teaching; Computer animation; Effective teaching; Knowledge-sharing; Open sources; Space technologies; Systemic designs; Teaching",2-s2.0-85028769056
"Otaduy M.","Introduction to the Special Section on the ACM/Eurographics Symposium on Computer Animation 2016",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029185692&doi=10.1109%2fTVCG.2017.2738478&partnerID=40&md5=049fb0a5e357468b2e429cfdb2cf2d9c",[No abstract available],,,2-s2.0-85029185692
"Li Y., Xu H., Barbic J.","Enriching Triangle Mesh Animations with Physically Based Simulation",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029235096&doi=10.1109%2fTVCG.2016.2620467&partnerID=40&md5=fa20b2ad6a6079f5b71ff74ff16e5fa4","We present a system to combine arbitrary triangle mesh animations with physically based Finite Element Method (FEM) simulation, enabling control over the combination both in space and time. The input is a triangle mesh animation obtained using any method, such as keyframed animation, character rigging, 3D scanning, or geometric shape modeling. The input may be non-physical, crude or even incomplete. The user provides weights, specified using a minimal user interface, for how much physically based simulation should be allowed to modify the animation in any region of the model, and in time. Our system then computes a physically-based animation that is constrained to the input animation to the amount prescribed by these weights. This permits smoothly turning physics on and off over space and time, making it possible for the output to strictly follow the input, to evolve purely based on physically based simulation, and anything in between. Achieving such results requires a careful combination of several system components. We propose and analyze these components, including proper automatic creation of simulation meshes (even for non-manifold and self-colliding undeformed triangle meshes), converting triangle mesh animations into animations of the simulation mesh, and resolving collisions and self-collisions while following the input. © 1995-2012 IEEE.","animation; animation system; collisions; Computer graphics; directable simulation; FEM; physically based modeling","Animation; Computer graphics; Mesh generation; User interfaces; Animation systems; Automatic creations; collisions; directable simulation; Finite element method simulation; Physically based modeling; Physically-based animation; Physically-based simulation; Finite element method",2-s2.0-85029235096
"Luo G., Lei G., Cao Y., Liu Q., Seo H.","Joint entropy-based motion segmentation for 3D animations",2017,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986292153&doi=10.1007%2fs00371-016-1313-1&partnerID=40&md5=d2b16c486b0a6c77aa7a86f02d3a6ae3","With the recent advancement of data acquisition techniques, 3D animation is becoming a new challenging subject for data processing. In this paper, we present a joint entropy-based key-frame extraction method, which further derives a motion segmentation method for 3D animations. We start by applying an existing deformation-based feature descriptor to measure the degree of deformation of each triangle within each frame, from which we compute the statistical joint probability distribution of triangles’ deformation between two consecutive subsequences of frames with a fixed length. Then, we further compute joint entropy between the two subsequences. This allows us to extract key-frames by taking the local maximal from the joint entropy curve (or energy curve) of a given 3D animation. Furthermore, we classify the extracted key-frames by grouping the key-frames with similar motions into the same cluster. Finally, we compute a boundary frame between each of the two neighboring frames with different motions, which is achieved by minimizing the variance of energy between the two motions. The experimental results show that our method successfully extracts representative key-frames of different motions, and the comparisons with existing methods show the effectiveness and the efficiency of our method. © 2016, Springer-Verlag Berlin Heidelberg.","3D animation; Joint entropy; Key-frame extraction; Motion segmentation","Animation; Data acquisition; Data handling; Deformation; Entropy; Extraction; Motion analysis; Probability distributions; 3D animation; Degree of deformations; Energy curve; Feature descriptors; Joint entropy; Joint probability distributions; Key-frame extraction; Motion segmentation; Three dimensional computer graphics",2-s2.0-84986292153
"Suarez J., Belhadj F., Boyer V.","Real-time 3D rendering with hatching",2017,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961989640&doi=10.1007%2fs00371-016-1222-3&partnerID=40&md5=4778904d4ce24dc1d7b51f81a70d6580","We present an approach for real-time pen-and-ink hatching renderings on large scenes. Starting with 3D models including photorealistic textures and materials, we aim to propose a solution that produces hatched renderings. As we consider scene objects described as polygonal meshes with their own textures, we produce once hatching patterns at different tones and resolutions considering the material of each object. To achieve that, we create a flow direction map per texture pixel, using contour characteristics extracted from the original texture and then interpolated. Stroke trajectories are thus generated depending on the flow direction and using B-splines, providing tones from light-to-dark. Tones are then stored in a mutli-resolution tonal art map. Moreover, we aim to overcome the limitations of existing hatching rendering methods by introducing an illumination model, fully implemented on GPU and able to manage three shading types: regular shadow, soft/cast shadow and self-shadowing. Tones and hatching resolutions are, therefore, assigned according to local/global illumination supporting multiple light sources. Our model, both dedicated for 3D static model renderings and 3D model animation, supports model deformations and is also spatially and temporally coherent since it gives continuous hatching strokes during object animations and/or light displacements. © 2016, Springer-Verlag Berlin Heidelberg.","GPU; Hatching; Real-time rendering; Stylized rendering and animation","Animation; Light sources; Three dimensional computer graphics; Hatching; Illumination modeling; Model deformations; Multiple light source; Object animation; Polygonal meshes; Real-time rendering; Rendering methods; Rendering (computer graphics)",2-s2.0-84961989640
"Zheng M., Yuan Z., Zhu W., Zhang G.","A fast mass spring model solver for high-resolution elastic objects",2017,"Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029502352&doi=10.1177%2f0037549717699073&partnerID=40&md5=448664162de72ca643fff63ed04afa4f","Real-time simulation of elastic objects is of great importance for computer graphics and virtual reality applications. The fast mass spring model solver can achieve visually realistic simulation in an efficient way. Unfortunately, this method suffers from resolution limitations and lack of mechanical realism for a surface geometry model, which greatly restricts its application. To tackle these problems, in this paper we propose a fast mass spring model solver for high-resolution elastic objects. First, we project the complex surface geometry model into a set of uniform grid cells as cages through ∗cages mean value coordinate method to reflect its internal structure and mechanics properties. Then, we replace the original Cholesky decomposition method in the fast mass spring model solver with a conjugate gradient method, which can make the fast mass spring model solver more efficient for detailed surface geometry models. Finally, we propose a graphics processing unit accelerated parallel algorithm for the conjugate gradient method. Experimental results show that our method can realize efficient deformation simulation of 3D elastic objects with visual reality and physical fidelity, which has a great potential for applications in computer animation. © The Author(s) 2017.","cages mean value coordinates; conjugate gradient method; Elastic object; fast mass spring model solver; graphics processing unit acceleration; high-resolution geometry model","Animation; Computer graphics; Computer graphics equipment; Geometry; Graphics processing unit; Program processors; Virtual reality; Cholesky decomposition; Deformation simulation; Elastic objects; Geometry model; Mass-spring models; Mean value coordinates; Real time simulations; Realistic simulation; Conjugate gradient method",2-s2.0-85029502352
"Overby M., Brown G.E., Li J., Narain R.","ADMM ⊇ Projective Dynamics: Fast Simulation of Hyperelastic Models with Dynamic Constraints",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028821124&doi=10.1109%2fTVCG.2017.2730875&partnerID=40&md5=d977a59f79be147927aa346f861d8394","We apply the alternating direction method of multipliers (ADMM) optimization algorithm to implicit time integration of elastic bodies, and show that the resulting method closely relates to the recently proposed projective dynamics algorithm. However, as ADMM is a general purpose optimization algorithm applicable to a broad range of objective functions, it permits the use of nonlinear constitutive models and hard constraints while retaining the speed, parallelizability, and robustness of projective dynamics. We further extend the algorithm to improve the handling of dynamically changing constraints such as sliding and contact, while maintaining the benefits of a constant, prefactored system matrix. We demonstrate the benefits of our algorithm on several examples that include cloth, collisions, and volumetric deformable bodies with nonlinear elasticity and skin sliding effects. © 1995-2012 IEEE.","animation; Computer graphics; computer simulation; dynamics; optimization methods","Dynamics; Elasticity; Alternating direction method of multipliers; Changing constraints; Dynamic constraints; Hyperelastic models; Implicit time integration; Nonlinear constitutive model; Nonlinear elasticity; Optimization algorithms; Optimization",2-s2.0-85028821124
"Farahani N., Liu Z., Jutt D., Fine J.L.","Pathologists' computer-assisted diagnosis a mock-up of a prototype information system to facilitate automation of pathology sign-out",2017,"Archives of Pathology and Laboratory Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030761699&doi=10.5858%2farpa.2016-0214-OA&partnerID=40&md5=5b01e136a7c35f3480430773477d8e82","Context. - Pathologists' computer-assisted diagnosis (pCAD) is a proposed framework for alleviating challenges through the automation of their routine sign-out work. Currently, hypothetical pCAD is based on a triad of advanced image analysis, deep integration with heterogeneous information systems, and a concrete understanding of traditional pathology workflow. Prototyping is an established method for designing complex new computer systems such as pCAD. Objective. - To describe, in detail, a prototype of pCAD for the sign-out of a breast cancer specimen. Design. - Deidentified glass slides and data from breast cancer specimens were used. Slides were digitized into whole-slide images with an Aperio Scan Scope XT, and screen captures were created by using vendor-provided software. The advanced workflow prototype was constructed by using PowerPoint software. Results. - We modeled an interactive, computer-assisted workflow: pCAD previews whole-slide images in the context of integrated, disparate data and predefined diagnostic tasks and subtasks. Relevant regions of interest (ROIs) would be automatically identified and triaged by the computer. A pathologist's sign-out work would consist of an interactive review of important ROIs, driven by required diagnostic tasks. The interactive session would generate a pathology report automatically. Conclusions. - Using animations and real ROIs, the pCAD prototype demonstrates the hypothetical sign-out in a stepwise fashion, illustrating various interactions and explaining how steps can be automated. The file is publicly available and should be widely compatible. This mock-up is intended to spur discussion and to help usher in the next era of digitization for pathologists by providing desperately needed and long-awaited automation.",,"Breast Neoplasms; computer assisted diagnosis; female; human; pathology; procedures; software; workflow; Breast Neoplasms; Female; Humans; Image Interpretation, Computer-Assisted; Pathology, Surgical; Software; Workflow",2-s2.0-85030761699
"Castelló V., Traver V.J., Serrano B., Montoliu R., Botella C.","Assisting therapists in assessing small animal phobias by computer analysis of video-recorded sessions",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992046917&doi=10.1007%2fs11042-016-3997-7&partnerID=40&md5=afedaea365ed2dbe365d6a5e552ce2e1","Behavioural Avoidance Tests (BATs) are commonly used for assessing phobias. While easy to deploy, these tests have some practical difficulties. For instance, therapists have to make distance estimations that are hard to do with accuracy and objectivity; or information regarding the performance of the patients (e.g. their walking pattern) is lost. To alleviate these difficulties, a computerized tool has been developed to extract the walking pattern of patients while approaching the phobic stimulus. From a video-recorded BAT session, two visual representations have been explored to compactly summarize the patient’s behavior: a static one (an image) and a dynamic one (an animation). A proof-of-concept prototype has been tested with 23 therapists. Most of the therapists preferred the animated representation, since it provides them with a better sense of the dynamics of how the patient really behaved. The participants agreed that this tool might be useful in assisting therapist when assessing phobia through BATs, since diagnostics could be made in a more accurate and objective way. © 2016, Springer Science+Business Media New York.","Clinical diagnostics; Computer vision; Small-animal phobia; Therapists; Visual representations","Animals; Diagnosis; Clinical diagnostics; Computer analysis; Computerized tools; Distance estimation; Proof of concept; Small Animal; Therapists; Visual representations; Computer vision",2-s2.0-84992046917
"Liao J., Eisemann M., Eisemann E.","Split-Depth Image Generation and Optimization",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031432465&doi=10.1111%2fcgf.13283&partnerID=40&md5=5ad69e6104512ea010c95a6f561fce8f","Split-depth images use an optical illusion, which can enhance the 3D impression of a 2D animation. In split-depth images (also often called split-depth GIFs due to the commonly used file format), static virtual occluders inform of vertical or horizontal bars are added to a video clip, which leads to occlusions that are interpreted by the observer as a depth cue. In this paper, we study different factors that contribute to the illusion and propose a solution to generate split-depth images for a given RGB + depth image sequence. The presented solution builds upon a motion summarization of the object of interest (OOI) through space and time. It allows us to formulate the bar positioning as an energy-minimization problem, which we solve efficiently. We take a variety of important features into account, such as the changes of the 3D effect due to changes in the motion topology, occlusion, the proximity of bars or the OOI, and scene saliency. We conducted a number of psycho-visual experiments to derive an appropriate energy formulation. Our method helps in finding optimal positions for the bars and, thus, improves the 3D perception of the original animation. We demonstrate the effectiveness of our approach on a variety of examples. Our study with novice users shows that our approach allows them to quickly create satisfying results even for complex animations. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","CCS Concepts; Computing methodologies → Image processing; Perception","Animation; Image processing; Optical data processing; Sensory perception; CCS Concepts; Computing methodologies; Energy formulations; Energy minimization problem; Important features; Optical illusions; Optimal position; Visual experiments; Image enhancement",2-s2.0-85031432465
"Ruiz A.","Transformation through Repetition: Walking, Listening and Drawing on Tlicho Lands",2017,"International Journal of Art and Design Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030993678&doi=10.1111%2fjade.12156&partnerID=40&md5=090f6047f8554e8791aaccd4ec2de6a8","As part of my PhD practice-based research on Tlicho lands (a self-governed Indigenous region in Canada's Northwest Territories), drawing is being used to embody intangible cultural heritage (which includes activities such as oral history and the social practice of walking). Recent work to emerge from this research consists of two drawings created by Tlicho elders, and an animated film made of 900 graphite drawings referencing regional oral history. The process of rendering these drawings embodied experiences on the land that are repetitive, albeit transformative, such as walking or listening to multiple versions of a single story. The entanglement of continually moving lines, evident through the animation, provides a counter-narrative to colonial interpretations of the land – particularly narratives constructed through Cartesian coordinate systems (on which computer graphics and the geometry of built environments are based). This article will describe the production of this film, while also inquiring into how line-making provides a trace of memory, rhythmic movement and epistemology. © 2017 The Author. iJADE © 2017 NSEAD/John Wiley & Sons Ltd","animation; culture; drawing; epistemology; indigenous; intangible; memory; movement",,2-s2.0-85030993678
"Albrecht G., Beccari C.V., Canonne J.-C., Romani L.","Planar Pythagorean-Hodograph B-Spline curves",2017,"Computer Aided Geometric Design",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030450867&doi=10.1016%2fj.cagd.2017.09.001&partnerID=40&md5=24c814f4b13692703dddf398e38e3c2b","We introduce a new class of planar Pythagorean-Hodograph (PH) B-Spline curves. They can be seen as a generalization of the well-known class of planar Pythagorean-Hodograph (PH) Bézier curves, presented by R. Farouki and T. Sakkalis in 1990, including the latter ones as special cases. Pythagorean-Hodograph B-Spline curves are non-uniform parametric B-Spline curves whose arc length is a B-Spline function as well. An important consequence of this special property is that the offsets of Pythagorean-Hodograph B-Spline curves are non-uniform rational B-Spline (NURBS) curves. Thus, although Pythagorean-Hodograph B-Spline curves have fewer degrees of freedom than general B-Spline curves of the same degree, they offer unique advantages for computer-aided design and manufacturing, robotics, motion control, path planning, computer graphics, animation, and related fields. After providing a general definition for this new class of planar parametric curves, we present useful formulae for their construction and discuss their remarkable attractive properties. Then we solve the reverse engineering problem consisting of determining the complex pre-image spline of a given PH B-Spline, and we also provide a method to determine within the set of all PH B-Splines the one that is closest to a given reference spline having the same degree and knot partition. © 2017 Elsevier B.V.","Arc-length; Non-uniform B-Spline; Offset; Plane curve; Pythagorean-Hodograph; Reverse engineering","Carbon dioxide arc welding; Computer aided design; Computer graphics; Curve fitting; Degrees of freedom (mechanics); Kinematics; Motion planning; Reverse engineering; Robot programming; Ship propellers; Splines; Arc length; Nonuniform B spline; Offset; Plane curves; Pythagorean hodograph; Interpolation",2-s2.0-85030450867
"Miyamoto E., Endo Y., Kanamori Y., Mitani J.","Semi-Automatic Conversion of 3D Shape into Flat-Foldable Polygonal Model",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031398016&doi=10.1111%2fcgf.13270&partnerID=40&md5=2f22278f4b983eacbfca8548a7af265f","This paper presents a method that can convert a given 3D mesh into a flat-foldable model consisting of rigid panels. A previous work proposed a method to assist manual design of a single component of such flat-foldable model, consisting of vertically-connected side panels as well as horizontal top and bottom panels. Our method semi-automatically generates a more complicated model that approximates the input mesh with multiple convex components. The user specifies the folding direction of each convex component and the fidelity of shape approximation. Given the user inputs, our method optimizes shapes and positions of panels of each convex component in order to make the whole model flat-foldable. The user can check a folding animation of the output model. We demonstrate the effectiveness of our method by fabricating physical paper prototypes of flat-foldable models. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Physically based modeling","Computational geometry; Mesh generation; Computational Geometry and Object Modeling; Descriptors; Manual design; Paper prototypes; Polygonal modeling; Semi-automatics; Shape approximation; Single components; Computer graphics",2-s2.0-85031398016
"Jochems A., Deist T.M., El Naqa I., Kessler M., Mayo C., Reeves J., Jolly S., Matuszak M., Ten Haken R., van Soest J., Oberije C., Faivre-Finn C., Price G., de Ruysscher D., Lambin P., Dekker A.","Developing and Validating a Survival Prediction Model for NSCLC Patients Through Distributed Learning Across 3 Countries",2017,"International Journal of Radiation Oncology Biology Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028706252&doi=10.1016%2fj.ijrobp.2017.04.021&partnerID=40&md5=2c7936545b3da8a41e99a3aface32752","Purpose Tools for survival prediction for non-small cell lung cancer (NSCLC) patients treated with chemoradiation or radiation therapy are of limited quality. In this work, we developed a predictive model of survival at 2 years. The model is based on a large volume of historical patient data and serves as a proof of concept to demonstrate the distributed learning approach. Methods and Materials Clinical data from 698 lung cancer patients, treated with curative intent with chemoradiation or radiation therapy alone, were collected and stored at 2 different cancer institutes (559 patients at Maastro clinic (Netherlands) and 139 at Michigan university [United States]). The model was further validated on 196 patients originating from The Christie (United Kingdon). A Bayesian network model was adapted for distributed learning (the animation can be viewed at https://www.youtube.com/watch?v=ZDJFOxpwqEA). Two-year posttreatment survival was chosen as the endpoint. The Maastro clinic cohort data are publicly available at https://www.cancerdata.org/publication/developing-and-validating-survival-prediction-model-nsclc-patients-through-distributed, and the developed models can be found at www.predictcancer.org. Results Variables included in the final model were T and N category, age, performance status, and total tumor dose. The model has an area under the curve (AUC) of 0.66 on the external validation set and an AUC of 0.62 on a 5-fold cross validation. A model based on the T and N category performed with an AUC of 0.47 on the validation set, significantly worse than our model (P<.001). Learning the model in a centralized or distributed fashion yields a minor difference on the probabilities of the conditional probability tables (0.6%); the discriminative performance of the models on the validation set is similar (P=.26). Conclusions Distributed learning from federated databases allows learning of predictive models on data originating from multiple institutions while avoiding many of the data-sharing barriers. We believe that distributed learning is the future of sharing data in health care. © 2017 The Author(s)",,"Bayesian networks; Biological organs; Chemoradiotherapy; Diseases; Distributed computer systems; Hospital data processing; HTTP; Patient monitoring; Radiotherapy; Area under the curves; Bayesian network models; Conditional probability tables; Distributed learning; Federated Databases; Methods and materials; Non small cell lung cancer; Survival prediction; Patient treatment; aged; Article; cancer center; cancer patient; cancer prognosis; cancer survival; chemoradiotherapy; female; human; major clinical study; male; Michigan; Netherlands; patient coding; post treatment survival; priority journal; small cell lung cancer; survival prediction; task performance; United Kingdom; age; area under the curve; Bayes theorem; cancer staging; Carcinoma, Non-Small-Cell Lung; clinical trial; cohort analysis; conformal radiotherapy; factual database; forecasting; Kaplan Meier method; learning; Lung Neoplasms; lymph node; mortality; multicenter study; pathology; procedures; severity of illness index; standards; statistical model; statistics and numerical data; time factor; validation study; antineoplastic agent; Age Factors; Aged; Antineoplastic Combined Chemotherapy Protocols; Area Under Curve; Bayes Theorem; Carcinoma, Non-Small-Cell Lung; Chemoradiotherapy; Cohort Studies; Databases, Factual; Female; Forecasting; Humans; Kaplan-Meier Estimate; Learning; Lung Neoplasms; Lymph Nodes; Male; Models, Statistical; Neoplasm Staging; Radiotherapy, Conformal; Severity of Illness Index; Time Factors",2-s2.0-85028706252
"Yuniarti A., Yeni L.F., Yokhebed","Development of Virtual Laboratory Based on Interactive Multimedia on Planting and Painting Bacteria",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032365854&doi=10.1088%2f1742-6596%2f895%2f1%2f012120&partnerID=40&md5=ea457034e1faa4426c3dcd9e1ad830ce","The Aim of this research is to produce Virtual Laboratory based on interactive multimedia on sub material of planting and painting bacteria. Knowing eligibility of the media and knowing the student's respond that has been taught of using Virtual Laboratory. The method of this research is development research. This research consists of two stages are preliminary (preparation and design) and formative evaluation (self evaluation, expert reviews, small group and fields test). Data collection techniques used in this research are questionnaires and tests. The subject of this research is 37 students. Based on validation result from validator expert, Virtual Laboratory is categorized valid. This value is obtained because Virtual Laboratory can be installed in various hardware and software, easy to use, the program works well, and Virtual lab has a unique shape, interactive and good animation. Meanwhile, students give the positive respond, it means student can operate and simulate the experiment of planting and painting bacteria with Virtual Laboratory and helps students to understand the material of planting and painting bacteria easily. So it can be concluded that Virtual Laboratory has legibility to be used as learning media. © Published under licence by IOP Publishing Ltd.",,"Bacteria; Education; Interactive computer systems; Laboratories; Multimedia systems; Surveys; Data collection; Formative evaluation; Hardware and software; Interactive multimedia; Learning media; Self evaluation; Validation results; Virtual laboratories; Students",2-s2.0-85032365854
"Perkins-Buzo J.","3D printing: Of signs and objects",2017,"Semiotica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029327100&doi=10.1515%2fsem-2015-0127&partnerID=40&md5=288080d60aba7825b0c924e7abd33527","3D printing has surely come of age. Widely available, and integrated into many computer-based design and animation curricula, it almost seems to have become a simple extension of what we already had in 2D printing. A 2D image (e.g., of a pipe) acts as the basis of a sign, which, perhaps upon further twists of the semiotic spiral, may lead one to cognition of a 3D physical pipe. But then, perhaps not. And only in a rare case would the physical pipe in turn find use as a sign of the aforesaid 2D image. With 3D printing, this order of semiosis no longer applies. Since 3D printing mainly occurs as a non-mass-production manufacturing technique, a 3D-printed artifact acts as a physical object - and generally it is printed to act precisely in that manner. It is a being that has an ontic difference from its digital source. The case of 3D printing provides an intriguing, complex, case study for semiosis, since the printables move in and out of the virtual and physical. © 2017 Walter de Gruyter GmbH, Berlin/Boston.","3D-printing; Benjamín; Deely; representation",,2-s2.0-85029327100
"Bali J.S., Nandi A.V.","An experience, using software based tools for teaching and learning mathematically intensive signal processing theory concepts",2017,"Proceedings - 2016 IEEE 4th International Conference on MOOCs, Innovation and Technology in Education, MITE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032802333&doi=10.1109%2fMITE.2016.37&partnerID=40&md5=6db81dff5512fcb15781f14275005b72","The paper emphasizes the need for teaching and learning mathematically intensive theory subjects using very powerful software tools. Under Electrical Engineering discipline, there are subjects like Signals & systems, Control Systems, Digital Signal/Image Processing etc. where teachers need to spend a considerable amount of time in classroom, teaching the mathematical concepts, ending up with very low level of learning by students. Learners find it very complex and unrelated as mere lecturing doesn't help them in effective interpretation of the information conveyed. There are many such software tools available nowadays having a powerful graphical data flow programming environment with a rich set of library functions and tools sets in simulation and real time mode. Such tools can simplify the teaching and learning of subjects with intense mathematical background in lesser time for the students from non-electronics stream. Here we present the efforts of teachers in learning and teaching, Signal acquisition, processing and analysis techniques for sixth semester students of Automation and Robotics in a much effective manner, using LabVIEW tool. The processed data can be presented from the tool using measurement graphs, indicators, animations, tabulated data, automated calculations, physical interpretation, visualization effects etc., thus enabling the learner with better understanding of concepts. Here we present the results of extensive use of tool to teach and learn different signal processing and analysis techniques used for biomedical signals along with the experience shared by teachers and students undergoing the activity. Course projects implemented by students after undergoing the proposed activity helped teachers to know the accelerated process of learning of the basic concepts of signal processing by students. © 2016 IEEE.","Automation & robotics; Digital signal processing; Electrical engineering discipline; LabVIEW tool; Signal acquisition; Signals and systems","Automation; Bioelectric phenomena; Computer aided software engineering; Computer software; Data visualization; Digital signal processing; Education; Educational technology; Engineering research; Robotics; Students; Teaching; LabViEW; Learning and teachings; Mathematical concepts; Physical interpretation; Powerful software tools; Signal acquisitions; Signal processing theory; Signals and systems; Signal processing",2-s2.0-85032802333
"Liu Y.","The design and realization of the automatic generation system of 2D animation",2017,"Proceedings - 2016 International Conference on Intelligent Transportation, Big Data and Smart City, ICITBS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032825269&doi=10.1109%2fICITBS.2016.109&partnerID=40&md5=02d23c4f5a0b1b05eadeba851fc40ae5","Automatically generation of full life cycle computer aided animation is a combination of a cartoon art, artificial intelligence technology and film art research field. In 3D animation automatically generated there has been progress, this paper attempts to expand it to the field of two-dimensional animation, this paper puts forward a 2D animation auto generation technology. For the two-dimensional animation features, this paper designed a series of innovative technologies and methods, in principle realized from the whole process of animation script to the two-dimensional animation automatic conversion, and has developed a prototype system to verify the design idea. This topic has the important scientific research significance, the cultural significance and the creative industry significance. According to the characteristics of two-dimensional animation frame by frame display, this paper will automatically generating 2D animation design established in two-dimensional continuous spatial (horizontal and vertical) and one-dimensional discrete spatial (depth) of 2.5 dimensional layer space. Layer is the frame of the drawing carrier, in the two-dimensional animation of the planning and generation process plays a key role. 2.5 dimensional layer space is a layer of multiple layers, so the expression of animation elements in the 2.5 dimensional space and three-dimensional space is completely different. This makes the automatic generation of 2D animation can not fully follow the research ideas of the automatic generation of 3D animation, it is needed to design some new techniques for the characteristics of 2D animation. This is a challenge, but also has important research value. © 2016 IEEE.","2D animation; Automatic generation; Knowledge storage; Layer planning; Software design","Big data; Digital storage; Innovation; Life cycle; One dimensional; Smart city; Software design; 2D animation; Artificial intelligence technologies; Automatic Generation; Automatically generated; Innovative technology; Knowledge storage; Scientific researches; Three dimensional space; Animation",2-s2.0-85032825269
"Xie N., Yuan T.Y., Nakajima M., Shen H.","LipSync generation based on discrete cosine transform",2017,"Proceedings - 2017 NICOGRAPH International, NICOInt 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032805597&doi=10.1109%2fNICOInt.2017.45&partnerID=40&md5=8159984fe6406de75895426bb4f6d2ad","Nowadays, voice acting plays more advanced in the video games, especially for the role-playing games, anime-based games and serious games. In order to enhance the communication, synchronizing the lip and mouth movements naturally is an important part of convincing 3D character performance [XFMS13]. In this paper, we propose a lightweight LipSync generation algorithm. According to the heuristic knowledge on the mouth movement in game, extracting the value of voice frequency domain is essential for LipSync in game. Therefore, we analytically convert the problem into Discrete Cosine Transform (DCT) that focuses on extracting the voice frequency domain value by absolute value computing operation so as to avoid redundant computation on phases and modulus of operation in Fourier Transform (FT) voice model. Our experimental results demonstrate that our DCT based method enables to achieve good performance for game making. © 2017 IEEE.","Animation; Computer graphics applications; DCT","Animation; Computer graphics; Frequency domain analysis; Human computer interaction; Interactive computer graphics; Serious games; Absolute values; Computer graphics applications; Discrete Cosine Transform(DCT); Frequency domains; Generation algorithm; Heuristic knowledge; Redundant computation; Role-playing game; Discrete cosine transforms",2-s2.0-85032805597
"Isoyama N., Terada T., Tsukamoto M.","Evaluating effects of listening to content with lip-sync animation on head mounted displays",2017,"UbiComp/ISWC 2017 - Adjunct Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030872211&doi=10.1145%2f3123024.3129265&partnerID=40&md5=5a5a8ea792cf0e295af91049243c3a12","Users should always be able to receive information when using a head-mounted display (HMD) anytime, anywhere. Users can watch content shown on an HMD hands-free even when moving or working. It seems that presenting specific information affects humans. In this paper, we investigate the effects on listening to speech information that are caused by presenting animation on an HMD. It is difficult to listen to information that is presented in noisy surroundings. If the solution were only to turn up the volume, we would feel uncomfortable because this is very inconvenient. Therefore, by additionally presenting animation, we aim to make it easy for users to listen to speech information. With our method, we use lip-sync animation that matches specific speech information. We performed two experiments to determine whether it is easier to get speech information with animation. Copyright held by the owner/author(s).","Cognitive psychology; Head mounted display; Speech information; Wearable computing","Animation; Sensory perception; Speech; Street traffic control; Ubiquitous computing; Wearable computers; Wearable technology; Cognitive psychology; Hands-free; Head mounted displays; Lip sync; Specific information; Speech information; Wearable computing; Helmet mounted displays",2-s2.0-85030872211
"Sorensen V., Thummanapalli N.","Digital amulet: Smart necklace",2017,"Proceedings - International Symposium on Wearable Computers, ISWC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030485899&doi=10.1145%2f3123021.3123067&partnerID=40&md5=9a189adf8fca2ae596a77bc08b62348f","This project explores aesthetic territory at the intersection of wearable technologies with global traditional cultures and contemporary fashion design, providing alternative ways for people across cultures to express and communicate in the networked, hybrid physical-digital domain. It is a form of smart jewelry, a smart necklace, or collar that lays flat on the chest, employs wireless and multimedia computing, including animation, music, networking, and 3D printing. © 2017 Association for Computing Machinery.","3D printing; Bio-mimicry; Computer animation; Design; Digital culture; Fashion; Global cultures; Smart necklace; Traditional cultures; Wearable technologies","3D printers; Animation; Design; Printing; Wearable computers; 3-D printing; Bio-mimicry; Computer animation; Digital culture; Fashion; Global cultures; Smart necklace; Traditional cultures; Wearable technology",2-s2.0-85030485899
"Hallam J., Zheng C., Posner N., Ericson H., Swarts M., Do E.Y.-L.","The Light orchard: An immersive display platform for collaborative tangible interaction",2017,"UbiComp/ISWC 2017 - Adjunct Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030838168&doi=10.1145%2f3123024.3123175&partnerID=40&md5=22913704148f5cb149587876f0327a04","This paper describes the Light Orchard, an installation that encourages crowds to collaboratively interact with a tangible field of information, visualized by 36 lantern stations. The interface is presented through as a stack of lantern shades, which can track user interaction through touch, motion, and sound. The system is designed as a platform capable of displaying multiple different games, animations, and simulations, and adapts to support many different group interactions. Copyright © 2017 ACM.","Immersive display; Installation; Tangible interaction","Animation; Farms; Installation; Orchards; Wearable computers; Wearable technology; Group interaction; Immersive display; Tangible interaction; User interaction; Ubiquitous computing",2-s2.0-85030838168
"Zhao K., Sakamoto N., Koyamada K.","Using interactive particle-based rendering to visualize a large-scale time-varying unstructured volume with mixed cell types",2017,"IEEE Pacific Visualization Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032019438&doi=10.1109%2fPACIFICVIS.2017.8031593&partnerID=40&md5=e258a86134f22ac40ae6ab44a5b29aed","The primary challenge in the visualization of a large-scale unstructured volume data with mixed cell types is to dissolve a bottleneck caused by visibility sorting of unstructured cells. In this paper, we implement an interactive particle-based rendering method to solve this complex visualization problem. This technique uses opaque particles as the proxy geometry of the mixed unstructured cells so that the visibility sorting process is not needed. This characteristic makes the rendering of mixed-cell unstructured volume efficient. We also construct a resizing function to adjust the particle radius depending on the assigned transfer function so that the transfer function can be adjusted in real time. Furthermore, we develop a time-varying level-of-detail (LOD) rendering to efficiently handle the large-scale time-varying data. This LOD rendering can provide high-speed rendering for animation rendering and high-quality rendering when the animation is stopped at any time step of interest. These features facilitate the detailed analysis of the temporal features of the data. © 2017 IEEE.","Large-scale visualization; Mixed cell; Time-varying visualization; Unstructured volume","Animation; Cells; Cytology; Data visualization; Screening; Sorting; Transfer functions; Visibility; Visualization; Interactive particles; Large-scale visualization; Mixed cells; Time varying; Time-varying data; Unstructured cell; Unstructured volume; Visibility sorting; Rendering (computer graphics)",2-s2.0-85032019438
"Zheng D., Lugaresi L., Inakage M., Chernyshov G., Kunze K., Tag B.","Wearable aura: An interactive projection on personal space to enhance communication",2017,"UbiComp/ISWC 2017 - Adjunct Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030835966&doi=10.1145%2f3123024.3123161&partnerID=40&md5=f09a4296d50cfcefb52dea7690511fb7","This study focuses on how technology can encourage and ease awkwardness-free communications between people in real-world scenarios. We propose a device, The Wearable Aura, able to project a personalized animation onto one's Personal Distance zone. This projection, as an extension of one-self is reactive to user's cognitive status, aware of its environment, context and user's activity. Our user study supports the idea that an interactive projection around an individual can indeed benefit the communications with other individuals. Copyright held by the owner/author(s).","Aura; Communication; Display; Personal Distance; Proxemics; Social interaction; Wearable devices","Communication; Display devices; Human computer interaction; Optical projectors; Ubiquitous computing; Wearable computers; Aura; Personal Distance; Proxemics; Social interactions; Wearable devices; Wearable technology",2-s2.0-85030835966
"Kunama N., Worapan M., Phithakkitnukoon S., Demissie M.","GTFS-VIZ: Tool for preprocessing and visualizing GTFS data",2017,"UbiComp/ISWC 2017 - Adjunct Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030860928&doi=10.1145%2f3123024.3124415&partnerID=40&md5=104fbe324c568050540f03cd0030b598","This paper presents a tool called GTFS-Viz for preprocessing and visualizing General Transit Feed Specification (GTFS) data. GTFS data is a common format for the public transportation schedules with associated geographic information. The tool consists of two main parts: preprocessor and visualizer. The preprocessor retrieves and transfers the GTFS data into a new data format for the visualizer. The visualizer displays an animation of public transport movement according to its schedule specified in the GTFS data on a map. It also displays a graph of the number of public transport vehicles per hour, and allows the user to choose a specific transport route, trip, and stations to visualize. This is the first attempt to build a tool that preprocesses and visualizes GTFS data that is publically available in a format that is not so easy to process with existing standard data visualization tools. © 2017 Association for Computing Machinery.","General Transit Feed Specification; GTFS data; Visualization","Flow visualization; Mass transportation; Specifications; Ubiquitous computing; Visualization; Wearable computers; Wearable technology; Common format; Data visualization tools; Geographic information; GTFS data; Public transport; Public transport vehicles; Public transportation; Transport routes; Data visualization",2-s2.0-85030860928
"Binthaisong A., Srichan J., Phithakkitnukoon S.","Wi-Crowd: Sensing and visualizing crowd on campus using Wi-Fi access point data",2017,"UbiComp/ISWC 2017 - Adjunct Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030859746&doi=10.1145%2f3123024.3124413&partnerID=40&md5=5aae07ab88fa41e96b3a66fe4480e676","This paper presents Wi-Crowd, a system for visualizing the crowd level based on Wi-Fi usage data on campus by presenting it on an interactive 3D graphics, including map rotation, zoom-in/out, and display selections. The system uses animation to display the dynamism of crowd on campus based on the internet usage behavior in different buildings and time periods. The sensed crowd level is comparable to the student registration information. This developed system can be used to sense the crowd level and can be beneficial to future studies in campus behavior or even city-level behavior, and management of internet usage and crowd on campus such as scheduling optimization, campus traffic management and planning. © 2017 Association for Computing Machinery.","Crowd sensing; Smart campus; Visualization tool; Wi-Fi access point data","Data visualization; Scheduling; Wearable computers; Wearable technology; Wireless local area networks (WLAN); Crowd sensing; Internet usage; Scheduling optimization; Smart campus; Time-periods; Traffic management; Visualization tools; Wi-fi access points; Ubiquitous computing",2-s2.0-85030859746
"Kraft J.F., Hurtienne J.","Transition animations support orientation in mobile interfaces without increased user effort",2017,"Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030312797&doi=10.1145%2f3098279.3098566&partnerID=40&md5=735f3936de2f6420ff62fe9664aff558","Some animations in mobile user interfaces aim at supporting user orientation by facilitating users to build a mental model of the UI's structure. Possible drawbacks are that animations are time-consuming and that complex and distracting animations may increase users' mental workload. These effects of orientation animations are investigated in an empirical study. Participants either used an animated or a non-animated version of a mobile movie recommender app. The results imply that animations can support users in building more accurate mental models of the app's structure and enhance gesture-based interaction. No additional costs in terms of time or mental workload were incurred when using the animations. Thus, lightweight orientation animations can have large potential benefits at little cost. © 2017 Association for Computing Machinery.","Animation; Mental model; Mental workload; Orientation; Usability; User experience","Animation; Cognitive systems; Crystal orientation; User interfaces; Gesture-based interaction; Mental model; Mental workload; Mobile user interface; Potential benefits; Transition animation; Usability; User experience; Human computer interaction",2-s2.0-85030312797
[No author name available],"Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2017",2017,"Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030310091&partnerID=40&md5=43a4cb751074bbb40ad69660d168d53f","The proceedings contain 107 papers. The topics discussed include: Zap++: a 20-channel electrical muscle stimulation system for fine-grained wearable force feedback; an interactive 3D health app with multimodal information representation for frozen shoulder: co-creation and evaluation with patients; productive, anxious, lonely - 24 hours without push notification; predicting interruptibility for manual data collection: a cluster-based user model; too tense for candy crush: affect influences user engagement with proactively suggested content; understanding users' perception of simultaneous tactile textures; the connected car: an empirical study of electric cars as mobile digital devices; Roman-txt: forms and functions of Roman Urdu texting; pharos: improving navigation instructions on smart watches by including global landmarks; transition animations support orientation in mobile interfaces without increased user effort; enabling remote deictic communication with mobile devices: an elicitation study; CETA: designing mixed-reality tangible interaction to enhance mathematical learning; designing a ubiquitous sensor-based platform to facilitate learning for young children in Thailand; no passwords needed: the iterative design of a parent-child authentication mechanism; using nature elements in mobile AR for education with children; and improving pocket paint usability via material design compliance and internationalization & localization support on application level.",,,2-s2.0-85030310091
"Stütz T., Domhardt M., Emsenhuber G., Huber D., Tiefengrabner M., Matis N., Ginzinger S.","An Interactive 3D health app with multimodal information representation for Frozen Shoulder: Co-creation and evaluation with patients",2017,"Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030314268&doi=10.1145%2f3098279.3098562&partnerID=40&md5=758d03a9e7e48b448f75dd126277a015","Patients with Frozen Shoulder suffer from a decreased mobility and pain. Exercise-based physiotherapy is a common treatment and patients mostly perform the exercises at home. Correct exercise performance and compliance are the main issues in home-based therapy of Frozen Shoulder patients. To support patients diagnosed with Frozen Shoulder, a multimodal 3D smartphone app was designed, developed and evaluated. Additional to ten potential users, one physician, five physiotherapists, three computer scientists, two 3D artists and one HCI specialist were involved in the co-creation process. The app was evaluated by five patients during a three-week pilot study, which showed the feasibility of our approach. Exercise correctness, usage of multimodal instructions and user satisfaction were analyzed. Exercise correctness was nearly perfect and the interactive 3D animation was used for exercise instructions. Satisfaction using the app was rated very high according to SUS score. The results confirm that the co-creation process led to an effective, highly satisfactory and actually used system.","Co-Creation; eHealth; Evaluation; MHealth; Multimodal information representation; Patients; User study","mHealth; Patient monitoring; Patient treatment; Co-creation; Ehealth; Evaluation; Multi-modal information; Patients; User study; Human computer interaction",2-s2.0-85030314268
"Mirza I., Tabak J.","Designing for delight",2017,"Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030311295&doi=10.1145%2f3098279.3119911&partnerID=40&md5=4201468ddc12bba259d9ff6bac037a0a","Delightful user experiences (UX) create memorable products and generate brand love. Mobile technology allows for UX theatric affordances such as animations, transitions and gestures that can craft macro and micro feature delight. Mobile experiences crafted by companies such as Google, Facebook, KakaoTalk and Uber integrate fun and surprises into their products in an attempt to develop an emotional connection with their users. This talk unpacks what constitutes UX delight, the psychology behind emotional design, how to create a culture that supports building not just usable and simple products but magical ones, and methods to measure the impact of delight on user success and brand perception.","Brand perception; Designing for emotion; Memorable user experiences; User delight","Behavioral research; Product design; Designing for emotion; Emotional connections; Emotional design; Micro-feature; Mobile Technology; User delight; User experience; User experiences (ux); Human computer interaction",2-s2.0-85030311295
"Kim J.","Digital and postdigital 3D animation in the contemporary Chinese art scene: Miao Xiaochun and Lu Yang",2017,"Journal of Chinese Cinemas",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029600596&doi=10.1080%2f17508061.2017.1376553&partnerID=40&md5=41983dd3c74d0192c177d661071cc13f","This article discusses digital three-dimensional animations by Miao Xiaochun and Lu Yang. The two artists’ works are commonly based on the expressive possibilities of digital software and virtual space, such as non-naturalistic rendering of objects, vertical and multiple perspectives distinct from the linear perspective of traditional painting and photography, and the virtual camera's freedom of omnidirectional and gravitation-free movements. While this article provides in-depth analyses of the works in terms of how these expressive possibilities allow Miao and Lu to create the spatially and temporally complex worlds in which past, present and future dynamically coexist and interact with one another, I also argue that both artists are different in their technical and conceptual approaches to digital technology and its impact on reality and subjectivity. To demonstrate these differences, I draw on the ideas of ‘digital’ and ‘postdigital’ art: whereas digital art is marked by the ambivalent tendency to exploit the new properties of the digital while also seeking the ways of translating the forms and techniques of traditional arts in the tools and space of the computer, postdigital art means a variety of artistic responses to the situation that the internet and digital technologies are no longer perceived as new but as fundamentally restructuring our subjectivity and world. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",,,2-s2.0-85029600596
"Yao C.-Y., Chen K.-Y., Guo H.-N., Li C.-C., Lai Y.-C.","Resolution Independent Real-Time Vector-Embedded Mesh for Animation",2017,"IEEE Transactions on Circuits and Systems for Video Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029939404&doi=10.1109%2fTCSVT.2016.2555738&partnerID=40&md5=9a9e7f2a71a4c1ba81d8e59a56757669","High-resolution textures are determinant of not only high rendering quality in gaming and movie industries, but also of burdens in memory usage, data transmission bandwidth, and rendering efficiency. Therefore, it is desirable to shade 3D objects with vector images such as scalable vector graphics (SVG) for compactness and resolution independence. However, complicated geometry and high rendering cost limit the rendering effectiveness and efficiency of vector texturing techniques. In order to overcome these limitations, this paper proposes a real-time resolution-independent vector-embedded shading method for 3D animated objects. Our system first decomposes a vector image consisting of layered close coloring regions into unifying-coloring units for mesh retriangulation and 1D coloring texture construction, where coloring denotes color determination for a point based on an intermediate medium such as a raster/vector image, unifying denotes the usage of the same set of operations, and unifying coloring denotes coloring with the same-color computation operations. We then embed the coloring information and distances to enclosed unit boundaries in retriangulated vertices to minimize embedded information, localize vertex-embedded shading data, remove overdrawing inefficiency, and ensure fixed-length shading instructions for data compactness and avoidance of indirect memory accessing and complex programming structures when using other shading and texturing schemes. Furthermore, stroking is the process of laying down a fixed-width pen-centered element along connected curves, and our system also decomposes these curves into segments using their curve-mesh intersections and embeds their control vertices as well as their widths in the intersected triangles to avoid expensive distance computation. Overall, our algorithm enables high-quality real-time Graphics Processing Unit (GPU)-based coloring for real-time 3D animation rendering through our efficient SVG-embedded rendering pipeline while using a small amount of texture memory and transmission bandwidth. © 2017 IEEE.","Antialiasing; resolution-independent shading; vector embedded; vector representations","Animation; Anti-aliasing; Bandwidth; Coloring; Computer graphics; Computer graphics equipment; Efficiency; Graphics processing unit; Mesh generation; Program processors; Rasterization; Rendering (computer graphics); Structure (composition); Vectors; Wave transmission; Distance computation; Effectiveness and efficiencies; High-resolution textures; Programming structures; Resolution independence; Scalable vector graphics; Transmission bandwidth; Vector representations; Three dimensional computer graphics",2-s2.0-85029939404
"Baldacci A., Ganovelli F., Corsini M., Scopigno R.","Presentation of 3D Scenes Through Video Example",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029285403&doi=10.1109%2fTVCG.2016.2608828&partnerID=40&md5=39f4400ca23266c0ce5ac278a2e27e3c","Using synthetic videos to present a 3D scene is a common requirement for architects, designers, engineers or Cultural Heritage professionals however it is usually time consuming and, in order to obtain high quality results, the support of a film maker/computer animation expert is necessary. We introduce an alternative approach that takes the 3D scene of interest and an example video as input, and automatically produces a video of the input scene that resembles the given video example. In other words, our algorithm allows the user to 'replicate' an existing video, on a different 3D scene. We build on the intuition that a video sequence of a static environment is strongly characterized by its optical flow, or, in other words, that two videos are similar if their optical flows are similar. We therefore recast the problem as producing a video of the input scene whose optical flow is similar to the optical flow of the input video. Our intuition is supported by a user-study specifically designed to verify this statement. We have successfully tested our approach on several scenes and input videos, some of which are reported in the accompanying material of this paper. © 2017 IEEE.","2D vector field comparison; computer animation; Multimedia content production; video similarity","Animation; Optical flows; Computer animation; Cultural heritages; Example videos; Multimedia content production; Static environment; Vector fields; Video sequences; Video similarity; Three dimensional computer graphics",2-s2.0-85029285403
"Carlos García Orden J., Cuenca Queipo J.","A Simple Shear and Torsion-Free Beam Model for Multibody Dynamics",2017,"Journal of Computational and Nonlinear Dynamics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018528310&doi=10.1115%2f1.4036116&partnerID=40&md5=7cf506f50679d884a4da280322583bbb","This paper describes a very simple beam model, amenable to be used in multibody applications, for cases where the effects of torsion and shear are negligible. This is the case of slender rods connecting different parts of many space mechanisms, models useful in polymer physics, computer animation, etc. The proposed new model follows a lumped parameter method that leads to a rotation-free formulation. Axial stiffness is represented by a standard nonlinear truss model, while bending is modeled with a force potential. Several numerical experiments are carried out in order to assess accuracy, which is usually the main drawback of this type of approach. Results reveal a remarkable accuracy in nonlinear dynamical problems, suggesting that the proposed model is a valid alternative to more sophisticated approaches. Copyright © 2017 by ASME.",,"Animation; Torsional stress; Computer animation; Dynamical problems; Lumped parameter method; Multi-body dynamic; Multibody applications; Non-linear truss; Numerical experiments; Space mechanisms; Shear flow",2-s2.0-85018528310
"Bulbul A., Dahyot R.","Populating virtual cities using social media",2017,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006021770&doi=10.1002%2fcav.1742&partnerID=40&md5=a1ead953a1a439c6612f0f6b9d7a3b6e","We propose to automatically populate geo-located virtual cities by harvesting and analyzing online contents shared on social networks and websites. We show how pose and motion paths of agents can be realistically rendered using information gathered from social media. 3D cities are automatically generated using open-source information available online. To provide our final rendering of both static and dynamic urban scenes, we use Unreal game engine. Copyright © 2016 John Wiley & Sons, Ltd.","computer animation; crowd simulations; social media; virtual worlds","Animation; Social networking (online); Virtual reality; Automatically generated; Computer animation; Crowd Simulation; On-line contents; Open source information; Social media; Virtual cities; Virtual worlds; Information use",2-s2.0-85006021770
"Zhang X.","Presentation and Applications of Lotus-root-shaped Grid of Tetrahedron Coordinate Systems",2017,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032286313&partnerID=40&md5=ab7f8edf5cf899441cf3eeaad7f55e50","To achieve smooth morphing between different models with features correspondence, a method of directly establishing correspondences is proposed. Firstly according to the structural characteristics of the input models, divide them into several corresponding parts, and then generate same spherical tetrahedron mesh for each part. Secondly through relevant calculation, find the corresponding point in the target model for each point from source model in each tetrahedron. Finally establish the direct correspondence on the whole. Since the connection of spherical tetrahedron mesh shapes like lotus root, and the calculation for correspondence is mainly based on tetrahedron coordinate system, then we call the generated grid lotus-root-shaped grid of tetrahedron coordinate systems. The experiment results show that this method can effectively realize 3D morphing with features correspondences. © 2017, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","3D morphing; Computer animation; Lotus-root-shaped grid of tetrahedron coordinate systems; Tetrahedron coordinate system","Animation; Computational mechanics; Mesh generation; 3D morphing; Co-ordinate system; Computer animation; Input models; Source modeling; Structural characteristics; Target model; Tetrahedron mesh; Geometry",2-s2.0-85032286313
"Papaefthymiou M., Hildenbrand D., Papagiannakis G.","A Conformal Geometric Algebra Code Generator Comparison for Virtual Character Simulation in Mixed Reality",2017,"Advances in Applied Clifford Algebras",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976328968&doi=10.1007%2fs00006-016-0689-3&partnerID=40&md5=57be9eb05c4a4613a1749d69211a5cee","Over the last few years, recent advances in user interface and mobile computing, introduce the ability to create new experiences that enhance the way we acquire, interact and display information within the world that surrounds us with virtual characters. Virtual reality (VR) is a 3D computer simulated environment that gives to user the experience of being physically present in real or computer-generated worlds; on the other hand, augmented reality (AR) is a live direct or indirect view of a physical environment whose elements are augmented (or supplemented) by computer-generated sensory inputs. Both technologies use interactive devices to achieve the optimum adaptation of the user in the immersive world achieving enhanced presence, harnessing latest advances in computer vision, glasses or head-mounted-displays featuring embedded mobile devices. A common issue in all of them is interpolation errors while using different linear and quaternion algebraic methods when (a) tracking the user’s position and orientation (translation and rotation) using computer vision; (b) tracking using mobile sensors; (c) tracking using gesture input methods to allow the user to interactively edit the augmented scene (translation, rotation and scale) and (d) having animation blending of the virtual characters that augmented the mixed reality scenes (translation and rotation). In this work, we propose an efficient method for robust authoring (rotation) of Augmented reality scene using Euclidean geometric algebra (EGA) rotors and we propose two fast animation blending methods using GA and CGA. We also compare the efficiency of different GA code generators: (a) Gaigen library, (b) libvsr and (c) Gaalop using our animation blending methods and compare them with other alternative animation blending techniques: (a) quaternions and (b) dual-quaternions, so that a future user of GA libraries can choose the most appropriate one that will give the most optimal and faster results. © 2016, Springer International Publishing.","animation; animation blending; augmented Reality; conformal model; Geometric algebra",,2-s2.0-84976328968
"Lakshika E., Barlow M., Easton A.","Understanding the Interplay of Model Complexity and Fidelity in Multiagent Systems via an Evolutionary Framework",2017,"IEEE Transactions on Computational Intelligence and AI in Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030109394&doi=10.1109%2fTCIAIG.2016.2560882&partnerID=40&md5=0a0ddcee7fb3f3435adc2b1570733b78","Modern video games come with highly realistic graphics enabling the players to interact with visually rich virtual worlds. Realistic (life-like) animation of nonplayer characters (NPCs) in such virtual worlds is particularly important to enhance the gaming experience. Multiagent systems are one effective approach to synthesize life-like behaviors and interactions by codifying simple rules into NPCs (each NPC as an autonomous agent). However, such behaviors generally come at the cost of increasing computational expense and complexity in terms of aspects such as number of rules and parameters. Therefore, the desire for high fidelity (highly realistic) behaviors is often in conflict with the drive for low complexity. Multiobjective evolutionary algorithms provide a sophisticated mechanism to optimize two or more conflicting objectives simultaneously. However, evolutionary computing techniques need an appropriate objective function to drive the exploration in the correct direction. Pairing of evolutionary techniques and multiagent systems is challenging in the classes of problems in which the fitness is evaluated based on human aesthetic judgment rather than on objective forms of measurements. In this study, we present a multiobjective evolutionary framework to evolve low complexity and high fidelity multiagent systems by utilizing a machine learning system trained by bootstrapping human aesthetic judgment. We have gathered empirical data in three problem areas - simulation of conversational group dynamics, sheepdog herding behaviors, and traffic dynamics, and show the effectiveness of our approach in deriving low complexity and high fidelity multiagent systems. Further, we have identified common properties of the Pareto-optimal frontiers in the three problem areas that can ultimately lead to an understanding of a relationship between simulation model complexity and behavior fidelity. This understanding will be useful in deciding which level of behavioral fidelity is required for the characters in video games based on the distance to the camera, importance to the scene, and available computational resources. © 2009-2012 IEEE.","Complexity; fidelity; level of detail artificial intelligence (LOD AI); multiagent systems; multiobjective optimization","Animation; Artificial intelligence; Autonomous agents; Digital storage; Evolutionary algorithms; Interactive computer graphics; Learning systems; Multiobjective optimization; Pareto principle; Virtual reality; Complexity; Evolutionary techniques; fidelity; Level of detail; Multi objective evolutionary algorithms; Multi-objective evolutionary; Pareto-optimal frontiers; Sophisticated mechanism; Multi agent systems",2-s2.0-85030109394
"Peter W.F., Dagfinrud H.S., Østerås N., Terwee C.B.","Animated Activity Questionnaire (AAQ), a new method of self-reporting activity limitations in patients with hip and knee osteoarthritis: Comparisons with observation by spouses for construct validity",2017,"Musculoskeletal Care",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263729&doi=10.1002%2fmsc.1172&partnerID=40&md5=e10462a12127cc13188990396e1a4cb8","Objective: The aim of the present study was to evaluate the construct validity of the Animated Activity Questionnaire (AAQ) for measuring activity limitations of patients with hip and knee osteoarthritis (HKOA). Design: In a psychometric design, data from HKOA patients and their spouses in Norway and the Netherlands were collected independently of each other, using the AAQ, the Function of Daily Living (FDL) subscale from the Hip disability or Knee injury Osteoarthritis Outcome Scale (H/KOOS) and the Numerical Rating Scale for pain (NRS-pain). By showing standardized animations on a computer, the AAQ minimizes the influence of the patient's own frame of reference. Therefore, we expected a strong correlation (≥ 0.6) for the AAQ, between patients and spouses. By contrast, we expected a moderate correlation (0.3–0.6) between patients and spouses on the H/KOOS and the NRS-pain. Analyses were carried out by partial correlations. Results: In total, 29 Norwegian and 30 Dutch patients with HKOA and their spouses participated. A high correlation between patient and spouse scores on the AAQ (r = 0.61) was confirmed, but the correlations between patient and spouses scores on the H/KOOS FDL subscale (0.55) and NRS-pain (0.64) were higher than expected, indicating that spouses may have insight not only into the observed activity limitations of the patient (as measured by the AAQ), but also into patients' subjectively perceived activity limitations (as measured by written questionnaires). Conclusions: The construct validity of the AAQ was supported by a high correlation between patients' and spouses' scores. Our hypothesis that spouses are less influenced by patients' subjective frame of reference in responding to self-report questionnaires may not be correct. Copyright © 2016 John Wiley & Sons, Ltd.","activity limitations; osteoarthritis; PROM; video animations",,2-s2.0-85008263729
"Brom C., Hannemann T., Stárková T., Bromová E., Děchtěrenko F.","The role of cultural background in the personalization principle: Five experiments with Czech learners",2017,"Computers and Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019136212&doi=10.1016%2fj.compedu.2017.01.001&partnerID=40&md5=549e7f4d85fd4815f958ec7c8cbafd23","Composing instructional texts in multimedia learning materials in a conversational style rather than a formal style can facilitate learning. We investigated whether a specific language/cultural background could present a boundary condition for this effect. In four experiments with a Czech sample (N = 278), we replicated a seminal experiment conducted on a US sample (with a short animation on the topic of lightning formation), which demonstrated a large effect size in favor of the instructional texts in the conversational style. In our four experiments, we varied between two types of audiences (a college and a high school audience) and two types of short animations (the original one and a complementary one). Instructional texts in a conversational style brought no overall advantage for the Czech audience (ηp 2 = .00; the high school audience: d = 0.48, 0.22; the college audience: d = −0.45, −0.04). Twenty-nine percent of participants who received the conversational instructional texts expressed explicit reservations regarding the style of the language. In the fifth supplementary experiment, Czech participants (N = 138) had to rate preferences on computer tutor's printed statements. Direct rather than polite statements were preferred. Limited benefits of conversational/polite instructional texts for Czech learners are probably related to the generally more formal approach to education in the Czech Republic compared to the US schooling system. We also failed to find a link between several affective variables and learning outcomes; with the exception of a relationship of generalized positive affect, levels of flow and perceived difficulty to some of the learning outcomes. © 2017 Elsevier Ltd","Animation; Mental model; Multimedia learning; Personalization principle; Positive affect","Animation; Cultural backgrounds; Instructional texts; Mental model; Multi-media learning; Perceived difficulties; Personalizations; Positive affects; Specific languages; E-learning",2-s2.0-85019136212
"Chan L., Mackintosh J., Dobbins M.","How the “Understanding Research Evidence” web-based video series from the national collaborating centre for methods and tools contributes to public health capacity to practice evidence-informed decision making: Mixed-methods evaluation",2017,"Journal of Medical Internet Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031126927&doi=10.2196%2fjmir.6958&partnerID=40&md5=eaad9151c466a4afef863ba8376eb289","Background: The National Collaborating Centre for Methods and Tools (NCCMT) offers workshops and webinars to build public health capacity for evidence-informed decision-making. Despite positive feedback for NCCMT workshops and resources, NCCMT users found key terms used in research papers difficult to understand. The Understanding Research Evidence (URE) videos use plain language, cartoon visuals, and public health examples to explain complex research concepts. The videos are posted on the NCCMT website and YouTube channel. Objective: The first four videos in the URE web-based video series, which explained odds ratios (ORs), confidence intervals (CIs), clinical significance, and forest plots, were evaluated. The evaluation examined how the videos affected public health professionals’ practice. A mixed-methods approach was used to examine the delivery mode and the content of the videos. Specifically, the evaluation explored (1) whether the videos were effective at increasing knowledge on the four video topics, (2) whether public health professionals were satisfied with the videos, and (3) how public health professionals applied the knowledge gained from the videos in their work. Methods: A three-part evaluation was conducted to determine the effectiveness of the first four URE videos. The evaluation included a Web-based survey, telephone interviews, and pretest and posttests, which evaluated public health professionals’ experience with the videos and how the videos affected their public health work. Participants were invited to participate in this evaluation through various open access, public health email lists, through informational flyers and posters at the Canadian Public Health Association (CPHA) conference, and through targeted recruitment to NCCMT’s network. Results: In the Web-based surveys (n=46), participants achieved higher scores on the knowledge assessment questions from watching the OR (P=.04), CI (P=.04), and clinical significance (P=.05) videos but not the forest plot (P=.12) video, as compared with participants who had not watched the videos. The pretest and posttest (n=124) demonstrated that participants had a better understanding of forest plots (P<.001) and CIs (P<.001) after watching the videos. Due to small sample size numbers, there were insufficient pretest and posttest data to conduct meaningful analyses on the clinical significance and OR videos. Telephone interview participants (n=18) thought the videos’ use of animation, narration, and plain language was appropriate for people with different levels of understanding and learning styles. Participants felt that by increasing their understanding of research evidence, they could develop better interventions and design evaluations to measure the impact of public health initiatives. Conclusions: Overall, the results of the evaluation showed that watching the videos resulted in an increase in knowledge, and participants had an overall positive experience with the URE videos. With increased competence in using the best available evidence, professionals are empowered to contribute to decisions that can improve health outcomes of communities.","Capacity building; Computer-assisted instruction; Continuing education; Evidence-based practice; Public health; Public health practice","adult; capacity building; comparative effectiveness; continuing education; controlled study; decision making; e-mail; female; forest; human; language; learning style; major clinical study; male; pretest posttest control group design; public health service; sample size; teaching; telephone interview; videorecording",2-s2.0-85031126927
"Wellmann J.","Animating embryos: The in toto representation of life",2017,"British Journal for the History of Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032631730&doi=10.1017%2fS0007087417000656&partnerID=40&md5=62f0ce37649f8260705c0ef9732a3ab6","With the recent advent of systems biology, developmental biology is taking a new turn. Attempts to create a 'digital embryo' are prominent among systems approaches. At the heart of these systems-based endeavours, variously described as 'in vivo imaging', 'live imaging' or 'in toto representation', are visualization techniques that allow researchers to image whole, live embryos at cellular resolution over time. Ultimately, the aim of the visualizations is to build a computer model of embryogenesis. This article examines the role of such visualization techniques in the building of a computational model, focusing, in particular, on the cinematographic character of these representations. It asks how the animated representation of development may change the biological understanding of embryogenesis. By situating the animations of the digital embryo within the iconography of developmental biology, it brings to light the inextricably entwined, yet shifting, borders between the animated, the living and the computational. © 2017 British Society for the History of Science.",,,2-s2.0-85032631730
"Sadikov A., Groznik V., Možina M., Žabkar J., Nyholm D., Memedi M., Bratko I., Georgiev D.","Feasibility of spirography features for objective assessment of motor function in Parkinson's disease",2017,"Artificial Intelligence in Medicine",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017478908&doi=10.1016%2fj.artmed.2017.03.011&partnerID=40&md5=39b593a885cb3467cd6b65f62c2d7b9f","Objective Parkinson's disease (PD) is currently incurable, however proper treatment can ease the symptoms and significantly improve the quality of life of patients. Since PD is a chronic disease, its efficient monitoring and management is very important. The objective of this paper was to investigate the feasibility of using the features and methodology of a spirography application, originally designed to detect early Parkinson's disease (PD) motoric symptoms, for automatically assessing motor symptoms of advanced PD patients experiencing motor fluctuations. More specifically, the aim was to objectively assess motor symptoms related to bradykinesias (slowness of movements occurring as a result of under-medication) and dyskinesias (involuntary movements occurring as a result of over-medication). Materials and methods This work combined spirography data and clinical assessments from a longitudinal clinical study in Sweden with the features and pre-processing methodology of a Slovenian spirography application. The study involved 65 advanced PD patients and over 30,000 spiral-drawing measurements over the course of three years. Machine learning methods were used to learn to predict the “cause” (bradykinesia or dyskinesia) of upper limb motor dysfunctions as assessed by a clinician who observed animated spirals in a web interface. The classification model was also tested for comprehensibility. For this purpose a visualisation technique was used to present visual clues to clinicians as to which parts of the spiral drawing (or its animation) are important for the given classification. Results Using the machine learning methods with feature descriptions and pre-processing from the Slovenian application resulted in 86% classification accuracy and over 0.90 AUC. The clinicians also rated the computer's visual explanations of its classifications as at least meaningful if not necessarily helpful in over 90% of the cases. Conclusions The relatively high classification accuracy and AUC demonstrates the usefulness of this approach for objective monitoring of PD patients. The positive evaluation of computer's explanations suggests the potential use of this methodology in a decision support setting. © 2017 Elsevier B.V.","Movement disorder; Objective monitoring; Parkinson's disease; Spirography; Spirography features; Visualisation","Artificial intelligence; Decision support systems; Learning systems; Neurodegenerative diseases; Patient treatment; Visualization; Classification accuracy; Classification models; Involuntary movements; Machine learning methods; Movement disorders; Parkinson's disease; Spirography; Spirography features; Diseases; aged; Article; behavior; bradykinesia; clinical assessment; daily life activity; decision support system; dyskinesia; early diagnosis; female; human; longitudinal study; machine learning; major clinical study; male; mood; motor dysfunction; motor performance; Parkinson disease; priority journal; retrospective study; spirography; Sweden; symptom assessment; task performance; telemetry; thinking; time series analysis; tremor; Unified Parkinson Disease Rating Scale; upper limb",2-s2.0-85017478908
"Ivson P., Nascimento D., Celes W., DJ Barbosa S.","CasCADe: A Novel 4D Visualization System for Virtual Construction Planning",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028714319&doi=10.1109%2fTVCG.2017.2745105&partnerID=40&md5=1aeb1414abbef024a7971a06c7266972","Building Information Modeling (BIM) provides an integrated 3D environment to manage large-scale engineering projects. The Architecture, Engineering and Construction (AEC) industry explores 4D visualizations over these datasets for virtual construction planning. However, existing solutions lack adequate visual mechanisms to inspect the underlying schedule and make inconsistencies readily apparent. The goal of this paper is to apply best practices of information visualization to improve 4D analysis of construction plans. We first present a review of previous work that identifies common use cases and limitations. We then consulted with AEC professionals to specify the main design requirements for such applications. These guided the development of CasCADe, a novel 4D visualization system where task sequencing and spatio-temporal simultaneity are immediately apparent. This unique framework enables the combination of diverse analytical features to create an information-rich analysis environment. We also describe how engineering collaborators used CasCADe to review the real-world construction plans of an Oil &amp; Gas process plant. The system made evident schedule uncertainties, identified work-space conflicts and helped analyze other constructability issues. The results and contributions of this paper suggest new avenues for future research in information visualization for the AEC industry. IEEE","Animation; Data visualization; design studies; integrating spatial and non-spatial data visualization; Schedules; Solid modeling; task and requirements analysis; Three-dimensional displays; Visualization; Visualization in physical sciences and engineering","Animation; Architectural design; Flow visualization; Information analysis; Information systems; Scheduling; Three dimensional computer graphics; Uncertainty analysis; Visualization; Design studies; Requirements analysis; Solid model; Three-dimensional display; Visualization in physical sciences and engineerings; Data visualization",2-s2.0-85028714319
"Yu J., Chen C.W.","From talking head to singing head: A significant enhancement for more natural human computer interaction",2017,"Proceedings - IEEE International Conference on Multimedia and Expo",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030237478&doi=10.1109%2fICME.2017.8019362&partnerID=40&md5=86f9b7b6a88365011eca81da2a5bb824","This paper proposes a 3D virtual animating head system, which can not only talk but also sing. With a reconstructed head mesh model, including external/internal articulators, from multi-source images, biology information are first used to visualize each phoneme with a musical note. The synchronicity between songs and articulatory movements is then modeled by a deep neural network trained on an audio/articulatory corpus. Finally, the visualization results of phonemes are blended by the synchronicity model to produce the song synchronized articulatory animations. Quantitative and qualitative improvements of singing ability on human computer interaction are demonstrated by comparing with other state-of-the-art talking head systems. © 2017 IEEE.","Articulatory animation; Virtual head","Deep neural networks; Mesh model; Multi-source images; Musical notes; Natural human computer interactions; State of the art; Talking heads; Virtual heads; Visualization results; Human computer interaction",2-s2.0-85030237478
"Vlachos E., Lalos A.S., Moustakas K., Berberidis K.","Efficient graph-based matrix completion on incomplete animated models",2017,"Proceedings - IEEE International Conference on Multimedia and Expo",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030216644&doi=10.1109%2fICME.2017.8019502&partnerID=40&md5=cbc6e384f3711b2e2c10ad24d990daa2","Recently, there has been increasing interest for easy and reliable generation of 3D animated models facilitating several real-time applications. In most of these applications, the reconstruction of soft body animations is based on time-varying point clouds which are irregularly sampled and highly incomplete. To overcome these imperfections, we introduce a novel reconstruction technique, using graph-based matrix completion approaches. The presented method exploits spatio-temporal coherences by implicitly forcing the proximity of the adjacent 3D points in time and space. The proposed constraints are modeled by using the weighted Laplacian graphs and are constructed from the available points. Extensive evaluation studies, carried out using a collection of different highly-incomplete dynamic models, verify that the proposed technique achieves plausible reconstruction output despite the constraints posed by arbitrarily complex and motion scenarios. © 2017 IEEE.","Animated models; Incomplete dynamic point clouds; Matrix completion; Point cloud reconstruction","Graphic methods; Animated models; Evaluation study; Matrix completion; Point cloud; Real-time application; Reconstruction techniques; Spatio temporal; Weighted laplacian; Three dimensional computer graphics",2-s2.0-85030216644
"Pham H.X., Cheung S., Pavlovic V.","Speech-Driven 3D Facial Animation with Implicit Emotional Awareness: A Deep Learning Approach",2017,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030238989&doi=10.1109%2fCVPRW.2017.287&partnerID=40&md5=3b1af41b009212d33823fe4c5ebfa4a6","We introduce a long short-term memory recurrent neural network (LSTM-RNN) approach for real-time facial animation, which automatically estimates head rotation and facial action unit activations of a speaker from just her speech. Specifically, the time-varying contextual non-linear mapping between audio stream and visual facial movements is realized by training a LSTM neural network on a large audio-visual data corpus. In this work, we extract a set of acoustic features from input audio, including Mel-scaled spectrogram, Mel frequency cepstral coefficients and chromagram that can effectively represent both contextual progression and emotional intensity of the speech. Output facial movements are characterized by 3D rotation and blending expression weights of a blendshape model, which can be used directly for animation. Thus, even though our model does not explicitly predict the affective states of the target speaker, her emotional manifestation is recreated via expression weights of the face model. Experiments on an evaluation dataset of different speakers across a wide range of affective states demonstrate promising results of our approach in real-time speech-driven facial animation. © 2017 IEEE.",,"Animation; Audio acoustics; Blending; Computer vision; Deep learning; Long short-term memory; Recurrent neural networks; Speech recognition; 3d facial animations; Acoustic features; Audio-visual data; Emotional awareness; Facial animation; Learning approach; Mel frequency cepstral co-efficient; Nonlinear mappings; Pattern recognition",2-s2.0-85030238989
"He Z., Zhang J., Kan M., Shan S., Chen X.","Robust FEC-CNN: A High Accuracy Facial Landmark Detection System",2017,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030256078&doi=10.1109%2fCVPRW.2017.255&partnerID=40&md5=88364d390dbb24474ac1743e0cebb79f","Facial landmark detection, as a typical and crucial task in computer vision, is widely used in face recognition, face animation, facial expression analysis, etc. In the past decades, many efforts are devoted to designing robust facial landmark detection algorithms. However, it remains a challenging task due to extreme poses, exaggerated facial expression, unconstrained illumination, etc. In this work, we propose an effective facial landmark detection system, recorded as Robust FEC-CNN (RFC), which achieves impressive results on facial landmark detection in the wild. Considering the favorable ability of deep convolutional neural network, we resort to FEC-CNN as a basic method to characterize the complex nonlinearity from face appearance to shape. Moreover, face bounding box invariant technique is adopted to reduce the landmark localization sensitivity to the face detector while model ensemble strategy is adopted to further enhance the landmark localization performance. We participate the Menpo Facial Landmark Localisation in-the-Wild Challenge and our RFC significantly outperforms the baseline approach APS. Extensive experiments on Menpo Challenge dataset and IBUG dataset demonstrate the superior performance of the proposed RFC. © 2017 IEEE.",,"Computer vision; Deep neural networks; Neural networks; Pattern recognition; Complex nonlinearity; Convolutional neural network; Facial expression analysis; Facial Expressions; Facial landmark; Facial landmark detection; Landmark localization; Model ensembles; Face recognition",2-s2.0-85030256078
"Sra M., Vijayaraghavan P., Rudovic O., Maes P., Roy D.","DeepSpace: Mood-Based Image Texture Generation for Virtual Reality from Music",2017,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030214716&doi=10.1109%2fCVPRW.2017.283&partnerID=40&md5=c87ba54dac21c2a2c123703b7ac8552c","Affective virtual spaces are of interest for many VR applications in areas of wellbeing, art, education, and entertainment. Creating content for virtual environments is a laborious task involving multiple skills like 3D modeling, texturing, animation, lighting, and programming. One way to facilitate content creation is to automate sub-processes like assignment of textures and materials within virtual environments. To this end, we introduce the DeepSpace approach that automatically creates and applies image textures to objects in procedurally created 3D scenes. The main novelty of our DeepSpace approach is that it uses music to automatically create kaleidoscopic textures for virtual environments designed to elicit emotional responses in users. Specifically, DeepSpace exploits the modeling power of deep neural networks, which have shown great performance in image generation tasks, to achieve mood-based image generation. Our study results indicate the virtual environments created by DeepSpace elicit positive emotions and achieve high presence scores. © 2017 IEEE.",,"Computer vision; Deep neural networks; Pattern recognition; Virtual reality; Content creation; Emotional response; Image generations; Modeling power; Positive emotions; Texture generation; Virtual spaces; VR applications; Image texture",2-s2.0-85030214716
"Decker M.J., Du Vernay J.P., McLeod J.B.","Putting roman dams in context: A virtual approach",2017,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030238732&partnerID=40&md5=c90b7f375918f560128467e3b887d6a4","Water resources and management have become a critical global issue. During the half-millennium of its existence, the Roman Empire developed numerous strategies to cope with water management, from large-scale urban aqueduct systems, to industrial-scale water mills designed to cope with feeding growing city populations. Roman engineers encountered, adopted, and adapted indigenous hydraulic systems, and left lasting imprints on the landscape of the Mediterranean and temperate Western Europe by employing a range of water technologies. A recent academic study has enabled the identification of remains of and references to seventy-Two dams from the Roman era, constructed in Spain between the 1st and 4th century AD. Such unique heritage, without comparisons in the Mediterranean makes Spain an emblematic case study for the analysis of Roman hydraulic engineering and water management policies. Fifty dams have been located and detailed. The twenty-Two outstanding, although identified on the ground, have not been able to be acceptably characterized, due in some cases to their being ruins in a highly degraded state, others due to their being masked by repairs and reconstructions subsequent to the Roman era. A good example of such neglected dams is the buttress dam of Consuegra , in Toledo province (Castilla-La Mancha). Dating to the 3rd - 4th century AD, the Dam of Consuegra, on the basin of the Guadiana, with its over 600 metres length and 4,80 metres height, is a remarkable case of Roman engineering mastery. It had a retaining wall upstream, numerous buttresses and perhaps an embankment downstream, of which no remains are left. The application of 3D digital imaging technique to create a high quality virtual model of such monuments has proved to be successful especially for the study of the technological aspects related its construction. The case study of the Roman dam of Muel (Zaragoza) has shown, in fact, as best practices in digital archaeology can provide an original and innovative perspective on a long time studied monument. In this paper it will be explored how deploying recent computer technologies to the Roman dam at Consuegra can advance our understanding of the history of local and regional landscape change and the technology of water management. In summer 2016, the dam has been documented with terrestrial laser scanning with two FARO Focus 3D x330 and aerial photogrammetry image capturing with a DJI Phantom 4 drone. Data was processed in various 3D software applications to generate 3D representations of the dam including 3D point clouds, animations, and meshed models. © Authors 2017. CC BY 4.0 License.","3D modeling; Drone-based photogrammetry; GIS; Point cloud; Roman dam; Spain; Terrestrial laser scanning","Application programs; Dams; Drones; Fluid mechanics; Geographic information systems; Hydraulic equipment; Hydraulic machinery; Hydraulic structures; Imaging techniques; Laser applications; Photogrammetry; Shore protection; Steel beams and girders; Surface analysis; Three dimensional computer graphics; Unmanned aerial vehicles (UAV); Water management; Water resources; 3-d modeling; Aerial photogrammetry; Hydraulic engineering; Point cloud; Spain; Technological aspects; Terrestrial laser scanning; Water management policy; Rivers",2-s2.0-85030238732
"Cheong Y.-G., Park K., Park W.-H., Bae B.-C.","A database-centric architecture for interactive storytelling",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030772064&doi=10.1145%2f3102071.3106356&partnerID=40&md5=bbf4d84d9773bc6ae54a04e6c0392396","In this study, we propose a system design for interactive narrative generation which uses database for information exchange among system sub-modules. We present database schema design and a simple example to show how our approach works. We conclude with our future work. © 2017 ACM.","Animation; Narrative generation; System","Animation; Computer games; Database schemas; Information exchanges; Interactive narrative; Interactive storytelling; Narrative generation; Submodules; System; Database systems",2-s2.0-85030772064
"Pineda I., Gwun O.","Leaf modeling and growth process simulation using the level set method",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028965011&doi=10.1109%2fACCESS.2017.2738032&partnerID=40&md5=1be83e0c7482156607dfc1fcd1ba7490","This paper presents a simulation of the growth process of leaves for computer graphics, visualization, and virtual reality applications. The following two-stage simulation is presented in this paper. First, a reference image is used to guide the early stage growth of the leaf; second, a growth function was created based on several vector fields controlled by a generalized logistic function. This growth function allows the leaf growth to continue beyond the information provided by the reference image. The core of both stages is the use of the level set method to extract and evolve the leaf shape. The proposed method facilitates the creation of frequently needed objects in an easy and flexible way that releases the user, usually an animator, from the burden of animating a leaf, which is usually a background object in a scene. We present several results from our experiments using various growth parameters and different leaves to showcase the advantages of using our method. © 2017 IEEE.","leaf growth; Leaf simulation; level set method; signed distance function","Animation; Computer graphics; Drop breakup; Functions; Level measurement; Mathematical models; Virtual reality; Computational model; Leaf growth; Leaf simulation; Level Set; Level Set method; Shape; Signed distance function; Solid model; Numerical methods",2-s2.0-85028965011
"Phadung M., Wani N., Tongmnee N.-A.","The development of AR book for computer learning",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028315241&doi=10.1063%2f1.4995161&partnerID=40&md5=5ea2633cac9aebf33aafc987e4f2bef1","Educators need to provide the alternative educational tools to foster learning outcomes of students. By using AR technology to create exciting edutainment experiences, this paper presents how augmented reality (AR) can be applied in the education. This study aims to develop the AR book for tenth grade students (age 15-16) and evaluate its quality. The AR book was developed based on ADDIE framework processes to provide computer learning on software computer knowledge. The content was accorded with the current Thai education curriculum. The AR book had 10 pages in three topics (the first was ""Introduction,"" the second was ""System Software"" and the third was ""Application Software""). Each page contained markers that placed virtual objects (2D animation and video clip). The obtained data were analyzed in terms of average and standard deviation. The validity of multimedia design of the AR book was assessed by three experts in multimedia design. A five-point Likert scale was used and the values were X=4.84, S.D. = 1.27 which referred to very high. Moreover, three content experts, who specialize in computer teaching, evaluated the AR book's validity. The values determined by the experts were X=4.69, S.D. = 0.29 which referred to very high. Implications for future study and education are discussed. © 2017 Author(s).",,,2-s2.0-85028315241
"Hu Y., Zhu J., Wu B.","Scaffolding Spatial Thinking with Visualization and Embodiment: A 3D Multimedia Approach",2017,"Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030221313&doi=10.1109%2fICALT.2017.53&partnerID=40&md5=f74134fbfcc693471b3d1489e282ff8a","Spatial thinking is a prevalent ability required in Science, Technology Engineering, and Math (STEM) domains, which suggests the importance of training spatial abilities. This study investigated a multimedia approach in terms of combing 3D animation and manipulation to train the spatial skills. 128 undergraduates recruited in the experiment revealed that the designed 3-D learning tool is a promising strategy to improve mental rotation with the help of 3D animation and embodied learning. © 2017 IEEE.","3D animation and rotation; multimedia learning; spatial thinking","Animation; Personnel training; Scaffolds; Three dimensional computer graphics; 3D animation; 3D multimedia; Learning tool; Mental rotation; Multi-media learning; Spatial abilities; Spatial skills; Spatial thinking; Engineering education",2-s2.0-85030221313
"Mancera L., Baldiris S., Fabregat R., Gomez S., Mejia C.","ATenDerAH: A Videogame to Support e-Learning Students with ADHD",2017,"Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030266223&doi=10.1109%2fICALT.2017.157&partnerID=40&md5=bcfdd07fe66e741395debdde694e7e87","This paper presents aTenDerAH, a videogame designed to support e-Learning processes of young-adults students, especially those suffering from Attention Deficit Hyperactivity Disorder (ADHD). aTenDerAH was developed using Unity as the cross-platform game engine and development tool, Cinema 4D for creating models and animations in 3D, and Photoshop for creating textures to the 3D models. The videogame was integrated into the architecture of Atutor e-learning platform to carry out a case study of the perception of aTenDerAH from the point of view of a student suffering from ADHD, a student without this syndrome and a teacher. Participants agreed on being satisfied with the tool goals and the positive influence of the videogame in the learning process. © 2017 IEEE.","ADHD; Attention Deficit Hyperactivity Disorder; e-entertainment; e-learning; game-based learning; Videogame","Animation; Diseases; E-learning; Students; Teaching; Three dimensional computer graphics; ADHD; Attention deficit hyperactivity disorder; Cross-platform; Development tools; E-learning platforms; Game-based Learning; Learning process; Videogame; Education",2-s2.0-85030266223
"Punchimudiyanse M., Meegama R.G.N.","Animation of fingerspelled words and number signs of the Sinhala Sign language",2017,"ACM Transactions on Asian and Low-Resource Language Information Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028544363&doi=10.1145%2f3092743&partnerID=40&md5=b92b7f2e5d4c2ffd0051cfb7e3f49a6b","Sign language is the primary communication medium of the aurally handicapped community. Often, a sign gesture is mapped to a word or a phrase in a spoken language and named as a conversational sign. A fingerspelling sign is a special sign derived to show a single character that matches a character in the alphabet of a given language. This enables the deaf community to express words that do not have a conversational sign, such as a name, using a letter-by-letter technique. Sinhala Sign Language (SSL) uses a phonetic pronunciation mechanism to decode such words due to the presence of one or more modifiers after a consonant. Expressing numbers also have a similar notation, and it is broken down into parts before interpretation in sign gestures. This article presents the variations implemented to make the 3D avatar-based interpreter system look similar to an actual fingerspelled SSL by a human interpreter. To accomplish the task, a phonetic English-based 3D avatar animation system is developed with Blender animation software. The conversion of Sinhala Unicode text to phonetic English and numbers written in digits to sign gestures is done with a Visual Basic.NET (VB.NET) application. The presented application has 61 SSL fingerspelling signs and 40 SSL number signs. It is capable of interpreting any word written using the modern Sinhala alphabet without conversational signs and interprets the numbers that go up to the billions. This is a helpful tool in teaching SSL fingerspelling and number signs of SSL to deaf children. © 2017 ACM.","3D signing avatar; Number gesture animation; Sinhala fingerspelling; Sinhala Sign language","Animation; Blending; Education; Linguistics; 3D avatar animation; Animation softwares; Communication medium; Gesture animation; Interpreter systems; Sign language; Signing avatars; Sinhala fingerspelling; Three dimensional computer graphics",2-s2.0-85028544363
"Scherer U., Godin J.-G.J., Schuett W.","Validation of 2D-animated pictures as an investigative tool in the behavioural sciences: A case study with a West African cichlid fish, Pelvicachromis pulcher",2017,"Ethology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019255151&doi=10.1111%2feth.12630&partnerID=40&md5=481cd4e49f597d4eebde625e3c9678fe","Virtual stimuli represent an increasingly popular tool in the study of animal behaviour. Modern techniques have the potential to simplify and improve traditional experiments using live stimuli. However, the increasing availability of diverse techniques is associated with problems and limitations. Although many new methods have been developed, their validation remains largely untested. In the present study, we therefore performed two experiments to test whether 2-D animations of predators and conspecifics elicit biologically appropriate behavioural responses in male rainbow kribs, Pelvicachromis pulcher. Individual responses towards a sympatric natural fish predator, Parachanna obscura, were tested using live predators and still colour photographs, animated using PowerPoint©. Compared to control trials (empty aquarium and white computer screen, respectively), individuals decreased their activity in response to both live and animated predators. We found no difference in activity between live and animation trials. Further, we tested individual aggression (frequency of aggressive behaviours) exhibited towards live and animated conspecifics. Individual aggressive behaviours shown towards live and animated conspecifics were positively correlated. Moreover, an individual's mean distance towards the opponent was a suitable proxy for individual aggression permitting the facilitation and standardisation of an individual's aggression through the use of a tracking software compared with the more laborious, traditional manual assessment. Our results show that simple, inexpensive animation techniques have the potential to provide an easy-to-apply and useful technological advance in animal behaviour research. © 2017 Blackwell Verlag GmbH","activity; aggression; boldness; computer animation; Parachanna obscura; virtual stimulus","activity pattern; aggression; behavioral response; cichlid; computer; conspecific; model validation; percid; photograph; software; standardization; technological development; two-dimensional modeling; African cichlids; Animalia; Pelvicachromis; Pelvicachromis pulcher",2-s2.0-85019255151
"Butler N.E., Magrath R.D., Peters R.A.","Lack of alarm calls in a gregarious bird: models and videos of predators prompt alarm responses but no alarm calls by zebra finches",2017,"Behavioral Ecology and Sociobiology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024378157&doi=10.1007%2fs00265-017-2343-z&partnerID=40&md5=cce078c474b910cd70514bd6bb2abd17","Abstract: Many vertebrates use vocalizations to communicate about the presence of predators, and some encode information about predator type or behavior. A fast-approaching predator typically elicits a “flee alarm call,” prompting others to escape to safety. In a field experiment, we presented gliding models of a predatory bird to several species representing four families of passerine, including our model species, the zebra finch (Taeniopygia guttata). All families presented with the glider gave a distinct call on at least one occasion, apart from the zebra finch, for which no specific alarm call was recorded. Following on from this unexpected result, we conducted an experiment in which we exposed captive zebra finches to video of a looming raptor. Results of the captive study showed that birds responded to the looming raptor with escape behavior and responded to less threatening stimuli with orienting or startle behavior. Despite this anti-predator response, birds did not give any distinct alarm call, and the distance calls of both males and females did not differ in structure or rate of delivery after exposure to a stimulus. Zebra finches are one of the most studied birds in the world, are gregarious, and have a rich vocal repertoire, yet their alarm communication has not been investigated experimentally. Our results are consistent with the hypothesis that zebra finches lack a flee alarm call and appear not to signal about immediate danger through a change in calling rate. Significance statement: Many animals emit alarm calls when faced with a threatening event in order to communicate with nearby group members. Threatening events can be simulated with models or by presenting a video of a looming stimulus on a screen. In separate studies, we presented gliding models and computer animations of a hawk to zebra finches, a bird species used in studies around the world, in order to test if they gave alarm calls to warn others of approaching danger. Although birds fled in response to the simulated predators, they did not emit a distinct alarm call. The birds also did not change their rate of calling or the acoustic structure of their distance calls. Surprisingly for a social and highly vocal species, the birds appear to lack alarm calls warning flockmates of immediate danger. © 2017, Springer-Verlag GmbH Germany.","Alarm calls; Anti-predator behavior; Computer animation; Field study; Video playback; Zebra finch","antipredator defense; behavioral response; computer; escape behavior; field method; gliding; passerine; predator; raptor; signaling; videography; vocalization; Animalia; Aves; Passeriformes; Raptores; Taeniopygia guttata; Vertebrata",2-s2.0-85024378157
"Shi N., Min Z., Zhang P.","Effects of visualizing roles of variables with animation and IDE in novice program construction",2017,"Telematics and Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013954997&doi=10.1016%2fj.tele.2017.02.005&partnerID=40&md5=6afff5728c45e071d9e256459439521f","In this research, the researchers apply the roles of variables visualization to the teaching of novice C language programmers. The results are evaluated using the Structure of Observed Learning Outcomes (SOLO) taxonomy. The participants of the research were fifty-five undergraduates who major in computer science at a polytechnic institute. They were divided into an experimental group and a control group. The students from the control group learned programming in the traditional role-based teaching method. The students in the experimental group learned programming using variables visualization with the support of PlanAni and generic integrated development environment (IDE). For the purposes of determining the effects of the role-based visualization teaching, the SOLO level of the code writing was graded according the SOLO categories for program construction. A course satisfaction questionnaire was conducted. Data analyses show there was a significant improvement of SOLO level of program construction and a higher approval about the roles of variables. These results indicate that visualizing the roles of variables with animations and IDE can provide novices with a new conceptual framework that enables them to design relational program from a holistic point of view and helps them learn the concept of the roles of variables. © 2017 Elsevier Ltd","Novice programming; Roles of variables; SOLO taxonomy; Teaching/learning strategies; Visualization","Flow visualization; Integrodifferential equations; Taxonomies; Teaching; Visualization; Conceptual frameworks; Experimental groups; Integrated development environment; Novice programming; Program construction; Roles of variables; Teaching methods; Teaching/learning strategy; C (programming language)",2-s2.0-85013954997
"Fujita M., Saito S.","Hand-drawn animation with self-shaped canvas",2017,"ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028584933&doi=10.1145%2f3102163.3102212&partnerID=40&md5=0f062645441b1cb04a76740317f06418","Although 3D CG tools produce similar style animations with conventional 2D animation, conventional hand-drawn animation has advantages that cannot be substituted in animation produced by those tools. This paper introduces a new method to assist animators in creating 2D keyframe animation, which utilizes the self-shaped canvas hidden from the user. Drawing keyframes is the main input. Because the canvas has a three-dimensional shape deformed according to keyframes, inbetween animation with them mapped on it obtains depth-aware motion. © 2017 Copyright held by the owner/author(s).","Animation; Drawing; Inbetweening; Non-photorealistic rendering","Computer graphics; Drawing (graphics); Interactive computer graphics; 2D animation; Hand-drawn; In-betweening; Key-frames; Non-Photorealistic Rendering; Three-dimensional shape; Animation",2-s2.0-85028584933
"Maki N., Yamanouchi T., Hilano T., Yanaka K.","Creation of 3DCG animation using a four-plane depth-fused display",2017,"ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028598128&doi=10.1145%2f3102163.3102221&partnerID=40&md5=af42d0e94b00e106e01ab3a1357496db","A four-plane depth-fused display (DFD) is an autostereoscopic system that can display four images at different depth positions using a single liquid crystal display and mirrors or half mirrors. This system increases the number of images in the depth direction, thereby enhancing stereoscopic effect. To date, however, the contents of proposed DFD remain limited to still images. Therefore, we introduced an animation that included object motion in the XYZ space in four planes into DFD. This approach considerably increased the sense of depth. © 2017 Copyright held by the owner/author(s).","3D display; Depth-fused display","Animation; Computer graphics; Display devices; Liquid crystal displays; Mirrors; Stereo image processing; 3-D displays; Autostereoscopic systems; Depth-fused displays; Half mirror; Object motion; Still images; Interactive computer graphics",2-s2.0-85028598128
"Ren M., Xie N., Yang Y., Shen H.T.","Cosmetic-Vis: Sample-based 3D facial editor for cosmetic medical visualization",2017,"ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028622097&doi=10.1145%2f3102163.3102177&partnerID=40&md5=fcaa4bcf31b3953d187bf9c5b6bd4049","Cosmetic medical visualization has become an important application in computer graphics, especially for facial appearance visualization[Chandawarkar et al. 2013]. Recent approaches have reached very realistic results by blend shape[Ma et al. 2012], which is the most practical tool to make the facial appearance and expression animation in application domains on the entertainment industry (VFXs and games). In many role-playing games (RPGs), players enable to edit the character's facial appearance. However, it is unrealistic since arbitrary discontinuities and position relationship violations (a selected nose might be at a higher position that the bottom of the eyes selected from a different character) caused by players' manual operation. Moreover, the validity on changing facial organs has not be considered well yet. © 2017 Copyright held by the owner/author(s).","Blendshapes; Cosmetic medical visualization; Facial organ partition; Laplacian matrix","Animation; Computer graphics; Cosmetics; Interactive computer graphics; Matrix algebra; Visualization; Arbitrary discontinuities; Blendshapes; Entertainment industry; Expression animation; Laplacian matrices; Manual operations; Medical visualization; Role-playing game; Three dimensional computer graphics",2-s2.0-85028622097
"Goodhue D.","Velocity-based compression of 3D animated rotations",2017,"ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028624189&doi=10.1145%2f3102163.3102236&partnerID=40&md5=5e1d3b51e9ecd127838dfcf5a1d32260","Modern video game engines feature animation compression built using algorithms which offer fast runtime decompression. In comparison to other state-of-the-art industry techniques, we present new methods by which better compression ratios can be realized without significantly impacting performance. We first present a technique for reconstructing a stream of sparsely-keyed rotations from a sequence of angular velocities. Next, we encode those velocities as consecutive deltas, making it possible to use much smaller key sizes. As a final enhancement, we allow the speed component of our angular velocity to in some cases receive influence from velocity keys which do not specify an axis of rotation. Instead, the axis remains unchanged from the previous frame's velocity, yielding smaller data on those frames. © 2017 Copyright held by the owner/author(s).","Animation; Compression; Video games","Angular velocity; Animation; Compaction; Computer graphics; Interactive computer graphics; Velocity; Animation compression; Axis of rotation; Key sizes; Runtimes; State of the art; Velocity-based; Video game; Image compression",2-s2.0-85028624189
"Hu Y., Fang Y.","An asynchronous Material Point Method",2017,"ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028614306&doi=10.1145%2f3102163.3102170&partnerID=40&md5=174df25fa90fdd95f38a953db53dfc88","We propose a novel asynchronous time integration scheme for the Material Point Method (MPM), which offers temporal adaptivity when objects of different stiffness or velocity coexist. We show via multiple test scenes that our asynchronous MPM leads to 6x speed up over traditional synchronous MPM without sacrificing accuracy. © 2017 Copyright held by the owner/author(s).","Asynchronous time integration; Material point method; Physically based animation","Computer graphics; Adaptivity; Material point methods; Multiple test; Physically-based animation; Speed up; Time integration; Time-integration scheme; Interactive computer graphics",2-s2.0-85028614306
"Nozawa N., Fukusato T., Morishima S.","3D model partial-resizing via normal and texture map combination",2017,"ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028618082&doi=10.1145%2f3102163.3102203&partnerID=40&md5=fc4f4b55a1689a49860ad600f2e4bdb7","Resizing of 3D model is necessary for computer graphics animation and application such as games and movies. In general, when users deform a target model, they built on a bounding box or a closed polygon mesh (cage) to enclose a target model. Then, the resizing is done by deforming the cage with target model. However, these approaches are not good for detailed adjustment of 3D shape because they do not preserve local information. In contrast, based on a local information (e.g., edge set and weight map), Sorkine et al. [Sorkine and Alexa 2007; Sorkine et al. 2004] can generate smooth and conformal deformation results with only a few control points. While these approaches are useful for some situations, the results depend on resolution and topology of the target model. In addition, these approaches do not consider texture (UV) information. © 2017 Copyright held by the owner/author(s).","Geometry image; Seam carving","Animation; Computer games; Computer graphics; Deformation; Interactive computer graphics; Topology; 3-d modeling; Control point; Deformation result; Geometry images; Local information; Polygon meshes; Seam carving; Texture maps; Three dimensional computer graphics",2-s2.0-85028618082
"Han P.-H., Chen Y.-S., Wang H.-L., Huang Y.-J., Hsiao J.-C., Chen K.-W., Hung Y.-P.","The design of video see-through window for manipulating physical object with head-mounted display",2017,"ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028614646&doi=10.1145%2f3102163.3102176&partnerID=40&md5=436133f9a23cccd35460579154211072","In general, highly-skilled manipulation without instruction is difficult. Recently there are some works which apply the manipulating guidance by a Virtual Reality (VR) or Augmented Reality (AR) head-mounted display (HMD) to keep the user hands-free. Henderson et al. [Henderson and Feiner 2009] applied AR to armored vehicle turret maintenance. With a head-worn display, the mechanic could acquire steps in the form of texts, images and animations. Our previous work (My Tai-Chi Coaches) [Han et al. 2017] used optical see-through HMD for Tai-Chi Chuan (TCC) augmented learning tool. Although it can provide the user visual hints such as virtual coaches, the visual hints which the user can see are constrained to the small augmented FOV of the HMD. © 2017 Copyright held by the owner/author(s).","HCI; User study; VR/AR","Armored vehicles; Augmented reality; Computer graphics; Human computer interaction; Interactive computer graphics; Military vehicles; Virtual reality; Hands-free; Head mounted displays; Head-worn displays; Learning tool; Optical see-through; Physical objects; User study; VR/AR; Helmet mounted displays",2-s2.0-85028614646
"Golembeski D., Forziati R., George B., Sherman D.","PipelineX: A feature animation pipeline on microservices",2017,"Proceedings - DigiPro 2017: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028623133&doi=10.1145%2f3105692.3105702&partnerID=40&md5=4b172440c445caf593b0ae1bb2030ccb","Here we present a unique approach to building a highly-scalable, multi-functional, and production-friendly feature animation pipeline on a core infrastructure comprised of microservices. We discuss basic service layer design as well as the benefits and challenges of moving decades-old production processes for an entire animation studio to a new, transactional pipeline operating against a compartmentalized technology stack. The goal is to clean up the clutter of a legacy pipeline and enable a more flexible production environment using modern, web-based technology. © 2017 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","Feature animation; Microservices; Pipeline","Animation; Interactive computer graphics; Animation pipeline; Animation studios; Core infrastructure; Flexible production; Microservices; Multi-functional; Production process; Web-based technologies; Pipelines",2-s2.0-85028623133
"Pohl B.J., Harris A., Balog M., Clausen M., Moran G., Brucks R.","Fortnite: Supercharging CG animation pipelines with game engine technology",2017,"Proceedings - DigiPro 2017: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028612157&doi=10.1145%2f3105692.3114816&partnerID=40&md5=3afa6fefdea79273fac743e323f213db","Game engine technology, when applied to traditional linear animation production pipelines, can positively alter the dynamics of animated content creation. With realtime interactivity, the iterative revision process improves, fexibility during scene assembly increases, and rendering overhead is potentially eliminated. © 2017 Copyright held by the owner/author(s).","Alembic; Animation; Pipeline; Realtime; Rendering; Unreal engine; Workflow","Interactive computer graphics; Pipelines; Rendering (computer graphics); Alembic; Animation pipeline; Content creation; Production pipelines; Real time; Real-time interactivity; Rendering; Workflow; Animation",2-s2.0-85028612157
"Castaneda S., Akleman E.","Shading with painterly filtered layers: A technique to obtain painterly portrait animations",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028510676&doi=10.1145%2f3092912.3122800&partnerID=40&md5=74d7bb118b65162ea246f312ebb9ea54","In this manuscript, we describe a process that can be used to create still and/or animated portrait paintings to be shown in Expressive Art Exhibit. Our process consists of two stages: (1) Creation of control textures for a Barycentric shader by using color information gathered from photographs to provide realistic looking skin rendering; (2) Filtering and compositing the layers of images that are obtained by control textures, which correspond to effects such as diffuse, specular and ambient. To demonstrate proof-of-concept, we have created a few rigid body animations of painterly portraits under different lighting conditions. © 2017 Copyright held by the owner/author(s).","Expressive depiction; Painterly portraits; Painterly rendering","Animation; Rendering (computer graphics); Color information; Compositing; Expressive depiction; Lighting conditions; Painterly portraits; Painterly Rendering; Proof of concept; Skin rendering; Information filtering",2-s2.0-85028510676
"Smith A., Pohle S., Ma W.-C., Ma C., Wu X.-C., Chen Y., Danvoye E., Jimenez J., Patel S., Sanders M., Wilson C.A.","Emotion challenge: Building a new photoreal facial performance pipeline for games",2017,"Proceedings - DigiPro 2017: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028621606&doi=10.1145%2f3105692.3105695&partnerID=40&md5=9fab6b3cbbe2da4471472c1bd3ab9416","In recent years the expected standard for facial animation and character performance in AAA video games has dramatically increased. The use of photogrammetric capture techniques for actor-likeness acquisition, coupled with video-based facial capture and solving methods, has improved quality across the industry. However, due to variability across project pipelines, increased per-project scope for performance capture, and a reliance on external vendors, it is often challenging to maintain visual consistency from project to project, and even from character to character within a single project. Given these factors, we identified the need for a unified, robust and scalable pipeline for actor likeness acquisition, character art, performance capture, and character animation. © 2017 Copyright held by the owner/author(s).",,"Interactive computer graphics; Pipelines; Character animation; Facial animation; Performance capture; Project scope; Solving method; Video game; Visual consistency; Animation",2-s2.0-85028621606
"Castaneda S., Akleman E.","Shading with painterly filtered layers: A technique to obtain painterly portrait animations",2017,"Proceedings - Sketch-Based Interfaces and Modeling, SBIM 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028501228&doi=10.1145%2f3092912.3122800&partnerID=40&md5=930a53fc526003b97fc9960fc38ced7b","In this manuscript, we describe a process that can be used to create still and/or animated portrait paintings to be shown in Expressive Art Exhibit. Our process consists of two stages: (1) Creation of control textures for a Barycentric shader by using color information gathered from photographs to provide realistic looking skin rendering; (2) Filtering and compositing the layers of images that are obtained by control textures, which correspond to effects such as diffuse, specular and ambient. To demonstrate proof-of-concept, we have created a few rigid body animations of painterly portraits under different lighting conditions. © 2017 Copyright held by the owner/author(s).","Expressive depiction; Painterly portraits; Painterly rendering","Rendering (computer graphics); Color information; Compositing; Expressive depiction; Lighting conditions; Painterly portraits; Painterly Rendering; Proof of concept; Skin rendering; Information filtering",2-s2.0-85028501228
"Castaneda S., Akleman E.","Shading with painterly filtered layers: A technique to obtain painterly portrait animations",2017,"Proceedings - Computational Aesthetics, CAe 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028577888&doi=10.1145%2f3092912.3122800&partnerID=40&md5=7ad96d79d5523e70f2fafda31de84834","In this manuscript, we describe a process that can be used to create still and/or animated portrait paintings to be shown in Expressive Art Exhibit. Our process consists of two stages: (1) Creation of control textures for a Barycentric shader by using color information gathered from photographs to provide realistic looking skin rendering; (2) Filtering and compositing the layers of images that are obtained by control textures, which correspond to effects such as diffuse, specular and ambient. To demonstrate proof-of-concept, we have created a few rigid body animations of painterly portraits under different lighting conditions. © 2017 Copyright held by the owner/author(s).","Expressive depiction; Painterly portraits; Painterly rendering","Rendering (computer graphics); Color information; Compositing; Expressive depiction; Lighting conditions; Painterly portraits; Painterly Rendering; Proof of concept; Skin rendering; Information filtering",2-s2.0-85028577888
"Lan L., Cong M., Fedkiw R.","Lessons from the evolution of an anatomical facial muscle model",2017,"Proceedings - DigiPro 2017: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028621324&doi=10.1145%2f3105692.3105693&partnerID=40&md5=6c87c8094ae091de6c08c0f6514b8e20","Recently, Industrial Light & Magic has begun exploring facial muscle simulation as a means of augmenting our blendshape-based facial animation workflow in order to attain higher quality results. During this process, we discovered that a precise and accurate model of the underlying facial anatomy is key to obtaining high-quality facial simulation results that can be used for photorealistic hero characters. We present an overview of our workflow for developing such a model along with some of the key anatomical lessons that were essential to the process. © 2017 Copyright held by the owner/author(s).","Blendshapes; Facial animation; Muscles","Animation; Interactive computer graphics; Accurate modeling; Blendshape; Blendshapes; Facial animation; Facial muscles; High quality; Photo-realistic; Muscle",2-s2.0-85028621324
"Zheng M., Milliez A., Gross M., Sumner R.W.","Example-based brushes for coherent stylized renderings",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028515618&doi=10.1145%2f3092919.3092929&partnerID=40&md5=8efe41ec066328caf2dd9a83e5052dc4","Painterly stylization is the cornerstone of non-photorealistic rendering. Inspired by the versatility of paint as a physical medium, existing methods target intuitive interfaces that mimic physical brushes, providing artists the ability to intuitively place paint strokes in a digital scene. Other work focuses on physical simulation of the interaction between paint and paper or realistic rendering of wet and dry paint. In our work, we leverage the versatility of example-based methods that can generate paint strokes of arbitrary shape and style based on a collection of images acquired from physical media. Such ideas have gained popularity since they do not require cumbersome physical simulation and achieve high fidelity without the need of a specific model or rule set. However, existing methods are limited to the generation of static 2D paintings and cannot be applied in the context of 3D painting and animation where paint strokes change shape and length as the camera viewport moves. Our method targets this shortcoming by generating temporally-coherent example-based paint strokes that accommodate to such length and shape changes. We demonstrate the robustness of our method with a 2D painting application that provides immediate feedback to the user and show how our brush model can be applied to the screen-space rendering of 3D paintings on a variety of examples. © 2017 Copyright held by the owner/author(s).","Painterly rendering; Stylization; Temporal coherence","Animation; Computer graphics; Paint; Three dimensional computer graphics; Example-based methods; Immediate feedbacks; Intuitive interfaces; Non-Photorealistic Rendering; Painterly Rendering; Realistic rendering; Stylization; Temporal coherence; Rendering (computer graphics)",2-s2.0-85028515618
"Liu X.-C., Cheng M.-M., Lai Y.-K., Rosin P.L.","Depth-aware neural style transfer",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028507068&doi=10.1145%2f3092919.3092924&partnerID=40&md5=b276d7589bbf9a99d050a088e35fb72f","Neural style transfer has recently received significant attention and demonstrated amazing results. An efficient solution proposed by Johnson et al. trains feed-forward convolutional neural networks by defining and optimizing perceptual loss functions. Such methods are typically based on high-level features extracted from pre-trained neural networks, where the loss functions contain two components: style loss and content loss. However, such pre-trained networks are originally designed for object recognition, and hence the high-level features often focus on the primary target and neglect other details. As a result, when input images contain multiple objects potentially at different depths, the resulting images are often unsatisfactory because image layout is destroyed and the boundary between the foreground and background as well as different objects becomes obscured. We observe that the depth map effectively reflects the spatial distribution in an image and preserving the depth map of the content image after stylization helps produce an image that preserves its semantic content. In this paper, we introduce a novel approach for neural style transfer that integrates depth preservation as additional loss, preserving overall image layout while performing style transfer. © 2017 Copyright held by the owner/author(s).","Deep learning; Depth; Non-photorealistic rendering","Animation; Computer graphics; Deep learning; Neural networks; Object recognition; Semantics; Convolutional neural network; Depth; High-level features; Loss functions; Multiple objects; Non-Photorealistic Rendering; Semantic content; Trained neural networks; Rendering (computer graphics)",2-s2.0-85028507068
"Spicker M., Hahn F., Lindemeier T., Saupe D., Deussen O.","Quantifying visual abstraction quality for stipple drawings",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028514527&doi=10.1145%2f3092919.3092923&partnerID=40&md5=3a6d5d408da0e210b2ceb160acf5bb56","We investigate how the perceived abstraction quality of stipple illustrations is related to the number of points used to create them. Since it is difficult to find objective functions that quantify the visual quality of such illustrations, we gather comparative data by a crowdsourcing user study and employ a paired comparison model to deduce absolute quality values. Based on this study we show that it is possible to predict the perceived quality of stippled representations based on the properties of an input image. Our results are related to Weber-Fechner's law from psychophysics and indicate a logarithmic relation between numbers of points and perceived abstraction quality. We give guidance for the number of stipple points that is typically enough to represent an input image well. © 2017 Copyright held by the owner/author(s).","Non-photorealistic rendering; Perception; Quantitative evaluation; Stippling; User study; Visual abstraction","Animation; Computer graphics; Rendering (computer graphics); Sensory perception; Non-Photorealistic Rendering; Quantitative evaluation; Stippling; User study; Visual abstraction; Abstracting",2-s2.0-85028514527
"Rosin P.L., Mould D., Berger I., Collomosse J., Lai Y.-K., Li C., Li H., Shamir A., Wand M., Wang T., Winnemöller H.","Benchmarking non-photorealistic rendering of portraits",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028515099&doi=10.1145%2f3092919.3092921&partnerID=40&md5=e9fce663c1f20c433573e2ab4acc8e5a","We present a set of images for helping NPR practitioners evaluate their image-based portrait stylisation algorithms. Using a standard set both facilitates comparisons with other methods and helps ensure that presented results are representative. We give two levels of difficulty, each consisting of 20 images selected systematically so as to provide good coverage of several possible portrait characteristics. We applied three existing portrait-specific stylisation algorithms, two general-purpose stylisation algorithms, and one general learning based stylisation algorithm to the first level of the benchmark, corresponding to the type of constrained images that have often been used in portrait-specific work. We found that the existing methods are generally effective on this new image set, demonstrating that level one of the benchmark is tractable; challenges remain at level two. Results revealed several advantages conferred by portrait-specific algorithms over general-purpose algorithms: portrait-specific algorithms can use domain-specific information to preserve key details such as eyes and to eliminate extraneous details, and they have more scope for semantically meaningful abstraction due to the underlying face model. Finally, we provide some thoughts on systematically extending the benchmark to higher levels of difficulty. © 2017 ACM.","Evaluation; Image stylisation; Non-photorealistic rendering; Portraits","Animation; Computer graphics; Domain-specific information; Evaluation; Face modeling; General learning; Non-Photorealistic Rendering; Portraits; Specific works; Stylisation; Rendering (computer graphics)",2-s2.0-85028515099
"De La Torre-Arenas I., Cruz P.","A taxonomy of motion applications in data visualization",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028501970&doi=10.1145%2f3092912.3122798&partnerID=40&md5=1b128625de869f83b040577c8181fc3f","We propose a new taxonomy that explains the roles of motion in data visualization, focusing especially on their communicative aspects. Our taxonomy clarifies the main axis in how visualization designers can employ motion in data portrayal. © 2017 Copyright held by the owner/author(s).","Information visualization; Visualization; Visualization theory","Animation; Flow visualization; Information systems; Rendering (computer graphics); Taxonomies; Visualization; Information visualization; Visualization theory; Data visualization",2-s2.0-85028501970
"Parakkat A.D., Joshi S.A., Pundarikaksha U.B., Muthuganapathy R.","Sketch and shade: An interactive assistant for sketching and shading",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028513540&doi=10.1145%2f3092912.3122799&partnerID=40&md5=d39cc23d426f39c31691647dac9642ca","We present a drawing assistant for sketching and for assisting users in shading a hand drawn sketch. The augmented reality based system uses a sketch made by a professional and uses it to help inexperienced users to do sketching and shading. The input image is converted to a set of points based on simple heuristics for providing a ""connect the dots"" interface for a user to aid sketching. With the help of a 2.5D mesh generated by our algorithm, the system assists the user by providing information about the colors that can be given in different parts of the sketch. The system was tested with users of different age groups and skill levels, indicating its usefulness. © 2017 Copyright held by the owner/author(s).","Delaunay triangulation; Inflation; Paper sketch; Shading","Animation; Augmented reality; Rendering (computer graphics); Age groups; Delau-nay triangulations; Hand-drawn sketches; Inflation; Input image; Shading; Simple heuristics; Skill levels; Drawing (graphics)",2-s2.0-85028513540
"Aharoni-Mack E., Shambik Y., Lischinski D.","Pigment-based recoloring of watercolor paintings",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028503765&doi=10.1145%2f3092919.3092926&partnerID=40&md5=0a610472672960e0befdc4368b84b2ea","The color palette used by an artist when creating a painting is an important tool for expressing emotion, directing attention, and more. However, choosing a palette is an intricate task that requires considerable skill and experience. In this work, we introduce a new tool designed to allow artists to experiment with alternative color palettes for existing watercolor paintings. This could be useful for generating alternative renditions for an existing painting, or for aiding in the selection of a palette for a new painting, related to an existing one. Our tool first estimates the original pigment-based color palette used to create the painting, and then decomposes the painting into a collection of pigment channels, each corresponding to a single palette color. In both of these tasks, we employ a version of the Kubelka-Munk model, which predicts the reflectance of a given mixture of pigments. Each channel in the decomposition is a piecewise-smooth map that specifies the concentration of one of the colors in the palette across the image. Another estimated map specifies the total thickness of the pigments across the image. The mixture of these pigment channels, also according to the Kubelka-Munk model, reconstructs the original painting. The artist is then able to manipulate the individual palette colors, obtaining results by remixing the pigment channels at interactive rates. © 2017 Association for Computing Machinery.","Color-transfer; Decomposition; Kubelka-Munk; Pigments; Recoloring; Watercolor","Animation; Color; Decomposition; Mixtures; Pigments; Rendering (computer graphics); Color transfers; Interactive rates; Kubelka-Munk; Kubelka-Munk Model; Piecewise-smooth map; Recoloring; Watercolor; Watercolor paintings; Painting",2-s2.0-85028503765
"Missey B., Davalath M., Somasundaram A.","The Fashionista Twins: Conjoined hair in Trolls",2017,"Proceedings - DigiPro 2017: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028593492&doi=10.1145%2f3105692.3105694&partnerID=40&md5=39adc596f2ceb49db15b980b16464de6","This talk presents the techniques used to create the hair for 'The Fashionista Twins', Satin and Chenille, from the film Trolls. The conjoined twins are uniquely connected in a loop by their brightly colored hair. The seamless connection of their hair posed unique technical challenges in grooming, rigging, and the shot pipeline and it required a collaborative efort to bring their hair to life. © 2017 Copyright held by the owner/author(s).","Animation; Conjoined; Constraints; Grooming; Hair; Rigging; Seamless","Animation; Conjoined; Constraints; Grooming; Hair; Rigging; Seamless; Interactive computer graphics",2-s2.0-85028593492
"Duchêne S., Aliaga C., Pouli T., Pérez P.","Mixed illumination analysis in single image for interactive color grading",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028503231&doi=10.1145%2f3092919.3092927&partnerID=40&md5=fea8785add8bd50836e4407d2966cb99","Colorists often use keying or rotoscoping tools to access and edit particular colors or parts of the scene. Although necessary, this is a time-consuming and potentially imprecise process, as it is not possible to fully separate the influence of light sources in the scene from the colors of objects and actors within it. To simplify this process, we present a new solution for automatically estimating the color and influence of multiple illuminants, based on image variation analysis. Using this information, we present a new color grading tool for simply and interactively editing the colors of detected illuminants, which fits naturally in color grading workflows. We demonstrate the use of our solution in several scenes, evaluating the quality of our results by means of a psychophysical study. © 2017 Association for Computing Machinery.","Color grading; Illuminant detection; Mixed illumination","Animation; Color; Image analysis; Light sources; Rendering (computer graphics); Color grading; Illuminant detection; Illumination analysis; Image variations; Psychophysical studies; Rotoscoping; Single images; Work-flows; Grading",2-s2.0-85028503231
"Montesdeoca S.E., Seah H.S., Bénard P., Vergne R., Thollot J., Rall H.-M., Benvenuti D.","Edge- and substrate-based effects for watercolor stylization",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028513054&doi=10.1145%2f3092919.3092928&partnerID=40&md5=8ab529c16b14026a52494afda0d60950","We investigate characteristic edge- and substrate-based effects for watercolor stylization. These two fundamental elements of painted art play a significant role in traditional watercolors and highly influence the pigment's behavior and application. Yet a detailed consideration of these specific elements for the stylization of 3D scenes has not been attempted before. Through this investigation, we contribute to the field by presenting ways to emulate two novel effects: dry-brush and gaps & overlaps. By doing so, we also found ways to improve upon well-studied watercolor effects such as edge-darkening and substrate granulation. Finally, we integrated controllable external lighting influences over the watercolorized result, together with other previously researched watercolor effects. These effects are combined through a direct stylization pipeline to produce sophisticated watercolor imagery, which retains spatial coherence in object-space and is locally controllable in real-time. © 2017 Copyright held by the owner/author(s).","Direct stylization; Dry-brush; Gaps & overlaps; Watercolor","Animation; 3D scenes; Direct stylization; Dry brushes; Object space; Real time; Spatial coherence; Watercolor; Rendering (computer graphics)",2-s2.0-85028513054
"Faraj N., Xia G.-S., Delon J., Gousseau Y.","A generic framework for the structured abstraction of images",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028515964&doi=10.1145%2f3092919.3092930&partnerID=40&md5=52bfb68ff9799568cf521d50dc8c8869","Structural properties are important clues for non-photorealistic representations of digital images. Therefore, image analysis tools have been intensively used either to produce stroke-based renderings or to yield abstractions of images. In this work, we propose to use a hierarchical and geometrical image representation, called a topographic map, made of shapes organized in a tree structure. There are two main advantages of this analysis tool. Firstly, it is able to deal with all scales, so that every shape of the input image is represented. Secondly, it accounts for the inclusion properties within the image. By iteratively performing simple local operations on the shapes (removal, rotation, scaling, replacement⋯), we are able to generate abstract renderings of digital photographs ranging from geometrical abstraction and painting-like effects to style transfer, using the same framework. In particular, results show that it is possible to create abstract images evoking Malevitchs Suprematist school, while remaining grounded in the structure of digital images, by replacing all the shapes in the tree by simple geometric shapes. © 2017 Copyright held by the owner/author(s).","Hierarchical; Image abstraction; Image processing; Image representation; Morphological; Picture/image generation","Abstracting; Animation; Forestry; Geometry; Image processing; Maps; Trees (mathematics); Hierarchical; Image abstraction; Image representations; Morphological; Picture/image generation; Rendering (computer graphics)",2-s2.0-85028515964
"Semmo A., Isenberg T., Döllner J.","Neural style transfer: A paradigm shift for image-based artistic rendering?",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028511836&doi=10.1145%2f3092919.3092920&partnerID=40&md5=57ef23b5d70f8a0bc565af1d1a327a31","In this meta paper we discuss image-based artistic rendering (IB-AR) based on neural style transfer (NST) and argue, while NST may represent a paradigm shift for IB-AR, that it also has to evolve as an interactive tool that considers the design aspects and mechanisms of artwork production. IB-AR received significant attention in the past decades for visual communication, covering a plethora of techniques to mimic the appeal of artistic media. Example-based rendering represents one the most promising paradigms in IB-AR to (semi-)automatically simulate artistic media with high fidelity, but so far has been limited because it relies on pre-defined image pairs for training or informs only low-level image features for texture transfers. Advancements in deep learning showed to alleviate these limitations by matching content and style statistics via activations of neural network layers, thus making a generalized style transfer practicable. We categorize style transfers within the taxonomy of IB-AR, then propose a semiotic structure to derive a technical research agenda for NSTs with respect to the grand challenges of NPAR. We finally discuss the potentials of NSTs, thereby identifying applications such as casual creativity and art production. © 2017 Copyright held by the owner/author(s).","Convolutional neural networks; Image processing; Image-based artistic rendering; Semiotics; Style transfer; Stylization","Animation; Content based retrieval; Image processing; Nanostructured materials; Network layers; Neural networks; Semiotics; Visual communication; Convolutional neural network; Example-based rendering; Image-based; Interactive tool; Low-level image features; Style transfer; Stylization; Technical research; Rendering (computer graphics)",2-s2.0-85028511836
"Liu C., Hodgins J., McCann J.","Whole-cloth qilting paterns from photographs",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028512270&doi=10.1145%2f3092919.3092925&partnerID=40&md5=34114c3098213512b9cc20f775748c0f","Whole-cloth quilts are decorative and functional artifacts made of plain cloth embellished with complicated stitching patterns. We describe a method that can automatically create a sewing pattern for a whole-cloth quilt from a photograph. Our technique begins with a segmented image, extracts desired and optional edges, and creates a continuous sewing path by approximately solving the Rural Postman Problem (RPP). In addition to many example quilts, we provide visual and numerical comparisons to previous singleline illustration approaches. © 2017 Copyright held by the owner/author(s).","Line drawing; Quilting; Rural postman problem; Whole-cloth quilt","Animation; Rendering (computer graphics); Line drawings; Numerical comparison; Quilting; Rural postman problem; Segmented images; Whole-cloth quilt; Photography",2-s2.0-85028512270
"Altiok O.C., Sezgin T.M.","Characterizing user behavior for speech and sketch-based video retrieval interfaces",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028510192&doi=10.1145%2f3092912.3122801&partnerID=40&md5=df8b0c13eb8a4abf774642802318cf99","From a user interaction perspective, speech and sketching make a good couple for describing motion. Speech allows easy specification of content, events and relationships, while sketching brings in spatial expressiveness. Yet, we have insufficient knowledge of how sketching and speech can be used for motion-based video retrieval, because there are no existing retrieval systems that support such interaction. In this paper, we describe a Wizard-of-Oz protocol and a set of tools that we have developed to engage users in a sketch-and speech-based video retrieval task. We report how the tools and the protocol fit together using ""retrieval of soccer videos"" as a use case scenario. Our software is highly customizable, and our protocol is easy to follow. We believe that together they will serve as a convenient and powerful duo for studying a wide range of multi-modal use cases. © 2017 Copyright held by the owner/author(s).","Human-centered design; Motion; Multimedia retrieval; Sketch-based interfaces","Animation; Behavioral research; Speech; Human-centered designs; Motion; Multimedia Retrieval; Retrieval systems; Sketch based Interface; Use case scenario; User interaction; Video retrieval; Rendering (computer graphics)",2-s2.0-85028510192
"Alex Brown S., Samavati F.","Real-time panorama maps",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028517527&doi=10.1145%2f3092919.3092922&partnerID=40&md5=6a7bedfe168007178f9194daa5bd8036","Panorama maps are stylized paintings of terrain often seen at tourist destinations. They are difficult to create since they are both artistic and grounded in real geographic data. In this paper we present techniques for rendering real-world data in the style of Heinrich Berann's panorama maps in a real-time application. We analyse several of Berann's paintings to identify the artistic elements used. We use this analysis to form algorithms that mimic the panorama map style, focusing on replicating the terrain deformation, distorted projection, terrain colouring, tree brush strokes, water rendering, and atmospheric scattering. In our approach we use freely available digital earth data to render interactive panorama maps without needing further design work. © 2017 Copyright held by the owner/author(s).","Digital earth; Non-photorealistic rendering; Panorama map; Realtime rendering","Animation; Computer graphics; Atmospheric scattering; Digital Earth; Non-Photorealistic Rendering; Real-time application; Real-time panorama; Real-time rendering; Terrain deformation; Tourist destinations; Landforms",2-s2.0-85028517527
"Dunn O., Renton J., Sarsfield A.","LEGO Batman: Graphical breakdown editing - Optimising assembly workflow",2017,"Proceedings - DigiPro 2017: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028622953&doi=10.1145%2f3105692.3105696&partnerID=40&md5=8f7b46a119ff8e9a0f1f0b296360b873","The ever increasing complexity of the LEGO movies demanded a new way of managing project breakdowns. Animal Logic's finegrained, modular representation for assets[Sarsfied and Murphy 2011] meant that hundreds and thousands of shots, and shot objects, needed to be managed. It was clear from our experience on the The LEGO Movie that our existing text-based spreadsheet approach would not scale to demands of The LEGO Batman Movie. © 2017 Copyright held by the owner/author(s).","Animation; Assembly; Breakdown","Animation; Assembly; Interactive computer graphics; Breakdown; Managing projects; Modular representations; Motion pictures",2-s2.0-85028622953
"Lai C.-A., Chiang P.-Y.","Modeling Go: A mobile sketch-based modeling system for extracting objects",2017,"Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028500149&doi=10.1145%2f3092912.3122797&partnerID=40&md5=eca6f1d09085b6911d8df8a044eca7f6","This article presents an easy to use mobile application which allows users to create 3D digital copies of their interested objects anywhere and anytime. An advanced 3-sweep modeling technique is developed to construct 3D primitives not only from generalized cylinder and cuboid, but also objects with symmetrical or non-uniformly scaled profiles. In addition, our system supports the texture and structure refinement which combine results created from multiple source images. The constructed 3D model will be the combination of our 3D primitives. The combined result can preserve more features which may not be seen from a single photo. © 2017 Copyright held by the owner/author(s).","Interactive techniques; Mobile application; Sketch-based modeling","Animation; Mobile computing; Mobile telecommunication systems; Generalized cylinders; Interactive techniques; Mobile applications; Modeling technique; Multiple source; Sketch-based modeling; Sketch-based modeling system; Structure refinements; Rendering (computer graphics)",2-s2.0-85028500149
"Vitali A., Rizzi C.","A virtual environment to emulate tailor’s work",2017,"Computer-Aided Design and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009260427&doi=10.1080%2f16864360.2016.1273584&partnerID=40&md5=6f98a86d23983a9e39612257e59763bc","In fashion industry, 2D and 3D CAD systems to design garments already exist; however, some tasks of the process are neglected. We refer to made-to-measure garments and focus the attention on the first step of garment design, i.e. acquisition of customer’s measurement. In this paper we present an application based on mixed reality, named Tailor LABoratory (TLAB), which permits to take measures for clothing design as traditionally done by the tailor. TLAB has been developed using open source libraries (e.g., VTK and Blender) and low cost devices, such as Microsoft Kinect v2 to scan the human body, Oculus Rift v2 to create the 3D virtual reality and Leap Motion device to track hands motion. In particular, a virtual tape measure is made available to take measures interacting with the human avatar. To replicate the customer’s posture with her/his digital model, Blender has been adopted. It permits to manage body animations and automatic association of an animation to the 3D human avatar. Finally, preliminary tests are illustrated as well as results reached so far and future development. © 2017 CAD Solutions, LLC.","Leap Motion; mixed reality; Oculus Rift; tailor’s work; virtual garments design","Blending; Computer aided design; Digital libraries; Garment manufacture; Hosiery manufacture; Interactive computer graphics; Three dimensional computer graphics; 3D virtual reality; Fashion industry; Leap Motion; Low-cost devices; Mixed reality; Oculus Rift; Open-source libraries; Virtual garments; Virtual reality",2-s2.0-85009260427
[No author name available],"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031690439&partnerID=40&md5=bb90d3cc81d2537ae68cabea31ccc341","The proceedings contain 32 papers. The topics discussed include: fully asynchronous SPH simulation; a micropolar material model for turbulent SPH fluids; physically-based droplet interaction; a positive-definite cut-cell method for strong two-way coupling between fluids and deformable bodies; emotion control of unstructured dance movements; production-level facial performance capture using deep convolutional neural networks; augmenting sampling based controllers with machine learning; learning locomotion skills using DeepRL: does the choice of action space matter?; tunable robustness: an artificial contact strategy with virtual actuator control for balance; long range constraints for rigid body simulations; designing cable-driven actuation networks for kinematic chains and trees; real-time interactive tree animation; modeling and data-driven parameter estimation for woven fabrics; automated regression tests for character animation systems; comparing traditional key frame and hybrid animation; human grasping interaction capture and analysis; online compression of rigid body simulations using physics-inspired interpolation; and position-based multi-agent dynamics for real-time crowd simulation.",,,2-s2.0-85031690439
"AhlstrÃ¶m E., Holmqvist L., Goswami P.","Comparing traditional key frame and hybrid animation",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031681871&doi=10.1145%2f3099564.3106640&partnerID=40&md5=480b38d02bb71130d991a7a0de4521cd","In this research the authors explore a hybrid approach which uses the basic concept of key frame animation together with procedural animation to reduce the number of key frames needed for an animation clip. The two approaches are compared by conducting an experiment where the participating subjects were asked to rate them based on their visual appeal.","Hybrid animation; Key frame animation; Procedural animation","Interactive computer graphics; Basic concepts; Hybrid approach; Key frames; Procedural animation; Visual appeals; Animation",2-s2.0-85031681871
"Mohr-Daurat H.","Automated regression tests for character animation systems",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031676096&doi=10.1145%2f3099564.3106641&partnerID=40&md5=1d2fc05b1d73493934c4cf57f8ab7d35","We present a process to verify code changes in an animation system by using regression tests which guarantee to cover every combination of animation features used in production. For this, we need to identify the untested combinations of animation features, create an immutable set of animation data which is representative of it, and when performing the tests, automatically compare the difference in the generated poses at each revision of the code.","Automation; Character Animation; Regression Tests","Automatic test pattern generation; Automation; Interactive computer graphics; Regression analysis; Animation systems; Character animation; Code changes; Regression tests; Animation",2-s2.0-85031676096
"Corker-Marin Q., Adzhiev V., Pasko A.","Cubification and animation of artistic shapes",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031683181&doi=10.1145%2f3099564.3108162&partnerID=40&md5=3da261fa18ffd9fb24826ae6f034ee8e","This poster describes an original approach to creating static and dynamic sculptures in a cubist style. We propose a novel method for faceting and local distortion thus adding cubist features and generating time-variant sculptural shapes. We introduce the concept of a 4D cubist camera for blending multiple projections from 4D space-time to 3D space. We describe a practical pipeline embracing all the main phases of production of static and dynamic cubist shapes. The proposed techniques are implemented and experimental results are presented.","3D Printing; Cubism; Hybrid Representation; Space-Time Blending","3D printers; Blending; Interactive computer graphics; 3-D printing; 3-D space; Cubism; Hybrid representations; Local distortion; Multiple projections; Space-time blending; Time variant; Animation",2-s2.0-85031683181
"Ciccone L., Nitti M., Guay M., Sumner R.W.","Authoring motion cycles",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031707852&doi=10.1145%2f3099564.3099570&partnerID=40&md5=4c49f48d49dc5e72b2d3c975678093be","Motion cycles play an important role in animation production and game development. However, creating motion cycles relies on general-purpose animation packages with complex interfaces that require expert training. Our work explores the specific challenges of motion cycle authoring and provides a system simple enough for novice animators while maintaining the flexibility of control demanded by experts. Due to their cyclic nature, we show that performance animation provides a natural interface for motion cycle specification. Our system allows the user to act several loops of motion using a variety of capture devices and automatically extracts a looping cycle from this potentially noisy input. Motion cycles for different character components can be authored in a layered fashion, or our method supports cycle extraction from higher-dimensional data for capture devices that deliver many degrees of freedom. After capture, a custom curve representation and manipulation tool allows the user to coordinate and control spatial and temporal transformations from a single viewport. Ground and other planar contacts are specified with a single sketched line that adjusts a curveâ€™s position and timing to establish non-slipping","Animation interface; Motion curves; Motion cycles; Performance","Degrees of freedom (mechanics); Interactive computer graphics; Animation interfaces; Character components; Curve representations; Motion curve; Motion cycle; Performance; Performance animations; Temporal transformations; Animation",2-s2.0-85031707852
"Laine S., Herva A., Karras T., Saito S., Aila T., Yu R., Li H., Lehtinen J.","Production-level facial performance capture using deep convolutional neural networks",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031703382&doi=10.1145%2f3099564.3099581&partnerID=40&md5=dfacf17f17a6b89bcbee168c213f795a","We present a real-time deep learning framework for video-based facial performance captureâ€”the dense 3D tracking of an actorâ€™s face given a monocular video. Our pipeline begins with accurately capturing a subject using a high-end production facial capture pipeline based on multi-view stereo tracking and artist-enhanced animations. With 5â€“10 minutes of captured footage, we train a convolutional neural network to produce high-quality output, including self-occluded regions, from a monocular video sequence of that subject. Since this 3D facial performance capture is fully automated, our system can drastically reduce the amount of labor involved in the development of modern narrative-driven video games or films involving realistic digital doubles of actors and potentially hours of animated dialogue per character. We compare our results with several state-of-the-art monocular real-time facial capture techniques and demonstrate compelling animation inference in challenging areas such as eyes and lips.","Facial animation, deep learning","Convolution; Deep learning; Deep neural networks; Interactive computer graphics; Neural networks; Pipelines; Three dimensional computer graphics; Convolutional neural network; Facial animation; Learning frameworks; Monocular video sequences; Multi-view stereo; Performance capture; Production level; State of the art; Animation",2-s2.0-85031703382
"Peng X.B., van de Panne M.","Learning locomotion skills using deep RL: Does the choice of action space maer?",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031697014&doi=10.1145%2f3099564.3099567&partnerID=40&md5=eab065f414d7cd2d2e0392da627f637b","The use of deep reinforcement learning allows for high-dimensional state descriptors, but little is known about how the choice of action representation impacts learning and the resulting performance. We compare the impact of four different action parameterizations (torques, muscle-activations, target joint angles, and target joint-angle velocities) in terms of learning time, policy robustness, motion quality, and policy query rates. Our results are evaluated on a gait-cycle imitation task for multiple planar articulated figures and multiple gaits. We demonstrate that the local feedback provided by higher-level action parameterizations can significantly impact the learning, robustness, and motion quality of the resulting policies.","Locomotion skills; Motion control; Physics-based character animation","Interactive computer graphics; Motion control; Reinforcement learning; Action representations; Action spaces; Articulated figures; Character animation; Descriptors; High-dimensional; Learning time; Muscle activation; Animation",2-s2.0-85031697014
"Juarez-Perez A., Kallmann M.","Coordinating full-body interactions with the environment",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031700349&doi=10.1145%2f3099564.3106642&partnerID=40&md5=d9703da20fea594c73cfe49ff1df84f4","We present a methodology for synthesizing coordinated full-body motions in order to achieve autonomous virtual characters capable of interacting with the environment while walking. Starting with a parameterized walking controller and a set of mocap examples our method is then able to coordinate upper-body interactions with the walking controller in order to achieve full-body object interactions in generalized situations.","Full-Body Character Animation, Coordination Learning","Interactive computer graphics; Character animation; Full body; Full-body interaction; Full-body motions; Object interactions; Parameterized; Upper bodies; Virtual character; Animation",2-s2.0-85031700349
"Ibrahim Z.H.","The stretch-engine: A method for adjusting the exaggeration of bipedal characters through squash and stretch",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031662196&doi=10.1145%2f3099564.3106639&partnerID=40&md5=10ffd0594f60bb55d785f2d94d5ae40f","This paper describes a new method to control changes in a characterâ€™s form during exaggeration, through squash and stretch (SS). The Stretch-Engine is the result of this method, designed to be integrated into an existing animation system, Maya. The Stretch-Engine is a three-part system where the first is a bipedal-humanoid rig with controls necessary for animation and the ability to SS its limbs. The second is a set of rules determined from studying Looney Tunes animation to create a range of SS. The third is a user interface that allows users to control changes in SS using 3D curves created within the Maya interface.","Bipedal rig; Exaggeration; Motion path; Squash; Stretch","Engines; Interactive computer graphics; Stretching; User interfaces; Animation systems; Bipedal rig; Exaggeration; Motion path; Set of rules; Squash; Squash and stretches; Animation",2-s2.0-85031662196
"Aristidou A., Yin K., Zeng Q., Cohen-Or D., Chen B., Stavrakis E., Chrysanthou Y.","Emotion control of unstructured dance movements",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031703826&doi=10.1145%2f3099564.3099566&partnerID=40&md5=aa1be06c738879ca9a1295a343cac0d9","Motion capture technology has enabled the acquisition of high quality human motions for animating digital characters with extremely high fidelity. However, despite all the advances in motion editing and synthesis, it remains an open problem to modify pre-captured motions that are highly expressive, such as contemporary dances, for stylization and emotionalization. In this work, we present a novel approach for stylizing such motions by using emotion coordinates defined by the Russellâ€™s Circumplex Model (RCM). We extract and analyze a large set of body and motion features, based on the Laban Movement Analysis (LMA), and choose the effective and consistent features for characterizing emotions of motions. These features provide a mechanism not only for deriving the emotion coordinates of a newly input motion, but also for stylizing the motion to express a different emotion without having to reference the training data. Such decoupling of the training data and new input motions eliminates the necessity of manual processing and motion registration. We implement the two-way mapping between the motion features and emotion coordinates through Radial Basis Function (RBF) regression and interpolation, which can stylize freestyle highly dynamic dance movements at interactive rates. Our results and user studies demonstrate the effectiveness of the stylization framework with a variety of dance movements exhibiting a diverse set of emotions.","Character animation; Computer Graphics; Data-driven motion style transfer; Motion editing; Motion synthesis","Computer graphics; Interactive computer graphics; Motion picture editing machines; Radial basis function networks; Character animation; Circumplex models; Digital characters; Manual processing; Motion editing; Motion styles; Motion synthesis; Radial Basis Function(RBF); Animation",2-s2.0-85031703826
"Toothman N., Neff M.","Aachment-based character deformation",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031669963&doi=10.1145%2f3099564.3108161&partnerID=40&md5=411dc4034d49e9f33a53e32d99584d4e","While advancements have made it easier to work with digital characters, it remains difficult to author animations that display the free and highly expressive shape change that characterize hand-drawn animation. We present a deformation method that combines skeletal control and free shape change in a single framework, along with an intuitive, sketch-based interface. By ending attachment points between the mesh and skeleton, we enable configurable skeleton and surface-based deformations, and avoid common skinning artifacts. Use of sketch-based interfaces and graphics hardware make both skeletal and mesh deformation simple to control and fast enough for interactive use.","Animation; Deformation; Shape control; Skinning","Computer graphics; Deformation; Interactive computer graphics; Mesh generation; Musculoskeletal system; Attachment points; Digital characters; Graphics hardware; Mesh deformation; Shape control; Sketch based Interface; Skinning; Surface-based; Animation",2-s2.0-85031669963
"Bender J., Kugelstadt T., Koschier D., Weiler M.","A micropolar material model for turbulent SPH fluids",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031704977&doi=10.1145%2f3099564.3099578&partnerID=40&md5=042c2d67705d4121e56a9dca2d12e7e1","In this paper we introduce a novel micropolar material model for the simulation of turbulent inviscid fluids. The governing equations are solved by using the concept of Smoothed Particle Hydrodynamics (SPH). As already investigated in previous works, SPH fluid simulations suffer from numerical discusion which leads to a lower vorticity, a loss in turbulent details and finally in less realistic results. To solve this problem we propose a micropolar fluid model. The micropolar fluid model is a generalization of the classical Navier-Stokes equations, which are typically used in computer graphics to simulate fluids. In contrast to the classical Navier-Stokes model, micropolar fluids have a microstructure and therefore consider the rotational motion of fluid particles. In addition to the linear velocity field these fluids also have a field of microrotation which represents existing vortices and provides a source for new ones. However, classical micropolar materials are viscous and the translational and the rotational motion are coupled in a dissipative way. Since our goal is to simulate turbulent fluids, we introduce a novel modified micropolar material for inviscid fluids with a non-dissipative coupling. Our model can generate realistic turbulences, is linear and angular momentum conserving, can be easily integrated in existing SPH simulation methods and its computational overhead is negligible.","Incompressible fluids; Micropolar fluids; Smoothed Particle Hydrodynamics; Turbulence","Animation; Computer graphics; Fluid dynamics; Hydrodynamics; Interactive computer graphics; Rotation; Rotational flow; Turbulence; Velocity; Computational overheads; Dissipative coupling; Incompressible fluid; Linear and angular momentums; Micro-polar fluids; Micropolar material; Navier-Stokes model; Smoothed particle hydrodynamics; Navier Stokes equations",2-s2.0-85031704977
"Jin T., Kim M., Lee S.-H.","Motion retargeting to preserve spatial relationship between skinned characters",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031685033&doi=10.1145%2f3099564.3106647&partnerID=40&md5=7a5336b91719bd1a0cadb45f53ba0f44","Applying motion capture data for multi-person interaction to virtual characters is challenging because one needs to preserve interaction semantics in addition to satisfying the general requirements for motion retargeting, such as preventing penetration and preserving naturalness. An ecient method for representing the scene semantics of interaction motions is to dene the spatial relationships between body parts of characters. However, existing methods of this kind consider only character skeleton, and thus may require post-processing to rene the interaction motions and remove artifacts from the viewpoint of skin meshes. This paper proposes a novel method for retargeting interaction motions with respect to character skins. To this end, we introduce the aura mesh surrounding a characterâ€™s skin in order to represent skin-level spatial relationships between body parts. Using the aura mesh, we can retarget interaction motions while preserving skin-level spatial relationships and reducing skin inter-penetrations.","Close interaction; Motion retargeting; Spatial relationship","Animation; Interactive computer graphics; Mesh generation; Semantics; Body parts; Close interaction; Interaction semantics; Motion capture data; Motion retargeting; Post processing; Spatial relationships; Virtual character; Computer graphics",2-s2.0-85031685033
"Jin N., Geng Z., Lu W., Fedkiw R.P.","Inequality cloth",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031701344&doi=10.1145%2f3099564.3099568&partnerID=40&md5=a25a3b38aed3d0eee3311843dc205bf9","As has been noted and discussed by various authors, numerical simulations of deformable bodies often adversely suffer from so-called â€œlockingâ€ artifacts. We illustrate that the â€œlockingâ€ of out-of-plane bending motion that results from even an edge-spring-only cloth simulation can be quite severe, noting that the typical remedy of softening the elastic model leads to an unwanted rubbery look. We demonstrate that this â€œlockingâ€ is due to the well-accepted notion that edge springs in the cloth mesh should preserve their lengths, and instead propose an inequality constraint that stops edges from stretching while allowing for edge compression as a surrogate for bending. Notably, this also allows for the capturing of bending modes at scales smaller than those which could typically be represented by the mesh. Various authors have recently begun to explore optimization frameworks for deformable body simulation, which is particularly germane to our inequality cloth framework. After exploring such approaches, we choose a particular approach and illustrate its feasibility in a number of scenarios including contact, collision, and self-collision. Our results demonstrate the efficacy of the inequality approach when it comes to folding, bending, and wrinkling, especially on coarser meshes, thus opening up a plethora of interesting possibilities.","Cloth; Folds; Inequality; Optimization; Wrinkles","Animation; Computer graphics; Constraint theory; Deformation; Fabrics; Interactive computer graphics; Mesh generation; Optimization; Deformable bodies; Elastic modeling; Folds; Inequality; Inequality constraint; Optimization framework; Out-of-plane bending; Wrinkles; Locks (fasteners)",2-s2.0-85031701344
"Usman M., Haworth B., Berseth G., Kapadia M., Faloutsos P.","Understanding spatial perception and visual modes in the review of architectural designs",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031675054&doi=10.1145%2f3099564.3108164&partnerID=40&md5=75e2faf8a3c8c11fa62fc00810ca289d","Spatial analysis of floor plans is typically constrained to blueprints. We investigate how a personâ€™s perception of space in different visual modes relates to common computational spatial measures for environment designs. The three spatial measures, grounded in Space-Syntax analysis, are used to capture different aspects of a design such as visibility, accessibility, and organization. We perform two studies involving novice users and the experts. First, we conduct a perceptual study to find out how novice users perceive these spatial measures when exploring and environment design using different visual modes including 2D blueprints, 3D first-person view, and room-scale virtual reality. A correlation analysis between the usersâ€™ perceptual ratings and the spatial measures indicates that virtual reality is the most eective of the three methods. We conclude that virtual reality provides the requisite delity needed to suciently capture subtle aspects of 3D space, needed to perceive accessibility, visibility, and organization of an environment. On the other hand, 2D blueprints and 3D rst-person exploration often fail to convey the spatial measures. In the second study, experts are asked to evaluate and rank the design blueprints for each spatial measure. The expert observations are in strong agreement with the spatial measures for accessibility and organization, but not for visibility in some cases. This indicates that even experts have diculty understanding spatial aspects of an architectural design from 2D blueprints alone.","Architecture; Perceptual study; Spatial analysis; Virtual reality","Animation; Architectural design; Architecture; Blueprints; Interactive computer graphics; Syntactics; Transportation; Virtual reality; Visibility; Correlation analysis; Environment design; Perceptual study; Space syntax; Spatial analysis; Spatial aspect; Spatial measures; Spatial perception; Spatial variables measurement",2-s2.0-85031675054
"Hochstetter H., Kolb A.","Evaporation and condensation of SPH-based fluids",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031708926&doi=10.1145%2f3099564.3099580&partnerID=40&md5=8e573e92dd77c378a26ba52658f2ce17","In this paper we present a method to simulate evaporation and condensation of liquids. Therefore, both the air and liquid phases have to be simulated. We use, as a carrier of vapor, a coarse grid for the air phase and mass-preservingly couple it to an SPH-based liquid and rigid body simulation. Since condensation only takes place on rigid surfaces, it is captured using textures that carry water to achieve high surface detail. The textures can exchange water with the air phase and are used to generate new particles due to condensation effects yielding a full two-way coupling of air phase and liquid. In order to allow gradual evaporation and condensation processes, liquid particles can take on variable sizes. Our proposed improved implicit surface definition is able to render dynamic contact angles for moving droplets yielding highly detailed fluid rendering.","Condensation; Dynamic contact angle; Evaporation; Fluid rendering; Fluid simulation; Implicit surface; Smoothed particle hydrodynamics","Animation; Condensation; Contact angle; Evaporation; Hydrodynamics; Interactive computer graphics; Liquids; Rolling resistance; Condensation effects; Dynamic contact angle; Evaporation and condensation; Fluid simulations; Implicit surfaces; Rigid-body simulations; Smoothed particle hydrodynamics; Two-way coupling; Fluids",2-s2.0-85031708926
"Zarifi O., Batty C.","A positive-definite cut-cell method for strong two-way coupling between fluids and deformable bodies",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031692203&doi=10.1145%2f3099564.3099572&partnerID=40&md5=3639157d63b6f62d64333eaf68362c38","We present a new approach to simulation of two-way coupling between inviscid free surface fluids and deformable bodies that exhibits several notable vantages over previous techniques. By fully incorporating the dynamics of the solid into pressure projection, we simultaneously handle fluid incompressibility and solid elasticity and damping. Thanks to this strong coupling, our method does not suffer from instability, even in very taxing scenarios. Furthermore, use of a cut-cell discretization methodology allows us to accurately apply proper free-slip boundary conditions at the exact solid-fluid interface. Consequently, our method is capable of correctly simulating inviscid tangential flow, devoid of grid artefacts or artificial sticking. Lastly, we present an efficient algebraic transformation to convert the indefinite coupled pressure projection system into a positive-definite form. We demonstrate the efficacy of our proposed method by simulating several interesting scenarios, including a light bath toy colliding with a collapsing column of water, liquid being dropped onto a deformable platform, and a partially liquid-filled deformable elastic sphere bouncing.","Fluid simulation; Pressure projection; Solid simulation","Animation; Deformation; Interactive computer graphics; Algebraic transformations; Cut cell methods; Deformable bodies; Fluid simulations; Free-slip boundary conditions; Positive definite; Solid-fluid interfaces; Two-way coupling; Phase interfaces",2-s2.0-85031692203
"RajamÃ¤ki J., HÃ¤mÃ¤lÃ¤inen P.","Augmenting sampling based controllers with machine learning",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031688419&doi=10.1145%2f3099564.3099579&partnerID=40&md5=bcbf8ca8beb6fdfb54af1fa3d5e06089","Efficient learning of 3D character control still remains an open problem despite of the remarkable recent advances in the field. We propose a new algorithm that combines planning by a sampling-based model-predictive controller and learning from the planned control, which is very noisy. We combine two methods of learning: 1) immediate but imprecise nearest-neighbor learning, and 2) slower but more precise neural network learning. The nearest neighbor learning allows to rapidly latch on to new experiences whilst the neural network learns more gradually and develops a stable representation of the data. Our experiments indicate that the learners augment each other, and allow rapid discovery and refinement of complex skills such as 3D bipedal locomotion. We demonstrate this in locomotion of 1-, 2- and 4-legged 3D characters under disturbances such as heavy projectile hits and abruptly changing target direction. When augmented with the learners, the sampling based model predictive controller can produce these stable gaits in under a minute on a 4-core CPU. During training the system runs real-time or at interactive frame rates depending on the character complexity.","Model Predictive Controller; Monte Carlo Tree Search; Reinforcement Learning","Animation; Artificial intelligence; Complex networks; Interactive computer graphics; Learning systems; Personnel training; Reinforcement learning; Bipedal locomotion; Efficient learning; Interactive frame rates; Model predictive controllers; Monte-Carlo tree searches; Nearest neighbor learning; Neural network learning; Target direction; Controllers",2-s2.0-85031688419
"Reinhardt S., Eberhardt B., Huber M., Weiskopf D.","Fully asynchronous SPH simulation",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031687765&doi=10.1145%2f3099564.3099571&partnerID=40&md5=fd2758c619ef4f3f367b1f144d07ab9f","We present a novel method for fully asynchronous time integration of particle-based uids using smoothed particle hydrodynamics (SPH). With our approach, we allow a dedicated time step for each particle. Therefore, we are able to increase the eciency of simulations. Previous approaches of locally adaptive time steps have shown promising results in the form of increased time steps, however, they need to synchronize time steps in recurring intervals, which involves either interpolation operations or matching time steps. With our method, time steps are asynchronous through the whole simulation and no global time barriers are needed. In addition, we present an ecient method for parallelization of our novel asynchronous time integration. For both serial and parallel execution, we achieve speedups of up to 7.5 compared to xed time steps and are able to outperform previous adaptive approaches considerably.","Asynchronous time integration; Fluid simulation; Smoothed particle hydrodynamics","Animation; Fluid dynamics; Integration; Interactive computer graphics; Adaptive approach; Adaptive time step; Fluid simulations; Parallel executions; Parallelizations; Smoothed particle hydrodynamics; SPH simulation; Time integration; Hydrodynamics",2-s2.0-85031687765
"MÃ¼ller M., Macklin M., Chentanez N., Jeschke S.","Long range constraints for rigid body simulations",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031701517&doi=10.1145%2f3099564.3099574&partnerID=40&md5=bbbd3fff412518e75b1df96a9463238f","The two main constraints used in rigid body simulations are contacts and joints. Both constrain the motion of a small number of bodies in close proximity. However, it is often the case that a series of constraints restrict the motion of objects over longer distances such as the contacts in a large pile or the joints in a chain of rigid bodies. When only short range constraints are considered, a large number of solver iterations is typically needed for long range effects to emerge because information has to be propagated through individual joints and contacts. Our basic idea to significantly speed up this process is to analyze the contact or joint graphs and automatically derive long range constraints such as upper and lower distance bounds between bodies that can potentially be far apart both spatially and topologically. The long range constraints are either generated or updated at every time step in case of contacts or whenever their topology changes within a joint graph. The significant increase of the convergence rate due to the use of long range constraints allows us to simulate scenarios that cannot be handled by traditional solvers with a number of solver iterations that allow real time simulation.","Long range constraints; Position based simulation; Rigid body simulation","Animation; Interactive computer graphics; Piles; Rigid structures; Close proximity; Convergence rates; Long range effects; Position based simulation; Range constraints; Real time simulations; Rigid-body simulations; Topology changes; Topology",2-s2.0-85031701517
"Erleben K.","Rigid body contact problems using proximal operators",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031669407&doi=10.1145%2f3099564.3099575&partnerID=40&md5=ec2862d1336398b37ccd4dedd27f7f09","Iterative methods are popular for solving contact force problems in rigid body dynamics. They are loved for their robustness and surrounded by mystery as to whether they converge or not. We provide a mathematical foundation for iterative (PROX) schemes based on proximal operators. This is a class of iterative Jacobi and blocked Gaussâ€“Seidel variants that theoretically proven always converge and provides a exible plug and play framework for exploring dierent friction laws. We provide a portfolio of experience for choosing r-Factor strategies for such schemes and we analyze the distribution of convergence behaviors. Our results indicate the Gauss-Seidel variant is superior in terms of delivering predictable convergence behaviour and hence should be preferred over Jacobi variants. Our results also suggest that Global r-Factor strategies are better for structured stacking scenarios and can achieve absolute convergence in more cases.","Contact Force Problems; Proximal Operators; Rigid Body Dynamics","Animation; Friction; Interactive computer graphics; Iterative methods; Mathematical operators; Rigid structures; Social sciences computing; Contact forces; Convergence behaviors; Friction laws; Gauss-Seidel; Mathematical foundations; Plug and play; Rigid body; Rigidbody dynamics; Problem solving",2-s2.0-85031669407
"Jeruzalski T., Jacobson A., Fiume E., Levin D.I.W.","Online compression of rigid body simulations using physics-inspired interpolation",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031696390&doi=10.1145%2f3099564.3106643&partnerID=40&md5=0e8aa5ee19950fe2b17e8c34c7f570e9","Methods to compress simulation data are invaluable as they facilitate efficient transmission along the visual effects pipeline, fast and efficient replay of simulations for visualization and enable storage of scientific data. However, all current approaches to compressing simulation data require access to the entire dynamic simulation, leading to large memory requirements and additional computational burden. In this paper we perform physics-based simulation compression in an online fashion, requiring access to only a narrow window of simulation data at a time and achieving good agreement with the original simulation.","Animation; Rigid body; Simulation compression","Animation; Digital storage; Interactive computer graphics; Rigid structures; Computational burden; Memory requirements; On-line fashion; Physics-based Simulation; Rigid body; Rigid-body simulations; Scientific data; Simulation data; Data visualization",2-s2.0-85031696390
"Eberhardt S., Pinkall U., Weissmann S., Thuerey N.","Hierarchical vorticity skeletons",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031669811&doi=10.1145%2f3099564.3099569&partnerID=40&md5=5dc44edda02a2530d9845e1a49406635","We propose a novel method to extract hierarchies of vortex filaments from given three-dimensional how velocity fields. We call these collections of filaments Hierarchical Vorticity Skeletons (HVS). They extract multi-scale information from the input velocity field, which is not possible with any previous filament extractionapproach. Once computed, these HVSs provide a powerful mechanism for data compression and a very natural way for modifying flows. The data compression rates for all presented examples are above 99%. Employing our skeletons for flow modification has several advantages over traditional approaches. Most importantly, they reduce the complexity of three-dimensional fields to one-dimensional lines and, make complex fluid data more accessible for changing defining features of a flow. The strongly reduced HVS dataset still carries the main characteristics of the flow. Through the hierarchy we can capture the main features of different scales in the flow and by that provide a level of detail control. In contrast to previous","Compression; Flow Guiding; Scale separation; Vortex filaments","Animation; Compaction; Interactive computer graphics; Musculoskeletal system; One dimensional; Transpiration; Velocity; Vortex flow; Vorticity; Compression rates; Flow Guiding; Level-of-detail controls; Multi-scale informations; Presented examples; Scale separation; Traditional approaches; Vortex filament; Data compression",2-s2.0-85031669811
"Megaro V., Levin D.I.W., Knoop E., Matusik W., Spielberg A., Gross M., Thomaszewski B., BÃ¤cher M.","Designing cable-driven actuation networks for kinematic chains and trees",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031692357&doi=10.1145%2f3099564.3099576&partnerID=40&md5=9fcfd3bf5fe7b2003a4dc077108c05fb","In this paper we present an optimization-based approach for the design of cable-driven kinematic chains and trees. Our system takes as input a hierarchical assembly consisting of rigid links jointed together with hinges. The user also specifies a set of target poses or keyframes using inverse kinematics. Our approach places torsional springs at the joints and computes a cable network that allows us to reproduce the specified target poses. We start with a large set of cables that have randomly chosen routing points and we gradually remove the redundancy. Then we refine the routing points taking into account the path between poses or keyframes in order to further reduce the number of cables and minimize required control forces. We propose a reduced coordinate formulation that links control forces to joint angles and routing points, enabling the co-optimization of a cable network together with the required actuation forces. We demonstrate the efficacy of our technique by designing and fabricating a cable-driven, animated character, an animatronic hand, and a specialized gripper.",,"Animation; Chains; Design; Forestry; Interactive computer graphics; Inverse kinematics; Kinematics; Actuation force; Animated characters; Cable networks; Co-optimization; Control force; Hierarchical assemblies; Kinematic chain; Torsional springs; Cables",2-s2.0-85031692357
"Weiss T., Jiang C., Litteneker A., Terzopoulos D.","Position-based multi-agent dynamics for real-time crowd simulation",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031685781&doi=10.1145%2f3099564.3108160&partnerID=40&md5=e811e0a867c1f3fa8d744d55b71290d3","Exploiting the eciency and stability of Position-Based Dynamics (PBD), we introduce a novel crowd simulation method that runs at interactive rates for hundreds of thousands of agents. Our method enables the detailed modeling of per-agent behavior in a Lagrangian formulation. We model short-range and long-range collision avoidance constraints to simulate both sparse and dense crowds. The local short-range interaction is represented with collision and frictional contact between agents, as in the discrete simulation of granular materials. We incorporate a cohesion model for modeling collective behaviors and propose a new constraint for dealing with potential future collisions. Our new real-time crowd simulation method is suitable for use in interactive games.","Collision avoidance; Crowd simulation; Position-based dynamics","Collision avoidance; Dynamics; Interactive computer graphics; Multi agent systems; Collective behavior; Crowd Simulation; Discrete simulations; Frictional contact; Interactive rates; Lagrangian formulations; Real-time crowd simulation; Short range interactions; Animation",2-s2.0-85031685781
"Seki S., Igarashi T.","Sketch-based 3D hair posing by contour drawings",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031676697&doi=10.1145%2f3099564.3106638&partnerID=40&md5=c498ad30341a51bfd27fe6d85123bbc3","We propose a sketch-based method for posing a three-dimensional (3D) hair model that enables artists to create attractive hairstyles more easily and intuitively. The system takes partial contour drawings of a preferred hair shape to modify the rig parameters so that the hair model ts into the sketch. Our method consists of two parts: ow extraction from a sketch and pose construction using the ow. The method was evaluated by a user study and an interview with a professional 3D artist.","Sketch-based posing, hairstyling","Interactive computer graphics; Hair model; Partial contours; Sketch-based posing, hairstyling; Threedimensional (3-d); User study; Animation",2-s2.0-85031676697
"Jang D.-K., Lee S.-H.","Regression-based locating landmark on dynamic humans",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031691714&doi=10.1145%2f3099564.3106645&partnerID=40&md5=d76b33eedb9bf9e76e09e186593a24a6","We present a novel framework that consists of two-level regressors for finding correlations between human shapes and landmark positions in both body part and holistic scales. To this end, we first develop pose invariant coordinates of landmarks that represent both local and global shape features by using the pose invariant local shape descriptors and their spatial relationships. Our body part-level regression deals with the shape features from only those body parts corresponding to a certain landmark. For this, we develop a method that identifies such body parts per landmark, by using geometric shape dictionary obtained through the bag of features method. Our method is nearly automatic, requiring human assistance only once to dierentiate the left and right sides, and shows the prediction accuracy comparable to or better than those of existing methods, with a test data set containing a large variation of human shapes and poses.","KCCA; Landmark detection; Regression; Segmentation","Image segmentation; Interactive computer graphics; Regression analysis; Statistical tests; Geometric shape; Global shape feature; Human assistance; KCCA; Landmark detection; Prediction accuracy; Regression; Spatial relationships; Animation",2-s2.0-85031691714
"Clyde D., Teran J., Tamstorf R.","Modeling and data-driven parameter estimation for woven fabrics",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031686156&doi=10.1145%2f3099564.3099577&partnerID=40&md5=3b22ae003dc2de8a59c6910edd885477","Accurate estimation of mechanical parameters for simulation of woven fabrics is essential in many fields. To facilitate this we first present a new orthotropic hyperelastic constitutive model for woven fabrics. Next, we design an experimental protocol for characterizing real fabrics based on commercially available tests. Finally, we create a method for accurately fitting the material parameters to the experimental data. The last step is accomplished by solving inverse problems based on a Catmull-Clark subdivision finite element discretization of the Kirchhoff-Love equations for thin shells. Using this approach we are able to reproduce the fully nonlinear behavior corresponding to the captured data with a small number of parameters while maintaining all fundamental invariants from","Cloth; Constitutive modeling; Data fitting; Orthotropy","Animation; Constitutive models; Fabrics; Interactive computer graphics; Inverse problems; Weaving; Accurate estimation; Data fittings; Experimental protocols; Finite-element discretization; Hyperelastic constitutive model; Material parameter; Mechanical parameters; Orthotropy; Parameter estimation",2-s2.0-85031686156
"Koschier D., Bender J.","Density maps for improved SPH boundary handling",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031687422&doi=10.1145%2f3099564.3099565&partnerID=40&md5=574c7d145418649fa00fec0cd16e5bdc","In this paper, we present the novel concept of density maps for robust handling of static and rigid dynamic boundaries in fluid simulations based on Smoothed Particle Hydrodynamics (SPH). In contrast to the vast majority of existing approaches, we use an implicit discretization for a continuous extension of the density field throughout solid boundaries. Using the novel representation we enhance accuracy and efficiency of density and density gradient evaluations in boundary regions by computationally efficient lookups into our density maps. The map is generated in a preprocessing step and discretizes the density contribution in the boundaryâ€™s near-field. In consequence of the high regularity of the continuous boundary density field, we use cubic Lagrange polynomials on a narrow-band structure of a regular grid for discretization. This strategy not only removes the necessity to sample boundary surfaces with particles but also decouples the particle size from the number of sample points required to represent the boundary. Moreover, it solves the ever-present problem of particle deficiencies near the boundary. In several comparisons we show that the representation is more accurate than particle samplings, especially for smooth curved boundaries. We further demonstrate that our approach robustly handles scenarios with highly complex boundaries and even outperforms one of the most recent sampling based techniques.","Boundary handling; Implicit representation; Incompressible fluids; Smoothed Particle Hydrodynamics","Animation; Fluid dynamics; Interactive computer graphics; Particle size; Boundary handling; Computationally efficient; Density contribution; Implicit representation; Incompressible fluid; Lagrange polynomials; Pre-processing step; Smoothed particle hydrodynamics; Hydrodynamics",2-s2.0-85031687422
"Lee S., Mitchell N., Aanjaneya M., Sifakis E., Lee J.","Volumetric muscle controller",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031694880&doi=10.1145%2f3099564.3106646&partnerID=40&md5=f86b0851afef9790ad4340d29efb8cac","We describe a controller with a fully integrated musculoskeletal model actuated by more than a hundred muscles. Inspired by a QP-based control algorithm, we improved the algorithm to control the volumetric muscles directly. Furthermore, the highly-detailed musculoskeleton was modeled using a non-manifold method and a computation time was effectively reduced through implicit jacobian computation. Our entire system can simulate the musculoskeleton model with detailed volumetric muscles in a feasible computation time.","Biomechanics, Musculoskeletal system","Animation; Interactive computer graphics; Muscle; Musculoskeletal system; Computation time; Entire system; Fully integrated; Jacobians; Musculoskeletal model; Non-manifolds; Controllers",2-s2.0-85031694880
"Verdier B., Andrews S., Kry P.G.","Human grasping interaction capture and analysis",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031702309&doi=10.1145%2f3099564.3108163&partnerID=40&md5=a55551b3c6058ea7e8e603615873f38f","We design a system to capture, clean, and segment a high quality database of hand based grasping and manipulation. We capture interactions with a large collection of everyday objects. Optical marker-based motion capture and glove data are combined in a physics-based lter to improve the quality of thumb motion. Sensors stitched into our glove provide recordings of the pressure image across the ngers and the palm. We evaluate dierent segmentation techniques for processing motion and pressure data. Finally, we describe examples that explain how the data will be useful in applications such as virtual reality and the design of physics-based control of virtual and robotic hands.","Grasping; Hands; Interaction capture; Segmentation","Image segmentation; Interactive computer graphics; Virtual reality; Grasping; Grasping and manipulation; Hands; Interaction capture; Motion capture; Optical markers; Pressure data; Segmentation techniques; Animation",2-s2.0-85031702309
"Jones R., Southern R.","Physically-based droplet interaction",2017,"Proceedings - SCA 2017: ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031701782&doi=10.1145%2f3099564.3099573&partnerID=40&md5=bb5431908ddfaae6b8e30381f744f380","In this paper we present a physically-based model for simulating realistic interactions between liquid droplets in an efficient manner. Our particle-based system recreates the coalescence, separation and fragmentation interactions that occur between colliding liquid droplets and allows systems of droplets to be meaningfully represented by an equivalent number of simulated particles. By considering the interactions specific to liquid droplet phenomena directly, we display novel levels of detail that cannot be captured using other interaction models at a similar scale. Our work combines experimentally validated components, originating in engineering, with a collection of novel modifications to create a particle-based interaction model for use in the development of mid-to-large scale droplet-based liquid spray effects. We demonstrate this model, alongside a size-dependent drag force, as an extension to a commonly-used ballistic particle system and show how the introduction of these interactions improves the quality and variety of results possible in recreating liquid droplets and sprays, even using these otherwise simple systems.","Fluid simulation, Particle systems","Animation; Drag; Interactive computer graphics; Liquids; Ballistic particles; Droplet interaction; Interaction model; Levels of detail; Liquid droplets; Particle systems; Physically based; Physically based modeling; Drops",2-s2.0-85031701782
"Lee M., Green B., Xie F., Tabellion E.","Vectorized production path tracing",2017,"Proceedings of High Performance Graphics, HPG 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028576915&doi=10.1145%2f3105762.3105768&partnerID=40&md5=28d7cde1738351a5d59e943454f235f8","This paper presents MoonRay, a high performance production rendering architecture using Monte Carlo path tracing developed at DreamWorks Animation. MoonRay is the first production path tracer, to our knowledge, designed to fully leverage Single Instruction/Multiple Data (SIMD) vector units throughout. To achieve high SIMD efficiency, we employ Embree for tracing rays and vectorize the remaining compute intensive components of the renderer: the integrator, the shading system and shaders, and the texturing engine. Queuing is used to help keep all vector lanes full and improve data coherency. We use the ISPC programming language [Intel 2011; Pharr and Mark 2012] to achieve improved performance across SSE, AVX/AVX2 and AVX512 instruction sets. Our system includes two functionally equivalent uni-directional CPU path tracing implementations: a C++ scalar depth-first version and an ISPC vectorized breadth-first wavefront version. Using side by side performance comparisons on complex production scenes and assets we show our vectorized architecture, running on AVX2, delivers between a 1.3× to 2.3× speed-up in overall render time, and up to 3×, 6×, and 4×, speed-ups within the integration, shading, and texturing components, respectively. © 2017 ACM.","Computer graphics; Monte Carlo; Path tracing; Production rendering; Vectorization","C++ (programming language); Computer graphics; Knowledge management; Monte Carlo methods; Complex production; Instruction set; Monte Carlo path tracing; Path tracing; Performance comparison; Shading systems; Single instruction/multiple datum; Vectorization; Rendering (computer graphics)",2-s2.0-85028576915
"Shao X., Liao E., Zhang F.","Improving SPH fluid simulation using position based dynamics",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028856064&doi=10.1109%2fACCESS.2017.2729601&partnerID=40&md5=3725e09cfb6b436a69cdb55087b6ed0b","Physical-based simulation technique has been widely used in creating astounding fluid appearances for film industries and computer games. However, stable and realistic fluid simulation based on Smoothed Particle Hydrodynamics (SPH) method is still challenging, as unstable solid boundary handling and numerical dissipation always plague current SPH fluid solvers. To solve these issues, we present a new method for improving SPH fluid simulation using position-based dynamics (PBD). For the stable fluid-solid interaction, by combining the position constraint solved by PBD and the relative contribution of solid boundary particles, we significantly alleviate the penetration issues at fluid-solid interfaces. And in order to stably simulate turbulence diffusion of SPH fluids, we enforce a novel nonlinear vorticity constraint on each fluid particle, and then solve it using PBD to smooth the vorticity field. The implementation results demonstrate that our method significantly improves SPH method for simulating realistic and stable animations of fluid phenomena. © 2013 IEEE.","fluid simulation; Fluid-solid interaction; position based dynamics; Smoothed Particle Hydrodynamics; turbulence","Animation; Budget control; Computer games; Dynamics; Flow interactions; Fluids; Hydrodynamics; Mathematical models; Numerical methods; Numerical models; Solids; Turbulence; Vorticity; Computational model; Fluid simulations; Fluid solid interaction; Force; Solid model; Diffusion in liquids",2-s2.0-85028856064
"Prashanth B.N., Roy K.","To select the best tool for generating 3D maintenance data and to set the detailed process for obtaining the 3D maintenance data",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026426590&doi=10.1063%2f1.4990202&partnerID=40&md5=70628affa5b197177048a405cf0c620b","Three Dimensional (3D) maintenance data provides a link between design and technical documentation creating interactive 3D graphical training and maintenance material. It becomes difficult for an operator to always go through huge paper manuals or come running to the computer for doing maintenance of a machine which makes the maintenance work fatigue. Above being the case, a 3D animation makes maintenance work very simple since, there is no language barrier. The research deals with the generation of 3D maintenance data of any given machine. The best tool for obtaining the 3D maintenance is selected and the tool is analyzed. Using the same tool, a detailed process for extracting the 3D maintenance data for any machine is set. This project aims at selecting the best tool for obtaining 3D maintenance data and to select the detailed process for obtaining 3D maintenance data. 3D maintenance reduces use of big volumes of manuals which creates human errors and makes the work of an operator fatiguing. Hence 3-D maintenance would help in training and maintenance and would increase productivity. 3Dvia when compared with Cortona 3D and Deep Exploration proves to be better than them. 3Dvia is good in data translation and it has the best renderings compared to the other two 3D maintenance software. 3Dvia is very user friendly and it has various options for creating 3D animations. Its Interactive Electronic Technical Publication (IETP) integration is also better than the other two software. Hence 3Dvia proves to be the best software for obtaining 3D maintenance data of any machine. © 2017 Author(s).","Data; Maintenance; Three Dimensional; Tool",,2-s2.0-85026426590
"Abdi L., Takrouni W., Meddeb A.","In-vehicle cooperative driver information systems",2017,"2017 13th International Wireless Communications and Mobile Computing Conference, IWCMC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027864416&doi=10.1109%2fIWCMC.2017.7986319&partnerID=40&md5=a7ae05d267b7b5b31f2bb0e483d5fbfe","Critical traffic problems such as accidents and traffic congestion require the development of new transportation systems. Research in perceptual and human factors assessment is needed for relevant and correct display of this information for maximal road traffic safety as well as optimal driver comfort. One of the solutions to prevent accidents is to provide information on the surrounding environment of the driver. The development and deployment of cooperative vehicular safety systems undeniably require a combination of dedicated wireless communications, computer vision, and AR technologies as the building blocks of cooperative safety systems. Augmented Reality Head-Up Display (AR-HUD) can facilitate a new form of dialogue between the vehicle and the driver; and enhance ITS by superimposing surrounding traffic information on the users view and keep drivers view on roads. In this paper, we propose a fast deep-learning-based object detection approaches for identifying and recognizing road obstacles types, as well as interpreting and predicting complex traffic situations. A single Convolutional Neural Network (CNN) predicts region of interest and class probabilities directly from full images in one evaluation. We also investigated potential costs and benefits of using dynamic conformal AR cues in improving driving safety. A new AR-HUD approach to create real-time interactive traffic animations was introduced in terms of types of obstacle, rules for placement and visibility, and projection of these on an in-vehicle display. © 2017 IEEE.","Augmented Reality Head-Up Display; Convolutional Neural Network; Cooperative Vehicular Safety systems; Deep Learning; Transportation Systems","Accidents; Advanced driver assistance systems; Augmented reality; Convolution; Cooperative communication; Deep learning; Image segmentation; Intelligent vehicle highway systems; Mobile computing; Neural networks; Object detection; Roads and streets; Safety engineering; Security systems; Traffic control; Transportation; Vehicles; Wireless telecommunication systems; Convolutional neural network; Driver information systems; Head up displays; Interactive traffics; Surrounding environment; Transportation system; Vehicular safety; Wireless communications; Traffic congestion",2-s2.0-85027864416
"Lau B.T., Win K.M.","Differentiated animated social stories to enhance social skills acquisition of children with autism spectrum disorder",2017,"Handbook of Research on Human Development in the Digital Age",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028888837&doi=10.4018%2f978-1-5225-2838-8.ch014&partnerID=40&md5=ea1db1243d6d84549feafb5dc96d8d82","This study developed a web-based social skills intervention system accessible via a tablet/laptop computer which combines differentiated instructions, social stories, multimedia, and animations. This creates an interactive learning environment which (1) allows children to learn social skills repeatedly and pervasively; and (2) promotes teacher/caretaker-parent collaborations to boost the ASD children's social skills acquisition as, a simple logon to the portal enables parents/ caretakers and teachers to view the media prepared by others; track and reinforce the skills a child has learnt at home/ in school, and add his/her social stories which others can view. The prototype evaluation and observation of voluntary participants from the special education school who were treated with differentiated animated social stories demonstrates that digital-based differentiated social story interventions have made the learning of social skills more interactive, appealing and effective compared to the traditional social skill tools. © 2018 IGI Global. All rights reserved.",,,2-s2.0-85028888837
"Sommer-Trembo C., Plath M., Gismann J., Helfrich C., Bierbach D.","Context-dependent female mate choice maintains variation in male sexual activity",2017,"Royal Society Open Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023759775&doi=10.1098%2frsos.170303&partnerID=40&md5=439db8b3e891585f657f918f9443073c","The existence of individual variation in males’ motivation to mate remains a conundrum as directional selection should favour high mating frequencies. Balancing selection resulting from (context-dependent) female mate choice could contribute to the maintenance of this behavioural polymorphism. In dichotomous choice tests, mosquitofish (Gambusia holbrooki) females preferred virtual males showing intermediate mating frequencies, reflecting females’ tendencies to avoid harassment by highly sexually active males. When tested in the presence of a female shoal—which protects females from male harassment—focal females showed significantly stronger preferences for high sexual activity. A trade-off between (indirect) benefits and (direct) costs of mating with sexually active males probably explains context-dependent female mate choice, as costs depend on the social environment in which females choose their mates. No preference was observed when we tested virgin females, suggesting that the behavioural pattern described here is part of the learned behavioural repertoire of G. holbrooki females. © 2017 The Authors.","Computer animations; Male mating activity; Poeciliids; Sexual selection",,2-s2.0-85023759775
"Cruz M., Oliveira A., Esmerado J.","Animation and adults: Between the virtual and social reality",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027224153&doi=10.23919%2fCISTI.2017.7975836&partnerID=40&md5=302d597cd0010e45d8c58247c0cf3dde","In our modern societies, the reality that we live is continuously transformed by technology, different ways of communication and multiple information, creating a (new) virtual reality. How is our social world linked to the virtual world? Animated films may help us to discover and understand this interface, in which their boundaries may not be clear. What we call human reality approaches fantasy realms in the virtual worlds. The aim of this study is to explore what animated films transmit to an adult population - what they feel and what they value in animated films, trying to understand the importance of animated films in adults' lives. It is also intended to explore which technologies are most used to consult information about animated films, and which are the most important reasons for choosing an animated film, instead of other styles of movies. Our study consists in the development of two focus groups, with adult participants, between 25 and 35 years. This study is part of a master's thesis that is under development. Through the focus group we aim to obtain data and gather knowledge about our research topic. The results will help us to verify the most relevant factors and indicating the items to include in a questionnaire that will be used in a next study. © 2017 AISTI.","Adults; Animation; Social reality; Technology; Virtual reality","Animation; Information systems; Interactive computer graphics; Interfaces (materials); Motion pictures; Technology; Adult populations; Adults; Focus groups; Research topics; Social reality; Virtual worlds; Virtual reality",2-s2.0-85027224153
"Vijayalaxmi S.W., Sreenivasan A.","""design and simulation of ircular Microstrip patch antenna""",2017,"IEEE International Conference on Innovative Mechanisms for Industry Applications, ICIMIA 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027438670&doi=10.1109%2fICIMIA.2017.7975519&partnerID=40&md5=1822755f5a463318a5a41cfcbb87de5d","A simple microstrip patch antenna consists of metallic patch and ground between a dielectric medium called the substrate. Microstrip patch antennas are widely used in communication, especially in military and civil applications. The printed antennas have played a major role in development of antenna at different frequency. The proposed antenna is done on fr4 (frame sensitive) substrate with dielectric permittivity £ o and the thickness 'h' will provide with good omnidirectional radiation pattern. It has a advantages in simple design, Compact in size and easy in fabrication. Design and simulation of patch antenna using HFSS Software. Design of a circular micro-strip patch antenna for 2.4 GHz application and study s-parameter, Gain and field animations. © 2017 IEEE.","Fr4 (frame resistive) substrate; HFSS software; Slotted circular Microstrip patch antenna; Strip line feeding","Computer software; Directional patterns (antenna); Microstrip devices; Microwave antennas; Military applications; Omnidirectional antennas; Permittivity; Scattering parameters; Slot antennas; Circular microstrip patch; Civil applications; Design and simulation; Dielectric permittivities; Different frequency; HFSS software; Micro-strip patch antennas; Omnidirectional radiation pattern; Microstrip antennas",2-s2.0-85027438670
"Ribeiro A.C.R., Sonego A.H.S., Do Amaral C.B., Torrezzan C.A.W., Machado L.R., Behar P.A.","Social interactions in distance education: Development of a digital educational material [Interações Sociais na Educação a Distância: desenvolvimento de um material educacional digital]",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027231064&doi=10.23919%2fCISTI.2017.7975876&partnerID=40&md5=a2c67307bf0317180083180ea2b23060","This work presents the planning, development and implementation of the SocioAVA digital educational material - Social Interactions in Virtual Learning Environments. This material is aimed at professionals working in Distance Education (DE) who are interested in discussing social interactions in the virtual. The objective is to discuss social interactions as an important factor to be included in pedagogical practices developed in Virtual Learning Environments (VEL). SocioAVA consists of four modules, bringing cases that can contextualize, discuss and exemplify social interactions in pedagogical practices in DE. In each module are explanatory texts and support materials such as videos, presentations, animations, audios, hypertexts, infographics, among others. To help in the discussion about the content in question, activities are also proposed in the form of challenges in order to problematize the topics addressed. For the development of SocioAVA digital educational material, an interdisciplinary team composed of educators, programmers, musicians and web designers was involved. The methodology adopted was ConstruMED in which it is focused on the construction of Digital Educational Materials (DEM) based on pedagogical design. This methodology is composed of five stages: Preparation, Planning, Implementation, Evaluation and Distribution. The application of DEM will occur in undergraduate and postgraduate courses in the area of Education. It is intended to test the operation of the material, its degree of adequacy to the target audience and level of achievement of the objectives, verifying the operation and to analyze if the DEM was in agreement with the technical, functional and didactic characteristics that are included in the project. It is understood that in DE is extremely important the appreciation of the student's role in learning, since at various moments is physically distant from the teacher and colleagues. In this way, the constant interaction between the actors of the VEL is fundamental for the pedagogical success in this modality. © 2017 AISTI.","Digital Educational Material; Distance Education; Social Interactions","Computer aided instruction; Distance education; Education; Hypertext systems; Information systems; Social sciences; Surveying; Teaching; Educational materials; Interdisciplinary teams; Pedagogical designs; Pedagogical practices; Postgraduate course; Social interactions; Support materials; Virtual learning environments; E-learning",2-s2.0-85027231064
"Dong H., Figueroa N., El Saddik A.","Development of a handheld human head scanner based on an RGB-D sensor",2017,"I2MTC 2017 - 2017 IEEE International Instrumentation and Measurement Technology Conference, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026780514&doi=10.1109%2fI2MTC.2017.7969656&partnerID=40&md5=62fdd9eb7564d3d31ee4b6e4c0f64809","The accessible acquisition of 3D models of human heads has many applications, such as anthropological studies, ergonomic product design and digital avatar animation. In this paper we introduce a low-cost system that accurately reconstructs 3D models of the human head using a consumer RGB-D sensor. Our proposed system uses an RGB-D sensor (i.e. the Microsoft Kinect) as the 3D sensing device and the KinectFusion algorithm as our reconstruction method. A segmentation algorithm based on face detection methods on the RGB images is applied to the 3D reconstructed model of the human, resulting in an automatic human head scanning device. © 2017 IEEE.",,"Face recognition; Image segmentation; Product design; Ergonomic product design; Face detection methods; Low-cost systems; Microsoft kinect; Reconstruction method; Rgb-d sensors; Scanning device; Segmentation algorithms; Three dimensional computer graphics",2-s2.0-85026780514
"Zhu S., Wang J.","Computer-aided 3D ethnic art animation design and based on maya software",2017,"Boletin Tecnico/Technical Bulletin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028720063&partnerID=40&md5=3491b0b6e2a612539b1e79deb4fee5f6","The rapid development of digital and information technology brings new opportunities for the protection of traditional art form. In this paper, the author analysed computer-aided 3D ethnic art animation design and based on maya software. Through digital exhibition hall, virtual reality technology, digital technology can provide real experience for visitors to enjoy, computer interaction can make people feel immersive. Through the three dimensional animation software, the author has completed a ethnic art animation design and demonstrated the production process.","3D Animation design; Ethnic art; Maya; Virtual reality","Animation; Exhibition buildings; Exhibitions; Virtual reality; 3D animation; Computer interaction; Digital exhibition halls; Digital technologies; Ethnic art; Maya; Three-dimensional animations; Virtual reality technology; Computer software",2-s2.0-85028720063
"Sun J., Lu D., Liu L., Ma H.","A Visual Disparity Adjustment Method for Stereoscopic 3D Animation Production",2017,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031692494&partnerID=40&md5=caf9fc9dc851ed5bd0563bd570ffde66","With the rapid development of stereoscopic display technology in recent years, the requirements in stereoscopic 3D (S3D) animation for many fields are increasing gradually. However, in the procedure of S3D animation production the stereo effect is difficult to control so that the perceived depth is not obvious or visual fatigue happens. We proposed a stereo effect adjustment method for prophase of S3D animation production. First, we generated the disparity gradient maps according to the relationships among scene depth, stereo image disparity and stereo effect. Then, through analyzing the relationship between disparity and view distance, we derived the disparity range for the best visual effect and further marked the regions for visual fatigue on the disparity gradient map. Moreover, we obtained the curves between the stereo parameters and the disparity and analyzed the influence of the stereo parameters on the disparity, which can assist the animation producer to accurately adjust the stereo effect. We also built a Maya plug-in and used the typical scene cuts of a commercial animation film ""Legend of A Rabbit: The Martial of Fire"" to verify our method. Experimental results show that our method with high accuracy and automation level could significantly improve the efficiency of the S3D animation production. © 2017, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Disparity adjustment; Stereoscopic 3D animation; Stereoscopic effect; Visualization comfort","Animation; Display devices; Stereo image processing; 3D animation; Adjustment method; Automation levels; Disparity adjustments; Stereoscopic display technologies; Stereoscopic effect; Visual effects; Visual fatigue; Three dimensional computer graphics",2-s2.0-85031692494
"Yu J., Li L., Zou J.","Realistic emotion visualization by combining facial animation and hairstyle synthesis",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009738424&doi=10.1007%2fs11042-016-4239-8&partnerID=40&md5=7654bdf36b58879bb3638074eabe5bf2","Facial expressions are one of most intuitive way for expressing emotions, and can facilitate human-computer interaction by enabling users to communicate with computers using more natural ways. Besides, the hair can be designed to enhance the expression of emotions particularly. To visualize the emotions in multiple aspects for completeness, we propose a realistic visual emotional synthesis system based on the combination of facial expression and hairstyle in this paper. Firstly, facial expression is synthesized by the anatomical model and parameterized model. Secondly, cartoonish hairstyle is synthesized to describe emotion implicitly by the mass-spring model and cantilever beam model. Finally, the synthesis results of facial expression and hairstyle are combined to produce a complete visual emotion synthesis result. Experiment results demonstrate the proposed system can synthesize realistic animation, and the emotion expressiveness by combining of face and hair outperform that by face or hair alone. © 2017, Springer Science+Business Media New York.","Facial animation; Hair animation; Visual emotion synthesis","Animation; Anatomical modeling; Emotion synthesis; Facial animation; Facial Expressions; Mass-spring models; Parameterized model; Human computer interaction",2-s2.0-85009738424
"Sheu J.-J., Chu K.-T., Wang S.-M.","The associate impact of individual internal experiences and reference groups on buying behavior: A case study of animations, comics, and games consumers",2017,"Telematics and Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014809358&doi=10.1016%2fj.tele.2016.08.013&partnerID=40&md5=c0a56286054c8750a25ee3ff5a852dff","Among the entertainment and media market, it can be observed that animations, comics, and video games (hereinafter abbreviated as ACG) have the highest output value and most market influence. Moreover, ACG also incorporates various industries and creates many derivative products. As the ACG industry emphasizes acousto-optics, imagery, and storylines, personal impressions derived from consumer experiences will influence consumer decisions. In addition, the ACG industry is mainly marketed towards younger age groups, with younger people being the main consumers; as such, these consumers’ decisions are more easily affected by peer behavior. This study aims to analyze the effects of internal cognitions and external influences on buying behavior of ACG consumers by applying the uncomplicated decision tree data mining algorithm. We analyze and develop the target attributes on measures of customer loyalty for ACG industry to set up the decision trees from the collected questionnaire data. The decision tree data mining method is applied to analyze the hidden association rules between the target attributes (i.e., consumer loyalty) and the critical influencing factors of consumer's internal impressions and external influences for ACG consumers. The results and suggestions of this paper can be used as a reference for enterprises in the ACG industry to help with business policies concerning products’ extensional design, marketing, and CRM, and to further strengthen customer satisfaction and loyalty, thus increasing company profits. © 2016 Elsevier Ltd","Animation, comics, and games; Data mining; Decision tree; Loyalty; Strategic experiential module","Animation; Commerce; Customer satisfaction; Data mining; Decision trees; Human computer interaction; Product design; Trees (mathematics); Business policies; Buying behavior; Consumer loyalty; Customer loyalty; External influences; Loyalty; Questionnaire data; Strategic experiential module; Consumer behavior",2-s2.0-85014809358
"Kim N., Park S., Jeong D., Hwang M., Park S., In H.P.","EURECA: End-user requirements engineering with collaborative animation",2017,"Software - Practice and Experience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017520060&doi=10.1002%2fspe.2471&partnerID=40&md5=f69e66a6eaabc3a3ec949a1389dd5373","In recent years, software development environments have changed from being driven by professional developers to being driven by technical end users. One of the key issues in end-user-driven software development environments is how to guarantee the quality of the software artifacts. Measuring the quality of developed software requires the correct specification of a quality range the software is expected to meet. However, technical end users are non-professionals in engineering techniques for software requirements, and training a developer to be an expert in requirements engineering in a short period of time is difficult. This paper proposes a new software development life cycle based on reutilizing previously evaluated software requirements assets from completed projects. End-User Requirements Engineering with Collaborative Animation, a tool that was developed to support the proposed software development life cycle, is described and demonstrated by application to three projects. The results from real cases are used as the basis for a discussion on the efficiency enhancement of requirements work, an increased rate of reusing legacy software requirements assets, and an improvement in the technical end user's individual competency level using the End-User Requirements Engineering with Collaborative Animation. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","end-user software engineering; requirements engineering; software reuse","Animation; Application programs; Computer software; Computer software reusability; Life cycle; Requirements engineering; Software engineering; Efficiency enhancement; End-user software engineering; Engineering techniques; Individual competencies; Software artifacts; Software development environment; Software development life cycle; Software requirements; Software design",2-s2.0-85017520060
"Lajevardi N., Narang N.S., Marcus N., Ayres P.","Can mimicking gestures facilitate learning from instructional animations and static graphics?",2017,"Computers and Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016052664&doi=10.1016%2fj.compedu.2017.03.010&partnerID=40&md5=03cf3741fca7f72b6ae633bf2b545516","The main aim of the study was to investigate the effects of mimicking gestures on learning from animations and static graphics. In Experiment 1, 48 university students learned to write Mandarin characters, and in Experiment 2, 44 young children learned to write Persian characters. In both experiments, participants were randomly assigned to one of four conditions – animations without gestures, animations with gestures, statics without gestures, or statics with gestures. All groups viewed instructional content showing how to write the foreign characters, and then were tested. In the gesturing conditions, participants were required to mimic the character writing at the same time as watching the instructional presentation, and in the non-gesturing conditions, mimicking was prevented. Results from both experiments indicated a presentation-gesturing interaction, where gesturing was an advantage for static graphics but not animations. Experiment 2 found an advantage for animations over static graphics, and gesturing compared to not gesturing. © 2017","Animation effects; Cognitive load theory; Embodied cognition; Gesturing to learn; Interactive learning environments","Knowledge acquisition; Animation effects; Cognitive load theory; Embodied cognition; Gesturing to learn; Interactive learning environment; Computer aided instruction",2-s2.0-85016052664
"Aktaş A.Z., Orçun E.R.","A real-time strategy game, “GALLIPOLI WARS,” as a centennial tribute to the Gallipoli Campaign (1915–2015)",2017,"Journal of Defense Modeling and Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020375790&doi=10.1177%2f1548512916649455&partnerID=40&md5=e20b2b50dc9ebc33f66b45d9be95178d","The same authors had reported a review of game development processes and methodologies in an earlier paper. In that paper, game design elements, such as the players, story, rules, objectives, procedures, conflict, and challenge, and their effect over gameplay were treated. Technical components in that paper included the render engine and rendering pipeline (fixed function pipeline and flexible pipeline), physics engine and physics-related techniques (collision detection, ray-casting, etc.), game codes (for game mechanics, artificial intelligence, scenario creation, and management) and artwork contents (game level, three-dimensional (3D) models, two-dimensional maps for shaders, skeletal animation, and audio assets) that form a game. Along with their development processes and approaches, all of these technical and artwork components are applied on a case problem and are summarized in this paper. The case problem considered is a small part of Gallipoli or Dardanelles Wars in Ottoman history, as a real-time 3D strategy game. © 2016, © The Author(s) 2016.","Dardanelles wars; software engineering; the Gallipoli Campaign real-time strategy game; three-dimensional computer game; “GALLIPOLI WARS”","Animation; Computer games; Computer software; Engines; Interactive computer graphics; Pipeline codes; Pipelines; Real time systems; Rendering (computer graphics); Software design; Software engineering; Collision detection; Dardanelles; Development process; Real-time strategy games; Rendering pipelines; Skeletal animation; Three-dimensional (3D) model; Two-dimensional map; Three dimensional computer graphics",2-s2.0-85020375790
"Stüvel S.A., Magnenat-Thalmann N., Thalmann D., Van Der Stappen A.F., Egges A.","Torso crowds",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021695877&doi=10.1109%2fTVCG.2016.2545670&partnerID=40&md5=5b9a6ea9c27288314b5582460825de41","We present a novel dense crowd simulation method. In real crowds of high density, people manoeuvring the crowd need to twist their torso to pass between others. Our proposed method does not use the traditional disc-shaped agent, but instead employs capsule-shaped agents, which enables us to plan such torso orientations. Contrary to other crowd simulation systems, which often focus on the movement of the entire crowd, our method distinguishes between active agents that try to manoeuvre through the crowd, and passive agents that have no incentive to move. We introduce the concept of a focus point to influence crowd agent orientation. Recorded data from real human crowds are used for validation, which shows that our proposed model produces equivalent paths for 85 percent of the validation set. Furthermore, we present a character animation technique that uses the results from our crowd model to generate torso-twisting and side-stepping characters. © 2016 IEEE.","Agent representation; Crowd animation; Crowd simulation; Dense crowds; Holonomic motion","Computer graphics; Software engineering; Active agents; Agent orientation; Character animation; Crowd animation; Crowd modeling; Crowd Simulation; Dense crowds; Holonomic; Animation",2-s2.0-85021695877
"Steffen W., Koning N.","Hybrid polygon and hydrodynamic nebula modeling with multi-waveband radiation transfer in astrophysics",2017,"Astronomy and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024933505&doi=10.1016%2fj.ascom.2017.06.002&partnerID=40&md5=6a228565f7cffc6db2a2de8d30ba9af8","We demonstrate the potential for research and outreach of mixed polygon and hydrodynamic modeling and multi-waveband rendering in the interactive 3-D astrophysical virtual laboratory Shape. In 3-D special effects and animation software for the mass media, computer graphics techniques that mix polygon and numerical hydrodynamics have become common place. In astrophysics, however, interactive modeling with polygon structures has only become available with the software Shape. Numerical hydrodynamic simulations and their visualization are usually separate, while in Shape it is integrated with the polygon modeling approach that requires no programming by the user. With two generic examples, we demonstrate that research and outreach modeling can be achieved with techniques similar to those used in the media industry with the added capability for physical rendering at any wavelength band, yielding more realistic radiation modeling. Furthermore, we show how the hydrodynamics and the polygon mesh modeling can be mixed to achieve results that are superior to those obtained using either one of these modeling techniques alone. © 2017 The Authors","3-D; Hydrodynamics; Numerical methods; Polygon modeling; Shape; Software","Astrophysics; Computer graphics; Computer software; Fluid dynamics; Hydrodynamics; Numerical methods; Rendering (computer graphics); Three dimensional computer graphics; Animation softwares; Hydrodynamic model; Interactive modeling; Numerical hydrodynamics; Polygon-models; Radiation transfer; Shape; Virtual laboratories; Geometry",2-s2.0-85024933505
"Yu J., Wang Z.","A Video-Based Facial Motion Tracking and Expression Recognition System",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984846487&doi=10.1007%2fs11042-016-3883-3&partnerID=40&md5=c89a3a45ef355d157934ab2bb580ca90","We proposed a facial motion tracking and expression recognition system based on video data. By a 3D deformable facial model, the online statistical model (OSM) and cylinder head model (CHM) were combined to track 3D facial motion in the framework of particle filtering. For facial expression recognition, a fast and efficient algorithm and a robust and precise algorithm were developed. With the first, facial animation and facial expression were retrieved sequentially. After that facial animation was obtained, facial expression was recognized by static facial expression knowledge learned from anatomical analysis. With the second, facial animation and facial expression were simultaneously retrieved to increase the reliability and robustness with noisy input data. Facial expression was recognized by fusing static and dynamic facial expression knowledge, the latter of which was learned by training a multi-class expressional Markov process using a video database. The experiments showed that facial motion tracking by OSM+CHM is more pose robust than that by OSM, and the facial expression score of the robust and precise algorithm is higher than those of other state-of-the-art facial expression recognition methods. © 2016, Springer Science+Business Media New York.","Facial expression recognition; Facial motion tracking; Markov process; Particle filtering","Algorithms; Animation; Computer software maintenance; Markov processes; Monte Carlo methods; Motion analysis; Signal filtering and prediction; Video recording; Dynamic facial expression; Expression recognition; Facial expression recognition; Facial motions; Fast and efficient algorithms; Particle Filtering; Reliability and robustness; Statistical modeling; Face recognition",2-s2.0-84984846487
"Ladner R.E., Rector K.","Making your presentation accessible",2017,"Interactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021742191&doi=10.1145%2f3085564&partnerID=40&md5=c5e46b1815de8f9bc019cf5e5e68c62f","Some of the guidelines and resources for giving accessible conference talks are discussed. A great talk is not about the slides; it's about the speaker. The focus of the audience should be on the speaker, not the slides. The slides only amplify what the speaker is saying. How the speaker connects with the audience makes people want to listen, so it is paramount that the speaker know who the listeners are. Sign-language interpreters are often requested by deaf audience members. It is important to recognize that a deaf audience member using an interpreter can focus on only one thing at a time, the interpreter, the speaker, or the slides. When referring to information on a slide, it is good to pause for a moment to allow time for the translation and the attention shift to the slide. No one wants to read a complicated graphic when there are only a few important facts about it. Save the complicated graphic for the paper. Avoiding or controlling the speed of animation will help people who cannot see the animation clearly. All audience members will appreciate an animation that moves slowly and is explained. Sometimes it is good to give a brief description of what is in the video before it is played. This will help blind audience members to establish context for what they will hear.",,"Human computer interaction; Attention shifts; Sign language; Animation",2-s2.0-85021742191
"Rozefelds A.C., Milroy A.K., Dettmann M.E., Clifford H.T., Maksimenko A.","Synchrotron computer tomographic (CT) scans complement traditional techniques in understanding the internal anatomy of permineralised Fontainocarpa (Crotonoideae, Euphorbiaceae) fruits from the Oligocene of eastern Australia",2017,"Review of Palaeobotany and Palynology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017092809&doi=10.1016%2fj.revpalbo.2017.03.001&partnerID=40&md5=a124c354565e5928b8e852142040c3bb","The internal morphology and anatomy of silicified fruits of Fontainocarpa were studied using traditional thin sectioning techniques, SEM and synchrotron computed tomographic (CT) imaging and animations, to enable comparative analyses with extant, indehiscent-fruited genera in the Euphorbiaceae including Fontainea, Aleurites and Hylandia from Australia, and other non-Australian crotonoid genera. Thin sections and sectioning show that the fruits of Fontainocarpa are indehiscent, multicarpellate and usually 3- to 5-loculate, with axial placentation, a single ovule per carpel and the ovules are anatropous and have antitropous curvature. A ventral vascular trace that supplies each ovule is embedded in the bitegmic seed coat. The internal anatomy is therefore consistent with the Euphorbiaceae. Additional characters, including indehiscent fruits, distinctive vascular channels (foramina) that penetrate through the fruit wall into the locule, and thin membranous seed coats are restricted to very few genera in the Euphorbiaceae, but occur together in extant Fontainea. The seed coat in extant Fontainea and fossil Fontainocarpa seeds is membranous, and appears to lack the palisadal exotegmen of most genera in the Euphorbiaceae. Fontainocarpa fruits were compared with those of extant Fontainea and the fossil has a combination of features unlike those of extant taxa. It shares with Fontainea picrosperma in having endocarps with convex intersutural surfaces lacking ornamentation and a similar number of locules and with Fontainea venosa in having conspicuous foramina. This study therefore supports a close relationship between Fontainea and Fontainocarpa and is further evidence of the Crotonoideae in the fossil record in Australia, and is one of the few records of this subfamily worldwide. This study is one of the few, to date, using synchrotron CT imaging to reveal the internal morphology of silicified fruits and to utilize animations to examine the structure of these fruits. © 2017 Elsevier B.V.","Australia; Cenozoic; Euphorbiaceae; Fontainea; Fontainocarpa; Indehiscent fruit","analytical method; anatomy; Cenozoic; computer vision; dicotyledon; fossil record; fruit; imaging method; morphology; Oligocene; paleobotany; tomography; ultrastructure; Australia; Aleurites; Crotonoideae; Euphorbiaceae; Fontainea; Fontainea venosa; Hylandia",2-s2.0-85017092809
"Vural C., Yıldırım İ.","Reversible video watermarking through recursive histogram modification",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983801009&doi=10.1007%2fs11042-016-3854-8&partnerID=40&md5=195f7a1c1652d6533d9f500d0ebefd1f","In this study, a new reversible video watermarking method is developed. Unlike the existing reversible video watermarking algorithms that are based on motion compensated prediction or interpolation error expansion, motion compensated interpolation errors in the proposed method are watermarked in a totally different manner with the aid of recursive histogram modification algorithm developed recently for the purpose of reversible image watermarking. However,the recursive histogram modification can not be used directly for reversible video watermarking since the important problems of ensuring reversibility for each frame and distribution of total capacity among frames are encountered. In this study, novel ideas are proposed to solve the aforementioned two problems. The proposed method is tested on the video sequences commonly used in the literature. It is shown to give better performance than the existing reversible video watermarking algorithms in terms of capacity and distortion by means of computer simulations. Also, a numerical example is provided. © 2016, Springer Science+Business Media New York.","Recursive histogram modification; Reversible video watermarking; Reversible watermarking","Animation; Digital watermarking; Image coding; Image watermarking; Interpolation; Histogram modification; Motion compensated interpolation; Motion compensated prediction; Reversible image watermarking; Reversible watermarking; Video watermarking; Video watermarking algorithm; Video watermarking method; Graphic methods",2-s2.0-84983801009
"Vatansever F., Yalcin N.A.","e-Signals&Systems: A web-based educational tool for signals and systems",2017,"Computer Applications in Engineering Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018970835&doi=10.1002%2fcae.21826&partnerID=40&md5=e59538efd6ea735b4f2e4314b4447483","Computers are widely used for educational purposes. Multimedia tools and simulations are mostly preferred for learning especially hard and complex structures in technical field and hardly realized experiments in laboratory environment. Besides, supporting theoretical knowledge with practical applications is crucial in engineering education. But, effects of negative conditions such as hardware deficiency (experimental gadgets, measuring instruments, etc.) in education environment, high number of students, less number of educators can be diminished with concepts which are distance education, computer-aided education, etc. In this study, web-based educational tool which is oriented to signals and systems subjects/courses is realized. This tool provides learning of signals and systems subjects with its subject descriptions, solved/unsolved problems, animations, simulations, interactive simulators, real-time applications, general exams, online communication/support, and new educational strategy in easy, simple, and effective way. Usability and educational contribution of realized study was inspected with questionnaires which were filled anonymously by 110 students in Uludag University and assessed according to SUS and Likert scales. © 2017 Wiley Periodicals, Inc.","computer-aided learning; distance learning; e-learning; signals and systems","Computer aided instruction; Computer hardware; Distance education; Education; Online systems; Real time systems; Students; Surveys; Websites; Computer aided learning; Computer-aided education; Interactive simulators; Laboratory environment; Measuring instruments; Real-time application; Signals and systems; Web-based educational tool; E-learning",2-s2.0-85018970835
"Zipke M.","Preschoolers explore interactive storybook apps: The effect on word recognition and story comprehension",2017,"Education and Information Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976506826&doi=10.1007%2fs10639-016-9513-x&partnerID=40&md5=52ade58a630ab187ec19ca0abf81f009","Two experiments explored the effects of reading digital storybooks on tablet computers with 25 preschoolers, aged 4–5. In the first experiment, the students’ word recognition scores were found to increase significantly more when students explored a digital storybook and employed the read-aloud function than when they were read to from a comparable print book. Their comprehension scores did not change significantly in the two conditions. In Experiment 2, the same students explored digital storybooks with more animation embedded in them. The students listened to the read aloud function on the tablet computer and explored digital storybooks in both conditions, but in one condition a teacher guided the talk about the story. Contrary to expectations, the students’ word recognition and story comprehension scores were higher in the independent condition than in the guided condition. One explanation for the higher word recognition scores when students were reading with the tablet computer is the effect of multimedia, like hotspots and/or text tracking. Although digital storybooks are not a substitute for adult interaction, these preschoolers learned surprisingly well on their own. The importance of digital storybook design, as well as what elements to look for in an e-book to encourage literacy learning are discussed. © 2016, Springer Science+Business Media New York.","Computers and learning; E-books; Early childhood education; Instructional technology; Literacy; Media",,2-s2.0-84976506826
"Carlin J.D., Kriegeskorte N.","Adjudicating between face-coding models with individual-face fMRI responses",2017,"PLoS Computational Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026633541&doi=10.1371%2fjournal.pcbi.1005604&partnerID=40&md5=f8e6c2c81dc5211bdd15e5bb55e0a9e1","The perceptual representation of individual faces is often explained with reference to a norm-based face space. In such spaces, individuals are encoded as vectors where identity is primarily conveyed by direction and distinctiveness by eccentricity. Here we measured human fMRI responses and psychophysical similarity judgments of individual face exemplars, which were generated as realistic 3D animations using a computer-graphics model. We developed and evaluated multiple neurobiologically plausible computational models, each of which predicts a representational distance matrix and a regional-mean activation profile for 24 face stimuli. In the fusiform face area, a face-space coding model with sigmoidal ramp tuning provided a better account of the data than one based on exemplar tuning. However, an image-processing model with weighted banks of Gabor filters performed similarly. Accounting for the data required the inclusion of a measurement-level population averaging mechanism that approximates how fMRI voxels locally average distinct neuronal tunings. Our study demonstrates the importance of comparing multiple models and of modeling the measurement process in computational neuroimaging. © 2017 Carlin, Kriegeskorte.",,"Article; brain region; computer model; electroencephalogram; facial recognition; functional magnetic resonance imaging; human; human experiment; image processing; neuroimaging; normal human; psychophysics; signal noise ratio; task performance; three dimensional imaging; visual stimulation; voxel based morphometry; algorithm; biological model; brain; brain mapping; face; facial recognition; nuclear magnetic resonance imaging; physiology; principal component analysis; procedures; Algorithms; Brain; Brain Mapping; Face; Facial Recognition; Humans; Magnetic Resonance Imaging; Models, Neurological; Principal Component Analysis",2-s2.0-85026633541
"Esteve-Taboada J.J., Del Águila-Carrasco A.J., Bernal-Molina P., López-Gil N., Montés-Micó R., Kruger P., Marín-Franch I.","Dynamic accommodation without feedback does not respond to isolated blur cues",2017,"Vision Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021146037&doi=10.1016%2fj.visres.2017.05.007&partnerID=40&md5=3270c2b10592dbf89e94357c130475f0","The aim of this study was to determine whether dynamic accommodation responds to isolated blur cues without feedback, and without changes in the distance of the object. Nine healthy subjects aged 21–40 years were recruited. Four different aberration patterns were used as stimuli to induce blur with (1) the eye's natural, uncorrected, optical aberrations, (2) all aberrations corrected, (3) spherical aberration only, or (4) astigmatism only. The stimulus was a video animation based on computer-generated images of a monochromatic Maltese cross. Each individual video was generated for each subject off-line, after measuring individual aberrations at different accommodation levels. The video simulated sinusoidal changes in defocus at 0.2 Hz. Dynamic images were observed through a 0.8 mm pinhole placed at a plane conjugated with the eye's pupil, thus effectively removing potential feedback stemming from accommodation changes. Accommodation responses were measured with a Hartmann-Shack aberrometer for the four different aberration patterns. The results showed that seven out of nine subjects did not respond to any stimuli, whereas the response of the other two subjects was erratic and they seemed to be searching rather than following the stimulus. A significant reduction in average accommodative gain (from 0.52 to 0.11) was obtained when the dioptric demand cue was removed. No statistically significant differences were found among the experimental conditions used. We conclude that aberration related blur does not drive the accommodation response in the absence of feedback from accommodation. © 2017 The Authors","Accommodation; Dynamic accommodation; Higher-order aberrations; Vergence","accommodation; adult; Article; association; computer analysis; feedback system; human; human experiment; image analysis; methodology; normal human; priority journal; task performance; visual stimulation; visual system parameters",2-s2.0-85021146037
"Reyes M.E.P., Chen S.-C.","A 3D Virtual Environment for Storm Surge Flooding Animation",2017,"Proceedings - 2017 IEEE 3rd International Conference on Multimedia Big Data, BigMM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027714300&doi=10.1109%2fBigMM.2017.54&partnerID=40&md5=d96870c01912e92952c2e7a6b3d008ea","In this paper, we present a storm surge flooding animation system using Three-Dimensional (3D) visualization of real life Geographic Information System (GIS) data. Putting together ground elevation with building information provided by Open Street Maps (OSM), we can recreate real life cities (e.g., South Miami Beach in this paper) in a 3D environment. The 3D terrain development and visualization are done with the aid of the game engine Unity. With this tool, learning about storm surge and hurricanes can be an interactive experience. Moreover, since the system more closely portrays a real life environment, visualizing the effects of storm surge can help users study past hurricane disasters as well as possible forecasted hurricane events. For an immersive experience, we connect the system with an Integrated Computer Augmented Virtual Environment (I-CAVE) to give users the capability of navigation through the terrain in a human-scale view. © 2017 IEEE.","3D visualization; augmented reality; digital elevation models; GIS; storm surge modeling; Unity","Animation; Augmented reality; Big data; Data visualization; Floods; Geographic information systems; Hurricane effects; Hurricanes; Storms; Virtual reality; Visualization; 3-D environments; 3-D virtual environment; 3D Visualization; Animation systems; Digital elevation model; Storm surges; Three dimensional (3D) visualization; Unity; Three dimensional computer graphics",2-s2.0-85027714300
"Zou X., Cheng A.M.K., Rincon C., Jiang Y.","Multi-mode P-FRP task scheduling",2017,"Proceedings - 2017 IEEE 20th International Symposium on Real-Time Distributed Computing, ISORC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026751626&doi=10.1109%2fISORC.2017.19&partnerID=40&md5=e360828a98e2bbc114a453675c5a71ad","Functional Reactive Programming (FRP) provides an elegant way to express computation in domains such as interactive animations, robotics, computer vision, user interfaces, and simulation. Priority-based (preemptive) FRP (P-FRP), a variant of FRP with more real-time characteristics, demands research in its scheduling and timing analysis. Different from the classic preemptive model, in a P-FRP system, when a task is preempted, all changes made by the task are discarded and after higher priority tasks complete their execution the preempted task will restart from the beginning (abort-and-restart). P-FRP is thus able to capture changes of the task in time and provides an option other than the classic preemptive model in certain scenarios. In the P-FRP model, previous studies use the largest execution time of a task for all its restarted jobs. In practice, however, when considering the changing/unchanging inputs/outputs of the task or the memory effects such as cache-hit in loading code and data, the restarted jobs likely consume less time than its largest execution time. In this paper, for the first time we present a multi-mode P-FRP task framework and two particular scenarios for the framework that are able to reflect such effects and then improve the performance of a developing commercial software platform. We show that the multi-mode task P-FRP system has significant schedulability improvements over the original P-FRP model. © 2017 IEEE.","Multi-mode Task; P-FRP; Real-time Scheduling","Computer programming; Distributed computer systems; Functional programming; Robot programming; User interfaces; Commercial software; Functional reactive programming; Interactive animations; Multimodes; Real - time scheduling; Real time characteristics; Task-scheduling; Timing Analysis; Scheduling",2-s2.0-85026751626
"Neog D.R., Ranjan A., Pai D.K.","Seeing Skin in Reduced Coordinates",2017,"Proceedings - 12th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2017 - 1st International Workshop on Adaptive Shot Learning for Gesture Understanding and Production, ASL4GUP 2017, Biometrics in the Wild, Bwild 2017, Heterogeneous Face Recognition, HFR 2017, Joint Challenge on Dominant and Complementary Emotion Recognition Using Micro Emotion Features and Head-Pose Estimation, DCER and HPE 2017 and 3rd Facial Expression Recognition and Analysis Challenge, FERA 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026288858&doi=10.1109%2fFG.2017.65&partnerID=40&md5=4d86e62504d91d3dbd3598200d52f8a9","We present a skin tracking and reconstruction method that uses a monocular camera and a depth sensor to recover skin sliding motions on the surface of a deforming object. Such depth cameras are widely available. Our key idea is to use a reduced coordinate framework that implicitly constrains skin to conform to the shape of the underlying object when it slides. The skin configuration in 3D can then be efficiently reconstructed by tracking two dimensional skin features in video. This representation is well suited for tracking subtle skin movements in the upper face and on the hand. The reconstructed skin motions have many uses, including synthesizing and retargeting animations, recognizing facial expressions, and for learning datadriven models of skin movement. In our face tracking examples, we recover subtle but important details of skin movement around the eyes. We validated the algorithm using a hand gesture sequence with known skin motion, recovering skin sliding motion with a low reconstruction error. © 2017 IEEE.",,"Cameras; Education; Eye movements; Gesture recognition; Human computer interaction; Recovery; Three dimensional computer graphics; Data-driven model; Deforming objects; Facial Expressions; Monocular cameras; Reconstruction error; Reconstruction method; Skin tracking; Sliding motions; Face recognition",2-s2.0-85026288858
"Gao Y., Li S., Qin H., Hao A.","A novel fluid-solid coupling framework integrating FLIP and shape matching methods",2017,"ACM International Conference Proceeding Series",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025478672&doi=10.1145%2f3095140.3095151&partnerID=40&md5=166cd4c1fc9c23d126fef91512b7ec74","Physically-based fluid animation and solid deformation driven by numerical simulation have manifested their significance for many graphics applications during the past two decades. For example, the fluid implicit particle (FLIP) method and shape matching technique based on position based dynamics (PBD) have demonstrated their unique graphics strength in fluid and solid animation, respectively. We propose a novel integrated approach supporting the seamless unification of FLIP and shape matching. We devise new algorithms to tackle existing difficulties when handling new phenomena such as high-fidelity fluid-solid interaction and solid melting. The key innovation of this paper is a unified Lagrangian framework that seamlessly blends FLIP and PBD based shape matching constraint towards the natural yet strong coupling between fluid and deformable solid. Within our integrated framework, it enables many complicated fluid-solid phenomena with ease. We conduct various kinds of experiments. All the results demonstrate the advantages of our unified hybrid approach towards visual fidelity, efficiency, stability, and versatility. © 2017 ACM.","FLIP; Position based dynamics; Shape matching; Solid deformation","Animation; Budget control; Deformation; FLIP; Fluid solid interaction; Graphics applications; Integrated frameworks; Lagrangian frameworks; Physically based fluid animation; Shape matching; Solid deformation; Computer graphics",2-s2.0-85025478672
"Shirota Y., Hashimoto T., Chakraborty B.","Visualization challenge on time series statistical data",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025464766&doi=10.1145%2f3095140.3095152&partnerID=40&md5=bc544308cf0607dd8a9b90d2d6d2b284","It has been very significant to visualize time series big data. In the paper we shall discuss design on time series statistical data. As an example, we present an animation of Gibbs sampling process to clarify the time changes. Gibbs sampling is widely used MCMC algorithm in the deep learning field. We consider that an additional z-axis coordinate or a time line are helpful for the visualization and the functions could be implemented automatically by some kind ofchart-wizards. We shall discuss the design rules and tips on visualization of time series data. © 2017 ACM.","Bayesian inference; Gibbs sampler; MCMC; Shape analysis; Simple topic model; Visualization","Bayesian networks; Big data; Computer graphics; Deep learning; Flow visualization; Inference engines; Statistics; Time series; Visualization; Bayesian inference; Gibbs samplers; MCMC; Shape analysis; Topic Modeling; Data visualization",2-s2.0-85025464766
"Ishida Y., Itoh T.","A force-directed visualization of conversation logs",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025480803&doi=10.1145%2f3095140.3095156&partnerID=40&md5=b5463e312f4f508884212cc859fe0c8a","We1 often want to track back the conversation logs, such as meeting or group chats which users were late to participate, and timelines of social network services. It often happens to be difficult to find important remarks if the logs are very long. Micro-blogs (e.g. Twitter) is a typical example. We often miss to find important remarks if we have large number of followers. Also, it often happens that many topics are mixed in a single timeline; this situation may also make us difficult to find important remarks. This paper presents a visualization tool which briefly displays the flow of conversations. This tool provides animations of flow of topics and speakers/writers applying a force-directed visualization technique. © 2017 ACM.","Conversation log; Force-directed visualization; Micro-blog (e.g. Twitter)","Computer graphics; Social networking (online); Conversation log; Force-Directed; Micro-blog; Social network services; Visualization technique; Visualization tools; Visualization",2-s2.0-85025480803
"Quweider M.K., Khan F.","Visualization as effective instructional and learning tools in the computer science curriculum",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030563081&partnerID=40&md5=f3e8ade3b42ee6836b5137b93282a86e","Visualization (the use of images, diagrams, presentations, animations, gaming, and video) represents a potentially effective aid in teaching and learning, especially in the STEM (Science, Technology, Engineering, and Mathematics) fields where abstract complex ideas and concepts are abound. Educators, especially in academia, are always searching for effective pedagogical methodologies to use in the classroom to enhance students' understanding and retention of key concepts of the subject area they are teaching. With the rapid advancements in software, hardware, networking, computing and storage technologies, including laptops, tablets, smartphones, cloud and distributed computing, the use of multimedia as an effective tool and aid in the classroom has become a standard procedure, rendering obsolete the traditional pure ""chalk and talk."" The next natural step to take is to enhance the presented course content through effective multimedia techniques. Of those techniques, visualization and animation have the most potential to revolutionize the way students learn and understand complex concepts that usually arise in the STEM fields, as they inherently appeal to our highly developed and specialized visual system that effortlessly identifies patterns, trends, and outliers. Our paper presents a set of student-developed visualizations in strategically selected CS courses that enabled them to learn STEM related concepts in general (such as limits, differentiation, integration, and projectiles to name a few), and CS concepts/algorithms in particular. In creating these visualizations, the professors and the graduate assistants focused on incorporating into them a set of overarching themes that are effective and can be expanded to other fields. The themes were inspired by findings from a leading NSF Cutting Edge grant on teaching with visualization in a closely related field, although not one in STEM. The visualizations created were clear and simple; they are built on top of proven educational activities that were used in the past; the students' feedback was a central component as the visualizations were built step by step; the visualizations defined the pre-conditions before which a student can watch or run them, so that context is welldefined and not lost; and finally, the visualizations were organized to reflect the mental organization that the student is creating. The paper gives details about the visualization algorithms, the criteria for their selection and inclusion in the curriculum, the students' immediate feedback, and survey results, taken by the students, that contrast the traditional ways of teaching CS and STEM concepts vs. The additional use of the developed visualizations. Our survey results shed light on whether visualizations make good tools for teaching, and if they have an effect on the rate (how quickly) of learning. Conclusions and recommendations are also presented. © American Society for Engineering Education, 2017.","Analysis of algorithms; Animation; Computer vision.; CS education; Gaming; Software engineering; STEM (Science, technology, engineering, and mathematics) fields; Visualization",,2-s2.0-85030563081
"Mohammed A., Babatunde A.O.","Modelling heavy metals transformation in vertical flow constructed wetlands",2017,"Ecological Modelling",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016415499&doi=10.1016%2fj.ecolmodel.2017.03.012&partnerID=40&md5=feb6a879d82ee17e508f453bdb6cf9f7","Constructed wetlands are dynamic ecosystems for which we generally have poor predictive capabilities of the succession relationships between the interdependent components and the processes. In this study, a dynamic simulation model that can evaluate the transport and fate of heavy metals in vertical flow constructed wetland systems was developed using a dynamic software program: Structural Thinking Experiential Learning Laboratory with Animation (STELLA) v9.0.2. The key heavy metals transformation processes considered in the study were adsorption and plant uptake; whilst the forcing functions considered were wastewater volume, temperature, heavy metals concentration, contact time, flow rate and adsorbent media. The model results indicate that up to 89%, 91% and 91% of Pb, Cr and Cd respectively, can be removed through adsorption process; whereas uptake by plants was 6%, 5.1% and 5.2% based on mass balance calculations. Sensitivity analysis also showed that the most sensitive areas in the model coincide with the adsorption parameter (the heterogeneity factor (n) and the Freundlich constant (Kf)). The results obtained indicates that the model can be used to simulate outflow heavy metal concentrations, and it can also be used to estimate the amount of heavy metal removed by individual processes in the system. © 2017","Constructed wetland; Ferric sludge; Heavy metals; STELLA","Adsorbents; Adsorption; Computer software; Heavy metals; Lead; Sensitivity analysis; Structural metals; Constructed wetlands; Ferric sludge; Heavy metal concentration; Inter-dependent components; Mass-balance calculations; Predictive capabilities; STELLA; Vertical flow constructed wetlands; Wetlands; adsorption; concentration (composition); constructed wetland; heavy metal; hydrological modeling; pollutant removal; pollutant transport; sensitivity analysis; sludge; software; transformation",2-s2.0-85016415499
"Zhang Y., Probst D.K.","Thinking and understanding from writing",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030544417&partnerID=40&md5=7a6ddf4bb89be4265e04359149aa59cb","Many concepts in physics and engineering courses cannot be understood easily. Although powerful computers with advanced software can generate fancy animations, students still cannot grasp these concepts without spending time reflecting on them. In the past, homework was the tool used by instructors to challenge students and enforce their learning. Unfortunately, now many students can bypass this challenge and directly go to the solution manual for answers, which is widely available from the internet. One way to nudge students reflecting on the concepts and theories is writing a weekly summary. Unlike the homework, the summary cannot be copied from other sources easily. We asked students to submit their summary through Turnitin, an effective plagiarism check software. When they submit their summaries, they can see by themselves how much percent is plagiarized, which will deter them from the practice of copy and paste. The effectiveness of this approach was assessed in two different ways. The first assessment was a direct questionnaire, and most students considered it very helpful for them to understand the concepts and theories in writing the summaries. The second assessment was a concept inventory test, which was part of the final exam. The test result demonstrated that there was a strong correlation between the scores of the two sections on conceptual questions and problem solving. © American Society for Engineering Education, 2017.",,,2-s2.0-85030544417
"Kade D., Lindell R., Ürey H., Özcan O.","Supporting motion capture acting through a mixed reality application",2017,"Optimizing Human-Computer Interaction With Emerging Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027712029&doi=10.4018%2f978-1-5225-2616-2.ch0010&partnerID=40&md5=7e562cbabd0d85ca7c4d8e8d7f045822","Current and future animations seek for more human-like motions to create believable animations for computer games, animated movies and commercial spots. A technology widely used technology is motion capture to capture actors' movements which enrich digital avatars motions and emotions. However, a motion capture environment poses challenges to actors such as short preparation times and the need to highly rely on their acting and imagination skills. To support these actors, we developed a mixed reality application that allows showing digital environments while performing and being able to see the real and virtual world. We tested our prototype with 6 traditionally trained theatre and TV actors. As a result, the actors indicated that our application supported them getting into the demanded acting moods with less unrequired emotions. The acting scenario was also better understood with less need of explanation than when just discussing the scenario, as commonly done in theatre acting. © 2018, IGI Global. All rights reserved.",,,2-s2.0-85027712029
"Yu J., Wang Z.-F.","A real-time 3D head mesh modeling and expressive articulatory animation system",2017,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023769046&doi=10.1109%2fICASSP.2017.7952696&partnerID=40&md5=7702dd626dc8f65cf57dee31c8bd69f7","In view of animated human computer interfaces, this paper proposes a 3D head mesh modeling and expressive articulatory animation system. The appearance mesh model is first reconstructed from multi-view visible images using inter-regional cooperative optimization and depth super-resolution, and the universal internal articulatory mesh is then integrated with the reconstructed appearance mesh by interpolation. After establishing the head mesh model, the anatomical and biomechanical characteristics of articulators are combined to synthesize articulatory animation. The evaluations demonstrate the system can build a realistic and vivid virtual head for animated interface in real-time. © 2017 IEEE.","articulatory animation; Head model reconstruction; image super-resolution; stereo matching",,2-s2.0-85023769046
"Santika W.G., Sudiartha I.K.G.","Persuasive technology with normative feedback to reduce energy consumption",2017,"PIC 2016 - Proceedings of the 2016 IEEE International Conference on Progress in Informatics and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024478227&doi=10.1109%2fPIC.2016.7949517&partnerID=40&md5=fda4827515d459a8e4ee14e9060986e2","The present study applies persuasive technology to promote energy conservation behaviour. The aim of the study is to investigate the role of descriptive norm in persuading air conditioner (AC) users to select higher room temperatures to save energy. We predicted that, when their natural propensity to mimic other behaviour was exploited, people would behave accordingly. An experiment was conducted and 102 students participated. They were randomly assigned into control, animation and normative groups. Participants in the normative group were given descriptive norm feedback displayed on a computer screen, whereas those in animation group were given negative social feedback, which was, in our previous study, found to be effective in persuading AC users to set higher temperatures. Results show that there was a significant effect of negative social and normative feedbacks on AC temperature setting. Participants in normative feedback group, having their natural predisposition to follow other behaviour triggered, set higher AC temperatures than those without any feedback. Participants in the animation (negative social) feedback group showed similar outcome, confirming previous study results. Implication of the finding is discussed in the discussion section. © 2016 IEEE.","Air conditioning; Descriptive norm; Energy conservation; Negative social feedback; Persuasive technology; Social influence","Air conditioning; Animation; Economic and social effects; Energy conservation; Energy utilization; Computer screens; Descriptive norms; Persuasive technology; Reduce energy consumption; Save energy; Social feedbacks; Social influence; Temperature setting; Feedback",2-s2.0-85024478227
"Wang Y., Luo S., Lu Y., Gong H., Zhou Y., Liu S., Hansen P.","AnimSkin: Fabricating epidermis with interactive, functional and aesthetic color animation",2017,"DIS 2017 - Proceedings of the 2017 ACM Conference on Designing Interactive Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023181868&doi=10.1145%2f3064663.3064687&partnerID=40&md5=96b009b95ad71273e84513a0af668ba2","Human epidermis, as the largest organ on body, has become a new design platform for wearable computing. The availability of miniature electronics makes more possibilities for on-skin designs. In this paper, we present AnimSkin, a thin-film interface, which will emit dynamic color animations directly on skin. This is done by using thermochromic material embedded with transparent electrode acting as a capacitive sensor. Moreover, an accessible and low-cost fabrication method is introduced. Individuals could also customize aesthetic graphic designs by following the detailed fabrication process to achieve personalized patterns. We propose four different dynamic types of color animation by applying certain voltage to the heating circuitry. With two examples, Email Reminder and Light Control System, we demonstrate how AnimSkin can be integrated into everyday life, and specifically, we show how AnimSkin can benefit areas such as on-skin design, thin-film interface and beauty technology. © 2017 ACM.","Beauty technology; Color animation; Fabrication; Hybrid material; On-skin interfaces; Wearable computing","Animation; Availability; Capacitive sensors; Chromogenics; Color; Fabrication; Hybrid materials; Wearable computers; Wearable technology; Fabrication process; Light control systems; Low cost fabrication; Miniature electronics; Thermochromic materials; Thin film interfaces; Transparent electrode; Wearable computing; Interfaces (materials)",2-s2.0-85023181868
"Patil G.V., Deshpande S.L.","Distributed rendering system for 3D animations with Blender",2017,"2016 IEEE International Conference on Advances in Electronics, Communication and Computer Technology, ICAECCT 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021412777&doi=10.1109%2fICAECCT.2016.7942562&partnerID=40&md5=3b4ad5db2f575a13ddb757f27d103066","Photo realistic effects in a complex animation scene can be achieved using the process of rendering. Rendering is more time and cost consuming process as it involves pixel based light and camera effects that will be converted into actual photo realistic scenes. To upgrade quality of animated scenes up to the mark, rendering requires high end computational set up. Processing cost of rendering goes on increasing as the quality and efficiency required increases. Required computational set up includes high end computational resources which are not affordable to a small scale animator. So with the present work we here are going to provide a solution to this problem so that small scale animator also can have effective rendering at a low cost and better efficiency. We are going to provide a Blender based low cost distributed, efficient rendering set up. © 2016 IEEE.","Blender; Ray Tracing; Rendering","Animation; Blending; Costs; Efficiency; Image processing; Ray tracing; Three dimensional computer graphics; 3D animation; Blender; Computational resources; Distributed rendering; Photo-realistic; Processing costs; Rendering; Small scale; Rendering (computer graphics)",2-s2.0-85021412777
"Funke A., Geldreich K., Hubwieser P.","Analysis of scratch projects of an introductory programming course for primary school students",2017,"IEEE Global Engineering Education Conference, EDUCON",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023623971&doi=10.1109%2fEDUCON.2017.7943005&partnerID=40&md5=9d918c09901aff2b693eb62ed03a9b0f","Computer Science (CS) is increasingly entering the early levels of early childhood education, like primary school or even kindergarten. Therefore, it becomes more and more important to gain insight into which teaching methods and content would be appropriate for young students of primary levels. To investigate this, we have designed a specific three-day introductory programming course for 4th grade students (ages 9-10), which was taught four times up to now. Fifty-eight children (26 girls and 32 boys) participated in the courses from May to August 2016. At the end of the courses, the children have developed 127 Scratch projects during the course. The methodology and the results of the qualitative analysis are described in this paper. We discovered that the students created three different types of programs in particular: Stories, Animations, and Games. The level of understanding of the students, who programmed a Game, was mostly found to be advanced. Stories, on the other hand, reached only the two basic levels. Most of the students met the requirements we had set for the projects. © 2017 IEEE.","Computer science education; Primary education; Primary school; Programming; Scratch","Animation; Computer programming; Education; Education computing; Engineering education; Mathematical programming; Teaching; Computer Science Education; Early childhood educations; Introductory programming course; Primary education; Primary schools; Qualitative analysis; Scratch; Teaching methods; Students",2-s2.0-85023623971
"Delair R., Sojitra H., Patel K., Bhatt K., Gharia K., Mahajan R.","Text to Scene conversion for smart learning",2017,"2016 IEEE International Conference on Advances in Electronics, Communication and Computer Technology, ICAECCT 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021398767&doi=10.1109%2fICAECCT.2016.7942559&partnerID=40&md5=fdb84d14178b9a952e5322eed8e8e1f1","Text to Scene conversion system automatically converts the given natural language text in to its visual representation such as readymade image, composite scene or animation. Natural language is a language in which we, humans interact with each other. We have built a system which converts the natural language text into the composite scene. It basically converts the sentences with spatial relationships into virtual scene. It involves the natural language processing and 3D computer graphics techniques. System consists of two main modules: text processing module and graphics module. Text processing module plays an important role. It processes the text given by user and finds the objects to create the scene. Graphics module takes this information as input and generates scene by placing those objects in relative position. As students can understand the concepts easily with the visualization, we have proposed a system of text to scene conversion to visualize maths problems, which can be useful to understand the problem statement and solve it. Application of this system in education domain can be useful in developing efficient methodology. © 2016 IEEE.","Natural Language Processing; Spatial Relationships; Text to Scene conversion","Computer graphics; Education; Text processing; Three dimensional computer graphics; Visual languages; 3D computer graphics; Conversion systems; Natural language text; Problem statement; Relative positions; Spatial relationships; Text to scenes; Visual representations; Natural language processing systems",2-s2.0-85021398767
"Stojanova A., Stojkovikj N., Kocaleva M., Zlatanovska B., Martinovska-Bande C.","Application of VARK learning model on 'Data structures and algorithms' course",2017,"IEEE Global Engineering Education Conference, EDUCON",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023600312&doi=10.1109%2fEDUCON.2017.7942909&partnerID=40&md5=58b9cca5e22145bb9efc42d07e037a70","The process of learning and understanding can be different for each person. The teaching methods are particularly important for students to learn the curriculum, because not every student can learn the teaching material in the same way. Some students can easily learn if they listen the information, others use videos presentations and graphs for better learning and there are students who learn through practical examples. This paper presents VARK (Visual, Aural, Reading or Write and Kinesthetic) model as an effective learning style. The learning model is applied in the Data structures and algorithms course. Data Structure and Algorithms is a fundamental course in Computer Science, but many students find it difficult because it requires abstract thinking. For this reason, except traditional way of explaining (reading/listening), using visualization tool, watching videos and animations is very helpful. At the University 'Goce Delchev' teaching of the subject Data Structures and Algorithms contains: classroom lectures, classroom problem solving exercises and laboratory exercises. Classroom lectures are performed by using only listening and reading methods. On classroom problem solving exercises, students watch videos or animations that are some kind of Java applets or Flash elements that illustrate the basic operation in data structure. On laboratory exercises, students use programs for software visualization and have opportunity to write parts of code by their own. This way of combined learning increases overall study experience and improve student success. This method has significant positive effect on students. © 2017 IEEE.","Anmation; Courses; Learning; Learning styles; VARK; Visualization","Data structures; Education; Education computing; Engineering education; Flow visualization; Learning algorithms; Problem solving; Teaching; Visualization; Anmation; Courses; Learning; Learning Style; VARK; Students",2-s2.0-85023600312
"Sikos L.F.","3D Model Indexing in Videos for Content-Based Retrieval via X3D-Based Semantic Enrichment and Automated Reasoning",2017,"Proceedings - Web3D 2017: 22nd International Conference on 3D Web Technology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021837775&doi=10.1145%2f3055624.3075943&partnerID=40&md5=ec172873e749365934b08ee29d20d693","3D models play an important role in a wide range of applications from engineering to training, from visualization to entertainment. The formal representation of, and reasoning over, concepts and properties associated with 3D models can contribute to next-generation 3D scene understanding, classification, indexing, and retrieval via 3D characteristics as opposed to keywords of traditional retrieval methods. This paper introduces a novel 3D model indexing method with X3D-Alignment, with an emphasis on the representation, annotation, and efficient content-based retrieval of 3D models and their regions of interest from computer animations. © 2017 ACM.","3d semantics; Cgi; Content-based 3d model retrieval; Mpeg-7; Spatiotemporal reasoning; X3d","Animation; Content based retrieval; Indexing (of information); Information retrieval; Motion Picture Experts Group standards; Self organizing maps; Semantics; Web services; Automated reasoning; Computer animation; Content-based 3D model retrieval; Formal representations; Mpeg-7; Regions of interest; Semantic enrichment; Spatio-temporal reasoning; Three dimensional computer graphics",2-s2.0-85021837775
"Chou M., Liang K.-W., Tu M.-H., Wu S.-M.","Transmission line signal radiation pattern by near-field measurement",2017,"2017 International Conference on Electronics Packaging, ICEP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021440712&doi=10.23919%2fICEP.2017.7939366&partnerID=40&md5=52942e18740bb7eeb5b8637ea8a91dea","In recent years, the chip, clock rate and current density become smaller, higher and faster. Above all, that will course the 'Simultaneous Switching Noise' (SSN) more severe on the power or ground plane. This paper focuses on how to know the situation in the DUT when the SSN problem happen. So, this research find a way to create a animation with the time-varying magnetic field in the DUT by the near field measurement(EM-Isight) and the programing software (Labview). © 2017 Japan Institute of Electronics Packaging.","LabVIEW; Near-field measurement instrument; SSN","Electronics packaging; Clock rate; Ground planes; LabViEW; Near-field measurement; Signal radiation; Simultaneous switching noise; Time-varying magnetic fields; Computer programming languages",2-s2.0-85021440712
"Yan C., Wang L.-H., Li J., Li D.-X., Zhang M.","LBF based 3D regression for facial animation",2017,"Proceedings - 2016 International Conference on Virtual Reality and Visualization, ICVRV 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025432108&doi=10.1109%2fICVRV.2016.52&partnerID=40&md5=15dbd485db220068702dc76b58e46a11","This paper presents a system for performance-driven avatar animation by estimating facial pose and expression parameters from single image. In this system, a 3D shape prediction model is trained based on local binary feature (LBF) algorithm, which use random forest to extract image features and learns a linear regression model mapping these features to 3D shape. With the help of this model, the 3D positions of facial vertexes can be estimated from a web camera image. The facial pose and expression parameters can be calculated by solving an optimization problem that fitting a set of blend shapes models to these 3D vertexes. Experiments show that our system can estimate accurate facial parameters from single image and generate similar looking avatar animation. © 2016 IEEE.","Avatar animation; Face tracking; Facial performance; LBF regression","Animation; Decision trees; Face recognition; Linear regression; Optimization; Regression analysis; Three dimensional computer graphics; Virtual reality; Visualization; Binary features; Face Tracking; Facial animation; Facial performance; LBF regression; Linear regression models; Optimization problems; Performance-driven; Mapping",2-s2.0-85025432108
"Carvalho L., Marroquim R., Vital Brazil E.","DiLight: Digital light table – Inbetweening for 2D animations using guidelines",2017,"Computers and Graphics (Pergamon)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019110770&doi=10.1016%2fj.cag.2017.04.001&partnerID=40&md5=5831bd30f9e692c015b256528989f459","In traditional 2D animation several intermediate frames are drawn between two consecutive key frames. This process can be very time-consuming and tedious for the animator. In this paper we present a semi-automatic inbetweening method that is tightly coupled with the animation production pipeline. We exploit the fact that artists typically start with an outline of the drawing to help preview the illustration, and use these guidelines to improve the curve correspondence inference. The method is based on a two-level matching algorithm, where the first one finds correspondences between the guidelines, and the second one between the final art. This separation further aids the artist by using transformed guidelines and drawings from preceding frames to guide the creation of new ones, acting as a digital light table. We show the robustness of our method with a variety of animation examples, including sequences from animation books and professional animators. © 2017 Elsevier Ltd","2D animation; Inbetweening","Computer graphics; Human computer interaction; 2D animation; In-betweening; Key frames; Level matching; Production pipelines; Semi-automatics; Tightly-coupled; Animation",2-s2.0-85019110770
"Hu S., Zhang Z., Xie H., Igarashi T.","Data-driven modeling and animation of outdoor trees through interactive approach",2017,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018736868&doi=10.1007%2fs00371-017-1377-6&partnerID=40&md5=db1ade78554b9b225e0f6331c9e7bebd","Computer animation of trees has widespread applications in the fields of film production, video games and virtual reality. Physics-based methods are feasible solutions to achieve good approximations of tree movements. However, realistically animating a specific tree in the real world remains a challenge since physics-based methods rely on dynamic properties that are difficult to measure. In this paper, we present a low-cost interactive approach to model and animate outdoor trees from photographs and videos, which can be captured using a smartphone or handheld camera. An interactive editing approach is proposed to reconstruct detailed branches from photographs by considering an epipolar constraint. To track the motions of branches and leaves, a semi-automatic tracking method is presented to allow the user to interactively correct mis-tracked features. Then, the physical parameters of branches and leaves are estimated using a fast Fourier transform, and these properties are applied to a simplified physics-based model to generate animations of trees with various external forces. We compare the animation results with reference videos on several examples and demonstrate that our approach can achieve realistic tree animation. © 2017, Springer-Verlag Berlin Heidelberg.","Animation; Data-driven; Interactive; Modeling; Tree; Video","Computer games; Fast Fourier transforms; Forestry; Interactive computer graphics; Models; Photography; Trees (mathematics); Virtual reality; Data driven; Epipolar constraints; Interactive; Interactive approach; Physics-based methods; Physics-based modeling; Tree; Video; Animation",2-s2.0-85018736868
"Ismail M.E., Irwan Mahazir I., Othman H., Amiruddin M.H., Ariffin A.","The use of animation video in teaching to enhance the imagination and visualization of student in engineering drawing",2017,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021837691&doi=10.1088%2f1757-899X%2f203%2f1%2f012023&partnerID=40&md5=62a779a258807c42b526ff558550e04c","The rapid development of information technology today has given a new breath toward usage of computer in education. One of the increasingly popular nowadays is a multimedia technology that merges a variety of media such as text, graphics, animation, video and audio controlled by a computer. With this technology, a wide range of multimedia element can be developed to improve the quality of education. For that reason, this study aims to investigate the use of multimedia element based on animated video that was developed for Engineering Drawing subject according to the syllabus of Vocational College of Malaysia. The design for this study was a survey method using a quantitative approach and involved 30 respondents from Industrial Machining students. The instruments used in study is questionnaire with correlation coefficient value (0.83), calculated on Alpha-Cronbach. Data was collected and analyzed descriptive analyzed using SPSS. The study found that multimedia element for animation video was use significant have capable to increase imagination and visualization of student. The implications of this study provide information of use of multimedia element will student effect imagination and visualization. In general, these findings contribute to the formation of multimedia element of materials appropriate to enhance the quality of learning material for engineering drawing. © Published under licence by IOP Publishing Ltd.",,"Animation; Education; Machining; Multimedia systems; Students; Surveys; Visualization; Correlation coefficient; Engineering drawing; Industrial machining; Multimedia technologies; Quality of education; Quality of learning; Quantitative approach; Vocational colleges; Engineering education",2-s2.0-85021837691
"Jiang T., Qian K., Liu S., Wang J., Yang X., Zhang J.","Consistent as-similar-as-possible non-isometric surface registration",2017,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019132877&doi=10.1007%2fs00371-017-1390-9&partnerID=40&md5=8468d527068508e152fdf8464f7dcb91","Non-isometric surface registration, aiming to align two surfaces with different sizes and details, has been widely used in computer animation industry. Various existing surface registration approaches have been proposed for accurate template fitting; nevertheless, two challenges remain. One is how to avoid the mesh distortion and fold over of surfaces during transformation. The other is how to reduce the amount of landmarks that have to be specified manually. To tackle these challenges simultaneously, we propose a consistent as-similar-as-possible (CASAP) surface registration approach. With a novel defined energy, it not only achieves the consistent discretization for the surfaces to produce accurate result, but also requires a small number of landmarks with little user effort only. Besides, CASAP is constrained as-similar-as-possible so that angles of triangle meshes are preserved and local scales are allowed to change. Extensive experimental results have demonstrated the effectiveness of CASAP in comparison with the state-of-the-art approaches. © 2017, The Author(s).","As-Similar-As-Possible; Consistent; Non-Isometric; Surface Registration","Interfaces (computer); Software engineering; Computer animation; Consistent; Discretizations; Isometric surfaces; Non-Isometric; State-of-the-art approach; Surface registration; Template fittings; Animation",2-s2.0-85019132877
"Vaillant J., Bouyarmane K., Kheddar A.","Multi-character physical and behavioral interactions controller",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018904962&doi=10.1109%2fTVCG.2016.2542067&partnerID=40&md5=6da6dccffcc23f950080a5e57920d68e","We extend the quadratic program (QP)-based task-space character control approach - initially intended for individual character animation - to multiple characters interacting among each other or with mobile/articulated elements of the environment. The interactions between the characters can be either physical interactions, such as contacts that can be established or broken at will between them and for which the forces are subjected to Newton's third law, or behavioral interactions, such as collision avoidance and cooperation that naturally emerge to achieve collaborative tasks from high-level specifications. We take a systematic approach integrating all the equations of motions of the characters, objects, and articulated environment parts in a single QP formulation in order to embrace and solve the most general instance of the problem, where independent individual character controllers would fail to account for the inherent coupling of their respective motions through those physical and behavioral interactions. Various types of motions/behaviors are controlled with only the one single formulation that we propose, and some examples of the original motions the framework allows are presented in the accompanying video. © 1995-2012 IEEE.","and visualization; I.3 Computer graphics; I.3.7 three-dimensional graphics and realism; I.3.7.a animation; I.6 simulation; I.6.8 types of simulation; I.6.8.a animation; modeling","Animation; Computer graphics; Equations of motion; Models; Quadratic programming; Behavioral interactions; Character animation; Collaborative tasks; High level specification; I.6 simulation; I.6.8 types of simulation; Physical interactions; Three-dimensional graphics and realism; Three dimensional computer graphics",2-s2.0-85018904962
"Montesdeoca S.E., Seah H.S., Rall H.-M., Benvenuti D.","Art-directed watercolor stylization of 3D animations in real-time",2017,"Computers and Graphics (Pergamon)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017477245&doi=10.1016%2fj.cag.2017.03.002&partnerID=40&md5=e06cdbcf24f96606a3187399996117ce","This paper presents a direct stylization system to render 3D animated geometry as watercolor painted animation. Featuring low-level art-direction in real-time, our approach focuses on letting users paint custom stylization parameters in the 3D scene. These painted parameters drive watercolor effects in object-space, managing localized control and emulating the characteristic appearance of traditional watercolor. For this purpose, the parameters alter the object-space geometric representations and are rasterized, to coherently control and enhance further image-space effects. The watercolor effects are simulated through improved and novel algorithms to recreate hand tremors, pigment turbulence, color bleeding, edge darkening, paper distortion and granulation. All these represent essential characteristic effects of traditional watercolor. The proposed direct stylization system scales well with scene complexity, can be implemented in most rendering pipelines and can be adapted to simulate a wide range of watercolor looks. The simulation is compared to previous approaches and is evaluated through a user study, involving professional CG artists spending over 50 h stylizing their own assets and sharing their feedback about the watercolor stylization, the direct stylization system and their needs as artists using Non-photorealistic Rendering (NPR). © 2017 Elsevier Ltd","Direct stylization; Expressive rendering; NPR; Object-space; Real-time; Watercolor","Computer graphics; Rasterization; Direct stylization; Expressive rendering; Object space; Real time; Watercolor; Rendering (computer graphics)",2-s2.0-85017477245
"Michael N., Drakou M., Lanitis A.","Model-based generation of personalized full-body 3D avatars from uncalibrated multi-view photographs",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981501484&doi=10.1007%2fs11042-016-3808-1&partnerID=40&md5=adc002707be2e598dda8ee078f0c570f","According to a number of studies, the use of personalized avatars in virtual environments can enhance the immersion experience of users and the effectiveness of communication between different players. The benefits of using personalized avatars in conjunction with recent technological developments in Virtual Reality (VR) prompted an increasing demand for low-cost systems that are capable of fast and easy generation of personal avatars for use in VR applications. In this paper we present a novel model-based technique that is capable of generating personalized full-body 3D avatars from orthogonal photographs. The proposed method utilizes a statistical model of human 3D shape and a multi-view statistical 2D shape model of its corresponding silhouettes. Our technique is automatic, requiring minimal user intervention, and does not need a calibrated camera. Each component of our proposed technique is extensively evaluated and validated, in an attempt to test the geometric accuracy and identifiability of generated avatars. Furthermore, we demonstrate the use of the proposed method for generating and importing animation-ready avatars in collaborative VR environments. © 2016, Springer Science+Business Media New York.","3D body shape modeling; Animation-ready avatars; Collaborative virtual reality; Multi-view active shape model; Personalized avatars","Animation; Photography; Virtual reality; 3D body shape model; Active Shape Models; Collaborative virtual reality; Model based techniques; Orthogonal photograph; Personalized avatars; Statistical modeling; Technological development; Three dimensional computer graphics",2-s2.0-84981501484
"Hu P., Komura T., Holden D., Zhong Y.","Scanning and animating characters dressed in multiple-layer garments",2017,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019103510&doi=10.1007%2fs00371-017-1388-3&partnerID=40&md5=d79b9edd859041e938e417cfd58cd4ba","Despite the development of user-friendly interfaces for modeling garments and putting them onto characters, preparing a character dressed in multiple layers of garments can be very time-consuming and tedious. In this paper, we propose a novel scanning-based solution for modeling and animating characters wearing multiple layers of clothes. This is achieved by making use of real clothes and human bodies. We first scan the naked body of a subject by an RGBD camera, and a statistical body model is fit to the scanned data. This results in a skinned articulated model of the subject. The subject is then asked to put on one piece of garment after another, and the articulated body model dressed up to the previous step is fit to the newly scanned data. The new garment is segmented in a semi-automatic fashion and added as an additional layer to the multi-layer garment model. During runtime, the skinned character is controlled based on the motion capture data and the multi-layer garment model is controlled by blending the movements computed by physical simulation and linear blend skinning, such that the cloth preserves its shape while it shows realistic physical motion. We present results where the character is wearing multiple layers of garments including a shirt, coat and a skirt. Our framework can be useful for preparing and animating dressed characters for computer games and films. © 2017, Springer-Verlag Berlin Heidelberg.","3D scanning; Cloth animation; Dressed character","Animation; Blending; Computer games; 3D-scanning; Articulated body model; Articulated models; Cloth animation; Dressed character; Motion capture data; Physical simulation; User friendly interface; Scanning",2-s2.0-85019103510
"Latham K., Hurs W., Shone N., El Rhalibi A., Pan Z.","A case study on the advantages of 3D walkthroughs over photo stitching techniques",2017,"Proceedings - 2016 International Conference on Virtual Reality and Visualization, ICVRV 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025431537&doi=10.1109%2fICVRV.2016.68&partnerID=40&md5=146aef2de45d7d508395f14d97e1d023","Virtual tours and interactive walkthroughs enable a more in-depth platform for communicating information. Many current techniques employ the use of Photo Stitching to accomplish this. However, over the last decade advancements in computing power and the accessibility of game engines, meant that developing rich 3D content for virtual tours is more possible than ever before. As such, the purpose of this paper is to present a study into the advantages of developing an interactive 3D virtual tour of student facilities, using the Unreal Development 4 Game Engine, for educational establishments. The project aims to demonstrate a comparison between the use of Photo Stitching and 3D Modelled interactive walkthrough for developing rich visual environments. The research reveals that the approach in this paper can improve educational facilities prominence within universities, and contains many advantages over Photo Stitching techniques. © 2016 IEEE.","3D Modelling; Animation; Education; Virtual Tour","Animation; Computer games; Virtual reality; Visualization; 3D modelling; Computing power; Educational establishments; Interactive walkthrough; Stitching techniques; Virtual tour; Visual environments; Walkthroughs; Education",2-s2.0-85025431537
"Wackermannova M.A., Horky P., Amorim M.C.P., Fonseca P.J.","Computer-manipulated stimuli as a research tool in Mozambique tilapia Oreochromis mossambicus",2017,"Acta Ethologica",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026766965&doi=10.1007%2fs10211-017-0252-9&partnerID=40&md5=e45e4f4d4a8e6142d084a5bfbc0d13be","Multimodal communication is essential in social interactions in cichlid fish, including conspecifics’ recognition, agonistic interactions and courtship behaviour. Computer-manipulated image stimuli and sound playback offer powerful tools to assess the relative relevance of visual and acoustic stimuli in fish behavioural studies, but these techniques require validation for each taxon. The aim of the present study was to investigate whether Mozambique tilapia Oreochromis mossambicus responds to computer-manipulated visual stimuli and acoustic playback. Six experiments were conducted: computer animation playback, video playback, interaction with a mirror, presentation of a live male in a jar alone and combined with courting sound playback or with white noise playback. Individual agonistic interactions (lateral displays, up and down swimming, butting) and courting behaviours (tilting leading, digging) were tallied for each experiment. Our results suggest that non-interactive computer-manipulated visual stimuli is not a suitable tool in behavioural research with Mozambique tilapia. In contrast, interaction with a live male in a jar seems to remain the best visual research instrument inducing significant strong behavioural responses. Although none or only a few agonistic interactions were observed towards video playbacks or computer animations, such interactions significantly increased towards a male in jar and were modulated by courtship sound playback, suggesting the additional relevance of sound playback as a tool in behavioural research with Mozambique tilapia, including the study of multimodal signalling. © 2017, Springer-Verlag Berlin Heidelberg and ISPA.","Acoustic signals; Agonistic interactions; Courtship behaviour; Playback experiments; Visual stimuli",,2-s2.0-85026766965
"Hummel M., Jöckel L., Schäfer J., Hlawitschka M.W., Garth C.","Visualizing Probabilistic Multi-Phase Fluid Simulation Data using a Sampling Approach",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022184218&doi=10.1111%2fcgf.13203&partnerID=40&md5=b700d5caae4236f8a84dd6e8fe2ef9a9","Eulerian Method of Moment (MoM) solvers are gaining popularity for multi-phase CFD simulation involving bubbles or droplets in process engineering. Because the actual positions of bubbles are uncertain, the spatial distribution of bubbles is described by scalar fields of moments, which can be interpreted as probability density functions. Visualizing these simulation results and comparing them to physical experiments is challenging, because neither the shape nor the distribution of bubbles described by the moments lend themselves to visual interpretation. In this work, we describe a visualization approach that provides explicit instances of the bubble distribution and produces bubble geometry based on local flow properties. To facilitate animation, the instancing of the bubble distribution provides coherence over time by advancing bubbles between time steps and updating the distribution. Our approach provides an intuitive visualization and enables direct visual comparison of simulation results to physical experiments. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.8 [Computer Graphics]: Picture/Image Generation—Applications","Computational fluid dynamics; Computer graphics; Method of moments; Probability density function; Visualization; Bubble distributions; CFD simulations; Descriptors; Multiphase fluids; Physical experiments; Picture/image generation; Visual comparison; Visual interpretation; Probability distributions",2-s2.0-85022184218
"Helwig N.E., Sohre N.E., Ruprecht M.R., Guy S.J., Lyford-Pike S.","Dynamic properties of successful smiles",2017,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021694054&doi=10.1371%2fjournal.pone.0179708&partnerID=40&md5=b13905d6911cef0688088a9ab959fe0a","Facial expression of emotion is a foundational aspect of social interaction and nonverbal communication. In this study, we use a computer-animated 3D facial tool to investigate how dynamic properties of a smile are perceived. We created smile animations where we systematically manipulated the smile's angle, extent, dental show, and dynamic symmetry. Then we asked a diverse sample of 802 participants to rate the smiles in terms of their effectiveness, genuineness, pleasantness, and perceived emotional intent. We define a ""successful smile"" as one that is rated effective, genuine, and pleasant in the colloquial sense of these words. We found that a successful smile can be expressed via a variety of different spatiotemporal trajectories, involving an intricate balance of mouth angle, smile extent, and dental show combined with dynamic symmetry. These findings have broad applications in a variety of areas, such as facial reanimation surgery, rehabilitation, computer graphics, and psychology. © 2017 Helwig et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"computer graphics; facial expression; female; human; human tissue; major clinical study; male; mouth; psychology; rehabilitation; resuscitation; surgery; tooth; adolescent; adult; aged; emotion; facial expression; facial recognition; human relation; middle aged; perception; photostimulation; physiology; psychology; very elderly; young adult; Adolescent; Adult; Aged; Aged, 80 and over; Emotions; Facial Expression; Facial Recognition; Female; Humans; Interpersonal Relations; Male; Middle Aged; Photic Stimulation; Smiling; Social Perception; Young Adult",2-s2.0-85021694054
"Farber C.","Exploring how avatar control erodes the Uncanny Valley",2017,"International Journal of Technology, Knowledge and Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021016791&partnerID=40&md5=eb3e5f7c79de5b481b5d151c44bc871f","The effects of the Uncanny Valley Theory, created by roboticist Masahiro Mori, seems to apply to contemporary movie animation but not always in situations of realistic animated interaction design, such as realistic game environments with controllable avatars. The Uncanny Valley Theory, written in 1970, measures a person's comfort level with a robot that displays human-like visual qualities, sounds, and movements. His theory directly correlates with how people perceive computer generated humans on screen in movies (Mori 1970). Generally speaking, people feel more familiar with a robot, or animation, that acts like a human but does not look very human. In essence, the Theory examines how humans dislike images, animations, and robots that seem almost human, but not human enough-invoking emotions such as fear and repulsion-specifically with certain facial gestures and certain parts of the face exhibiting more eeriness than other. I hypothesize another way of thinking of the effects of the Uncanny Valley Theory as it relates to game-play by exploring the roles of ""sense of presence,"" flow and narrative when judging a game-experience where the uncanny features of an avatar or character may be diminished by game immersion. © 2016 Common Ground, Ross Farrelly, Eng Chew, All Rights Reserved.","Avatar hypothesis; Gaming; Uncanny valley; Virtual reality",,2-s2.0-85021016791
"Thirunarayanan I., Khetarpal K., Koppal S., Le Meur O., Shea J., Jain E.","Creating segments and effects on comics by clustering gaze data",2017,"ACM Transactions on Multimedia Computing, Communications and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022343718&doi=10.1145%2f3078836&partnerID=40&md5=92b69c84422b8806275be9ed72066a98","Traditional comics are increasingly being augmented with digital effects, such as recoloring, stereoscopy, and animation. An open question in this endeavor is identifying where in a comic panel the effects should be placed. We propose a fast, semi-automatic technique to identify effects-worthy segments in a comic panel by utilizing gaze locations as a proxy for the importance of a region. We take advantage of the fact that comic artists influence viewer gaze towards narrative important regions. By capturing gaze locations from multiple viewers, we can identify important regions and direct a computer vision segmentation algorithm to extract these segments. The challenge is that these gaze data are noisy and difficult to process. Our key contribution is to leverage a theoretical breakthrough in the computer networks community towards robust and meaningful clustering of gaze locations into semantic regions, without needing the user to specify the number of clusters. We present a method based on the concept of relative eigen quality that takes a scanned comic image and a set of gaze points and produces an image segmentation. We demonstrate a variety of effects such as defocus, recoloring, stereoscopy, and animations. We also investigate the use of artificially generated gaze locations from saliency models in place of actual gaze locations. © 2017 ACM.","Comics; Effects","Location; Semantics; Stereo image processing; Comic panels; Comics; Digital effects; Effects; Gaze point; Number of clusters; Segmentation algorithms; Semi-automatics; Image segmentation",2-s2.0-85022343718
"Taylor L.F., Macaskill A.C., Hunt M.J.","Realistic Free-Spins Features Increase Preference for Slot Machines",2017,"Journal of Gambling Studies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019751061&doi=10.1007%2fs10899-016-9630-x&partnerID=40&md5=8b0b358164e325d9c8bbce779e8049b5","Despite increasing research into how the structural characteristics of slot machines influence gambling behaviour there have been no experimental investigations into the effect of free-spins bonus features—a structural characteristic that is commonly central to the design of slot machines. This series of three experiments investigated the free-spins feature using slot machine simulations to determine whether participants allocate more wagers to a machine with free spins, and, which components of free-spins features drive this preference. In each experiment, participants were exposed to two computer-simulated slot machines—one with a free-spins feature or similar bonus feature and one without. Participants then completed a testing phase where they could freely switch between the two machines. In Experiment 1, participants did not prefer the machine with a simple free-spins feature. In Experiment 2 the free-spins feature incorporated additional elements such as sounds, animations, and an increased win frequency; participants preferred to gamble on this machine. The Experiment 3 “bonus feature” machine resembled the free spins machine in Experiment 2 except spins were not free; participants showed a clear preference for this machine also. These findings indicate that (1) free-spins features have a major influence over machine choice and (2) the “freeness” of the free-spins bonus features is not an important driver of preference, contrary to self-report and interview research with gamblers. © 2016, Springer Science+Business Media New York.","Bonus features; EGMs; Free spins; Gambling; Slot machines","driver; exposure; female; gambling; human; human experiment; interview; machine; male; self report; simulation; sound",2-s2.0-85019751061
"Macdonald S.","Jin Xi: Master of puppet animation",2017,"Journal of Chinese Cinemas",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019011744&doi=10.1080%2f17508061.2017.1322785&partnerID=40&md5=3e7a79b3013e62c6a03f484c6875bfcd","Puppet animation was one of the key forms of animation at Shanghai meishu dianying zhipianchang and would remain so until the late 1970s transition into television. One of the most important puppet animators at the studio, Jin Xi 靳夕, contributed to approximately 23 productions, including features, shorts, and a television series. Jin Xi's animation theory, partially derived from poetics, represents some of the most sophisticated discussion of animation in the Chinese language. The employment of three-dimensional volume, texture, lighting and space in puppet animation more closely resembles three-dimensional computer animation than other animation forms. Jin Xi's last film, Xiyue qitong/Saving Mother, 1984, is tacitly the first episode of a film based on a folk story about Chenxiang, a rebellious boy-god who travels through a series of adventures to save his mother, magically trapped beneath a mountain. Chenxiang references both the national style and the house style of an earlier SAFS character, Nezha. Jin Xi's episode is a complete, self-contained example of episodic storytelling that showcases miniature landscapes, superb use of stop-motion, well-rounded characterizations and, most significantly, a non-idealized, post-revolutionary hero-protagonist. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Chinese animated films; Jin Xi; puppet animation, Xiyue qitong; Shanghai Animation Film Studio; stop-motion",,2-s2.0-85019011744
"Li H.","An analysis of computer animation and its acceleration technique using physical technology",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020846138&partnerID=40&md5=0adb9ca988ba0c022268836ea65b57c3","To those animators, it is quite difficult to realize the smooth movement of objects by matching the spatial data points with continuous and smooth curves and planes in computer graphics. In this paper, the accelerated motion of curves and planes are controlled by simple manipulation of a set of control parameters or the real-time interaction between animators and the scenarios created by dynamic simulation. And all the objects discussed in this paper are with the forms of rigid links of trees linking at joints in this paper. Motion equations are expressed in the coordinate centering on the joint, and are to be resolved by effective timing-technique which is increased linearly with the growth of the number of links.","Acceleration technique; Computer animation; Physical technology","Computer graphics; Equations of motion; Accelerated motion; Acceleration technique; Computer animation; Control parameters; Real time interactions; Smooth curves; Smooth movement; Spatial data; Animation",2-s2.0-85020846138
"Jing X., Yu K.","Architecture course multimedia making based on animation presentation strategy",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020858814&partnerID=40&md5=4a13d3d9abb3c49d626863e5ee85b91d","With the rapid development of multimedia, computer-aided instruction has existed universally. Animation presentation is widely applied due to its vivid and visual expression mode. This paper studied three modes of animation presentation strategy, i.e. strategy of controlling animation subsection presentation, strategy of controlling study pace by learners, and meta-cognitive monitoring prompt strategy. Besides, this paper expounded the application of different animation presentation strategies in architecture course and the effects. Meanwhile, experimental data verified the significant role of this method in improving learning effect, its good research value and application prospect.","Animation presentation strategy; Architecture course; Computer-assisted instruction; Teaching effect","Animation; Cognitive systems; Curricula; Teaching; Application prospect; Computer Assisted Instruction; Good research; Improving learning; Metacognitives; Presentation strategies; Teaching effects; Computer aided instruction",2-s2.0-85020858814
"Wang Y.","The design of 3D animation rendering system based on cloud computing",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020871445&partnerID=40&md5=e9fdd94296e4423c7509536ca84c7948","The animation rendering time can be greatly reduced and the rendering effects can be improved when cloud computing is applied in a 3D animation rendering system. In view of this, this paper starts from the previous studies of Chinese researchers regarding cloud computing and 3D animation rendering system, and elaborates the relevant theories of cloud computing and cloud rendering, as well as the key technologies in cloud computing-based rendering. A cloud computing-based 3D animation rendering system is designed including its basic framework and workflow. Hopefully the 3D animation rendering system may make full use of the advantages of cloud computing, reduce the rendering time and cost, and improve rendering effects.","3D animation; Cloud computing; Cloud rendering; Design; Rendering system","Animation; Cloud computing; Computation theory; Design; Three dimensional computer graphics; 3D animation; Cloud rendering; Key technologies; Rendering system; Rendering time; Distributed computer systems",2-s2.0-85020871445
"Song J., Blanco i Ribera R., Cho K., You M., Lewis J.P., Choi B., Noh J.","Sparse Rig Parameter Optimization for Character Animation",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019759222&doi=10.1111%2fcgf.13109&partnerID=40&md5=e3a36d9777ca503268739aa5b18cecbe","We propose a novel motion retargeting method that efficiently estimates artist-friendly rig space parameters. Inspired by the workflow typically observed in keyframe animation, our approach transfers a source motion into a production friendly character rig by optimizing the rig space parameters while balancing the considerations of fidelity to the source motion and the ease of subsequent editing. We propose the use of an intermediate object to transfer both the skeletal motion and the mesh deformation. The target rig-space parameters are then optimized to minimize the error between the motion of an intermediate object and the target character. The optimization uses a set of artist defined weights to modulate the effect of the different rig space parameters over time. Sparsity inducing regularizers and keyframe extraction streamline any additional editing processes. The results obtained with different types of character rigs demonstrate the versatility of our method and its effectiveness in simplifying any necessary manual editing within the production pipeline. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); [Computer Graphics]: Three-Dimensional Graphics as Realism—Animation","Computer graphics; Three dimensional computer graphics; Character animation; Descriptors; Key-frame extraction; Mesh deformation; Motion retargeting; Parameter optimization; Production pipelines; Three-dimensional graphics; Animation",2-s2.0-85019759222
"Zhang S., Kong F., Li C., Wang C., Qin H.","Hybrid modeling of multiphysical processes for particle-based volcano animation",2017,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018979495&doi=10.1002%2fcav.1758&partnerID=40&md5=dce5f75ccc3a62943039dd7c54bff580","Many complex natural phenomena with dramatic spatial and temporal variation are difficult to animate accurately with anticipated performance in many graphics tasks and applications, because oftentimes in prior art, a single type of physical process could not afford high fidelity and effective scene production. Volcano eruption and its subsequent interaction with earth is one such complicated phenomenon that must depend on multiphysical processes and their tight coupling. This paper documents a novel and effective particle-based solution for volcano animation that embraces multiphysical processes and their tight unification. First, we introduce a governing physical model consisting of multiphysical processes enabling flexible state transition among solid, fluid, and gas. This computational physics model is dictated by temperature and accommodates dynamic viscosity that is changing according to the temperature. Second, we propose an augmented smoothed particle hydrodynamics as the underlying numerical model to simulate the behavior of lava and smoke with several required physical attributes. Third, multiphysical quantities are tightly coupled to support the interaction with surroundings including fluid–solid coupling, ground friction, and lava–smoke coupling. We also develop a temperature-directed rendering technique with nearly no extra computational cost and demonstrate realistic graphics effects of volcano eruption and its interaction with earth with visual appeal. Copyright © 2017 John Wiley & Sons, Ltd.","heat transfer, multiphysical interaction and coupling, multiphysical processes, volcano animation","Animation; Computer graphics; Heat transfer; Hydrodynamics; Computational costs; Computational physics model; Dynamic viscosities; Fluid-solid coupling; Natural phenomena; Smoothed particle hydrodynamics; Spatial and temporal variation; Volcano eruptions; Volcanoes",2-s2.0-85018979495
"Goff E.E., Reindl K.M., Johnson C., McClean P., Offerdahl E.G., Schroeder N.L., White A.R.","Variation in external representations as part of the classroom lecture:An investigation of virtual cell animations in introductory photosynthesis instruction*",2017,"Biochemistry and Molecular Biology Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007489189&doi=10.1002%2fbmb.21032&partnerID=40&md5=04948fb46c5dedaacaedb491472a29de","The use of external representations (ERs) to introduce concepts in undergraduate biology has become increasingly common. Two of the most prevalent are static images and dynamic animations. While previous studies comparing static images and dynamic animations have resulted in somewhat conflicting findings in regards to learning outcomes, the benefits of each have been shown individually. Using ERs developed by the Virtual Cell Animation project, we aim to further investigate student learning using different ERs as part of an introductory biology lecture. We focus our study on the topic of photosynthesis as reports have noted that students struggle with a number of basic photosynthesis concepts. Students (n = 167) in ten sections of introductory biology laboratory were introduced to photosynthesis concepts by instructional lectures differing only in the format of the embedded ERs. Normalized gain scores were calculated, showing that students who learned with dynamic animations outperformed students who learned from static images on the posttest. The results of this study provide possible instructional guidelines for those delivering photosynthesis instruction in the introductory biology classroom. © 2016 by The International Union of Biochemistry and Molecular Biology, 45(3):226–234, 2017. © 2016 The International Union of Biochemistry and Molecular Biology","Animation; external representations; introductory biology; photosynthesis","audiovisual aid; cell function; computer graphics; controlled study; education; female; human; male; molecular biology; photosynthesis; physiology; procedures; randomized controlled trial; student; teaching; Audiovisual Aids; Cell Physiological Phenomena; Computer Graphics; Computer-Assisted Instruction; Female; Humans; Male; Molecular Biology; Photosynthesis; Students",2-s2.0-85007489189
"Kozlov Y., Bradley D., Bächer M., Thomaszewski B., Beeler T., Gross M.","Enriching Facial Blendshape Rigs with Physical Simulation",2017,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019659774&doi=10.1111%2fcgf.13108&partnerID=40&md5=631199d91f90907a6e8cbb16bd0e9cd2","Oftentimes facial animation is created separately from overall body motion. Since convincing facial animation is challenging enough in itself, artists tend to create and edit the face motion in isolation. Or if the face animation is derived from motion capture, this is typically performed in a mo-cap booth while sitting relatively still. In either case, recombining the isolated face animation with body and head motion is non-trivial and often results in an uncanny result if the body dynamics are not properly reflected on the face (e.g. the bouncing of facial tissue when running). We tackle this problem by introducing a simple and intuitive system that allows to add physics to facial blendshape animation. Unlike previous methods that try to add physics to face rigs, our method preserves the original facial animation as closely as possible. To this end, we present a novel simulation framework that uses the original animation as per-frame rest-poses without adding spurious forces. As a result, in the absence of any external forces or rigid head motion, the facial performance will exactly match the artist-created blendshape animation. In addition we propose the concept of blendmaterials to give artists an intuitive means to account for changing material properties due to muscle activation. This system allows to automatically combine facial animation and head motion such that they are consistent, while preserving the original animation as closely as possible. The system is easy to use and readily integrates with existing animation pipelines. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling–-Physically Based Modeling","Computational geometry; Computer graphics; Animation pipeline; Blendshape animation; Computational Geometry and Object Modeling; Descriptors; Facial animation; Muscle activation; Physical simulation; Simulation framework; Animation",2-s2.0-85019659774
"Vermeulen J.L., Hillebrand A., Geraerts R.","A comparative study of k-nearest neighbour techniques in crowd simulation",2017,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018586916&doi=10.1002%2fcav.1775&partnerID=40&md5=9fea370f95fb92ab67911b060c124e1e","The k-nearest neighbour (kNN) problem appears in many different fields of computer science, such as computer animation and robotics. In crowd simulation, kNN queries are typically used by a collision-avoidance method to prevent unnecessary computations. Many different methods for finding these neighbours exist, but it is unclear which will work best in crowd simulations, an application which is characterised by low dimensionality and frequent change of the data points. We therefore compare several data structures for performing kNN queries. We find that the nanoflann implementation of a k-d tree offers the best performance by far on many different scenarios, processing 100,000 agents in about 35 ms on a fast consumer PC. Copyright © 2017 John Wiley & Sons, Ltd.","comparative study; crowd simulation; nearest neighbours","Animation; Comparative studies; Computer animation; Crowd Simulation; Data points; K nearest neighbours (k-NN); K-nearest neighbours; Low dimensionality; Nearest neighbour; Nearest neighbor search",2-s2.0-85018586916
"Muzi S., Shi M., Han H.","Contour Extraction and Vectorization Algorithm for Paper-Cut Pattern",2017,"Proceedings - 4th International Conference on Applied Computing and Information Technology, 3rd International Conference on Computational Science/Intelligence and Applied Informatics, 1st International Conference on Big Data, Cloud Computing, Data Science and Engineering, ACIT-CSII-BCD 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020231444&doi=10.1109%2fACIT-CSII-BCD.2016.072&partnerID=40&md5=4e59f283e3aa51e90074c1237eac23ab","Based on the analysis of the types and characteristics of Chinese traditional paper-cut patterns, we propose a new algorithm for extracting and vectoring the patterns. On the contour extraction, the algorithm uses a grayscale, binary, contour tracking method. On the vectorization, we improved the segment Displaced curve segments so that you can make the final contour paper cutting pattern vector into a control point and a curve. Using this algorithm, we can quickly get the vector contour of the pattern of manual cutting. Further, we can carry on the processing, such as filling, deformation, combination, animation control, so as to complete the core function of the paper cutting animation software. The algorithm is also suitable for the extraction and the vector of common bitmap image, although the algorithm is put forward for the particularity of the paper cutting patterns. © 2016 IEEE.","Contour extraction; Displaced Subdivision Curve; Vector","Animation; Cloud computing; Cutting; Extraction; Three dimensional computer graphics; Vectors; Animation control; Animation softwares; Contour Extraction; Contour tracking; Core functions; Curve segments; Subdivision Curve; Vectorization algorithm; Big data",2-s2.0-85020231444
"Klaudiny M., McDonagh S., Bradley D., Beeler T., Mitchell K.","Real-Time Multi-View Facial Capture with Synthetic Training",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019704384&doi=10.1111%2fcgf.13129&partnerID=40&md5=484fa3a4c1dcf56e45999a503c27c5b0","We present a real-time multi-view facial capture system facilitated by synthetic training imagery. Our method is able to achieve high-quality markerless facial performance capture in real-time from multi-view helmet camera data, employing an actor specific regressor. The regressor training is tailored to specified actor appearance and we further condition it for the expected illumination conditions and the physical capture rig by generating the training data synthetically. In order to leverage the information present in live imagery, which is typically provided by multiple cameras, we propose a novel multi-view regression algorithm that uses multi-dimensional random ferns. We show that higher quality can be achieved by regressing on multiple video streams than previous approaches that were designed to operate on only a single view. Furthermore, we evaluate possible camera placements and propose a novel camera configuration that allows to mount cameras outside the field of view of the actor, which is very beneficial as the cameras are then less of a distraction for the actor and allow for an unobstructed line of sight to the director and other actors. Our new real-time facial capture approach has immediate application in on-set virtual production, in particular with the ever-growing demand for motion-captured facial animation in visual effects and video games. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation; I.4.8 [Computer Graphics]: Scene Analysis—Tracking","Animation; Cameras; Computer graphics; Video streaming; Camera configuration; Descriptors; I.3.7 [computer graphics]: three-dimensional graphics and realism; Illumination conditions; Multiple video streams; Performance capture; Regression algorithms; Scene analysis; Three dimensional computer graphics",2-s2.0-85019704384
"Dutra T.B., Marques R., Cavalcante-Neto J.B., Vidal C.A., Pettré J.","Gradient-based steering for vision-based crowd simulation algorithms",2017,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019652805&doi=10.1111%2fcgf.13130&partnerID=40&md5=d3a127a94361239749155081c9d1f3f4","Most recent crowd simulation algorithms equip agents with a synthetic vision component for steering. They offer promising perspectives through a more realistic simulation of the way humans navigate according to their perception of the surrounding environment. In this paper, we propose a new perception/motion loop to steering agents along collision free trajectories that significantly improves the quality of vision-based crowd simulators. In contrast with solutions where agents avoid collisions in a purely reactive (binary) way, we suggest exploring the full range of possible adaptations and retaining the locally optimal one. To this end, we introduce a cost function, based on perceptual variables, which estimates an agent's situation considering both the risks of future collision and a desired destination. We then compute the partial derivatives of that function with respect to all possible motion adaptations. The agent then adapts its motion by following the gradient. This paper has thus two main contributions: the definition of a general purpose control scheme for steering synthetic vision-based agents; and the proposition of cost functions for evaluating the perceived danger of the current situation. We demonstrate improvements in several cases. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation; I.6.5 [Simulation and Modeling]: Types of Simulation—Animation","Animation; Computer graphics; Cost benefit analysis; Cost functions; Collision-free trajectory; Current situation; Descriptors; I.3.7 [computer graphics]: three-dimensional graphics and realism; Partial derivatives; Realistic simulation; Simulation and modeling; Surrounding environment; Three dimensional computer graphics",2-s2.0-85019652805
"Hädrich T., Benes B., Deussen O., Pirk S.","Interactive Modeling and Authoring of Climbing Plants",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019746492&doi=10.1111%2fcgf.13106&partnerID=40&md5=81dbcdbc14a6d2f6da04564933fe68da","We present a novel system for the interactive modeling of developmental climbing plants with an emphasis on efficient control and plausible physics response. A plant is represented by a set of connected anisotropic particles that respond to the surrounding environment and to their inner state. Each particle stores biological and physical attributes that drive growth and plant adaptation to the environment such as light sensitivity, wind interaction, and physical obstacles. This representation allows for the efficient modeling of external effects that can be induced at any time without prior analysis of the plant structure. In our framework we exploit this representation to provide powerful editing capabilities that allow to edit a plant with respect to its structure and its environment while maintaining a biologically plausible appearance. Moreover, we couple plants with Lagrangian fluid dynamics and model advanced effects, such as the breaking and bending of branches. The user can thus interactively drag and prune branches or seed new plants in dynamically changing environments. Our system runs in real-time and supports up to 20 plant instances with 25k branches in parallel. The effectiveness of our approach is demonstrated through a number of interactive experiments, including modeling and animation of different species of climbing plants on complex support structures. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—; I.3.6 [Computer Graphics]: Methodology and Techniques–-Interaction Techniques; I.6.8 [Simulation and Modeling]: Types of Simulation—Visual","Computational geometry; Computer graphics; Anisotropic particles; Changing environment; Computational Geometry and Object Modeling; Descriptors; Interaction techniques; Modeling and animation; Simulation and modeling; Surrounding environment; Seed",2-s2.0-85019746492
"Radinschi I., Fratiman V., Ciocan V., Cazacu M.-M.","Interactive computer simulations for standing waves",2017,"Computer Applications in Engineering Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017478046&doi=10.1002%2fcae.21818&partnerID=40&md5=15e8151686636f0a0c3b8f5c25203f4a","Interactive computer simulations and learning environments like virtual laboratories come out as an excellent alternative to conventional physics laboratories. Two of the physics laboratories from the second semester within the Faculty of Civil Engineering and Building Services of “Gheorghe Asachi” Technical University are focused on the study of standing waves. Standing waves are very important in the field of Civil Engineering because the structural integrity of buildings can be affected by standing waves and the mechanical resonance phenomenon. A good understanding of the properties of standing waves will make the properly constructed structures withstand various risk factors. Some improperly constructed structures could damage or breakdown even in the presence of vibrations or strong winds. This paper presents the computer simulations developed for the study of the standing waves on a vibrating string and the propagation of electromagnetic standing waves in a Lecher system. For both simulations, the canvas element, part of HTML5 standard, is used to draw the graphics animations. Also, many control components and some external JavaScript libraries are used to perform the virtual applications. Further, these computer simulations are posted on the virtual physics laboratory web-site and thus, students are able to engage in more productive self or group activities. © 2017 Wiley Periodicals, Inc. Comput Appl Eng Educ 25:521–529, 2017; View this article online at wileyonlinelibrary.com/journal/cae; DOI 10.1002/cae.21818. © 2017 Wiley Periodicals, Inc.","Civil Engineering and Building Services; computer simulations; HTML5; JavaScript; standing waves","Computer aided instruction; Computer simulation; Digital libraries; High level languages; HTML; Laboratories; Building services; HTML5; Interactive computer simulations; Javascript; Learning environments; Physics laboratories; Standing wave; Technical universities; Elastic waves",2-s2.0-85017478046
"Meng W., Guo J., Bonaventura X., Sbert M., Zhang X.","Shape exploration of 3D heterogeneous models based on cages",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976336874&doi=10.1007%2fs11042-016-3642-5&partnerID=40&md5=a01ebca1480bb624acd19d342e7ecba0","Shape exploration of 3D heterogeneous models is essential for special effects in 3D animation and games. As heterogeneous models have different numbers of vertices and different topological structures,the mapping between source and target model may be ambiguous for deformation transfer. We propose a new framework for heterogeneous model shape exploration based on cages, which provides a feasible and fast solution to this open problem. Using a public cage as an intermediate medium, the deformation of the source models can be denoted as the position changing of the cage. When applying the cage change to the target model, rough deformation transfer can be achieved. After an optimization and interpolation to generate the explored shape of the heterogeneous target model, animation can be acquired. Our method is not only suitable for triangle meshes, but also for quadrilateral meshes or any other type of meshes. We demonstrate the validity of our scheme by a series of shape exploration experiments with different models. © 2016, Springer Science+Business Media New York.","Cage coordinates; Deformation transfer; Differential coordinates; Interpolation; Shape space","Animation; Deformation; Interpolation; Topology; Cage coordinates; Deformation transfer; Differential coordinates; Heterogeneous modeling; Heterogeneous models; Quadrilateral meshes; Shape space; Topological structure; Three dimensional computer graphics",2-s2.0-84976336874
"Yang J.","Design and practice of children's e-picture books based on the iPad",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020878172&partnerID=40&md5=0c75955db42a11e8c2b5ca704d4b2ac4","In recent years, children's electronic picture books in our country have achieved the great development, but they lack their own characteristics, so the innovation is poor. In order to better promote the develop the children's electronic picture books in China, based on the IOS platform, the APP application program that can be e used in the iPad system was developed. The application includes three parts: The animation design module, the main menu scene module and the sound design module. After the completion of the design of the corresponding picture, the compiler debugging, the unit testing and the functional testing were carried out for it. Through the test we can see that the system can run normally and meet the various functions of the application.","APP; Children; Electronic books; IPad","Developing countries; Hand held computers; Animation designs; Children; Design and practices; Electronic books; Electronic pictures; Functional testing; IPad; Various functions; Application programs",2-s2.0-85020878172
"Narang S., Best A., Feng A., Kang S.-H., Manocha D., Shapiro A.","Motion recognition of self and others on realistic 3D avatars",2017,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019836180&doi=10.1002%2fcav.1762&partnerID=40&md5=28d08c82b7b1de53cc0e6f298ba7a6f9","Current 3D capture and modeling technology can rapidly generate highly photo-realistic 3D avatars of human subjects. However, while the avatars look like their human counterparts, their movements often do not mimic their own due to existing challenges in accurate motion capture and retargeting. A better understanding of factors that influence the perception of biological motion would be valuable for creating virtual avatars that capture the essence of their human subjects. To investigate these issues, we captured 22 subjects walking in an open space. We then performed a study where participants were asked to identify their own motion in varying visual representations and scenarios. Similarly, participants were asked to identify the motion of familiar individuals. Unlike prior studies that used captured footage with simple “point-light” displays, we rendered the motion on photo-realistic 3D virtual avatars of the subject. We found that self-recognition was significantly higher for virtual avatars than with point-light representations. Users were more confident of their responses when identifying their motion presented on their virtual avatar. Recognition rates varied considerably between motion types for recognition of others, but not for self-recognition. Overall, our results are consistent with previous studies that used recorded footage and offer key insights into the perception of motion rendered on virtual avatars. Copyright © 2017 John Wiley & Sons, Ltd.","animation; avatar; gaint; perception; virtual reality","Animation; Sensory perception; Three dimensional computer graphics; Virtual reality; avatar; Biological motion; gaint; Modeling technology; Motion recognition; Photo-realistic; Self-recognition; Visual representations; Motion estimation",2-s2.0-85019836180
"Hu L., Bradley D., Li H., Beeler T.","Simulation-Ready Hair Capture",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019723303&doi=10.1111%2fcgf.13126&partnerID=40&md5=6a7703d14374792b276278280e9bc4a8","Physical simulation has long been the approach of choice for generating realistic hair animations in CG. A constant drawback of simulation, however, is the necessity to manually set the physical parameters of the simulation model in order to get the desired dynamic behavior. To alleviate this, researchers have begun to explore methods for reconstructing hair from the real world and even to estimate the corresponding simulation parameters through the process of inversion. So far, however, these methods have had limited applicability, because dynamic hair capture can only be played back without the ability to edit, and solving for simulation parameters can only be accomplished for static hairstyles, ignoring the dynamic behavior. We present the first method for capturing dynamic hair and automatically determining the physical properties for simulating the observed hairstyle in motion. Since our dynamic inversion is agnostic to the simulation model, the proposed method applies to virtually any hair simulation technique, which we demonstrate using two state-of-the-art hair simulation models. The output of our method is a fully simulation-ready hairstyle, consisting of both the static hair geometry as well as its physical properties. The hairstyle can be easily edited by adding additional external forces, changing the head motion, or re-simulating in completely different environments, all while remaining faithful to the captured hairstyle. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation","Computer graphics; Physical properties; Three dimensional computer graphics; Descriptors; Dynamic behaviors; Dynamic inversion; I.3.7 [computer graphics]: three-dimensional graphics and realism; Physical parameters; Physical simulation; Simulation model; Simulation parameters; Dynamics",2-s2.0-85019723303
"Ouyang Y., Paz J.O., Feng G., Read J.J., Adeli A., Jenkins J.N.","A Model to Estimate Hydrological Processes and Water Budget in an Irrigation Farm Pond",2017,"Water Resources Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028269526&doi=10.1007%2fs11269-017-1639-0&partnerID=40&md5=9205a103e08b2ee699e960aec16ca7fe","With increased interest to conserve groundwater resources without reducing crop yield potential, more on-farm water storage ponds have been constructed in recent years in USA and around the world. However, the hydrological processes, water budget, and environmental benefits and consequences of these ponds have not yet been fully quantified. This study developed a computer model to estimate farm pond hydrological processes and water budgets using the STELLA (Structural Thinking and Experiential Learning Laboratory with Animation) software. The model was applied, as demonstrations, to estimate the diurnal and seasonal pond hydrological processes and water budget at Metcalf Farm (33o 39′ 48″ N, 90o 39′ 12″W) in Porter Bayou Watershed located in Mississippi Delta, USA. Two simulation scenarios were chosen in this study, one without and the other with pumping pond water for soybeans irrigation. Simulations showed that the evaporative loss of water from the pond was minimal, while the runoff water from rainfall was a major source of water entering into the pond. Therefore, factors that would affect surface water runoff should be considered in locating and sizing a farm pond in Mississippi. The seasonal rainwater and runoff water collected by the pond was: winter &gt; spring &gt; summer &gt; fall, which corresponded well to the seasonal rainfall events; whereas seasonal order of pond evaporation was: summer &gt; spring &gt; fall &gt; winter, which corresponded well to the seasonal solar radiation and air temperature. The STELLA model developed proved to be a useful tool for estimating pond water budget and consequently irrigation practices for crops. © 2017, © Springer Science+Business Media Dordrecht (outside the USA).","Computer model; Conservation farming; Pond hydrology; Water budget","Budget control; Crops; Groundwater; Groundwater resources; Irrigation; Rain; Runoff; Surface waters; Computer modeling; Conservation farmings; Environmental benefits; Experiential learning; Hydrological process; Irrigation practices; Surface water runoff; Water budget; Lakes; computer simulation; hydrological modeling; irrigation system; numerical model; pond; rainfall; runoff; water budget; Louisiana; Mississippi Delta; United States; Glycine max",2-s2.0-85028269526
"Salamon N.Z., Lancelle M., Eisemann E.","Computational Light Painting Using a Virtual Exposure",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019656102&doi=10.1111%2fcgf.13101&partnerID=40&md5=8e5136d10578d4812cd2744b0e5ad988","Light painting is an artform where a light source is moved during a long-exposure shot, creating trails resembling a stroke on a canvas. It is very difficult to perform because the light source needs to be moved at the intended speed and along a precise trajectory. Additionally, images can be corrupted by the person moving the light. We propose computational light painting, which avoids such artifacts and is easy to use. Taking a video of the moving light as input, a virtual exposure allows us to draw the intended light positions in a post-process. We support animation, as well as 3D light sculpting, with high-quality results. © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.4 [Computer Graphics]: Graphics Utilities—Paint systems","Computer graphics; Descriptors; High quality; Long exposures; Paint systems; Post process; Light sources",2-s2.0-85019656102
"Kawatake S., Torii I., Ishii N.","Increasing Concentration with Neurofeedback",2017,"Proceedings - 4th International Conference on Applied Computing and Information Technology, 3rd International Conference on Computational Science/Intelligence and Applied Informatics, 1st International Conference on Big Data, Cloud Computing, Data Science and Engineering, ACIT-CSII-BCD 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020169935&doi=10.1109%2fACIT-CSII-BCD.2016.055&partnerID=40&md5=b2f73a6a8a2eb60c18f177c7cad99a07","Bio-signals as electroencephalography (EEG) has been studied extensively in clinical and cognitive neurosciences. Recently, neurofeedback(NFB) is discussed as a type of biofeedback that measures brain waves(EEG) to produce a signal that can be used as feedback to teach self-regulation(self-control) of brain function. The neurofeedback has drawn much attention as a self-control training for children with developmental disorder who show several body disorders, attention deficit and attention deficit-hyperactivity disorder (ADHD). In this paper, first, the neurofeedback studies for the ADHD are surveyed. Neurofeedback is commonly provided using video or sound. Second, the neurofeedback is studied from the human-computer interaction. We experimented by using several animation videos to make relaxed states in the brain. © 2016 IEEE.","Attention deficit; Attention deficit-hyperactivity disorder (ADHD); Electroencephalography (EEG); Neurofeedback","Biofeedback; Cloud computing; Diseases; Electroencephalography; Electrophysiology; Human computer interaction; Attention deficit; Attention deficit hyperactivity disorder; Brain functions; Cognitive neurosciences; Developmental disorders; Neurofeedback; Relaxed state; Self regulation; Big data",2-s2.0-85020169935
"Mahato N.K., Montuelle S., Goubeaux C., Cotton J., Williams S., Thomas J., Clark B.C.","Quantification of intervertebral displacement with a novel MRI-based modeling technique: Assessing measurement bias and reliability with a porcine spine model",2017,"Magnetic Resonance Imaging",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008655896&doi=10.1016%2fj.mri.2016.12.022&partnerID=40&md5=49c333303120788902b1f15f7a719f12","The purpose of this study was to develop a novel magnetic resonance imaging (MRI)-based modeling technique for measuring intervertebral displacements. Here, we present the measurement bias and reliability of the developmental work using a porcine spine model. Porcine lumbar vertebral segments were fitted in a custom-built apparatus placed within an externally calibrated imaging volume of an open-MRI scanner. The apparatus allowed movement of the vertebrae through pre-assigned magnitudes of sagittal and coronal translation and rotation. The induced displacements were imaged with static (T1) and fast dynamic (2D HYCE S) pulse sequences. These images were imported into animation software, in which these images formed a background ‘scene’. Three-dimensional models of vertebrae were created using static axial scans from the specimen and then transferred into the animation environment. In the animation environment, the user manually moved the models (rotoscoping) to perform model-to-‘scene’ matching to fit the models to their image silhouettes and assigned anatomical joint axes to the motion-segments. The animation protocol quantified the experimental translation and rotation displacements between the vertebral models. Accuracy of the technique was calculated as ‘bias’ using a linear mixed effects model, average percentage error and root mean square errors. Between-session reliability was examined by computing intra-class correlation coefficients (ICC) and the coefficient of variations (CV). For translation trials, a constant bias (β0) of 0.35 (± 0.11) mm was detected for the 2D HYCE S sequence (p = 0.01). The model did not demonstrate significant additional bias with each mm increase in experimental translation (β1Displacement = 0.01 mm; p = 0.69). Using the T1 sequence for the same assessments did not significantly change the bias (p &gt; 0.05). ICC values for the T1 and 2D HYCE S pulse sequences were 0.98 and 0.97, respectively. For rotation trials, a constant bias (β0) of 0.62 (± 0.12)° was detected for the 2D HYCE S sequence (p &lt; 0.01). The model also demonstrated an additional bias (β1Displacement) of 0.05° with each degree increase in the experimental rotation (p &lt; 0.01). Using T1 sequence for the same assessments did not significantly change the bias (p &gt; 0.05). ICC values for the T1 and 2D HYCE S pulse sequences were recorded 0.97 and 0.91, respectively. This novel quasi-static approach to quantifying intervertebral relationship demonstrates a reasonable degree of accuracy and reliability using the model-to-image matching technique with both static and dynamic sequences in a porcine model. Future work is required to explore multi-planar assessment of real-time spine motion and to examine the reliability of our approach in humans. © 2016 Elsevier Inc.","Back-pain; Biomechanics; MRI; Rotoscoping; Spine motion","adult; algorithm; animal tissue; Article; calibration; controlled study; image segmentation; intervertebral displacement; lumbar spine; measurement accuracy; model to image matching algorithm; nonhuman; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; pig; priority journal; quantitative analysis; reliability; software; spine instability; statistical bias; algorithm; animal; biomechanics; diagnostic imaging; equipment design; human; image processing; intervertebral disk; lumbar vertebra; motion; reproducibility; Algorithms; Animals; Biomechanical Phenomena; Calibration; Equipment Design; Humans; Image Processing, Computer-Assisted; Intervertebral Disc; Lumbar Vertebrae; Magnetic Resonance Imaging; Motion; Reproducibility of Results; Software; Swine",2-s2.0-85008655896
"Wang S., Wang H.-Y., Wu Y.-D., Wu B., Wu Y.-C.","Application of large-scale CFD flowfield visualization analysis system",2017,"Hangkong Dongli Xuebao/Journal of Aerospace Power",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027139299&doi=10.13224%2fj.cnki.jasp.2017.05.015&partnerID=40&md5=09066e0584639e913d0053171e663538","A new visualization system for large scale computational fluid dynamics(CFD)flowfield data, called flow field visualization analysis system or FVAS for short, was presented. FVAS has several complete and practical functions such as three dimensional steady and unsteady flow field data preprocessing and feature extraction, volume rendering, glyph (streamline, isosurface, etc) rendering, texture rendering and so on. Many different data analysis methods and favorable interactions were also supported in the system. FVAS could show the inner-outer flow structure characteristics and complicated physical phenomena with eight ways of demonstration, three kinds of display modes and five types of views. FVAS also implemented animation display function for time-varying data and multi-core parallel rendering. Such cases verify that our system is simple, useful, and strongly universal. A variety of mixed rendering technologies can effectively show the internal responses in flow field data such as combustor dataset, air inlet dataset. Interactions including section and subdivision can show local features and details in multiple views, and analysis tools like chart and graph can statistically analyze the information of special grid cell. 300 test cases were completed in our system test. Compared with the traditional CFD software, our system can promote more than 70% rendering efficiency. The system fault rate is 0.6%, transaction success rate is 100%, and it can effectively accelerate the analysis and statistical process of flow field data. © 2017, Editorial Department of Journal of Aerospace Power. All right reserved.","Flowfield visualization analysis system(FVAS); Glyph rendering; Multi-core parallel; Texture rendering; Visualization toolkit; Volume rendering","Computational fluid dynamics; Data visualization; Flow fields; Unsteady flow; Visualization; Volume rendering; Data analysis methods; Favorable interactions; Flowfield visualization; Glyph rendering; Multi-core parallels; Structure characteristic; Visualization system; Visualization toolkits; Three dimensional computer graphics",2-s2.0-85027139299
"Han X., Yu H., Yu Y., Zhang J.","A fast propagation scheme for approximate geodesic paths",2017,"Graphical Models",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014083693&doi=10.1016%2fj.gmod.2017.02.004&partnerID=40&md5=39dde275dc9b5f1140a3b4ccfbba20ec","Geodesic paths on surfaces are indispensable in many research and industrial areas, including architectural and aircraft design, human body animation, robotic path planning, terrain navigation, and reverse engineering. 3D models in these applications are typically large and complex. It is challenging for existing geodesic path algorithms to process large-scale models with millions of vertices. In this paper, we focus on the single-source geodesic path problem, and present a novel framework for efficient and approximate geodesic path computation over triangle meshes. The algorithm finds and propagates paths based on a continuous Dijkstra strategy with a two-stage approach to compute a path for each propagating step. Starting from an initial path for each step, its shape is firstly optimized by solving a sparse linear system and then the output floating path is projected to the surface to obtain the refined one for further propagation. We have extensively evaluated our algorithms on a number of 3D models and also compared their performance against existing algorithms. Such evaluation and comparisons indicate our algorithm is fast and produces acceptable accuracy. © 2017 Elsevier Inc.","Continuous Dijkstra strategy; Discrete geodesic computation; Fast Path Propagation","Air navigation; Fighter aircraft; Geodesy; Industrial research; Linear systems; Motion planning; Reverse engineering; Robot programming; Continuous Dijkstra; Discrete geodesic; Fast path; Industrial area; Large-scale models; Sparse linear systems; Terrain navigations; Two stage approach; Three dimensional computer graphics; accuracy assessment; algorithm; geodesy; optimization; robotics; three-dimensional modeling",2-s2.0-85014083693
"He X.","Transitivity of kinetic typography: theory and application to a case study of a public service advertisement",2017,"Visual Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018768587&doi=10.1177%2f1470357216684080&partnerID=40&md5=da64591e43c2dad6603f199313334a8d","With the advance of computer technology, kinetic typography, the animation of moving text, is becoming widely used in human communication. Yet, to date, there have been few social semiotic and multimodality studies in this area. This article draws on a case analysis of a national television public service advertisement in China to demonstrate how the concept of transitivity can be used to understand the meaning-making processes of kinetic typography. Kress and Van Leeuwen’s Reading Images: The Grammar of Visual Design (2006[1996]) transitivity of visual grammar and Leão’s ‘A systemic functional approach to the analysis of animation in film opening titles’ (2013) transitivity system of animation are applied in the analysis. The results show that their models can be basically applied to the analysis of kinetic typography. However, they also have restrictions that can be improved. For this reason, the author proposes an extended model of transitivity for the analysis of kinetic typography. The article ends with a discussion of some cross-cultural aspects of the analysed advertisement. © 2016, © The Author(s) 2016.","kinetic typography; meaning-making; public service advertisement; social semiotic multimodality; transitivity",,2-s2.0-85018768587
"Bhattarai B., Drabold D.A.","Amorphous carbon at low densities: An ab initio study",2017,"Carbon",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009990075&doi=10.1016%2fj.carbon.2017.01.031&partnerID=40&md5=e87e876e8acf7b1d16ca640ca988ba90","In this paper, we present new computer models of low-density amorphous carbon, and study the structural, electronic and vibrational properties all based upon plane-wave density functional methods. The static structure factor and real space pair-correlation function is in agreement with available experimental data. We observe chains of sp bonded carbon in the models, along with sp2 and sp3 structures in varying concentrations. These models provide atomistic insight into the microstructure of the system, delineating variation in bonding (sp2, sp3 and sp) preferences as a function of density. For these low densities, the vibrational density of states is computed for the first time, along with localization of modes and the specific heat with comparison to experiments. We contrast the amorphous three dimensional networks with amorphous graphene, which bears a striking similarity in the radial distribution functions, but shows a distinct signature in the vibrational density of states. The vibrational modes are analyzed and discussed, and animations of particularly interesting modes are provided as Supplementary Material. The modes are generally well extended, but are more complex than simple molecular pictures that are sometimes invoked, in some cases even revealing mixing among modes of different type. © 2017 Elsevier Ltd","Ab initio; Amorphous carbon; Low density; Phonons; Specific heat","Complex networks; Density functional theory; Distribution functions; Electronic properties; Phonons; Specific heat; Ab initio; Low density; Pair correlation functions; Radial distribution functions; Static structure factors; Three-dimensional networks; Vibrational density of state; Vibrational properties; Amorphous carbon",2-s2.0-85009990075
"Iqbal M.M., Saleem Y., Naseer K., Kim M.","Multimedia based student-teacher smart interaction framework using multi-agents in eLearning",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018317242&doi=10.1007%2fs11042-017-4615-z&partnerID=40&md5=13b4cd8ee92e8944c82a9d96469e7249","Multimedia content comprises the graphics, audio & video clips, animation and text to present learning materials in a style, which improves learner expectation in eLearning paradigm. Electronic learning gained the popularity due to its immense coverage of students and subjects all over the world. The aim of this study is enhancements using agent-based framework through multimedia data in eLearning paradigm. Analysis of multimedia contents and eLearning data are helpful for the course designers, teachers, and administrators of eLearning environments to hunt for undetected patterns and underlying data in learning processes. This research improves the learning curves for the students. It also needs to improve the overall processes in eLearning paradigm. Information and Communication Technologies supported education, and virtual classrooms environments are mandatory. In eLearning data is evolving day by day that includes the semi-structured data, unstructured data, and structured data which is also collectively marked as multimedia big data. Multimedia data has the potential to mining for the analytics and learning. The learning outcomes for the students are very important to find the facts that what impacts the input data on the student. There are 1108 students posted questions in online Learning Management System (LMS) and instructors reply these queries. Sensor data is also gathered by the mobile GPS to find the student location. The system has analyzed the relevance of the replied answers. The student satisfaction is achieved by providing the multimedia-based student-teacher interaction. This can lead to synchronous communication and multimedia content conversation in eLearning paradigm. Machine learning techniques are applied to that data to discover the patterns and behavioral trends. It can also be used in the eLearning environments for the teacher to assist and enhance the pedagogical skills and for student’s learning curve enhancements. © 2017 Springer Science+Business Media New York","eLearning; Machine learning; Multimedia application; Multimedia data; Text mining","Artificial intelligence; Big data; Computer aided instruction; Data mining; Education; Learning systems; Multi agent systems; Students; Teaching; E-learning environment; Information and Communication Technologies; Interaction framework; Machine learning techniques; Multimedia applications; Multimedia data; Synchronous communications; Text mining; E-learning",2-s2.0-85018317242
"Tan E.L., Heh D.Y.","Demonstration of electromagnetic polarization app on iPad",2017,"2017 IEEE International Conference on Computational Electromagnetics, ICCEM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019750703&doi=10.1109%2fCOMPEM.2017.7912849&partnerID=40&md5=11224ee96ba990520be89dd922022656","This paper presents the demonstration of electromagnetic (EM) polarization app on iPad. The app provides an interactive visualization to help students better understand EM polarization concepts. Electric field expressions comprising two orthogonal components are provided in both time domain form and phasor form. The parameters such as magnitude and phase of each component can be input and modified conveniently. Based on the input parameters, electric field vector animations are depicted to illustrate the type of polarization in real time. The overview and features of the app are described, along with examples of linear, circular and elliptical polarizations. © 2017 IEEE.",,"Electric fields; Hand held computers; Polarization; Visualization; Electric field vectors; Electromagnetic polarization; Elliptical polarization; Input parameter; Interactive visualizations; Orthogonal components; Real time; Time domain; Computational electromagnetics",2-s2.0-85019750703
"Gunanto S.G., Hariadi M., Yuniarno E.M.","Computer facial animation with synthesize marker on 3D faces surface",2017,"2016 2nd International Conference of Industrial, Mechanical, Electrical, and Chemical Engineering, ICIMECE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019437969&doi=10.1109%2fICIMECE.2016.7910452&partnerID=40&md5=ddbaf8868c56b1518acf049d8dd60582","An animated character has its own characteristics and behaviour. The animator needs to be skilled enough to make a complex animation, especially on making face expression. a Well defined facial expression can represent the emotional condition and make the animation more expressing the mood. But most facial animation is done by manually, frame-by-frame. It is very time-consuming. This research proposed a combination methods for handling the facial animation based on marker location and face surface from the 3D character. The motion data captured based on the location and movement of the marker then implemented on 3D face model to generate the motion guidance. As a guidance, this marker data role as a centroid of a vertex cluster. The cluster provided by implementing segmentation fp-NN Clustering method based on surface and can visualize the deformation using linear blend skinning methods. The result from this research shows that this system can automatically generate facial animations based on the marker data and the surface segmentation. The visualization of deformation arranges accordingly to the motion captured data and organized sequentially. © 2016 IEEE.","facial animation; feature marker; surface","Blending; Cluster analysis; Data visualization; Deformation; Surfaces; 3-D face modeling; Animated characters; Clustering methods; Combination method; Facial animation; Facial Expressions; feature marker; Surface segmentation; Animation",2-s2.0-85019437969
"McCarthy J.W., Boster J.B.","A comparison of the performance of 2.5 to 3.5-year-old children without disabilities using animated and cursor-based scanning in a contextual scene",2017,"Assistive Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018842611&doi=10.1080%2f10400435.2017.1307883&partnerID=40&md5=e3396997c211db0d7467cc36516dd1e5","Although recent evidence suggests learning demands for children can be reduced by organizing augmentative and alternative communication (AAC) displays in contextual scenes, there is little evidence on how such scenes could be made accessible for children who cannot use direct selection. Using a line drawn scene of a living room, a traditional traveling cursor (a green outline of objects within the scene) was compared with sequential animation—logically matching the function of items in the scene (e.g., hands of a clock moving, a lamp turning on and off, etc.). After three learning sessions, only the matched function animation condition revealed a significant increase in accuracy scores from session 1 to session 3. Age-related trends suggested the mean scores in the cursor-based condition were associated with older children consistently performing at high levels and younger children remaining at low levels, while trends in the animated group were associated with children learning the interface in a way not associated with age. Findings support that enhanced presentations of scanning can increase the transparency of the scanning interface for some children and suggest that contextual scene displays could benefit from animations and sound for children not using direct selection. © 2017 RESNA","augmentative and alternative communication; computer access; pediatrics; usability","Animation; Human rehabilitation engineering; Pediatrics; Age-related; Augmentative-and-alternative communication; Children learning; Computer access; Learning sessions; Living room; usability; Scanning",2-s2.0-85018842611
"Ren S., Zhou H., Li Z., Tao W.","Animation generating based on MRLS image deformation",2017,"Proceedings - 15th International Symposium on Parallel and Distributed Computing, ISPDC 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020314041&doi=10.1109%2fISPDC.2016.62&partnerID=40&md5=e165f9b63ff66f98747a6d74a3641966","Animation generating, which refers to generating a movie or animation according to one or more images, has a number of useful application ranging from movie effects to virtual reality. This paper proposes a novel animation generating method via MRLS image deformation and designs an animation system, which can generate a vividly animation from a static image by choosing set of point handles and deformation paths. Firstly, users need to choose a set of fixed control points and a distorted image deformation path. Then, construct deformation mapping functions according to the control points and the deformation path, and get a series of deformed images with the mapping function. Finally, users get the animation by packaging the deformed images into an AVI video files frame-by-frame. Experiment results show that the non-rigid deformation animations produced with our method are deformed smoothly, naturally and realistically. © 2016 IEEE.","Animation generating; Image deformation; Moving regularized least squares","Animation; Distributed computer systems; Mapping; Virtual reality; Animation systems; Deformation mapping; Distorted images; Generating methods; Image deformation; Mapping functions; Non-rigid deformation; Regularized least squares; Deformation",2-s2.0-85020314041
"Daher S., Kim K., Lee M., Bruder G., Schubert R., Bailenson J., Welch G.F.","Can social presence be contagious? Effects of social presence priming on interaction with Virtual Humans",2017,"2017 IEEE Symposium on 3D User Interfaces, 3DUI 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018982664&doi=10.1109%2f3DUI.2017.7893341&partnerID=40&md5=e71b6cd8c3e582ab3c49ebf50f282b68","This paper explores whether witnessing a Virtual Human (VH) in what appears to be a socially engaging discussion with another virtual human confederate/accomplice (VHC) can prime a person to feel and behave more socially engaged with the VH in a subsequent interaction. To explore this social priming phenomenon, we conducted an experiment in which participants in a control group had no priming while those in an experimental group were briefly exposed to an engaging social interaction between a VH and a nearby VHC. The participants primed by exposure to the brief VHC-VH interaction reported being significantly more excited and alert, perceiving the VH closer, and showed significantly higher measures of Co-Presence, Attentional Allocation, and Message Understanding dimensions of social presence towards the VH, compared to those who were not primed. © 2017 IEEE.","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial, Augmented, and Virtual Realities; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual reality; I.68 [Simulation and Modeling]: Types of Simulation - Animation; J.4 [Computer Applications]: Social and Behavioral Sciences - Psychology, Sociology","Behavioral research; Computer graphics; Social sciences; User interfaces; Virtual reality; Experimental groups; H.5.1 [Information interfaces and presentation]: Multimedia Information Systems Artificial , augmented , and virtual realities; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; J.4 [computer applications]: social and behavioral sciences - psychologies; Message understanding; Simulation and modeling; Social interactions; Social presence; Three dimensional computer graphics",2-s2.0-85018982664
"Barbulescu A., Garcia M., Begault A., Cani M.-P., Portaz M., Viand A., Dulery R., Boissieux L., Heinish P., Ronfard R., Vaufreydaz D.","A system for creating virtual reality content from make-believe games",2017,"Proceedings - IEEE Virtual Reality",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018438563&doi=10.1109%2fVR.2017.7892249&partnerID=40&md5=9f1ac82ac2137966595054050a56d726","Pretend play is a storytelling technique, naturally used from very young ages, which relies on object substitution to represent the characters of the imagined story. We propose a system which assists the storyteller by generating a virtualized story from a recorded dialogue performed with 3D printed figurines. We capture the gestures and facial expressions of the storyteller using Kinect cameras and IMU sensors and transfer them to their virtual counterparts in the story-world. As a proof-of-concept, we demonstrate our system with an improvised story involving a prince and a witch, which was successfully recorded and transferred into 3D animation. © 2017 IEEE.","I.3.7 [Computer graphics]: Three-Dimensional Graphics and Realism - Animation; I.3.7 [Computer graphics]: Three-dimensional graphics and realism - Virtual reality","3D printers; Animation; Computer graphics; Virtual reality; 3D animation; Facial Expressions; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Kinect cameras; Proof of concept; Three dimensional computer graphics",2-s2.0-85018438563
"Alwi E.I., Adji T.B., Sumaryono S.","Implementation and performance analysis of MPI cluster system in distributed rendering",2017,"Proceedings - CYBERNETICSCOM 2016: International Conference on Computational Intelligence and Cybernetics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018979843&doi=10.1109%2fCyberneticsCom.2016.7892575&partnerID=40&md5=5997419cb2f6f9c66f5f2bd178f9a35c","Graphic image is compulsory in delivering information and communication in this information technology era. Graphic applications are used widely to manipulate images in advertising industries and in animation movie productions. In order to manipulate numerous and complex images, it is required long period of time and high-performance computers. However, computers with high-performance specification are still very expensive these days. This condition triggers the development of distributed processing technique using the implementation of computer cluster which does not require very advanced specifications. A computer cluster is a computer system that employs many computers (PCs) which are connected within a computer network and work simultaneously in parallel for solving given computational processes. MPICH2 cluster system was implemented in cloud computing infrastructure in the laboratory. A performance analysis was conducted on how the system handle parallel distributed processes using POV-Ray software. The performance of the system was then tested, using execution time, efficiency rate, and speedup as the parameters. This research used 4 sample images tested in MPICH cluster system for rendering. After speedup and efficiency rate analyses were conducted, it is then possible to conclude that the produced average speedup is 2.68 and the average efficiency rate in rendering the four 3D images is 92%. Those results show that the cluster system of the distributed rendering is efficient in executing the computational processes. © 2016 IEEE.","Cloud Computing; Computer Cluster; Distributed rendering; MPICH2; Parallel computing","Artificial intelligence; Cloud computing; Cluster analysis; Cluster computing; Cybernetics; Efficiency; Parallel processing systems; Rendering (computer graphics); Specifications; Three dimensional computer graphics; Cloud computing infrastructures; Computer clusters; Distributed processing techniques; Distributed rendering; Information and communication; MPICH2; Parallel distributed process; Performance specifications; Distributed computer systems",2-s2.0-85018979843
"Nakayasu T., Yasugi M., Shiraishi S., Uchida S., Watanabe E.","Three-dimensional computer graphic animations for studying social approach behaviour in medaka fish: Effects of systematic manipulation of morphological and motion cues",2017,"PLoS ONE",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017518406&doi=10.1371%2fjournal.pone.0175059&partnerID=40&md5=f5cc8320d8960783d6af08b9e62bac51","We studied social approach behaviour in medaka fish using three-dimensional computer graphic (3DCG) animations based on the morphological features and motion characteristics obtained from real fish. This is the first study which used 3DCG animations and examined the relative effects of morphological and motion cues on social approach behaviour in medaka. Various visual stimuli, e.g., lack of motion, lack of colour, alternation in shape, lack of locomotion, lack of body motion, and normal virtual fish in which all four features (colour, shape, locomotion, and body motion) were reconstructed, were created and presented to fish using a computer display. Medaka fish presented with normal virtual fish spent a long time in proximity to the display, whereas time spent near the display was decreased in other groups when compared with normal virtual medaka group. The results suggested that the naturalness of visual cues contributes to the induction of social approach behaviour. Differential effects between body motion and locomotion were also detected. 3DCG animations can be a useful tool to study the mechanisms of visual processing and social behaviour in medaka. © 2017 Nakayasu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"body movement; human; locomotion; nonhuman; Oryzias; social behavior; stimulus; vision",2-s2.0-85017518406
"Li K., Yang J., Liu L., Boulic R., Lai Y.-K., Liu Y., Li Y., Molla E.","SPA: Sparse Photorealistic Animation Using a Single RGB-D Camera",2017,"IEEE Transactions on Circuits and Systems for Video Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018505909&doi=10.1109%2fTCSVT.2016.2556419&partnerID=40&md5=838cea981cc3a9c9baddb1ab74a75ef3","Photorealistic animation is a desirable technique for computer games and movie production. We propose a new method to synthesize plausible videos of human actors with new motions using a single cheap RGB-D camera. A small database is captured in a usual office environment, which happens only once for synthesizing different motions. We propose a marker-less performance capture method using sparse deformation to obtain the geometry and pose of the actor for each time instance in the database. Then, we synthesize an animation video of the actor performing the new motion that is defined by the user. An adaptive model-guided texture synthesis method based on weighted low-rank matrix completion is proposed to be less sensitive to noise and outliers, which enables us to easily create photorealistic animation videos with new motions that are different from the motions in the database. Experimental results on the public data set and our captured data set have verified the effectiveness of the proposed method. © 2017 IEEE.","Marker-less performance capture; Photorealistic animation; RGB-D camera; Sparse representation; Texture synthesis","Cameras; Computer games; Computer graphics; Database systems; Performance capture; Photo-realistic animation; Rgb-d cameras; Sparse representation; Texture synthesis; Animation",2-s2.0-85018505909
"Boucheix J.-M., Forestier C.","Reducing the transience effect of animations does not (always) lead to better performance in children learning a complex hand procedure",2017,"Computers in Human Behavior",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007484051&doi=10.1016%2fj.chb.2016.12.029&partnerID=40&md5=f791cfce6e650f3f44c5c99f09df4fcf","When large amounts of information are presented in long-section animations, or videos, depicting hand procedures, a transient information effect has often been shown to potentially weaken the superiority of dynamic visualizations over static graphics and to increase cognitive load. In the present paper, 103 ten-year-old children learnt to tie complex nautical knots from either a video of hand movements or from a static graphics presentation. Experiment 1 extended previous studies in the field using a conventional sequential presentation of the knots, under four conditions (long-section animation, short-section animation, long-section static graphics and short-section static graphics), but in a more “ecological” learning task than the majority of previous studies, involving a combination of observation and practice. In Experiment 2, with the same task and the same conditions, transience was reduced using animated simultaneous presentations. Results showed that long-section animation did not always lose its superiority over static graphics in this type of learning task. In addition to the transient information effect of the cognitive load theory, complementary explanations in terms of inhibition processes, attentional continuity and task affordance are suggested. © 2016 Elsevier Ltd","Animation; Knot tying; Sequential/Simultaneous presentation; Short-long sections; Transience","Behavioral research; Human computer interaction; Cognitive load theory; Dynamic visualization; Knot-tying; nocv1; Sequential/Simultaneous presentation; Short-long sections; Simultaneous presentations; Transience; Transient information; Animation; child; experimental model; hand movement; human; human experiment; learning; videorecording",2-s2.0-85007484051
"Kang C., Lee S.-H.","Multi-contact locomotion using a contact graph with feasibility predictors",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018797459&doi=10.1145%2f2983619&partnerID=40&md5=1133f1db7a488821c437be0233057988","Multi-contact locomotion that uses both the hands and feet in a complex environment remains a challenging problem in computer animation. To address this problem, we present a contact graph, which is a motion graph augmented by learned feasibility predictors, namely contact spaces and an occupancy estimator, for a motion clip in each graph node. By estimating the feasibilities of candidate contact points that can be reached by modifying a motion clip, the predictors allow us to find contact points that are likely to be valid and natural before attempting to generate the actual motion for the contact points. The contact graph thus enables the efficient generation of multi-contact motion in two steps: planning contact points to the goal and then generating the whole-body motion. We demonstrate the effectiveness of our method by creating several climbing motions in complex and cluttered environments by using only a small number of motion samples. © 2017 ACM.",,"Animation; Cluttered environments; Complex environments; Computer animation; Contact graphs; Contact points; Motion graph; Multi-contact; Whole-body motion; Estimation",2-s2.0-85018797459
"MacDorman K.F., Chattopadhyay D.","Categorization-based stranger avoidance does not explain the uncanny valley effect",2017,"Cognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009799161&doi=10.1016%2fj.cognition.2017.01.009&partnerID=40&md5=bc59326619cfe45ea43dd82ccd5324fb","The uncanny valley hypothesis predicts that an entity appearing almost human risks eliciting cold, eerie feelings in viewers. Categorization-based stranger avoidance theory identifies the cause of this feeling as categorizing the entity into a novel category. This explanation is doubtful because stranger is not a novel category in adults; infants do not avoid strangers while the category stranger remains novel; infants old enough to fear strangers prefer photographs of strangers to those more closely resembling a familiar person; and the uncanny valley's characteristic eeriness is seldom felt when meeting strangers. We repeated our original experiment with a more realistic 3D computer model and found no support for categorization-based stranger avoidance theory. By contrast, realism inconsistency theory explains cold, eerie feelings elicited by transitions between instances of two different, mutually exclusive categories, given that at least one category is anthropomorphic: Cold, eerie feelings are caused by prediction error from perceiving some features as features of the first category and other features as features of the second category. In principle, realism inconsistency theory can explain not only negative evaluations of transitions between real and computer modeled humans but also between different vertebrate species. © 2017 Elsevier B.V.","Anthropomorphism; Computer animation; Face perception; Novelty; Stranger avoidance","adult; avoidance behavior; classification; cognition; computer model; controlled study; facial recognition; fear; female; human; hypothesis; male; measurement error; Note; photography; prediction; priority journal; response time; semantic differential scale; uncanny valley hypothesis; virtual reality; weird sensation; young adult; computer simulation; emotion; perception; Computer Simulation; Emotions; Humans; Perception",2-s2.0-85009799161
"Xu H., Barbic J.","6-DoF Haptic Rendering Using Continuous Collision Detection between Points and Signed Distance Fields",2017,"IEEE Transactions on Haptics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028333408&doi=10.1109%2fTOH.2016.2613872&partnerID=40&md5=a73ac7737410b8ee4ac5064ff9b92269","We present an algorithm for fast continuous collision detection between points and signed distance fields, and demonstrate how to robustly use it for 6-DoF haptic rendering of contact between objects with complex geometry. Continuous collision detection is often needed in computer animation, haptics, and virtual reality applications, but has so far only been investigated for polygon (triangular) geometry representations. We demonstrate how to robustly and continuously detect intersections between points and level sets of the signed distance field. We suggest using an octree subdivision of the distance field for fast traversal of distance field cells. We also give a method to resolve continuous collisions between point clouds organized into a tree hierarchy and a signed distance field, enabling rendering of contact between rigid objects with complex geometry. We investigate and compare two 6-DoF haptic rendering methods now applicable to point-versus-distance field contact for the first time: Continuous integration of penalty forces, and a constraint-based method. An experimental comparison to discrete collision detection demonstrates that the continuous method is more robust and can correctly resolve collisions even under high velocities and during complex contact. © 2017 IEEE.","6-DoF; constraints; contact; continuous collision detection; Haptics; penalty forces; signed distance fields","Animation; Contacts (fluid mechanics); Geometry; Object recognition; Virtual reality; 6-DoF; constraints; Continuous collision detection; Haptics; Penalty force; Signed distance fields; Collision avoidance",2-s2.0-85028333408
"Atiker B., Turan B.O.","Screen design principles of computer-aided instructional software for elementary school students",2017,"Turkish Online Journal of Educational Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017035228&partnerID=40&md5=6de5882e23bd4258c5ec682b13444a98","This study aims to present primary school students’ views about current educational software interfaces, and to propose principles for educational software screens. The study was carried out with a general screening model. Sample group of the study consisted of sixth grade students in Şehit Öğretmen Hasan Akan Elementary School. In this context, the evaluation of 142 sixth grade students’ about existing software are analyzed with Instructional Software Screen Design Survey. Some of the survey items were created by researchers and some of them were taken from previously created questionnaire items. The research is limited with Bilden, Eurosoft, Kraker software and the sample group is limited to sixth grade students in Şehit Öğretmen Hasan Akan Elemantary School. In the scope of this study, selected examples of current instructional software are evaluated in terms of graphics, text, animation, color and screen layout. Survey data where students’ ideas are collected is processed with the SPSS 15 software. There is significant difference in text, graphic and screen layout of three software. In addition, there is significant difference between Eurosoft and the other two software in terms of color and animation. In the light of the findings, revision of educational software will be useful. Qualified screen designs will be created with user reviews and the studies done in this field. Uncomplicated, simple structured graphics, and animations created with vibrant colors, and screenshots which can be adapted easily, won the admiration of students. The study based on findings aims at guiding software manufacturers and educators. © The Turkish Online Journal of Educational Technology.","Computer aided instruction; Computer aided learning; Elementary school education; Instructional softwares; Screen design",,2-s2.0-85017035228
"Mammar A., Laleau R.","Modeling a landing gear system in Event-B",2017,"International Journal on Software Tools for Technology Transfer",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939864530&doi=10.1007%2fs10009-015-0391-0&partnerID=40&md5=e0d933aa784d24b2eb4556d42544f55a","This article describes the Event-B modeling of a landing gear system of an aircraft whose complete description can be found in Boniol and Wiels (The Landing Gear System Case Study, ABZ Case Study, Communications in Computer Information Science, vol 433, Springer, Berlin, 2014). This real-life case study has been proposed by the ABZ’2014 track that took place in Toulouse, the European capital of the aeronautic industry. Our modeling is based on the Parnas and Madey’s 4-Variable Model that permits to consider the different parts of a system. These parts are incrementally introduced using the Event-B refinement technique. The entire development has been carried out with the Rodin toolset. To ensure the correctness of the different components, we use several verification techniques (animation, model checking and proof) depending on the complexity and the kind of the properties to verify. Basically, prior to the proof phase that can be tedious and complex, we use the animator AnimB and the model checker ProB that permit to discover some trivial inconsistencies. Once no error is reported, we start the proof phase by using the Atelier B and SMT provers which we installed on Rodin. We conclude the article by drawing up some key findings of and lessons learned from this experience. © 2015, Springer-Verlag Berlin Heidelberg.","Development strategy; Event-B; Formal development; Refinement; Validation; Verification","Animation; Gears; Landing; Landing gear (aircraft); Verification; Development strategies; Event-B; Formal development; Refinement; Validation; Model checking",2-s2.0-84939864530
"Tang J., Xu L., He L., Guan S., Ming X., Liu Q.","Virtual Laparoscopic Training System Based on VCH Model",2017,"Journal of Medical Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014456607&doi=10.1007%2fs10916-017-0702-y&partnerID=40&md5=d51707dff746c8c72dd24a7b48253b26","Laparoscopy has been widely used to perform abdominal surgeries, as it is advantageous in that the patients experience lower post-surgical trauma, shorter convalescence, and less pain as compared to traditional surgery. Laparoscopic surgeries require precision; therefore, it is imperative to train surgeons to reduce the risk of operation. Laparoscopic simulators offer a highly realistic surgical environment by using virtual reality technology, and it can improve the training efficiency of laparoscopic surgery. This paper presents a virtual Laparoscopic surgery system. The proposed system utilizes the Visible Chinese Human (VCH) to construct the virtual models and simulates real-time deformation with both improved special mass-spring model and morph target animation. Meanwhile, an external device that integrates two five-degrees-of-freedom (5-DOF) manipulators was designed and made to interact with the virtual system. In addition, the proposed system provides a modular tool based on Unity3D to define the functions and features of instruments and organs, which could help users to build surgical training scenarios quickly. The proposed virtual laparoscopic training system offers two kinds of training mode, skills training and surgery training. In the skills training mode, the surgeons are mainly trained for basic operations, such as laparoscopic camera, needle, grasp, electric coagulation, and suturing. In the surgery-training mode, the surgeons can practice cholecystectomy and removal of hepatic cysts by guided or non-guided teaching. © 2017, Springer Science+Business Media New York.","Human-computer interaction; Laparoscopy; Training; Virtual laparoscopic surgery; Virtual learning environments; Virtual reality","abdominal cavity; Article; Chinese; cholecystectomy; controlled study; cystic duct; electrocoagulation; finite element analysis; gallbladder; laparoscopic surgery; liver cyst; physical parameters; surface property; surgical training; virtual reality; Asian continental ancestry group; biological model; China; clinical competence; computer interface; computer simulation; education; human; laparoscopic cholecystectomy; laparoscopy; surgical equipment; Asian Continental Ancestry Group; China; Cholecystectomy, Laparoscopic; Clinical Competence; Computer Simulation; Humans; Laparoscopy; Models, Biological; Surgical Instruments; User-Computer Interface",2-s2.0-85014456607
"Betts B.","Software reviews: Media goes mobile, plus weather or not?",2017,"Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017369235&partnerID=40&md5=7758422c4c1f7513457cc88b28190c7f","Much of the media we play today is either stored on or streamed to a phone or tablet. As we become more and more centred on our smartphones, clever app developers are finding ways for them to do things that we might never have thought possible. Momento is just such an app, where users feed it a set of still photos and it looks for those it can turn into looping mini-animations, using the animated GIF format that's become hugely popular for sharing online. As usual with graphics apps, users can add little icons or stickers, insert text, or layer on a colour effect, then send the resulting animated GIF to a friend or share it to one of your social media accounts. Lumyer Photo Editor can add multiple effects to a single photo, moving them around and twisting and zooming to get the best or most comical result. As usual, one can share the results with friends via social media or with other users via the Lumyer Instagram page, or save them as animated GIFs. Gboard is a new keyboard app which lets users search direct from the keyboard, with the results displayed there too so they don't have to leave their current screen. If users are in a messaging app and looking up something for their message, they can then insert the search result just by tapping on it.",,"Computer software selection and evaluation; Multiple effect; Photo editors; Social media; Software reviews; Social networking (online)",2-s2.0-85017369235
"Cheng H.-Y.K., Chang H.-T., Huang P.-H., Ju Y.-Y., Chen L.-Y., Tseng K.C.","The Design and Validation of a Child Developmental e-Screening System",2017,"Journal of Medical Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014954169&doi=10.1007%2fs10916-017-0701-z&partnerID=40&md5=0fbf77a7820d903f77a6137cd560e286","An effective screening test could significantly impact identification of developmental delays at an early age. However, many studies have shown that delay screenings still use text-based screening survey questionnaires. Unfortunately, the traditional text-based screening method tends to be fairly passive. In addition, the advantages of using an interactive system and animation have been shown to lead to positive effects on learning in medical research. Therefore, a multimedia screening system is necessary. This study constructs a system architecture to develop an e-screening system for child developmental delays. To validate the system after development, this study conducted an experiment and employed a questionnaire to survey users. Five experts and 120 subjects participated in the experiment. After the experiment, the results of the system evaluation revealed excellent agreement between the text-based and multimedia version of Taipei II. A total of 118 (98%) participants preferred the multimedia version or had no preference, and only 2 (2%) preferred the paper version. Regular text-based screening sometimes excludes those with low literacy and those whose native language is different from the text. In addition, text-based screening tools lose users’ attention easily. The current study successfully developed a multimedia text-based screening system. Feedback from the participants showed that the e-screening system was well accepted and more easily accessible than the original. In this study, a child developmental delays e-screening system was developed. After the experiment, the subjects indicated that the developmental delay e-screening system increased their comprehension and kept them interested in the screening. © 2017, Springer Science+Business Media New York.","Child development; Early intervention; Screening; System design","adult; aged; Article; checklist; child; child development; child developmental electronic screening system; computer interface; crossover procedure; developmental disorder; developmental screening; developmental stage; early intervention; electronic device; equipment design; feedback system; female; groups by age; health care survey; health care utilization; human; infant; instrument validation; major clinical study; male; multimedia; online system; program acceptability; questionnaire; screening test; test retest reliability; validation process; caregiver; Developmental Disabilities; early diagnosis; Internet; mass screening; preschool child; procedures; reproducibility; socioeconomics; standards; Caregivers; Child, Preschool; Cross-Over Studies; Developmental Disabilities; Early Diagnosis; Female; Humans; Infant; Internet; Male; Mass Screening; Reproducibility of Results; Socioeconomic Factors",2-s2.0-85014954169
"Ernawati D., Ikhsan J.","The Development of Monograph with 3-Dimentional Illustrations Titled ""augmented Chemistry: Hydrocarbon"" as Learning Enrichment Materials",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017217303&doi=10.1088%2f1742-6596%2f812%2f1%2f012088&partnerID=40&md5=8e341543c28900fd66eeff42edbe9b76","The development of 3D technology provides more advantages in education sectors. In chemistry, the 3D technology makes chemistry objects look more tangible. This research developed a monograph titled ""Augmented Chemistry: Hydrocarbon"" as learning enrichment materials. The development model consisted of 5 steps, which were the adaptation of the ADDIE model. The 3D objects of chemistry were built using the computer applications of Chem Sketch, and Google Sketch Up with AR Plugin. The 3D objects were displayed by relevant markers on the texts of the monograph from which the visualizations of the 3D objects appeared when they were captured by digital camera of laptop or smartphone, and were possibly viewed with free-rotation. Not only were 3D chemistry objects included in the monograph, but also graphics, videos, audios, and animations, which facilitated more fun learning for readers of the monograph. After the reviews by the experts of subject matter, of media, of instruction, and by peers, the monograph was revised, and then rated by chemistry teachers. The analysis of the data showed that the monograph titled ""Augmented Chemistry: Hydrocarbon"" was in the criteria of very good for the enrichment materials of Chemistry learning. © Published under licence by IOP Publishing Ltd.",,"Education; Education computing; Hydrocarbons; Teaching; Three dimensional computer graphics; 3D object; 3D technology; ADDIE model; Chemistry teachers; Development model; Education sectors; Free rotation; Subject matters; Chemical analysis",2-s2.0-85017217303
"Loureiro R., Lopes A., Carona C., Almeida D., Faria F., Garrote L., Premebida C., Nunes U.J.","ISR-RobotHead: Robotic head with LCD-based emotional expressiveness",2017,"ENBENG 2017 - 5th Portuguese Meeting on Bioengineering, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018673872&doi=10.1109%2fENBENG.2017.7889437&partnerID=40&md5=d95b10f8a072db1d970a087d5729e586","Worldwide, several research works have been devoted to the development of humanoid robots for human-robot interaction (HRI). Particular attention has been paid to the concept, design and applications of robotic heads and facial-expressions. Together, head and its facial expressions, they compose a fundamental, and 'familiar', interface to end-users; which is particularly true in child-robot interaction (CRI). This paper contributes with a functional prototype of a robotic head using LCDs for eyes-eyebrows and mouth animations. The prototype also incorporates vision cameras, microphones, speakers and pan and tilt control on the vertical and horizontal axis. Experiments and validation of the robotic head were carried out at the Cerebral Palsy Association of Coimbra with children (6-10 years old). Preliminary observations show that the proposed robotic head, motivated mainly as an interface for children, can accurately convey some of the most basic emotions, whose were recognised by children. The study carried out helped to identify issues for future developments, such as specific or complex emotional states that need to be refined. © 2017 IEEE.",,"Anthropomorphic robots; Human computer interaction; Robotics; Robots; Child-robot interactions; Design and application; Emotional state; Facial Expressions; Functional Prototypes; Horizontal axis; Human robot Interaction (HRI); Humanoid robot; Human robot interaction",2-s2.0-85018673872
"Liu X., He G., Peng S., Cheung Y., Tang Y.Y.","Efficient Human Motion Retrieval via Temporal Adjacent Bag of Words and Discriminative Neighborhood Preserving Dictionary Learning",2017,"IEEE Transactions on Human-Machine Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016420840&doi=10.1109%2fTHMS.2017.2675959&partnerID=40&md5=bdb6b1142d3eacbeaf8aaa5aa5dfceb2","Human motion retrieval from motion capture data forms the fundamental basis for computer animation. In this paper, the authors propose an efficient human motion retrieval approach via temporal adjacent bag of words (TA-BoW) and discriminative neighborhood preserving dictionary learning (DNP-DL). The retrieval process includes two phases: offline training and online retrieval. In the first phase, the original skeleton model is first simplified and then pairwise joint distances are computed to characterize each motion frame. Then, a novel motion descriptor, namely TA-BoW, is proposed to discriminatively code the motion appearances, through which the articulated complexity and spatiotemporal dimensionality can be greatly reduced. Subsequently, by considering the neighborhood relationships of intraclass structure and the advantage of Fisher criterion, a DNP-DL method is exploited through which each human action can be discriminatively and sparsely represented by a linear combination of such dictionary atoms. In the second phase, a hierarchical retrieval mechanism is used by incorporating the sparse classification and chi-square ranking, whereby the searching range is significantly reduced. The experimental results show that the proposed human motion retrieval approach performs better than the state-of-the-art competing approaches.",,"Computer animation; Dictionary learning; Hierarchical retrieval; Human motion retrieval; Linear combinations; Motion capture data; Motion descriptors; Sparse classification; Animation",2-s2.0-85016420840
"Ali I.R., Kolivand H., Alkawaz M.H.","Lip syncing method for realistic expressive 3D face model",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015795154&doi=10.1007%2fs11042-017-4437-z&partnerID=40&md5=8caccf115a01a6cd5b4d757923801eb8","Lip synchronization of 3D face model is now being used in a multitude of important fields. It brings a more human, social and dramatic reality to computer games, films and interactive multimedia, and is growing in use and importance. High level of realism can be used in demanding applications such as computer games and cinema. Authoring lip syncing with complex and subtle expressions is still difficult and fraught with problems in terms of realism. This research proposed a lip syncing method of realistic expressive 3D face model. Animated lips requires a 3D face model capable of representing the myriad shapes the human face experiences during speech and a method to produce the correct lip shape at the correct time. The paper presented a 3D face model designed to support lip syncing that align with input audio file. It deforms using Raised Cosine Deformation (RCD) function that is grafted onto the input facial geometry. The face model was based on MPEG-4 Facial Animation (FA) Standard. This paper proposed a method to animate the 3D face model over time to create animated lip syncing using a canonical set of visemes for all pairwise combinations of a reduced phoneme set called ProPhone. The proposed research integrated emotions by the consideration of Ekman model and Plutchik’s wheel with emotive eye movements by implementing Emotional Eye Movements Markup Language (EEMML) to produce realistic 3D face model. © 2017 Springer Science+Business Media New York","Facial expression; Lip syncing; Mpeg-4; PCA; Plutchik’s wheel","Animation; Eye movements; Film growth; Interactive computer systems; Markup languages; Motion Picture Experts Group standards; Multimedia systems; Wheels; 3-D face modeling; Facial animation; Facial Expressions; Interactive multimedia; Lip synchronization; Lip syncing; Mpeg-4; Pair-wise combinations; Computer games",2-s2.0-85015795154
"Huang C.-Y.","An innovative proposal for young students to learn computer science and technology through Pokemon go",2017,"Proceedings - 2016 International Conference on Computational Science and Computational Intelligence, CSCI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017289423&doi=10.1109%2fCSCI.2016.0055&partnerID=40&md5=096ba7966fdfb396da0e215aac03eb87","Pokemon Go is a mobile device based game that is very popular among teenagers. The game is based on the Geographic Information System (GIS) that utilizes the player's location and interacts with many fancy characters stored in local databases, and occasionally some information stored in remote databases. The game requires a lot of computations for distances, rules, and interactions. In this paper, we propose an innovative method for young students to learn about computer science through GIS and Pokemon Go. It is very important for young students to know that computer science is not just only about coding, but also involves many other interesting topics such as security, networking, animation, modeling, graphic and interface design, databases, user experiences (UX), requirement design, technical writing, etc. The purpose of this paper is to document how to encourage young students interested in pursuing careers in computer science and technology fields. © 2016 IEEE.","Augmented Reality; database; Geographic Information System; mobile device; young students","Animation; Artificial intelligence; Augmented reality; Database systems; Education; Geographic information systems; Information systems; Mobile devices; Students; Computer science and technologies; Innovative method; Interface designs; Know-that; Local database; Remote database; User experiences (ux); Engineering education",2-s2.0-85017289423
"Wu J., Xu H., Vassilev T.","Design of 3D Rendering Platform Based on Cloud Computing",2017,"Proceedings - 4th International Conference on Enterprise Systems: Advances in Enterprise Systems, ES 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017308373&doi=10.1109%2fES.2016.26&partnerID=40&md5=cefe4d53a7a10e8db7b1f9dc812c8ec7","In the recent years cloud computing has become one of the hottest topics in the field of information technology. It links a certain amount of computing, storage and software resources to make a huge scale of shared virtual IT resource pool, providing unlimited capacity IT services for remote computer users. Cloud computing attracts the attention of more and more enterprises by using its advantages such as convenience, economical benefit, high scalability. It can release the companies from the heavy pressure of managing and maintaining IT infrastructure. With the development of university information infrastructure many universities have built digital campuses and cloud platforms, so a cloud rendering platform can be established on the basis of the private cloud in a digital campus. Then idle resources can be shared for animation rendering, which will provide a solid backing for animation teaching, research and experiment. From the application point of view, this paper analyzes the challenges which animation rendering industry is faced with, and introduces the cloud computing theory and key technologies of cloud rendering solutions. Finally, we propose an instance of cloud rendering platform established on the private cloud in a campus, analyzing the system structure, work processes and the method of use. © 2016 IEEE.","cloud computing; cloud rendering; IaaS; PaaS; render farm; SaaS; self-service","Animation; Cloud computing; Computation theory; Network function virtualization; Cloud rendering; IaaS; PaaS; SaaS; self-service; Three dimensional computer graphics",2-s2.0-85017308373
"Elrawi O.M.","The use of mixed-realities techniques for the representation of islamic cultural heritage",2017,"Proceedings - 2017 International Conference on Machine Vision and Information Technology, CMVIT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017261378&doi=10.1109%2fCMVIT.2017.16&partnerID=40&md5=f1d407cd7bf3c9fb045160e32ca9f9c9","Left in the wake of cataclysmic change are the knowledge creation and holding structure of the past. Information knowledge and culture are central to human freedom and human development. How they are produced and exchanged in our society critically affects the way we see the state of the world as it is and might be. In recent years Mixed Reality (MR) has emerged as an area of extreme interest for visualizing and interacting with three-dimensional (3D) information in context, set in a story that reinforces learning and understanding of the cultural content. A commonly used and very inclusive definition of MR is that of all applications between pure Virtual Reality and the real world. How can we provide an intuitive user-friendly application for cultural heritage, which blends virtual imagery with the actual world, where users operate and interact with the information? How effectively can historical information and visual interpretations of the past be disseminated through such technologies? 'Tangible Pasts' consists of cultural domain expressing and analyzing the intended meaning of the shared vocabulary of concepts and relations in a domain of knowledge containing hierarchical classification systems and structured vocabularies with rich inter-linking of conceptual 'trees' i.e.: An object-oriented conceptual KC 'Knowledge Cube', which combines audio-visual information and three dimensional models and animations. Modern cultural heritage exhibitions have evolved from static exhibitions to dynamic and challenging multimedia explorations. The main goal of visualization is to bring understanding of data. The task is to present complex information in the most comprehensive manner. Considering architectural artefacts, the visualization process is mostly focused on the understanding of spatial relations and on the recognition of particular style and form, letting users see characters and events in the past. This paper describes a storytelling-driven framework for Islamic Cultural Heritage representation that supports a new communication strategy able to combine content belonging to different cultural archives and accessed through an ontology-based integration and discovery mechanism, and fosters new data sharing and distribution policies that preserve the intellectual property rights of the involved institutions. © 2017 IEEE.","augmented reality; cultural heritage; cultural tourism; Islamic architecture; Islamic civilization","Audio systems; Augmented reality; Classification (of information); Computer vision; Data visualization; Hierarchical systems; Historic preservation; Intellectual property; Laws and legislation; Ontology; Virtual reality; Visualization; Cultural heritages; cultural tourism; Hierarchical classification; Intellectual property rights; Islamic architectures; Islamic civilization; Ontology-based integrations; Three-dimensional (3D) information; Exhibitions",2-s2.0-85017261378
"Nasir F.M., Sunar M.S.","Simulating large group behaviour in tawaf crowd",2017,"Proceedings - APMediaCast 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017245717&doi=10.1109%2fAPMediaCast.2016.7878169&partnerID=40&md5=0ff0884de55bd2a04cc87abcb4853827","Crowd simulation is one of the important fields in computer graphics. It helps us develop an understanding of the complexity and the degree of crowd interactions of people in spaces over time. Many techniques have been introduced to simulate crowd, especially in the past few decades. These techniques often focus on emergency situations rather than simulating the more common normal conditions. Simulating crowd under normal condition is of higher importance as there are significant number of crowd related incidents occurring under this condition. The most recent occurred in Mina, Saudi Arabia when two large pilgrim groups converged on the same street causing a crowd crush. Additionally, many of the crowd simulation techniques introduced tend to focus more on individual behaviours while group behaviours are ignored. Less attention were given on the grouping aspects of the crowd even though it is a common phenomenon and a key element as it affects crowd behaviour. Therefore, this research intends to create a simulation of multi-group crowd under normal condition based on the social force model. Tawaf is used as the case study due to the heterogeneous nature of the pilgrims which come from various countries from all over the world. © 2016 IEEE.","computer animation; computer graphics; crowd simulation; modelling and simulation technique","Animation; Computer graphics; Computer animation; Crowd Simulation; Emergency situation; Individual behaviour; Modelling and simulations; Normal condition; Saudi Arabia; Social force models; Behavioral research",2-s2.0-85017245717
"Hegarini E., Dharmayanti, Syakur A.","Indonesian traditional dance motion capture documentation",2017,"Proceedings - 2016 2nd International Conference on Science and Technology-Computer, ICST 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017321111&doi=10.1109%2fICSTC.2016.7877357&partnerID=40&md5=49bc1deb143abf9e8bc6177917388802","Indonesia is an archipelago country with various kind of arts and cultures that must be maintained and preserved. Traditional dance is one kind of arts and cultures owned by each territory in Indonesia. Optical motion capture computer technology had been successfully implemented as traditional dance motion captured. Using this technology, traditional dancer movement could be documented and stored into digital movement data that could subsequently be used for traditional dance animation making purpose. The result of this research was traditional dance movement data compilation in raw data (.bvh stand for Biovision Hierarchy) form and its animation into the databased the originality of the traditional dance's move can be maintained. © 2016 IEEE.","movement data documentation; option motion capture technology; traditional dance","Computer science; Computers; Animation makings; Computer technology; Dance movement; Indonesia; Motion capture; Movement datum; Optical motion capture; traditional dance; Animation",2-s2.0-85017321111
"Wang Z., Liu S., Qian R., Jiang T., Yang X., Zhang J.J.","Human motion data refinement unitizing structural sparsity and spatial-temporal information",2017,"International Conference on Signal Processing Proceedings, ICSP",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016243832&doi=10.1109%2fICSP.2016.7877975&partnerID=40&md5=0fd862a7b61c6cc07137f81db6d405a0","Human motion capture techniques (MOCAP) are widely applied in many areas such as computer vision, computer animation, digital effect and virtual reality. Even with professional MOCAP system, the acquired motion data still always contains noise and outliers, which highlights the need for the essential motion refinement methods. In recent years, many approaches for motion refinement have been developed, including signal processing based methods, sparse coding based methods and low-rank matrix completion based methods. However, motion refinement is still a challenging task due to the complexity and diversity of human motion. In this paper, we propose a data-driven-based human motion refinement approach by exploiting the structural sparsity and spatio-temporal information embedded in motion data. First of all, a human partial model is applied to replace the entire pose model for a better feature representation to exploit the abundant local body posture. Then, a dictionary learning which is for special task of motion refinement is designed and applied in parallel. Meanwhile, the objective function is derived by taking the statistical and locality property of motion data into account. Compared with several state-of-art motion refine methods, the experimental result demonstrates that our approach outperforms the competitors. © 2016 IEEE.","Motion Capture Data; Motion Refinement","Animation; Virtual reality; Dictionary learning; Feature representation; Human motion capture; Low-rank matrix completions; Motion capture data; Motion Refinement; Objective functions; Spatiotemporal information; Signal processing",2-s2.0-85016243832
"Chen T., Fan B., Chen D., Li C.","A knowledge modeling method for computer graphics design & production based on ontology",2017,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018606515&doi=10.1051%2fmatecconf%2f201710002041&partnerID=40&md5=687ab0f99bc00c1f0661ac8ce1a77e33","As one of the most critical stages of CG (Computer Graphics) industry, CG design & production needs the support of professional knowledge and practice experience of multidisciplinary. With the outstanding performance in knowledge sharing, integration and reuse, knowledge modeling could increase greatly the efficiency, reduce the cost and avoid repeated error in CG design & production. However, knowledge modeling of CG design & production differs greatly from those of other fields. On the one hand, it is similar to physical product design, which involves great deal of tacit knowledge such as modeling skills, reasoning knowledge and so on. On the other hand, as film, CG design & production needs a lot of unstructured description information. The heterogeneity between physical product and film makes knowledge modeling more complicated. Thus a systematic knowledge modelling method based on Ontology is proposed to aid CG design & production in this paper. CG animation knowledge is capture and organized from viewpoint of three aspects: requirements and design and production. The knowledge are categorized into static and dynamic knowledge, and Ontology is adopted to construct a hierarchic model to organize the knowledge, so as to offer a uniform communication semantic foundations for designers from different fields. Based on animation script, the CG design task model is proposed to drive the organization and management of different knowledge involved in CG design & production. Finally, we apply this method in the knowledge modeling of naked-eye animation design and production to illustrate effectiveness of this method.","CG; Dynamic knowledge; Knowledge modeling; Ontology; OWL; Static knowledge","Animation; Computer graphics; Dynamics; Manufacture; Ontology; Semantics; Description information; Knowledge model; Knowledge modelling; Organization and management; Physical products; Professional knowledge; Semantic foundation; Static knowledge; Product design",2-s2.0-85018606515
"Deb D., Muztaba Fuad M., Kanan M.","Creating engaging exercises with mobile response system (MRS)",2017,"Proceedings of the Conference on Integrating Technology into Computer Science Education, ITiCSE",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018280528&doi=10.1145%2f3017680.3017793&partnerID=40&md5=83f400da64d0a22ff25d31037f8e9b7c","Computer Science instructors have been exploiting learning technology such as Algorithm Visualization (AV) for last few years to explain hard-to-understand algorithms to the learners through simulations and animations. In this work, we explore an active and highly engaging approach, namely, the construction of visualizations of the algorithms under study. Our approach is further augmented with automated assessment of students' inclass construction activities, which they execute as apps in their mobile devices. In this paper, we utilize case study, a step-by-step visualization of a construction exercise app, to explain how technology is leveraged to provide a richer way for learners to interact with a problem, and how instructor can acquire real-time evidence of learners' comprehension of covered lecture material. Our experimental evaluation shows the educational benefits of the proposed approach in terms of enhanced student learning, reduced drop-out rate and increased student satisfaction. © 2017 ACM.","Algorithm visualization; Automated assessment; Interactive learning environments; Learning technology; Mobile technology","Computer aided instruction; Construction industry; Education; Education computing; Learning algorithms; Learning systems; Students; Visualization; Algorithm visualization; Automated assessment; Interactive learning environment; Learning technology; Mobile Technology; Engineering education",2-s2.0-85018280528
"Megidish B., Zuckerman O., Hoffman G.","Animating mechanisms: A pipeline for authoring robot gestures",2017,"ACM/IEEE International Conference on Human-Robot Interaction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016444245&doi=10.1145%2f3029798.3036667&partnerID=40&md5=e9f0952504e3545bfe0fcb9bb71bf3fc","Designing and authoring gestures for socially expressive robots has been an increasingly important problem in recent years. In this demo we present a new pipeline that enables animators to create gestures for robots in a 3D animation authoring environment, without knowledge in computer programming. The pipeline consists of an exporter for a 3D animation software and an interpreter running on a System-on-Module translating the exported animation into motor control commands. © 2017 Authors.","animation; expressive gestures; expressive movement; human-robot interaction; robot animation","Animation; Computer programming; Man machine systems; Pipelines; Robot programming; Robots; 3D animation; Authoring environments; Expressive gestures; expressive movement; Motor control; Robot gestures; System on modules; Human robot interaction",2-s2.0-85016444245
"Bertails-Descoubes F., Coros S.","Guest Editor's Introduction: Special Section on the ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA)",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011411671&doi=10.1109%2fTVCG.2016.2638546&partnerID=40&md5=47326538aa3ef017757bfb275af09b54",[No abstract available],,,2-s2.0-85011411671
"Borno M.A., Van De Panne M., Fiume E.","Domain of attraction expansion for physics-based character control",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017134446&doi=10.1145%2f3009907&partnerID=40&md5=49fa094e2de21e148b19ccbca10cdc0b","Determining effective control strategies and solutions for high-degree-offreedom humanoid characters has been a difficult, ongoing problem. A controller is only valid for a subset of the states of the character, known as the domain of attraction (DOA). This article shows how many states that are initially outside the DOA can be brought inside it. Our first contribution is to show how DOA expansion can be performed for a high-dimensional simulated character. Our second contribution is to present an algorithm that efficiently increases the DOA using random trees that provide denser coverage than the trees produced by typical sampling-basedmotion-planning algorithms. The trees are constructed offline but can be queried fast enough for near-real-Time control.We show the effect of DOA expansion on getting up, crouch-To-stand, jumping, and standing-Twist controllers. We also show how DOA expansion can be used to connect controllers together.","Character animation this; Computer animation; Physics simulation","Animation; Expansion; Forestry; Trees (mathematics); Character animation; Computer animation; Control strategies; Domain of attraction; High-dimensional; Near-real time; Physics simulation; Planning algorithms; Controllers",2-s2.0-85017134446
"Holden D., Saito J., Komura T.","Learning Inverse Rig Mappings by Nonlinear Regression",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011573811&doi=10.1109%2fTVCG.2016.2628036&partnerID=40&md5=97f34d9a3d77711f21ce96c08dcccae2","We present a framework to design inverse rig-functions-functions that map low level representations of a character's pose such as joint positions or surface geometry to the representation used by animators called the animation rig. Animators design scenes using an animation rig, a framework widely adopted in animation production which allows animators to design character poses and geometry via intuitive parameters and interfaces. Yet most state-of-the-art computer animation techniques control characters through raw, low level representations such as joint angles, joint positions, or vertex coordinates. This difference often stops the adoption of state-of-the-art techniques in animation production. Our framework solves this issue by learning a mapping between the low level representations of the pose and the animation rig. We use nonlinear regression techniques, learning from example animation sequences designed by the animators. When new motions are provided in the skeleton space, the learned mapping is used to estimate the rig controls that reproduce such a motion. We introduce two nonlinear functions for producing such a mapping: Gaussian process regression and feedforward neural networks. The appropriate solution depends on the nature of the rig and the amount of data available for training. We show our framework applied to various examples including articulated biped characters, quadruped characters, facial animation rigs, and deformable characters. With our system, animators have the freedom to apply any motion synthesis algorithm to arbitrary rigging and animation pipelines for immediate editing. This greatly improves the productivity of 3D animation, while retaining the flexibility and creativity of artistic input. © 1995-2012 IEEE.","Animation rig; character animation; regression","Feedforward neural networks; Mapping; Regression analysis; Character animation; Gaussian process regression; Learning from examples; Low level representation; Non-linear regression; Nonlinear regression technique; regression; State-of-the-art techniques; Animation",2-s2.0-85011573811
"Wang D.-H., Hsieh H.-C., Chiang Y.-J., Yang P.-H., Chen T.-H., Wu C.-S.","Integration of geographic information with 3D visualization technologies for dynamic simulations of forest trail landscapes",2017,"Taiwan Journal of Forest Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016323254&partnerID=40&md5=d5d196852e2c769ecab06716dfeed26f","In landscape planning, simulation of the landscape is a powerful tool for public understanding. In the simulation, the reality of the simulated image is very important and recent progress in computer graphics enables very precise simulation of landscapes. A walk-through simulation is a new technique for accurately analyzing landscape resources and assessing visual impacts of proposed plans. In this study, we integrated GIS and 3D animation techniques to develop an animation system to show the landscape visualization of 5 types of forest trail in the Lienhuachi Research Center, Taiwan Forestry Research Institute. Digital terrain models in the research area were built using Lidar image. 3D object models were simulated using SketchUp 3D software, and delicate 3D plant models were constructed through Xfrog plant models. Then, simulated information was displayed in the LandSim3D platform for walk-through images of forest trails. Moreover, scenario designs on improvements to trail scenery for 2 forest trails selected were also animated. Results show that the great applicability of the animation system can provide an efficient way to communicate with the public about scenario designs of forest trail planning. It is expected that the 3D animation technique developed in this study can be used in forest trail management in forest recreation areas.","3D animation; Forest landscape planning; Forest trail; Geospatial information","Animation; Computer graphics; Forestry; Geographic information systems; Plants (botany); Visualization; 3-D visualization technology; 3D animation; Digital terrain model; Forest landscape; Forest trail; Geo-spatial informations; Geographic information; Landscape visualization; Three dimensional computer graphics",2-s2.0-85016323254
"Huber P., Perl R., Rumpf M.","Smooth interpolation of key frames in a Riemannian shell space",2017,"Computer Aided Geometric Design",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014839763&doi=10.1016%2fj.cagd.2017.02.008&partnerID=40&md5=4f3e7dd10a638fcb99e5b8a05caa00cf","Splines and subdivision curves are flexible tools in the design and manipulation of curves in Euclidean space. In this paper we study generalizations of interpolating splines and subdivision schemes to the Riemannian manifold of shell surfaces in which the associated metric measures both bending and membrane distortion. The shells under consideration are assumed to be represented by Loop subdivision surfaces. This enables the animation of shells via the smooth interpolation of a given set of key frame control meshes. Using a variational time discretization of geodesics efficient numerical implementations can be derived. These are based on discrete geodesic interpolation, a discrete geometric logarithm, a discrete exponential map, and discrete parallel transport. With these building blocks at hand discrete Riemannian cardinal splines and three different types of discrete, interpolatory subdivision schemes are defined. Numerical results for two different subdivision shell models underline the potential of this approach in key frame animation. © 2017 Elsevier B.V.","Cardinal splines; Interpolatory subdivision; Riemannian calculus; Shape space; Variational discretization","Animation; Calculations; Geometry; Shells (structures); Three dimensional computer graphics; Cardinal splines; Interpolatory subdivision; Riemannian calculus; Shape space; Variational discretization; Interpolation",2-s2.0-85014839763
"Vantzos O., Azencot O., Wardeztky M., Rumpf M., Ben-Chen M.","Functional Thin Films on Surfaces",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027401652&doi=10.1109%2fTVCG.2016.2605083&partnerID=40&md5=ca27232cb61358c1b05435e093e59989","The motion of a thin viscous film of fluid on a curved surface exhibits many intricate visual phenomena, which are challenging to simulate using existing techniques. A possible alternative is to use a reduced model, involving only the temporal evolution of the mass density of the film on the surface. However, in this model, the motion is governed by a fourth-order nonlinear PDE, which involves geometric quantities such as the curvature of the underlying surface, and is therefore difficult to discretize. Inspired by a recent variational formulation for this problem on smooth surfaces, we present a corresponding model for triangle meshes. We provide a discretization for the curvature and advection operators which leads to an efficient and stable numerical scheme, requires a single sparse linear solve per time step, and exactly preserves the total volume of the fluid. We validate our method by qualitatively comparing to known results from the literature, and demonstrate various intricate effects achievable by our method, such as droplet formation, evaporation, droplets interaction and viscous fingering. Finally, we extend our method to incorporate non-linear van der Waals forcing terms which stabilize the motion of the film and allow additional effects such as pearling. © 1995-2012 IEEE.","animation; Computer graphics; three-dimensional graphics and realism","Animation; Computer graphics; Drops; Three dimensional computer graphics; Van der Waals forces; Droplet formation; Geometric quantities; Temporal evolution; Thin viscous films; Three-dimensional graphics and realism; Underlying surface; Variational formulation; Viscous fingering; Thin films",2-s2.0-85027401652
"Xia M., Yang G., Li L., Li R., Sun X.","Detecting video frame rate up-conversion based on frame-level analysis of average texture variation",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962158399&doi=10.1007%2fs11042-016-3468-1&partnerID=40&md5=c085c9a3a3427c97305a820d94d5cf74","Frame rate up-conversion (FRUC) refers to frame interpolation between adjacent video frames to increase the motion continuity of low frame rate video, which can improve the visual quality on hand-held displays. However, FRUC can also be used for video forgery purposes such as splicing two videos with different frame-rates. We found that most FRUC approaches introduce visual artifacts into texture regions of interpolated frames. Based on this observation, a two-stage blind detection approach is proposed for video FRUC based on the frame-level analysis of average texture variation (ATV). First, the ATV value is computed for each frame to obtain an ATV curve of candidate video. Second, the ATV curve is further processed to highlight its periodic property, which indicates the existence of FRUC operation and further estimates the original frame rate. Thus, the positions of interpolated frames can be inferred as well. Extensive experimental results show that the proposed forensics approach is efficient and effective for the detection of existing typical FRUC approaches such as linear frame averaging and motion-compensated interpolation (MCI). The detection performance is superior to the existing approaches in terms of time efficiency and detection accuracy. © 2016, Springer Science+Business Media New York.","Average texture variation (ATV); Digital video forensics; Frame-rate up-conversion (FRUC); Motion compensated interpolation (MCI)","Aerospace vehicles; Animation; Image coding; Interpolation; Motion compensation; Multimedia systems; Detection performance; Digital video forensics; Frame interpolation; Frame rate up conversion; Low frame rate video; Motion compensated interpolation; Periodic properties; Texture variation; Computer graphics",2-s2.0-84962158399
"Demirsöz T., Ayvaşık H.B.","The Role of Distinctiveness of Stimulus in Memory Distrust as a Function of Repeated Checking [Tekrarlı Kontrol Etme Davranışının Bir Sonucu Olarak Hafızaya Olan Güvenin Azalmasıyla İlgili Ayırt Edici Uyaranın Rolü]",2017,"Turk psikiyatri dergisi = Turkish journal of psychiatry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028664373&partnerID=40&md5=fd281c8055f6565ca78b2f26ccc869ab","OBJECTIVE: Recent literature proposes that repeated checking increases familiarity with the material, making recollections less vivid and detailed and promoting distrust in memory. The aim of the current study is to investigate the possible underlying mechanisms of low confidence in memory.METHOD: The Padua Inventory-Washington State University Revision (PI-WSUR) was applied in a cohort of university students. Among the students who completed the PI-WSUR, 84 participants were selected and assigned to low Obsessive-Compulsive Symptomatology (OCS) group or high OCS group according to their PI-WSUR scores. An interactive computer animation was developed to test repeated checking behavior. Participants were randomly assigned to two experimental conditions: ""Feedback condition"" and ""no feedback condition"". The participants were all asked to carry out checking rituals on a virtual gas ring. However, half of the participants were given feedback indicating that checking activity was successful and complete and half of the participants were not.RESULTS: While there was no significant difference in terms of memory accuracy, memory detail and memory vividness between feedback condition and no feedback condition, there was a significant difference in terms of memory confidence between two experimental groups.DISCUSSION: Results are discussed in the light of a different explanation offering that the level of distinctiveness of recollections plays crucial role in memory distrust rather than the explanation of low confidence hypothesis.",,"adolescent; adult; cohort analysis; computer graphics; controlled study; female; human; male; memory; obsessive compulsive disorder; psychologic test; psychological model; psychology; randomized controlled trial; self concept; student; treatment outcome; Adolescent; Adult; Cohort Studies; Computer Graphics; Female; Humans; Male; Memory; Models, Psychological; Obsessive-Compulsive Disorder; Psychological Tests; Self Efficacy; Students; Treatment Outcome",2-s2.0-85028664373
"Ni Y.Q., Lin K.C., Wu L.J., Wang Y.W.","Visualized spatiotemporal data management system for lifecycle health monitoring of large-scale structures",2017,"Journal of Aerospace Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014326954&doi=10.1061%2f%28ASCE%29AS.1943-5525.0000622&partnerID=40&md5=3d2233604942428804f8986bbba037a8","Lifecycle structural health monitoring (SHM) systems provide an abundance of information that is greatly beneficial for securing structural safety over the whole service life. In application to large-scale structures, the management of accumulated massive data from a sophisticated long-term SHM system poses a challenge. A robust data management system (DMS), which not only facilitates spatiotemporal data management but also enables display in an attractive way, is highly desirable. This article presents the development of an effective visualized DMS specific for managing immense and heterogeneous SHM data by integrating nested relational database, three-dimensional (3D) model, and virtual reality (VR) technology and demonstrates its application to an instrumented supertall structure. A custom nested data model is designed to store redundant inherent temporal data and hierarchical inherent spatial data. Strategies for speeding up querying massive data are set up in the database. Making use of OpenSceneGraph (OSG) 3D engine, a 3D model is reconstructed from the 3D spatial data, which serves as a platform for data visualization. A four-dimensional (4D) animation protocol is presented by tying temporal data and construction schedule to the 3D model. The efficiency of the proposed DMS is exemplified through its application to a supertall structure instrumented with a sophisticated long-term SHM system. © 2016 American Society of Civil Engineers.","Data management systems; Long-term monitoring; Nested relational databases; Sensory systems; Spatiotemporal; Supertall structures; Visualization","Data visualization; Flow visualization; Life cycle; Metadata; Monitoring; Query processing; Structural health monitoring; Three dimensional computer graphics; Virtual reality; Visualization; Data management system; Long term monitoring; Relational Database; Sensory system; Spatiotemporal; Supertall structures; Information management",2-s2.0-85014326954
"Demirsöz T., Ayvaşik H.B.","The role of distinctiveness of stimulus in memory distrust as a function of repeated checking",2017,"Turk Psikiyatri Dergisi",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016389557&doi=10.5080%2fu13513&partnerID=40&md5=ffdb428b256a680a9e9709f5d8a4c7cc","Objective: Recent literature proposes that repeated checking increases familiarity with the material, making recollections less vivid and detailed and promoting distrust in memory. The aim of the current study is to investigate the possible underlying mechanisms of low confidence in memory. Method: The Padua Inventory-Washington State University Revision (PI-WSUR) was applied in a cohort of university students. Among the students who completed the PI-WSUR, 84 participants were selected and assigned to low Obsessive-Compulsive Symptomatology (OCS) group or high OCS group according to their PI-WSUR scores. An interactive computer animation was developed to test repeated checking behavior. Participants were randomly assigned to two experimental conditions: ""Feedback condition"" and ""no feedback condition"". The participants were all asked to carry out checking rituals on a virtual gas ring. However, half of the participants were given feedback indicating that checking activity was successful and complete and half of the participants were not. Results: While there was no significant difference in terms of memory accuracy, memory detail and memory vividness between feedback condition and no feedback condition, there was a significant difference in terms of memory confidence between two experimental groups. Discussion: Results are discussed in the light of a different explanation offering that the level of distinctiveness of recollections plays crucial role in memory distrust rather than the explanation of low confidence hypothesis.","Compulsive behavior; Distinctiveness; Doubt; Memory; Obsessive behavior; Obsessive-compulsive disorder",,2-s2.0-85016389557
"Claessens T.","Finding the location of the instantaneous center of rotation using a particle image velocimetry algorithm",2017,"American Journal of Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013213795&doi=10.1119%2f1.4973427&partnerID=40&md5=2772ff51b283e0b839b67f82341a1bcf","This work is about planar rigid-body kinematics and, in particular, the principle of the instantaneous center of rotation (IC). Using a computer simulated approach, a workflow is presented that results in a visual representation of the locus of the IC, based on particle image velocimetry (PIV). Here, a small number of digital animations of textured objects are created with multibody dynamics software, and later imported in PIV software to extract the velocity field (magnitude and direction) of objects moving within a plane. We believe the workflow presented may help learners improve their understanding of the concept of the IC, thus enhancing their knowledge of rigid body kinematics. © 2017 American Association of Physics Teachers.",,,2-s2.0-85013213795
"Podila S., Zhu Y.","Animating escape maneuvers for a school of fish",2017,"Proceedings - I3D 2017: 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022222818&doi=10.1145%2f3023368.3036845&partnerID=40&md5=e2f7bee2764b34bcd8101c9a93d566b6","A school of fish exhibit a variety of distinctive maneuvers to escape from predators. Although these escape maneuvers have long been observed and studied in the fields of biology and ecology, they have not been sufficiently modeled in computer graphics. For example, a school of fish often use fountain and flash maneuvers at the time of final attacks by their predators. Previous works on fish animation provide relatively simple escape behavior model and lack variety. We propose a behavioral model to simulate two fish escape maneuvers at the time of a single predator attack: fountain and flash maneuvers. We demonstrate our results with simulations of predator attacks.","3D animation; Behavior animation; Fish escape maneuvers; Fish schooling behavior","Animation; Computer graphics; Fish; Fountains; Interactive computer graphics; 3D animation; Behavioral model; Escape behavior; Fish schoolings; Three dimensional computer graphics",2-s2.0-85022222818
"Roque K.F.J., Atienza R.O.","Real-time procedural generation of a growing corn model",2017,"Proceedings - I3D 2017: 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022220654&doi=10.1145%2f3023368.3036843&partnerID=40&md5=a0ef82edcb9b27a0e38bcc254510ae7c","We present a method for the real-time procedural generation of a growing plant based on biological rules and physical assumptions, using corn as our model organism. Circular contours and segments of spirals are used to model the plant modules, i.e. leaf lamina, leaf sheath and stem. The growth of the plant modules is controlled by parametrized growth functions with growth rates determined by factors such as nutrient uptake. Leaf margin undulation is determined using a modified differential growth model. Leaf curvature due to gravity is estimated using a spring-based rigidity model for the leaf midrib. This plant model may be used as basis for realistic, virtual plants in virtual and augmented reality platforms. © 2017 Copyright held by the owner/author(s).","Growth animation; Plant model; Procedural model","Animation; Augmented reality; Interactive computer graphics; Nutrients; Growth functions; Growth modeling; Model organisms; Nutrient uptake; Physical assumptions; Plant model; Procedural modeling; Virtual and augmented reality; Three dimensional computer graphics",2-s2.0-85022220654
"Arief M., Todo H., Mikami K., Kondo K.","Textured splat based rendering for stylized shading",2017,"Proceedings - I3D 2017: 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022174282&doi=10.1145%2f3023368.3036840&partnerID=40&md5=b9188d42cf7cc2c39d6c0c15f9bcce1e","To create brush-stroke style animation with temporal coherence, the artist needs to refer the previous frame carefully for drawing. Moreover, brush-stroke lighting style is challenging to animate coherently because it dynamically changes and contains lots of features compared to physically-based lighting. © 2017 Copyright held by the owner/author(s).","Splat; Stroke-based rendering; Stylized shading","Animation; Computer graphics; Interactive computer graphics; Lighting; Three dimensional computer graphics; Brush stroke; Physically based; Splat; Stroke based rendering; Stylized shading; Temporal coherence; Rendering (computer graphics)",2-s2.0-85022174282
"De Belen R.A.J., Saludaresy M.I.S., Atienzaz R.O.","ANEEME: Interactive mesh cutting using 3D snakes for automatic skeletal rigging of scanned character models",2017,"Proceedings - I3D 2017: 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022185791&doi=10.1145%2f3023368.3036841&partnerID=40&md5=01dbe3e095a59fb23a99714d3aa79cac","ANEEME is a system for automatic skeletal rigging of 3D scanned humanoid objects such as toys, figurines, sculptures and even humans. Unlike other automatic skeletal rigging techniques, ANEEME does not require humanoid objects to be in a specific pose, (e.g. T-Pose) before scanning and rigging. If 3D models have limbs touching other parts of the body, the system provides an interactive cutout tool to separate and re-mesh the conjoined regions based on a few user-supplied points. After separating the overlapping body parts and filling the holes generated, ANEEME implements a hierarchical mesh segmentation to infer skeletal joints and perform a smooth skinning technique. Within minutes, the input can be easily incorporated and used to setup skeletal-based animations in most animation software applications. © 2017 Copyright held by the owner/author(s).","Character skinning; Geometric processing; Interactive mesh cutting; Rigging; Segmentation; Skeleton extraction; Virtual and augmented reality","Animation; Application programs; Augmented reality; Cutting; Image segmentation; Interactive computer graphics; Mesh generation; Musculoskeletal system; Character skinning; Geometric processing; Rigging; Skeleton extraction; Virtual and augmented reality; Three dimensional computer graphics",2-s2.0-85022185791
"Pantuwong N.","A tangible interface for 3D character animation using augmented reality technology",2017,"Proceedings of 2016 8th International Conference on Information Technology and Electrical Engineering: Empowering Technology for Better Future, ICITEE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015991863&doi=10.1109%2fICITEED.2016.7863263&partnerID=40&md5=1d0117f5b484a6d3c32081f2aaf29fa7","Nowadays, several systems have been proposed to reduce the difficulty of computer animation authoring. The 3D motion capture system could be used to record the motion data from real actors. The recorded motion could be used to drive an animation. Although this technique reduces the difficulty of computer animation, a user still needs to interact with 3D environment through mouse and keyboard which are 2D interface devices. This paper presents a novel interaction technique for 3D character animation control. A user does not need to interact with typical mouse and keyboard to control an animation, but interacts with a tangible object attached with several visible markers. Our system exploits a benefit of the Augmented Reality technology. The user could see the character movement on the screen of his/her tablet that records the tangible objects by its camera. The user could also move that tangible object to move the 3D character. We also use the Augmented Reality to assist the use for animation scene decoration. Our use study confirms that the proposed interaction technique could reduces the difficulty of 3D character animation, and our system could be by everyone. © 2016 IEEE.",,"Augmented reality; Digital storage; Mammals; 3D character animation; 3D motion capture systems; Augmented reality technology; Computer animation; Interaction techniques; Interface devices; Novel interaction techniques; Tangible interfaces; Animation",2-s2.0-85015991863
"Zhang G., Zhao J., Xu W., Lu D., Wang Y., Meng X.","An efficient parallel method for photo-realistic fluid animation",2017,"Computer-Aided Design and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983315213&doi=10.1080%2f16864360.2016.1223425&partnerID=40&md5=e3846593381e777004c2c6de0d8a76b1","Fluid animation often appears in applications such as games, films and cartoons. How to animate photo-realistic fluid motion efficiently is an important issue. We present an efficient parallel method for photo-realistic fluid animation in this paper. Our method is designed to generate fluid animation results with high efficiency on a cluster system. To do this, we categorize the computers in our cluster system into two classes, the server and the client. The server controls the process of the fluid animation while the clients are responsible for numerical computation. Given 3D virtual environment and fluid initial condition, we make pre-processing on the server so as to decompose the fluid animation task into several subtasks. Thus, the computation domain is divided into blocks and each client executes numerical computation for one block. The blocks of two adjacent clients are overlapped to keep the continuity of the solution across subdomain interface. We demonstrate the efficiency of our method by animating the motion of smoke and liquid. Results show that the proposed parallel algorithm can improve the computation speed of physically-based fluid animation significantly while getting interesting fluid details. © 2016 CAD Solutions, LLC.","Fluid animation; parallel algorithm; photo-realistic; preconditioned conjugate gradient method","Cluster analysis; Conjugate gradient method; Efficiency; Parallel algorithms; Virtual reality; 3-D virtual environment; Computation domains; Fluid animation; Initial conditions; Numerical computations; Photo-realistic; Physically based fluid animation; Preconditioned conjugate gradient method; Animation",2-s2.0-84983315213
"Garcia Fernandez J., Tammi K., Joutsiniemi A.","Extending the life of virtual heritage: Reuse of TLS point clouds in synthetic stereoscopic spherical images",2017,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021701753&doi=10.5194%2fisprs-archives-XLII-2-W3-317-2017&partnerID=40&md5=c8b8ec1dd3ad92ff22f755b8cce6fc63","Recent advances in Terrestrial Laser Scanner (TLS), in terms of cost and flexibility, have consolidated this technology as an essential tool for the documentation and digitalization of Cultural Heritage. However, once the TLS data is used, it basically remains stored and left to waste. How can highly accurate and dense point clouds (of the built heritage) be processed for its reuse, especially to engage a broader audience? This paper aims to answer this question by a channel that minimizes the need for expert knowledge, while enhancing the interactivity with the as-built digital data: Virtual Heritage Dissemination through the production of VR content. Driven by the ProDigiOUs project's guidelines on data dissemination (EU funded), this paper advances in a production path to transform the point cloud into virtual stereoscopic spherical images, taking into account the different visual features that produce depth perception, and especially those prompting visual fatigue while experiencing the VR content. Finally, we present the results of the Hiedanranta's scans transformed into stereoscopic spherical animations.","Point cloud; Reuse; Spherical images; Stereoscopic; Terrestrial Laser Scanner; VR","Depth perception; Laser applications; Scanning; Seebeck effect; Spheres; Stereo image processing; Three dimensional computer graphics; Point cloud; Reuse; Spherical images; Stereoscopic; Terrestrial laser scanners; Surveying instruments",2-s2.0-85021701753
"Max N., Duff T., Mildenhall B., Yan Y.","Approximations for the distribution of microflake normals",2017,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013485191&doi=10.1007%2fs00371-017-1352-2&partnerID=40&md5=44696e992213de01304b265bc858d741","Scenes in computer animation can have extreme complexity, especially when high resolution objects are placed in the distance and occupy only a few pixels. A useful technique for level of detail in these cases is to use a sparse voxel octree containing both hard surfaces and a participating medium consisting of microflakes. In this paper, we discuss three different methods for approximating the distribution of normals of the microflakes, which is needed to compute extinction, inscattering of attenuated direct illumination, and multiple scattering in the participating medium. Specifically, we consider (a) k means approximation with k weighted representatives, (b) expansion in spherical harmonics, and (c) the distribution of the normals of a specific ellipsoid. We compare their image quality, data size, and computation time. © 2017 Springer-Verlag Berlin Heidelberg","Distribution of normals; Microflake; Sparse voxel octree; Volume rendering","Animation; Volume rendering; Computation time; Computer animation; Direct illumination; Distribution of normals; Microflake; Participating medium; Sparse voxel octree; Spherical harmonics; Image quality",2-s2.0-85013485191
"Khan S., Chen L., Zhe X., Yan H.","Feature selection based on co-clustering for effective facial expression recognition",2017,"Proceedings - International Conference on Machine Learning and Cybernetics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021054620&doi=10.1109%2fICMLC.2016.7860876&partnerID=40&md5=7c0ace3d933625cb3992d5a92e7a967b","Facial expressions are considered to be an effective and non-verbal means of expressing the emotional states of humans in more natural and non-intrusive way. Automatically recognizing the emotions consequently contributes towards the advances in the areas such as human computer interaction, clinical psychology and data-driven animations. Deriving a relevant and reduced set of features is a vital step for effective facial expression recognition. In this paper, we propose a co-clustering based approach to the selection of distinguished and interpretable features to deal with the curse of dimensionality issue. First, the features are extracted from images using a bank of Gabor filters. Then, a co-clustering based algorithm is designed to seek distinguishable features based on their non-inclusive information in co-clusters. Experiments illustrate that the selected features are accurate and effective for the facial expression recognition on JAFFE database and the best recognition rate is obtained by using selected features with SVM for classification. Moreover, we illustrate that the selected features not only reduces the dimensionality but also identify the distinguishable face regions on images amongst all expressions. © 2016 IEEE.","Co-clustering; Face expression recognition; Feature selection; Gabor wavelets","Artificial intelligence; Classification (of information); Clustering algorithms; Cobalt compounds; Cybernetics; Education; Feature extraction; Gabor filters; Human computer interaction; Learning systems; Co-clustering; Curse of dimensionality; Data-driven animation; Emotional state; Face expression recognition; Facial expression recognition; Facial Expressions; Gabor wavelets; Face recognition",2-s2.0-85021054620
"Kawai J., Mitsuhara H., Shishibori M.","Tsunami Evacuation Drill System using Motion Hazard Map and Smart Devices",2017,"Proceedings of the 2016 3rd International Conference on Information and Communication Technologies for Disaster Management, ICT-DM 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016028056&doi=10.1109%2fICT-DM.2016.7857221&partnerID=40&md5=9592c7303f7f873c9e6805967df33f81","Tsunami resulting from large-scale earthquakes can cause significant damage. Therefore, a tsunami evacuation drill (TED) is important for disaster education. However, conventional TEDs do not necessarily produce the maximum effect because some participants move quickly to evacuation sites while simply imagining the tsunami and do not feel a sense of tension. We have developed a TED system that uses a motion hazard map (MHM) and smait devices (e.g. tablet computers and smart glasses). This system has three phases, i.e. simulation, evacuation and reflection phases. For the simulation, the system allows users to generate a MHNI by configuring tsunami simulation using Google Maps. For the evacuation, the system presents the generated MHM by panoramically visualising the approaching tsunami (simulated animation) and plotting the participants' current locations on Google Maps. The participants can move quickly while feeling a sense of tension and viewing the simulated animation to determine the speed of and distance to the tsunami. For the reflection, the system supeiimposes recorded participants' evacuation routes onto the simulated animation.","Motion hazard map; Smart glasses; Tablet computers; Tsunami evacuation drill","Animation; Disaster prevention; Disasters; Drills; Glass; Hazards; Evacuation drill; Evacuation routes; Hazard map; Large-scale earthquakes; Reflection phasis; Smart glass; Tablet computer; Tsunami simulation; Tsunamis",2-s2.0-85016028056
"Choubisa T., Upadrashta R., Panchal S., Praneeth A., Ranjitha H.V., Senthoor K., Bhattacharya A., Anand S.V.R., Hegde M., Kumar A., Kumar P.V., Iyer M.S., Sampath A., Prabhakar T.V., Kuri J., Singh A.N.","Challenges in Developing and Deploying a PIR Sensor-Based Intrusion Classification System for an Outdoor Environment",2017,"Proceedings - Conference on Local Computer Networks, LCN",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017523075&doi=10.1109%2fLCN.2016.041&partnerID=40&md5=34fd3058711315df893239a8eb47d895","The aim of the current paper is to describe the challenges faced during the development and deployment of a PIR sensor-based intrusion classification system in an outdoor environment. Some potential solutions to overcome these challenges are also presented. The challenges are of three types: (a) challenges in designing a sensor tower platform that is physically aligned to the accuracies demanded by the application, (b) challenges involved in implementing high-accuracy algorithms on a mote and, finally and perhaps most importantly, (c) challenges faced in attempting to operate a PIR-based sensor tower platform at temperatures close to that of the human body. A test deployment over a 15-week period, beginning Feb 6, 2016, was carried out within the campus of the Indian Institute of Science, Bengaluru. This period of deployment coincided with the peak summer season at which time the ambient temperature in Bengaluru ranged from 15 °C to 38 °C. This made it possible to study the behavior of the PIR-based sensor tower platform in settings where the ambient temperature is close to that of the human body. © 2016 IEEE.","6LoWPAN; animation; energy harvesting; intrusion detection; passive infrared sensor; sensor network deployment; wildlife protection; Wireless sensor network","Animation; Computer networks; Energy harvesting; Infrared detectors; Intrusion detection; Mercury (metal); Temperature; 6LoWPAN; Classification system; High-accuracy; Indian institute of science; Network deployment; Outdoor environment; Passive infrared sensors; Wildlife protection; Wireless sensor networks",2-s2.0-85017523075
"Gunanto S.G., Hariadi M., Yuniarno E.M.","Marker-based tracking using temporal coherence in computer facial animation system",2017,"Proceeding - 2016 2nd International Conference on Science in Information Technology, ICSITech 2016: Information Science for Green Society and Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016199615&doi=10.1109%2fICSITech.2016.7852599&partnerID=40&md5=9db73f8ec5063c39550f26c1818545fb","High demand on the productivity of the animation industry in Indonesia requires a change in the existing production process. Motion capture technology is the implementation of a computer vision principle to adopt the human eye senses to understand the phenomenon of motion results from a camera and mapped the virtual movement patterns. This paper will discuss a method for tracking marker features in the human face to obtain information about facial expressions. The tracking technique is using implementation of temporal coherence principle. This research assumes that using temporal coherence approach, the tracking process in sequential images can be simplified by calculating similarity on markers in each frame. The results show this feature-tracking process have reliable results to handle a lot of frames. Computation used very efficiently and cheap because it does not require a learning process in advance. The precision accuracy of tracking parameters generated a database of good visual expression. © 2016 IEEE.","facial animation; marker-based tracking; temporal coherence","Eye movements; Virtual reality; Calculating similarities; Facial animation; Facial Expressions; Marker-based tracking; Production process; Sequential images; Temporal coherence; Tracking techniques; Animation",2-s2.0-85016199615
"Pereira T., Pereira O., Fazendeiro P., Gomes A.","A gyro-enhanced smart-phone framework to develop motion-based user interfaces for animation and virtual environments",2017,"2016 23 Encontro Portugues de Computacao Grafica e Interacao, EPCGI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016051050&doi=10.1109%2fEPCGI.2016.7851199&partnerID=40&md5=d995bf74743def6c7de957d05ac9a2b4","In this paper, the mobile phone is presented as an alternative device to interact with animation systems and virtual environments, including video games. Basically, we show how the gyroscope of a mobile device can work as a sensor to control the pose and motion of a mobile device controlled object or character in a 3D virtual world. More specifically, we introduce a framework that enables the development and rapid prototyping of motion-based user interfaces for animation systems and virtual environments. This framework provides tools to capture and control the motion of mobile devices-binded objects in a 3D virtual scene over a wireless communication channel via a simple, fast and efficient protocol named Open Sound Control (OSC). © 2016 IEEE.","gyroscope; mobile devices; Motion capture; motion control; motion-based user interfaces; open sound control","Animation; Cellular telephone systems; Computer graphics; Gyroscopes; Interactive computer graphics; Mobile devices; Motion control; Smartphones; Telephone sets; Virtual reality; Wireless telecommunication systems; 3d virtual worlds; Animation systems; Controlled objects; Efficient protocols; Motion capture; Open Sound Control; Virtual scenes; Wireless communication channels; User interfaces",2-s2.0-85016051050
"Gradil A., Ferreira J.F.","A visualisation and simulation framework for local and remote HRI experimentation",2017,"2016 23 Encontro Portugues de Computacao Grafica e Interacao, EPCGI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015987595&doi=10.1109%2fEPCGI.2016.7851191&partnerID=40&md5=5da6ad224fcda4933b8ee0866b2e4519","In this text, we will present work on the design and development of a ROS-based (Robot Operating System1) remote 3D visualisation, control and simulation framework. This architecture has the purpose of extending the usability of a system devised in previous work by this research team during the CASIR (Coordinated Attention for Social Interaction with Robots) project. The proposed solution was implemented using ROS, and designed to attend the needs of two user groups - local and remote users and developers. The framework consists of: (1) a fully functional simulator integrated with the ROS environment, including a faithful representation of a robotic platform, a human model with animation capabilities and enough features for enacting human robot interaction scenarios, and a virtual experimental setup with similar features as the real laboratory workspace; (2) a fully functional and intuitive user interface for monitoring and development; (3) a remote robotic laboratory that can connect remote users to the framework via a web browser. The proposed solution was thoroughly and systematically tested under operational conditions, so as to assess its qualities in terms of features, ease-of-use and performance. Finally, conclusions concerning the success and potential of this research and development effort are drawn, and the foundations for future work will be proposed. © 2016 IEEE.","Framework; Gazebo; Remote; ROS; Simulation; User Interface; Visualisation","Computer graphics; Machine design; Network function virtualization; Robotics; Robots; User interfaces; Virtual reality; Visualization; Framework; Gazebo; Intuitive user interface; Operational conditions; Remote; Remote robotic laboratories; Research and development; Simulation; Human robot interaction",2-s2.0-85015987595
"Liang H.","Application of the roving machine control system based on MCGS configuration software",2017,"Wool Textile Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026443609&doi=10.19333%2fj.mfkj.2016090140204&partnerID=40&md5=cf464711ad03e72992907bbe2f4ffae0","In view of modern wool textile businesses' need for intelligent weaving machines and based on the requirements of roving machine intelligent monitoring in the process of fore-spinning, the paper puts forward the use of MCGS configuration software to construct the roving machine monitoring system to enhance human-computer interaction, real-time monitoring and alarming of parameters, and provides the setting of process parameters. It explains how to use MCGS configuration software from the aspects of monitoring interface design, communication parameter setting, simulated animation design, monitoring and alarm design, variable definition and correlation. Commissioning of the proposed monitoring system proved that the system is of great value in practice due to its improvement in productivity and production flexibility.","Configuration software; MCGS; Real-time monitoring; Roving machine",,2-s2.0-85026443609
"Sun Q., Wan W., Yu X.","The simulation of building escape system based on Unity3D",2017,"ICALIP 2016 - 2016 International Conference on Audio, Language and Image Processing - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016133938&doi=10.1109%2fICALIP.2016.7846656&partnerID=40&md5=cb73c2057b621a68ee0d1454407d5acc","With the maturity of a variety of 3D modeling software and animation software as well as the emergence of various virtual reality equipment, Virtual reality technology has received more attention and application. In this paper, the author uses 3Ds Max and Esri CityEngine to generate 3D modeling and animation. These models are imported into Unity 3D to simulate the escape scene. The result of the simulation can be displayed and interacted by virtual reality head wear equipment named Oculus Rift DK2. The simulation provides users with direct feelings and experience about the proposed escape system. © 2016 IEEE.","3Ds MAX; High-altitude escape; Oculus Rift DK2; Unity3D; Virtual reality","Animation; Application programs; Hypersonic aerodynamics; Three dimensional computer graphics; Virtual reality; 3ds max; Animation softwares; Escape system; High-altitude escape; Oculus Rift DK2; Simulation of buildings; Unity3d; Virtual reality technology; Image processing",2-s2.0-85016133938
"Yin J., Yang X.","3D facial reconstruction of based on OpenCV and DirectX",2017,"ICALIP 2016 - 2016 International Conference on Audio, Language and Image Processing - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016115763&doi=10.1109%2fICALIP.2016.7846562&partnerID=40&md5=54854eae7b0e30a6849a20e0cc2a1e0b","Face as a biometric identification in computer vision is an important medium, in areas such as video surveillance, animation games, security anti-terrorist has a very wide range of applications, creating vivid, strong visibility of 3d face model, now has become a challenging in the field of computer vision is one of the important topics. At first, this paper used the zhongxing-micro ZC301P cameras to build a binocular stereo vision system for recording images. After the camera calibration and binocular calibration, the three-dimensional data of facial images were extracted using the functions of OpenCV computer vision library, and then 3d face model were reconstructed preliminary by DirectX. According the reconstruction process, the human face three-dimensional reconstruction software was designed and developed. The paper laid the foundation for the next step work that is to obtain more clear and strong visibility of 3d face. © 2016 IEEE.","3d face model; Computer vision; DirectX; OpenCV","Animation; Bins; Calibration; Cameras; Computer games; Computer vision; Image processing; Security systems; Stereo image processing; Stereo vision; Terrorism; Visibility; 3-D face modeling; 3d facial reconstruction; Binocular stereo vision system; Biometric identifications; Computer vision library; DirectX; OpenCV; Three-dimensional reconstruction; Three dimensional computer graphics",2-s2.0-85016115763
"Trausan-Matu S.","Is it possible to grow an I–Thou relation with an artificial agent? A dialogistic perspective",2017,"AI and Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011568240&doi=10.1007%2fs00146-017-0696-5&partnerID=40&md5=5d6be56bdc04376ec1914012b7179d52","The paper analyzes if it is possible to grow an I–Thou relation in the sense of Martin Buber with an artificial, conversational agent developed with Natural Language Processing techniques. The requirements for such an agent, the possible approaches for the implementation, and their limitations are discussed. The relation of the achievement of this goal with the Turing test is emphasized. Novel perspectives on the I–Thou and I–It relations are introduced according to the sociocultural paradigm and Mikhail Bakhtin’s dialogism, polyphony inter-animation, and carnavalesque. The polyphonic model, the associated analysis method, and the support tools are introduced. Some ideas on how the polyphonic model may be used for the implementation of a computer application able to analyze some features of the existence of an I–Thou relation are included. © 2017 Springer-Verlag London","Conversational agent; Dialogism; Empathy; Inter-animation; I–Thou; Polyphonic model","Animation; Analysis method; Artificial agents; Conversational agents; Dialogism; Empathy; NAtural language processing; Polyphonic models; Support tool; Natural language processing systems",2-s2.0-85011568240
"Ariyanto M., Ismail R., Nurmiranto A., Caesarendra W., Paryanto, Franke J.","Development of a low cost anthropomorphic robotic hand driven by modified glove sensor and integrated with 3D animation",2017,"IECBES 2016 - IEEE-EMBS Conference on Biomedical Engineering and Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015641035&doi=10.1109%2fIECBES.2016.7843470&partnerID=40&md5=05eda2ee577f65489941371a66f27438","In this paper, a low cost anthropomorphic robotic hand is developed using low cost materials. The robotic hand has 6 joints and 6 actuators. User or operator gives the hand movement command by a modified glove sensor. The glove consists of six flex sensors placed on the fingers and wrist join that detect the bend of the fingers into a joint angle in each finger. 3D CAD model of robotic hand is exported into SimMechanics model using SimMechanics link to generate SimMechanics block diagram that can run in MATLAB/ Simulink environment. The model in SimMechanics is utilized as 3D animation hand. The relationship of the servo motor rotation angle among metacarpal phalangeal (MCP), proximal inter phalangeal (PIP) and distal inter phalangeal (DIP) joints will be presented. Finally, the performance of robotic hand is tested to grasp various objects and to perform specific motion augmented with 3D animation. The experiment results show the successful development of a low cost anthropomorphic robotic hand that can perform activities of daily living (ADLs). © 2016 IEEE.","3D animation; anthropomorphic; flex sensor; robotic hand; SimMechanics","Animation; Biomedical engineering; Computer aided design; Costs; End effectors; Robotic arms; 3D animation; 3D CAD Modeling; Activities of daily living (ADLs); anthropomorphic; Block diagrams; Flex sensor; MATLAB/ SIMULINK; SimMechanics; Robotics",2-s2.0-85015641035
"Yang X., Liu M.","On the new trend of ink animation techniques in digital age",2017,"Proceedings of the IEEE International Conference on Advanced Materials for Science and Engineering: Innovation, Science and Engineering, IEEE-ICAMSE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015259010&doi=10.1109%2fICAMSE.2016.7840291&partnerID=40&md5=53b5b6430a378b7010f4ee72e7fbd38a","Chinese ink animation occupies an important position in the world animation history, while its complex processes and painting techniques have always been the pride of Chinese people. With the advent of the digital age, the popularity of computer technology and network provides a new creative environment and platform for painting. Compared with traditional painting, computer painting not only is faster, more environmentally-friendly and more convenient, but also makes the artistic forms and types of animation more diverse. This paper will focus on the new trends of some new technology and development during the production of ink animation in the digital era. © 2016 IEEE.","digital technology; ink animation; painting","Complex networks; Painting; Chinese people; Complex Processes; Computer technology; Digital age; Digital era; Digital technologies; Ink animations; Painting techniques; Animation",2-s2.0-85015259010
"de Lima E.S., Feijó B., Furtado A.L.","Video-based interactive storytelling using real-time video compositing techniques",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011565181&doi=10.1007%2fs11042-017-4423-5&partnerID=40&md5=da6e85e137dba4544a51ab812cbdbf35","Interactive storytelling systems usually adopt computer graphics to represent virtual story worlds, which facilitates the dynamic generation of visual content. However, the quality of the images and motion produced by these systems is still inferior compared to the high quality experience found in live-action films. Interactive rates in photorealistic rendering for the film industry will not be possible for decades to come. A promising alternative is the replacement of 3D virtual characters with video sequences with real actors. In this paper, we propose a new method for video-based interactive narratives that uses video compositing algorithms that run at truly interactive frame rates. The proposed method is consistent with plots that are generated by nondeterministic planning algorithms. Moreover, we propose a system of artificial intelligent agents that perform the same roles played by filmmaking professionals. A user evaluation of the proposed method is presented. We believe that future improvements of the techniques proposed in this paper represent an important contribution to the quest for new and more immersive forms of interactive cinema. © 2017 Springer Science+Business Media New York","Interactive cinema; Interactive storytelling; Video compositing; Video-based interactive storytelling; Virtual cinematography","Animation; Computer graphics; Intelligent agents; Artificial intelligent; Interactive cinema; Interactive frame rates; Interactive storytelling; Nondeterministic planning; Photorealistic rendering; Video compositing; Virtual cinematography; Interactive computer graphics",2-s2.0-85011565181
"Wang H., Xu M., Mao T., Jin X., Wang Z.","Survey of Three-Dimension Traffic Animation",2017,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019366399&partnerID=40&md5=43f1d55324e57c6bd185a4d8ff1657cc","Recently, as the development of virtual reality techniques, traffic animation turns to be one of hotspots in computer graphics. This paper provides a survey of the methods in three-dimension traffic animations. First, we present a structured review of methods of road networks, which are the carriers of vehicles. Second, we describe vehicle movement simulations from seven perspectives, including one-dimension car-following method, continuum method, mesoscopic method, hybrid method, path-planning method, rule-based method and data-driven method. We detail their principles, advantages and drawbacks. Finally, we point out some open research areas and possible future directions. © 2017, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Road network; Traffic animation; Urban environment; Vehicle movement","Computer graphics; Motion planning; Motor transportation; Roads and streets; Surveys; Vehicles; Virtual reality; Data-driven methods; Mesoscopic method; Path planning method; Road network; Structured review; Urban environments; Vehicle movements; Virtual reality techniques; Animation",2-s2.0-85019366399
"Khooshabeh P., Dehghani M., Nazarian A., Gratch J.","The cultural influence model: when accented natural language spoken by virtual characters matters",2017,"AI and Society",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908149034&doi=10.1007%2fs00146-014-0568-1&partnerID=40&md5=899738fe70bb5e7bc8bf008d549da810","Advances in artificial intelligence and computer graphics digital technologies have contributed to a relative increase in realism in virtual characters. Preserving virtual characters’ communicative realism, in particular, joined the ranks of the improvements in natural language technology, and animation algorithms. This paper focuses on culturally relevant paralinguistic cues in nonverbal communication. We model the effects of an English-speaking digital character with different accents on human interactants (i.e., users). Our cultural influence model proposes that paralinguistic realism, in the form of accented speech, is effective in promoting culturally congruent cognition only when it is self-relevant to users. For example, a Chinese or Middle Eastern English accent may be perceived as foreign to individuals who do not share the same ethnic cultural background with members of those cultures. However, for individuals who are familiar and affiliate with those cultures (i.e., in-group members who are bicultural), accent not only serves as a motif of shared social identity, it also primes them to adopt culturally appropriate interpretive frames that influence their decision making. © 2014, Springer-Verlag London (Outside the USA).","Biculturals; Cultural priming; Natural language","Animation; Artificial intelligence; Computer graphics; Decision making; Linguistics; Animation algorithms; Biculturals; Cultural backgrounds; Cultural priming; Digital technologies; Natural languages; Non-verbal communications; Paralinguistic cues; Natural language processing systems",2-s2.0-84908149034
"Li C., Sun R., Dai Y., Cai S., Li Q., Li J.","Intelligent exhibition platform of Chinese ancient farming virtual scene based on Unity3D",2017,"Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017574579&doi=10.11975%2fj.issn.1002-6819.2017.z1.046&partnerID=40&md5=22c1f6ac990e1931aac34f6a8015dbd0","The limitation of the current mode of transmission has hindered the spread and development of farming culture and spirit. In view of the mentioned facts, a method of developing an intelligent exhibition platform based on virtual reality was proposed. In order to avoid the error and delay caused by interaction, we proposed an algorithm of model interactive control that could realize observing the 3D (three-dimensional) model by rotating and zooming it accurately. Meanwhile, we put forward a virtual scene roaming algorithm for orientation changing aiming at the problem that the present virtual scene path roaming algorithm cannot change the object's orientation, and as a result, the effect achieved by this algorithm was more similar to behavior of human. The intelligent exhibition platform of virtual farming scene was designed and developed based on the Unity3D platform, with 3D Max as the 3D modeling tool and C# as the scripting language. Virtual farming scene should be built on the basis of the objective facts, so that it can be in line with the historical background and reality. But one of the difficulties of this platform was that we had no real scene for reference, so we proposed a method of observation and measurement to solve the problem. According to the analysis and design of the data, the display platform was divided into 2 parts, the north ancient China with dry land and the south ancient China with paddy fields. Each part would be shown from 3 aspects, i.e. scene, farming tools and typical production skills. By observing the appearance, recording the structure, size and angle measurement of real farming tools and its components, we obtained the basic data to complete 3D modeling. There were 2 frequently used methods for 3D modeling: entity modeling and fractal modeling. Through the analysis of physical characteristics of objects, different modeling methods were adopted to complete modeling. With its convenient and intelligent features, key frame animation has become the most basic computer animation technology. In order to achieve the final animation effect, combined with the characteristics of the 3D models of this platform, we adopted key frame animation technology to complete the animation. In order to achieve the intelligent display of scenes, we used 3D virtual roaming technology, and the scene roaming was divided into 2 modes, automatic mode and manual mode. The first way could browse the virtual scene automatically by using the virtual scene roaming algorithm for orientation changing that we have proposed, while the second provided user an opportunity to view the scenes manually through a virtual character. We adopted human-computer interaction technology by using the algorithm of model interactive control that we have proposed. And the interaction accuracy was favorable. Unity3D was utilized as the development software for the platform. The completed 3D models were imported into Unity3D project file with a file format of.FBX. Both the scene roaming and interactive function of the platform were achieved by coding C# scripts. The virtual scene that could show experiment results of the platform rendered a good effect. The research result showed that blended with roaming and controlling, the intelligent platform restored an ancient farming scene, which publicizes the typical production skills, greatly improves the practicability of the platform, and offers a kind of new method for culture exhibition. © 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","3D modeling; Control; Farms; Interactions; Unity 3D; Virtual reality; Virtual scene roaming","Animation; Beam plasma interactions; Behavioral research; Control; Exhibitions; Farms; Human computer interaction; Modeling languages; Virtual reality; 3-D (three-dimensional); 3-d modeling; Historical background; Intelligent displays; Interactive functions; Observation and measurement; Physical characteristics; Virtual scenes; Three dimensional computer graphics",2-s2.0-85017574579
"O'Connor D., Potler N.V., Kovacs M., Xu T., Ai L., Pellman J., Vanderwal T., Parra L.C., Cohen S., Ghosh S., Escalera J., Grant-Villegas N., Osman Y., Bui A., Cameron Craddock R., Milham M.P.","The healthy brain network serial scanning initiative: A resource for evaluating inter-individual differences and their reliabilities across scan conditions and sessions",2017,"GigaScience",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021859950&doi=10.1093%2fgigascience%2fgiw011&partnerID=40&md5=7cbeaf855ebef79e4fdc6fe516963d40","Background: Although typically measured during the resting state, a growing literature is illustrating the ability to map intrinsic connectivity with functional MRI during task and naturalistic viewing conditions. These paradigms are drawing excitement due to their greater tolerability in clinical and developing populations and because they enable a wider range of analyses (e.g., inter-subject correlations). To be clinically useful, the test-retest reliability of connectivity measured during these paradigms needs to be established. This resource provides data for evaluating test-retest reliability for full-brain connectivity patterns detected during each of four scan conditions that differ with respect to level of engagement (rest, abstract animations, movie clips, flanker task). Data are provided for 13 participants, each scanned in 12 sessions with 10 minutes for each scan of the four conditions. Diffusion kurtosis imaging data was also obtained at each session. Findings: Technical validation and demonstrative reliability analyses were carried out at the connection-level using the Intraclass Correlation Coefficient and at network-level representations of the data using the Image Intraclass Correlation Coefficient. Variation in intrinsic functional connectivity across sessions was generally found to be greater than that attributable to scan condition. Between-condition reliability was generally high, particularly for the frontoparietal and default networks. Between-session reliabilities obtained separately for the different scan conditions were comparable, though notably lower than between-condition reliabilities. Conclusions: This resource provides a test-bed for quantifying the reliability of connectivity indices across subjects, conditions and time. The resource can be used to compare and optimize different frameworks for measuring connectivity and data collection parameters such as scan length. Additionally, investigators can explore the unique perspectives of the brain's functional architecture offered by each of the scan conditions. © The Author 2017.","Data sharing; fMRI; Reliability","adult; connectome; dorsal attention network; female; frontoparietal cortex; functional connectivity; functional magnetic resonance imaging; human; human experiment; limbic cortex; male; neuroimaging; Note; phenotype; priority journal; quality control; test retest reliability; validation study; ventral attention network; visual cortex; adolescent; brain; brain mapping; cluster analysis; computer assisted diagnosis; connectome; image processing; individuality; middle aged; nuclear magnetic resonance imaging; physiology; procedures; questionnaire; reproducibility; software; three dimensional imaging; web browser; young adult; Adolescent; Adult; Brain; Brain Mapping; Cluster Analysis; Connectome; Female; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Individuality; Magnetic Resonance Imaging; Male; Middle Aged; Reproducibility of Results; Software; Surveys and Questionnaires; Web Browser; Young Adult",2-s2.0-85021859950
"Ye K., Woodcock J.","Model checking of state-rich formalism [InlineEquation not available: see fulltext.] by linking to CSP‖B",2017,"International Journal on Software Tools for Technology Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946104350&doi=10.1007%2fs10009-015-0402-1&partnerID=40&md5=a969bdc4f8be7e18a2f52f5045d19645","Since state-rich formalism [Figure not available: see fulltext.] is a combination of Z, CSP, refinement calculus and Dijkstra’s guarded commands, its model checking is intrinsically more complicated and difficult than that of individual state-based languages or process algebras. Current solutions translate executable constructs of [Figure not available: see fulltext.] programs to Java with JCSP, or translate them to CSP processes. Data aspects of [Figure not available: see fulltext.] programs are expressed in the Java programming language or as CSP processes. Both of them have disadvantages. This work presents a new approach to model-checking [Figure not available: see fulltext.] by linking it to CSP‖ B; then we utilise ProB to model-check and animate the CSP‖ B program. The most significant advantage of this approach is the direct mapping of the state part in [Figure not available: see fulltext.] to Z and finally to B, which maintains the high-level abstraction of data specification. In addition, introduction of deadlock, invariant violation checking, LTL formula checking and animation is another key advantage. We present our approach, a link definition for a subset of [Figure not available: see fulltext.] constructs, as well as a popular case study (reactive buffer) to show the practical usability of our work. We conclude with a discussion of related work, advantages and potential limitations of our approach and future work. © 2015, Springer-Verlag Berlin Heidelberg.","B; Buffer; CSP; CSP‖ B; Model checking; ProB; Z; [InlineEquation not available: see fulltext.]","Boron; Calculations; Computational linguistics; Computer programming; Computer software; Java programming language; Translation (languages); Buffer; CSP; ProB; Z; [InlineEquation not available: see fulltext.]; Model checking",2-s2.0-84946104350
"Liang D., Balz T., Wang Z., Wei L., Liao M.","Dynamic online visualization of PS-InSAR surface motion estimation results using WebGL",2017,"Remote Sensing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994667727&doi=10.1080%2f2150704X.2016.1235807&partnerID=40&md5=9f92a67709cb1eb84046d2435cead3e4","Persistent scatterer interferometry (PS-InSAR) is a common technique used in surface motion estimation. However, it is not easy to fully analyse the results, especially for non-experts. Due to the complexity of the formation of Persistent Scatterers (PS) points as well as the large difference in scale and time-series characteristics, it is necessary to develop new visualization methods for a better understanding and analysis of PS-InSAR data. In this article, we implement a dynamic online visualization for PS-InSAR surface motion estimation results using WebGL. A 3D interactive visualization method gives users vivid experiences with interactive operations so that they can easily observe scene details. Animation is used to show the development of surface motion over time as estimated using PS-InSAR, presenting results in an intuitive way through scientific visualization methods. Online visualization through our application makes PS-InSAR results accessible and relevant to dispersed users from diverse domains. © 2016 Informa UK Limited, trading as Taylor & Francis Group.",,"Data visualization; Three dimensional computer graphics; Time series analysis; Visualization; Estimation results; Interactive operations; Interactive visualizations; Online visualizations; Persistent scatterer interferometry (PSI); Persistent scatterers; Time series characteristic; Visualization method; Motion estimation; complexity; estimation method; interferometry; numerical method; remote sensing; synthetic aperture radar; visualization; World Wide Web",2-s2.0-84994667727
"Sakai T., Tamaki H., Ota Y., Tominaga H., Kusunoki F., Mizoguchi H.","Interactive objet d'art based on IoT technology",2017,"2016 14th International Conference on Control, Automation, Robotics and Vision, ICARCV 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015190159&doi=10.1109%2fICARCV.2016.7838748&partnerID=40&md5=6975eccb20ca5f9b356c2bb1b4d8295e","Applying Internet of Things (IoT) technology to art can open up new possibilities for the interaction between systems and humans. In this study, interaction between appreciators and fine art was realized using Ion technology. Raspberry Pi, a low-cost credit card-sized single-board computer, was used to enable appreciators to change animations displayed onscreen in fine art using physical movement. This paper reports on our realization of interaction between appreciators and objet d'art using IoT technology and describes a demonstration conducted via an exhibition that was open to the public. © 2016 IEEE.","animation; cyber-physical systems; fine art","Animation; Arts computing; Computer vision; Cyber Physical System; Embedded systems; Exhibitions; Robotics; Credit cards; Fine arts; Internet of Things (IOT); Low costs; Physical movements; Single board computers; Internet of things",2-s2.0-85015190159
"Petitprez P.-J., Kerrien E., Villard P.-F.","PoLAR: A Portable Library for Augmented Reality",2017,"Adjunct Proceedings of the 2016 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015216681&doi=10.1109%2fISMAR-Adjunct.2016.0081&partnerID=40&md5=312751c376d69e1211779410e248e9d5","We present here a novel cross-platform library to facilitate research and development applications dealing with augmented reality (AR). Features include 2D and 3D objects visualization and interaction, camera flow and image manipulation, and soft-body deformation. Our aim is to provide computer vision specialists' with tools to facilitate AR application development by providing easy and state of the art access to GUI creation, visualization and hardware management.We demonstrate both the simplicity and the efficiency of coding AR applications through three detailed examples. PoLAR can be downloaded at http://polar.inria.fr and is distributed under the GPL licence. © 2016 IEEE.","1.3.4 [Computer Graphics]: Graphics Utilities - Application packages; I.4.9 [Image Processing and Computer Vision]: Applications - [I.6.8]: Simulation and Modeling - Types of Simulation Animation","Augmented reality; Computer graphics; Computer hardware; Image processing; Three dimensional computer graphics; Visualization; AR application; Cross-platform; Image manipulation; Image processing and computer vision; Portable libraries; Research and development; Soft-bodies; State of the art; Computer vision",2-s2.0-85015216681
"Somova T.","Attitude guidance and simulation with animation of a land-survey satellite motion",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013649557&doi=10.1063%2f1.4972744&partnerID=40&md5=2723748334a777ccbb031fdaa7de55ff","We consider problems of synthesis of the vector spline attitude guidance laws for a land-survey satellite and an in-flight support of the satellite attitude control system with the use of computer animation of its motion. We have presented the results on the efficiency of the developed algorithms. © 2017 Author(s).",,,2-s2.0-85013649557
"Hong H.-J., Chuang J.-C., Hsu C.-H.","Animation rendering on multimedia fog computing platforms",2017,"Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012980528&doi=10.1109%2fCloudCom.2016.0060&partnerID=40&md5=ab8d882256ff4e00a519d2ebbfdd981f","Modern distributed multimedia applications are resource-hungry, and they often leverage on-demand cloud services to reduce their expenses. Existing cloud services deploy many servers in a few data centers, which consume a lot of electricity to power up and cold down, and thus are expensive and environmentally unfriendly. In this paper, we present a multimedia fog computing platform that utilizes resources from public crowds, edge networks, and data centers to serve distributed multimedia applications at lower costs. We use animation rendering as a case study, and identify several challenges for optimizing it on our multimedia fog computing platform. Among these challenges, we focus on the problem of predicting the completion time of each rendering job. We propose an efficient algorithm based on state-of-the-art machine learning algorithms. We also fine-tune the algorithm using multi-fold cross-validation for higher prediction accuracy. With real datasets, we conduct trace-driven simulations to quantify the performance of our prediction algorithm and that of the whole platform. The simulation results show that our proposed algorithm outperforms a state-of the-art statistical model in several aspects: Completed job ratio by 20%, makespan by 2 times, and normalized deviation by 30 times, on average. Moreover, the overall performance of the platform with our proposed algorithm is fairly close to that with an Oracle of the actual job completion time: A small factor of 1.48 in terms of makespan is observed. © 2016 IEEE.","animation rendering; Edge computing; fog computing; prediction; volunteer computing","Animation; Cloud computing; Distributed database systems; Fog; Forecasting; Learning algorithms; Learning systems; Multimedia services; Multimedia systems; Web services; Distributed multimedia; Edge computing; Multi-fold cross validation; Prediction accuracy; Prediction algorithms; Statistical modeling; Trace driven simulation; Volunteer computing; Distributed computer systems",2-s2.0-85012980528
"Li J., Zhang Y., Xu P., Lan S., Li S.","3D Personalized Face Modeling Based on KINECT2",2017,"Proceedings - 2016 9th International Symposium on Computational Intelligence and Design, ISCID 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013638879&doi=10.1109%2fISCID.2016.1052&partnerID=40&md5=e5f7ad891d010b9be83443afa1a128f8","As a challenging topic in computer graphics and computer vision, 3D face modeling has been applied in various fields including film and animation production, game development as well as medical analysis. In this paper, we mainly aims at face personalized modeling optimization based on KINECT2. The optimization of the scheme proposed is the mesh deformation based on the differential coordinates constrained by face++ feature points and facial muscle function, namely firstly by extracting the location of feature points on the color image and depth map to obtain the feature information of the personalized face, then aligning the intermediate results of the KINECT2 modeling to the feature information. It is good to keep the local grid differential property, at the same time. In this paper, the automatic UV mapping is realized by means of planar differential mesh deformation, which improves the accuracy and efficiency of manual adjustment of UV coordinates in Maya. The experimental results show that the optimization results are more fit in with the individual face. © 2016 IEEE.","3D face modeling; KINECT2; Mesh deformation; The differential coordinates","Animation; Artificial intelligence; Color computer graphics; Computer games; Computer graphics; Constrained optimization; Deformation; Mesh generation; 3-D face modeling; Differential coordinates; Differential properties; Feature information; Intermediate results; KINECT2; Mesh deformation; Personalized face modeling; Three dimensional computer graphics",2-s2.0-85013638879
"Ismail R., Ariyanto M., Caesarendra W., Nurmiranto A.","Development of robotic hand integrated with SimMechanics 3D animation",2017,"Proceeding - 2016 International Seminar on Intelligent Technology and Its Application, ISITIA 2016: Recent Trends in Intelligent Computational Technologies for Sustainable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016736149&doi=10.1109%2fISITIA.2016.7828733&partnerID=40&md5=99db11e900598c484d6b41e151e1e4b7","In this study, a robotic hand is developed using low cost material to meet the demand for prosthetic hand in Indonesia. It has five actuators utilizing five micro servo motors. The robot consists of three joints for index, middle, ring and little respectively and two joints for the thumb. The robotic hand movement is triggered using electromyography (EMG) sensor. The sensors read the information of muscle activities and send them to the microcontroller to drive the robotic hand. By using the same signal for opening and closing fingers, the three pattern grip is embedded in the robotic grip pattern. The patterns are power grip, hook and OK sign. The 3D CAD model of robotic hand is exported into SimMechanics First Generation. The 3D animation in SimMechanics First Generation is augmented to visualize the 3D virtual hand. Based on the experimental result, the robotic hand successfully shows three patterns grip motion driven by EMG sensor. The present roboctic hand is the initial model of the prosthetic hand. © 2016 IEEE.","3D animation; electromyography; robotic hand; SimMechanics","Animation; Computer aided design; Electromyography; End effectors; Joint prostheses; Prosthetics; Robotic arms; 3D animation; 3D CAD Modeling; Hand movement; Muscle activities; Prosthetic hands; Robotic grips; SimMechanics; Virtual hand; Robotics",2-s2.0-85016736149
"Gao H., Zhang L., Ding W., Hao F., Zhou Y.","Physical animation simulation of robot kit",2017,"M2VIP 2016 - Proceedings of 23rd International Conference on Mechatronics and Machine Vision in Practice",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015186273&doi=10.1109%2fM2VIP.2016.7827313&partnerID=40&md5=f80b55a92ac43551401f4d1d2b9b8277","A robot simulator integrating robot assembly, program design and animation simulation is developed and its physical simulation method is mainly studied. To simulate the real world and robotic behavior, architecture of physical animation simulation is built and multi-body dynamics theory including unilateral constraints is applied to physical interaction. A complementarity-based method is proposed to model unilateral constraints, and this method can deal with dependent contacts and coulomb friction as well as non-elastic impulse. In order to solve the multi-body dynamics equations with unilateral constraints effectively, the mixed nonlinear complementary equations are converted into linear complementary equations by eliminating all of the equality constraints and linearizing friction law. Moreover, a direct correction algorithm is established to avoid drift phenomena. Finally, physical animation simulation is applied and gets a good effect. © 2016 IEEE.","Animation simulation; Multi-body dynamics; robot kit","Animation; Friction; Machine design; Mechanics; Nonlinear equations; Robots; Correction algorithms; Equality constraints; Linear complementary equation; Multi-body dynamic; Physical interactions; Physical simulation; Simulation of robots; Unilateral constraints; Computer vision",2-s2.0-85015186273
"Akinjala T.B., Agada R., Yan J.","Animating human movement & gestures on an agent using Microsoft kinect",2017,"Proceedings - 2016 IEEE International Symposium on Multimedia, ISM 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015177735&doi=10.1109%2fISM.2016.3&partnerID=40&md5=6a6323782f1ab54cafd9b3e3d71afc4e","It is used in different places for different functions for different reasons using different methods. With increasing use of animations, there is a need for an efficient method of animating human movements. Human movement involves a lot of complicated animations and as such, there are different methods out there for animating this movement. With the increase in development of projects like animated movies, animated advertisement, animated instructional agents, and video games, the need for an accurate method of transferring complex human motions onto a 3D model has also increased. The animated virtual commentator can enhance the cyber defense competition experience in several important ways. It will provide a remarkable communication instrument to the human computer interface. The project leveraged latestgeneration techniques in cost effective motion capturing hardware and software, character modeling and rigging, and animation. © 2016 IEEE.",,"Animation; Cost effectiveness; Education computing; Human computer interaction; Network security; Character modeling; Cost effective; Cyber defense; Hardware and software; Human computer interfaces; Human movements; Microsoft kinect; Motion capturing; Three dimensional computer graphics",2-s2.0-85015177735
"Abdullah S.C., Jusoh M.A.M., Nawi N.M., Amari M.D.","Robot arm simulation using 3D software application with 3D modeling, programming and simulation support",2017,"2016 International Symposium on Micro-NanoMechatronics and Human Science, MHS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013649709&doi=10.1109%2fMHS.2016.7824231&partnerID=40&md5=f3b619eb1e3d91f715a603185f8d7e53","This paper present a new robotics simulator, completely based on Blender 3D and Python as scripting language. The simulation of robot works smoothly with six degree of freedom implemented within it, as the end effector starts to pick the object and to place it, all the links shown their rotation which definitely shown the movement mimics the real movement of robotic arm. The simulation was done with key frame animation and game engine simulation and comparison made relatively to the result obtained. © 2016 IEEE.",,"Animation; Application programs; Blending; Computer programming; Degrees of freedom (mechanics); End effectors; Robot programming; Robotic arms; Robotics; Social sciences; Three dimensional computer graphics; 3-d modeling; Game Engine; Key frames; Robot arms; Scripting languages; Simulation of robots; Six degree-of-freedom; Software applications; Computer software",2-s2.0-85013649709
"Troy, Pranowo, Gunanto S.G.","2D to 3D space transformation for facial animation based on marker data",2017,"Proceedings - 2016 6th International Annual Engineering Seminar, InAES 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015042570&doi=10.1109%2fINAES.2016.7821896&partnerID=40&md5=4b83e6dc36aff13c7b22b6ddff01ffe1","Computer facial animation aims to create an animated character expression as natural as possible as well as human facial expressions. Using the data marker catches facial motion capture, will be determined the location of the feature points of 3D face models to follow the motion of the marker points of human faces. To overcome the morphological differences between the face of the source with the character's face, then applied with radial basis retargeting process mapping so that the character's face can still display the natural expression. Using the data marker 2D, Radial Basis Function (RBF) transformation was applied to determine the position of the feature points on the 3D face models. RBF space transformation has good ability in determining the appropriate facial motion marker points on a human face to the character's face. Motion that occurs in 3D face models is scaled according to the relative scale between the source and the target. © 2016 IEEE.","facial animation; marker data; radial basis function","Animation; Functions; Radial basis function networks; Technical presentations; Animated characters; Facial animation; Facial motion capture; Human facial expressions; marker data; Radial Basis Function(RBF); Radial basis functions; Space transformations; Metadata",2-s2.0-85015042570
"Yu J., Wang Z.","A realistic and reliable 3D pronunciation visualization instruction system for computer-assisted language learning",2017,"Proceedings - 2016 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013231185&doi=10.1109%2fBIBM.2016.7822623&partnerID=40&md5=55289983a029f079ba09e5ec14cc1ab5","A text-driven 3D pronunciation visualization instruction system is proposed for computer-assisted language learning. Based on a 3D articulatory mesh model including appearance and internal articulators, both finite element method and anatomical model are used to synthesize the articulatory animation of phonemes by fitting the mesh model to the detected articulatory shapes in X-ray images. Visual co-articulation is modeled with a Hidden Markov Model trained on an articulatory speech corpus. Articulatory animations corresponding to all phonemes of a learned text are concatenated by visual co-articulation model to produce the speech synchronized articulatory animation. The experiments for Mandarin Chinese show the system can increase the pronunciation accuracy of learners. © 2016 IEEE.","Articulatory animation; Language learning","Animation; Bioinformatics; Computer aided instruction; Computer graphics; Finite element method; Hidden Markov models; Linguistics; Markov processes; Mesh generation; Three dimensional computer graphics; Visualization; Anatomical modeling; Co-articulation; Computer assisted language learning; Instruction system; Language learning; Mandarin Chinese; Speech corpora; X-ray image; E-learning",2-s2.0-85013231185
"Rahayu E.S., Permanasari A.E., Mahaseng K.M.","Improvement in learning coordinate systems topic for Electrical Engineering students using Interactive Multimedia",2017,"Proceedings - 2016 6th International Annual Engineering Seminar, InAES 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015001650&doi=10.1109%2fINAES.2016.7821912&partnerID=40&md5=0849ad0b0fb1a06f2ee929356b2b1d70","Coordinate system is a basic topic in engineering students in our department. Some advance subjects use this topic as the basic knowledge for analysis both electrical and information technology study programs, such as electromagnetism and computer vision. Main function of them is to represent such a position of a matter in space. In delivering this topic, some problems came up when it was presented by conventional method of teaching, such as by explaining it on a whiteboard or using presentation slides. Text font was limited related to the size of classroom. Steps of drawing the coordinate systems were not clear when it was only explained in one slide without any animations. By developing this topic in interactive multimedia, the teaching method can be improved using one of existing e-learning system in our university, called eLisa, which is not limited by time, distance, and also can overcome those mentioned problems due to this simple and clear visualization of Cartesian, Cylindrical, and Spherical Coordinate Systems. This research is conducted to investigate the benefit of the developed multimedia to improve knowledge of students about the topic. This investigation used t-Test to find the significance improvement of learning the topics using this interactive multimedia by doing a hands on quiz and walkthru method to find the multimedia in eLisa. The result showed that by learning it in 15 minutes, the knowledge of students was improved based on data scores of quiz as a measurement instruments. © 2016 IEEE.","coordinate systems; e-lisa; hands on; interactive multimedia; t-Test; walkthru","Education; Interactive computer systems; Multimedia systems; Teaching; Technical presentations; Co-ordinate system; hands on; Interactive multimedia; T-tests; walkthru; Students",2-s2.0-85015001650
"Miwa K., Nomura J., Takakuwa S.","Module-based modeling and analysis of a manufacturing system adopting a dual-card kanban system with a delivery cycle",2017,"Proceedings - Winter Simulation Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014239664&doi=10.1109%2fWSC.2016.7822319&partnerID=40&md5=8e11c326dfc0bd06dcabb9813084689d","A systematic procedure for module-based modeling is designed and proposed to simulate of any multistage manufacturing flow type system adopting a dual-card kanban system with a delivery cycle. First, a functional analysis was performed to present kanban flows in exactly the same fashion in a simulation model as they actually appear in a real manufacturing system. One shipping area module, the required number of parts store modules, and one supplier center module were used to develop a designated simulation. Proposed modules have focused dialogs, animation, and modeling functionality. In addition, a procedure to obtain the necessity minimum number of kanbans to achieve no stock-out events is proposed. Then, a numerical example is shown to apply the proposed procedure. © 2016 IEEE.",,"Computer simulation; KANBAN system; Kanbans; Model and analysis; Module-based; Multistage manufacturing; Simulation model; Stock-out; Manufacture",2-s2.0-85014239664
"Cortes-Davalos A., Mendoza S.","Collaborative Web Authoring of 3D Surfaces Using Augmented Reality on Mobile Devices",2017,"Proceedings - 2016 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013080190&doi=10.1109%2fWI.2016.0113&partnerID=40&md5=9cbaf5bea8b8e99c0003ac34983c8671","3D Surfaces are widely employed to model geometric assets (e.g., mountains on a landscape), which are used in digital animations and video games. A single surface commonly needs to be created and modified by a group of collaborators, but most of the 3D content creation applications are essentially single-user. In addition, such surfaces are visualized in 2D projections, causing confusion to new users, when imagining their shape in 3D. In this paper, we propose a novel approach based on Augmented Reality (AR) to the task of collaboratively authoring surfaces on the Web using mobile devices. We rely on AR technology to help collaborators to easily understand the shape of the surface's 3D representation, and we provide them with the basic authoring tools to intuitively modify its shape. To support real time face-To-face interaction, we implement an object sharing scheme, which according to our results is enough in practice. In this way, our approach is able to create a new online collaborative setting in which a group of collocated participants, each one using a mobile device, or connected to the Web, can concurrently modify a surface, while visualizing it in their own real environment through AR. © 2016 IEEE.","Augmented Reality Applications; Object Sharing Scheme; Real-Time Face to Face Collaboration; Web Authoring of 3D Surfaces","Animation; Augmented reality; Mobile devices; 3d representations; 3D surface; Augmented reality applications; Collaborative settings; Collaborative webs; Face to face; Face-to-face interaction; Sharing schemes; Three dimensional computer graphics",2-s2.0-85013080190
"Wang Y., Li E., Wang F., Xu B.","A virtual character learns to defend himself in sword fighting based on Q-Network",2017,"Proceedings - 2016 IEEE 28th International Conference on Tools with Artificial Intelligence, ICTAI 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013627642&doi=10.1109%2fICTAI.2016.49&partnerID=40&md5=89eb480bd2b82cd8b7ddbf47293e1162","In this paper, we create a virtual character that interacts with human player in a sword-fighting task. The data taken from a human player waving a stick as the 'sword' is mapped into the virtual environment; and the result of the collision detection during the virtual interaction is used as a reward for the reinforcement learning.We train a Q-network that animates the virtual character by rotating its joints toward the blocking the incoming attacks in each individual frame base on the current state. The trained virtual character makes quick and accurate blockings to 'sword' attacks coming in various forms. Further, a human-body dynamic model is used to predict the movements of the task irrelevant joints of the virtual character to create a more human like behavior. Experiment results demonstrate that this method can inspirit a virtual character with an automatic, human-like animation that interacts with human player in real time. © 2016 IEEE.","Character animation; Human-computer interaction; Q-network; Reinforcement learning","Animation; Artificial intelligence; Behavioral research; Human computer interaction; Reinforcement learning; Character animation; Collision detection; Human body dynamics; Human like; Human players; Sword-fighting; Virtual character; Virtual interactions; Virtual reality",2-s2.0-85013627642
"Choi K.-S., Chan S.-T., Leung C.H.-M., Chui Y.-P.","Stereoscopic Three-Dimensional Visualization for Immersive and Intuitive Anatomy Learning",2017,"Proceedings - IEEE 8th International Conference on Technology for Education, T4E 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013270386&doi=10.1109%2fT4E.2016.046&partnerID=40&md5=d1cdca997aefe57604d655fc1b4a0595","Conventional anatomy education makes use of twodimensional (2D) images of three-dimensional (3D) anatomical objects to illustrate their spatial locations and interrelationships. Good visual-spatial ability is needed to mentally transform or fuse multiple images that are required to understand a concept. While animations and videos are developed for anatomy learning, the presentation of 3D anatomical objects on 2D planar computer screen does not render the depth perception necessary for intuitive understanding of the spatial details and subtlety. To enhance anatomy education, a stereoscopic 3D visualization system is proposed in this paper. Depth perception is naturally rendered using active stereo technology to create an immersive learning environment which allows students to directly interact with and explore the virtual anatomical objects. In addition to translation, rotation, zooming in and out, the body parts are modeled as multi-layer objects so that the outer layers can be set to semi-transparent to expose the inner layers, while the associations between the inner and outer layers can also be depicted. A pilot study is conducted to evaluate the system usability and user interface of the proposed stereoscopic 3D visualization system. The response of the 14 healthcare students who participate in the study is positive. They appreciate the intuitiveness and flexibility offered by the system, which can facilitate anatomy learning. Feedbacks are collected to further improve the system. © 2016 IEEE.","anatomy education; computer-assisted learning; immersive virtual reality; stereo vision; visual-spatial ability","Depth perception; E-learning; Education; Rendering (computer graphics); Stereo image processing; Stereo vision; Students; Three dimensional computer graphics; User interfaces; Virtual reality; Visualization; Anatomy educations; Computer assisted learning; Immersive virtual reality; Intuitive understanding; Stereoscopic 3D visualization; Three dimensional visualization; Two-dimensional (2D) images; Visual-spatial abilities; Computer aided instruction",2-s2.0-85013270386
"Silva D.F.E., Berndt I., Torchelsen R.P., Maciel A.","A levels-of-precision approach for simulating multiple physics-based soft tissues",2017,"Proceedings - 2016 29th SIBGRAPI Conference on Graphics, Patterns and Images, SIBGRAPI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013746237&doi=10.1109%2fSIBGRAPI.2016.011&partnerID=40&md5=693250cfa3b66c1568b82f6ecf3bbfb3","Computer simulation of surgical environments is always oversimplified in terms of physical behavior due to the complexity of the tissues and interactions involved, which cannot be fully simulated in real time. To better manage this trade-off between efficiency and effectiveness, we present a hybrid and adaptive environment that combines a set of methods to achieve higher accuracy and performance. Our approach merges physics-based deformation methods (Finite Elements and Mass Spring) with a non-physical method (Green Coordinates) to approximate more coarsely the behavior when the focus of the interaction is away, and more precisely during direct interaction. We experimentally demonstrate that the computational complexity of the simulation with our method does not increase with the number of objects being simulated. With our approach, a virtual surgery environment with many dynamic organs can be computed at interactive rates for the first time. © 2016 IEEE.","computer animation; finite element method; green coordinates; haptic feedback; heat diffusion; mass-spring; minimally invasive surgery; physics-based animation","Animation; Economic and social effects; Green computing; Haptic interfaces; Histology; Surgery; Tissue; Tissue engineering; Computer animation; green coordinates; Haptic feedbacks; Heat diffusions; Mass-spring; Minimally invasive surgery; Physics-based animation; Finite element method",2-s2.0-85013746237
"Coutinho J., Marques B.A.D., Gois J.P.","Puppeteering 2.5D models",2017,"Proceedings - 2016 29th SIBGRAPI Conference on Graphics, Patterns and Images, SIBGRAPI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013861753&doi=10.1109%2fSIBGRAPI.2016.010&partnerID=40&md5=e913976100f5e2f3a9f6e22bc857d11b","A laborious task for animators is the redrawing of 2D models for each new required view or pose. As a consequence, several applications have been proposed to make this task easier. A successful approach is the Cartoon 2.5D Models. Its goal is the automatic computation of new views - by the simulation of 3D global rotation - from user-provided 2D models. However, previous work of 2.5D Models does not have support to calculate new poses efficiently, i.e., the user redraws the input views again in the new pose. We present a novel approach that allows the user to produce both new views and new poses easily for the 2.5D Models, thus puppeteering the 2.5D Models. It makes use of a hierarchical bone structure that explores the methodology of the 2.5D Models, ensuring coherence between the bone structure and the model. The usability of the present approach is intuitive for users acquainted with previous 2.5D Modeling tools. © 2016 IEEE.","cartoon modeling; computer animation; geometric transformations; vector-art drawing","Bone; Mathematical transformations; 2-D model; Automatic computations; Bone structure; Computer animation; Geometric transformations; Global rotation; Modeling tool; Animation",2-s2.0-85013861753
"Arellano D., Rauh R., Krautheim B., Spicker M., Schaller U.M., Helzle V., Deussen O.","Interactive testbed for research in autism—the SARA project",2017,"Universal Access in the Information Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008430073&doi=10.1007%2fs10209-016-0521-9&partnerID=40&md5=b34fa15c1efd019f1becb724db5b903d","The project Stylized Animations for Research on Autism (SARA) aims to develop a better understanding of the cognitive processes behind emotional categorization in children and adolescents with high-functioning autism spectrum disorder (ASD), in comparison with neurotypically developed peers. To this end, we combine novel real-time non-photorealistic rendering (NPR) algorithms, emotional facial animations, and eye-tracking technologies in a framework that serves as an interactive testbed for empirical research. In this paper, we focus on three experiments that: (1) validate real-time facial animations of virtual characters, (2) evaluate the NPR algorithms to create abstracted facial expressions, and (3) elucidate the relation between eye gaze behavior, ASD and alexithymia (i.e., difficulties in expressing ones emotions). The results show that our animations can be used in the proposed experiments; however, more evaluation is needed regarding the NPR abstractions, especially with individuals with ASD. Finally, even though no correlation was found between gaze behavior, ASD and alexithymia, the study opened several questions that will be addressed in future work. © 2017 Springer-Verlag Berlin Heidelberg","Autism spectrum disorder; Eye tracking; Facial animation; Stylization","Abstracting; Computer graphics; Testbeds; Autism spectrum disorders; Children and adolescents; Empirical research; Eye tracking technologies; Eye-tracking; Facial animation; Real-time non-photorealistic rendering; Stylization; Diseases",2-s2.0-85008430073
"Mokhtar S.A., Anuar S.S.S., Anuar S.M.S.","Web-based application for learning Malaysian sign language",2017,"Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication, IMCOM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015216954&doi=10.1145%2f3022227.3022235&partnerID=40&md5=69c30bfc509b66f2de388bf282d7fa2c","Malaysian Sign Language is the native language for the deaf people in Malaysia. However, there is still a lack of web resources available to the public to facilitate the learning of the language. To overcome this problem, a research initiative has been undertaken in developing a web-based learning application for Malaysian Sign Language. The design and development of the web application covers two aspects: the content and the application modules. The web application incorporates 2-D animation and utilises open source technologies. The modules developed includes sign language representation of 200 words or more, letters of the alphabet, numbers, fingerspelling with userdefined words, and formation of user-defined sentences. In addition, fingerspellings and external videos was built into the web application. Within one year of publishing the web application to the World Wide Web, the web application has attracted more than 17,000 visitors. In terms of search engine ranking, the web application is currently the top ranked web site for Malaysian Sign Language. User evaluation conducted on users found that more than 90% of the respondents gave positive response to the functionalities and elements offered by the web application. © 2017 ACM.","Animation; Deaf; Learning application; Malaysia; Sign Language; Web application","Animation; Computer aided instruction; Information management; Search engines; Web services; Websites; Deaf; Design and Development; Malaysia; Open-source technology; Research initiatives; Sign language; WEB application; Web-based applications; E-learning",2-s2.0-85015216954
"Prihodko A.L., Lukoyanov A.V., Grif M.G.","Approach to the analysis and synthesis of the sign language",2017,"2016 13th International Scientific-Technical Conference on Actual Problems of Electronic Instrument Engineering, APEIE 2016 - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020730483&doi=10.1109%2fAPEIE.2016.7806403&partnerID=40&md5=51827118dcae1ef0b8031be5b4d371e9","The article discusses various approaches to demonstrating, training, application and study Russian sign language (RSL). The most well-known projects on development of computer translation RSL. It raised the basic problems of RSL and analyses various approaches to their solution, including the problem of linguistic text analysis. The author proposer the way of solving some of these problem. Comparing different notations of RSL the key factors and differences are found. The articles dive examples of such notations as Dimksim, SignWriter and HamNoSys, briefly considers the specificity of each of them, and shows how to work with them. It provides a way to convert sign language notation in the clip raises the problem of the inverse transform, gives examples, which show the parsing of some aspects of the RSL, as well as examples of how to transforming the notation in the clip using various libraries RSL. In the same way is an example of converting an animation clip in the notation element is given. The analysis and synthesis of the RSL in different variations is also considered. © 2016 IEEE.","gesture recognition; Human-computer interaction; manual alphabet; notation; Sign language","Electronics industry; Gesture recognition; Human computer interaction; Inverse transforms; Analysis and synthesis; manual alphabet; notation; Sign language; Text analysis; Inverse problems",2-s2.0-85020730483
"Gilanyi A., Merentes N., Quintero R.","Mathability and an animation related to a convex-like property",2017,"7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011044654&doi=10.1109%2fCogInfoCom.2016.7804553&partnerID=40&md5=06ee9c0927f64fb225c64a4bf44cf5c6","In connection with investigations related to mathability and to applications of computer assisted methods for studying mathematical problems, an animation of the m-convex hull of finite sets of points on the Cartesian plane is presented. © 2016 IEEE.","Animation; Cognitive Infocommunications; Computer Assisted Methods; Convexity; m-Convexity; Mathability","Cognitive infocommunications; Computer-assisted methods; Convexity; m-Convexity; Mathability; Animation",2-s2.0-85011044654
"Gilanyi A., Merentes N., Quintero R.","Presentation of an animation of the m-convex hull of sets",2017,"7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011048617&doi=10.1109%2fCogInfoCom.2016.7804566&partnerID=40&md5=dbb4fb17bbe8a57a2fb8b6f9d7506795","In this paper, we present an animation developed in the Wolfram Mathematica System for the visualization of the m-convex hull of sets containing finitely many points on the Cartesian plane. © 2016 IEEE.","Animation; Computer Assisted Methods; Convexity; m-convexity; Mathability","Computational geometry; Cartesian plane; Computer-assisted methods; Convex hull; Convexity; m-convexity; Mathability; Mathematica; Animation",2-s2.0-85011048617
"López-Colino F., Colás J., Garrido J.","Full Skeleton-based Virtual Human Animation: An Improved Design for SL Avatars",2017,"IETE Technical Review (Institution of Electronics and Telecommunication Engineers, India)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026849809&doi=10.1080%2f02564602.2016.1141075&partnerID=40&md5=bdd140590b032a2b5521c9748e196e22","This paper presents a novel skeleton design for avatar animation. This design includes new bones, whose purpose is to meet the requirements of sign language (SL) synthesis. SL synthesis presents particular challenges regarding the processing of phonetic descriptions of signs to create animations. Although traditional animation techniques have solved the synthesis of signs, the proposed skeleton design allows for the simplification of the phonetic processing, the inverse kinematics calculations, and the collision avoidance processes. The proposed design has been tested to demonstrate that the generated animations have the same quality as the ones produced with state-of-the-art techniques. Importantly, the proposed structure reduces the time required for generating an animation by 52% compared to existing solutions and requires less storage resources. © 2017 IETE.","Animation; Avatar; Computer graphics; Graphical user Interfaces; Sign language; Software performance","Computer graphics; Graphical user interfaces; Inverse kinematics; Linguistics; Musculoskeletal system; User interfaces; Virtual reality; Avatar; Improved designs; Sign language; Skeleton designs; Software performance; State-of-the-art techniques; Storage resources; Traditional animations; Animation",2-s2.0-85026849809
"Liu B.","Computer animation production technology for practical application",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020843938&partnerID=40&md5=f7188a167a09a0685a7f2dfccb6f7bdc","Computer animation technology has been widely used in various fields, but the computer animation has been unable to meet the growing needs of people. So in this paper, the research of computer animation production technology for practical application was put forward and the development of animation technology in our country was explained, and the analysis and research on the technology of computer animation which is opposite to the practical application were made. Through the analysis of survey data, we confirmed that the computer animation technology for practical application has high speed, good effects and low cost, which brings a different visual experience for the audience and is recognized by the majority of the audience.","Animation production; Computer; Practical application; Technology research","Agronomy; Computers; Food technology; Computer animation; High Speed; Low costs; Production technology; Survey data; Technology research; Visual experiences; Animation",2-s2.0-85020843938
"Zhao H.","Exploration of the influence of computer digital animation technology on film style",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020508984&partnerID=40&md5=06aca0f5b8ac202c7dfe129cda3a8098","With the information age, the movie industry has become more popular and developed rapidly. From the perspective of film industry development, film language, writing techniques, and technical means have different forms of expression in different periods. The film industry will face more challenges in the information age. In the new era, the film industry needs to absorb more and better elements and constantly innovate to face these challenges and achieve a breakthrough in the arts. The main factor affecting film development is the technical means. However, as a product of the information age, the influence of computer digital animation technology is also far-reaching. The influence of computer digital animation technology on film style was analyzed in the present paper.","Computer; Digital animation technology; Movie style","Agronomy; Computers; Food technology; Film development; Film industry; Information age; Movie industry; Movie style; Animation",2-s2.0-85020508984
"Teng M.","Research on the application of computer digital technology in 2D animation design",2017,"Revista de la Facultad de Ingenieria",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029589014&partnerID=40&md5=ab2f01e15c7b730355fd7a39aced401e","In this paper, the author discusses the application of computer digital technology in 2D animation design. This paper introduces the status quos and development tendency of current animation industry at home and abroad, and analyses the differences between two-dimensional animation and three-dimensional animation, the advantages of digital technology of two-dimensional animation and its core production process, relative technology, artistry and applications. This paper, taking the project material world as its case, illustrates the importance of the pre-script, role design, scene design and sub-lens design of two-dimensional animation, and it accomplishes the role design and production, scene production, the movement of background lens, the production of role key frame, the midcults in role motion, path animation, layered processing and the shearing and composition of digital technology in this project by using digital software. The experiment result shows the proposed method can improve the overall performance for the system.","2D Animation Design; Application; Computer Digital Technology","Applications; Earth sciences; Engineering; 2D animation; Core production; Development tendency; Digital technologies; Lens designs; Material world; Scene designs; Three-dimensional animations; Animation",2-s2.0-85029589014
"Minxia P., Jun L.","Research on the construction of animation design training room based on computer platform",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020502703&partnerID=40&md5=55ebb2a87da9db6ec3784498575df661","At present, the rapid development of the cartoon market in China has led to the cartoon boom batch after batch, which has made the animation industry become one of the most potential industries in the 21st century, and at the same time, it has also become a new growth point of China's national economy. Animation design and production major is an animation talent cultivation base, its development will directly affect China's animation industry and even the development of the entire cultural industry, therefore, its importance is self-evident. At present, in China, there are many problems in the cultivation of animation talents in all kinds of colleges and universities, which restrict the overall development of animation industry in our country. So it is necessary to further explore the teaching method which is more suitable for animation major. In this paper, a university in Guangxi was taken as an example, and the current situations and existing problems of the animation design and production major in this college were analyzed, then, the feasibility of establishing the training room of animation design based on computer platform was analyzed, furthermore, according to combine with the previous research experience, a construction scheme of the animation design training room which was suitable for a certain college in Guangxi was put forward. According to research the construction scheme of animation design training room based on computer platform, some development ideas were provided for our country's training teaching mode of animation major, at the same time, a solid foundation for the future development of the cartoon market in China was laid.","Animation major; Personnel training; Teaching mode","Commerce; Personnel training; Colleges and universities; Computer platforms; Construction scheme; Cultural industries; Potential industries; Research experience; Talent cultivations; Teaching modes; Animation",2-s2.0-85020502703
"Balzarini V., Taborsky M., Villa F., Frommen J.G.","Computer animations of color markings reveal the function of visual threat signals in Neolamprologus pulcher",2017,"Current Zoology",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014836029&doi=10.1093%2fcz%2fzow086&partnerID=40&md5=3d6024256f31903f63a468fa77d1ac43","Visual signals, including changes in coloration and color patterns, are frequently used by animals to convey information. During contests, body coloration and its changes can be used to assess an opponent's state or motivation. Communication of aggressive propensity is particularly important in group-living animals with a stable dominance hierarchy, as the outcome of aggressive interactions determines the social rank of group members. Neolamprologus pulcher is a cooperatively breeding cichlid showing frequent within-group aggression. Both sexes exhibit two vertical black stripes on the operculum that vary naturally in shape and darkness. During frontal threat displays these patterns are actively exposed to the opponent, suggesting a signaling function. To investigate the role of operculum stripes during contests we manipulated their darkness in computer animated pictures of the fish. We recorded the responses in behavior and stripe darkness of test subjects to which these animated pictures were presented. Individuals with initially darker stripes were more aggressive against the animations and showed more operculum threat displays. Operculum stripes of test subjects became darker after exposure to an animation exhibiting a pale operculum than after exposure to a dark operculum animation, highlighting the role of the darkness of this color pattern in opponent assessment. We conclude that (i) the black stripes on the operculum of N. pulcher are a reliable signal of aggression and dominance, (ii) these markings play an important role in opponent assessment, and (iii) 2D computer animations are well suited to elicit biologically meaningful short-term aggressive responses in this widely used model system of social evolution. © The Author (2016).","Aggression; Agonistic behavior; Animated pictures; Cichlid fish; Communication; Cooperation; Social; Threat display",,2-s2.0-85014836029
"Ni N.","Application of intelligent optimization algorithm on group animation design",2017,"Revista de la Facultad de Ingenieria",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032821581&partnerID=40&md5=f85086c08c104a4123da2f58f4dc9875","Group animation is an important field of computer applications. Due to the complexity of controlling group behavior, group animation is still a challenging research work in computer animation. This paper introduces the characteristics and basic principles of group animation. The use of social learning mechanism in the convergence and divergence behavior has been improved. In order to study the use of improved algorithm for the role of the movement path planning and design, the resulting path data provides the tools to complete the production of group animation. In the production of group animation the application of intelligent algorithm breaks the limitations of traditional animation. It enhances the authenticity of the movement and improves the creative efficiency.","Artificial fish swarm algorithm; Collision detection; Group animation; Intelligent optimization algorithm","Animation; Motion planning; Animation designs; Artificial fish swarm algorithms; Collision detection; Computer animation; Intelligent Algorithms; Intelligent optimization algorithm; Planning and design; Traditional animations; Optimization",2-s2.0-85032821581
"Filhol M., McDonald J., Wolfe R.","Synthesizing sign language by connecting linguistically structured descriptions to a multi-track animation system",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025125881&doi=10.1007%2f978-3-319-58703-5_3&partnerID=40&md5=acf99a8917c311fd834a20b1fea2ed27","Animating sign language requires both a model of the structure of the target language and a computer animation system capable of producing the resulting avatar motion. On the language modelling side, AZee proposes a methodology and formal description mechanism to build grammars of Sign languages. It has mostly assumed the existence of an avatar capable of rendering its low-level articulation specifications. On the computer animation side, the Paula animator system proposes a multi-track SL generation platform designed for realism of movements, programmed from its birth to be driven by linguistic input. This paper presents a system architecture making use of the advantages of the two research efforts that have matured in recent years to the point where a connection is now possible. This paper describes the essence of both systems and describes the foundations of a connected system, resulting in a full process from abstract linguistic input straight to animated video. The main contribution is in addressing the trade-off between coarser natural-looking segments and composition of linguistically relevant atoms. © Springer International Publishing AG 2017.","Avatar; Computational linguistics; Computer animation; Sign language","Animation; Computational linguistics; Linguistics; Modeling languages; Animation systems; Avatar; Computer animation; Connected systems; Formal Description; Language modelling; Sign language; System architectures; Human computer interaction",2-s2.0-85025125881
"Cui J., Popescu V., Adamo-Villani N., Wagner Cook S., Duggan K.A., Friedman H.S.","Animation stimuli system for research on instructor gestures in education",2017,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028839086&doi=10.1109%2fMCG.2017.3271471&partnerID=40&md5=d1a982c5b2655c177bfa8b91c0c12d36","Education research has shown that instructor gestures can help capture, maintain, and direct the student's attention during a lecture as well as enhance learning and retention. Traditional education research on instructor gestures relies on video stimuli, which are time consuming to produce, especially when gesture precision and consistency across conditions are strictly enforced. The proposed system allows users to efficiently create accurate and effective stimuli for complex studies on gesture, without the need for computer animation expertise or artist talent. © 1981-2012 IEEE.","CAI; computer graphics; computer-assisted instruction; computers and education","Animation; Computer graphics; Education; Computer animation; Computer Assisted Instruction; Computers and education; Education research; Enhance learning; Stimuli systems; Traditional educations; Computer aided instruction",2-s2.0-85028839086
"Corda F.","A skeleton/cage hybrid paradigm for digital animation",2017,"CEUR Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029165605&partnerID=40&md5=db8d9ad79400ebb4de6d8422d92a4961","Digital animators require simple tools and techniques that allow them to create computer animations in an easy, fast and intuitive way. To perform this kind of task, several methods are available, like cagebased or skeleton-based skinning. Cages and skeletons allow animators to define mesh deformation in order to obtain a character pose. Both of them have different pros and cons, and different expressive power. We aim to create a new skinning technique using a skeleton/cage hybrid paradigm that merges together the expressive power of both of them, reducing the complexity of pose definition and making the animation pipeline more simple, intuitive and straightforward.",,"Musculoskeletal system; Animation pipeline; Computer animation; Expressive power; Hybrid paradigm; Mesh deformation; Tools and techniques; Animation",2-s2.0-85029165605
"Rumman N.A., Fratarcangeli M.","Skin deformation methods for interactive character animation",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028328225&doi=10.1007%2f978-3-319-64870-5_8&partnerID=40&md5=335cf1c71197a2ead07df1ad8349bc56","Character animation is a vital component of contemporary computer games, animated feature films and virtual reality applications. The problem of creating appealing character animation can best be described by the title of the animation bible: “The Illusion of Life”. The focus is not on completing a given motion task, but more importantly on how this motion task is performed by the character. This does not necessarily require realistic behavior, but behavior that is believable. This of course includes the skin deformations when the character is moving. In this paper, we focus on the existing research in the area of skin deformation, ranging from skeleton-based deformation and volume preserving techniques to physically based skinning methods. We also summarize the recent contributions in deformable and soft body simulations for articulated characters, and discuss various geometric and example-based approaches. © Springer International Publishing AG 2017.","Character animation; Deformation; Physics-based animation; Skeleton-based animation; Skinning; Volume-preserving","Computer games; Computer graphics; Computer vision; Deformation; Motion pictures; Musculoskeletal system; Virtual reality; Based animations; Character animation; Physics-based animation; Skinning; Volume-preserving; Animation",2-s2.0-85028328225
"Rusli M., Negara I.K.R.Y.","The effect of animation in multimedia computer-based learning and learning style to the learning results",2017,"Turkish Online Journal of Distance Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030696589&partnerID=40&md5=59eb8d0859cd4cb30d641486f5b19059","The effectiveness of a learning depends on four main elements, they are content, desired learning outcome, instructional method and the delivery media. The integration of those four elements can be manifested into a learning modul which is called multimedia learning or learning by using multimedia. In learning context by using computer-based multimedia, there are two main things that need to be noticed so that the learning process can run effectively: how the content is presented, and what the learner's chosen way in accepting and processing the information into a meaningful knowledge. First it is related with the way to visualize the content and how people learn. The second one is related with the learning style of the learner. This research aims to investigate the effect of the type of visualization-static vs animated-on a multimedia computer-based learning, and learning styles-visual vs verbal, towards the students' capability in applying the concepts, procedures, principles of Java programming. Visualization type act as independent variables, and learning styles of the students act as a moderator variable. Moreover, the instructional strategies followed the Component Display Theory of Merril, and the format of presentation of multimedia followed the Seven Principles of Multimedia Learning of Mayer and Moreno. Learning with the multimedia computer-based learning has been done in the classroom. The subject of this research was the student of STMIK-STIKOM Bali in odd semester 2016-2017 which followed the course of Java programming. The Design experiments used multivariate analysis of variance, MANOVA 2 x 2, with a large sample of 138 students in 4 classes. Based on the results of the analysis, it can be concluded that the animation in multimedia interactive learning gave a positive effect in improving students' learning outcomes, particularly in the applying the concepts, procedures, and principles of Java programming. The difference of students' learning styles-visual or verbal, it can also gave the different effect in students' learning results acquisition. There was no interaction effect between the factors of visualization type and learning styles.","Animated visualization; Java programming; Learning result; Learning styles; Multimedia learning; Static visualization",,2-s2.0-85030696589
"Yu Y., Yang J., Zan X., Huang J., Zhang X.","Research of Simulation in Character Animation Based on Physics Engine",2017,"International Journal of Digital Multimedia Broadcasting",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026520987&doi=10.1155%2f2017%2f4815932&partnerID=40&md5=07ad2c8e1781d7e7528edaabf359855b","Computer 3D character animation essentially is a product, which is combined with computer graphics and robotics, physics, mathematics, and the arts. It is based on computer hardware and graphics algorithms and related sciences rapidly developed new technologies. At present, the mainstream character animation technology is based on the artificial production of key technologies and capture frames based on the motion capture device technology. 3D character animation is widely used not only in the production of film, animation, and other commercial areas but also in virtual reality, computer-aided education, flight simulation, engineering simulation, military simulation, and other fields. In this paper, we try to study physics based character animation to solve these problems such as poor real-time interaction that appears in the character, low utilization rate, and complex production. The paper deeply studied the kinematics, dynamics technology, and production technology based on the motion data. At the same time, it analyzed ODE, PhysX, Bullet, and other variety of mainstream physics engines and studied OBB hierarchy bounding box tree, AABB hierarchical tree, and other collision detection algorithms. Finally, character animation based on ODE is implemented, which is simulation of the motion and collision process of a tricycle. © 2017 Yang Yu et al.",,"Computer aided instruction; Computer graphics; Computer hardware; Engineering education; Engines; Flight simulators; Forestry; Ordinary differential equations; Three dimensional computer graphics; Virtual reality; 3D character animation; Artificial production; Character animation; Collision detection algorithm; Computer-aided education; Engineering simulation; Production technology; Real time interactions; Animation",2-s2.0-85026520987
"Ruhland K., Prasad M., Mcdonnell R.","Data-driven approach to synthesizing facial animation using motion capture",2017,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028803654&doi=10.1109%2fMCG.2017.3271467&partnerID=40&md5=bc3a1c49a1ac30ed5a32a54eae499288","Producing cartoon animations is a laborious task, and there is a distinct lack of automatic tools to help animators, particularly with creating facial animation. The proposed method uses real-time video-based motion tracking to generate facial motion as input and then matches it to existing hand-created animation curves. The synthesized animations can then be refined and polished by an animator, saving considerable time in overall production. © 1981-2012 IEEE.","animation curves; cartoon animation; computer graphics; facial animation; motion capture","Computer graphics; Automatic tools; Cartoon animation; Data-driven approach; Facial animation; Facial motions; Motion capture; Motion tracking; Real time videos; Animation",2-s2.0-85028803654
"Hwang J., Kim K., Suh I.H., Kwon T.","Performance-based animation using constraints for virtual object manipulation",2017,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028824828&doi=10.1109%2fMCG.2017.3271455&partnerID=40&md5=efee403155014d2fc40e7831a7b5d5b8","Optical motion-capture systems can be used to animate characters in real time based on human demonstrations. However, most approaches do not consider the detailed finger movements necessary for object manipulation. The proposed online motion-capture framework encourages natural motions by automatically guiding the avatar's motion toward the desired behavior based on a set of captured reference motions for the same behavior. The proposed motion controller imitates the user's finger and body gestures to enable performance-based animation of human avatars that can manipulate virtual objects in real time. © 1981-2012 IEEE.","computer graphics; computer graphics applications; motion controller; object manipulation; performance-based animation; virtual reality","Animation; Computer graphics; Motion control; Real time systems; Computer graphics applications; Finger movements; Human demonstrations; Motion controller; Natural motions; Object manipulation; Optical motion capture; Performance-based animations; Virtual reality",2-s2.0-85028824828
"Patel P., Gupta H., Chaudhuri P.","Sketching 2D character animation using a data-assisted interface",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028350912&doi=10.1007%2f978-3-319-64870-5_7&partnerID=40&md5=bdd98c7200c82b43f1167b299aa5815b","This paper presents a system to assist novice animators in creating 2D, hand-drawn, character animation. This system, called TraceMove, helps the user to sketch the character and to animate it. Frames from recorded videos of human performers are stored in a database. This is subsequently used to provide a static pose hint to the users, in the form of silhouette suggestions, as they sketch the character. The desired pose of the character is thus easy to sketch for the user as they can trace and draw over the generated pose hint. The system then predicts the next frame of the animation as a moving pose hint. This is done with the help of a user marked skeleton on a single sketched pose and a motion capture database. The sketch predicted by the system can be edited by the animator as desired. The moving and static pose hints used together, let novice artists and animators easily generate hand-drawn, 2D animated characters. © Springer International Publishing AG 2017.","Data-assisted; Hand-drawn character animation; Sketch-based system","Computer graphics; Computer vision; Drawing (graphics); Animated characters; Character animation; Data-assisted; Hand-drawn; Motion capture; Sketch-based system; Animation",2-s2.0-85028350912
"Cui X., Diao J., Liu Y.","Study on the three dimensional animation creation based on digital technology and multimedia simulation",2017,"Revista de la Facultad de Ingenieria",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024841166&partnerID=40&md5=afadd0de5e2a72996942f54a8d94950f","Three dimensional animation is the development trend of computer animation, and the product of 3D technology and art. In this paper, the authors analyze the three dimensional animation creation based on digital technology and multimedia simulation. In the process of the three dimensional animation design, the digital electronic technology is used to create a real 3D scene. Through 3D animation production process and technical analysis, the authors use multimedia software to create 3D animation on the computer. The development of 3D animation in China is still in the exploratory period, thus 3D animation talents need continuous efforts in understanding the process of 3D animation, to master relevant 3D animation software application and technology. © 2017 Universidad Central de Venezuela.","Animation creation; Digital technology; Multimedia","Application programs; Digital electronics; Digital technologies; Multimedia; Multimedia simulation; Multimedia software; Production process; Technical analysis; Three-dimensional animations; Animation",2-s2.0-85024841166
"Serra J., Cetinaslan O., Ravikumar S., Orvalho V., Cosker D.","Easy Generation of Facial Animation Using Motion Graphs",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020414305&doi=10.1111%2fcgf.13218&partnerID=40&md5=77b947ecb5aea7dfc5dcb9e43e833b56","Facial animation is a time-consuming and cumbersome task that requires years of experience and/or a complex and expensive set-up. This becomes an issue, especially when animating the multitude of secondary characters required, e.g. in films or video-games. We address this problem with a novel technique that relies on motion graphs to represent a landmarked database. Separate graphs are created for different facial regions, allowing a reduced memory footprint compared to the original data. The common poses are identified using a Euclidean-based similarity metric and merged into the same node. This process traditionally requires a manually chosen threshold, however, we simplify it by optimizing for the desired graph compression. Motion synthesis occurs by traversing the graph using Dijkstra's algorithm, and coherent noise is introduced by swapping some path nodes with their neighbours. Expression labels, extracted from the database, provide the control mechanism for animation. We present a way of creating facial animation with reduced input that automatically controls timing and pose detail. Our technique easily fits within video-game and crowd animation contexts, allowing the characters to be more expressive with less effort. Furthermore, it provides a starting point for content creators aiming to bring more life into their characters. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","Facial animation; Motion blending; Motion graphs; Motion synthesis; Procedural animation","Blending; Graphic methods; Interactive computer graphics; Facial animation; Motion blending; Motion graph; Motion synthesis; Procedural animation; Animation",2-s2.0-85020414305
"Fang W.T., Lin P.-H., Lin R.","Western vs. eastern: A reflective research on the development of Chinese animation",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021652776&doi=10.1007%2f978-3-319-57931-3_3&partnerID=40&md5=f5bd35ec8150dc49a4067abfaf6798eb","Animation in China, stretching across a century, has been through many vicissitudes. In view of the current development of Chinese animation industry, animators imitate the styles of America and Japan excessively, which contain a large number of western elements from character modeling to story building. It has showed a serious lack of confidence, and entered into an erroneous zone with a general over-reliance on imitation. The literature review of this research consists of the comparison of the animated films from different cultures and eras and discuss the related research models. This research is based on animation study model with the method of attribute evaluation, the questionnaire survey and MDS, and will make a large-scale comparative study of domestically and abroad-produced animated films, with the special focus on technical level, semantic level and effectiveness level to deeply investigate the connotation based on the differences between Chinese and Western cultures. To re-produce folk and re-shape traditional art, creators show prominent Chinese unique oriental charm in value, customs, aesthetic concepts, and so on. To raise feasible countermeasures on how to enhance core competitiveness of animated films, it is urgent to grasp the opportunity to regain confidence of Chinese animation. © 2017, Springer International Publishing AG.","Chinese animation; Cultural industry; Effectiveness level; Semantic level; Technical level; Western animation","Motion pictures; Semantics; Surveys; Human computer interaction; Attribute evaluation; Core competitiveness; Cultural industries; Effectiveness level; Questionnaire surveys; Reflective researches; Semantic levels; Technical levels; Animation",2-s2.0-85021652776
"Neff M., Pelachaud C.","Animation of natural virtual characters",2017,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028844427&doi=10.1109%2fMCG.2017.3271459&partnerID=40&md5=3b9271cdbcd0c4e96ba65e277264add9",[No abstract available],"3D characters; animation; cartoon animation; computer graphics; computer graphics research; crowd simulation; facial animation; socio-emotional signals; virtual characters",,2-s2.0-85028844427
"Gierszewski S., Müller K., Smielik I., Hütwohl J.-M., Kuhnert K.-D., Witte K.","The virtual lover: Variable and easily guided 3D fish animations as an innovative tool in mate-choice experiments with sailfin mollies-II. Validation",2017,"Current Zoology",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014860112&doi=10.1093%2fcz%2fzow108&partnerID=40&md5=d89c1003a80293cfe1bb2c1bf209094f","The use of computer animation in behavioral research is a state-of-the-art method for designing and presenting animated animals to live test animals. The major advantages of computer animations are: (1) the creation of animated animal stimuli with high variability of morphology and even behavior; (2) animated stimuli provide highly standardized, controlled and repeatable testing procedures; and (3) they allow a reduction in the number of live test animals regarding the 3Rs principle. But the use of animated animals should be attended by a thorough validation for each test species to verify that behavior measured with live animals toward virtual animals can also be expected with natural stimuli. Here we present results on the validation of a custom-made simulation for animated 3D sailfin mollies Poecilia latipinna and show that responses of live test females were as strong to an animated fish as to a video or a live male fish. Movement of an animated stimulus was important but female response was stronger toward a swimming 3D fish stimulus than to a ""swimming"" box. Moreover, male test fish were able to discriminate between animated male and female stimuli; hence, rendering the animated 3D fish a useful tool inmate-choice experiments with sailfinmollies. © The Author (2016).","Computer animation; Fish behavior; Mate-choice experiment; Validation; Virtual fish model",,2-s2.0-85014860112
"Karras T., Aila T., Laine S., Herva A., Lehtinen J.","Audio-driven facial animation by joint end-to-end learning of pose and emotion",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030784373&doi=10.1145%2f3072959.3073658&partnerID=40&md5=19a859153dcbb398e5ec7b4df0166bd5","We present a machine learning technique for driving 3D facial animation by audio input in real time and with low latency. Our deep neural network learns a mapping from input waveforms to the 3D vertex coordinates of a face model, and simultaneously discovers a compact, latent code that disambiguates the variations in facial expression that cannot be explained by the audio alone. During inference, the latent code can be used as an intuitive control for the emotional state of the face puppet. We train our network with 3-5 minutes of high-quality animation data obtained using traditional, vision-based performance capture methods. Even though our primary goal is to model the speaking style of a single actor, our model yields reasonable results even when driven with audio from other speakers with different gender, accent, or language, as we demonstrate with a user study. The results are applicable to in-game dialogue, low-cost localization, virtual reality avatars, and telepresence. © 2017 Copyright held by the owner/author(s).","Audio; Deep learning; Facial animation","Deep learning; Deep neural networks; Interactive computer graphics; Learning systems; Virtual reality; Visual communication; 3d facial animations; Audio; Facial animation; Facial Expressions; Intuitive controls; Machine learning techniques; Performance capture; Vertex coordinates; Animation",2-s2.0-85030784373
"Fišer J., Jamriška O., Simons D., Shechtman E., Lu J., Asente P., Lukáč M., Sýkora D.","Example-based synthesis of stylized facial animations",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030753948&doi=10.1145%2f3072959.3073660&partnerID=40&md5=838005993b38caf70aa70f8d8e5b77aa","We introduce a novel approach to example-based stylization of portrait videos that preserves both the subject's identity and the visual richness of the input style exemplar. Unlike the current state-of-the-art based on neural style transfer [Selim et al. 2016], our method performs non-parametric texture synthesis that retains more of the local textural details of the artistic exemplar and does not suffer from image warping artifacts caused by aligning the style exemplar with the target face. Our method allows the creation of videos with less than full temporal coherence [Ruder et al. 2016]. By introducing a controllable amount of temporal dynamics, it more closely approximates the appearance of real hand-painted animation in which every frame was created independently. We demonstrate the practical utility of the proposed solution on a variety of style exemplars and target videos. © 2017 ACM.","Hand-drawn animation; Style transfer","Interactive computer graphics; Example-based synthesis; Facial animation; Hand-drawn; State of the art; Style transfer; Temporal coherence; Temporal dynamics; Texture synthesis; Animation",2-s2.0-85030753948
"Stallmann M.F.","Algorithm Animation with Galant",2017,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010311123&doi=10.1109%2fMCG.2017.2&partnerID=40&md5=91167961549b3ff76121529a3327a359","Although surveys suggest positive student attitudes toward the use of algorithm animations, it is not clear that they improve learning outcomes. The Graph Algorithm Animation Tool, or Galant, challenges and motivates students to engage more deeply with algorithm concepts, without distracting them with programming language details or GUIs. Even though Galant is specifically designed for graph algorithms, it has also been used to animate other algorithms, most notably sorting algorithms. © 1981-2012 IEEE.","Algorithm animation; Computer graphics; Computer graphics education; Graph algorithms","Computer graphics; Algorithm animation; Computer graphics education; Graph algorithms; Learning outcome; Sorting algorithm; Student attitudes; Animation",2-s2.0-85010311123
"Kätsyri J., Mäkäräinen M., Takala T.","Testing the ‘uncanny valley’ hypothesis in semirealistic computer-animated film characters: An empirical evaluation of natural film stimuli",2017,"International Journal of Human Computer Studies",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989171903&doi=10.1016%2fj.ijhcs.2016.09.010&partnerID=40&md5=82cd81c7b864335861e8ac7a1efc6662","The uncanny valley (UV) hypothesis, which predicts that almost but not fully humanlike artificial characters elicit negative evaluations, has become increasingly influential. At the same time, the hypothesis has become associated with many computer-animated films that have aimed at high realism. In the present investigation, we tested whether semirealistic animated film characters do in fact elicit negative evaluations. Fifty-four participants were asked to evaluate five matched film excerpts from each of cartoonish, semirealistic, and human-acted films. Mixed model analyses were conducted to reduce the effects of participant and stimulus related confounds. Explicit selections made after the experiment confirmed that participants associated semirealistic film characters correctly with the UV. Semirealistic animated characters also received higher eeriness ratings than the other film characters. In particular, two semirealistic films ‘Beowulf’ and ‘The Polar Express’ were selected the most often explicitly, and ‘Beowulf’ also received higher eeriness ratings than any other film. Somewhat unexpectedly, cartoonish characters received the highest strangeness ratings and (after confound correction) the lowest likability ratings. Taken together, the present findings demonstrate that semirealistic animated film characters are more eerie than cartoonish characters or real actors, and hence provide evidence for the existence of the UV in animated film characters. © 2016 The Authors","Animation films; Anthropomorphism; Computer animation; Human-computer interaction; Uncanny valley","Animation; Landforms; Motion pictures; Animated characters; Anthropomorphism; Beowulf; Computer animation; Empirical evaluations; Mixed-model analysis; Uncanny valley; Human computer interaction",2-s2.0-84989171903
"Schweickart E., James D.L., Marschner S.","Animating elastic rods with sound",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030753713&doi=10.1145%2f3072959.3073680&partnerID=40&md5=6fb0ece9951ec17fc42ecc9b4af7a2c6","Sound generation methods, such as linear modal synthesis, can sonify a wide range of physics-based animation of solid objects, resolving vibrations and sound radiation from various structures. However, elastic rods are an important computer animation primitive for which prior sound synthesis methods, such as modal synthesis, are ill-suited for several reasons: large displacements, nonlinear vibrations, dispersion effects, and the geometrically singular nature of rods. In this paper, we present physically based methods for simultaneous generation of animation and sound for deformable rods. We draw on Kirchhoff theory to simplify the representation of rod dynamics and introduce a generalized dipole model to calculate the spatially varying acoustic radiation. In doing so, we drastically decrease the amount of precomputation required (in some cases eliminating it completely), while being able to resolve sound radiation for arbitrary body deformations encountered in computer animation. We present several examples, including challenging scenes involving thousands of highly coupled frictional contacts. © 2017 Copyright held by the owner/author(s).","Physically based animation; Sound synthesis","Acoustic generators; Acoustic properties; Acoustic wave propagation; Acoustic wave scattering; Deformation; Interactive computer graphics; Modal analysis; Acoustic radiation; Computer animation; Frictional contact; Large displacements; Non-linear vibrations; Physically-based animation; Physics-based animation; Sound synthesis; Animation",2-s2.0-85030753713
"Ichim A.-E., Kadleček P., Kavan L., Pauly M.","Phace: Physics-based face modeling and animation",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030763506&doi=10.1145%2f3072959.3073664&partnerID=40&md5=0fe789832950b65d4277f106f4e1fd1f","We present a novel physics-based approach to facial animation. Contrary to commonly used generative methods, our solution computes facial expressions by minimizing a set of non-linear potential energies that model the physical interaction of passive flesh, active muscles, and rigid bone structures. By integrating collision and contact handling into the simulation, our algorithm avoids inconsistent poses commonly observed in generative methods such as blendshape rigs. A novel muscle activation model leads to a robust optimization that faithfully reproduces complex facial articulations. We show how person-specific simulation models can be built from a few expression scans with a minimal data acquisition process and an almost entirely automated processing pipeline. Our method supports temporal dynamics due to inertia or external forces, incorporates skin sliding to avoid unnatural stretching, and offers full control of the simulation parameters, which enables a variety of advanced animation effects. For example, slimming or fattening the face is achieved by simply scaling the volume of the soft tissue elements. We show a series of application demos, including artistic editing of the animation model, simulation of corrective facial surgery, or dynamic interaction with external forces and objects. © 2017 ACM.","3D avatar creation; Anatomical models; Facial animation; Rigging","Animation; Data acquisition; Interactive computer graphics; Muscle; Optimization; Potential energy; Three dimensional computer graphics; 3D Avatars; Anatomical models; Automated processing; Facial animation; Physical interactions; Rigging; Robust optimization; Simulation parameters; Rigid structures",2-s2.0-85030763506
"Cheng D.","Application and practice of animation and digital image in interactive media teaching in colleges and universities",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020848402&partnerID=40&md5=78d77aa4cf6dc41039ad9587855070ac","Animation and digital image have become the key technical factors in the construction of interactive teaching resources in colleges and universities. As an important means of teaching reform in colleges and universities, more and more attention has been paid to animation and digital images. The quality requirements of animation and digital image resources are gradually increased. Currently the quality of teaching resources of animation and digital image has become one of the important roles of interactive teaching. Thus, the development of high quality resources was considered as an urgent task. On the basis of the application and practice of animation and digital image in the teaching resources of interactive media, the current situation of research was summarized. Moreover, the research content, research objectives, key issues to be addressed and prospects for the future were elaborated in this paper.","Animation and digital image; Colleges and universities; Interactive media teaching; Resources","Animation; E-learning; Education; Educational technology; Human computer interaction; Image processing; Colleges and universities; Digital image; Interactive media; Quality of teaching; Quality requirements; Research objectives; Resources; Teaching resources; Societies and institutions",2-s2.0-85020848402
"Day J.-M., Hsu S.-C., Chen C.-C.","White crane dance-transforming woodcut print and folk dance into animation art",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025141908&doi=10.1007%2f978-3-319-58524-6_45&partnerID=40&md5=095ce4124ec575e8d0e4de570ebef3dd","The new media art exhibitions integrated animation is gradually replacing the traditional “static” trend. For example, the cooperation of two palace museums of Taiwan and China unveiled. “The Dwelling in the Fuchun Mountains” combined with sound, light, and video technology to extend original work. By integrating the animation into the static art work, it will reflect the sense of time and dynamic feeling. The animation can make clearer annotation of life condition then, as well as join the situation sound to influence and persuade the audience. The topic of our research is to explain how we can use new technology to transform traditional contents into popular media format while preserving the originality of the art and culture. We found a process to integrate art, culture, woodcut print and folk dance with technology and animation, by using motion capture, 3d animation and photo retouch technology. © Springer International Publishing AG 2017.","Animation; Folk dance; Motion capture; Woodcut print","Buildings; Decision making; Exhibitions; Human computer interaction; 3D animation; Art and cultures; Folk dances; Media formats; Motion capture; New media art; Sense of time; Video technologies; Animation",2-s2.0-85025141908
"Müller K., Smielik I., Hütwohl J.-M., Gierszewski S., Witte K., Kuhnert K.-D.","The virtual lover: Variable and easily guided 3D fish animations as an innovative tool in mate-choice experiments with sailfin mollies-I. Design and implementation",2017,"Current Zoology",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014826751&doi=10.1093%2fcz%2fzow106&partnerID=40&md5=85ada10b156491923763f4f77554d4a6","Animal behavior researchers often face problems regarding standardization and reproducibility of their experiments. This has led to the partial substitution of live animals with artificial virtual stimuli. In addition to standardization and reproducibility, virtual stimuli open new options for researchers since they are easily changeable in morphology and appearance, and their behavior can be defined. In this article, a novel toolchain to conduct behavior experiments with fish is presented by a case study in sailfin mollies Poecilia latipinna. As the toolchain holds many different and novel features, it offers new possibilities for studies in behavioral animal research and promotes the standardization of experiments. The presented method includes options to design, animate, and present virtual stimuli to live fish. The designing tool offers an easy and user-friendly way to define size, coloration, and morphology of stimuli and moreover it is able to configure virtual stimuli randomly without any user influence. Furthermore, the toolchain brings a novel method to animate stimuli in a semiautomatic way with the help of a game controller. These created swimming paths can be applied to different stimuli in real time. A presentation tool combines models and swimming paths regarding formerly defined playlists, and presents the stimuli onto 2 screens. Experiments with live sailfin mollies validated the usage of the created virtual 3D fish models in mate-choice experiments. © The Author (2016).","Computer animation; Fish behavior; Mate-choice experiment; Research tool; Virtual fish model",,2-s2.0-85014826751
"Gunanto S.G., Hariadi M., Yuniarno E.M., Nendya M.B.","acial animation of life-like avatar based on feature point cluster",2017,"Journal of Engineering Science and Technology Review",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017365230&partnerID=40&md5=72041ed61cf1cb81d710350d08b87171","The problems that are often encountered in the making of facial expressions on 3D animated avatars heavily dependent on the ability of key animators to create movement and combine them into a series of facial motion animation. This research proposes an automatic preprocessing for facial animation using feature point cluster. The mechanism of a transfer system for animated facial expressions using a radial basis function technique that is effective, especially in terms of production speed. This study focuses on the improvement of animated facial expressions using the feature point cluster. The result is to provide improved motion animation more expressive. This process will be easier and faster for the formation of facial motion animation without the need for process adjustments manually. © 2017 Eastern Macedonia and Thrace Institute of Technology.","Avatar; Facial animation; Feature point cluster; Radial basis function; Retargeting","Functions; Radial basis function networks; Three dimensional computer graphics; Avatar; Facial animation; Point clusters; Radial basis functions; Retargeting; Animation",2-s2.0-85017365230
"Taylor S., Kim T., Yue Y., Krahe M.M., Rodriguez A.G., Hodgins J., Matthews I.","A deep learning approach for generalized speech animation",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030773470&doi=10.1145%2f3072959.3073699&partnerID=40&md5=9303f28b8b7f79280abaa5ecf8947c54","We introduce a simple and efective deep learning approach to automatically generate natural looking speech animation that synchronizes to input speech. Our approach uses a sliding window predictor that learns arbitrary nonlinear mappings from phoneme label input sequences to mouth movements in a way that accurately captures natural motion and visual coarticulation effects. Our deep learning approach enjoys several attractive properties: it runs in real-time, requires minimal parameter tuning, generalizes well to novel input speech sequences, is easily editedto create stylized and emotional speech, and is compatible with existing animation retargeting approaches. One important focus of our work is to develop an effective approach for speech animation that can be easily integrated into existing production pipelines. We provide a detailed description of our end-to-end approach, including machine learning design decisions. Generalized speech animation results are demonstrated over a wide range of animation clips on a variety of characters and voices, including singing and foreign language input. Our approach can also generate on-demand speech animation in real-time from user speech input. © 2017 Copyright held by the owner/author(s).","Machine learning; Speech animation","Animation; Artificial intelligence; Deep learning; Interactive computer graphics; Learning systems; Effective approaches; Emotional speech; Foreign language; Learning approach; Nonlinear mappings; Parameter-tuning; Production pipelines; Speech animation; Speech",2-s2.0-85030773470
"Liao J.","Uncertainty animation image analysis for cooperative feature constraints",2017,"Boletin Tecnico/Technical Bulletin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024504160&partnerID=40&md5=96ae1934044f35dc8b830c084e0b7401","In computer graphics, there are many ways to simplify the grid, but most of them are for static grids, and there is little simplification works for animated collaborative meshes. A method of generating dynamic surface uncertainty image for cooperative feature constraints is proposed, which is used to simplify the image by repeating the side contraction operation. The synergistic feature is used to measure the degree of synergism of the triangular patches in the whole cooperative sequence. In the cumulative edge folding cost, it is possible to effectively preserve the details of some of the larger regions. On this basis, a grid optimization algorithm on the sequence of animated images is proposed, which improves the time consistency of the dynamic image output while adjusting the shape of the triangle, and reduces the visual transition between adjacent frames. Experimental results show that the method is highly efficient, easy to implement, and can output arbitrary resolution high quality simplified image sequence.","Animation image; Collaborative feature; Detail level; Dynamic grid; Edge folding","Animation; Computer graphics; Distributed computer systems; Optimization; Adjacent frames; Collaborative feature; Detail level; Dynamic grid; Edge folding; Grid optimization algorithms; Time consistency; Triangular patch; Uncertainty analysis",2-s2.0-85024504160
"Huang Y., Zhou T., Li Y., Zhang Y., Ma C.","Interactive animation editing based on sketch interaction",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028556774&doi=10.1007%2f978-3-319-61994-1_8&partnerID=40&md5=6df393216f8a6ea901a648d6c6f2b3ac","User-centric interactive system shows potential in allowing users facilely access to the experience of natural interaction appropriate to user’s intention with a low cognitive load. A novel approach, central to the user’s experience, is presented based on knowledge reuse, user interaction model and sketch-based interaction. A proposed sketch platform for animation editing provide the key to instantiating typical application within the reuse methods. The sketch-based interface explores a point in the tradeoff between expressiveness and naturalness to provide users a natural interactive environment. It helps to fill in the gaps of traditional WIMP (Window Icon Menu Pointing Device) pattern in the process animation drawings by sketching, exploring and modifying their ideas interactively with immediate and continuous visual feedback, and validate existing efforts and provide impetus for future work in the area of natural interaction research. © 2017, Springer International Publishing AG.","Knowledge reuse; Natural user interface; Sketch; User-centric","Animation; Human computer interaction; User interfaces; Visual communication; Interactive animations; Knowledge reuse; Natural user interfaces; Sketch; Sketch based Interface; Sketch-based interactions; User Interaction Modeling; User-centric; Big data",2-s2.0-85028556774
"Dvorožňák M., Bénard P., Barla P., Wang O., Sýkora D.","Example-based expressive animation of 2D rigid bodies",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030769103&doi=10.1145%2f3072959.3073611&partnerID=40&md5=d19b0fc8ec9b3416c5fe9bf69387893a","We present a novel approach to facilitate the creation of stylized 2D rigid body animations. Our approach can handle multiple rigid objects following complex physically-simulated trajectories with collisions, while retaining a unique artistic style directly specified by the user. Starting with an existing target animation (e.g., produced by a physical simulation engine) an artist interactively draws over a sparse set of frames, and the desired appearance and motion stylization is automatically propagated to the rest of the sequence. The stylization process may also be performed in an off-line batch process from a small set of drawn sequences. To achieve these goals, we combine parametric deformation synthesis that generalizes and reuses hand-drawn exemplars, with non-parametric techniques that enhance the hand-drawn appearance of the synthesized sequence. We demonstrate the potential of our method on various complex rigid body animations which are created with an expressive hand-drawn look using notably less manual interventions as compared to traditional techniques. © 2017 ACM.","2D animation; Example-based synthesis","Batch data processing; Interactive computer graphics; Rigid structures; 2D animation; Example-based synthesis; Manual intervention; Non-parametric techniques; Parametric deformation; Physical simulation; Simulated trajectories; Traditional techniques; Animation",2-s2.0-85030769103
"Shuangmei M.","The application of interactive animation in the film and television industry under the background of digital media",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020507049&partnerID=40&md5=ae0e2211b8fc69e408c06ceea4c83a48","In the context of the rapid development of the digital media technology, the interaction of digital media technology has brought more and more influences on the film. Based on this, in this paper, the application of interactive animation in the film and television industry under the background of digital media was studied; related meaning of digital media, interactivity, interactive digital media were briefly introduced; the influence of the digital media technology interaction on film narration was summarized; the interaction effect in the movie audience identity and change were illustrated; through relevant tests and analysis, the significance of the interactive digital media technology development of movies was revealed.","Audience identity; Digital media; Film narrative; Interaction; Significance","Animation; Digital storage; Human computer interaction; Audience identity; Digital media technologies; Interaction; Interaction effect; Interactive animations; Interactivity; Significance; Tests and analysis; Interactive television",2-s2.0-85020507049
"Kim M., Pons-Moll G., Pujades S., Bang S., Kim J., Black M.J., Lee S.-H.","Data-driven physics for human soft tissue animation",2017,"ACM Transactions on Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030784530&doi=10.1145%2f3072959.3073685&partnerID=40&md5=eb454b07eafa6e7b997271a6e8b557c0","Data driven models of human poses and soft-tissue deformations can produce very realistic results, but they only model the visible surface of the human body and cannot create skin deformation due to interactions with the environment. Physical simulations can generalize to external forces, but their parameters are difficult to control. In this paper, we present a layered volumetric human body model learned from data. Our model is composed of a data-driven inner layer and a physics-based external layer. The inner layer is driven with a volumetric statistical body model (VSMPL). The soft tissue layer consists of a tetrahedral mesh that is driven using the finite element method (FEM). Model parameters, namely the segmentation of the body into layers and the soft tissue elasticity, are learned directly from 4D registrations of humans exhibiting soft tissue deformations. The learned two layer model is a realistic full-body avatar that generalizes to novel motions and external forces. Experiments show that the resulting avatars produce realistic results on held out sequences and react to external forces. Moreover, the model supports the retargeting of physical properties from one avatar when they share the same topology. © 2017 Copyright held by the owner/author(s).","Character animation; Finite element method; Parameter estimation; Statistical human shape","Animation; Deformation; Interactive computer graphics; Parameter estimation; Tissue; Topology; Character animation; Data-driven model; Human body modeling; Human shapes; Model parameters; Physical simulation; Soft tissue deformation; Tetrahedral meshes; Finite element method",2-s2.0-85030784530
"Végh L., Takáč O.","Using interactive card animations for understanding of the essential aspects of non-recursive sorting algorithms",2017,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009480799&doi=10.1007%2f978-3-319-46535-7_25&partnerID=40&md5=2ed5bd98231b7a92cb84872db91a3af4","Animations can help students to comprehend computer science algorithms. Previous experiments, mentioned in this paper, show that interactivity is very important in educational animations. In this contribution we also describe three categories of algorithm animations with different views, and we introduce our interactive card animations that belong to the first group (animations with conceptual views). These card animations of sorting algorithms were used in our experiment, where first-year computer science students were asked to fill out a pre-test, use the animations, and fill out a post-test. In the third part of the paper we discuss the obtained results, which proved that the interactive card animations can help students to understand the essential aspects of different sorting algorithms. Finally, we draw conclusions and introduce our future plans. © Springer International Publishing AG 2017.",,"Education; Students; Algorithm animation; Computer science students; Conceptual views; First year; Interactivity; Post test; Sorting algorithm; Three categories; Software design",2-s2.0-85009480799
"Cheung M.Y.M., Hong W., Thong J.Y.L.","Effects of animation on attentional resources of online consumers",2017,"Journal of the Association of Information Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029372845&partnerID=40&md5=f71ca17f65be9e57e32285f00ec61af1","Websites commonly use animation to capture the attentional resources of online consumers. While prior research has focused on the effects of animation on animated banner ads, limited research has examined the effects of animation on other items on the same webpage. Drawing from psychological theories that the amount of an individual’s attentional resources may vary under different conditions, this study focuses on the effects of animation on how individuals allocate attentional resources to both the animated item and the remaining non-animated items. We conducted an eye-tracking experiment to follow online consumers’ visual attention while they performed two types of online shopping tasks: browsing and searching tasks. The results showed that a product item that used animation led to increased visual attention to all items on a webpage, which suggests that the amount of attentional resources increases when a webpage includes animation. Meanwhile, animation influenced how individuals allocate their attentional resources such that it increased visual attention on the animated item at the expense of attention on non-animated items on the same webpage. In addition, the type of shopping task moderated animation’s effect on how individuals allocate their attentional resources. Specifically, animation’s effect on attracting attentional resources to the animated item was stronger when online consumers browsed than when they searched for a specific target item. We discuss the theoretical and practical implications of our findings. © 2017 by the Association for Information Systems.","Animation; Attentional resources; Experiment; Eye-tracking; Human-computer interaction; Online consumers; Website design","Behavioral research; Electronic commerce; Experiments; Human computer interaction; Web Design; Websites; Attentional resources; Eye-tracking; Online consumers; Online shopping; Psychological theory; Searching task; Shopping task; Visual Attention; Animation",2-s2.0-85029372845
"Zhang J., Cheng C., Ge W., Zhang T., Zhu H., Mounir S.","Constructing kinematic animation of products in virtual assembly environments",2017,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007028690&doi=10.1007%2f978-3-319-49568-2_44&partnerID=40&md5=b4aed8145fbc51e339c618584b743355","The traditional assembly simulation is designed for product design system which doesn’t support 3D interaction, and the design is very complicated. This paper proposes a new strategy and an algorithm to construct an assembly animation in VE. Engine components are used to realize animation as building blocks. Algorithm and process about how to construct engine components as well as parameters’ transfer between components are presented. The method will decrease designers’ burden and improve the production efficiency. At last, two examples are given to verify the feasibility of this strategy. © Springer International Publishing AG 2017.","Animation; Direct manipulation; Engine component; Human-computer interaction; Virtual assembly; Virtual environment","Animation; Engines; Human computer interaction; Intelligent systems; Product design; Virtual prototyping; Virtual reality; 3D interactions; Assembly simulation; Building blockes; Direct manipulation; Engine components; Production efficiency; Virtual assembly; Assembly",2-s2.0-85007028690
"McDonald J., Wolfe R., Johnson S., Baowidan S., Moncrief R., Guo N.","An improved framework for layering linguistic processes in sign language generation: Why there should never be a “brows” tier",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025155485&doi=10.1007%2f978-3-319-58703-5_4&partnerID=40&md5=c57817d1a45a1321d0a50f91b46538d8","Creating legible animations of sign language that satisfy the needs of native users requires drawing from the fields of computational linguistics, computer animation and user experience research. This paper explores the problem of layering the many linguistic processes that contribute to a sign language utterance in avatar animation. A new framework is presented that satisfies requirements from each of these fields, and yields a flexible architecture for sign language avatars capable of leveraging a wide range of animation techniques to generate rich multi-layered animations of sign. © Springer International Publishing AG 2017.","Computational linguistics; Computer animation; Hierarchical models; Sign language avatars; User interface","Animation; Computational linguistics; Hierarchical systems; Linguistics; User interfaces; Animation techniques; Computer animation; Flexible architectures; Hierarchical model; Multi-layered; Sign language; User experience research; Human computer interaction",2-s2.0-85025155485
"Kang D., Vu D.Q., Yoon K.","Generating Stained Glass Animation",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032471522&doi=10.1007%2f978-3-319-65849-0_25&partnerID=40&md5=9c5c1302c65eb855db5198e532811892","Generating stained glass animation from a given video is a challenging issue in computer graphics. It requires to maintain the temporally coherent stained glass pieces between all frames in video. To cope up with this problem, we propose a method for generating stained glass animation with panoramic image. In this method, we first extract temporally coherent segments from a given video. We then divide each big segment into sub-segments by dividing the panoramic image. As a result, we obtain temporally coherent segments as glass pieces. Then, we generate stained glass pieces by employing image-based stained glass rendering method to each sub-divided region. © 2017, Springer International Publishing AG.","NPR; Panoramic image; Temporal coherency","Animation; Computer graphics; E-learning; Image segmentation; Glass pieces; Image-based; Panoramic images; Rendering methods; Temporal coherency; Stained glass",2-s2.0-85032471522
"Marcopoulos E., Rayatidamavandi M., Suarez C., Zhang Y.","Online SPARC for drawing and animation",2017,"31st AAAI Conference on Artificial Intelligence, AAAI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030451619&partnerID=40&md5=fda68e527ba2a829486f312d6e80e7cd","We developed a method to draw and animate using SPARC, a logic programming system, and an online environment to support this method. Particularly, we introduce two predicates: one for drawing and one for animation. By our method, programmers will write a SPARC program, using our introduced predicates, to specify their drawing or animation. The drawing or animation will then be rendered upon executing the program with our system. In fact, our online system provides an environment where the programmers can easily edit and execute their programs. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Artificial intelligence; Computer programming; Logic programming; Logic programming systems; Online environments; Animation",2-s2.0-85030451619
"Stebner F., Kühl T., Höffler T.N., Wirth J., Ayres P.","The role of process information in narrations while learning with animations and static pictures",2017,"Computers and Education",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994890040&doi=10.1016%2fj.compedu.2016.11.001&partnerID=40&md5=6e50b5f3d5aa981275ed69b879e31b8a","The role of process information in annotating narrations used for learning with animations compared to static pictures is examined. In two experiments, seventh and eighth graders from German high schools were randomly assigned to learning environments which differed in the combination of visualization (no visualization vs. static pictures vs. animation) and type of narration (no narration vs. non-process narration vs. process narration). Results revealed that visualizations were necessary for this kind of instructional material to gain a deeper understanding. Moreover, the results consistently show a significant superiority of animations over static pictures. Concerning narrations, results display a significant superiority of process descriptions only in Experiment 1. Contrary to prior assumptions, the interaction of specific information in narrations with the type of visualizations was not significant. © 2016 Elsevier Ltd","Animation; Cognitive load; Multimedia; Narration; Static pictures","Animation; Computer aided instruction; Visualization; Cognitive loads; Instructional materials; Learning environments; Multimedia; Narration; Process descriptions; Specific information; Static pictures; Image processing",2-s2.0-84994890040
"Végh L., Stoffová V.","Algorithm animations for teaching and learning the main ideas of basic sortings",2017,"Informatics in Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019019784&doi=10.15388%2finfedu.2017.07&partnerID=40&md5=65a4e8a5be2ea8aae6ecc44a4eb11983","Algorithms are hard to understand for novice computer science students because they dynamically modify values of elements of abstract data structures. Animations can help to understand algorithms, since they connect abstract concepts to real life objects and situations. In the past 30-35 years, there have been conducted many experiments in the field of usage of animations and visualizations in education, but they showed mixed results. In this paper, we review past research within the field and summarize recommendations regarding the graphic design and interactivity of the animations. In the second part of the paper, we present our interactive card sorting animations with conceptual views. The goal of these animations is to help students understand the main ideas and differences between basic sorting algorithms. In a pedagogical experiment related to these animations, 92 first-year computer science students of J. Selye University in Komarno (Slovakia) were asked to fill in a pre-test, experiment with the interactive animations, and fill in a post-test. The results showed that animations helped students to understand essential aspects of sorting algorithms. However, the participants were not able to understand the sorting algorithms in detail, so other types of animations are needed to teach algorithms in-depth.","Interactive algorithm animations; Multimedia learning; Teaching algorithms",,2-s2.0-85019019784
"Kytö M., Dhinakaran K., Martikainen A., Hämäläinen P.","Improving 3D Character Posing with a Gestural Interface",2017,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027412736&doi=10.1109%2fMCG.2015.117&partnerID=40&md5=3c00a621ca12c5b72a86f7b6e14a89bb","The most time-consuming part of character animation is 3D character posing. Posing using a mouse is a slow and tedious task that involves sequences of selecting on-screen control handles and manipulating the handles to adjust character parameters, such as joint rotations and end effector positions. Thus, various 3D user interfaces have been proposed to make animating easier, but they typically provide less accuracy. The proposed interface combines a mouse with the Leap Motion device to provide 3D input. A usability study showed that users preferred the Leap Motion over a mouse as a 3D gestural input device. The Leap Motion drastically decreased the number of required operations and the task completion time, especially for novice users. © 2017 IEEE.","3D user interfaces; character posing; computer animation; computer graphics","Animation; Computer graphics; Mammals; Three dimensional computer graphics; 3D user interface; Character animation; character posing; Computer animation; Gestural interfaces; Task completion time; Time-consuming parts; Usability studies; User interfaces",2-s2.0-85027412736
"Ramírez Flores J.E., Sánchez A.S.","Segmentation-based skinning",2017,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011891376&doi=10.1002%2fcav.1687&partnerID=40&md5=d5f5d17d4c7dcdb5c2f1031746746cb3","Skeleton-driven animation is popular by its simplicity and intuitive control of the limbs of a character. Linear blend skinning (LBS) is up to date the most efficient and simple deformation method; however, painting influence skinning weights is not intuitive, and it suffers the candy-wrapper artifact. In this paper, we propose an approach based on mesh segmentation for skinning and skeleton-driven computer animation. We propose a novel and fast method, based in watershed segmentation to deal with characters in T-Pose and arbitrary poses, a simple weight assign algorithm based in the rigid skinning obtained with the segmentation algorithm for the LBS deformation method, and finally, a modified version of the LBS that avoids the loss of volume in twist rotations using the segmentation stage output values. Copyright © 2015 John Wiley & Sons, Ltd. Copyright © 2015 John Wiley & Sons, Ltd.","computer animation; mesh segmentation; rigging; skinning; weight assignment algorithm","Computer graphics; Copyrights; Deformation; Image segmentation; Mesh generation; Musculoskeletal system; Computer animation; Mesh segmentation; rigging; skinning; Weight assignment algorithms; Animation",2-s2.0-85011891376
"Tavares P.C., Henriques P.R., Gomes E.F.","A computer platform to increase motivation in programming students-PEP",2017,"CSEDU 2017 - Proceedings of the 9th International Conference on Computer Supported Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023760938&partnerID=40&md5=11a3308f6f3011a0c7ccb1f7db2006bc","Motivate students is one of the biggest challenges that teachers have to face, in general and in particular in programming courses. In this article two techniques, aimed at supporting the teaching of programming, are discussed: program animation, and automatic evaluation of programs. Based on the combination of these techniques and their currently available tools, we will describe two possible approaches to increase motivation and improve the success. The conclusions of a first experiment conducted in the classroom will be presented. PEP, a Web-based tool that implements one of the approaches proposed, will be introduced. Copyright © 2017 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved.","Automatic evaluation; Immediate feedback; Motivation; Program animation","Animation; Education; Motivation; Students; Teaching; Automatic evaluation; Computer platforms; Immediate feedbacks; Program animation; Programming course; Teaching-of-programming; Web-based tools; Computer programming",2-s2.0-85023760938
"da Silva D.B., Nunes R.F., Vidal C.A., Cavalcante-Neto J.B., Kry P.G., Zordan V.B.","Tunable Robustness: An Artificial Contact Strategy with Virtual Actuator Control for Balance",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016178213&doi=10.1111%2fcgf.13096&partnerID=40&md5=1f0e9e360864a205d577a065d199100f","Physically based characters have not yet received wide adoption in the entertainment industry because control remains both difficult and unreliable. Even with the incorporation of motion capture for reference, which adds believability, characters fail to be convincing in their appearance when the control is not robust. To address these issues, we propose a simple Jacobian transpose torque controller that employs virtual actuators to create a fast and reasonable tracking system for motion capture. We combine this controller with a novel approach we call the topple-free foot strategy which conservatively applies artificial torques to the standing foot to produce a character that is capable of performing with arbitrary robustness. The system is both easy to implement and straightforward for the animator to adjust to the desired robustness, by considering the trade-off between physical realism and stability. We showcase the benefit of our system with a wide variety of example simulations, including energetic motions with multiple support contact changes, such as capoeira, as well as an extension that highlights the approach coupled with a Simbicon controlled walker. With this work, we aim to advance the state-of-the-art in the practical design for physically based characters that can employ unaltered reference motion (e.g. motion capture data) and directly adapt it to a simulated environment without the need for optimization or inverse dynamics. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","3D interaction; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation; Motion control; Physics-based animation","Actuators; Animation; Computer graphics; Controllers; Economic and social effects; Motion control; Robust control; Three dimensional computer graphics; Virtual addresses; 3D interactions; Entertainment industry; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Motion capture data; Physics-based animation; Simulated environment; Torque controllers; Virtual actuators; Robustness (control systems)",2-s2.0-85016178213
"Wang J.-H., Setaluri R., James D.L., Pai D.K.","Bounce maps: An improved restitution model for real-time rigid-body impact",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030758540&doi=10.1145%2f3072959.3073634&partnerID=40&md5=66802a804b0a056c74add0ecc909214b","We present a novel method to enrich standard rigid-body impact models with a spatially varying coeficient of restitution map, or Bounce Map. Even state-of-the art methods in computer graphics assume that for a single rigid body, post- and pre-impact dynamics are related with a single global, constant, namely the coeficient of restitution. We first demonstrate that this assumption is highly inaccurate, even for simple objects. We then present a technique to eficiently and automatically generate a function which maps locations on the object's surface along with impact normals, to a scalar coeficient of restitution value. Furthermore, we propose a method for two-body restitution analysis, and, based on numerical experiments, estimate a practical model for combining one-body Bounce Map values to approximate the two-body coeficient of restitution. We show that our method not only improves accuracy, but also enables visually richer rigid-body simulations. © 2017 Association for Computing Machinery.","Bounce; Chatter; Coeficient of restitution; Collision; Computer animation; Contact; Impact; Modal vibration; Newton's law of restitution; Rigid body","Animation; Computer graphics; Contacts (fluid mechanics); Interactive computer graphics; Numerical methods; Bounce; Chatter; Coeficient of restitution; Collision; Computer animation; Impact; Modal vibrations; Newton's Laws; Rigid body; Rigid structures",2-s2.0-85030758540
"Zhang Z., Morishima S.","Screen space hair self shadowing by translucent hybrid ambient occlusion",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018487514&doi=10.1007%2f978-3-319-53838-9_3&partnerID=40&md5=af2b03e3d71d7104fbfe58663edaab58","Screen space ambient occlusion is a very efficient means to capture the shadows caused by adjacent objects. However it is incapable of expressing transparency of objects. We introduce an approach which behaves like the combination of ambient occlusion and translucency. This method is an extension of the traditional screen space ambient occlusion algorithm with extra density field input. It can be applied on rendering mesh objects, and moreover it is very suitable for rendering complex hair models. We use the new algorithm to approximate light attenuation though semi-transparent hairs at real-time. Our method is implemented on common GPU, and independent from pre-computation. When it is used in environment lighting, the hair shading is visually similar to however one order of magnitude faster than existing algorithm. © Springer International Publishing AG 2017.","Computer animation; Deferred shading; Hair shadowing; Real-time rendering","Animation; Computer graphics; Ambient occlusion; Computer animation; Deferred shadings; Environment lighting; Hair shadowing; Light attenuation; Real-time rendering; Rendering meshes; Rendering (computer graphics)",2-s2.0-85018487514
"Sibbing D., Kobbelt L.","Building a Large Database of Facial Movements for Deformation Model-Based 3D Face Tracking",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013662978&doi=10.1111%2fcgf.13080&partnerID=40&md5=3bb9743928540ba3c26d8b5a8d7c828d","We introduce a new markerless 3D face tracking approach for 2D videos captured by a single consumer grade camera. Our approach takes detected 2D facial features as input and matches them with projections of 3D features of a deformable model to determine its pose and shape. To make the tracking and reconstruction more robust we add a smoothness prior for pose and deformation changes of the faces. Our major contribution lies in the formulation of the deformation prior which we derive from a large database of facial animations showing different (dynamic) facial expressions of a fairly large number of subjects. We split these animation sequences into snippets of fixed length which we use to predict the facial motion based on previous frames. In order to keep the deformation model compact and independent from the individual physiognomy, we represent it by deformation gradients (instead of vertex positions) and apply a principal component analysis in deformation gradient space to extract the major modes of facial deformation. Since the facial deformation is optimized during tracking, it is particularly easy to apply them to other physiognomies and thereby re-target the facial expressions. We demonstrate the effectiveness of our technique on a number of examples. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","Animation; Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism; Data-driven animation; Facial animation; I.4.8 [Image Processing and Computer Vision]: Scene Analysis; Markerless performance capture; Tracking; Tracking","Animation; Computer graphics; Deformation; Image processing; Principal component analysis; Surface discharges; Target tracking; Three dimensional computer graphics; Data-driven animation; Facial animation; I.3.7 [computer graphics]: three-dimensional graphics and realism; Performance capture; Scene analysis; Face recognition",2-s2.0-85013662978
"Dagenais F., Gagnon J., Paquette E.","Detail-Preserving Explicit Mesh Projection and Topology Matching for Particle-Based Fluids",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017366172&doi=10.1111%2fcgf.13091&partnerID=40&md5=b51231ade5b34dfe3e0f869231f9674c","We propose a new explicit surface tracking approach for particle-based fluid simulations. Our goal is to advect and update a highly detailed surface, while only computing a coarse simulation. Current explicit surface methods lose surface details when projecting on the isosurface of an implicit function built from particles. Our approach uses a detail-preserving projection, based on a signed distance field, to prevent the divergence of the explicit surface without losing its initial details. Furthermore, we introduce a novel topology matching stage that corrects the topology of the explicit surface based on the topology of an implicit function. To that end, we introduce an optimization approach to update our explicit mesh signed distance field before remeshing. Our approach is successfully used to preserve the surface details of melting and highly viscous objects, and shown to be stable by handling complex cases involving multiple topological changes. Compared to the computation of a high-resolution simulation, using our approach with a coarse fluid simulation significantly reduces the computation time and improves the quality of the resulting surface. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","Animation; Animation; Animation; Categories and Subject Descriptors (according to ACM CCS): I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling; Fluid modelling; Physically based animation; Physically based modelling I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism","Animation; Computational geometry; Mesh generation; Three dimensional computer graphics; Topology; Fluid modelling; High resolution simulations; I.3.7 [computer graphics]: three-dimensional graphics and realism; Object modelling; Optimization approach; Physically-based animation; Signed distance fields; Topological changes; Computer graphics",2-s2.0-85017366172
"Yu J.","A real-time 3D visual singing synthesis: From appearance to internal articulators",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009813078&doi=10.1007%2f978-3-319-51811-4_5&partnerID=40&md5=13f66d7ab89aac3be4fa8e52df91b7eb","A facial animation system is proposed for visual singing synthesis. With a reconstructed 3D head mesh model, both finite element method and anatomical model are used to simulate articulatory deformation corresponding to each phoneme with musical note. Based on an articulatory song corpus, articulatory movements, phonemes and musical notes are trained simultaneously to obtain the visual co-articulation model by a context-dependent Hidden Markov Model. Articulatory animations corresponding to all phonemes are concatenated by visual co-articulation model to produce the song synchronized articulatory animation. Experimental results demonstrate the system can synthesize realistic song synchronized articulatory animation for increasing the human computer interaction capability objectively and subjectively. © Springer International Publishing AG 2017.","Articulatory animation; Song-to-articulator mapping","Animation; Finite element method; Hidden Markov models; Human computer interaction; Markov processes; Anatomical modeling; Co-articulation; Context dependent; Facial animation; Mesh model; Musical notes; Real time; Singing synthesis; Three dimensional computer graphics",2-s2.0-85009813078
"Hamdan F., Matussin H., Serjuddin S., Phon-Amnuaisuk S., Shannon P.D.","3D facial expressions from performance data",2017,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994851427&doi=10.1007%2f978-3-319-48517-1_24&partnerID=40&md5=5695d7c56e96c368bf5a716446a799b5","Advances in facial animation technology have been extended into various creative applications such as computer games, 3D animations and interactive multimedia. In this work, we explore performance-driven facial animations using a rigged bone approach. A 3D face model is rigged with bones positioned at the desired control points. The performance information for controlling these control points are extracted using the marker-based technique where color dots are painted on a performer’s face at desired positions. Facial expression performances are recorded using a low cost camera. The information from the recorded performances is extracted and mapped onto a targeted face. Hence facial expression performances of the actor can be applied to different 3D model faces, provided that they share the same control points. This approach affords reusability of the facial performances without expensive equipment. We present the creative process of our approach, discuss the outcome and the prospect of future works. © Springer International Publishing AG 2017.","Face rigged bone; MEL script; Performance driven facial animation","Artificial intelligence; Bone; Computer games; Image coding; Information systems; Interactive computer systems; Multimedia systems; Reusability; 3-D face modeling; 3-d facial expressions; Expensive equipments; Facial Expressions; Interactive multimedia; MEL script; Performance data; Performance-driven facial animation; Animation",2-s2.0-84994851427
"Schröder M., Waltemate T., Maycock J., Röhlig T., Ritter H., Botsch M.","Design and evaluation of reduced marker layouts for hand motion capture",2017,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017366156&doi=10.1002%2fcav.1751&partnerID=40&md5=f2037e80f8aca9718f7d9e0eb9149b30","We present a method for automatically generating reduced marker layouts for marker-based optical motion capture of human hands. The employed motion reconstruction method is based on subspace-constrained inverse kinematics, which allows for the recovery of realistic hand movements even from sparse input data. We additionally present a user-specific hand model calibration procedure that fits an articulated hand model to point cloud data of the user's hand. Our marker layout optimization is sensitive to the kinematic structure and the subspace representations of hand articulations utilized in the reconstruction method, in order to generate sparse marker configurations that are optimal for solving the constrained inverse kinematics problem. We propose specific quality criteria for reduced marker sets that combine numerical stability with geometric feasibility of the resulting layout. These criteria are combined in an objective function that is minimized using a specialized surface-constrained particle swarm optimization scheme, which generates marker layouts bound to the surface of an animated hand model. Our method provides a principled way for determining reduced marker layouts based on subspace representations of hand articulations. We demonstrate the effectiveness of our motion reconstruction and model calibration methods in a thorough evaluation. © 2017 John Wiley & Sons, Ltd.","Computer animation; Geometric modeling; Hand tracking; Motion capture","Animation; Constrained optimization; End effectors; Inverse kinematics; Kinematics; Particle swarm optimization (PSO); Stability criteria; Computer animation; Constrained particle swarm optimization; Design and evaluations; Geometric modeling; Hand tracking; Motion capture; Optical motion capture; Subspace representation; Inverse problems",2-s2.0-85017366156
"Jing Y., Guo S., Wu X.","Vocal music teaching mode based on a computer platform",2017,"Agro Food Industry Hi-Tech",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020528766&partnerID=40&md5=c27273151b1661f2a7c3ed86c9db527d","The purpose of this study is to study the teaching mode of vocal music based on a computer platform. Spectrogram analysis in traditional vocal music teaching and multimedia animation vocal music teaching are used as the key technologies in the platform. The vocal music teaching method and reforms made to improve the method can enhance the quality of vocal music teaching, cultivate students' innovative spirit and practice ability, as well as improve their ability to learn effective measures. A new means of teaching method for reformation can maximize the initiatives of both teachers and students, heighten their enthusiasm and creativity, create the ""teaching"" and ""learning"" interactive atmosphere, help create an abstract visualization of the vocal music teaching and visualization, as well as promote the students' singing ability, practical skills, and innovativeness. Analysis and validation of the vocal music teaching method are both conducted to ensure the achievement of optimal skills.","Computer platform; Spectrogram analysis; Teaching mode; Vocal music","Education; Spectrographs; Students; Visualization; Computer platforms; Effective measures; Innovative spirit; Key technologies; Multimedia animation; Spectrograms; Teaching modes; Vocal music; Teaching",2-s2.0-85020528766
"Htike K.K.","A review on data-driven learning of a talking head model",2017,"International Journal of Intelligent Systems Technologies and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019683781&doi=10.1504%2fIJISTA.2017.084239&partnerID=40&md5=314a92f16c09d6be68cbeeccb3b57c1d","Constructing a talking head model of a person allows generation of a novel talking face animation from an unseen audio sequence of the person. This has important applications such as building virtual avatars of people that can interact with real people in novel situations, model-based video compression, teleconferencing, human-computer interaction, computer graphics and video games. Traditionally, talking head models have been built by manual painstaking work. The advancement of computer vision and machine learning techniques, especially in the past decade, has made possible the automatic learning of a talking head model of a person from data. In this paper, we focus on this area of machine learning based data-driven facial animation and critically review the most common approaches, compare and contrast among them and identify promising research directions and prospects. © Copyright 2017 Inderscience Enterprises Ltd.","Animated speech; Audio-driven facial motion synthesis; Audio-visual correlation; Facial animation; Talking face; Virtual avatar","Animation; Artificial intelligence; Computer games; Computer graphics; Computer vision; Image compression; Interactive computer graphics; Learning systems; Virtual reality; Animated speech; Audio-visual correlations; Facial animation; Facial motions; Talking face; Virtual avatar; Human computer interaction",2-s2.0-85019683781
"Ribera R.B.I., Zell E., Lewis J.P., Noh J., Botsch M.","Facial retargeting with automatic range of motion alignment",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030774292&doi=10.1145%2f3072959.3073674&partnerID=40&md5=c57d1f44de11b834620f56fbce047e92","While facial capturing focuses on accurate reconstruction of an actor's performance, facial animation retargeting has the goal to transfer the animation to another character, such that the semantic meaning of the animation remains. Because of the popularity of blendshape animation, this effectively means to compute suitable blendshape weights for the given target character. Current methods either require manually created examples of matching expressions of actor and target character, or are limited to characters with similar facial proportions (i.e., realistic models). In contrast, our approach can automatically retarget facial animations from a real actor to stylized characters. We formulate the problem of transferring the blendshapes of a facial rig to an actor as a special case of manifold alignment, by exploring the similarities of the motion spaces defined by the blendshapes and by an expressive training sequence of the actor. In addition, we incorporate a simple, yet elegant facial prior based on discrete differential properties to guarantee smooth mesh deformation. Our method requires only sparse correspondences between characters and is thus suitable for retargeting marker-less and marker-based motion capture as well as animation transfer between virtual characters. © 2017 ACM.","Blendshapes; Facial animation; Retargeting","Interactive computer graphics; Semantics; Blendshape animation; Blendshapes; Differential properties; Facial animation; Manifold alignments; Retargeting; Sparse correspondence; Training sequences; Animation",2-s2.0-85030774292
"Duan S.-M.","Development and review of multimedia information processing technology",2017,"Recent Patents on Computer Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028917725&doi=10.2174%2f2213275909666161117160136&partnerID=40&md5=3638501ad5320e28b987222d2a212fab","Background: Multimedia information processing technology is an important part in the field of computer information processing, as described in various patents. Method: In order to solve the problems existing in different methods in this field, this paper focused on image processing, audio processing, video processing, 3D animation technology and other information processing technology and the application of the technology’s frontier approach to make a detailed theoretical analysis and describe their application. The principle and the prospect of the application and the existing problems were also analyzed. The validity of the proposed viewpoint was proved by experiments. Result: Improved algorithm significantly increased the quantity of processed information and processing efficiency, and reduced the error rate. Conclusion: Through the summary of multimedia information processing technology, an effective basis for the related research is provided. © 2017 Bentham Science Publishers.","3D animation technology; Audio processing; Image processing; Information processing technology; Multimedia","Animation; Audio signal processing; Three dimensional computer graphics; Video signal processing; 3D animation; Audio processing; Existing problems; Information processing technology; Multimedia; Multimedia information processing; Processed information; Video processing; Image processing",2-s2.0-85028917725
"Ebling S., Johnson S., Wolfe R., Moncrief R., McDonald J., Baowidan S., Haug T., Sidler-Miserez S., Tissi K.","Evaluation of animated Swiss German sign language fingerspelling sequences and signs",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025150892&doi=10.1007%2f978-3-319-58703-5_1&partnerID=40&md5=37f47c3514a973c84f3b304268631bf4","This paper reports on work in animating Swiss German Sign Language (DSGS) fingerspelling sequences and signs as well as on the results of a study evaluating the acceptance of the animations. The animated fingerspelling sequences form part of a fingerspelling learning tool for DSGS, while the animated signs are to be used in a study exploring the potential of sign language avatars in sign language assessment. To evaluate the DSGS fingerspelling sequences and signs, we conducted a focus group study with seven early learners of DSGS. We identified the following aspects of the animations as requiring improvement: nonmanual features (in particular, facial expressions and head and shoulder movements), (fluidity of) manual movements, and hand positions of fingerspelling signs. © Springer International Publishing AG 2017.","Animation evaluation; Focus group; Sign language animation","Animation; Facial Expressions; Focus group studies; Focus groups; Hand positions; Learning tool; Shoulder movements; Sign language; Human computer interaction",2-s2.0-85025150892
"Chouinard-Thuly L., Gierszewski S., Rosenthal G.G., Reader S.M., Rieucau G., Woo K.L., Gerlai R., Tedore C., Ingley S.J., Stowers J.R., Frommen J.G., Dolins F.L., Witte K.","Technical and conceptual considerations for using animated stimuli in studies of animal behavior",2017,"Current Zoology",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014841406&doi=10.1093%2fcz%2fzow104&partnerID=40&md5=bf5ef23552f969b793671a42cd2b9e61","Rapid technical advances in the field of computer animation (CA) and virtual reality (VR) have opened new avenues in animal behavior research. Animated stimuli are powerful tools as they offer standardization, repeatability, and complete control over the stimulus presented, thereby ""reducing"" and ""replacing"" the animals used, and ""refining"" the experimental design in line with the 3Rs. However, appropriate use of these technologies raises conceptual and technical questions. In this review, we offer guidelines for common technical and conceptual considerations related to the use of animated stimuli in animal behavior research. Following the steps required to create an animated stimulus, we discuss (I) the creation, (II) the presentation, and (III) the validation of CAs and VRs. Although our review is geared toward computer-graphically designed stimuli, considerations on presentation and validation also apply to video playbacks. CA and VR allow both new behavioral questions to be addressed and existing questions to be addressed in new ways, thus we expect a rich future for these methods in both ultimate and proximate studies of animal behavior. © The Author (2016).","Animal behavior; Animated stimulus; Computer animation; Experimental design; Virtual reality; Visual communication",,2-s2.0-85014841406
"Peng X.B., Berseth G., Yin K., Van De Panne M.","DeepLoco: Dynamic locomotion skills using hierarchical deep reinforcement learning",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030768433&doi=10.1145%2f3072959.3073602&partnerID=40&md5=239249820999b026609e2d6ea06e7c5a","Learning physics-based locomotion skills is a difficult problem, leading to solutions that typically exploit prior knowledge of various forms. In this paper we aim to learn a variety of environment-aware locomotion skills with a limited amount of prior knowledge. We adopt a two-level hierarchical control framework. First, low-level controllers are learned that operate at a fine timescale and which achieve robust walking gaits that satisfy stepping-target and style objectives. Second, high-level controllers are then learned which plan at the timescale of steps by invoking desired step targets for the low-level controller. The high-level controller makes decisions directly based on high-dimensional inputs, including terrain maps or other suitable representations of the surroundings. Both levels of the control policy are trained using deep reinforcement learning. Results are demonstrated on a simulated 3D biped. Low-level controllers are learned for a variety of motion styles and demonstrate robustness with respect to force-based disturbances, terrain variations, and style interpolation. High-level controllers are demonstrated that are capable of following trails through terrains, dribbling a soccer ball towards a target location, and navigating through static or dynamic obstacles. © 2017 ACM.","Locomotion skills; Motion control; Physics-based character animation","Animation; Deep learning; Dynamics; Interactive computer graphics; Level control; Motion control; Reinforcement learning; Character animation; Dynamic obstacles; High level controllers; High-dimensional; Learning physics; Low-level controllers; Style interpolation; Two-level hierarchical controls; Controllers",2-s2.0-85030768433
"Zhang W.","Research on chemical reaction simulation platform based on animation model",2017,"Chemical Engineering Transactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026421581&doi=10.3303%2fCET1759109&partnerID=40&md5=f88c9e097bf28ca25fab971756a4e489","With the continuous development of computer technology and the popularity of network technology, virtual reality technology has also been rapidly developed. As an important branch of virtual reality technology, the simulation experiment is gradually applied in various fields according to its excellent three-dimensional expression and interaction characteristics, and has become an important part of computer assisted instruction, arousing widespread concern. The cognitive learning theory, media theory and constructivist learning theory are taken as the guidance to establish a set of simulation system about organic chemistry micro teaching, so that students can get rid of the limitation of time and space to explore the microscopic world movement law. The simulation experiment of the bromine electrophilic addition reaction mechanism is developed by using the virtual reality technology based on X3D standard development, simulating the whole process of the reaction mechanism. Through the development of the simulation experiment, the general modeling method and development process based on of X3D standard are mainly described, and the interactive mechanism and interaction of X3D standard are analyzed. With the further improvement of network bandwidth, the simulation experiment based on X3D standard not only simulates the abstract concepts and principal in teaching field by using its unique encoding and the interaction mechanism, but also can transmit conveniently on the internet. The virtual simulation technology based on Web becomes the future development direction. With the rapidly development and popularization of virtual reality technology, it will bring profound and extensive influence to the society and education field. Copyright © 2017, AIDIC Servizi S.r.l.",,"Addition reactions; Computer aided instruction; Education; Education computing; Standardization; Virtual reality; Cognitive learning theories; Computer Assisted Instruction; Constructivist learning theory; Continuous development; Electrophilic addition reactions; Interaction characteristics; Interaction mechanisms; Virtual reality technology; Engineering education",2-s2.0-85026421581
"Miranda C.R., Orvalho V.C.","Consumer-level virtual reality motion capture",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028339514&doi=10.1007%2f978-3-319-64870-5_18&partnerID=40&md5=8ec827ceb25f8216182424d2d3e4f386","Virtual Reality (VR) is creating a new paradigm in humans’ communication. Today, we can enter in a virtual environment and interact with each other through 3D characters. However, VR headsets occlude user’s face, limiting the Motion Capture (MoCap) of facial expressions and, thus, limiting the introduction of this non-verbal component. The unique solution available is not suitable for consumer-level applications, relying on complex hardware and calibrations. In this work, we deliver consumer-level methods for facial MoCap under VR environments. We developed an occlusions-support method compatible with generic facial MoCap systems. Then, we extract facial features and deploy Random Forests algorithms that accurately estimate emotions and upper face movements occluded by the headset. Our VR MoCap methods are validated and a facial animation use case is provided. With our novel methods, both calibration and hardware is reduced, making possible face-to-face communication in VR environments. © Springer International Publishing AG 2017.","Emotion and expressions recognition; Facial animation; Facial motion capture; Virtual reality","Animation; Calibration; Computer graphics; Computer hardware; Computer vision; Decision trees; Hardware; Complex hardware; Emotion and expressions recognition; Face-to-face communications; Facial animation; Facial Expressions; Facial feature; Facial motion capture; Random forests; Virtual reality",2-s2.0-85028339514
"Kurihara T., Li L., Ishida M., Hoshino J.","Japanese anime production support system with digital storyboards",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028986131&doi=10.1007%2f978-3-319-66715-7_45&partnerID=40&md5=1f2a40731da73d8f9f68080bb4414cdc","Storyboards are used in the beginning stages of making animation to explain the story or screenplay. This paper proposes a system which assists with storyboard writing and the production process. This system is used with a tablet that allows for input with a pen. It automatically calculates the number of cuts and time required for each scene and can automatically produce a schedule from storyboards. This system makes management for overall animation easy. © IFIP International Federation for Information Processing 2017 Published by Springer International Publishing AG 2017. All Rights Reserved.","Animation production; Schedule; Storyboards","Artificial intelligence; Computer science; Computers; Scheduling; Production process; Production support systems; Storyboards; Animation",2-s2.0-85028986131
"Moldoveanu A., Nazare A.-K., Dascălu M.-I.","Immersive natural EEG neurofeedback to stimulate creativity",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029446256&doi=10.1007%2f978-3-319-65551-2_53&partnerID=40&md5=9a06181682f6af8ede16c6d50c0464bf","We propose a natural, 3D immersive and real-time representation of the mental state acquired through EEG. Unlike most other neurofeedback methods currently in use, which are mostly simplistic, synthetic representations, our approach will make use of rich natural visual metaphors, presented immersivity and user-centric. This powerful approach will stimulate deep neurofeedback-based learning and opens a wide range of applications, from the personal training of various mental capabilities (relaxation, focus, etc.) to psychological or psychiatric treatment. In this paper, we present the general concept of the system (acquiring the EEG data, it’s processing, mapping, and rendering) and discuss one of its most promising applications - in stimulating users’ creativity. There is detailed a training protocol to enhance neurological processes related to the creative activity, based on researched studies. © Springer International Publishing AG 2017.","Brain waves; Brain-computer interface; EEG; Neurofeedback; Procedural animation and generation; Virtual reality","Electroencephalography; Interfaces (computer); Virtual reality; Brain wave; Creative activity; Neurofeedback; Neurological process; Personal trainings; Procedural animation; Synthetic representations; Visual metaphor; Brain computer interface",2-s2.0-85029446256
"Sun H., Xia G., Zhang G., Feng L.","Survey on reuse of human motion capture data",2017,"Shuju Caiji Yu Chuli/Journal of Data Acquisition and Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016088017&doi=10.16337%2fj.1004-9037.2017.01.001&partnerID=40&md5=1488935870473c23df353b6bfd736aac","Human motion capture data, as a new type of multimedia data, is widely used in many areas because of its high fidelity, but the expensive motion capture equipment yields the high cost of the use of motion capture data. Therefore, the technologies of motion capture data reuse become the effective means to solve the problem. However, the complex structure and characteristics of motion capture data make the motion capture data reuse challenging. Even it has been researched for many years, there are still many problems to be solved and more attentions and research efforts are needed. In this paper, in terms of the important technologies used in the process of motion capture data reuse, we give introductions on the research significance, difficulties, strategy and used models of current methods and so on. And we give a detailed description on some representative methods. Finally, we conclude the research advances of motion capture data reuse and discuss the possible directions for future works. This aims to cause the deep thinking of this field and provides a valuable reference for the future research. © 2017, Editorial Department of Journal of Data Acquisition and Processing. All right reserved.","Computer animation; Human motion; Machine learning; Motion capture; Motion reuse",,2-s2.0-85016088017
"Tedore C., Johnsen S.","Using RGB displays to portray color realistic imagery to animal eyes",2017,"Current Zoology",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014845657&doi=10.1093%2fcz%2fzow076&partnerID=40&md5=47373fe9f0c0b95f9048c946fa3a0ab7","RGB displays effectively simulate millions of colors in the eyes of humans by modulating the relative amount of light emitted by 3 differently colored juxtaposed lights (red, green, and blue). The relationship between the ratio of red, green, and blue light and the perceptual experience of that light has been well defined by psychophysical experiments in humans, but is unknown in animals. The perceptual experience of an animal looking at an RGB display of imagery designed for humans is likely to poorly represent an animal's experience of the same stimulus in the real world. This is due, in part, to the fact that many animals have different numbers of photoreceptor classes than humans do and that their photoreceptor classes have peak sensitivities centered over different parts of the ultraviolet and visible spectrum. However, it is sometimes possible to generate videos that accurately mimic natural stimuli in the eyes of another animal, even if that animal's sensitivity extends into the ultraviolet portion of the spectrum. How independently each RGB phosphor stimulates each of an animal's photoreceptor classes determines the range of colors that can be simulated for that animal. What is required to determine optimal color rendering for another animal is a device capable of measuring absolute or relative quanta of light across the portion of the spectrum visible to the animal (i.e., a spectrometer), and data on the spectral sensitivities of the animal's photoreceptor classes. In this article, we outline how to use such equipment and information to generate video stimuli that mimic, as closely as possible, an animal's color perceptual experience of real-world objects. © The Author (2016).","Color vision; Computer animation; Perception; Video playback; Virtual reality",,2-s2.0-85014845657
"Yoon J.-C., Yoon I.S., Hong J.-S.","Naturalized motion generator for NPC in 3D game",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028986354&doi=10.1007%2f978-3-319-66715-7_41&partnerID=40&md5=407d161122b228fe46ee3950980097cc","In the 3D game, there are many NPCs for various purposes, and the variety of motion of these NPCs increases the immersion feeling of the game. In this paper, we propose a noise - based motion editing technique that can add diversity and naturalness to the motion of NPCs. In the area of computer graphics, noise function has been used as a classical method of applying the naturalness of the animation. We extract these noise functions from existing motion signals and control them to make many similar motions naturally. © IFIP International Federation for Information Processing 2017 Published by Springer International Publishing AG 2017. All Rights Reserved.","Character animation; Noise fitting; Noise function","Computer graphics; 3D games; Character animation; Classical methods; Motion editing; Motion generator; Motion signals; Noise fitting; Noise function; Animation",2-s2.0-85028986354
"Holden D., Komura T., Saito J.","Phase-functioned neural networks for character control",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030761955&doi=10.1145%2f3072959.3073663&partnerID=40&md5=3a0ae25a475f8b884685a713eb0a2c18","We present a real-time character control mechanism using a novel neural network architecture called a Phase-Functioned Neural Network. In this network structure, the weights are computed via a cyclic function which uses the phase as an input. Along with the phase, our system takes as input user controls, the previous state of the character, the geometry of the scene, and automatically produces high quality motions that achieve the desired user control. The entire network is trained in an end-to-end fashion on a large dataset composed of locomotion such as walking, running, jumping, and climbing movements fitted into virtual environments. Our system can therefore automatically produce motions where the character adapts to different geometric environments such as walking and running over rough terrain, climbing over large rocks, jumping over obstacles, and crouching under low ceilings. Our network architecture produces higher quality results than time-series autoregressive models such as LSTMs as it deals explicitly with the latent variable of motion relating to the phase. Once trained, our system is also extremely fast and compact, requiring only milliseconds of execution time and a few megabytes of memory, even when trained on gigabytes of motion data. Our work is most appropriate for controlling characters in interactive scenes such as computer games and virtual reality systems. © 2017 Copyright held by the owner/author(s).","Character animation; Character control; Deep learning; Human motion; Locomotion; Neural networks","Animation; Biped locomotion; Computer games; Deep learning; Interactive computer graphics; Neural networks; Quality control; Virtual reality; Auto regressive models; Character animation; Control mechanism; Human motions; Latent variable; Network structures; Novel neural network; Virtual reality system; Network architecture",2-s2.0-85030761955
"Sharaf N., Abdennadher S., Frühwirth T.","Using rules to animate prolog programs",2017,"CEUR Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027870099&partnerID=40&md5=3ea0cae59f3d71e53002ba40fdbe9caa","The paper provides a methodology to visualize the execution of Prolog programs. Program animation is useful in debugging programs. It could also help beginners to Prolog understand how Prolog works. The provided approach uses Constraint Handling Rules (CHR). The aim of the work is to animate the algorithm implemented by the Prolog program.","Animation; Constraint handling rules; Prolog programs","Animation; Computer programming languages; Program debugging; Constraint Handling Rules; Program animation; Prolog programs; PROLOG (programming language)",2-s2.0-85027870099
"Zilverschoon M., Vincken K.L., Bleys R.L.A.W.","The virtual dissecting room: Creating highly detailed anatomy models for educational purposes",2017,"Journal of Biomedical Informatics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999293341&doi=10.1016%2fj.jbi.2016.11.005&partnerID=40&md5=faccb224246c645fb088c48fcd25c47e","Introduction Virtual 3D models are powerful tools for teaching anatomy. At the present day, there are a lot of different digital anatomy models, most of these commercial applications are based on a 3D model of a human body reconstructed from images with a 1 mm intervals. The use of even smaller intervals may result in more details and more realistic appearances of 3D anatomy models. The aim of this study was to create a realistic and highly detailed 3D model of the hand and wrist based on small interval cross-sectional images, suitable for undergraduate and postgraduate teaching purposes with the possibility to perform a virtual dissection in an educational application. Methods In 115 transverse cross-sections from a human hand and wrist, segmentation was done by manually delineating 90 different structures. With the use of Amira the segments were imported and a surface model/polygon model was created, followed by smoothening of the surfaces in Mudbox. In 3D Coat software the smoothed polygon models were automatically retopologied into a quadrilaterals formation and a UV map was added. In Mudbox, the textures from 90 structures were depicted in a realistic way by using photos from real tissue and afterwards height maps, gloss and specular maps were created to add more level of detail and realistic lightning on every structure. Unity was used to build a new software program that would support all the extra map features together with a preferred user interface. Conclusion A 3D hand model has been created, containing 100 structures (90 at start and 10 extra structures added along the way). The model can be used interactively by changing the transparency, manipulating single or grouped structures and thereby simulating a virtual dissection. This model can be used for a variety of teaching purposes, ranging from undergraduate medical students to residents of hand surgery. Studying the hand and wrist anatomy using this model is cost-effective and not hampered by the limited access to real dissecting facilities. © 2016 Elsevier Inc.","3D anatomy model; 3D animation software; Anatomy education; Hand and wrist; Virtual dissection","Cost effectiveness; E-learning; Education; Education computing; Students; User interfaces; 3D animation; Anatomy educations; Commercial applications; Cross sectional image; Different structure; Educational Applications; Grouped structures; Hand and wrist; Three dimensional computer graphics; anatomic model; Article; computer model; dissection; hand; human; image segmentation; medical education; priority journal; simulation; software; surgical anatomy; three dimensional imaging; virtual reality; wrist",2-s2.0-84999293341
"Karamouzas I., Sohre N., Narain R., Guy S.J.","Implicit crowds: Optimization integrator for robust crowd simulation",2017,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029154013&doi=10.1145%2f3072959.3073705&partnerID=40&md5=e5737a4034a1df897e24e353caa1314c","Large multi-agent systems such as crowds involve inter-agent interactions that are typically anticipatory in nature, depending strongly on both the positions and the velocities of agents. We show how the nonlinear, anticipatory forces seen in multi-agent systems can be made compatible with recent work on energy-based formulations in physics-based animation, and propose a simple and effective optimization-based integration scheme for implicit integration of such systems. We apply this approach to crowd simulation by using a state-of-the-art model derived from a recent analysis of human crowd data, and adapting it to our framework. Our approach provides, for the first time, guaranteed collision-free motion while simultaneously maintaining high-quality collective behavior in a way that is insensitive to simulation parameters such as time step size and crowd density. These benefits are demonstrated through simulation results on various challenging scenarios and validation against real-world crowd data. © 2017 Copyright held by the owner/author(s).","Crowd simulation; Implicit integration; Physics-based animation","Animation; Integration; Interactive computer graphics; Collective behavior; Crowd Simulation; Implicit integration; Integration scheme; Inter-agent interactions; Physics-based animation; Simulation parameters; State of the art; Multi agent systems",2-s2.0-85029154013
"Guo Y., Chen X.","Research on improving and optimizing of 3D reconstruction based on single image",2017,"Boletin Tecnico/Technical Bulletin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029582678&partnerID=40&md5=d212541a046db962e79bd14a1f3de2b3","With the rapid development of computer technology, as a new type of high-tech, Image processing technology in the computer animation, video games, movies, clothing, construction and other industries have important position, the reconstruction of three-D images as an important branch of computer vision, has a very broad application prospects and application value. In this study, the three-dimensional surface information of the object is obtained from the single image by gradient optimization method. The normal and illumination rendering are transformed into the gradient of the image, which makes it three-dimensional deformation and re-illumination through the two-dimensional interaction. At the same time, the algorithm of numerical integration and spline interpolation is used to obtain more surface depth information, so that the smoothness of reconstruction is better. Finally, the algorithm performance and time complexity are analyzed and verified by image processing simulation experiment. The research of this subject has very high theoretical value and practical significance, which promotes the development of computer vision in computer technology, which is of great significance to the future research of image processing.","3D reconstruction; Computer technology; Image Processing; Machine vision; Silhouette optimization","Animation; Computer games; Computer vision; Image reconstruction; Interpolation; Optimization; Three dimensional computer graphics; Video signal processing; 3D reconstruction; Algorithm performance; Computer technology; Illumination rendering; Image processing technology; Numerical integrations; Three-dimensional deformations; Three-dimensional surface; Image processing",2-s2.0-85029582678
"Kilias A., Mousas C.","Motion style transfer in correlated motion spaces",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021247592&doi=10.1007%2f978-3-319-60922-5_18&partnerID=40&md5=35d8b1adf37b5a1e1e715739b27be185","This paper presents a methodology for transferring different motion style behaviors to virtual characters. Instead of learning the differences between two motion styles and then synthesizing the new motion, the presented methodology assigns to the style transformation the motion’s distribution transformation process. Specifically, in this paper, the joint angle values of motion are considered as a three-dimensional stochastic variable and as a set of samples respectively. Thus, the correlation between three components can be computed by the covariance. The presented method imports covariance between three components of joint angle values, while calculating the mean along each of the three axes. Then, by decomposing the covariance matrix using the singular value decomposition (SVD) algorithm, it is possible to retrieve a rotation matrix. For fitting the motion style of an input to a reference motion style, the joint angle orientation of the input motion is scaled, rotated and transformed to the reference style motion, therefore enabling the motion transfer process. The results obtained from such a methodology indicate that quite reasonable motion sequences can be synthesized while keeping the required style content. © Springer International Publishing AG 2017.","Character animation; Motion style; Style transfer","Animation; Augmented reality; Computer graphics; Covariance matrix; Stochastic systems; Virtual reality; Character animation; Correlated motions; Motion styles; Singular value decomposition algorithms; Stochastic variable; Style transfer; Transformation process; Virtual character; Singular value decomposition",2-s2.0-85021247592
"Mokhtar M.K., Mohamed F., Sunar M.S.","Real-time rendering blood flow visualisation using particle based technique",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029393606&doi=10.1007%2f978-981-10-6502-6_55&partnerID=40&md5=17accbce91652f942e78c1d2705cba33","The use of scientific visualization technique in real-time rendering environment has great potential to enhance user interaction in visualizing blood flow; therefore the integration algorithm of chosen scientific visualization technique and real-time algorithm should be developed and implemented in virtual environment. It is a basic fact that the effectiveness of blood flow visualization are reliant on two fundamental issues. First is how to present an improved visualization of cardiovascular flow, and the second is how to interactively visualize the fluidic blood flow in gaining insight into the cardiovascular physiology. This research proposed a framework on based on idea from previous research that improve visualization of blood flow by integrates with particle based simulation method in order to allow more user interaction. Despite the variety and number of existing method, there are still demands for new improved visualization technique with a mission to provide better information. Good understanding on blood flow pattern will aid clinician, engineer and researcher during the diagnosis and prognosis of pathology as well as the assessment of risk and follow-up finding. © Springer Nature Singapore Pte Ltd. 2017.","Blood flow; Physic-based animation; Position-based dynamic; Scientific visualization","Blood; Data visualization; Flow patterns; Flow visualization; Hemodynamics; Risk assessment; Virtual reality; Visualization; Based animations; Blood flow; Blood flow patterns; Diagnosis and prognosis; Integration algorithm; Particle based simulation methods; Real time algorithms; Visualization technique; Rendering (computer graphics)",2-s2.0-85029393606
"Cremonesi P., Garzotto F., Gribaudo M., Piazzolla P., Iacono M.","Toward a new fashion concepts design tool: The vMannequin framework",2017,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013113401&doi=10.1007%2f978-3-319-48511-9_11&partnerID=40&md5=1ec3deb8310a0231923daf6b72c5b5f0","IT offers significant tools to foster innovation in the fashion industry. Although the products have a low information content, the information content of the overall development and production process may be rich, specially for high end productions, and the same happens for ancillary processes connected to sales and after sales. In this paper we present the vMannequin framework, designed to assist the sales process by means of an interactive computer graphics assistance system that allows a customer to virtually explore, live or remotely, his experience with a chosen outfit, with possibility of customization. vMannequin is based on off the shelf systems, and is then applicable also to the small business segment, providing new ways for business development. © Springer International Publishing AG 2017.","3D computer graphics; Clothing animation; End user development; Fashion concept design","Computer graphics; Human computer interaction; Interactive computer graphics; Three dimensional computer graphics; 3D computer graphics; Assistance system; Business development; Concept designs; End user development; Information contents; Off-the-shelf systems; Production process; Sales",2-s2.0-85013113401
"Huang J., Wang Q., Fratarcangeli M., Yan K., Pelachaud C.","Multi-Variate Gaussian-Based Inverse Kinematics",2017,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013644375&doi=10.1111%2fcgf.13089&partnerID=40&md5=1baf2296ce16af8d7764aafbd3ef5ba3","Inverse kinematics (IK) equations are usually solved through approximated linearizations or heuristics. These methods lead to character animations that are unnatural looking or unstable because they do not consider both the motion coherence and limits of human joints. In this paper, we present a method based on the formulation of multi-variate Gaussian distribution models (MGDMs), which precisely specify the soft joint constraints of a kinematic skeleton. Each distribution model is described by a covariance matrix and a mean vector representing both the joint limits and the coherence of motion of different limbs. The MGDMs are automatically learned from the motion capture data in a fast and unsupervised process. When the character is animated or posed, a Gaussian process synthesizes a new MGDM for each different vector of target positions, and the corresponding objective function is solved with Jacobian-based IK. This makes our method practical to use and easy to insert into pre-existing animation pipelines. Compared with previous works, our method is more stable and more precise, while also satisfying the anatomical constraints of human limbs. Our method leads to natural and realistic results without sacrificing real-time performance. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","Animation; Animation; Clustering; Guassian process; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism; Inverse kinematics; Jacobian","Animation; Computer graphics; Covariance matrix; Gaussian distribution; Inverse kinematics; Joints (anatomy); Kinematics; Three dimensional computer graphics; Anatomical constraint; Approximated linearization; Clustering; Gaussian distribution model; I.3.7 [computer graphics]: three-dimensional graphics and realism; Jacobians; Objective functions; Real time performance; Inverse problems",2-s2.0-85013644375
"Palma G., Sabbadin M., Corsini M., Cignoni P.","Enhanced Visualization of Detected 3D Geometric Differences",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021417627&doi=10.1111%2fcgf.13239&partnerID=40&md5=6ad030efa8e03ce0913a85afa0e0ab0b","The wide availability of 3D acquisition devices makes viable their use for shape monitoring. The current techniques for the analysis of time-varying data can efficiently detect actual significant geometric changes and rule out differences due to irrelevant variations (such as sampling, lighting and coverage). On the other hand, the effective visualization of such detected changes can be challenging when we want to show at the same time the original appearance of the 3D model. In this paper, we propose a dynamic technique for the effective visualization of detected differences between two 3D scenes. The presented approach, while retaining the original appearance, allows the user to switch between the two models in a way that enhances the geometric differences that have been detected as significant. Additionally, the same technique is able to visually hides the other negligible, yet visible, variations. The main idea is to use two distinct screen space time-based interpolation functions for the significant 3D differences and for the small variations to hide. We have validated the proposed approach in a user study on a different class of datasets, proving the objective and subjective effectiveness of the method. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","I.4.8 [Image processing and Computer Vision]: Scene Analysis-Time-varying imagery I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation; Interaction; Interaction techniques; Perceptually based rendering; Rendering; Scientific visualization; Visualization","Computer graphics; Data visualization; Flow visualization; Geometry; Image processing; Rendering (computer graphics); Visualization; Interaction; Interaction techniques; Perceptually based rendering; Rendering; Scene analysis; Three dimensional computer graphics",2-s2.0-85021417627
"Henno J., Jaakkola H., Mäkelä J.","Tests of graphics rendering in browsers",2017,"CEUR Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030767696&partnerID=40&md5=a775414996e59fa87d34c7f013059057","Web browsers have become one of the most commonly used software and are important communication tool to access our data-driven, increasingly visual Internet. Browser graphics speed is essential for many commercial web applications - e-commerce sites, web portals, content management systems (CMS's), therefore web developers should well understand their possibilities. Browsers can be seen as multi-input (HTML-text, images, CSS, Scripts) multi-output (code for processor, graphics card, sound system) translators, but little is known about their 'internal life', especially how they render graphics. Browsers interpreting HTML5 documents have two graphic modes: Retained Mode (images defined in HTML text and animated with CSS) and Immediate Mode (images created on canvas and animated with JavaScript). In order to understand differences of these modes in animation rendering speed were created nine different versions of an animation of Lunar Eclipse which were tested in six major PC and Android mobile phone browsers. Results indicate, that there are no significant differences in major browsers except that IE and Edge (still) lag behind in implementing novel graphics/video formats and that in all tested browsers Retained Mode is at least two times quicker than Immediate Mode. © Copyright 2017 by the paper's authors.","CSS3; HTML5; JavaScript; Rendering; SVG","Animation; Application programs; Computer graphics; Computer software selection and evaluation; High level languages; HTML; Portals; Quality control; Web browsers; Communication tools; Content management system; CSS3; E-commerce sites; Graphics rendering; HTML5; Javascript; Rendering; Rendering (computer graphics)",2-s2.0-85030767696
"Rizescu C.I., Rizescu D.","The study of pinion - Rack mechanism using matlab and spyder-python",2017,"International Journal of Mechatronics and Applied Mechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029801572&partnerID=40&md5=30ef64e93e435093e54a90b16f7d0392","The study presents a comparison between a graphic simulation of a pinion-rack mechanism operating developed both in Matlab and PYTHON environments. Also some remarks, concerning the software’s efficiency and an economic analysis efficiency-cost of the two software, are presented in this study which have an identical use/purpose. Mainly, the idea of materialization of such a work has come out of necessity of programs usage that imply low purchase costs. From the point the view of acquisition, SPYDER-PYTHON is a open source e.g. free software. Spyder is the Scientific PYthon Development Environment. Both programs, MATLAB and PYTHON, can achieve certain accounts, can employ matrix and implement utility programs the difference between them are the used functions, because some of them don’t match. MATLAB is a broader program from the point of view of functions against PYTHON, but from the point of view of cost software PYTHON is the advantageous solution. Using PYTHON software in achieving performance and make an animation of pinion rack mechanism, it was noticed that the only differences between this program and MATLAB are certain functions with different syntaxes. In the pre-sent study it stands out in particular that both software are similar in terms of programming language and interface. Each environment has advantages and disadvantages and their use is identical in terms of performances compared to results. Considering that PYTHON environment uses a particular programming language MATLAB is much used in industry and academia worldwide. The study of present paper can be enhanced with new researches concerning the description and functionality of the programs as well as the presentation and improvement of the toolbox sites belonging PYTHON program, in order to achieve more complex animation in terms of the movement mechanisms. © 2017, Cefin Publishing House. All rights reserved.","Anaconda; Matlab; Pinion-rack mechanism; Pyton; Simulation; Spyder","Animation; Computer programming; Computer programming languages; Cost benefit analysis; Costs; Economic analysis; Efficiency; High level languages; MATLAB; Open source software; Open systems; Anaconda; Development environment; Free software; Graphic simulation; Movement mechanism; Pyton; Simulation; Spyder; Computer software",2-s2.0-85029801572
"Tomita A., Harada E.T., Ando S., Miyashiro K., Ohmori M., Yano H.","On-time measurement of subjective anxiety of a passenger in an autonomous vehicle: Gradually changing sounds decreases anxiety of passenger",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025165936&doi=10.1007%2f978-3-319-58472-0_17&partnerID=40&md5=252858fce679c53d51a743fd494ca747","The current study examined the possibility of measuring the subjective anxiety in real-time by means of a novel handle-shaped device, caused by riding an autonomous car. In our experiment, a participant was shown computer graphics (CG) animation, which gave the person a virtual experience of riding a new autonomous car. The CG animation stimuli were made with three variables: maximum speed (19 km/h, 160 km/h, or 320 km/h), acceleration/deceleration pattern (linear or exponential), and with and without ascending/descending sounds (sound, or no sound). The participants grasped the handle and moved it in the longitudinal direction, i.e., pulling when they experienced anxiety and pushing when they felt relaxed. Results of experiments by 16 participants showed that they moved the handle depending on the stimulus of speed at that instant, which indicated that our handle-shaped device was useful in assessing the participants’ anxiety on time. In addition, results indicated that sounds, especially those which gradually ascending with acceleration, could diminish the subjective anxiety under some conditions. © Springer International Publishing AG 2017.","Autonomous car; Psychological experiment with virtual reality; Subjective anxiety","Animation; Computer graphics; Human computer interaction; Transportation; Virtual reality; Acceleration/deceleration; Autonomous car; Autonomous Vehicles; Longitudinal direction; Maximum speed; Psychological experiment; Real time; Subjective anxiety; Ergonomics",2-s2.0-85025165936
"Díaz G., Iglesias A.","Swarm intelligence scheme for pathfinding and action planning of non-player characters on a last-generation video game",2017,"Advances in Intelligent Systems and Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012195850&doi=10.1007%2f978-981-10-3728-3_34&partnerID=40&md5=74eddc71cfd9d0885fe81150d609750c","Swarm intelligence is an emerging subfield of artificial intelligence (AI) where the sophisticated collective intelligence arising from a swarm of simple, unsophisticated individuals cooperating together is used to solve difficult problems. In our opinion, video games can be dramatically improved through swarm intelligence. As an illustration, we introduce a swam intelligence-based system for the representation and animation of some behavioral routines for the AI of the non-player characters (NPCs) of the last-generation first-person shooter video game “Isolated”. In this work we focus on the problems of pathfinding and action planning of the NPCs. Some computer experiments have been conducted to analyze the feasibility and performance of this approach. © Springer Nature Singapore Pte Ltd. 2017.","Action planning; Behavioral routines; Non-player characters; Pathfinding; Video game; Warm computation","Animation; Artificial intelligence; Human computer interaction; Interactive computer graphics; Learning algorithms; Action planning; Behavioral routines; Non-player character; Pathfinding; Video game; Swarm intelligence",2-s2.0-85012195850
"Zhang B., Wang S., Liu Y., Yang H.","Research on Trajectory Planning and Autodig of Hydraulic Excavator",2017,"Mathematical Problems in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019542734&doi=10.1155%2f2017%2f7139858&partnerID=40&md5=2d3d29f2091f5b7cd6e346654eead3fe","As the advances in computer control technology keep emerging, robotic hydraulic excavator becomes imperative. It can improve excavation accuracy and greatly reduce the operator's labor intensity. The 12-ton backhoe bucket excavator has been utilized in this research work where this type of excavator is commonly used in engineering work. The kinematics model of operation device (boom, arm, bucket, and swing) in excavator is established in both Denavit-Hartenberg coordinates for easy programming and geometric space for avoiding blind spot. The control approach is based on trajectory tracing method with displacements and velocities feedbacks. The trajectory planning and autodig program is written by Visual C++. By setting the bucket teeth's trajectory, the program can automatically plan the velocity and acceleration of each hydraulic cylinder and motor. The results are displayed through a 3D entity simulation environment which can present real-time movements of excavator kinematics. Object-Oriented Graphics Rendering Engine and skeletal animation are used to give accurate parametric control and feedback. The simulation result shows that a stable linear autodig can be achieved. The errors between trajectory planning command and simulation model are analyzed. © 2017 Bin Zhang et al.",,"C++ (programming language); Computer graphics; Computer software; Construction equipment; Engineering research; Excavators; Kinematics; Object oriented programming; Trajectories; Control technologies; Hydraulic cylinders; Hydraulic excavator; Kinematics modeling; Parametric control; Simulation environment; Skeletal animation; Trajectory Planning; Excavation",2-s2.0-85019542734
"Thiery J.-M., Eisemann E.","ARAPLBS: Robust and Efficient Elasticity-Based Optimization of Weights and Skeleton Joints for Linear Blend Skinning with Parametrized Bones",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019748792&doi=10.1111%2fcgf.13161&partnerID=40&md5=a94aa4f7d4528a512ca8f431aa4d6ed0","We present a fast, robust and high-quality technique to skin a mesh with reference to a skeleton. We consider the space of possible skeleton deformations (based on skeletal constraints, or skeletal animations), and compute skinning weights based on an optimization scheme to obtain as-rigid-as-possible (ARAP) corresponding mesh deformations. We support stretchable-and-twistable bones (STBs) and spines by generalizing the ARAP deformations to stretchable deformers. In addition, our approach can optimize joint placements. If wanted, a user can guide and interact with the results, which is facilitated by an interactive feedback, reached via an efficient sparsification scheme. We demonstrate our technique on challenging inputs (STBs and spines, triangle and tetrahedral meshes featuring missing elements, boundaries, self-intersections or wire edges). © 2017 The Eurographics Association and John Wiley & Sons Ltd.","Animation systems; Deformations; Geometric modelling; I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling-Curve; Solid and object representations; Surface","Bone; Computational geometry; Computer graphics; Deformation; Mesh generation; Surfaces; Animation systems; Geometric modelling; Interactive feedback; Object modelling; Optimization scheme; Self-intersections; Solid and object representation; Tetrahedral meshes; Musculoskeletal system",2-s2.0-85019748792
"Pokorný P., Jarošová Z.","The lukov Castle - A historical 3D visualization in different time periods",2017,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018696250&doi=10.1007%2f978-3-319-57141-6_32&partnerID=40&md5=8a63f781aee2f584a6b9e6a598010599","This paper briefly describes a visualization method for the Lukov Castle. This castle was probably founded at the beginning of the 13th Century and grew rapidly over the following centuries, so it became an important residence of the local aristocracy. All available historical materials of the Lukov Castle and its surrounding area were collected. The focus was mainly directed on historical sketches, historical paints and photos. All the collected information was chronologically sorted and, on this basis, seven 3D visualizations of this castle were created that demonstrate its development and decay. To begin with, the grounds terrain model was created-based on the Daftlogic database [14]. All buildings and accessories were separately modeled by period (using standard polygonal representation) and textured using UV mapping techniques. In this way, seven complex 3D scenes of the Lukov Castle in these periods were created: the first half of the 13th Century, the second half of the 13th Century; then, in the 14th, 15th, 17th and 18th Centuries. The last model corresponds to its current appearance. The visualization output is performed by rendered images and animations in these time periods. The Blender software suite was used for visualization purposes. © Springer International Publishing AG 2017.","3D visualization; Animation; Computer graphics; Historical visualization; Modeling; Texturing","Animation; Computer graphics; Intelligent systems; Models; Software engineering; Texturing; Visualization; 3D Visualization; Historical visualization; Polygonal representation; Rendered images; Software suite; Terrain Modeling; Time-periods; Visualization method; Three dimensional computer graphics",2-s2.0-85018696250
"Xu H., Barbič J.","Example-based damping design",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030790887&doi=10.1145%2f3072959.3073631&partnerID=40&md5=0f1c24040e11f21f524e4d3caa29cc20","To date, material modeling in physically based computer animation has largely focused on mass and stiffness material properties. However, deformation dynamics is largely affected also by the damping properties. In this paper, we propose an interactive design method for nonlinear isotropic and anisotropic damping of complex three-dimensional solids simulated using the Finite Element Method (FEM). We first give a damping design method and interface whereby the user can set the damping properties so that motion aligned with each of a few chosen example deformations is damped by an independently prescribed amount, whereas the rest of the deformation space follows standard Rayleigh damping, or any viscous damping. Next, we demonstrate how to design nonlinear damping that depends on the magnitude of the deformation along each example deformation, by editing a single spline curve for each example deformation. Our user interface enables an art-directed and intuitive approach to controlling damping in solid simulations. We mathematically prove that our nonlinear anisotropic damping generalizes the frequency-dependent Caughey damping model, when starting from the Rayleigh damping. Finally, we give an inverse design method whereby the damping curve parameters can be inferred automatically from high-level user input, such as the amount of amplitude loss in one oscillation cycle along each of the chosen example deformations. To minimize numerical damping for implicit integration, we introduce an accurate and stable implicit integrator, which removes spurious high-frequency oscillations while only introducing a minimal amount of numerical damping. Our damping can generate effects not possible with previous methods, such as controllable nonlinear decaying envelopes whereby large deformations are damped faster or slower than small deformations, and damping anisotropic effects. We also fit our damping to videos of real-world objects undergoing large deformations, capturing their nonlinear and anisotropic damping dynamics. © 2017 ACM.","Anisotropic; Damping; Example-space; FEM; Interactive; Nonlinear; Physically based simulation","Animation; Anisotropy; Arts computing; Deformation; Design; Finite element method; Interactive computer graphics; Inverse problems; User interfaces; Anisotropic; Example-space; Interactive; Nonlinear; Physically-based simulation; Damping",2-s2.0-85030790887
"Zajadacz A., Szmal P.","Accessible tourism for Deaf people in Poland: The SITur and SITex programs as proposals for accessible urban information",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025127515&doi=10.1007%2f978-3-319-58700-4_29&partnerID=40&md5=5fcdbd53b2704eb79d5536753b9cc827","SITur and SITex are multimedia programs addressed to Deaf tourists, whose main communication means is Polish Sign Language (PJM). In this article we present the background and main assumptions for the development of the programs, conducted experiments and conclusions regarding further development directions. By assumption, creating programs was carried with the participation of their beneficiaries. Before programs development, the style of leisure and tourist destination of the Deaf in Poland were recognized using questionnaire interviews; for comparison, the same questions were asked to a control group of hearing. Besides texts, maps, pictures, pictograms, the programs include PJM animation module, borrowed from Thetos translation program. PJM users repeatedly tested the programs, i.a. on selected tourism routes. The PJM and the tourism industry experts also reviewed them. Feedback from the Deaf environment is currently used to improve programs – to complement vocabulary and animation expression (including facial expressions of avatar-translator). © Springer International Publishing AG 2017.","Accessible information; Accessible tourism; Disability; Hearing impairment; The Deaf; Tourist information system","Animation; Audition; Multimedia systems; Program translators; Surveys; Urban growth; Accessible information; Accessible tourism; Disability; Hearing impairments; The Deaf; Human computer interaction",2-s2.0-85025127515
"Pons-Moll G., Pujades S., Hu S., Black M.J.","ClothCap: Seamless 4D clothing capture and retargeting",2017,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030772238&doi=10.1145%2f3072959.3073711&partnerID=40&md5=d8265cd7677b13548ba61b942525c8cb","Designing and simulating realistic clothing is challenging. Previous methods addressing the capture of clothing from 3D scans have been limited to single garments and simple motions, lack detail, or require specialized texture patterns. Here we address the problem of capturing regular clothing on fully dressed people in motion. People typically wear multiple pieces of clothing at a time. To estimate the shape of such clothing, track it over time, and render it believably, each garment must be segmented from the others and the body. Our ClothCap approach uses a new multi-part 3D model of clothed bodies, automatically segments each piece of clothing, estimates the minimally clothed body shape and pose under the clothing, and tracks the 3D deformations of the clothing over time. We estimate the garments and their motion from 4D scans; that is, high-resolution 3D scans of the subject in motion at 60 fps. ClothCap is able to capture a clothed person in motion, extract their clothing, and retarget the clothing to new body shapes; this provides a step towards virtual try-on. © 2017 Copyright held by the owner/author(s).","3D segmentation; 3D shape; Animation; Clothing; Performance capture; Try-on","Animation; Computer graphics; 3-D shape; 3D segmentation; Clothing; Performance capture; Try-on; Interactive computer graphics",2-s2.0-85030772238
"Inglis T., Eckert M.-L., Gregson J., Thuerey N.","Primal-Dual Optimization for Fluids",2017,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011968560&doi=10.1111%2fcgf.13084&partnerID=40&md5=86842b08d31823e00db0227394797e04","We apply a novel optimization scheme from the image processing and machine learning areas, a fast Primal-Dual method, to achieve controllable and realistic fluid simulations. While our method is generally applicable to many problems in fluid simulations, we focus on the two topics of fluid guiding and separating solid-wall boundary conditions. Each problem is posed as an optimization problem and solved using our method, which contains acceleration schemes tailored to each problem. In fluid guiding, we are interested in partially guiding fluid motion to exert control while preserving fluid characteristics. With our method, we achieve explicit control over both large-scale motions and small-scale details which is valuable for many applications, such as level-of-detail adjustment (after running the coarse simulation), spatially varying guiding strength, domain modification, and resimulation with different fluid parameters. For the separating solid-wall boundary conditions problem, our method effectively eliminates unrealistic artefacts of fluid crawling up solid walls and sticking to ceilings, requiring few changes to existing implementations. We demonstrate the fast convergence of our Primal-Dual method with a variety of test cases for both model problems. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","Computer graphics, Physical simulation, Convex optimization; Convex optimization; Flexible boundary conditions; Fluid guiding; Fluid simulation; Physically-based animation","Computer graphics; Convex optimization; Image processing; Learning systems; Optimization; Fluid simulations; Large scale motion; Optimization problems; Optimization scheme; Physical simulation; Physically-based animation; Primal-dual methods; Solid wall boundaries; Boundary conditions",2-s2.0-85011968560
"Sneed H.M., Verhoef C.","Validating converted java code via symbolic execution",2017,"Lecture Notes in Business Information Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010223142&doi=10.1007%2f978-3-319-49421-0_6&partnerID=40&md5=41964d643607f5c7e833c2e44ff8084a","The testing approach described here has grown out of migration projects aimed at converting procedural programs in COBOL or PL/1 to object-oriented Java code. The code conversion itself is now automated but not completely. The human reengineer still has to make some adjustments to the automatically generated code and that can lead to errors. These may also be subtle errors in the automated transformation. Therefore, converted code must be tested to prove that it is functionally equivalent to the original code. Up until now converted programs have been tested manually and their results compared, but that is a very labor intensive approach. Besides, it only shows which results differ and not where the code differs. It can be extremely difficult to trace differences in the results back to differences in the code. Such regression testing drives up the costs of migration, causing users to disregard this alternative. If they have to spend so much on testing a conversion they might as well redevelop the software. This paper describes how converted code can be validated at a much lower cost by symbolically executing it and comparting the execution paths. The theory behind this approach is that no matter how statements are statically reordered, dynamically they must still execute in the same sequence to produce the same result. © Springer International Publishing AG 2017.","Code conversion; Dynamic comparison; Functional equivalence; Object-oriented migration; Source code animation; Symbolic execution; Verification paths","COBOL (programming language); Code converters; Codes (symbols); Computer software; Computer software selection and evaluation; Java programming language; Model checking; Software engineering; Software testing; Code conversion; Functional equivalence; Object oriented; Source codes; Symbolic execution; Object oriented programming",2-s2.0-85010223142
"Oka K., Lu W., Özacar K., Takashima K., Kitamura Y.","Exploring in-the-Wild Game-Based Gesture Data Collection",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030839201&doi=10.1007%2f978-3-319-67684-5_7&partnerID=40&md5=4fcf3221fb320dea797c355617cd28bf","This paper presents an automatic 3D gesture collection concept and architecture based on a rhythm game for public displays. The system was implemented using an off-the-shelf gesture controller, was deployed on a public vertical screen, and was used to study the effects of alternative gesture guidance conditions. In the evaluation presented, we examined how alternative gesture guidance conditions affect users’ engagement. The study showed that demonstration animation (CDA) and tracking state feedback (TSI) each encourages sustained game engagement. The underlying concept and architecture presented here offer actionable UI design insight to help creating large gesture corpus from diverse populations. © 2017, IFIP International Federation for Information Processing.",,"Animation; State feedback; Architecture-based; Data collection; Game-Based; Public display; UI designs; Human computer interaction",2-s2.0-85030839201
"Roy V.","Digital storytelling for start-ups: A canadian MOOC design experience",2017,"CEUR Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020906970&partnerID=40&md5=3ae3239080d03bd149fdc28492762026","The four-week Business Start-up Massive Open Online Course (MOOC) is the first MOOC designed at the Southern Alberta Institute of Technology (SAIT), Calgary, Canada. This work in progress paper discusses the author's experience designing the course through digital storytelling in partnership with seven successful Canadian entrepreneurs using powerful digital tools, including 2D whiteboard video animations and interactive video presentations, to engage and motivate learners in planning their start-ups. The MOOC's target market is diverse and global: internal students from various programs at SAIT, alumni, lifelong learners, and professionals.","Authentic learning; Business start-ups; Case studies; Course design; Digital storytelling; E-learning; Entrepreneurship; Interactive presentations; MOOC; Video design; Video production; Whiteboard animations","Computer graphics; Curricula; Digital devices; Education; Paper; Authentic learning; Business start-ups; Case-studies; Course design; Digital storytelling; Entrepreneurship; Interactive presentation; MOOC; Video production; White board; E-learning",2-s2.0-85020906970
"Li Y., Xu Y.","Application and value analysis of urban landscape design based on computer simulation",2017,"Revista de la Facultad de Ingenieria",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024931120&partnerID=40&md5=b37873e092edf3a50e2d59c855b3fea1","In the urban landscape design practice, the designers need to design the effect of predictability, and need a large number of data and graph information to express the intention of landscape design, so it is necessary to simulate by computer image. In this paper, the authors analyze the application and value analysis of urban landscape design based on computer simulation. The rapid development of information technology and powerful three-dimensional solid modeling and animation rendering create a good environment for creation of landscape design. © 2017 Universidad Central de Venezuela.","Computer simulation; Environmental design; Value analysis","Computer simulation; Environmental design; Three dimensional computer graphics; Computer images; Graph information; Landscape design; Number of datum; Three-Dimensional Solid Modeling; Urban landscape; Value engineering",2-s2.0-85024931120
"Alaguero M., Checa D., Bustillo A.","Measuring the impact of low-cost short-term virtual reality on the user experience",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021231993&doi=10.1007%2f978-3-319-60922-5_26&partnerID=40&md5=805cdd80a643e4eff7b038c798a1a263","The continuous innovation of new affordable hardware and software over recent years is leading to a surfeit of Virtual Reality (VR) applications in the entertainment industry. However, the abundance of VR applications is unfortunately not matched by case studies and evaluation methods related to low-cost Virtual Reality experiences. A gap in the literature exists, where the utility of VR to display narrative stories could be studied, due to the sensations of amazement, astonishment, and excitement that it awakens. This research reports the steps taken to create a low-cost VR experience designed to transmit a single concept. The key aspects of the experience may be summarized as follows: a short duration, the selection of an evocative scenario limited to a single storyline, short animation of 3D-models selected to produce intense visual impacts with minimal modelling and animation and the collaborative participation of undergraduate students in the development of the VR environment. Members of the public were invited to trials of this VR experience portraying a Nativity scene over the 2016/17 Christmas Season in Burgos (Spain). The user experience was evaluated through surveys administered to numerous final-users immediately after the 3D-experience. The results showed very high levels of satisfaction, even though the 3D-experience for around half of the viewers was not their first one. In a few rare cases, sickness effects were reported. Viewers identified the movement of light as one of the most impressive aspects and considered the duration reasonable, with few or no suggestions for improvement. © Springer International Publishing AG 2017.","Blender; Low-cost; Oculus rift; Short experiences; Virtual reality","Animation; Application programs; Augmented reality; Blending; Computer graphics; Costs; Students; Blender; Entertainment industry; Hardware and software; Low costs; Oculus rift; Short experiences; Undergraduate students; Virtual reality experiences; Virtual reality",2-s2.0-85021231993
"Kalloo V., Mohan P., Kinshuk","Using games to address problems in mathematics-based e-learning environments",2017,"Proceedings of the International Conference on e-Learning, ICEL",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027846383&partnerID=40&md5=ea4e2969858ed6af995a7a68c51434c0","Researchers have demonstrated that asynchronous e-learning environments are not perfectly suited to learning mathematics. The traditional e-learning content-types such as text-based activities, tutorials, animations, images, and quizzes lack some ofthe key characteristics necessary for learning mathematics. These key characteristics include problem-solving, learning by doing, immediate feedback, communication, and motivation. These characteristics of learning are not easily facilitated using typical e-learning content-types. Learning mathematics in an e-learning environment can result in increased failure and dropout rates. In this desktop study, we propose that games can be used to help address the problem because some of the main characteristics of games can be correlated to the key characteristics necessary for learning mathematics. We describe each aspect ofthe problem in detail and discuss how games can be used to solve them, justifying why games are especially suitable for solving each of the problems identified. We present a comparison of two typical mathematics-based e-learning activities with a mathematics-based learning game we designed. This comparison demonstrates that the game can facilitate the necessary characteristics for learning mathematics whereas the e-learning activity is deficient. We then present guidelines for incorporating games into mathematics-based e-learning environments. These guidelines encourage content developers to first consider games for delivering the mathematics content and help them to avoid some ofthe common problems which arise from learning mathematics in e-learning environments.","Content-types; E-learning; Learning games; Learning mathematics; Problems in e-learning","Animation; E-learning; Problem solving; Asynchronous e-learning; Content-types; E-learning contents; E-learning environment; Immediate feedbacks; Key characteristics; Learning game; Learning Mathematics; Computer aided instruction",2-s2.0-85027846383
"Guo S., Xu H., Thalmann N.M., Yao J.","Customization and fabrication of the appearance for humanoid robot",2017,"Visual Computer",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991824437&doi=10.1007%2fs00371-016-1329-6&partnerID=40&md5=ee9925349f611cae099144d2d697b295","Designing a robot’s appearance is a challenging task because the design should be both aesthetically appealing and physically functional. Therefore, this task was previously limited to experts with professional knowledge and experiences. Given the increasing popularity of consumer-level robots, non-professional users are expecting tools that allow them to customize their robot appearance. We address this challenge with the technology of additive manufacturing and propose an end-to-end solution to customize and fabricate the robot appearance for non-professional users. The input to our solution is a triangular character mesh (commonly used in feature animations and video games) and the output is a set of 3D-printing-ready shell parts. The complete solution includes matching the shape of the character mesh with the robot endoskeleton, optimizing the shape design to maximally avoid collisions and adjusting the motion trajectories to adapt to new shell design. This approach requires no professional background in engineering design and efficiently produces accurate prototypes of robot shells. Both virtual and physically printed designs are demonstrated on a consumer level humanoid robot to validate the feasibility of our method. © 2016, Springer-Verlag Berlin Heidelberg.",,"3D printers; Animation; Anthropomorphic robots; Mesh generation; Professional aspects; Robots; Three dimensional computer graphics; Complete solutions; End-to-end solutions; Engineering design; Motion trajectories; Non-professional users; Professional backgrounds; Professional knowledge; Robot appearance; Machine design",2-s2.0-84991824437
"Wang B., Zhao Y., Barbič J.","Botanical materials based on biomechanics",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030771276&doi=10.1145%2f3072959.3073655&partnerID=40&md5=6dba33117e5fa17771c522dbc3edb0f3","Botanical simulation plays an important role in many fields including visual effects, games and virtual reality. Previous plant simulation research has focused on computing physically based motion, under the assumption that the material properties are known. It is too tedious and impractical to manually set the spatially-varying material properties of complex trees. In this paper, we give a method to set the mass density, stiffness and damping properties of individual tree components (branches and leaves) using a small number of intuitive parameters. Our method is rooted in plant biomechanics literature and builds upon power laws observed in real botanical systems. We demonstrate our materials by simulating them using offline and model-reduced FEM simulators. Our parameters can be tuned directly by artists; but we also give a technique to infer the parameters from ground truth videos of real trees. Our materials produce tree animations that look much more similar to real trees than previous methods, as evidenced by our user study and experiments. © 2017 ACM.","Biomechanics; Botanical; Domain decomposition; FEM; Large deformations; Material; Model reduction; Power law","Animation; Biomechanics; Biophysics; Domain decomposition methods; Finite element method; Interactive computer graphics; Materials; Plants (botany); Virtual reality; Botanical; Model reduction; Physically based; Plant biomechanics; Plant simulation; Power-law; Spatially varying material properties; Stiffness and damping; Forestry",2-s2.0-85030771276
"Craig D.","Time in Television Systems",2017,"Astrophysics and Space Science Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031282609&doi=10.1007%2f978-3-319-59909-0_15&partnerID=40&md5=e0dac793139bd2fe94529b476da1dbad","Clocks are fundamental to the transmission of television—the when of the picture top and left hand side is as important for display as the image content, and maintaining audio lip sync has always been a battle. In overlapping periods since the modern television era began in 1941, there have been a variety of different clock synchronization and time labeling schemes. Real or imagined compatibility constraints during architectural transitions, as well as confusion of time the label versus time the physical property, have led to the evolution of remarkably byzantine clocks, with repeating decimal fractional frame rates, discontinuous timelines, and complex counting rhythms. Beginning with monochrome transmissions, through the analog NTSC color system and into the digital ATSC system of today, this presentation explores the origins of the television system’s clocks and views from the safety of hindsight unintended consequences of some innocent design optimizations. Clock system technical constraints included the collapse of logically independent layers for needed efficiency, synchronization of electromechanical as well as purely electronic systems, and transmission paths ranging from short-range coaxial cable to long-range variable length microwave RF. As a commercial and quasi-governmental enterprise, television also has had to accommodate the eccentricities of civil timekeeping, offering content to a schedule synchronized with wall clock time across multiple time zones. Does it all need to be this complicated? A transition to television distribution over general purpose computer networks, coupled with the vastly improved performance ratio of low-cost modern digital circuitry, should eliminate the technical requirement for specialized clocks. The adoption of a new IEEE/SMPTE timing reference based on an epoch and an atomic time scale will provide an elegant mechanism for general purpose support of higher picture frame rates and audio sample rates. It remains for humans to abandon the old clocks and finally formalize the relationship with wall clock time in a way that doesn’t unduly complicate system engineering. © 2017, Springer International Publishing AG.","AES; AES-11; Alexander bain; Animation; Appointment TV; ATSC; Audio/video synchronization; David sarnoff; Edwin armstrong; Frame rate; Frame synchronizer; IEEE; IEEE-1588; Interlace; Jam sync; Joseph plateau; Lipsync; MPEG-2 transport stream; NTSC; Phenakistoscope; Raster; Remote electric clock; SMPTE; SMPTE ST-12M; SMPTE ST-2059; SMPTE ST-299; Synchronization; Television; Time as a label; Time as a physical property; Timecode; Timeline; Videotape; VOD; William paley","Animation; General purpose computers; Motion Picture Experts Group standards; Photographic accessories; Physical properties; Professional aspects; Synchronization; Television; Television broadcasting; Television systems; AES-11; Alexander bain; ATSC; Audio/video synchronization; David sarnoff; Edwin armstrong; Frame rate; Frame synchronizer; IEEE; IEEE-1588; Interlace; Jam sync; Joseph plateau; Lipsync; MPEG-2 transport stream; NTSC; Phenakistoscope; Raster; SMPTE; SMPTE ST-12M; SMPTE ST-2059; SMPTE ST-299; Timecode; Timeline; Videotape; William paley; Television networks",2-s2.0-85031282609
"Mukovskiy A., Taubert N., Endres D., Vassallo C., Naveau M., Stasse O., Souères P., Giese M.A.","Modeling of coordinated human body motion by learning of structured dynamic representations",2017,"Springer Tracts in Advanced Robotics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018396099&doi=10.1007%2f978-3-319-51547-2_11&partnerID=40&md5=7a38d27507806db0f9d239a871835b19","The modeling and online-generation of human-like body motion is a central topic in computer graphics and robotics. The analysis of the coordination structure of complex body movements in humans helps to develop flexible technical algorithms for movement synthesis. This chapter summarizes work that uses learned structured representations for the synthesis of complex human-like body movements in real-time. This work follows two different general approaches. The first one is to learn spatio-temporal movement primitives from human kinematic data, and to derive from this Dynamic Movement Primitives (DMPs), which are modeled by nonlinear dynamical systems. Such dynamical primitives are then coupled and embedded into networks that generate complex human-like behaviors online, as self-organized solutions of the underlying dynamics. The flexibility of this approach is demonstrated by synthesizing complex coordinated movements of single agents and crowds. We demonstrate that Contraction Theory provides an appropriate framework for the design of the stability properties of such complex composite systems. In addition, we demonstrate how such primitive-based movement representations can be embedded into a model-based predictive control architecture for the humanoid robot HRP-2. Using the primitive-based trajectory synthesis algorithm for fast online planning of full-body movements, we were able to realize flexibly adapting human-like multi-step sequences, which are coordinated with goal-directed reaching movements. The resulting architecture realizes fast online planing of multi-step sequences, at the same time ensuring dynamic balance during walking and the feasibility of the movements for the robot. The computation of such dynamically feasible multi-step sequences using state-of-the-art optimal control approaches would take hours, while our method works in real-time. The second presented framework for the online synthesis of complex body motion is based on the learning of hierarchical probabilistic generative models, where we exploit Bayesian machine learning approaches for nonlinear dimensionality reduction and the modeling of dynamical systems. Combining Gaussian Process Latent Variable Models (GPLVMs) and Gaussian Process Dynamical Models (GPDMs), we learned models for the interactive movements of two humans. In order to build an online reactive agent with controlled emotional style, we replaced the state variables of one actor by measurements obtained by real-time motion capture from a user and determined the most probable state of the interaction partner using Bayesian model inversion. The proposed method results in highly believable human-like reactive body motion. © 2017, Springer International Publishing AG.","Action sequences; Animation; Dynamic movement primitives; Gaussian process dynamical model; Gaussian process latent variable model; Goal-directed movements; Machine learning; Motor coordination; Navigation; Walking pattern generator","Animation; Anthropomorphic robots; Artificial intelligence; Bayesian networks; Behavioral research; Biomechanics; Case based reasoning; Complex networks; Computation theory; Computer graphics; Dynamical systems; Gaussian distribution; Gaussian noise (electronic); Hierarchical systems; Learning systems; Memory architecture; Model predictive control; Navigation; Network architecture; Nonlinear dynamical systems; Online systems; Principal component analysis; Robots; Stability; Action sequences; Dynamic movement primitives; Dynamical model; Goal directed; Latent variable modeling; Motor co-ordination; Walking pattern generator; Coordination reactions",2-s2.0-85018396099
"Monroe M., Martino M.","The panta rhei: Modernizing the marquee",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030844192&doi=10.1007%2f978-3-319-67687-6_24&partnerID=40&md5=fa5dcf6a320997c81e12477f693f8b25","Many multimedia visualizations abstract the underlying content into aggregate displays, requiring user interaction in order to expose the original text, images or video. The drawback of this approach is that unlike traditional, numerical data, multimedia data is readily interpretable. Users can catch an image or phrase out of the corner of their eye an immediately understand the content. However, this passive discovery cannot take place when content is only exposed through direct interaction. In this paper, we present the Panta Rhei, a peripheral display designed to avoid this pitfall by surfacing original content when the user is not actively engaged with the application. We provide the full implementation details, including the many ways in which the underlying parameters can be tuned to suit various objectives. Since the display can easily support text, images or videos, our goal is to enable more widespread discussion and experimentation involving this technique for multimedia visualization. © IFIP International Federation for Information Processing 2017 Published by Springer International Publishing AG 2017. All Rights Reserved.","Animation; Engagement-versatile; Passive; Visualization","Abstracting; Animation; Flow visualization; Visualization; Direct interactions; Engagement-versatile; Multimedia data; Multimedia visualization; Numerical data; Passive; Peripheral displays; User interaction; Human computer interaction",2-s2.0-85030844192
"Jeschke S., Wojtan C.","Water wave packets",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030776982&doi=10.1145%2f3072959.3073678&partnerID=40&md5=025595066aa8941cb3f0522c0431ceb3","This paper presents a method for simulating water surface waves as a displacement field on a 2D domain. Our method relies on Lagrangian particles that carry packets of water wave energy; each packet carries information about an entire group of wave trains, as opposed to only a single wave crest. Our approach is unconditionally stable and can simulate high resolution geometric details. This approach also presents a straightforward interface for artistic control, because it is essentially a particle system with intuitive parameters like wavelength and amplitude. Our implementation parallelizes well and runs in real time for moderately challenging scenarios. © 2017 ACM.","Computational fluid dynamics; Liquid animation; Particle system; Real-time simulation; Water surface waves; Wave packets","Computational fluid dynamics; Fluids; Interactive computer graphics; Surface waves; Wave energy conversion; Wave packets; Displacement field; Geometric details; Lagrangian particles; Particle systems; Real time simulations; Unconditionally stable; Water surface; Water wave energy; Water waves",2-s2.0-85030776982
"Wang T., Liu Z., Tang M., Tong R., Manocha D.","Efficient and Reliable Self-Collision Culling Using Unprojected Normal Cones",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016191461&doi=10.1111%2fcgf.13095&partnerID=40&md5=706a36b4e816948f37e22ca7b9e55659","We present an efficient and accurate algorithm for self-collision detection in deformable models. Our approach can perform discrete and continuous collision queries on triangulated meshes. We present a simple and linear time algorithm to perform the normal cone test using the unprojected 3D vertices, which reduces to a sequence point-plane classification tests. Moreover, we present a hierarchical traversal scheme that can significantly reduce the number of normal cone tests and the memory overhead using front-based normal cone culling. The overall algorithm can reliably detect all (self) collisions in models composed of hundreds of thousands of triangles. We observe considerable performance improvement over prior continuous collision detection algorithms. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","Animation; Collision detection","Animation; Clustering algorithms; Interactive computer graphics; Classification tests; Collision culling; Collision detection; Continuous collision detection; Deformable models; Linear-time algorithms; Memory overheads; Self-collision detection; Collision avoidance",2-s2.0-85016191461
"Bern J.M., Chang K.-H., Coros S.","Interactive design of animated plushies",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030779919&doi=10.1145%2f3072959.3073700&partnerID=40&md5=c4f506f99e8c1ac0723a63cb55c0e611","We present a computational approach to creating animated plushies, soft robotic plush toys specifically-designed to reenact user-authored motions. Our design process is inspired by muscular hydrostat structures, which drive highly versatile motions in many biological systems. We begin by instrumenting simulated plush toys with a large number of small, independently-actuated, virtual muscle-fibers. Through an intuitive posing interface, users then begin animating their plushie. A novel numerical solver, reminiscent of inverse-kinematics, computes optimal contractions for each muscle-fiber such that the soft body of the plushie deforms to best match user input. By analyzing the co-activation patterns of the fibers that contribute most to the plushie's motions, our design system generates physically-realizable winch-tendon networks. Winch-tendon networks model the motorized cable-driven actuation mechanisms that drive the motions of our real-life plush toy prototypes. We demonstrate the effectiveness of our computational approach by co-designing motions and actuation systems for a variety of physically-simulated and fabricated plushies. © 2017 Copyright held by the owner/author(s).","Animation; Computational design; Plushies; Soft robotics","Animation; Computational methods; Design; Interactive computer graphics; Inverse kinematics; Muscle; Robotics; Winches; Actuation mechanism; Actuation systems; Computational approach; Computational design; Interactive design; Muscular hydrostat; Plushies; Soft robotics; Tendons",2-s2.0-85030779919
"Li Y., Chen Y.","Physical Rigging for Physical Models and Posable Joint Designs Based on Additive Manufacturing Technology",2017,"Procedia Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029857663&doi=10.1016%2fj.promfg.2017.07.371&partnerID=40&md5=b90a23dc80cf4fd23d2ed2261c751ac5","In 3D computer animation, a lot researches illustrated rigging mesh or solid models can be easily converted to articulated characters. Even though these articulated characters can exhibit desired motions in computer, the joints facilitating the motion are not properly designed at all. All rigged joints must be clearly designed with consideration of mobility and manufacturability. In this paper, a physical rigging methodology and a set of joint designs for articulated characters are proposed. The joints can be easily used for both revolute and omnidirectional motion. They also allow a physical character to assume any poses that are within the designed motion range after fabricated by additive manufacturing (AM) technologies. A number of sample designs have been fabricated using two popular AM technologies to demonstrate the effectiveness of the proposed method. © 2017 The Authors","additive manufacturing; animation; character rigging; non-assembly mechanism; posable joints",,2-s2.0-85029857663
"Redweik P., Cláudio A.P., Carmo M.B., Naranjo J.M., Sanjosé J.J.","Digital preservation of cultural and scientific heritage: Involving university students to raise awareness of its importance",2017,"Virtual Archaeology Review",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025074513&doi=10.4995%2fvar.2017.4629&partnerID=40&md5=75d770ec8c77ef6f3f409244003db441","Cultural heritage is a relevant issue in contemporary society. While its preservation is a challenge, its dissemination, can contribute for an economic balance between costs and benefits. Scientific heritage can be considered as a special domain of cultural heritage, not yet sought by the mass tourism, but worth being preserved as the roots of today's knowledge. Considering that university students of engineering and computer science traditionally do not address cultural or scientific heritage issues in their syllabus, and that they constitute a layer of young citizens that will come to be influential in the future of society, an effort was undertaken to focus on this theme in disciplines of different courses, allying the learning of technical skills with the natural interest of younger people for 3D and animation for the profit of heritage. The goal was to raise the awareness of this particular group to the importance of maintaining heritage issues, in particular, in a virtual way, both for documentation and for divulgating their existence. Raising funds for buildings' restoration, attracting the public to visit buildings and collections that are outside the usual tourism routes, contributing to revenue generation, or allowing virtual visits of not accessible issues, complementing physical visits on site, were the general aims of the proposed projects. A survey was undertaken under the participating students to evaluate how the projects influenced their attitude towards heritage. The obtained feedback was very positive: 76% agreed that the project alerted them for the importance of preserving historical and cultural heritage, while 72% considered it was interesting that the topic of digital cultural heritage was used for the assessments of the disciplines. © UPV, SEAV, 2015.","3D modelling; Animation; Education; Heritage dissemination",,2-s2.0-85025074513
"Syrett H., Calvi L., van Gisbergen M.","The oculus rift film experience: A case study on understanding films in a head mounted display",2017,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000764515&doi=10.1007%2f978-3-319-49616-0_19&partnerID=40&md5=602674bde25d11cdef857bba661b2b02","The purpose of this research was to determine the level of narrative comprehension in films when watched in a virtual reality headset (Oculus Rift). A 360-degree live-action film was created and was shown to participants after which the level of comprehension of various literary aspects as well as the feeling of distraction and enjoyment were measured using questionnaires and interviews. Revealing how increased freedom to view a movie in virtual reality has an effect on storyline understanding, provided a framework to start a discussion on whether and how to utilize virtual reality as a means for storytelling through films. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2017.","Film; Narrative comprehension; Oculus rift; Storytelling; Virtual reality","Animation; Films; Helmet mounted displays; Surveys; Head mounted displays; Live actions; Narrative comprehension; Oculus rift; Storylines; Storytelling; Virtual-reality headsets; Virtual reality",2-s2.0-85000764515
"Woo K.L., Rieucau G., Burke D.","Computer-animated stimuli to measure motion sensitivity: Constraints on signal design in the Jacky dragon",2017,"Current Zoology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014856336&doi=10.1093%2fcz%2fzow074&partnerID=40&md5=1d56b45f0fc444bdf746d51aa7c119fc","Identifying perceptual thresholds is critical for understanding the mechanisms that underlie signal evolution. Using computer-animated stimuli, we examined visual speed sensitivity in the Jacky dragon Amphibolurus muricatus, a species that makes extensive use of rapid motor patterns in social communication. First, focal lizards were tested in discrimination trials using random-dot kinematograms displaying combinations of speed, coherence, and direction. Second, we measured subject lizards' ability to predict the appearance of a secondary reinforcer (1 of 3 different computer-generated animations of invertebrates: cricket, spider, and mite) based on the direction of movement of a field of drifting dots by following a set of behavioural responses (e.g., orienting response, latency to respond) to our virtual stimuli. We found an effect of both speed and coherence, as well as an interaction between these 2 factors on the perception of moving stimuli. Overall, our results showed that Jacky dragons have acute sensitivity to high speeds. We then employed an optic flow analysis to match the performance to ecologically relevant motion. Our results suggest that the Jacky dragon visual system may have been shaped to detect fast motion. This pre-existing sensitivity may have constrained the evolution of conspecific displays. In contrast, Jacky dragons may have difficulty in detecting the movement of ambush predators, such as snakes and of some invertebrate prey. Our study also demonstrates the potential of the computeranimated stimuli technique for conducting nonintrusive tests to explore motion range and sensitivity in a visually mediated species. © The Author (2016).","Amphibolurus muricatus; Jacky dragon; Motion sensitivity; Random-dot kinematograms; Signal evolution; Virtual stimuli",,2-s2.0-85014856336
[No author name available],"11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, VISIGRAPP 2016",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028341982&partnerID=40&md5=0141ed858d5b4e8bccd3ac93229e4f16","The proceedings contain 29 papers. The special focus in this conference is on Computer Vision, Imaging and Computer Graphics Theory. The Topics include: behaviour analysis of people aggregations; real-time contour image vectorization on GPU; screen space curvature and ambient occlusion; multi-class error-diffusion with blue-noise property and its application; copula eigenfaces with attributes: semiparametric principal component analysis for a combined color, shape and attribute model; representing shapes of 2D point sets by straight outlines; sketching 2D character animation using a data-assisted interface; skin deformation methods for interactive character animation; perceptual effects of stylization; on the visualization of hierarchical relations and tree structures with tagspheres; visual analysis of character and plot information extracted from narrative text; visual querying of semantically enriched movement data; efficient layouts for correlation tasks; analysis and comparison of feature-based patterns in urban street networks; swarm-based edge bundling applied to flow mapping; relative pose estimation from straight lines using optical flow-based line matching and parallel line clustering; a detailed description of direct stereo visual odometry based on lines; consumer-level virtual reality motion capture; ground-truth tracking data generation using rotating real-world objects; the sliced pineapple grid feature for predicting grasping affordances; extending guided image filtering for high-dimensional signals; exemplar-based image inpainting using an affine invariant similarity measure; real-time visual odometry by patch tracking using GPU-based Perspecti ve calibration and adaptive non-local means using weight thresholding.",,,2-s2.0-85028341982
[No author name available],"11th International Conference on Universal Access in Human-Computer Interaction, UAHCI 2017, held as part of the 19th International Conference on Human-Computer Interaction, HCI 2017",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025145856&partnerID=40&md5=3b4f5845f45abedc36c502996a7e42ec","The proceedings contain 130 papers. The special focus in this conference is on Universal Access in Human-Computer Interaction. The topics include: Evaluation of animated Swiss German sign language fingerspelling sequences and signs; synthesizing sign language by connecting linguistically structured descriptions to a multi-track animation system; coarticulation analysis for sign language synthesis; investigation of feature elements and performance improvement for sign language recognition by hidden Markov model; on capitalizing on augmented reality to impart solid geometry concepts; how augmented reality technology consolidates the SMB ecosystem of the tourism industry in Taiwan; AR based user interface for driving electric wheelchairs; geomorphology classroom practices using augmented reality; effect of difference in information between vision and vestibular labyrinth on a human body; exploring location-based augmented reality experience in museums; technology-enhanced accessible interactions for visually impaired Thai people; mobile audio games accessibility evaluation for users who are blind; providing dynamic access to electronic tactile diagrams; towards tangible and distributed UI for cognitively impaired people; evaluating vibrotactile recognition ability of geometric shapes by using a smartphone; designing interfaces to make information more tangible for visually impaired people; comparing pointing performance of mouse and eye-gaze input system; a visuospatial memory game for the elderly using gestural interface and the application of dynamic analysis to hand gestures.",,,2-s2.0-85025145856
[No author name available],"9th International Conference on Cross-Cultural Design, CCD 2017 Held as Part of 19th International Conference on Human-Computer Interaction, HCI International 2017",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027346704&partnerID=40&md5=84df7864afa712b7b06ba9f409d25fc8","The proceedings contain 60 papers. The special focus in this conference is on Cross-Cultural Design. The topics include: Transforming traditional paper cutting into LINE stickers; a systemic approach to concrete constructions; a reflective research on the development of Chinese animation; the impact of Chinese traditional cultural on the gesture and user experience in mobile interaction design; a first speculation on cultural experiments as design research methods; transforming concepts of a Taiwanese twin cup into social design activities; research and application of service design thoughts in subway advertisement design; consistency of use flow improving user experience of service-oriented websites; the integration of personal and public transportation in creating seamless experience; integration and innovation: learning by exchanging views - a report of the cross-cultural design workshop for stone craving; the interdisciplinary collaboration of innovational design; research on the service design of the museum visiting; designing a cross-cultural interactive music box through meaning construction; research on the design of bicycle service system in colleges and universities based on contact mining; investigating the comprehension of public symbols for wayfinding in transit hubs in china; a study on signage design and synesthesia in senior residences; Chinese migrant food business in Italy and design researches for intercultural dialogue; a pilot study of communication matrix for evaluating artworks and design to improve medication adherence for the elderly in china.",,,2-s2.0-85027346704
"Kambayashi Y., Furukawa K., Takimoto M.","Design of tangible programming environment for smartphones",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024397926&doi=10.1007%2f978-3-319-58753-0_64&partnerID=40&md5=21a3b46db8532fa408e397b7af62ecac","This paper proposes a tangible programming environment which the user uses on a smartphone. Our goal is to provide those who possess only a smartphone for a programming environment so that they can start learning programming without any preparations. Visualization requires certain region, i.e. big screen, but people do not have personal computers as commonly as smart phones. In order to address this problem, we propose a tangible programming environment where the user can program not in a screen but on a table by using physical cards. The users place cards on a table by hand and combined them to create programs. Each card has a QR code, which the user makes their smartphone read. After reading all the codes, the users make them execute on the smartphone and validates the results on the tiny screen. In addition, the user can draw arbitrary animation characters on a paper, which they input as a photo into their smartphones and use it in their programs just as the Scratch user can manipulate characters called sprits. Thus, the user of our programming environment can construct any program as the Scratch user can without using personal computers. © Springer International Publishing AG 2017.","Smartphone; Tangible; Visual programming","Human computer interaction; Personal computers; Signal encoding; Smartphones; Learning programming; Programming environment; QR codes; Tangible; Tangible programming; Visual programming; Computer programming",2-s2.0-85024397926
"Sasaki H., Mochizuki T., Wakimoto T., Hirayama R., Yoshida S., Miyawaki K., Mabuchi H., Nakaya K., Suzuki H., Yuuki N., Matsushima A., Kawakami R., Kubota Y., Suzuki H., Funaoi H., Kato H.","Development of a tangible learning system that supports role-play simulation and reflection by playing puppet shows",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025126754&doi=10.1007%2f978-3-319-58077-7_29&partnerID=40&md5=75b0f83dad6664a552036a3496b49a3f","This paper describes the development of a tangible puppetry role-play simulation system called “EduceBoard”, which enables students to role-play, based on various character’s voices, in role-play simulation. It is to be noted that students are unable to play the diverse roles of children due to psychological inhibition and other factors in face-to-face self-performed role-play. EduceBoard is a tangible puppetry role-play simulation system that assists improvisational role-play, such as microteaching, by enabling students to play using puppets. It also provides web animation and comment functions for reflecting upon their play, recorded in a server. This paper describes the design specifications and implementation of the EduceBoard system, and discusses the current and future system applications. © Springer International Publishing AG 2017.","Computer-supported collaborative learning (CSCL); Puppetry; Real-world oriented user interface; Role-play simulation","Human computer interaction; Students; User interfaces; Computer Supported Collaborative Learning; Design specification; Microteaching; Puppetry; Real-world; Role play; Simulation systems; System applications; Education",2-s2.0-85025126754
"Timofeev G., Egorova O., Grigorev I.","Applying modern CAD systems to reconstruction of old design",2017,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988489493&doi=10.1007%2f978-3-319-44156-6_33&partnerID=40&md5=7862619846a38a49c91f3400f5ccdabb","The paper presents an attempt to apply the modern CAD systems to keep information regarding the appearance and design of the mechanisms of the past and to provide the basis for reconstruction of the engineering technology of the previous epochs. The 3D model and animation of a responsyn, the device including a stepper motor and a flexible gear, allows obtaining of the original principles of the mechanism that does not exist anymore. New computer-aided technologies, such as CAD systems help us to promote knowledge and saving it for the future. © Springer International Publishing Switzerland 2017.","3D models; Harmonic drive; History of MMS; Responsyn; Wave transmission","Stepping motors; Wave transmission; 3-d modeling; 3D models; CAD system; Computer aided technologies; Harmonic drive; Responsyn; Stepper motor; Computer aided design",2-s2.0-84988489493
"Tong X., Li C., Shen H.-W.","GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization",2017,"IEEE Transactions on Visualization and Computer Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999143801&doi=10.1109%2fTVCG.2016.2599049&partnerID=40&md5=1785946ef445952b78120c995886b2a6","Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs. © 2016 IEEE.","focus + context techniques; glyph-based techniques; human-computer interaction; manipulation and deformation; View-dependent visualization","Data visualization; Deformation; Human computer interaction; Visualization; 3D spatial structure; Context information; Focus+context techniques; Glyph-based techniques; Multivariate visualization; View dependent visualization; Visualization application; Visualization system; Three dimensional computer graphics",2-s2.0-84999143801
"Flotyński J., Walczak K.","Ontology-Based Representation and Modelling of Synthetic 3D Content: A State-of-the-Art Review",2017,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013664023&doi=10.1111%2fcgf.13083&partnerID=40&md5=c6d21258b28d83e6101a7d75572fb4cc","An indispensable element of any practical 3D/VR/AR application is synthetic three-dimensional (3D) content. Such content is characterized by a variety of features-geometry, structure, space, appearance, animation and behaviour-which makes the modelling of 3D content a much more complex, difficult and time-consuming task than in the case of other types of content. One of the promising research directions aiming at simplification of modelling 3D content is the use of the semantic web approach. The formalism provided by semantic web techniques enables declarative knowledge-based modelling of content based on ontologies. Such modelling can be conducted at different levels of abstraction, possibly domain-specific, with inherent separation of concerns. The use of semantic web ontologies enables content representation independent of particular presentation platforms and facilitates indexing, searching and analysing content, thus contributing to increased content re-usability. A range of approaches have been proposed to permit semantic representation and modelling of synthetic 3D content. These approaches differ in the methodologies and technologies used as well as their scope and application domains. This paper provides a review of the current state of the art in representation and modelling of 3D content based on semantic web ontologies, together with a classification, characterization and discussion of the particular approaches. © 2017 The Eurographics Association and John Wiley & Sons Ltd.","[Graphical user interfaces (GUI)] Virtual reality; [Virtual reality]; Information interfaces and presentation [H.5.1]: Multimedia information systems; Computer graphics [I.3.7]: Three-Dimensional Graphics and Realism; [Artificial augmented and virtual realities]; Information interfaces and presentation [H.5.2]: User Interfaces","Computer graphics; Graphical user interfaces; Knowledge based systems; Ontology; Semantic Web; User interfaces; Virtual reality; Graphical user interfaces (GUI); Information interfaces and presentations; Ontology-based representation; Semantic representation; Semantic Web ontologies; Semantic-Web techniques; State-of-the art reviews; [i.3.7]: Three-dimensional graphics and realism; Three dimensional computer graphics",2-s2.0-85013664023
"Monkaresi H., Bosch N., Calvo R.A., D'Mello S.K.","Automated Detection of Engagement Using Video-Based Estimation of Facial Expressions and Heart Rate",2017,"IEEE Transactions on Affective Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017506702&doi=10.1109%2fTAFFC.2016.2515084&partnerID=40&md5=da8ba0c5eb5fd97bea9b72c8010aa535","We explored how computer vision techniques can be used to detect engagement while students (N = 22) completed a structured writing activity (draft-feedback-review) similar to activities encountered in educational settings. Students provided engagement annotations both concurrently during the writing activity and retrospectively from videos of their faces after the activity. We used computer vision techniques to extract three sets of features from videos, heart rate, Animation Units (from Microsoft Kinect Face Tracker), and local binary patterns in three orthogonal planes (LBP-TOP). These features were used in supervised learning for detection of concurrent and retrospective self-reported engagement. Area under the ROC Curve (AUC) was used to evaluate classifier accuracy using leave-several-students-out cross validation. We achieved an AUC =.758 for concurrent annotations and AUC =.733 for retrospective annotations. The Kinect Face Tracker features produced the best results among the individual channels, but the overall best results were found using a fusion of channels. © 2010-2012 IEEE.","Engagement detection; facial expression; remote heart rate measurement; writing task","Education; Heart; Students; Area under the ROC curve; Automated detection; Computer vision techniques; Educational settings; Facial Expressions; Heart rates; Local binary patterns; Structured writing; Computer vision",2-s2.0-85017506702
"Rodney J., Chicchon I.","Digital design and fabrication of surgical obturators based only on preoperative computed tomography data",2017,"International Journal of Prosthodontics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015717788&doi=10.11607%2fijp.5066&partnerID=40&md5=74503e45370bbfa47d741784244f5c24","This article describes the digital fabrication of a surgical obturator (SO) using only computed tomography (CT) data from the tumor area. This procedure is a departure from the traditional method of making an impression and obtaining a patient cast prior to surgery to allow for SO fabrication. The present approach allows for a virtual resection based on the patient's CT image; the SO is digitally designed with animation software and fabricated by 3D printing. The SO is relined with a denture reliner at the time of surgery to complete the obturation of the maxillectomy defect. © 2017 by Quintessence Publishing Co Inc.",,"computer aided design; dental impression; human; maxilla; palatal obturator; prosthesis design; surgery; three dimensional printing; x-ray computed tomography; Computer-Aided Design; Dental Impression Technique; Dental Prosthesis Design; Humans; Maxilla; Palatal Obturators; Printing, Three-Dimensional; Tomography, X-Ray Computed",2-s2.0-85015717788
"Prantl M., Skorkovská V., Martínek P., Kolingerová I.","Curvature-Based Feature Detection for Head Modeling",2017,"Procedia Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027314954&doi=10.1016%2fj.procs.2017.05.105&partnerID=40&md5=65a23bd2cb288981c8d0c1a036100e48","In the field of 3D head modeling and animation, feature points are often needed to mark important regions of the face and can be used to animate or deform the input model. However, an automatic detection of features remains a challenging task. This paper presents a novel approach to feature detection based on curvature and its derived descriptors, such as shape index, curvedness and Willmore energy. Four important feature regions are detected using the proposed approach - eyes, nose, mouth, ears. For each region, feature points are detected. Results show that the feature points are detected with sufficient accuracy for further use.","deformations; feature detection; head modeling","Computer science; Computers; Deformation; 3D head model; Automatic Detection; Feature detection; Head model; Important features; Input modeling; Shape indexes; Willmore energies; Feature extraction",2-s2.0-85027314954
"Braier Z., Šidlof P., Klouček P.","Usage of 3D CAD software for verification and representation of real machine measurements and results",2017,"EAN 2017 - 55th Conference on Experimental Stress Analysis 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026321265&partnerID=40&md5=91a91995145104d2689a69012ea2fca8","Many times the connections and transfers between main, driven and end parts are realized by a complicated transmission system with usage of several transfer structures. The contribution describes a complicated sewing machine, which uses several systems, such as tooth belt mechanisms, four-link mechanism, crank mechanism, cam mechanism, tilting mechanism and system shaft inside the hollow shaft etc. for connection of driving and driven mechanism members. A 3D CAD simulation is used for animation and visualization of expected (ideal) status and for verification and representation the measured results. © 2017 Technical University of Košice - Faculty of Mechanical Engineering.","3D CAD simulation; Complicated machine; Experiment on real machine; Measurement; Verification and representation","Cams; Computer aided design; Measurements; Stress analysis; Three dimensional computer graphics; 3-d cads; Belt mechanisms; Crank mechanism; Link mechanisms; Measured results; Tilting mechanism; Transfer structure; Transmission systems; Verification",2-s2.0-85026321265
"Lopes A.T., de Aguiar E., De Souza A.F., Oliveira-Santos T.","Facial expression recognition with Convolutional Neural Networks: Coping with few data and the training sample order",2017,"Pattern Recognition",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991821737&doi=10.1016%2fj.patcog.2016.07.026&partnerID=40&md5=2e155a8e529a2ef59639b0240f72a4a1","Facial expression recognition has been an active research area in the past 10 years, with growing application areas including avatar animation, neuromarketing and sociable robots. The recognition of facial expressions is not an easy problem for machine learning methods, since people can vary significantly in the way they show their expressions. Even images of the same person in the same facial expression can vary in brightness, background and pose, and these variations are emphasized if considering different subjects (because of variations in shape, ethnicity among others). Although facial expression recognition is very studied in the literature, few works perform fair evaluation avoiding mixing subjects while training and testing the proposed algorithms. Hence, facial expression recognition is still a challenging problem in computer vision. In this work, we propose a simple solution for facial expression recognition that uses a combination of Convolutional Neural Network and specific image pre-processing steps. Convolutional Neural Networks achieve better accuracy with big data. However, there are no publicly available datasets with sufficient data for facial expression recognition with deep architectures. Therefore, to tackle the problem, we apply some pre-processing techniques to extract only expression specific features from a face image and explore the presentation order of the samples during training. The experiments employed to evaluate our technique were carried out using three largely used public databases (CK+, JAFFE and BU-3DFE). A study of the impact of each image pre-processing operation in the accuracy rate is presented. The proposed method: achieves competitive results when compared with other facial expression recognition methods – 96.76% of accuracy in the CK+ database – it is fast to train, and it allows for real time facial expression recognition with standard computers. © 2016 Elsevier Ltd","Computer vision; Convolutional Neural Networks; Expression specific features; Facial expression recognition; Machine learning","Artificial intelligence; Big data; Computer vision; Convolution; Human computer interaction; Image processing; Learning systems; Neural networks; Convolutional neural network; Deep architectures; Expression specific features; Facial expression recognition; Image preprocessing; Machine learning methods; Recognition of facial expressions; Training and testing; Face recognition",2-s2.0-84991821737
"Kanetsuki Y., Nakata S.","Acceleration of particle based fluid simulation with adhesion boundary conditions using GPU",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029397929&doi=10.1007%2f978-981-10-6502-6_30&partnerID=40&md5=0291cdb28c5dd03cb0ceb5a6e7ef7b1e","We present adhesion boundary conditions for smoothed particle hydrodynamics (SPH) with implicit surfaces. An existing method called ghost SPH addresses adhesion boundary conditions and produces plausible liquid animations using ghost particles. The generation of ghost particles, however, takes considerable computation time when it is implemented on graphics processing units (GPUs). The purpose of this paper is to accelerate ghost SPH using GPUs. In order to accelerate the processing of adhesion boundary conditions, we propose a new boundary model that can skip the ghost particle generation process in air and solid objects. The proposed technique is not just efficient but also inherits other advantages of implicit surfaces such as smoothness. Our test results show that the proposed method efficiently produces natural fluid adhesion motion without air or solid particles and achieves more than a hundredfold speed up compared to ghost SPH. © Springer Nature Singapore Pte Ltd. 2017.","Boundary condition; Graphics processing unit; Implicit surfaces; Smoothed particle hydrodynamics","Adhesion; Air; Boundary conditions; Computer graphics; Computer graphics equipment; Fluid dynamics; Graphics processing unit; Image coding; Program processors; Acceleration of particles; Boundary models; Computation time; Fluid simulations; Implicit surfaces; Particle-generation process; Smoothed particle hydrodynamics; Solid particles; Hydrodynamics",2-s2.0-85029397929
"Han D., Li X., Zhao T.","The application of augmented reality technology on museum exhibition—a museum display project in Mawangdui Han dynasty tombs",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021642230&doi=10.1007%2f978-3-319-57987-0_32&partnerID=40&md5=ca177f72d2ef846ac4d4d3737906a5f5","Augmented Reality (AR) technology currently is widely used in the fields of military, medical, entertainment, Tourism, industrial and etc. In our research, we applied the AR technology into the exhibition of the historical relics in the Mawangdui Han dynasty tombs China. Thousands of the unearthed historical relics have close connections with each other in both cultural and spacial value. However, they are exhibited separately in traditional exhibition way. In this research, we have promoted a new method by using the AR technology to exhibit the historical relics together through the mobile terminal. This project has achieved impressive results on a scaled down model test. This application first captures real scene and detects features, then loads the 3D structure or animation after building the real word coordinate system from the data obtained before. Through the real-time rendering, we are able to argument archaeological features onto the real word scene, enable the audience to get much realer and richer museum experience. This method not only demonstrates a clear position and historical content of different historical relics but also provides interaction between users and historical relics. It brings a new exhibition method in the museum and people would enjoy a more interesting museum experience. © 2017, Springer International Publishing AG.","Augmented Reality; Mawangdui Han Tomb; Mobile terminal; Museum display","Augmented reality; Computer terminals; Industrial research; Mobile phones; Mobile telecommunication systems; Museums; Human computer interaction; Virtual reality; 3D Structure; Archaeological features; Augmented reality technology; Co-ordinate system; Mawangdui Han Tomb; Mobile terminal; Model tests; Real-time rendering; Exhibitions",2-s2.0-85021642230
"Sinha M., Deb S.","An Interactive Elementary Tutoring System for Oral Health Education Using an Augmented Approach",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030857565&doi=10.1007%2f978-3-319-67684-5_26&partnerID=40&md5=7cc63eedb9a8dcbd5c837b6f2b4b7424","The conventional elementary education system in India is mostly guided by formal content development, focusing on areas like math, language, science and social-science. Children tend to retain very little knowledge about other important areas of learning like heath care, which needs to be developed in their foundation years. The education on oral health is one such example which is not given the focus they ought to be. Considering its importance in early education, we propose a learning environment where children would gain knowledge through constant interaction with an intelligent tutoring system. The system addresses the challenges in developing a learning environment for children by introducing audio-visual effects, 3D animations and customizing the tutoring process to provide user-controlled pace of learning. It also employs the Wii Remote for imparting a tangible hardware interaction with the interface. This paper describes the proposed system and the studies conducted on treatment and control groups to evaluate its efficacy and compare the learning outcome at various domains. Experimental results depict positive effects on learning in the proposed technology-enhanced environment and paves a way for the deployment of more interactive, technology-driven learning process in the elementary education system. © 2017, IFIP International Federation for Information Processing.","Intelligent tutoring system; Tangible interaction; Wii remote","Computer aided instruction; Education computing; Engineering education; Human computer interaction; Process control; Audio-visual effects; Content development; Elementary education; Intelligent tutoring system; Learning environments; Learning process; Tangible interaction; Wii remote; Education",2-s2.0-85030857565
"Ao X., Fu Q., Wu Z., Wang X., Zhou M., Chen Q., Seah H.S.","An intersection algorithm for disk B-spline curves",2017,"Computers and Graphics (Pergamon)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026470059&doi=10.1016%2fj.cag.2017.07.021&partnerID=40&md5=dea027d98e269134a36b5b966a53e8dc","In this paper, we propose a method for finding all 2D intersection regions between disk B-spline curves (DBSCs), which is very crucial for DBSC's wide applications such as computer calligraphy, computer 2D animations, and non-photorealistic rendering. As a DBSC represents a region on a plane, the intersection of two DBSCs is a 2D region. To determine the region, the key is to compute the intersection points of the boundaries of two DBSCs. In our algorithm, the boundary of a DBSC is decomposed into four components: the upper boundary, the lower boundary, the start arc, and the end arc. The intersection of two DBSCs can be converted into the intersections between these four components. The main difficulty is to find the intersection involving the upper and lower boundaries of the two DBSCs, as they are variable offsets from the skeletons of the DBSC that are B-spline curves. In our approach, first the DBSCs are subdivided into several disk Bézier curves (DBCs). Therefore the problem of computing intersections of the DBSCs is converted into computing intersection of two DBCs. Then, the disk Bézier clipping method is proposed to exclude regions that have no intersection for the intersection of the two DBCs. In the case of where there is an intersection, we calculate the comparatively rough intersection to be used as initial values for later refinement through the disk Bézier clipping method. Besides, high precision (up to 10e. -15) intersections are achieved by using the Newton's iteration, which is quadratic convergent. The experimental results demonstrate that our algorithm can very efficiently compute all intersections between DBSCs with high precision. Our main contributions in this paper are as follows. First, for the first time, we give the direct parametric expression of DBSC's boundary, which can be simply and conveniently used to compute the properties of DBSC's boundary. Second, our proposed approach of calculating high-accuracy intersections of DBSCs makes DBSC a flexible and effective stroke representation that can be applied to further research such as corresponding computation, automatically coloring, region detection and so on. © 2017 Elsevier Ltd.","Clipping method; Disk B-spline curve; Intersection algorithm; Newton's method","Computer graphics; Curve fitting; D region; Interpolation; Newton-Raphson method; B spline curve; Clipping method; Intersection algorithms; Intersection points; Newton's iteration; Newton's methods; Non-Photorealistic Rendering; Parametric expressions; Iterative methods",2-s2.0-85026470059
"Kobak P., Alda W.","Modeling and rendering of convective cumulus clouds for real-time graphics purposes",2017,"Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030641777&doi=10.7494%2fcsci.2017.18.3.1491&partnerID=40&md5=68add206ab40d9122eef2bb09e637b21","This paper presents a simulation and rendering model of three-dimensional convective cloud evolution. The model is physically based; however, its purpose is graphical. The main stress is put on balancing two parts of the model: the atmosphere simulation with the convective motion of air and water vapor combined with the rendering of semi-transparent and light-scattering clouds in order to achieve realistic animation in real-time. We examine and compare two algorithmic approaches based on CPU and GPU computations.","Computer graphics; GPU programming; Natural phenomena",,2-s2.0-85030641777
"Drange T., Irons A., Drange K.","Creativity in the digital forensics curriculum",2017,"CSEDU 2017 - Proceedings of the 9th International Conference on Computer Supported Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023196165&partnerID=40&md5=7a1a2e43dffc27be8e0da402735231ec","Creativity is defined in the Oxford Dictionary as ""The use of imagination or original ideas to create something"". This definition is easy for students studying topics commonly recognised as creative, such as animation, drawing, photography and design, to put in context and understand. However, when studying topics commonly recognised as technical, such as computer science and digital forensics, it's not as easy for students to relate to this definition. One of the affiliated universities offers bachelor programs in several disciplines and through the first course, the university is trying to establish a common ground of studying for all students regardless of the program they are attending. One of the modules in this first course is called ""What is Creativity?"" but the digital forensic students do not seem to relate creativity to the topics contained in their own study program, and it has been challenging to get these students to see the relationship between creativity and the work situation they might find themselves in after they graduate. This paper will discuss the challenges of teaching creativity to students in perceived technical programs -And try to highlight the challenges experienced from both students and staffs point of views. © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Digital creativity; Higher education; Teaching creativity","Computer forensics; Digital forensics; Education; Electronic crime countermeasures; Forensic science; Teaching; Bachelor programs; Common ground; Digital creativity; Higher education; In contexts; Technical programs; Students",2-s2.0-85023196165
"Tamil Selvi P., Vyshnavi P., Jagadish R., Srikumar S., Veni S.","Emotion recognition from videos using facial expressions",2017,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027166008&doi=10.1007%2f978-981-10-3174-8_47&partnerID=40&md5=3fb181a18dd5e907c3f01e6a523e38e7","In recent days, automatic emotion detection is a field of interest and is used in fields such as e-learning, robotic applications, human–computer interaction (HCI), surveillance, ATM monitoring, mood-based playlists/YouTube videos, psychological studies, medical fields like supporting blind and dumb people, for treating autism in children, entertainment, animation, etc., The proposed work describes detection of human emotions from a real-time video or image with the help of classification technique. The major part of human communication constitutes of facial expression, which is around 55% of the total communicated information. The basic facial expressions that are considered by the psychologists are: happiness, sadness, anger, fear, surprise, disgust, and neutral. The proposed work aims to classify a given video into one of the above emotions using efficient facial features extraction techniques and SVM classifier. The author’s contribution is to increase the efficiency in emotion recognition by implementing the above mentioned superior feature extraction and classification methods. © Springer Nature Singapore Pte Ltd. 2017.","Appearance model; Emotion recognition; Feature extraction; Gabor filter; MATLAB; Occlusions; SVM classifier","Artificial intelligence; Extraction; Face recognition; Feature extraction; Gabor filters; Human computer interaction; MATLAB; Medical imaging; Security systems; Speech recognition; Appearance modeling; Classification technique; Emotion recognition; Facial features extractions; Human communications; Occlusions; Robotic applications; SVM classifiers; Classification (of information)",2-s2.0-85027166008
"Butler M.","Reasoned modelling with Event-B",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018448859&doi=10.1007%2f978-3-319-56841-6_3&partnerID=40&md5=058d0197bf71d991e6cf9ff2c87b00df","This paper provides an overview of how the Event-B language and verification method can be used to model and reason about system behaviour. Formal modelling and reasoning help to increase understanding and reduce defects in requirements specification. Sets and relations play a key role in modelling as do operators on these structures. Precise definitions and rules are provided in order to help the reader gain a strong understanding of the mathematical operators for sets and relations. While the emphasis is on mathematical reasoning, particularly through invariant proofs, the paper also covers less formal reasoning such as identification of problem entities supported by class diagrams and validation of formal models against informal requirements. The use of tools for animation, model checking and proof is also outlined. © 2017, Springer International Publishing AG.",,"Computer software; Mathematical operators; Class diagrams; Formal modelling; Formal reasoning; Informal requirements; Mathematical reasoning; Precise definition; Requirements specifications; Verification method; Model checking",2-s2.0-85018448859
"Yu C., Crane K., Coros S.","Computational design of telescoping structures",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030762337&doi=10.1145%2f3072959.3073673&partnerID=40&md5=42bcbb627c0b6a79643527568706abaa","Telescoping structures are valuable for a variety of applications where mechanisms must be compact in size and yet easily deployed. So far, however, there has been no systematic study of the types of shapes that can be modeled by telescoping structures, nor practical tools for telescopic design. We present a novel geometric characterization of telescoping curves, and explore how free-form surfaces can be approximated by networks of such curves. In particular we consider piecewise helical space curves with torsional impulses, which significantly generalize the linear telescopes found in typical engineering designs. Based on this principle we develop a system for computational design and fabrication which allows users to explore the space of telescoping structures; inputs to our system include user sketches or arbitrary meshes, which are then converted to a curve skeleton. We prototype applications in animation, fabrication, and robotics, using our system to design a variety of both simulated and fabricated examples. © 2017 Copyright held by the owner/author(s).","Computational design; Deployable structures; Discrete differential geometry; Fabrication; Telescoping structures","Fabrication; Geometry; Interactive computer graphics; Computational design; Curve skeletons; Deployable structure; Discrete differential geometry; Engineering design; Free-form surface; Geometric characterization; Systematic study; Computational geometry",2-s2.0-85030762337
"De Cecco M., Fornaser A., Tomasin P., Zanetti M., Guandalini G., Ianes P.G., Pilla F., Nollo G., Valente M., Pisoni T.","Augmented reality to enhance the clinician’s observation during assessment of daily living activities",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021218270&doi=10.1007%2f978-3-319-60928-7_1&partnerID=40&md5=4d43893824965855043e0c7627c52ed4","In rehabilitation medicine and in occupational therapy (OT) in particular the assessment tool is essentially the human eye observing the person performing activities of daily living to evaluate his/her level of independence, efficacy, effort, and safety, in order to design an individualized treatment program. On the contrary, in other clinical settings, diagnostics have very sophisticated technological tools such as the Computed Axial Tomography, 3D ultrasound, Functional Magnetic Resonance Imaging, Positron Emission Tomography and many others. Now it is possible to fill this gap in rehabilitation using various enabling technologies currently in a phase of real explosion, through which it will be possible to provide the rehabilitator, in addition to the evidence provided by the human eye, also a large amount of data describing the person’s motion in 3D, the interaction with the environment (forces, contact pressure maps, motion parameters related to the manipulation of objects, etc.), and the ‘internal’ parameters (heart rate, blood pressure, respiratory rate, sweating, etc.). This amount of information can be fed back to the clinician in an animation that represents the reality augmented with all the above parameters using methodologies of Augmented Reality (AR). The main benefit of this new interaction methodology is twofold: the observed scenarios depicted in animations contain all the relevant parameters simultaneously and the related data are well defined and contextualized. This new methodology is a revolution in rehabilitative evaluation methods that allow on one hand to increase the objectivity and effectiveness of clinical observation, and on the other hand to re-define more reliable assessment scales and more effective rehabilitation programs, more user-centered. © Springer International Publishing AG 2017.",,"Blood pressure; Computer graphics; Computerized tomography; Diagnosis; Magnetic resonance imaging; Multi agent systems; Positron emission tomography; Virtual reality; Activities of Daily Living; Amount of information; Clinical observation; Daily living activities; Enabling technologies; Functional magnetic resonance imaging; Rehabilitation medicine; Rehabilitation programs; Augmented reality",2-s2.0-85021218270
"Huang H.","Research and implementation of visualization technology for automobile electromagnetic field",2017,"Chemical Engineering Transactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026344839&doi=10.3303%2fCET1759147&partnerID=40&md5=1c119c8d4c9f13e46421dcee22deffce","Due to the electromagnetic compatibility of automotive electronic equipment, an automatic system based on 3-dimensional mechanical-arm was put forward and designed to detect electromagnetic field intensity. Visualization in scientific computing is a visual representation of space, geometric shapes, colors, textures, animations, etc., which transforms complex and vast amounts of data into organized structures. In this paper, 3D visualization of electromagnetic field in real automotive environment is studied to provide the visualization of electromagnetic field data and the recorded intensity of electromagnetic. It implements three display functions of electromagnetic field in the light of visualization technology: 3D display of electromagnetic field distribution could show the strength and the trend of electromagnetic field. Extreme value display could pick up the maximum and minimum values. Critical scope display could draw the distribution of all points which range the users set. The design application field of whole system is very wide, and provide a feasible and practical reference for electromagnetic compatibility problem of large electrical equipment. Copyright © 2017, AIDIC Servizi S.r.l.",,"Automobile electronic equipment; Data visualization; Electromagnetic compatibility; Electromagnetic fields; Electronic equipment; Mathematical transformations; Oscillators (electronic); Three dimensional computer graphics; Visualization; Automotive environment; Design applications; Electrical equipment; Electromagnetic field distribution; Organized structure; Visual representations; Visualization in scientific computing; Visualization technologies; Field emission displays",2-s2.0-85026344839
"Suzuki S.-N., Akimoto Y., Ishihara M., Kobayashi Y.","Basic Development of the Active Textbook System consisted of a General book and a Portable Electronic Terminal",2017,"Procedia Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032358450&doi=10.1016%2fj.procs.2017.08.181&partnerID=40&md5=06d3346a075017f39ba0c2d32182bd17","We have proposed a novel educational system named the active textbook (hereafter A-txt) system. A-txt system consists of an ordinary paper-based textbook, a general portable electronic terminal with a camera like a smartphone and application software for the system. A normal textbook can be evolved into a digital one through the attachment of additional digital information and all kinds of digital contents such as movie, animation, 3D CG and so on will be available. The teachers who use the system can create contents for A-txt freely without expertise about information technology. The introduction cost is relatively low, because the mobile terminal for students may be their owned general-purpose type, not special-purpose type, and authored educational materials do not need particular software. For the reasons above, the system has a large possibility to spread in multiple educational fields and it can be easy for students to understand several subjects into which the system is introduced. © 2017 The Authors. Published by Elsevier B.V.","Active textbook (A-txt); application software for A-txt; digital textbook; general portable electronic terminal; paper-based textbook","Application programs; Computer software; Education; Knowledge based systems; Students; Teaching; Active textbook (A-txt); Digital contents; Digital information; Digital textbooks; Educational materials; Educational systems; Ordinary papers; Portable electronics; Textbooks",2-s2.0-85032358450
"Kowitlawakul Y., Chan M.F., Tan S.S.L., Soong A.S.K., Chan S.W.C.","Development of an e-Learning research module using multimedia instruction approach",2017,"CIN - Computers Informatics Nursing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994316427&doi=10.1097%2fCIN.0000000000000306&partnerID=40&md5=d1209255a7e984243b1d7b452681acaf","Students nowadays feel more comfortable with new technologies, which increase their motivation and, as a result, improve their academic performance. In the last two decades, the use of information communication technology has been increasing in many disciplines in higher education. Online learning or e-learning has been used and integrated into the curriculum around the world. A team of nursing faculty and educational technology specialists have developed an e-learning research module and integrate it into the nursing curriculum. The aim was to assist master of nursing and postgraduate nursing students in developing their research knowledge before and throughout their enrollment in the research course. This e-learning module includes interactive multimedia such as audiovisual presentation, graphical theme, animation, case-based learning, and pretest and posttest for each topic area. The module focuses on three main topic areas: (1) basic research principles (for review), (2) quantitative method, and (3) qualitative method. The e-learning module is an innovative use of the information and communication technology to enhance student engagement and learning outcomes in a local context. This article discusses the development journey, piloting process, including the variety of evaluation perspectives, and the ways in which the results influenced the e-learning resource before its wider distribution.","E-learning; Instructional technology; Multimedia; Nursing program; Research module","curriculum; educational technology; human; Internet; learning; medical research; multimedia; nursing education; nursing informatics; procedures; program development; teaching; utilization; Biomedical Research; Computer-Assisted Instruction; Curriculum; Education, Nursing, Graduate; Educational Technology; Faculty, Nursing; Humans; Internet; Learning; Multimedia; Nursing Informatics; Program Development",2-s2.0-84994316427
"Larionov E., Batty C., Bridson R.","Variational stokes: A unified pressure-viscosity solver for accurate viscous liquids",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030775865&doi=10.1145%2f3072959.3073628&partnerID=40&md5=41283b45fb281a144fb55f3999d9155d","We propose a novel unsteady Stokes solver for coupled viscous and pressure forces in grid-based liquid animation which yields greater accuracy and visual realism than previously achieved. Modern fluid simulators treat viscosity and pressure in separate solver stages, which reduces accuracy and yields incorrect free surface behavior. Our proposed implicit variational formulation of the Stokes problem leads to a symmetric positive definite linear system that gives properly coupled forces, provides unconditional stability, and treats difficult boundary conditions naturally through simple volume weights. Surface tension and moving solid boundaries are also easily incorporated. Qualitatively, we show that our method recovers the characteristic rope coiling instability of viscous liquids and preserves fine surface details, while previous grid-based schemes do not. Quantitatively, we demonstrate that our method is convergent through grid refinement studies on analytical problems in two dimensions. We conclude by offering practical guidelines for choosing an appropriate viscous solver, based on the scenario to be animated and the computational costs of different methods. © 2017 Copyright held by the owner/author(s).","Free surfaces; Liquids; Stokes; Viscosity","Crystallography; Interactive computer graphics; Linear systems; Viscosity; Analytical problems; Computational costs; Free surfaces; Practical guidelines; Stokes; Symmetric positive definite linear systems; Unconditional stability; Variational formulation; Liquids",2-s2.0-85030775865
"Qureshi M., Kaleem M., Omer H.","Journey through k-space: An interactive educational tool",2017,"Biomedical Research (India)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014382421&partnerID=40&md5=3f841b282a6858c2db0ff703f6c5f62c","In Magnetic Resonance Imaging (MRI), the information about the image is collected in the form of Radio Frequency (RF) signals with a range of frequencies and phases. The MR image is then reconstructed by performing the inverse Fourier Transform of the acquired raw data (k-space). A good understanding of the k-space offers important insight into the basic properties related to signal-to-noise ratio, image distortion, resolution and contrast in MRI. This paper presents an implementation of various MATLAB functions for exploring the different properties of k-space such as acceleration factor, filtering schemes, different kinds of artefacts, quantifying parameters. The user is also able to visualize different kinds of trajectories (Cartesian and Non-Cartesian) using animations. The main purpose of this toolbox is to present an interactive graphical user interface (GUI) using MATLAB for researchers and graduate/undergraduate students to develop better understanding of MRI. In order to evaluate the usefulness of the tool, it is used by graduate/undergraduate students in different projects. It has been observed that the students were able to use the toolbox “k-space and Interactive Educational Tool” effectively without prior background knowledge in k-space. The software toolbox is available for free download from our research group website. © 2017, Scientific Publishers of India. All rights reserved.","Image reconstruction techniques; K-space; MRI","acceleration; artifact; computer interface; filtration; human; human experiment; image reconstruction; nuclear magnetic resonance imaging; scientist; software; undergraduate student",2-s2.0-85014382421
"Dedov D., Krasnyanskiy M., Karpov S., Obukhov A., Arkhipov A.","Development of a model of fire propagation for the implementation in adaptive training simulators",2017,"International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032500276&doi=10.5593%2fsgem2017%2f13%2fS03.031&partnerID=40&md5=7e5f528c470fc16489b977996e1653ba","The problem of visualization of fires is relevant to the design of emergency situation simulators for industrial facilities involving a risk of fire or explosion. The effectiveness of a simulator depends on the accuracy of animation (visualization) used in this simulator. The present paper aims to build a mathematical model of fire spread at industrial facilities with regard to the associated processes of smoke generation, release of toxic combustion products and their influence on physical condition of an individual. The model is based on the results of the analysis of fire hazard properties of materials, mechanisms of fire occurrence, their distribution among the objects and the elimination of fires using fire-fighting equipment. The developed mathematical model is intended for application in adaptive simulators (ASs) created using virtual and augmented reality technologies. The developed fire spread algorithm was used as the basis for software implementation of the mathematical model in the AS, using Unity 3D development environment. The results of the study were used to find the fire spread visualization parameters in the AS through simulated emergencies occurring in the manufacture of dyes and pigments at PJSC ""Pigment"" (Tambov, Russia). © SGEM2017","Adaptive training complex; Fires; Mathematical model; Visualization","Augmented reality; Fire extinguishers; Fire fighting equipment; Flow visualization; Mathematical models; Simulators; Three dimensional computer graphics; Visualization; Adaptive training; Combustion products; Development environment; Emergency situation; Industrial facilities; Physical conditions; Software implementation; Virtual and augmented reality; Fires",2-s2.0-85032500276
"Yuksel C., Yuksel C.","Lighting grid hierarchy for self-illuminating explosions",2017,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030761202&doi=10.1145%2f3072959.3073604&partnerID=40&md5=64f298a8b2c2c2d717b86dc4acea54df","Rendering explosions with self-illumination is a challenging problem. Explosions contain animated volumetric light sources immersed in animated smoke that cast volumetric shadows, which play an essential role and are expensive to compute. We propose an efficient solution that redefines this problem as rendering with many animated lights by converting the volumetric lighting data into a large number of point lights. Focusing on temporal coherency to avoid flickering in animations, we introduce lighting grid hierarchy for approximating the volumetric illumination at different resolutions. Using this structure we can efficiently approximate the lighting at any point inside or outside of the explosion volume as a mixture of lighting contributions from all levels of the hierarchy. As a result, we are able to capture high-frequency details of local illumination, as well as the potentially strong impact of distant illumination. Most importantly, this hierarchical structure allows us to efficiently precompute volumetric shadows, which substantially accelerates the lighting computation. Finally, we provide a scalable approach for computing the multiple scattering of light within the smoke volume using our lighting grid hierarchy. Temporal coherency is achieved by relying on continuous formulations at all stages of the lighting approximation. We show that our method is efficient and effective approximating the self-illumination of explosions with visually indistinguishable results, as compared to path tracing. We also show that our method can be applied to other problems involving a large number of (animated) point lights. © 2017 Copyright held by the owner/author(s).","Explosion rendering; Many-lights; Multiple scattering; Participating media; Translucent shadows; Virtual point lights","Explosions; Interactive computer graphics; Light sources; Multiple scattering; Different resolutions; Hierarchical structures; Lighting computations; Participating media; Temporal coherency; Translucent shadows; Virtual points; Volumetric illuminations; Lighting",2-s2.0-85030761202
"Wang Y., Si Z., Zhang L.","Design and implementation of interactive courseware based on mobile terminal",2017,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016004613&doi=10.1007%2f978-981-10-3530-2_49&partnerID=40&md5=3d9973f578efda0bd0a79f72666b6acb","Electronic courseware is an important tool for teachers to impart knowledge to students, and an innovative education mode in the environment of multimedia, but the courseware in the modern class only stays in the visual display stage of knowledge points, audio-video, animation and other elements, and is lack of interaction of multimedia courseware. The design is based on the interaction between teachers and students, students and students, and the popularity of mobile electronic devices, combined with image-processing and typesetting tools to designed a course which will meet the teaching demands, applying the FounderFX 6.0 digital version to realize the static effects of pages, and then according to the user experience, to realize the interactive effects, finally release it to the mobile terminal to assist the classroom teaching. The design makes full use of multimedia technology to transfer the interactive courseware to the mobile terminal, and students are really participate in the curriculum, which has provided a more flexible teaching environment for the modern classroom. © Springer Nature Singapore Pte Ltd. 2017.","Interaction; Mobile terminal; Multimedia courseware","Computer terminals; Curricula; Digital devices; E-learning; Education; Image processing; Mobile phones; Mobile telecommunication systems; Multimedia systems; Students; Classroom teaching; Design and implementations; Innovative education; Interaction; Mobile electronics; Mobile terminal; Multimedia courseware; Multimedia technologies; Teaching",2-s2.0-85016004613
"Dingli A., Mifsud N.","Using holograms to increase interaction in museums",2017,"Advances in Intelligent Systems and Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986265771&doi=10.1007%2f978-3-319-41661-8_12&partnerID=40&md5=5793f0ad27aeb9243331e4dbff422c54","Holographic Technology has made huge strides over the past few years. The range of applications is practically endless and we envisage seeing major investments in the coming years. The main aim of this project was to create virtual 3D agents capable of behaving in a believable manner and display them within a real 3D model of a megalithic temple called “Hagar Qim” (http://heritagemalta.org/ museums-sites/hagar-qim-temples/). These holographic humans are not only visually appealing with clear animations but must also behave in a psychologically sound and autonomous manner, meaning that they would be their own beings, not controlled by a user and their actions relate to the context of the world they are situated in. In order to achieve a high degree of autonomy and believability, the holographic humans developed in this work are self-determined with their own reactive plan of actions to organize their Neolithic daily routines, just like our ancestors did. In order to produce such believable behaviour, computational motivation models based on human psychological theories were explored. Each holographic human is also self-aware and adheres to its own biological needs. Furthermore, visitors are able to interact and communicate with the holographic humans via a mobile device. The system was tested by a number of people in order to test the subjective concept of believability of the system as a whole. On the whole we were extremely satisfied with the positive feedback obtained whereby 96% of respondents found the exhibit believable. There was also a 90% agreement that this platform would be suitable in a museum context since it would immerse visitors within this context whilst helping them learn in a fun and interactive way. © Springer International Publishing Switzerland 2017.","Believable systems; Holographic displays; Human computer interaction; Intelligent agents; Mobile technologies","Computation theory; Feedback; Holograms; Holography; Human computer interaction; Intelligent agents; Mobile agents; Mobile devices; Museums; Daily routines; Degree of autonomy; Holographic technology; Interactive way; Mobile Technology; Motivation models; Number of peoples; Psychological theory; Holographic displays",2-s2.0-84986265771
"Kaghazchi N., Yoshii A., Kodama S., Kaneko M.","Development and evaluation of an E-picture book system using multi-directional scrolling and illustrations with visual guidance",2017,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024363340&doi=10.1007%2f978-3-319-58753-0_79&partnerID=40&md5=f8db2f52daa902d2eb259743ebb63798","This study is about the development and evaluation of a new e-picture-book (electronic picture book) system designed for touch screen devices. The narration method of this e-picture-book is inspired by the Japanese old paintings in which the whole story was happening in a single page. The artists were using visual elements as navigation method on the page for their story telling propose. For this project, we have made an edgeless single-page picture book with many images (story scenes), which are arranged in several columns and rows. Each scene has illustrated images with visual guidance (e.g. pointing finger, gaze point, arrow shape composition, animation movements and sound effects), which indicates a certain direction to make the user able to find the story line. A multi-directional scrolling (similar to the scrolling method in the Google map) interface has been designed to enable the user to navigate freely between the story scenes and find the story line. Kaghazchi created an original story “The Cloudy Lady” for this e-picture book. For evaluating and verifying the effectiveness of each scene and also the guidance ability of the elements to navigate the user through the story line, we performed two types of experiments (eye tracking camera and video recording). Analyzing data from the experiments, we discussed which visual elements and expressions in each illustration have affected the user navigation considering the percentage of successful scrolls toward the target area(s) per each scene. Our future goal is to improve and complete the user navigation method for this e-picture-book. © Springer International Publishing AG 2017.","E-picture book; Eye navigation; GUI; Multi-direction scrolling","Graphical user interfaces; Navigation; Touch screens; Video recording; Electronic pictures; Multi-direction scrolling; Navigation methods; Old paintings; Story telling; User navigation; Visual elements; Visual guidance; Human computer interaction",2-s2.0-85024363340
"Marković S., Bulut T.","Attractiveness of the female body: Preference for the average or the supernormal?",2017,"Psihologija",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031791414&doi=10.2298%2fPSI1703403M&partnerID=40&md5=5e5eb0a3f2eb61e89c4c9d81d2221f34","The main purpose of the present study was to contrast the two hypotheses of female body attractiveness. The first is the ""preference-for-the average"" hypothesis: the most attractive female body is the one that represents the average body proportions for a given population. The second is the ""preference-for-the supernormal"" hypothesis: according to the so-called ""peak shift effect"", the most attractive female body is more feminine than the average. We investigated the preference for three female body characteristics: waist to hip ratio (WHR), buttocks and breasts. There were 456 participants of both genders. Using a program for computer animation (DAZ 3D) three sets of stimuli were generated (WHR, buttocks and breasts). Each set included six stimuli ranked from the lowest to the highest femininity level. Participants were asked to choose the stimulus within each set which they found most attractive (task 1) and average (task 2). One group of participants judged the body parts that were presented in the global context (whole body), while the other group judged the stimuli in the local context (isolated body parts only). Analyses have shown that the most attractive WHR, buttocks and breasts are more feminine (meaning smaller for WHR and larger for breasts and buttocks) than average ones, for both genders and in both presentation contexts. The effect of gender was obtained only for the most attractive breasts: males prefer larger breasts than females. Finally, most attractive and average WHR and breasts were less feminine in the local than in the global context. These results support the preference-forthe supernormal hypothesis: all analyses have shown that both male and female participants preferred female body parts which are more feminine than those judged average. © 2017 by the Serbian Psychological Association.","Attractiveness; Average; Breasts; Buttocks; Female body; Gender; Global; Local; Supernormal; WHR",,2-s2.0-85031791414
"Kim J.Y., Cho E.","Evaluation of a self-efficacy enhancement program to prevent pressure ulcers in patients with a spinal cord injury",2017,"Japan Journal of Nursing Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978105258&doi=10.1111%2fjjns.12136&partnerID=40&md5=6921f19c07be7d9d91ca8da5e4ce34f5","Aim: This study developed a self-efficacy enhancement program and evaluated its effects on the self-care behaviors, self-care knowledge, and self-efficacy regarding pressure ulcer prevention in patients with a spinal cord injury. Methods: This was a multicenter randomized controlled trial. Six hospitals were invited to recruit patients with a spinal cord injury who were undergoing rehabilitation after receiving acute treatment. These hospitals were randomly allocated into experimental (three hospitals) or control (three hospitals) groups and 47 patients participated (24 in the experimental group and 23 in the control group). The experimental group was given an 8 week self-efficacy enhancement program for pressure ulcer prevention. The self-efficacy enhancement program consisted of small-group face-to-face intervention (education and skills training), education with computer animation, phone counseling, face-to-face counseling, and self-management records. The control group only received a pressure ulcer prevention information booklet. Self-care knowledge, self-efficacy, self-care behaviors, and pressure ulcer incidence were measured at baseline and after the 8 week self-efficacy enhancement program. Results: The experimental group showed a significantly greater improvement in self-care knowledge, self-efficacy, and self-care behaviors for pressure ulcer prevention than did the control group. One participant in the control group developed a pressure ulcer, while none of the participants in the experimental group developed a pressure ulcer; this difference was not statistically significant. Conclusions: The self-efficacy enhancement program enabled patients with a spinal cord injury to engage in continued self-care behaviors and helped them to improve their knowledge and self-efficacy concerning pressure ulcer prevention. © 2016 Japan Academy of Nursing Science","behavior; pressure ulcer; self-care; self-efficacy; spinal cord injury","clinical trial; complication; controlled study; human; multicenter study; patient education; Pressure Ulcer; randomized controlled trial; self concept; South Korea; spinal cord injury; Humans; Patient Education as Topic; Pressure Ulcer; Republic of Korea; Self Efficacy; Spinal Cord Injuries",2-s2.0-84978105258
"Hodges R., Munro N., Baker E., McGregor K., Heard R.","The Monosyllable Imitation Test for Toddlers: influence of stimulus characteristics on imitation, compliance and diagnostic accuracy",2017,"International Journal of Language and Communication Disorders",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963930495&doi=10.1111%2f1460-6984.12249&partnerID=40&md5=90a0f59eed7c92e5b95cc86d258c7441","Background: Although verbal imitation can provide a valuable window into the developing language abilities of toddlers, some toddlers find verbal imitation challenging and will not comply with tests that involve elicited verbal imitation. The characteristics of stimuli that are offered to toddlers for imitation may influence how easy or hard it is for them to imitate. This study presents a new test of elicited imitation—the Monosyllable Imitation Test for Toddlers (MITT)—comprising stimuli of varying characteristics and test features designed to optimize compliance. Aims: To investigate whether the stimulus characteristics of neighbourhood density and consonant complexity have independent and/or convergent influences on imitation accuracy; and to examine non-compliance rates and diagnostic accuracy of the MITT and an existing test, the Test of Early Nonword Repetition (TENR) (Stokes and Klee 2009a). Methods & Procedures: Fifty-two toddlers (25–35 months) participated. Twenty-six had typically developing language (TDs) and 26 were defined as late talkers (LTs) based on parent-reported vocabulary. The MITT stimuli were created by manipulating both neighbourhood density (dense or sparse) and consonant complexity (early- or late-developing initial consonant). The MITT was designed to maximize compliance by: (1) using eight monosyllabic stimuli, (2) providing three exposures to stimuli and (3) embedding imitation in a motivating context: a computer animation with reasons for imitation. Outcomes & Results: Stimulus characteristics influenced imitation accuracy in TDs and LTs. For TDs, neighbourhood density had an independent influence, whereas for LTs consonant complexity had an independent influence. These characteristics also had convergent influences. For TDs, stimuli were all equally easy to imitate, except those that were both sparse and contained a late-developing consonant which were harder to imitate. For LTs, stimuli that were both dense and contained an early-developing consonant were easier to imitate than any other stimuli. Two LTs and no TDs were non-compliant with the MITT. With the TENR, five LTs and two TDs were non-compliant. The MITT and TENR yielded similar levels of diagnostic sensitivity, but the TENR offered higher specificity rates. Subsets of stimuli from the MITT and the TENR also showed diagnostic promise when explored post-hoc. Conclusions & Implications: Stimulus characteristics converge to influence imitation accuracy in both TD and LT toddlers and therefore should be considered when designing stimuli. The MITT resulted in better compliance than the TENR, but the TENR offered higher specificity. Insights about late talking, elicited imitation and speech production capabilities are discussed. © 2016 Royal College of Speech and Language Therapists","assessment; compliance; diagnostic accuracy; late talkers; nonword imitation; stimulus characteristics",,2-s2.0-84963930495
"Maharaj-Sharma R., Sharma A.S., Sharma A.","Using ICT-based instructional technologies to teach science: Perspectives from teachers in Trinidad and Tobago",2017,"Australian Journal of Teacher Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030679210&doi=10.14221%2fajte.2017v42n10.2&partnerID=40&md5=3634e1e748fbe9fbe9f31f1693f6bfb5","The purpose of this study was to investigate how science teachers in Trinidad and Tobago use ICT-based instructional technologies in classroom science teaching. The participants were 30 secondary school science teachers who completed their Postgraduate Diploma in Education within the last 2 years from the University of the West Indies in Trinidad and Tobago. The teachers were asked to prepare lesson plans which demonstrate their use of instructional technologies to teach science topics within their term's schemes of work. They were subsequently asked to explain their reasons for using the selected instructional technologies. The findings revealed that PowerPoint was the most widely used ICT-based instructional technology in the lesson plans analyzed. Animations and hands-on practical activities were the least used ICT-based instructional technologies. Virtual labs, computer-aided simulations and smartboards, were other ICT-based instructional technologies used by a few teachers. Textbooks and whiteboards were the non-ICTbased instructional technologies teachers used.",,,2-s2.0-85030679210
"Wu T., Zhang L.","Evolving strokes using aesthetic measures",2017,"ICIC Express Letters, Part B: Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014763996&partnerID=40&md5=828e0a6e302af4fbb5ef32425d2ab5b7","Computer-based evolutionary art is in the ascendant and widely applied in media contexts such as web design, games and video animation. The process of creating interesting images can be enjoyable if a useful method is involved. In this paper the effects of introducing novelty representation and evaluation in evolutionary art are explored. The technical aspects of using strokes to represent gene in evolutionary art are described, five types of strokes are defined mathematically, and genetic operators and evolutionary parameters are explained. Also, a novel aesthetic measure is provided based on data field, and used to evaluate fitness of individuals, as well as four existing aesthetic measures. A number of experiments using an unsupervised evolutionary art algorithm are performed. The results suggest that the proposed method can generate appealing images with different styles by choosing different fitness functions, and it would inspire graphic designers who may be interested in subtle aesthetic patterns created automatically. © 2017 ICIC International.","Computational aesthetics; Evolutionary art; Evolutionary computation; Genetic algorithm",,2-s2.0-85014763996
"Mityushov E.A., Misyura N.E., Berestova S.A.","Smooth movement of a rigid body in orientational space along the shortest path through the uniform lattice of the points on SO(3)",2017,"Vestnik Udmurtskogo Universiteta: Matematika, Mekhanika, Komp'yuternye Nauki",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018747547&doi=10.20537%2fvml70112&partnerID=40&md5=d52f8f616fb794e17759bdc8b4a87ca6","Many tasks of motion control and navigation, robotics and computer graphics are related to the description of a rigid body rotation in three-dimensional space. We give a constructive solution for the smooth movement of a rigid body to solve such problems. The smooth movement in orientational space is along the shortest path. Spherical solid body motion is associated with the movement of the point on the hypersphere in four-dimensional space along the arcs of large radius through the vertices of regular four-dimensional polytope. Smooth motion is provided by the choice of a special nonlinear function of quaternion interpolation. For an analytical presentation of the law of continuous movement, we use the original algebraic representation of the Heaviside function. The Heaviside function is represented using linear, quadratic and irrational functions. The animations in the computer program MathCad illustrate smooth motion of a rigid body through the nodes of a homogeneous lattice on the group SO(3). The algorithm allows one to change in a wide range the time intervals displacements between nodes, as well as the laws of motion on these intervals.","Discrete distribution on SO(3); Heaviside function; Quaternion interpolation; Regular four-dimensional polytope; Shortest paths",,2-s2.0-85018747547
"Zamzamin A.B., Ghani D., Amir Hussin A.A., Khairuddin M.Z.","Technological advancement through character design: Darth Vader as case study",2017,"Annales-Anali za Istrske in Mediteranske Studije - Series Historia et Sociologia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019862295&doi=10.19233%2fASHS.2017.01&partnerID=40&md5=630fc6874ea5ff6fb3deb5567c008d71","The importance of character design in films and other media may have an indirect impact on future concept arts, ideas and technological advancement. Based on a story, a conceptual artist would create many, even hundreds of different designs before reaching the final product of characters, environments, vehicles, creatures and more. From these final works we get iconic figures, futuristic weapons and new worlds on the big screen that serve our entertainment purposes and hint at what the future might hold. The purpose of this paper is to bridge the idea on how conceptual art can have an impact on science, our everyday lives and even the entire world. By analysing Darth Vader in Star Wars films as the core subject, one of the most iconic villains in the history of cinema, the research will focus on the pre-production process, and how his final design can be influential to advanced technological research on prosthetic limbs, breathing apparatus and more. The process of concept art as well as the understanding of Character Archetypes will also be presented. Other well-known characters from three different platforms (film, computer games and animation) will be used as comparisons to Darth Vader in terms of similarity regarding his type of injuries and the modifications made to their bodies that could one day become an invention and thus again relate to the importance of character design.","Character Archetypes; Character Design; Concept Arts; Darth Vader; Technology",,2-s2.0-85019862295
"Ali D.F., Omar M., Ibrahim N.H., Surif J., Ali M., Ismail S.","Overcoming the problems faced by student's in learning engineering drawing with the implementation of augmented reality learning environment",2017,"Man in India",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031786445&partnerID=40&md5=fff103171094faf30725f0dfd5bb07af","Engineering drawing is one of the compulsive course for engineering students in higher education. It is compulsory for them to master the course since it is the basic skills needed as an engineer. In engineering drawing students faced difficulties to understand the complex concepts of this course due to the lack of visualization skills. Thus, this study aims to find out the problems faced by first year undergraduates engineering students in Universiti Teknologi Malaysia in learning orthographic and isometric projection and the effects of implementing augmented reality learning environment towards their combining 2-dimensional object skills. To find out the problems faced by students, qualitative research approach is used among the respondents which involves 5 undergraduates engineering students. Meanwhile, 30 students were chosen as respondent for a quasi-experimental research design to find out the effectiveness of the implementation of augmented reality learning environment in engineering drawing teaching and learning process. Students were given a set of pre-test before being exposed to augmented reality learning environment and a set of post-test after the intervention. The test involved in this section is Differential Aptitude Test of Space Relation (DAT:SR) which is used to determine the students level of combining 2-dimensional object skills. As for data analysis, structured interview is used as research instruments for the qualitative sections and the results are analysed using thematic analysis to find out the problems faced by students in learning engineering drawing. For quantitative section, descriptive and inferential statistics were used to find out the effectiveness of the intervention. Descriptive statistics were used to find out the mean and standard deviation value of the data while paired sample t-test were used for inferential statistics to find out the significant differences for the test- results. The findings of this study found that most of the respondents are having difficulties in visualizing the 3 dimensional objects from the 2-dimensional projection images and vice versa which they prefer to learn using 3D computer-aided animation as teaching aid. Other than that, this study also found that students' are able to improve their combining 2-dimensional object skills when learning using augmented reality learning environment. While spatial training is a must to engineering students, utilization of advanced technology could be great alternatives to help students in improving their spatial ability. © Serials Publications.","Augmented Reality Learning Environment; Combining 2-Dimensional Object Skills; Engineering Drawing",,2-s2.0-85031786445
[No author name available],"CEUR Workshop Proceedings",2017,"CEUR Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029173541&partnerID=40&md5=081287b4069c596b82eb90069ac5650b","The proceedings contain 22 papers. The topics discussed include: a skeleton/cage hybrid paradigm for digital animation; a declarative and classifier gesture recognition method for creating an effective feedback and feedforward system; advanced visual interfaces supporting distributed cloud-based big data analysis; interactive data visualization for product search; tangibles for graph algorithmic thinking: research questions and work-in-progress; the evolution of a tangible for children's conversations: research questions and progress; developing a n400 brain computer interface based on semantic expectancy; gestural interaction in virtual environments: user studies and applications; effective user interactions for visual analytics tools; semiotic virtual reality framework validation; ChIP: teaching coding in primary schools; the Madeira touch: encouraging visual-spatial exploration using a tactile interactive display; SnAIR drum: a gesture interface for rhythm practice; demonstration of a sensor-based app for self-monitoring of medicine intake; learning system user interface preferences: an exploratory survey; comparison of UX evaluation methods that measures the UX over time; audio guides and human tour guides: measuring children's engagement & learning at a museum setting; UTAssistant: a web platform supporting usability testing in Italian public administrations; advanced interaction paradigms to define smart visit experiences in the internet of things era; does the perception of team collaboration changes with time? study with computer science students; and a multimodal interface for robot-children interaction in autism treatment.",,,2-s2.0-85029173541
"Martín R., Weinmann M., Hullin M.B.","Digital transmission of subjective material appearance",2017,"Journal of WSCG",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027254409&partnerID=40&md5=4db78b59aff0fc9e5f8d8b67881051d4","The digital recreation of real-world materials has a substantial role in applications such as product design, on-line shopping or video games. Since decisions in design or shopping are often driven by qualities like “softness” or “beautifulness” of a material (rather than its photo-accurate visual depiction), a digital material should not only closely capture the texture and reflectance of the physical sample, but also its subjective feel. Computer graphics research constantly struggles to trade physical accuracy against computational efficiency. However, the connection between measurable properties of a material and its perceived quality is subtle and hard to quantify. Here, we analyze the capability of a state-of-the-art model for digital material appearance (the spatially-varying BRDF) to transport certain subjective qualities through the visual channel. In a psychophysical study, we presented users with measured material SVBRDFs in the form of rendered still images and animations, as well as photographs and physical samples of the original materials. The main insight from this experiment is that photographs reproduce better those qualities associated with the sense of touch, particularly for textile materials. We hypothesized that the abstraction of volumetric materials as opaque and flat textures destroys important visual cues especially in border regions, where fluff and protruding fibers are most prominent. We therefore performed a follow-up experiment where the border regions have been removed from the photographs. The fact that this step greatly reduced the capability of photos to transport important qualities suggests strong directions of future research in applied perception and computer graphics. © 2017, Vaclav Skala Union Agency. All rights reserved.","Digital material appearance; Material perception; SVBRDF; Visual psychophysics",,2-s2.0-85027254409
"Caesar R., Suyoto, Gunanto S.G.","An automatic 3D face model segmentation for acquiring weight motion area",2016,"Proceedings - 2016 1st International Conference on Information Technology, Information Systems and Electrical Engineering, ICITISEE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011307882&doi=10.1109%2fICITISEE.2016.7803052&partnerID=40&md5=f11a26e711506b20799339c67c085b01","Inside facial animation works there is an animator that need to be skilled enough to produce detailed animation, so the facial animation can be smooth when doing facial expressions. Every animated character requires special handling based on the characteristics of the size and location of the bone. This process, where every face model need special handling were time consuming and tedious work. For that issue this research propose method for using motion capture marker data in 3D face model for automatically segment weight motion area based on the feature point. Marker data that came from motion capture of human model will be used to represent a centroid of vertex cluster that forming expressions in animated character. The data grouping process will be spherical coordinate result calculation between feature point and vertices using modified nearest neighbor algorithm. The result obtained in this research will show the weight motion area that generated automatically from the feature point based on nearest neighbor algorithm in a 3D face model. © 2016 IEEE.","facial animation; feature point; nearest neighbor; segmentation; weight motion area","Animation; Image segmentation; Information systems; Animated characters; Facial animation; Facial Expressions; feature point; Nearest neighbor algorithm; Nearest neighbors; Spherical coordinates; weight motion area; Three dimensional computer graphics",2-s2.0-85011307882
"Vogt D., Stepputtis S., Weinhold R., Jung B., Ben Amor H.","Learning human-robot interactions from human-human demonstrations (with applications in Lego rocket assembly)",2016,"IEEE-RAS International Conference on Humanoid Robots",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010208247&doi=10.1109%2fHUMANOIDS.2016.7803267&partnerID=40&md5=e8d50e3780213096b36deae6453583f6","This video demonstrates a novel imitation learning approach for learning human-robot interactions from human-human demonstrations. During training, the movements of two human interaction partners are recorded via motion capture. From this, an interaction model is learned that inherently captures important spatial relationships as well as temporal synchrony of body movements between the two interacting partners. The interaction model is based on interaction meshes that were first adopted by the computer graphics community for the offline animation of interacting virtual characters. We developed a variant of interaction meshes that is suitable for real-time human-robot interaction scenarios. During humanrobot collaboration, the learned interaction model allows for adequate spatio-temporal adaptation of the robots behavior to the movements of the human cooperation partner. Thus, the presented approach is well suited for collaborative tasks requiring continuous body movement coordination of a human and a robot. The feasibility of the approach is demonstrated with the example of a cooperative Lego rocket assembly task. © 2016 IEEE.",,"Anthropomorphic robots; Computer graphics; Human computer interaction; Man machine systems; Robots; Rockets; Collaborative tasks; Human demonstrations; Human interactions; Human-robot collaboration; Imitation learning; Interaction model; Spatial relationships; Virtual character; Human robot interaction",2-s2.0-85010208247
"Fernandez C.A.T., Paliyawan P., Yin C.C., Thawonmas R.","Piano learning application with feedback provided by an AR virtual character",2016,"2016 IEEE 5th Global Conference on Consumer Electronics, GCCE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010289360&doi=10.1109%2fGCCE.2016.7800380&partnerID=40&md5=d051548f546c9c0382845812bb5b3c1f","This paper proposes a mobile application that uses Augmented Reality to enhance the experience of learning to play keyboard instruments. The proposed application uses Google Cardboard to let users visualize a virtual character and instructions. The character gives the user real-time visual feedback according to their music playing performance as evaluated by the system. This application lets users choose among pre-defined songs that can be learned and practiced by using a simplified notation that eliminates the barrier of using actual musical notation. Having in mind the psychological benefits of music learning, we aim to present a fun and easy way to learn music and keep the users' motivation during the process. © 2016 IEEE.","Augmented Reality; character animation; Computer-based instruction; music; visualization","Animation; Augmented reality; Computer aided instruction; Flow visualization; Musical instruments; Visual communication; Character animation; Computer based instruction; Learning to play; Mobile applications; music; Musical notation; Real time visual feedback; Virtual character; E-learning",2-s2.0-85010289360
"Şendurur E., Ersoy E., Çetin İ.","The design and development of creative instructional materials: the role of domain familiarity for creative solutions",2016,"International Journal of Technology and Design Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006918713&doi=10.1007%2fs10798-016-9391-y&partnerID=40&md5=e6224616042e0497ddf308bf9d9146f8","The design and development processes of instructional materials might be considered simple and clear because the pre-established instructional goals can lead the way. However, in practice, there are lots of issues to be considered during these processes. The quality of the material, appropriate visual design, usability, and acceptable amount of cognitive load are some of these issues. On the other hand, an instructional material needs to be as original as possible. In this study, we focused on the creativity of the instructional materials designed and developed by second year students from the Computer Education and Instructional Technologies (CEIT) department. We divided students into two groups: (1) CEIT students designing and developing materials about Information Technology (IT); (2) CEIT students designing and developing materials about Math. The main aim of this study is to understand how CEIT students’ instructional materials differ when they design and develop materials, which are out of their field of experience. In other words, we tried to compare how the creativity of materials change when students create materials with familiar domain (IT) in comparison to unfamiliar domain (Math). Students worked on ten instructional materials such as digital story, animation, and worksheet for 14 weeks. The materials of students were evaluated in terms of creativity, and then they were interviewed. The students worked in groups of 4–5, and during the material development period, we as researchers observed and took notes about the whole process. The findings indicated that materials developed in familiar domain were higher in creativity than those of the unfamiliar. Students’ explanations of creativity and their evaluations about the process helped us to understand the reasons of the produced materials’ creativeness. Technical skills, authentic contributions, material type, and the boundaries of the content or familiarity were found as the primary factors affecting the design and development of creative instructional materials. © 2016 Springer Science+Business Media Dordrecht","Creativity; Instructional materials; Material design and development","Education; Students; Creativity; Design and Development; Design and development process; Domain familiarities; Instructional materials; Instructional technology; Material designs; Material development; Design",2-s2.0-85006918713
"Grover D., Chaudhuri P.","Data-driven 2D effects animation",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014847655&doi=10.1145%2f3009977.3010000&partnerID=40&md5=8faca582afa5add96d8ba475401a491e","Making plausible, high quality visual effects, like water splashes or fire, in traditional 2D animation pipelines require an animator to draw many frames of phenomena that are very difficult to recreate manually. We present a technique that uses a database of video clips of such phenomena to assist the animator. The animator has to only input sample sketched frames of the phenomena at particular time instants. These are matched to frames of the video clips and a plausible sequence of frames is generated from these clips that contain the animator drawn frames as constraints. The colour style of the hand-drawn frames is used to render the generated frames, thus resulting in a 2D animation that follows the style and intent of the 2D animator. Our system can also create multi-layered effects animation, allowing the animator to draw interacting mixed phenomena, like water being poured on fire. © 2016 ACM.","Non-photorealistic animation; Non-photorealistic rendering; Sketch-based; Special effects","Computer graphics; Computer vision; Image processing; Rendering (computer graphics); Special effects; Video cameras; 2D animation; High quality; Multi-layered; Non-Photorealistic Rendering; Photo-realistic animation; Sketch-based; Visual effects; Water splash; Animation",2-s2.0-85014847655
"Muralikrishnan S., Chaudhuri P.","Sketch-based simulated draping for Indian garments",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014813344&doi=10.1145%2f3009977.3010001&partnerID=40&md5=333528a45aca5176e59bd16b55abce58","Virtual garments like shirts and trousers are created from 2D patterns stitched over 3D models. However, Indian garments, like dhotis and saris, pose a unique draping challenge for physically-simulated garment systems, as they are not stitched garments. We present a method to intuitively specify the parameters governing the drape of an Indian garment using a sketch-based interface. We then interpret the sketch strokes to procedural, physically-simulated draping routines to wrap, pin and tuck the garments around the body mesh as needed. After draping, the garments are ready to be simulated and used during animation as required. We present several examples of our draping technique. © 2016 ACM.","Automated garment draping; Indian garment draping; Sketch-based","Computer vision; 2D patterns; 3D models; Automated garment draping; Indian garment draping; Sketch based Interface; Sketch-based; Virtual garments; Image processing",2-s2.0-85014813344
"Li B., Lu Y., Johan H., Fares R.","Sketch-based 3D model retrieval utilizing adaptive view clustering and semantic information",2016,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006484007&doi=10.1007%2fs11042-016-4187-3&partnerID=40&md5=6364fec2fe39d973daba46956d7029a6","Searching for relevant 3D models based on hand-drawn sketches is both intuitive and important for many applications, such as sketch-based 3D modeling and recognition, human computer interaction, 3D animation, game design, and etc. In this paper, our target is to significantly improve the current sketch-based 3D retrieval performance in terms of both accuracy and efficiency. We propose a new sketch-based 3D model retrieval framework by utilizing adaptive view clustering and semantic information. It first utilizes a proposed viewpoint entropy-based 3D information complexity measurement to guide adaptive view clustering of a 3D model to shortlist a set of representative sample views for 2D-3D comparison. To bridge the gap between the query sketches and the target models, we then incorporate a novel semantic sketch-based search approach to further improve the retrieval performance. Experimental results on several latest benchmarks have evidently demonstrated our significant improvement in retrieval performance. © 2016 Springer Science+Business Media New York","Adaptive view sampling; Machine learning; Semantic information; Shape context matching; Sketch recognition; Sketch-based 3D model retrieval; Viewpoint entropy","Animation; Artificial intelligence; Benchmarking; Computational complexity; Computer games; Content based retrieval; Drawing (graphics); Entropy; Human computer interaction; Information retrieval; Learning systems; Self organizing maps; Semantics; 3D information; Hand-drawn sketches; Representative sample; Retrieval performance; Semantic information; Shape contexts; Sketch recognition; Sketch-based 3D Modeling; Three dimensional computer graphics",2-s2.0-85006484007
"Zampoglou M., Kapetanakis K., Stamoulias A., Malamos A.G., Panagiotakis S.","Adaptive streaming of complex Web 3D scenes based on the MPEG-DASH standard",2016,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006368847&doi=10.1007%2fs11042-016-4255-8&partnerID=40&md5=75e869b38f963371fd29d4c23ea13391","Modern Web 3D technologies allow us to display complex interactive 3D content, including models, textures, sounds and animations, using any HTML-enabled web browser. Thus, due to the device-independent nature of HTML5, the same content might have to be displayed on a wide range of different devices and environments. This means that the display of Web 3D content is faced with the same Quality of Experience (QoE) issues as other multimedia types, concerning bandwidth, computational capabilities of the end device, and content quality. In this paper, we present a framework for adaptive streaming of interactive Web 3D scenes to web clients using the MPEG-DASH standard. We offer an analysis of how the standard’s Media Presentation Description schema can be used to describe adaptive Web 3D scenes for streaming, and explore the types of metrics that can be used to maximize the user’s QoE. Then, we present a prototype client we have developed, and demonstrate how the 3D streaming process can take place over such a client. Finally, we discuss how the client framework can be used to design adaptive streaming policies that correspond to real-world scenarios. © 2016 Springer Science+Business Media New York","3D streaming; HTML5; MPEG-DASH; Quality of Experience; Web 3D; X3D","Display devices; HTML; Motion Picture Experts Group standards; Quality of service; Three dimensional computer graphics; 3D streaming; Adaptive streaming; Computational capability; Content qualities; HTML5; Mpeg dashes; Quality of experience (QoE); Real-world scenario; Media streaming",2-s2.0-85006368847
"Queiroz R.B., Braun A., Musse S.R.","An adaptive methodology for facial expression transfer",2016,"Brazilian Symposium on Games and Digital Entertainment, SBGAMES",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010333147&doi=10.1109%2fSBGames.2015.10&partnerID=40&md5=6c8aa77799e27026547b5ff55b6937be","This work presents a methodology which aims to improve and automate the process of generating facial animation for interactive applications. We propose an adaptive and semiautomatic methodology, which allows to transfer facial expressions from a face mesh to another. The model has three main stages: rigging, expression transfer and animation, where the output meshes can be used as key poses for blendshape-based animation. The input of the model is a face mesh in neutral pose and a set of face data that can be provided from different sources, such as artist crafted meshes and motion capture data. The model generates a set of blendshapes corresponding to the input set, with minimum user intervention. We opted to use a simple rig structure in order to provide a trivial correspondence either with sparse facial feature points based systems or dense geometric data supplied by RGBD based systems. The rig structure can be refined on-the-fly to deal with different input geometric data according to the need. The main contribution of this work is an adaptive methodology which aims to create facial animations with few user intervention and capable or transferring expression details according to the need and/or amount of input data. © 2016 IEEE.","Expression transfer; Facial animation; Facial rigging","Computer games; Computer graphics; Face recognition; Mesh generation; Adaptive methodologies; Expression transfers; Facial animation; Facial Expressions; Facial feature points; Facial rigging; Interactive applications; Motion capture data; Animation",2-s2.0-85010333147
"Feitosa V.R.M., Maia J.G.R., Moreira L.O., Gomes G.A.M.","GameVis: Game data visualization for the web",2016,"Brazilian Symposium on Games and Digital Entertainment, SBGAMES",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010390643&doi=10.1109%2fSBGames.2015.21&partnerID=40&md5=1d6f078a548270176a652796304e1611","Gaming and eSports have become increasingly popular and complex. For that reason, it is necessary that tournament hosts and game developers provide a great amount of meaningful information for their audiences. Data visualization tools and frameworks are of upmost importance since these provides means to accomplish this task. In this paper we propose GameVis, a framework designed to aid developers in building game data visualization components for the Web. GameVis allows multiple data formats to be translated into a single data structure that can be extended and customized in many ways, allowing visualizations to suit different screen sizes and platforms while showing a great amount of variation and meaning. Visualizations built within the framework may feature animations, annotations and might even adapt to different visual themes in order to provide a richer, more interactive user experience. This is shown through experimental results. © 2016 IEEE.","Game analytics; Tools; Visualization; Web","Animation; Computer games; Flow visualization; Tools; Visualization; Data visualization tools; E-sports; Game analytics; In-buildings; Multiple data; Screen sizes; User experience; Data visualization",2-s2.0-85010390643
"Álvarez-Rúa C., Borge J.","From Discrete to Continuous Process Simulation in Classical Thermodynamics: Irreversible Expansions of Ideal Monatomic Gases",2016,"Journal of Chemical Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006013112&doi=10.1021%2facs.jchemed.6b00226&partnerID=40&md5=e4cee40d9c577aa2225d7bdddaec05aa","Thermodynamic processes are complex phenomena that can be understood as a set of successive stages. When treating processes, classical thermodynamics (and most particularly, the Gibbsian formulation, predominantly used in chemistry) only pays attention to initial and final states. However, reintroducing the notion of process is absolutely necessary to get to know the final state from the initial state conditions. In general, complex concepts can be better understood through visualization. Nowadays, computer graphics can be used to simulate processes, from initial to final states, including interactivity and time progression. This technology report attempts to illustrate the benefits that the use of computer graphics may provide in learning classical thermodynamics. Our work shows how interactive graphic animations may be used to dynamically study thermodynamic processes. This report illustrates how key concepts in thermodynamic process, such as reversibility and irreversibility, can be easily introduced to students through visualization and interactivity. For this goal, we have tested a programming environment called Processing, widely used in the context of the visual arts to create images, animations, and interactions. The Processing software development environment has four major advantages: it is free of charge and open source, easy to use, multiplatform, and oriented to get immediate visual feedback while programming. © 2016 The American Chemical Society and Division of Chemical Education, Inc.","Computer-Based Learning; First-Year Undergraduate/General; Internet/Web-Based Learning; Physical Chemistry; Second-Year Undergraduate; Thermodynamics",,2-s2.0-85006013112
"Sanchez A., Teran A., Ibarra A., Abatta L., Alulema D., Morocho D., Encalada F.","Design and construction of an anthropomorphic robotic arm of seven degrees of freedom with kinematic and dynamic analysis based on genetic algorithms",2016,"2016 IEEE International Conference on Automatica, ICA-ACCA 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010297500&doi=10.1109%2fICA-ACCA.2016.7778502&partnerID=40&md5=64407891d698ebabbe64ee1c03601891","This article describes the design and construction of an anthropomorphic robotic arm capable of performing activities difficult or avoid collisions within your workspace, which is controlled by a computer program where the user indicates the target position and orientation to be achieved by the robot TCP. The software programmed in Matlab is developed, it calculates the angular displacements of the actuators using Genetic Algorithms (GA) considered as restricting the minimum and maximum angular displacement of each motor. The program has a graphical interface that displays a 3D robot animation, displays graphs of torque, velocity and acceleration at each joint also allows you to generate trajectories based on programmed points. The robot is connected to the computer using an USB connection and has an USB2Dynamixel device through which communication with computer controllers and servomotors Dynamixel is managed. © 2016 IEEE.","Anthropomorphic Robot; Degrees of Freedom; Dynamics; Genetic Algorithms; Kinematics","Computer software; Degrees of freedom (mechanics); Dynamics; Genetic algorithms; Kinematics; Machine design; MATLAB; Mechanics; Robotic arms; Robotics; Robots; Angular displacement; Design and construction; Graphical interface; Target position; Anthropomorphic robots",2-s2.0-85010297500
"Sokolov M., Lavrenov R., Gabdullin A., Afanasyev I., Magid E.","3D modelling and simulation of a crawler robot in ROS/Gazebo",2016,"ACM International Conference Proceeding Series",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016422674&doi=10.1145%2f3029610.3029641&partnerID=40&md5=c47d3c32304a1f325a4fc2cb5e942ba5","1. Modelling and animation of crawler UGV's caterpillars is a complicated task, which has not been completely resolved in ROS/Gazebo simulators. In this paper, we proposed an approximation of track-terrain interaction of a crawler UGV, perform modelling and simulation of Russian crawler robot ""Engineer"" within ROS/Gazebo and visualize its motion in ROS/RViz software. Finally, we test the proposed model in heterogeneous robot group navigation scenario within uncertain Gazebo environment. Copyright is held by the owner/author(s). Publication rights licensed to ACM.","Crawler robot; Gazebo; Modeling; Path planning; Rescue robots; ROS; Rviz","Computer software; Models; Motion planning; Robot programming; 3D modelling; Gazebo; Heterogeneous robots; Modelling and simulations; Rescue robot; Rviz; Robots",2-s2.0-85016422674
"Liang H., Chang J., Wang M., Chen C., Zhang J.J.","Semantic framework for interactive animation generation",2016,"Proceedings - VRCAI 2016: 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009769366&doi=10.1145%2f3013971.3013998&partnerID=40&md5=1017ea02019621889a46a85ceb0ecfa9","As a key technology, interactive animation has been widely used in Virtual Reality nowadays which is important for the success of various VR applications. However, despite many years history and the ability to produce stunning illusory and immersive effects for many VR applications, interactive animation generation remains one of the most labour-intensive ones. As a tedious task, its generation requires a complicated systematic procedure. Its inherent functional features involve a lot of complex technical problems: various aspects of requirements have to be handled, from the HCI technologies to the efficient management of animation data assets. With the continual evolvement of the complexity of current interactive VR technologies and animation practices, systematic and standardised description is imperative to provide a clear understanding of this production process. In this paper, a semantic framework is constructed at an abstract and semantic level using ontological methods for modelling the construction of interactive animation generation. To facilitate the process of interactive animation generation and improve its reusability and modularity, domain-specific ontologies based on the semantic framework are defined by formalising the multimodal interaction method and the construction of the animation data assets repository at the ontological implementation level. Finally, hand-gesture-based interactive animation is generated in the context of traditional Chinese shadow play, which involves novel functional features like hand-gesture-based interactive control and ontology-based intelligent animation assets management. © 2016 ACM.","Hand-gesture-based control; Interactive animation; Ontology; Semantic framework; Shadow play; Virtual Reality","Animation; Interactive computer graphics; Ontology; Reusability; Virtual reality; Domain-specific ontologies; Efficient managements; Hand gesture; Interactive animations; Interactive control; Multi-Modal Interactions; Semantic framework; Shadow play; Semantics",2-s2.0-85009769366
"Zhang J., Zhou M., Du G., Huang Y., Wu Z., Wang X.","A mesh-insensitive elastic model for simulation of solid bodies",2016,"Proceedings - VRCAI 2016: 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009783237&doi=10.1145%2f3013971.3013972&partnerID=40&md5=5d642f60fb3014c02fd615f647b829d1","FEM-based elasticity models are popular in solid body simulation. To avoid its problems of mesh sensitivity and overly stiff, a novel smoothed pseudo-linear elasticity model is presented. First, the smoothed finite element method is employed to alleviate mesh distortion and overly stiff problems instead of the traditional spatial adaptive smoothing method. Then, we propose a smoothing domain-based stiffness warping technique to compensate the nonlinear errors introduced by linear elasticity models. With this approach, transient displacements are slightly affected by mesh distortion and total volumes are preserved under large rotations. It also shows apparently softening effects in the experiments. Simulation results are generated without adding significant complexity or computational cost to the standard corotational FEM. © 2016 Copyright held by the owner/author(s).","Mesh insensitive; Physically-based animation; Pseudo-linear elasticity model; Smoothed finite element method; Stiffness warping","Elasticity; Interactive computer graphics; Mesh generation; Stiffness; Virtual reality; Mesh-insensitive; Physically-based animation; Pseudo linear; Smoothed finite element method; Stiffness warping; Finite element method",2-s2.0-85009783237
"Wang R., Li P., Sheng B., Sun H., Wu E.","Real-time video stylization using spatial-temporal gabor filtering",2016,"Proceedings - VRCAI 2016: 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009810472&doi=10.1145%2f3013971.3013986&partnerID=40&md5=e7a102a1ed0061711235483921a95555","This paper describes a new video stylization approach that achieves non-photorealistic rendering effects by using highly efficient spatial-temporal Gabor filtering. An edge extraction algorithm is developed to detect long coherent edges, to which the human visual system is sensitive. A nonlinear diffusion is then applied to remove unimportant details. Our approach extends the optical flow computation for constructing the Gabor flow to represent pixel similarity, and to preserve the temporal coherence when applied to video sequences. In particular, our video stylization is designed in a spatiotemporal manner to achieve temporal coherence in resulting animations. Real-time performance is achieved through the highly parallel implementation on modern graphics hardware (GPU). Therefore, our video stylization can be naturally applied to real-time video communication and interactive video-based rendering. The experimental results have demonstrated the high-quality production of our real-time video stylization. © 2016 ACM.","Feature space; Gabor flow; Spatial-temporal processing; Temporal coherence; Video stylization","Color image processing; Computer graphics; Gabor filters; Interactive computer graphics; Video signal processing; Virtual reality; Feature space; Gabor flow; Spatial-temporal processing; Temporal coherence; Video stylization; Rendering (computer graphics)",2-s2.0-85009810472
"Jiang F., Yang X., Feng L.","Real-time full-body motion reconstruction and recognition for off-the-shelf VR devices",2016,"Proceedings - VRCAI 2016: 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009775310&doi=10.1145%2f3013971.3013987&partnerID=40&md5=f9823e3119c911f3f13ebc988cc9a02a","Almost all VR multi-person applications have the requirement of reconstructing the whole-body motions in real-time in order to create deeper immersion. In fact, if we can ensure that the motion we reconstruct is natural, we can improve upon the comfort and number of wearing sensors at the cost of reconstruction precision because all users in VR are blindfolded. In this paper, we introduce a novel real-time motion reconstruction and recognition method in VR only using the positions and orientations of user's head and two hands. To reconstruct natural motions according to rare sensors, we divide the whole body into the upper body and the lower body. The upper body reconstruction algorithm based on inverse kinematics which is more accurate and the lower body based on animation blending which only needs a small number of prepared animations. Meanwhile, a natural action recognition algorithm based on neural network will run in need to detect the target motions we have trained. We show that our method can reconstruct various full-body motions, such as walking in any direction, jogging, jumping, crouching and turning. Our method has the ability to reconstruct natural human motions which can be used in almost all VR multiperson interactive applications. The configuration of sensors we attached on the head and hands is very popular in VR well-known devices, so the method can be easily integrated into off-the-shelf VR devices. © 2016 ACM.","Full-body motion reconstruction; Motion re-congnition; Real-time; VR","Blending; Interactive computer graphics; Inverse kinematics; Virtual reality; Action recognition algorithms; Full-body motions; Interactive applications; Motion re-congnition; Real time; Real-time motion; Recognition methods; Whole-body motion; Inverse problems",2-s2.0-85009775310
"Liang H., Sit J., Chang J., Zhang J.J.","Computer animation data management: Review of evolution phases and emerging issues",2016,"International Journal of Information Management",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982712537&doi=10.1016%2fj.ijinfomgt.2016.07.008&partnerID=40&md5=a95b80e7709d80980b7ee861d1f7a1ef","The computer animation industry has been booming and prospering in recent thirty years. One of the significant changes faced by this industry is the evolution of computer-animation data and, yet, extant literature has offered very little insights into the evolution process and management issues pertinent to computer- animation data. Hence, many questions have surfaced in the extant literature of computer- animation data management. For example, to what extent has the data content expanded in terms of quantity and quality? To what extent has the information technology used to store and process the data changed? To what extent have the user and the community groups diversified in terms of their nature and number? Knowledge pertaining to these issues can provide new research directions to academics and also insights to practitioners for more effective and innovative management of computer- animation data. This conceptual paper, therefore, takes the pioneering step to address these issues by proposing four factors prudent for examining the evolution phases associated with computer-animation data management: technology, content, users, and community. Next, this paper presents a conceptual framework illustrating the inter- dependent relationships between these four factors together with associated theoretical and managerial issues. This paper, albeit limited by its conceptual nature, advances the extant literature of computer animation, information system, and open-product model. © 2016 Elsevier Ltd","Computer animation; Data management; Emerging issues; Evolution; Framework; Open product model; Review","Information management; Reviews; Computer animation; Emerging issues; Evolution; Framework; Product modeling; Animation",2-s2.0-84982712537
"Braga P.H.C., Silveira I.F.","SLAP: Storyboard Language for Animation Programming",2016,"IEEE Latin America Transactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010214327&doi=10.1109%2fTLA.2016.7817016&partnerID=40&md5=8cd6129abfa02e4e4cc8d284402c7d55","A pre-production phase of a digital animation is mainly characterized by the documentation of films production details. This step is essential for understanding the films idea and also which specific technique will be used. This article proposes a new approach to the main pre-production documents: storyboards. A new visual language for semi-automated computer generation of animatics, named SLAP (Storyboard Language for Animation Programming), is presented, along with a proof of concept using a web-based tool designed for interpret its symbols. © 2003-2012 IEEE.","Animatic; Computer Vision; Digital Animation; Pattern Language; Semiautomated Animation; Storyboard; Visual Language","Animation; Automation; Computer programming; Computer vision; Animatic; Computer generation; New approaches; Pattern languages; Pre-production; Proof of concept; Storyboard; Web-based tools; Visual languages",2-s2.0-85010214327
"Sagar M., Seymour M., Henderson A.","Creating connection with autonomous facial animation",2016,"Communications of the ACM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005978064&doi=10.1145%2f2950041&partnerID=40&md5=4ac5da185fbd253bc1973e6a2f088775","Biologically based computational modeling promises virtual characters capable of face-to-face human interaction. © 2016 ACM.",,"Computer applications; Computer science; Computational model; Face to face; Facial animation; Human interactions; nocv1; Virtual character; Virtual reality",2-s2.0-85005978064
"Toshiyuki Y., Nakatani S., Adachi A., Kadota M., Ohkura K.","Adaptive role assignment for self-organized flocking of a real robotic swarm",2016,"Artificial Life and Robotics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992702657&doi=10.1007%2fs10015-016-0331-4&partnerID=40&md5=0dee257c40fd6e0cb38d32e2207081b2","Self-organized flocking of robotic swarms has been investigated for approximately 20 years. Most studies are based on a computer animation model named Boid. This model reproduces flocking motion by three simple behavioral rules: collision avoidance, velocity matching, and flock centering. However, flocking performance depends on how these rules are configured and no guideline for the configuration exists. This paper investigates real robot flocking where individuals can switch their roles depending on the situations. Robots can move as leaders or followers, and the roles are dynamically allocated using stochastic learning automata. The flocking performance is evaluated, and swarming behavior is analyzed in a scenario where robots consecutively travel between two landmarks. © 2016, ISAROB.","Boid; Flocking; Leader–follower; Swarm Robotics","Animation; Robotics; Stochastic systems; Behavioral rules; Boid; Computer animation; Flocking; Stochastic learning automata; Swarm robotics; Swarming behavior; Velocity-matching; Robots",2-s2.0-84992702657
"Lai Y.-C., Wang C.-W., Chen K.-Y., Todorov D., Yao C.-Y.","Extra detail addition based on existing texture for animated news production",2016,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944711241&doi=10.1007%2fs11042-015-2950-5&partnerID=40&md5=472ec4df3367c39530574b5d623f35e9","Animated news proposed by Next Media Animation becomes more and more popular because an animation is adapted to tell the story in a piece of news which may miss visual and audial circumstances. In order to fulfill the requirement of creating a 90-second animation within 2 h, artists must quickly set up required news elements by selecting existing 3D objects from their graphics asset database and adding distinguished details such as tattoos, scars, and textural patterns onto selected objects. Therefore, the detail addition process is necessary and must be easy to use, efficient, and robust without any modification to the production pipeline and without addition of extra rendering pass to the rendering pipeline. This work aims at stitching extra details onto existing textures with a cube-based interface using the well-designed texture coordinates. A texture cube of the detail texture is first created for artists to manipulate and adjust stitching properties. Then, the corresponding transformation between the original and detail textures is automatically computed to decompose the. detail texture into triangular patches for composition with the original texture. Finally, a complete detail-added object texture is created for shading. The designed algorithm has been integrated into the Next Media Animation pipeline to accelerate animation production and the results are satisfactory © 2015, Springer Science+Business Media New York.","Animation production; Detail stitching; Paramterization; Texture mapping","Computer graphics; Pipelines; Rendering (computer graphics); Animation pipeline; News productions; Paramterization; Production pipelines; Rendering pipelines; Texture coordinates; Texture mapping; Triangular patch; Animation",2-s2.0-84944711241
"So W.-C., Wong M.K.-Y., Cabibihan J.-J., Lam C.K.-Y., Chan R.Y.-Y., Qian H.-H.","Using robot animation to promote gestural skills in children with autism spectrum disorders",2016,"Journal of Computer Assisted Learning",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980350611&doi=10.1111%2fjcal.12159&partnerID=40&md5=be3f68234b8beef8a930fea7076de718","School-aged children with autism spectrum disorders (ASDs) have delayed gestural development, in comparison with age-matched typically developing children. In this study, an intervention program taught children with low-functioning ASD gestural comprehension and production using video modelling (VM) by a computer-generated robot animation. Six to 12-year-old children with ASD (N = 20; IQ < 70) were taught to recognize 20 gestures produced by the robot animation (phase I), to imitate these gestures (phase II) and to produce them in appropriate social contexts (phase III). Across the three phases, significant differences were found between the results of the pretest and the immediate and follow-up posttests; the results of both posttests were comparable, after controlling for the children's motor and visual memory skills. The children generalized their acquired gestural skills to a novel setting with a human researcher. These results suggest that VM by a robot animation is effective in teaching children with low-functioning ASD to recognize and produce gestures. Lay Description: What is already known about this topic: Children with autism spectrum disorders (ASDs) have difficulties with nonverbal communication. Children with ASD have difficulties in recognizing and producing gestures. What this paper adds: A multiphase therapeutic intervention program using video modelling (VM) of robot animation is effective to promoting the gestural communication skills, both recognition and production, in children with low-functioning ASD. Children with ASD have improved their skills to recognize the taught gestures (phase I), imitate them (phase II) and produce them in appropriate social contexts (phase III). Children with ASD are able to generalize the acquired skills to human-to-human interactions after the intervention program. Implications for practice and/or policy: VM of a robot animation is effective in teaching children with low-functioning ASD both gesture recognition and gesture production. The multiphase therapeutic intervention protocol can be recommended for clinicians or teachers in special schools to teach children with low-functioning ASD gestural communication skills. © 2016 John Wiley & Sons Ltd","animated robot; autism spectrum disorders; gesture; video modelling",,2-s2.0-84980350611
"Merabti B., Christie M., Bouatouch K.","A Virtual Director Using Hidden Markov Models",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947474699&doi=10.1111%2fcgf.12775&partnerID=40&md5=383fc8740df51a7645724d2a435c2ff9","Automatically computing a cinematographic consistent sequence of shots over a set of actions occurring in a 3D world is a complex task which requires not only the computation of appropriate shots (viewpoints) and appropriate transitions between shots (cuts), but the ability to encode and reproduce elements of cinematographic style. Models proposed in the literature, generally based on finite state machine or idiom-based representations, provide limited functionalities to build sequences of shots. These approaches are not designed in mind to easily learn elements of cinematographic style, nor do they allow to perform significant variations in style over the same sequence of actions. In this paper, we propose a model for automated cinematography that can compute significant variations in terms of cinematographic style, with the ability to control the duration of shots and the possibility to add specific constraints to the desired sequence. The model is parametrized in a way that facilitates the application of learning techniques. By using a Hidden Markov Model representation of the editing process, we demonstrate the possibility of easily reproducing elements of style extracted from real movies. Results comparing our model with state-of-the-art first-order Markovian representations illustrate these features, and robustness of the learning technique is demonstrated through cross-validation. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","animation; animation systems; Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation","Animation; Encoding (symbols); Learning algorithms; Learning systems; Logic circuits; Markov processes; Robustness (control systems); Signal encoding; Trellis codes; Animation systems; Consistent sequence; Cross validation; First order markovian; Learning techniques; Sequence of actions; State of the art; Virtual director; Hidden Markov models",2-s2.0-84947474699
"Beacco A., Pelechano N., Andújar C.","A Survey of Real-Time Crowd Rendering",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944400755&doi=10.1111%2fcgf.12774&partnerID=40&md5=8295c63ad577276dbf317eaea907165c","In this survey we review, classify and compare existing approaches for real-time crowd rendering. We first overview character animation techniques, as they are highly tied to crowd rendering performance, and then we analyze the state of the art in crowd rendering. We discuss different representations for level-of-detail (LoD) rendering of animated characters, including polygon-based, point-based, and image-based techniques, and review different criteria for runtime LoD selection. Besides LoD approaches, we review classic acceleration schemes, such as frustum culling and occlusion culling, and describe how they can be adapted to handle crowds of animated characters. We also discuss specific acceleration techniques for crowd rendering, such as primitive pseudo-instancing, palette skinning, and dynamic key-pose caching, which benefit from current graphics hardware. We also address other factors affecting performance and realism of crowds such as lighting, shadowing, clothing and variability. Finally we provide an exhaustive comparison of the most relevant approaches in the field. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","and texture; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Colour; image-based rendering; level of detail algorithms; real-time rendering; shading; shadowing","Animation; Computer graphics; Image reconstruction; Surveys; Three dimensional computer graphics; I.3.7 [computer graphics]: three-dimensional graphics and realism; Image based rendering; Level of detail; Real-time rendering; Shading; Shadowing; Rendering (computer graphics)",2-s2.0-84944400755
"Du H.-B., Zhao Y.-W., Han J.-D., Zhao X.-G., Wang Z., Song G.-L.","Data fusion of human skeleton joint tracking using two Kinect sensors and extended set membership filter",2016,"Zidonghua Xuebao/Acta Automatica Sinica",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009989219&doi=10.16383%2fj.aas.2016.c160109&partnerID=40&md5=0226950155a09fb722c9227d911b64de","Kinect-like depth sensors are widely used in rehabilitation systems. However, using a single depth sensor is less reliable due to limb blocking, data-loss or error. This paper uses two Kinect sensors and a data fusion algorithm to solve these problems. Firstly, two Kinect sensors are used to capture the motion data of the healthy side arm of the hemiplegic patient. Secondly, the data is processed with time alignment, then coordinates are transformed with Bursa transform and data fusion is done using extended set membership filter (ESMF) successively. Then, the motion data is mirrored by the middle plane, namely ""mirror motion"". In the end, the mirrored motion data controls the wearable robotic arm to drive the patient's paralytic side arm so as to interactively and initiatively complete a variety of recovery actions prompted by computer with 3D animation games. The effectiveness of the proposed approach is validated by both experiments on Kinect sensors & VICON and a 7 DOF manipulator. Also, two Kinect sensors can solve those problems effectively. Copyright © 2016 Acta Automatica Sinica. All rights reserved.","Bursa linear model; Extended set membership filter (ESMF); Kinect sensor; Mirror rehabilitation","Animation; Bandpass filters; Computer games; Data fusion; Medical computing; Mirrors; Patient rehabilitation; Data fusion algorithm; Hemiplegic patients; Human skeleton; Kinect sensors; Linear modeling; Recovery actions; Rehabilitation System; Set-membership filters; Digital storage",2-s2.0-85009989219
"Altin A., Aktaş M., Koru Yücekaya G.","The effect of the use of symmetry included in tessellation techniques with computer assisted and activities on eighth grade students’ achievement in transformation geometry teaching",2016,"Turkish Online Journal of Educational Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006972404&partnerID=40&md5=6aa94a2c5d5ecf87d82fa1f64b55aaa9","In this study, the effect of use of the symmetries included in tessellation techniques in other words reflection, translation, rotation and glide reflection with computer animations and activities on students’ achievement in the teaching of eighth grade transformation geometry learning domain has been researched. The achievement test for which expert opinion is obtained and thus whose reliability is determined is applied on students as the pretest. After that, symmetries included in tessellation techniques are shown with an animated PowerPoint slides made with the original figures and students are asked to do tessellations by given them grid papers. At the end of teaching process, students are asked to find the types of symmetry in their drawings. Later, the achievement test is applied on them as the posttest. Having entered into the SPSS, the data is analyzed through Wilcoxon Signed-Rank and Mann-Whitney U tests. In consequence, efficiency of the use of computer-assisted tessellation techniques and symmetries included in tessellation techniques on the increase of eighth grade students’ academic achievement has been seen. © The Turkish Online Journal of Educational Technology.",,,2-s2.0-85006972404
"Xu X., Liu S., Chuang T.-D., Huang Y.-W., Lei S.-M., Rapaka K., Pang C., Seregin V., Wang Y.-K., Karczewicz M.","Intra Block Copy in HEVC Screen Content Coding Extensions",2016,"IEEE Journal on Emerging and Selected Topics in Circuits and Systems",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983058659&doi=10.1109%2fJETCAS.2016.2597645&partnerID=40&md5=f2dd00391c89a472e2de1210dfd438c9","With the emerging applications such as online gaming and Wi-Fi display, screen content video, including computer generated text, graphics and animations, becomes more popular than ever. Traditional video coding technologies typically were developed based on models that fit into natural, camera-captured video. The distinct characteristics exhibited between these two types of contents necessitate the exploration of coding efficiency improvement given that new tools can be developed specially for screen content video. The HEVC Screen Content Coding Extensions (HEVC SCC) have been developed to incorporate such new coding tools in order to achieve better compression efficiency. In this paper, intra block copy (IBC, or intra picture block compensation), also named current picture referencing (CPR) in HEVC SCC, is introduced and discussed. This tool is very efficient for coding of screen content video in that repeated patterns in text and graphics rich content occur frequently within the same picture. Having a previously reconstructed block with equal or similar pattern as a predictor can effectively reduce the prediction error and therefore improve coding efficiency. Simulation results show that up to 50% BD rate reduction in all intra coding can be achieved with intra block copy enabled, compared to the HEVC reference encoder without this tool. Significant BD rate reductions for other coding configurations are also observed. © 2011 IEEE.","Current picture referencing; high efficiency video coding (HEVC); intra block copy; motion compensation; screen content coding","Efficiency; Image coding; Coding efficiency; Compression efficiency; Computer generated; Emerging applications; Prediction errors; Repeated patterns; Screen content videos; Video coding technology; Codes (symbols)",2-s2.0-84983058659
"Thienmongkol R., Trakulphat P.","Using Co-design theory to develop graphical simulation for enhanced learning in a museum display",2016,"Turkish Online Journal of Educational Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006967169&partnerID=40&md5=a44764288d9b4cf5e0037ea2f98604e0","This paper presents the key design processes in our practical based design project. It involves developing a new graphical simulation of Thai dinosaur called “Siamosaurus-Suteethorni”. Since 1976, this dinosaur gene was found as the first fossil in Thailand. Most people desire to see how the dinosaur looks like. This project was collaboration with the key informants to provide the empowerment data. It also includes the experts from four areas; 1) curator, 2) paleontologist, 3) geologist and 4) computer graphics (CG) artist. This collaboration was brought to develop a 3D hologram project for simulating features and movements of Siamosaurus-Suteethorni. Where, the hologram was installed in the National of Geological Museum. A co-design theory was employed as the key method to contribute a first of the CG protocol with Thai dinosaur in the museum. The process of data collection started from analysing a prehistoric document in Thai contexts. Then we went to the exploration of dinosaur fossil in order to collect the information needs. The collection also conducted in-depth interviews with the key informants to find out more details (i.e. anatomical structure, number of bones, scale, dimensional of movement, textural skin and footprints). The focus group was conducted with the key informants. A feedback were brought to define as a design criteria for producing such; a 3D polygon, shading, texture, bone rigging, scale, proportion, animation and motion capture in the design processes. However, after installation-team released the 3D hologram of Siamosaurus-Suteethorni in the museum. The result from assessment survey indicated that the satisfaction degree from a visitor stays at (X) 4.39 points from 5 points. In addition the sum assessment for learning scores from visitors stays at (X) 4.33 points from 5 points. © The Turkish Online Journal of Educational Technology.","3D modeling; Computer graphic; Digital museum; Dinosaur; Hologram",,2-s2.0-85006967169
"Jang S.-W., Jung M.","Robust detection of mosaic regions in visual image data",2016,"Cluster Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996526086&doi=10.1007%2fs10586-016-0621-6&partnerID=40&md5=64d99616c8cd597e4bbc824c0d0611ea","Due to the explosive increase in the production and sharing of digital visual media such as photos, animations, films and video clips, the need to intentionally or unintentionally create mosaic blocks to effectively cover user-designated regions within images has grown. In this paper, a method using boundary characteristics to effectively detect the grid-type mosaic blocks existing within the input image is proposed. Initially, the Canny edge is detected from the input image. Then, the boundary characteristics of mosaic blocks are extracted from the detected edges, and the candidate regions which may contain mosaic blocks are detected. After this stage, geometric characteristics are used to eliminate non-mosaic blocks and select actual mosaic blocks. In the experiment performed in this paper, it was observed that the method using boundary characteristics achieved more robust detection of the grid-type mosaic blocks from various input images than other existing methods. The mosaic-detection method proposed in this paper is expected to be valuable for applications in various fields. © 2016, Springer Science+Business Media New York.","Average filter; Compactness; Geometric feature; Image data; Mosaic regions","Software engineering; Average filter; Compactness; Geometric feature; Image data; Mosaic regions; Computer networks",2-s2.0-84996526086
"Feng Z.-Q., Xu T., Lü N., Tang H.-K., Jiang Y., Liang L.-W.","Hand gesture tracking algorithm based on visual attention",2016,"Journal of Beijing Institute of Technology (English Edition)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009965092&doi=10.15918%2fj.jbit1004-0579.201625.0407&partnerID=40&md5=b14e1aed3174e34fc57a45a4fca7a9f1","In the majority of the interaction process, the operator often focuses on the tracked 3D hand gesture model at the “interaction points” in the collision detectionscene, such as “grasp” and “release” and objects in the scene, without paying attention to the tracked 3D hand gesture model in the total procedure. Thus in this paper, a visual attention distribution model of operator in the “grasp”, “translation”, “release” and other basic operation procedures is first studied and a 3D hand gesture tracking algorithm based on this distribution model is proposed. Utilizing the algorithm, in the period with a low degree of visual attention, a pre-stored 3D hand gesture animation can be used to directly visualise a 3D hand gesture model in the interactive scene; in the time period with a high degree of visual attention, an existing “frame-by-frame tracking” approach can be adopted to obtain a 3D gesture model. The results demonstrate that the proposed method can achieve real-time tracking of 3D hand gestures with an effective improvement on the efficiency, fluency, and availability of 3D hand gesture interaction. © 2016 Beijing Institute of Technology.","3D hand gesture tracking; Hand gesture interaction; Visual attention","Behavioral research; Palmprint recognition; Three dimensional computer graphics; Tracking (position); Basic operation; Distribution models; Hand gesture; Hand gesture tracking; Interaction points; Interaction process; Real time tracking; Visual Attention; Gesture recognition",2-s2.0-85009965092
"Wang N., Gao X., Tao D., Yang H., Li X.","Facial feature point detection: A comprehensive survey",2016,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020477378&doi=10.1016%2fj.neucom.2017.05.013&partnerID=40&md5=b097b72fd7ec44e8ec6b2efc16411f04","This paper presents a comprehensive survey of facial feature point detection with the assistance of abundant manually labeled images. Facial feature point detection favors many applications such as face recognition, animation, tracking, hallucination, expression analysis and 3D face modeling. Existing methods are categorized into two primary categories according to whether there is the need of a parametric shape model: parametric shape model-based methods and nonparametric shape model-based methods. Parametric shape model-based methods are further divided into two secondary classes according to their appearance models: local part model-based methods (e.g. constrained local model) and holistic model-based methods (e.g. active appearance model). Nonparametric shape model-based methods are divided into several groups according to their model construction process: exemplar-based methods, graphical model-based methods, cascaded regression-based methods, and deep learning based methods. Though significant progress has been made, facial feature point detection is still limited in its success by wild and real-world conditions: large variations across poses, expressions, illuminations, and occlusions. A comparative illustration and analysis of representative methods provides us a holistic understanding and deep insight into facial feature point detection, which also motivates us to further explore more promising future schemes. © 2017 Elsevier B.V.","Deep learning; Face alignment; Facial feature point detection; Facial landmark localization","Deep learning; Feature extraction; Surveys; Three dimensional computer graphics; Active appearance models; Constrained local models; Exemplar based methods; Expression analysis; Face alignment; Facial feature point detection; Facial landmark; Learning-based methods; Face recognition",2-s2.0-85020477378
"Sumangali K., Kalsi H.","A comprehensive review on multimedia database and their applications",2016,"International Journal of Pharmacy and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018203250&partnerID=40&md5=d41fdb3b5ff64ef8b67aa59448391e96","Everyone deals with multimedia at every walk of lives. We work with multimedia and are surrounded by multimedia. Due to the advancement of modern computer and information technology, multimedia systems play more and more impact on our lives. Therefore, it is more challenging fact how to organize and structure these huge multimedia information so that we can get information easily at any point of time. To do so, multimedia database is a tool required to manage and maintain huge multimedia objects. Multimedia objects consist of texts, graphics, animations, video, sounds, music etc. Multimedia applications often address file management interfaces at different levels of abstraction such as hypertext application, audio editor, audio-video distribution service depending on the real strength of multimedia database and its structure. The main objective of this paper isto provide a brief review on multimedia database and their applications. © 2016, International Journal of Pharmacy and Technology. All rights reserved.","Data retrieval; Modeling; Multimedia database; Query language","Article; controlled study; data base; image analysis; imaging system; information retrieval; information technology; multimedia; multimedia data base; online system; semantics; software",2-s2.0-85018203250
"Manera V., von der Lühe T., Schilbach L., Verfaillie K., Becchio C.","Communicative interactions in point-light displays: Choosing among multiple response alternatives",2016,"Behavior Research Methods",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944929512&doi=10.3758%2fs13428-015-0669-x&partnerID=40&md5=f70ed585b141cf73cda7735c1f7bf32d","Vision scientists are increasingly relying on the point-light technique as a way to investigate the perception of human motion. Unfortunately, the lack of standardized stimulus sets has so far limited the use of this technique for studying social interaction. Here, we describe a new tool to study the interaction between two agents starting from point-light displays: the Communicative Interaction Database - 5AFC format (CID-5). The CID-5 consists of 14 communicative and seven non-communicative individual actions performed by two agents. Stimuli were constructed by combining motion capture techniques and 3-D animation software to provide precise control over the computer-generated actions. For each action stimulus, we provide coordinate files and movie files depicting the action as seen from four different perspectives. Furthermore, the archive contains a text file with a list of five alternative action descriptions to construct forced-choice paradigms. In order to validate the CID-5 format, we provide normative data collected to assess action identification within a 5AFC tasks. The CID-5 archive is freely downloadable from http://bsb-lab.org/research/ and from the supplementary materials of this article. © 2015, The Author(s).","5AFC; Biological motion; Communicative interaction; Database; Point-light","adult; decision making; factual database; female; human; human relation; interpersonal communication; light; male; middle aged; movement perception; photostimulation; procedures; software; standards; vision test; young adult; Adult; Choice Behavior; Communication; Databases, Factual; Female; Humans; Interpersonal Relations; Light; Male; Middle Aged; Motion Perception; Photic Stimulation; Software; Vision Tests; Young Adult",2-s2.0-84944929512
"Taradolrattanakorn N., Tanamai S.","The study of training needs in educational innovation and information technology for teachers in the office of the basic education commission",2016,"Turkish Online Journal of Educational Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007002539&partnerID=40&md5=2e373dc9ad3d1d470c9c1e2185ee3776","This study aimed to investigate the training needs in educational innovation and information technology for teachers in the Office of the Basic Education Commission. The sample included 395 teachers under the Office of the Basic Education Commission selected by simple random sampling. The research instrument was an online questionnaire. Percentage, average and standard deviation were applied to analyze data. The results could be described as follows. 1) A majority of the questionnaire respondents was female aged between 36 - 50 years old. They possessed master degrees and taught in secondary schools (grade 7 - grade 12) and primary schools (grade 1 to grade 6). The teacher needs of innovation and information technology in education training under the Office of the Basic Education Commission involved instructional media design and production in 5 aspects as follows. 1) Graphic design and animation production included Adobe Photoshop for photo revision and media production, development of mobile games without program writing; 2) computer and internet design and production included development of computer skills to meet ICDL standard, construction of new instructional media on Mobile Learning through iTunes U; 3) electronic media design and production included innovative information technology for teaching instruction, construction of instructional media from Google Apps for Education; 4) web design and production and database included construction of online lessons by LMS Moodle, Edmodo and development of online lessons by Social Media through E-learning, Line, Facebook, YouTube, Email and Blog and; 5) Video design and production included video instructional media and construction of video presentation by Adobe After Effect. © The Turkish Online Journal of Educational Technology.",,,2-s2.0-85007002539
"Tharatipyakul A., Lee H., Zhao S., Davis R.C.","Supporting the comparison of alternative stories",2016,"Proceedings of the 28th Australian Computer-Human Interaction Conference, OzCHI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012013286&doi=10.1145%2f3010915.3010963&partnerID=40&md5=63b3e31d4e9d24b552ab6f5ec0042a0f","In media production, a team typically works with multiple alternative storylines or variations before selecting the best one for production. However, current media production tools do not support decision making through the comparison of alternative storylines. Using the conventional form of storyboards found in animation, commercial, and movie studios as a basis, we propose a novel user interaction feature that facilitates effective comparison amongst alternative storylines or variations. We review existing storyboarding practices, and then present our interaction strategy, which was informed by interviews of people in the industry. The fully-implemented system went through a series of usability tests with both professional and non-professional users. We discuss how our design can help the users with diverse backgrounds at different stages of story development in comparing the alternatives. Such a tool may be useful in other domain areas where temporal comparison of alternative solutions is beneficial. Copyright © 2016 ACM.","Interaction design; Story comparison; Storyboard","Behavioral research; Decision making; Interactive computer systems; Alternative solutions; Different stages; Interaction design; Interaction strategy; Media production; Non-professional users; Story comparison; Storyboard; Human computer interaction",2-s2.0-85012013286
"Messmer S., Fleischmann S., Sorkine-Hornung O.","Animato: 2D shape deformation and animation on mobile devices",2016,"SA 2016 - SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006955538&doi=10.1145%2f2999508.2999528&partnerID=40&md5=104fa3d7fbd10a1b295e036c39d8093a","We present Animato, an interactive app for the animation of 2D shapes using an intuitive multi-touch interface and a novel collaborative multi-user mode. We describe our implementation of a state-of-the-art nonlinear shape deformation method on iOS devices, overcoming their hardware limitations. Informal testing with users shows that even novices have an easily accessible entry point to computer animation and are quickly able to record animation performances using our app thanks to the direct and intuitive multitouch interface and the fast shape deformation algorithm.","Collaborative interfaces; Computer animation; Mobile devices; Multi-touch; Shape deformation; Skinning","Deformation; Interactive computer graphics; Interactive devices; Mobile devices; Collaborative interfaces; Computer animation; Multi-touch; Shape deformation; Skinning; Animation",2-s2.0-85006955538
"Sato S., Dobashi Y., Nishita T.","A combining method of fluid animations by interpolating flow fields",2016,"SA 2016 - SIGGRAPH ASIA 2016 Technical Briefs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263748&doi=10.1145%2f3005358.3005382&partnerID=40&md5=13376bfd67d5c3c8900810f810dad4b9","The computational cost for creating realistic fluid animations by simulation is generally very expensive. In digital production environment, existing precomputed fluid animations are often reused for different scenes in order to reduce the cost for creating scenes containing fluids. However, applying same animations to different scenes produces unacceptable results, so the animation needs to be edited. In order to do this, we develop a method for synthesizing desired flow fields by combining existing flow fields. Our system allows the user to place existing flow fields at arbitrary positions, and combine them by interpolating the regions between these flow fields, to synthesize a new flow field. The interpolation of the flow fields is realized by solving a minimization problem. Our minimization problem consists of two energy functions for smoothly interpolating the velocities and satisfying the incompressibility. Our method can create the desired incompressible flow fields by reusing existing flow fields. © 2016 ACM.","Fluid simulation; In-compressibility; Interpolating velocity fields; Reusing existing fluid animations","Incompressible flow; Interactive computer graphics; Interpolation; Velocity; Arbitrary positions; Combining method; Computational costs; Digital production; Fluid animation; Fluid simulations; Minimization problems; Velocity field; Flow fields",2-s2.0-85008263748
"Michigami T.","Interactive virtual reality animation STRAY SHEEP",2016,"SA 2016 - SIGGRAPH ASIA 2016 VR Showcase",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006982093&doi=10.1145%2f2996376.2996384&partnerID=40&md5=e944867b043d8f3d7beae65d67fc9a61","""STRAY SHEEP"" is a virtual reality character animation, which uses Oculus. This narrative film follows a quirky and curious lost sheep. The viewer will explore various imaginative environments made from common items of a child's daily life by following the sheep along its journey. The project ""STRAY SHEEP"" explores and illustrates, how narrative content and user interaction can coexist in VR.",,"Interactive computer graphics; User interfaces; Virtual reality; Character animation; Daily lives; Interactive virtual reality; User interaction; Animation",2-s2.0-85006982093
"Anasingaraju S., Wu M.-L., Adamo-Villani N., Popescu V., Cook S.W., Nathan M., Alibali M.","Digital learning activities delivered by eloquent instructor avatars: Scaling with problem instance",2016,"SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006839790&doi=10.1145%2f2993352.2993355&partnerID=40&md5=243e3df33a762fbe31f1a0da25375625","We present an approach for achieving scalable authoring of digital learning activities, without sacrificing delivery eloquence. A computer animation character serves as an instructor avatar that not only speaks but also makes deictic, iconic and charisma gestures. The avatar is controlled via a text script, without the prerequisites of computer programming or animation expertise. Given a script for a problem, the system automatically generates scripts for additional instances of the problem, by adapting the targets of the deictic gestures, the speech, and the synchronization between speech and gestures. Starting from initial learning activities of a few min- utes, the system can automatically generate hours of quality on-line learning activities. An evaluation by computer graphics, computer animation, and education research experts reveals that the automatically generated learning activities have animation quality that is comparable to that of the original activities. © 2016 ACM.","Digital learning activity authoring; Instructor avatar; Instructor gesture; Scalability","Animation; Computer graphics; Computer programming; Interactive computer graphics; Quality control; Scalability; Automatically generated; Computer animation; Digital-learning; Education research; Instructor avatar; Instructor gesture; Learning Activity; Problem instances; E-learning",2-s2.0-85006839790
"Guidazzoli A., Liguori M.C., Imboden S., De Luca D., Bellavia G., Verri L.","Ati the Etruscan: A transmedia CG character for educational storytelling",2016,"SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006873347&doi=10.1145%2f2993352.2993353&partnerID=40&md5=2ae236d14e63ee845866fa8b4777daf0","Ati the Etruscan is a 3D character developed in Blender at VisitLab Cineca. It can be considered as a versatile mascot of the Etruscan civilization, part of the recent efforts sustained in Italy by different cultural institutions to promote knowledge about the Etruscans. It can also be seen as an example of a methodology in educational video making, based on open source, multiple re-use and sharing of 3D assets opened towards new cross-media applications.","3D modeling; Computer animation; Digital cultural heritage; Edutainment","Animation; Blending; Education; Interactive computer graphics; 3-d modeling; 3D characters; Computer animation; Cultural institutions; Digital cultural heritages; Educational videos; Edutainment; Open sources; Three dimensional computer graphics",2-s2.0-85006873347
"Savoye Y.","Cage-based performance capture",2016,"SA 2016 - SIGGRAPH ASIA 2016 Courses",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007271068&doi=10.1145%2f2988458.2988459&partnerID=40&md5=4495d83cb130ed4dbe5eeafbf35f4748","Nowadays, highly-detailed animations of live-like performances are easier to acquire thanks to low-cost sensors. Also, 4D meshes have reached considerable attentions in visual media productions. This course will address new paradigm to achieve performance capture using cage-based shapes in motion. We define cage-based performance capture as the non-invasive process of capturing non-rigid surface of actors from multi-view in the form of sparse control deformation handles trajectories and a laser-scanned template shape. In this course, we address the hard problem of extracting or acquiring and then reusing non-rigid parametrization for video-based animations in four steps: (1) cage-based inverse kinematics, (2) conversion of surface performance capture into cage-based deformation, (3) cage-based cartoon surface exaggeration, and (4) cage-based registration of time-varying reconstructed point clouds. The key objective is to attract the interest of game programmers, digital artists, and filmmakers in employing purely geometric animator-friendly tools to capture and reuse surfaces in motion. Finally, a broad range of advanced animation techniques and promising research-to-production opportunities for the years to come, in-between Graphics, and Vision fields will be presented. At first sight, a central challenge is to express plausible boneless deformations while preserving global and local properties of dynamic captured surfaces with a limited number of controllable, flexible and reusable parameters. While abandoning the classical articulated skeleton as the underlying structure, we show that cage-based deformers offer a flexible design space abstraction to dynamically non-rigid surface motion through learning space-time shape variability. Registered cage-handles trajectories allow the reconstruction of complex mesh sequences by deforming an enclosed template mesh. Decoupling motion from geometry, cage-based performance capture techniques offer reusable outputs for animation transfer. © 2016 Copyright held by the owner/author(s).",,"Deformation; Interactive computer graphics; Inverse kinematics; Inverse problems; Mesh generation; Motion pictures; Animation techniques; Based animations; Decoupling motions; Low-cost sensors; Parametrizations; Performance capture; Shape variabilities; Surface performance; Animation",2-s2.0-85007271068
"Kenwright B.","Holistic game development curriculum",2016,"SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006925028&doi=10.1145%2f2993352.2993354&partnerID=40&md5=a74a7da0ab5f4e9dec13fc762d3e3e6c","This article discusses the design and implementation of a holistic game development curriculum. We focus on a technical degree centred around game engineering/technologies with transferable skills, problem solving, mathematics, software engineering, scalability, and industry practices. In view of the fact that there is a growing skills shortage for technically minded game engineers, we must also be aware of the rapidly changing advancements in hardware, technologies, and industry. Firstly, we want a synergistic game orientated curriculum (for a 4-year Bachelor's programme). Secondly, the organisation and teaching needs to adapt to future trends, while avoiding tunnel vision (too game orientated) and support both research and industry needs. Finally, we build upon collaborations with independent experts to support an educational programme with a diverse range of skills. The curriculum discussed in this article, connects with a wide variety of subjects (while strengthening and supporting one another), such as, programming, mathematics, computer graphics, physics-based animation, parallel systems, and artificial intelligence. All things considered, the development and incorporation of procedures into a curriculum framework to keep up with advancements in game technologies is important and valuable. Collaborative learning Computing education programs Contextual software domains Virtual worlds software. © 2016 Copyright held by the owner/author(s). SA '16 Symposium on Education, December 05-08, 2016, Macao.","Curriculum; Degree; Education; Game development; Holistic; Learning; Teaching; Technologies","Animation; Computer graphics; Computer programming; Computer systems programming; Education; Industrial research; Interactive computer graphics; Problem solving; Software design; Software engineering; Teaching; Technology; Virtual reality; Collaborative learning; Degree; Design and implementations; Game development; Holistic; Learning; Physics-based animation; Transferable skills; Curricula",2-s2.0-85006925028
"Ma W.-C., Lamarre M., Danvoye E., Ma C., Von Der Pahlen M.K.J., Wilson C.A.","Semantically-aware blendshape rigs from facial performance measurements",2016,"SA 2016 - SIGGRAPH ASIA 2016 Technical Briefs",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263850&doi=10.1145%2f3005358.3005378&partnerID=40&md5=ccc0909b7b2803c50e192af2a23fc371","We present a framework for automatically generating personalized blendshapes from actor performance measurements, while preserving the semantics of a template facial animation rig. Firstly, we capture various poses from the subject with our photogrammetry apparatus. The 3D reconstruction from each pose is then corresponded by an image-based tracking algorithm. The core of our framework is an optimization algorithm which iteratively refines the initial estimation of the blendshapes such that they can fit the performance measurements better. This framework facilitates creation of an ensemble of realistic digital-double face rigs for each individual with consistent behavior across the character set. © 2016 ACM.","Blendshapes; Blind signal separation; Facial animation; Performance capture; Retargeting","Animation; Blind source separation; Character sets; Image reconstruction; Interactive computer graphics; Iterative methods; Semantics; Blendshapes; Blind Signal Separation; Facial animation; Performance capture; Retargeting; Optimization",2-s2.0-85008263850
"Wang C., Shao Q.","Engaging Students in Learning Science and Technology Using Students-Generated Educational Videos",2016,"Proceedings - IEEE 16th International Conference on Advanced Learning Technologies, ICALT 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006893257&doi=10.1109%2fICALT.2016.52&partnerID=40&md5=6a28bdafb2670ab6f93e2c4873c62b76","The rapidly increasing use of digital media technologies offers students opportunities to represent science content in different ways. In this paper, we introduce an interdisciplinary and collaborative research project that engages students in learning both science and technology by developing educational videos for science explanation. In this project, students from the Digital Media course are paired with students from the Introductory Physics I course. They work together to create videos with blended digital media, such as images, animations, audio, and videos, to explain physics concepts and phenomena. The strategies for successfully conducting such an interdisciplinary project are discussed in the paper. The assessment results demonstrate the effectiveness of this project in student learning regarding understanding physics concepts, understanding the importance of digital media, and using digital media technologies. Results also show that this interdisciplinary project enhances students' communication skills and help them to learn skills and knowledge in the other STEM field by working together. © 2016 IEEE.","Animations; Digital media; Digital videos; Interdisciplinary learning; IT education; Physics education; STEM education","Animation; Computer graphics; Curricula; Digital storage; Education; Engineering education; Multimedia systems; Digital videos; Interdisciplinary learning; IT education; Physics education; STEM education; Students",2-s2.0-85006893257
"Yu J., Park J.","Real-time facial tracking in virtual reality",2016,"SA 2016 - SIGGRAPH ASIA 2016 VR Showcase",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006968903&doi=10.1145%2f2996376.2996390&partnerID=40&md5=162a2b3d033461b479bad62831e3db98","Virtual reality (VR) emerges as the next social computing platform. For realizing immersive social interactions, projecting facial expressions onto the virtual avatar a crucial component. This is a challenge in VR as it requires capturing the facial motions behind the VR head mounted displays (HMDs). In this paper, we present a real-time facial expression tracking system in VR HMDs. The core of the system is a 3D camera attached to the HMDs, capturing motions on the lower half of the face, which enables users to track and retarget their facial animations in realtime onto CG avatars. The system is capable of capturing 20 facial expression parameters and transfer it onto the 3D character in real-time. © 2016. ACM.","Facial capture; Virtual reality","Cameras; Helmet mounted displays; Interactive computer graphics; Three dimensional computer graphics; Virtual reality; Facial animation; Facial capture; Facial expression parameters; Facial Expressions; Head mounted displays; Social computing; Social interactions; Tracking system; Face recognition",2-s2.0-85006968903
"Miyashita L., Ishihara K., Watanabe Y., Ishikawa M.","Zoe Matrope for realistic and augmented materials",2016,"SA 2016 - SIGGRAPH ASIA 2016 Virtual Reality Meets Physical Reality: Modelling and Simulating Virtual Humans and Environments",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006915722&doi=10.1145%2f2992138.2992141&partnerID=40&md5=42d609d76d730336865537eaefbd581c","Reality is the most realistic representation. We introduce a material display called ZoeMatrope that can reproduce a variety of mate-rials with high resolution, high dynamic range, and high light field fidelity by using real objects and characteristics of the human vision system. ZoeMatrope can also create augmented materials such as a mixture of wood and clear glass, a material with an alpha channel, and a material that looks red when illuminated with a light source A but blue when illuminated with a light source B. In this paper, we give an outline of the ZoeMatrope system and show the results for various materials. © 2016 Copyright held by the owner/author(s). SA '16, December 05-08 2016.","Augmented material; Material animation; Material composition; Thaumatrope; Zoetrope","Computer vision; Field emission displays; Interactive computer graphics; Light sources; Alpha channel; High dynamic range; High resolution; Human vision systems; Material compositions; Real objects; Thaumatrope; Zoetrope; Virtual reality",2-s2.0-85006915722
"Wang Y., Chen Z., Chen Z., Li Q., Luo Q., Qu H.","Animated narrative visualization for video clickstream data",2016,"SA 2016 - SIGGRAPH ASIA 2016 Symposium on Visualization",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006893230&doi=10.1145%2f3002151.3002155&partnerID=40&md5=547fa7838967b6bc0201a8905e6d73b0","Video clickstream data are important for understanding user behaviors and improving online video services. Various visual analytics techniques have been proposed to explore patterns in these data. However, those techniques are mainly developed for analysis and do not sufficiently support presentations. It is still difficult for data analysts to convey their findings to an audience without prior knowledge. In this paper, we propose to use animated narrative visualization to present video clickstream data. Compared with traditional methods which directly turn click events into animations, our animated narrative visualization focuses on conveying the patterns in the data to a general audience and adopts two novel designs, non-linear time mapping and foreshadowing, to make the presentation more engaging and interesting. Our non-linear time mapping method keeps the interesting parts as the focus of the animation while compressing the uninteresting parts as the context. The foreshadowing techniques can engage the audience and alert them to the events in the animation. Our user study indicates the effectiveness of our system and provides guidelines for the design of similar systems. © 2016 ACM.","Animated visualization; Clickstream data; Data storytelling; Narrative visualization","Animation; Behavioral research; Interactive computer graphics; Mapping; Visualization; Clickstream data; Data analysts; Data storytelling; Mapping method; Novel design; Prior knowledge; User behaviors; Visual analytics; Data visualization",2-s2.0-85006893230
"Anthony R., De Belen J., Atienzay R.O.","Automatic skeleton generation using hierarchical mesh segmentation",2016,"SA 2016 - SIGGRAPH ASIA 2016 Virtual Reality Meets Physical Reality: Modelling and Simulating Virtual Humans and Environments",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006954184&doi=10.1145%2f2992138.2992150&partnerID=40&md5=6e753a58c2d1f1ad1c3cdeaa73c5c726","High fidelity and interactive 3D characters abound in virtual and augmented reality. However, making one usually requires manual skeleton extraction and specification on how the body reacts with the translation and rotation of the bones. While there are previous works that already solve this problem, most systems have limitations with the input or the output cannot be directly used for animation. With the goal of bringing any humanoid toys to life, a pipeline is presented to automatically generate the toy's skeletal structure and skinning weights. First, the mesh is segmented into several parts using normal characteristic value (NCV) and global point signatures (GPS) as candidate points for segmentation. Then, joint locations are generated based on the segmentation results. Furthermore, the skinning weights are generated by solving the Laplace diffusion equation. Experimental results show that our pipeline is robust enough to extract skeletal structures from graphic artists' models as well as from scanned models. In addition, our pipeline is deformation-invariant as it can generate the same skeletal structure of a model having different poses. Finally, our pipeline achieves both appealing virtual realism and fast speed. The output can be directly used to setup skeleton-based animations in games as well as real-time virtual and augmented reality applications within minutes. © 2016 ACM. VR Meets PR 2016, December 05-08, 2016.","Character skinning; Geometric processing; Rigging; Segmentation; Skeleton extraction; Virtual and augmented reality","Animation; Augmented reality; Extraction; Image segmentation; Interactive computer graphics; Mesh generation; Musculoskeletal system; Pipelines; Character skinning; Geometric processing; Rigging; Skeleton extraction; Virtual and augmented reality; Virtual reality",2-s2.0-85006954184
"Caldwell C.","Story structure for programmers, designers, animators, and artists",2016,"SA 2016 - SIGGRAPH ASIA 2016 Courses",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007174692&doi=10.1145%2f2988458.2988472&partnerID=40&md5=a570ec346b7c5b692d39e1c9a203636b","This course has been designed for technical directors, artists, animators, modelers, programmers, and designers whose work is essential in making ""the story"" come to life. This information can be particularly useful when communicating with screenwriters, directors, producers, and supervisors. This course answers the question ""what is story?"" Entertaining with numerous clips to show how this has been used in animation, games, and VFX. The purpose is to take the mystery out of ""what is story"" for those programmers, artists, and game designers whose work is essential in making Animation, VFX, and Games successful. The attendees will know the basic elements of story, so the next time a producer or director talk about what they want for the story, they will know what specific story benchmarks the producer/director are trying to meet in connecting emotionally with an audience. This course will build from the knowledge that story ""is a sequence of events (acts) that builds to a climax⋯."" and then lays out the universal elements of story that make up plot, character development, and narrative structure. This course emphasizes story elements in context (i.e. theme, character, setting, conflict etc.) and their relationship to classic story structure (i.e. setup, inciting incident, rising action, climax, resolution etc.). It analyzes conflict (i.e. internal, external, environmental), turning points, cause & effect, archetype vs stereotypes, inciting incident, and how choice defines character. In all stories there must be questions raised: What is at stake (i.e. survival, safety, love, esteem, etc.)? What is going to motivate (inciting incident) the main character (protagonist)? Will that be enough to move them from the ordinary (where they are comfortable) to go out into a different world (where the action takes place)?, and How will the character ""change"" (necessary for all dramatic stories)? These are just a few of the storytelling elements necessary to structure a solid story. This course is for all whose work makes the story better but their job isn't creating the story.",,"Curricula; Interactive computer graphics; Basic elements; Game designers; In contexts; Narrative structures; Sequence of events; Turning points; Animation",2-s2.0-85007174692
"Garcia J., Drakeley S., Palmer S., Ramos E., Hutchins D., Habel R., Stomakhin A.","Rigging the oceans of disney's ""Moana""",2016,"SA 2016 - SIGGRAPH ASIA 2016 Technical Briefs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008255182&doi=10.1145%2f3005358.3005379&partnerID=40&md5=90f59d7e5e6508eb7456be335fe29498","Disney's ""Moana"" was set in an environment inspired by the Pacific Islands, which made the ocean a prominent setting throughout the film. For much of the film, we found it necessary to treat our oceans like we would our hero characters, and so we developed three ocean rigs that formed the basis of all our ocean variants. Using a unified workflow that our artists were already familiar with, these rigs gave them the ability to easily portray and dial in a wide variety of ocean types such as open seas, calm seas, stormy seas, lagoons, shorelines, and wide ocean vistas, some which spanned hundreds of kilometers out to the horizon. This paper describes the techniques we used and some of the challenges we faced in developing these ocean rigs.","Animation; Maya; Oceans; Rigging","Animation; Interactive computer graphics; Dial-in; Maya; Oceans; Pacific islands; Rigging; Oceanography",2-s2.0-85008255182
"Yamamoto M., Suzuki R.","Does action have to relate to speech?",2016,"SA 2016 - SIGGRAPH ASIA 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006922919&doi=10.1145%2f3005274.3005321&partnerID=40&md5=b913a43529930cac3f6fdbed45c2a4b7","When an action does not relate to the speech, the speech may con- nect any action unrelated to the speech. In such case, a speech an- imation can be easily produced by choosing a suitable action from the data base containing actions captured beforehand. © 2016 Copyright held by the owner/author(s).","Action; Animation; Speech","Animation; Interactive computer graphics; Action; Imation; Speech",2-s2.0-85006922919
"Piper J., Bennett G., Kruse J.","Developing new pedagogical models for curricula targeting industry and government collaborations",2016,"SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006839923&doi=10.1145%2f2993352.2993360&partnerID=40&md5=e2db690f99c2bb61f62fbdf38131d938","Educational spaces within a university campus have traditionally been seen as a lecture theatre with an area set aside for tutorials. In the case of a computer-based teaching programme, this has been a computer lab, with projector, screen and lecturer at the front of the room. All teaching has usually been in semi-darkness and, as the work is computer-based, there is nothing stimulating within the walled environment: just rows of desks and computers. Perhaps for purely pragmatic reasons this has basically been accepted by educators as the way things were done. However, it has always meant that it limited the possibility of more diverse pedagogical approaches to learning and knowledge gathering. Within a computerbased environment, how is a more student-centered approach to knowledge being advanced? What type of changes need to happen or be developed to allow different types of classrooms or processes for learning to be adopted in higher education within the very fast moving and changing field of digital moving image production and post-production. How does a university campus need to change to accommodate new environments which allow for different models of student-centered approaches to learning, as well as the increasing requirement for an industry collaborative model for projects being the norm. What needs to be developed to better enable tertiary/industry collaborative teaching and research models being pursued to be taught both inside and outside the university environment? Within the digital moving image field, students are increasingly being able to really push the research boundaries and actually inform the industry. How do we enhance and enable this reality and enmesh it into future pedagogical models? This paper investigates this changing environment with reference to how it may be achieved specifically with some key case studies within the animation subject area which includes motion capture in it's pipeline. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Curriculum; Industry; Motion capture; Narrative; Pedagogy; Visual effects","Curricula; Education; Industry; Interactive computer graphics; Students; Teaching; Collaborative teaching; Computer-based environment; Computer-based teaching; Motion capture; Narrative; Pedagogy; Student-centered approach; Visual effects; Education computing",2-s2.0-85006839923
"Spielmann S., Schuster A., Götz K., Helzle V.","VPET - A toolset for collaborative virtual filmmaking",2016,"SA 2016 - SIGGRAPH ASIA 2016 Technical Briefs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008264267&doi=10.1145%2f3005358.3005370&partnerID=40&md5=593d51653bd3bc39bb50775e6c7bc863","Over the last decades the process of filmmaking has been subject to constant virtualization. Empty green screen stages leave the entire on-set crew clueless as real props are often replaced with virtual elements in later stages of production. With the development of virtual production workflows, solutions that enable the decision-makers to explore the virtually augmented reality have been introduced. However, current environments are either proprietary or lack usability, particularly when used by filmmakers without a specialized knowledge of computer graphics and 3D software. As part of the EU funded project Dreamspace, we have developed VPET (Virtual Production Editing Tool), a holistic approach for established film pipelines that allow on-set light, asset and animation editing via an intuitive interface. VPET is a tablet-based on-set editing application that works within a real-time virtual production environment. It is designed to run on mobile and head mounted devices (HMD), and communicates through a network interface with Digital Content Creation (DCC) tools and other VPET clients. The tool also provides functionality to interact with digital assets during a film production and synchronises changes within the film pipeline. This work represents a novel approach to interact collaboratively with film assets in real-time by maintaining fundamental parts of production pipelines. Our vision is to establish an on-set situation comparable to the early days of filmmaking where all creative decisions were made directly on set. Additionally, this will contribute to the democratisation of virtual production. © 2016 ACM.","Collaborative work; Filmmaking; On-set editing; Production pipeline; Virtual production","Augmented reality; Computer graphics; Decision making; Digital devices; Interactive computer graphics; Motion pictures; Pipelines; Three dimensional computer graphics; Collaborative Work; Filmmaking; On-set editing; Production pipelines; Virtual production; Interfaces (materials)",2-s2.0-85008264267
"Yaman O., Karakose M.","Development of image processing based methods using augmented reality in higher education",2016,"2016 15th International Conference on Information Technology Based Higher Education and Training, ITHET 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007378166&doi=10.1109%2fITHET.2016.7760723&partnerID=40&md5=3d627a7cb1f8b382b6de680abd36ba8c","Today, computer-based training is developing rapidly. The visual education is also quite commonly used in higher education as well as in primary and secondary education. The tablets, smart boards and computers constitute the basis of visual education. Visual education has many advantages, such as learning faster, memorability and in terms of paper expenses. The visual animations and presentations have become a very important material in higher education in recent years along with the development of computer technologies. The image processing has been proposed to improve instructiveness in higher education courses in the fields of Medicine, Engineering and Science. In the field of medicine, the image processing methods can be used to show the diseased regions in an easier way in many images such as CT and MR images [5]. In the fields of engineering, image processing can be used to improve images in visual courses in the fields such as Geology, Civil Mining engineering. In addition, it can be easily preferred and applied in the departments such as Chemistry, Biology and Geography in the field of Science. The unclarity of images used in courses leads to ambiguity. In this study, image processing based approaches have been developed to ensure more effective learning of the courses in higher education. Image processing is a technology which is used in many places in daily life. The image processing methods have become widespread along with the acceleration of computer technologies. Today, image processing is used in many environments such as education, health, defense industry and industrial areas. Successful results are obtained application areas such as fault diagnosis and condition monitoring using image processing methods. Today, the augmented reality which is commonly used in the field of education can further increase its contribution to the field of education by associating with image processing methods. © 2016 IEEE.","augmented reality; higher education; image processing","Augmented reality; Computerized tomography; Condition monitoring; Curricula; Diagnosis; Education; Engineering education; Fault detection; Magnetic resonance imaging; Medical image processing; Mining engineering; Processing; Application area; Computer - based trainings; Computer technology; Effective learning; Higher education; Image processing - methods; Primary and secondary education; Visual educations; Image processing",2-s2.0-85007378166
"Williams F., Zhang E.","Rendering kaleidoscopic scenes using orbifold theory",2016,"SA 2016 - SIGGRAPH ASIA 2016 Technical Briefs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008260019&doi=10.1145%2f3005358.3005368&partnerID=40&md5=50bf5c8a95ab7bae2d4bd0fdd6d6864d","Kaleidoscopes create fascinating visual effects due to the presence of multiple mirrors placed at carefully designed distances and angles. These effects, such as infinite repeating copies of a single object, are difficult to capture. Moreover, lighting and shadow effects in kaleidoscopic scenes are highly impacted by the interaction between lights and mirrors. Such effects pose challenges to existing rendering techniques such as ray tracing and photon mapping. In this paper, we present a unified framework to render scenes from the perspective of a viewer inside a kaleidoscope based on Orbifold theory, which provides the mathematical foundation to describe the position and orientation of reflected objects (including light sources). Our framework is able to accurately capture the global illumination effects inside a kaleidoscope. We demonstrate the power of our technique with the rendering of a number of scenes including animation. © 2016 ACM.","Global illumination; Kaleidoscopes; Orbifold theory","Interactive computer graphics; Light sources; Mirrors; Ray tracing; Topology; Global illumination; Kaleidoscopes; Mathematical foundations; Orbifold theory; Photon mapping; Position and orientations; Shadow effects; Unified framework; Rendering (computer graphics)",2-s2.0-85008260019
"You J., Zhou Z., Gao W.","Demo: Fingertip and card recognition mobile app for interactive play",2016,"SA 2016 - SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006868395&doi=10.1145%2f2999508.2999516&partnerID=40&md5=f66d4bd3f8ea97adceedefdc4df552d8","Augmented Reality (AR) has become widespread recently. In this paper we present a different interaction in our AR system. We provide an interesting interaction by combining fingertip movement and card recognition. Users no longer has to tap on mobile screen but only needs to control virtual objects by physical cards or hand gestures. For example, user could simply tap on card, model's animation with audio tutorial would be played. You could also rotate the card or move your fingertip, the model would rotate or follow your fingertip respectively. Tracking accuracy and rotation smoothness could be further optimized by given more pre-configured conditions since this AR scenario is in a small region such as on a table. We aim at combining learning and playing together and expand the environment from mobile screen to table. We propose a different interaction method which is more natural and intuitive, providing an interesting and engaging user experience.","Augmented Reality; Hand gesture; User interaction","Interactive computer graphics; Interactive devices; User interfaces; Hand gesture; Interaction methods; Interactive plays; Mobile screens; Tracking accuracy; User experience; User interaction; Virtual objects; Augmented reality",2-s2.0-85006868395
"Shah S.A.A., Bennamoun M., Boussaid F.","Automatic 3D face landmark localization based on 3D vector field analysis",2016,"International Conference Image and Vision Computing New Zealand",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006942604&doi=10.1109%2fIVCNZ.2015.7761526&partnerID=40&md5=5da7d80624be2691571e8fafab5b9dbf","In applications such as 3D face synthesis and animation, a prominent face landmark is required to enable 3D face normalization, pose correction, 3D face recognition and reconstruction. Due to variations in facial expressions, automatic 3D face landmark localization remains a challenge. Nose tip is one of the salient landmarks in a human face. In this paper, a novel nose tip localization technique is proposed. In the proposed approach, the rotation of the 3D vector field is analyzed for robust and efficient nose tip localization. The proposed technique has the following three characteristics: (1) it does not require any training; (2) it does not rely on any particular model; (3) it is very efficient, requiring an average time of only 1.9s for nose tip detection. We tested the proposed technique on BU3DFE and Shrec'10 datasets. Experimental results show that the proposed technique is robust to variations in facial expressions, achieving a 100% detection rate on these publicly available 3D face datasets. © 2015 IEEE.",,"Computer applications; Electrical engineering; 3-D face synthesis; 3D face recognition; 3D vectors; Detection rates; Face landmarks; Facial Expressions; Human faces; Localization technique; nocv1; Face recognition",2-s2.0-85006942604
"de Macedo D.V., Rodrigues M.A.F.","Real-time dynamic reflections for realistic rendering of 3D scenes",2016,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997530111&doi=10.1007%2fs00371-016-1335-8&partnerID=40&md5=51cc912369d7670953cb013f7910a57b","Visual effects, such as real-time dynamic reflections, are fundamental for realistic rendering of 3D scenes and walkthrough animations containing multiple moving objects, since they provide the correct identification of their relative distance and of their material properties, generating a closer perception of reality. Most rendering algorithms that generate realistic effects are quite expensive, such as ray tracing, usually used in offline rendering. This paper presents a solution for generating reflections, that we have developed with a real-time hybrid algorithm for rendering rigid objects in realistic dynamic scenes. The algorithm combines rasterization, the screen space reflection (SSR) technique, with pure GPU-ray tracing algorithm through deferred rendering pipeline, doing SSR per pixel and creating a mask with failed pixels to apply ray tracing for those pixels instead. The results demonstrate a significant improvement in performance with a very little perceptual loss in quality of our hybrid algorithm, when compared to the full ray tracing solution. In terms of FPS results, our hybrid solution remains positioned (most of the time) in between the SSR and the pure ray tracing’s methods, during the walkthrough. Besides, it scales quite well for realistic dynamic scenes with 3D rigid objects. © 2016 Springer-Verlag Berlin Heidelberg","3D scenes; Real-time dynamic reflections; Realistic rendering","Pixels; Rasterization; Ray tracing; Three dimensional computer graphics; 3D scenes; Multiple moving objects; Ray-tracing algorithm; Real-time dynamics; Realistic rendering; Relative distances; Rendering algorithms; Rendering pipelines; Rendering (computer graphics)",2-s2.0-84997530111
"Acharya K., Ghoshal D.","Computer animation in studying of magnetically levitate baggage system",2016,"International Conference on Electrical, Electronics, and Optimization Techniques, ICEEOT 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006818085&doi=10.1109%2fICEEOT.2016.7754796&partnerID=40&md5=f0a0b3eff95a16eca96c0863e953c102","This Passenger baggage framework is exceptionally key in the general population spots like the air terminals, railroad station and so forth. Speedy and safe conveyance of stuff is a critical element in this connection. Customary electronic traveler stuff framework is sufficient. For more speed, security and control magnetic levitation innovation is presented by trading the current stuff framework for a better result. This paper gives an outline of computer animation of passenger baggage system by the principle of magnetic levitation. The proposed system may save time and able to offer high-speed baggage system in the airport terminals. © 2016 IEEE.","animation; Autodesk Maya; baggage; maglev; superconductor","Animation; Magnetic levitation vehicles; Superconducting materials; Transportation; Airport terminals; Autodesk mayas; baggage; Computer animation; Critical elements; General population; High Speed; maglev; Magnetic levitation",2-s2.0-85006818085
"Acharya K., Ghoshal D.","3D computer animation of biomimetic underwater vehicle with magnetic levitation technology",2016,"International Conference on Electrical, Electronics, and Optimization Techniques, ICEEOT 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006823000&doi=10.1109%2fICEEOT.2016.7755173&partnerID=40&md5=5102475b6dd4bbce11ae03bad5cd4e29","The concept of Biomimicry and magnetic levitation have opened new area and possibility in the field of research. In the present study, biological behavior based design structure with magnetic levitation technology has been applied in the proposed underwater vehicle design. The bio-propelled balance plan on the vehicles has been made and animated based on the idea of magnetic levitation. The fish shaped vehicle design is proposed to produce the optimal movements in different modes and to provide smooth, balanced and high speed traveling facility to the passengers. Some animations of the underwater vehicle have been shown here. This paper is expected to provide a good basis for the understanding of magnetic levitation based optimized design of underwater vehicle using the concepts of Biomimicry. © 2016 IEEE.","3D modeling; Animation; Biomimicry; Design; Levitation; Maglev; Magnet; Maya; Superconductor; Underwater","Animation; Biomimetic processes; Biomimetics; Design; Magnetic levitation; Magnetism; Magnets; Superconducting materials; Vehicles; 3-d modeling; Biomimicry; Levitation; Maglev; Maya; Underwater; Magnetic levitation vehicles",2-s2.0-85006823000
"Ataucusi P.E., Espinoza N.R., Taype M., Ataucusi E., Ibarra M.J.","Yachay math: Learning fractions with spatio-temporal approach, using computer animation",2016,"Proceedings - 2016 11th Latin American Conference on Learning Objects and Technology, LACLO 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006943990&doi=10.1109%2fLACLO.2016.7751799&partnerID=40&md5=65dffe8d2e75bf10f5f2dc9a8e6dce4a","To improve the learning process in mathematics, new approaches are needed. Yachay Math is visual and interactive software that has been developed to use on desktop computers, tablets and mobile devices. It is a tool for spatio-temporal reasoning, designed for students to learn mathematical concepts dynamically. Yachay Math provides to teachers a visual approach for mathematics teaching and for the students is a new way to learn fractions without text instructions, so the focus is to solve problems by students discovering. The tool was tested and validated by students and teachers from three rural schools in Apurimac-Peru. Two types of tests were performed; the first one was by using the C-Means Fuzzy methodology and the second one by the user's opinion. The results show that teachers and students consider that Yachay Math is a funny way to learn fractions in mathematics. © 2016 IEEE.","Animación por Ordenador; Animación Visual Interactiva; Fracciones; Razonamiento Espacio-Temporal; Razonamiento Innato del Cerebro","Animation; Education; Personal computers; Students; Teaching; Fracciones; Interactive software; Mathematical concepts; Mathematics teachings; Razonamiento Espacio-Temporal; Razonamiento Innato del Cerebro; Spatio-temporal approach; Spatio-temporal reasoning; Engineering education",2-s2.0-85006943990
"Ibarra M.J., Soto W., Ataucusi P., Ataucusi E.","MathFraction: Educational serious game for students motivation for math learning",2016,"Proceedings - 2016 11th Latin American Conference on Learning Objects and Technology, LACLO 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006961111&doi=10.1109%2fLACLO.2016.7751777&partnerID=40&md5=91f725a118ac98f8fc6b767685332ecf","This article aims to improve the math learning process in students of rural schools. For this purpose, an educational serious game was developed for use on the web and mobile technologies. The tool was designed using a visual approach so that students reinforce their learning developed in class. The tool was tested and validated by thirty four students and four teachers of two rural schools in Apurímac-Perú. The test was given using a user usability questionnaire. The results of this research show a framework to design and implement Learning Objects and Serious Game to learn Fractions; in other hand, teachers and students agree that Math-Fraction allows them to teach and learn math in a fun way and different from the other traditional methodologies that they knew. © 2016 IEEE.","Computer Animation; Fractions; Human Computer Interaction; Math Learning; Serious Game","Animation; Computer games; Education; Engineering education; Human computer interaction; Teaching; Computer animation; Design and implements; Fractions; Learning objects; Learning process; Math Learning; Mobile Technology; Serious games; Students",2-s2.0-85006961111
"Salam H., Séguier R.","A survey on face modeling: building a bridge between face analysis and synthesis",2016,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995741090&doi=10.1007%2fs00371-016-1332-y&partnerID=40&md5=bd729b269fdc37db7c2f7ac86443a1aa","Face modeling refers to modeling the shape and appearance of human faces which lays the basis for model-based facial analysis, synthesis and animation. This paper summarizes the existing state-of-the-art work on face modeling and animation in the Computer Graphics and the Computer Vision areas. While some models or techniques are exclusively used for facial analysis or for facial animation and synthesis, other models combine analysis and synthesis in an analysis-by-synthesis loop. This paper introduces a taxonomy of face modeling methods in function of the area of application (synthesis and analysis) and builds a link between the two by reviewing analysis-by-synthesis face modeling methods. The interest of such a taxonomy is to introduce new face models that combine ideas from the analysis and synthesis domains. We also provide an overview of the extensions of the seminal works presented in this paper. Within each category, we discuss the advantages and disadvantages of each method with respect to the others. © 2016 Springer-Verlag Berlin Heidelberg","Analysis-by-Synthesis; Face analysis; Face modeling; Facial animation and synthesis","Computer graphics; Computer vision; Taxonomies; Analysis and synthesis; Analysis by synthesis; Face analysis; Face modeling; Facial analysis; Facial animation; Model-based OPC; State of the art; Animation",2-s2.0-84995741090
"Tosic N., Bukvic A., Dimitrijevic V., Bebic M., Ristic L.","Hardware in the loop model for irregular conditions in tension leveler applications",2016,"4th International Symposium on Environment Friendly Energies and Applications, EFEA 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006489356&doi=10.1109%2fEFEA.2016.7748816&partnerID=40&md5=7ffea77d41cb287797b48ae0110fe304","One of the main parts of the production line in a metal web processing applications is tension leveler. It contains unwinder, tension bridles and winder. Parameters setting of regulators which control the production line and their testing of control system are needed. The paper presents a simulation and 3D visualization model of tension leveler developed for purpose of testing the control strategy. Complete hardware installed on the production line (drives, motors, etc.) is emulated by Simulation Unit hardware and is connected with detailed mathematical model of the tension leveler. Control software developed for the application is tested on hardware-in-The-loop real time simulation. Main goal of the work presented in the paper is to design and test control strategy for regular and irregular conditions in the simulated process of web tension leveling, and to represent it as a 3D animation. © 2016 IEEE.","3D visualization modeling; emulation of hardware; hardware in the loop; real time simulation; tension leveler; testing control strategy; web slippage","Application programs; Computer software; Software testing; Synthetic apertures; Three dimensional computer graphics; Transients; Visualization; 3D visualization model; Control strategies; Hard-ware-in-the-loop; Real time simulations; Tension leveler; web slippage; Hardware",2-s2.0-85006489356
"Janković N.Z., Slijepčević M.Z., Čantrak D.S., Gadanski I.I.","Application of 3D printing in M.Sc. studies - Axial turbocompressors",2016,"1st International Conference on Multidisciplinary Engineering Design Optimization, MEDO 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002521838&doi=10.1109%2fMEDO.2016.7746545&partnerID=40&md5=a363900b5ce31ec942c56cae2538e6df","Teaching subject Fans and turbocompressors involves in its curriculum design of axial turbocompressors, with focus on impeller and guide vanes design. Students develop 3D construction on the basis of the inlet design parameters: mass flow rate, inlet pressure, inlet temperature, inlet and outlet pressure ratio and Mach number. The whole project was finalized only with the computer animation. Recently, digital fabrication is involved in the process of students' education. Nowadays students are able to print designed impeller blade and to study its construction. 3D printing machine - Printrbot Simple is used. Designed and fabricated axial fan impeller blade will be presented in this paper. © 2016 IEEE.","3D design; Axial turbocompressor; Digital fabrication; Education; Impeller","Animation; Curricula; Education; Fabrication; Fans; Impellers; Printing; Students; 3-d designs; Computer animation; Curriculum designs; Digital fabrication; Inlet pressures; Inlet temperature; Outlet pressures; Turbocompressor; 3D printers",2-s2.0-85002521838
"Prima D.A., Usagawa T., Purnama I.K.E., Hariadi M.","Camera control for shot selection in machinima generated animation",2016,"Journal of Theoretical and Applied Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995579378&partnerID=40&md5=5caa4319a9cb7b155c26d7db024fcc22","The development of computer graphics–rendering technology is rapidly increasing—the next-gen game can present 3D images that are closer to reality and can be run in real time. This allows the emergence of a new technique called “machinima,” derived from the words machine and cinema, to make real-time animation movies in a virtual environment. Machinima filmmaking requires a cinematography rule to produce a good animation. A behavior tree is used to select the camera shot according to the cinematography rule using shot idiom such as close-up, back-shot, shoulder-shot, etc. The system allows the camera to decide the proper shot based on events and actions happening in the virtual scene. © 2005 - 2016 JATIT & LLS. All rights reserved.","Behavior tree; Cinematography; Game; Machinima; Virtual camera; Virtual world",,2-s2.0-84995579378
"Sosa G.D., Rodriguez S., Guaje J., Victorino J., Mejia M., Fuentes L.S., Ramirez A., Franco H.","3D surface reconstruction of entomological specimens from uniform multi-view image datasets",2016,"2016 21st Symposium on Signal Processing, Images and Artificial Vision, STSIVA 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002875652&doi=10.1109%2fSTSIVA.2016.7743319&partnerID=40&md5=ec430a09acd5938aeacbbd63049105a3","Modeling of 3D objects and scenes have become a common tool in different applied fields from simulation-based design in high-end engineering applications (aviation, civil structures, engine components, etc.) to entertainment (computer-based animation, video-game development, etc.). In Biology and related fields, 3D object modeling and reconstruction provide valuable tools to support the visualization, comparison and even morphometric analysis in both academical and applied tasks. Such computational tools, usually implemented as web-based virtual reality applications, significantly reduce the manipulation of fragile samples, preventing their damage and, even, their complete loss. On the other hand, they allow to take the morphological properties of physical specimens to the digital domain, giving support to common entomology tasks such as characterization, morphological taxonomy and teaching. This paper addresses the problem of producing reliable 3D point clouds from the surface of entomological specimens, based on a proved approach for multi view 3D reconstruction from high resolution pictures. Given the traditional issues of macro-photography for small sized objects (i.e. short depth of field, presence of subtle and complex structures, etc.), a pre-processing protocol, based on focus stacking, supported the generation of enhanced views obtained by an acquisition device specifically designed for this work. The proposed approach has been tested on a sample of six representative subjects from the Entomological Collection of the Centro de Biosistemas, Universidad Jorge Tadeo Lozano (Colombia). The resulting point clouds exhibit an overall good visual quality for the body structure the selected specimens, while file sizes are portable enough to support web based visualization. © 2016 IEEE.",,"Animation; Computer games; Image processing; Image reconstruction; Signal processing; Structural design; Surface reconstruction; Virtual reality; Vision; Visualization; Websites; 3D surface reconstruction; Computational tools; Engineering applications; Morphological properties; Morphometric analysis; Simulation-based designs; Video game development; Web-based visualization; Three dimensional computer graphics",2-s2.0-85002875652
"Larrarte E.A., Alban A.V.","Virtual markers in virtual laparoscopy surgery",2016,"2016 21st Symposium on Signal Processing, Images and Artificial Vision, STSIVA 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002885401&doi=10.1109%2fSTSIVA.2016.7743367&partnerID=40&md5=429ffd56823c1b239e135a1fe9ee5618","Augmented Reality or AR is a technology characterized by virtual content adding on the perception of reality using the existing environment and overlaying additional information, this digital information is shown in a device display in real time. The aim of this study is to implement some tests for a mobile augmented reality system (MAR) and test the potential of AR development tools in a mobile application for a surgery training system to assist and train laparoscopic or minimal invasive surgery. These tests are the base for the first application to be developed, it will use 3D visualization, depth extraction from medical images and tracking to display information about the video surgery. Augmented reality apps are written in special 3D programs that allow the developer to tie animation or contextual digital information in a computer program to an augmented reality 'marker' in the real world. When a computing device AR app or browser plug-in receives digital information from a known marker, it begins to execute the marker's code and layer the correct image or images. © 2016 IEEE.",,"Augmented reality; Display devices; Laparoscopy; Medical imaging; Signal processing; Surgery; Three dimensional computer graphics; Vision; 3D Visualization; Computing devices; Digital information; Minimal invasive surgery; Mobile applications; Mobile augmented reality; Surgery training systems; Virtual laparoscopy; Image processing",2-s2.0-85002885401
"Feng Z., Yang B., Liu H., Lv N., Yang X., Yin J., Zhang Y., Zhao X.","An HCI paradigm fusing flexible object selection and AOM-based animation",2016,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977642390&doi=10.1016%2fj.ins.2016.06.052&partnerID=40&md5=a9f23348a2307591dfd3d57a5c8a272d","The use of three-dimensional (3D) gesture input devices is important and necessary in 3D systems, but such devices face considerable challenges posed by the high dimensionality of dexterous hand motion. The objective of this study is to achieve real-time interaction in object selection and direct manipulation in 3D application systems by capturing and visualizing the interaction intentions and probing the cognitive behavior models of users. An interactive operation procedure is divided into three stages: object selection, manipulation and reset. Trajectory scene interaction (TSI) is proposed for object selection starting from a fixed position called a forward point (FP). The manipulations exerted on the selected object include grasping and translation. After these manipulations, the gesture is reset to the FP. This work offers four novel contributions. First, flexible object selection and atomic operation model (AOM)-based animations are fused to form a uniform, real-time human-computer interaction (HCI) paradigm. Second, a cognitive behavior model is proposed for recognizing and reacting to hand gestures as captured by a monocular camera. Third, an approach to capturing, expressing, and probing a user's interaction intention is presented. Fourth, a 3D real-time gesture input interface is achieved. The use of the proposed HCI interface, which offers fast speed, satisfactory accuracy and a responsive user experience, is demonstrated in virtual assembly, a game of chess, dialing a cell phone number and menu operation. © 2016 Elsevier Inc.","3D human–computer interaction; Freehand tracking; Gestural UI; User interface","Animation; Cognitive systems; Gesture recognition; Mobile phones; Real time systems; Three dimensional computer graphics; User interfaces; Computer interaction; Freehand tracking; Gestural UI; Gesture input devices; Human computer interaction (HCI); Interactive operations; Real time interactions; Threedimensional (3-d); Human computer interaction",2-s2.0-84977642390
"Kehagias D., Raptis I.","An interactive MESI cache coherence simulator for educational purposes",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014814059&doi=10.1145%2f3003733.3003765&partnerID=40&md5=4b4ff0cf17615acc5acacef4507a4617","In multi-processor systems data can reside in multiple levels of cache, as well as in main memory. The problem of keeping the data consistent among all caches and memory is known as the cache coherence problem. There are different protocols to solve this problem. The MESI (Modified-Exclusive-Shared-Invalid) cache coherence protocol is one of them. In this paper, an educational MESI cache coherence simulator is presented that shows with animation how the MESI protocol works. It is targeted to be used for teaching and learning the cache memory coherence in advanced computer architecture courses. The simulator enables interactive communication with students and is implemented in Unity Engine and Visual Studio IDE using scripts in C#. © 2016 ACM.","Coherence protocol; Computer architecture; Interactive animation; MESI; Simulator","Animation; Computer architecture; Education; Memory architecture; Multiprocessing systems; Network architecture; Problem solving; Simulators; Teaching; Cache coherence protocols; Coherence protocol; Computer architecture course; Interactive animations; Interactive communications; MESI; Multi processor systems; Teaching and learning; Cache memory",2-s2.0-85014814059
"Hürst W., Tan X.J., De Coninck F.","Using digital extensions to create new VR museum experiences",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014636786&doi=10.1145%2f3001773.3001822&partnerID=40&md5=cb74b521b52f07cf0362b946d065b935","The digitization of paintings enables us to do various modifications with them and also to add digital content that complements such artworks. In our research we investigate how such digital extensions can be used in a VR museum setup. This Creative Showcase demo presents a first implementation of such an ""enhanced VR museum"" based on initial results and related user feedback from earlier experiments. By using techniques such as ""inpainting"", ""stylization"" of objects or other visuals in the style of a painting, and by adding of content-related 3D animations we aim at creating VR museum techniques that provide a better experience by, for example, being more immersive, creating a higher emotional connection, or having an educational value.","Virtual reality; VR experiences; VR museum","Computer applications; Computer programming; 3D animation; Digital contents; Emotional connections; Immersive; Inpainting; User feedback; VR experiences; Virtual reality",2-s2.0-85014636786
"Latoschik M.E., Lugriny J.-L., Rothz D.","FakeMi: A fake mirror system for avatar embodiment studies",2016,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998850000&doi=10.1145%2f2993369.2993399&partnerID=40&md5=28441605fc3ded517bb78359a9decf67","This paper introduces a fake mirror system as a research tool to study the effect of avatar embodiment with non-visually immersive virtual environments. The system combines marker-less face and body tracking to animate the individual avatars seen in a stereoscopic display with a correct perspective projection. The display dimensions match typical dimensions of a real physical mirror and the animated avatars are rendered based on a geometrically correct reflection as expected from a real mirror including correct body and face animations. The first evaluation of the system reveals the high acceptance of the setup as well as a convincing illusion of a real mirror with different types of avatars.","Avatar; Tool; Virtual Body Ownership; Virtual Mirror","Mirrors; Stereo image processing; Tools; Virtual reality; Avatar; Face animation; Immersive virtual environments; Mirror systems; Perspective projections; Stereoscopic display; Virtual bodies; Virtual mirror; Three dimensional computer graphics",2-s2.0-84998850000
"Latoschik M.E., Lugrin J.-L., Habel M., Roth D., Seufert C., Grafe S.","Breaking bad behavior: Immersive training of class room management",2016,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998704927&doi=10.1145%2f2993369.2996308&partnerID=40&md5=29d1d5b1e46c48d608183a9df3d40df2","This article presents a fully immersive portable low-cost Virtual Reality system to train classroom management skills. An instructor controls the simulation of a virtual classroom populated with 24 semi-autonomous virtual agents via a desktop-based graphical user interface (GUI). The GUI provides behavior control and trainee evaluation widgets alongside a non-immersive view of the class and the trainee. The trainee's interface uses an Head-Mounted Display (HMD) and earphones for output. A depth camera and the HMD's built-in motion sensors are used for tracking the trainee and for avatar animation. An initial evaluation of both interfaces confirms the system's usefulness, specifically its capability to successfully simulate critical aspects of classroom management.","Class Room Management; Student Simulation; Virtual Agent Interaction; Virtual Reality Training","Autonomous agents; Computer aided instruction; Graphical user interfaces; Teaching; User interfaces; Virtual reality; Class rooms; Classroom management; Graphical user interfaces (GUI); Head mounted displays; Virtual agent; Virtual Classroom; Virtual reality system; Virtual reality training; Helmet mounted displays",2-s2.0-84998704927
"De Masi V., Yan H.","The digital turn in storytelling and creative industries in china: A report",2016,"Storytelling and Education in the Digital Age: Experiences and Criticisms",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014276364&doi=10.3726%2f978-3-653-06976-1&partnerID=40&md5=3c7d02a6a098fa31410fabdc62482978","In recent years, creative industries in China have had an important role both economically and socially, and the sectors of animation and video games have had the chance to develop significantly. Animation, as a form of storytelling, can have a strong educational power (Van Riper, 2011): this is the basis of the new industrial strategy adopted by China in the creative sector, as far as the animation field is concerned (Tan, 2006). Over a few years, the animation industry was able to achieve a great development with the creation of products mainly for broadcast on TV. Animation now represents around 220,000 minutes per year. For this reason, China became the number one producer of animation in the world in 2010. But to achieve this, the Chinese government had to encourage and try to structure the entire animation industry (Lu Bin, 2013). In the early 2000s, the animation industry in China increased the production of animation contents, thanks to the introduction of computers in industrial production, bringing about an increase in minutes and quality (Tan, 2006). This new technological condition was somehow facilitated by the government that pushed the major animation production studios to adapt to new technological standards and keep pace with other countries competing in this area (Qing, 2006). The digital turn in storytelling seems to have increased the capacity of the government to promote traditional values, rather than improving the chances of the independent authors and private studios to create new stories. The development of technology and the entry of computers in many Chinese homes also generated a change in the spread of animation products, as many users, especially students, began to watch online products made abroad. Moreover, it has created a new generation of authors, who, although few, have begun to create new stories and have a clear idea of how to use new technologies - even criticising, in some animations, the social situation of modern China. At that moment, there was still a predominance of foreign productions, mainly Japanese and American: almost the totality of the merchandise was in the hands of foreign companies (Lu Bin, 2014).The digital turn in storytelling has made propaganda productive: not a cost for the government but actually a profitable business to reach in few years. This article will relate the historical and technological development, government policies in favour of this industry and it will analyse the reasons of the theatrical feature animation films success, highlighting the most representative works produced over the past 15 years.",,,2-s2.0-85014276364
"Lin W.-C., Wong S.-K., Li C.-H., Tseng R.","Generating Believable Mixed-Traffic Animation",2016,"IEEE Transactions on Intelligent Transportation Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966373375&doi=10.1109%2fTITS.2016.2542283&partnerID=40&md5=a94c09997be7a76d5a9546f1108398e6","We present an agent-based approach to animate microscopic mixed traffic involving cars and motorcycles in complex scenarios, including signalized and nonsignalized road intersections, and traffic jams due to blockage. Based on our new car-following and lateral movement models, our method can reproduce lane-based and nonlane-based traffic behaviors that are commonly seen in urban scenes. Our dynamic routing and intersection procedures enable a user to interactively control the movement of a car, and our system generates the microscopic behaviors of the influenced vehicles accordingly. Experimental results show that our approach can animate appealing microscopic mixed traffic with various behaviors. Our approach will benefit applications in virtual cities, computer games, and driving simulators. © 2016 IEEE.","Microscopic traffic animation; mixed-traffic animation","Computer games; Traffic congestion; Traffic control; Agent-based approach; Driving simulator; Dynamic routing; Lateral movement; Microscopic behavior; Road intersections; Traffic behavior; Virtual cities; Animation",2-s2.0-84966373375
"Barbieri S., Meloni P., Usai F., Spano L.D., Scateni R.","An interactive editor for curve-skeletons: SkeletonLab",2016,"Computers and Graphics (Pergamon)",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986296817&doi=10.1016%2fj.cag.2016.08.002&partnerID=40&md5=c32107935da5284d6a23071e2dbb6b84","Curve-skeletons are powerful shape descriptors able to provide higher level information on topology, structure and semantics of a given digital object. Their range of application is wide and encompasses computer animation, shape matching, modelling and remeshing. While a universally accepted definition of curve-skeleton is still lacking, there are currently many algorithms for the curve-skeleton computation (or skeletonization) as well as different techniques for building a mesh around a given curve-skeleton (inverse skeletonization). Despite their widespread use, automatically extracted skeletons usually need to be processed in order to be used in further stages of any pipeline, due to different requirements. We present here an advanced tool, named SkeletonLab, that provides simple interactive techniques to rapidly and automatically edit and repair curve skeletons generated using different techniques proposed in the literature, as well as handcrafting them. The aim of the tool is to allow trained practitioners to manipulate the curve-skeletons obtained with skeletonization algorithms in order to fit their specific pipelines or to explore the requirements of newly developed techniques. © 2016 Elsevier Ltd","3D meshes; Curve-skeleton; Geometry processing; Interactive editing","Animation; Pipelines; Semantics; 3D meshes; Computer animation; Curve skeletons; Geometry processing; Higher-level information; Interactive editing; Interactive techniques; Skeletonization algorithm; Musculoskeletal system",2-s2.0-84986296817
"Oshita M., Oshima H., Senju Y., Morishige S.","Character motion synthesis by principal component analysis and motion control interface by hands",2016,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000786957&doi=10.1002%2fcav.1673&partnerID=40&md5=36d3281343904ec01e73dfb223a59e5d","In this paper, we propose an interactive character motion control interface that uses hands. Using their hands and fingers, the user can control a large number of degrees of freedom at the same time. We applied principal component analysis to a set of sample poses and assigned the extracted principal components to each degree of freedom of the hands (such as the hand positions and finger bending/extending angles). The user can control the blending weights of the principal components and deform the character's pose by moving their hands and bending/extending their fingers. We introduced pose and action controls, so that we can alter the standing pose and perform various actions with deformations. So that various types of actions were possible, we constructed a number of action models in advance. We introduced action model selection and action execution mechanisms. We developed methods for computing the feature vector, for applying principal component analysis, and for pose and action synthesis. In addition, we introduced a pose transition method for performing a step motion when necessary to prevent foot sliding. We present our experimental results and demonstrate the effectiveness of our interface. Copyright © 2015 John Wiley & Sons, Ltd. Copyright © 2015 John Wiley & Sons, Ltd.","computer animation; hand; motion control; principal component analysis; user interface","Animation; Blending; Copyrights; Degrees of freedom (mechanics); Motion compensation; Motion control; User interfaces; Character motion; Character motion synthesis; Computer animation; Control interfaces; Degree of freedom; hand; Number of degrees of freedom; Principal Components; Principal component analysis",2-s2.0-85000786957
"Holliday C.","'I'm Not a Real Boy, I'm a Puppet': Computer-Animated Films and Anthropomorphic Subjectivity",2016,"Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992598435&doi=10.1177%2f1746847716661456&partnerID=40&md5=88c635841ce146c8cdbca14a49fcfb61","This article rethinks anthropomorphic representation and animated animality within the context of the contemporary digital era and, more precisely, against the rise of the computer-animated feature film. By interrogating the fractured identity of the anthropomorph as a necessarily hybrid figuration, it suggests how popular computer-animated films have rejected ánthrōpos and instead exploited the non-human morphē element to manipulate virtual space through anthropomorphic subjectivity. The anthropomorph is here refined into a more prescriptive and functional agent, absorbing viewers into a spectatorial game that sharpens their awareness of the digital realm. Films such as Ratatouille (Brad Bird, 2007) and Bee Movie (Simon J Smith and Steve Hickner, 2007) are offered as case studies that reflect the shift towards the form or morphē element, one that is registered through a particular mode of subjectified address. Drawing on Gilles Deleuze's notion of 'gaseous perception' to elucidate this delivery of enlivened space, this article argues that the computer-animated film is implicated in a hierarchical switch away from humanlike behaviour to embrace the possibilities of the anthropomorph's non-human morphē identity, thereby upturning the received narrative of how anthropomorphism has been conceptualized among critical studies of animation. © SAGE Publications.","animals; animation; anthropomorphism; computer-animated film; focalization; gaseous perception; Gilles Deleuze; Pixar; plasmaticness; Sergei Eisenstein; subjectivity",,2-s2.0-84992598435
"Yu L., Harrison L., Lu A.","Effectiveness of feature-driven storytelling in 3d time-varying data visualization",2016,"Journal of Imaging Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016301094&doi=10.2352%2fJ.ImagingSci.Technol.2016.60.6.060408&partnerID=40&md5=7cc648249c231222603984c1690ff6ad","Storytelling animation has a great potential to be widely adopted by domain scientists for exploring trends in scientific simulations. However, due to the dynamic nature and generation methods of animations, serious concerns have been raised regarding their effectiveness for analytical tasks. This has led to interactive techniques often being favored over animations, as they provide the user with complete control over the visualization. This trend in scientific visualization design has not yet considered newer algorithmic animation generation methods that are driven by the automatic analysis of data features and storytelling techniques. In this work, the authors performed an experiment which compares feature-driven storytelling animations to common interactive visualization techniques for time-varying scientific simulations. They discuss the design of the experiment, including tasks for storm-surge analysis that are representative of common scientific visualization projects. Their results illustrate the relative advantages of both feature-driven storytelling animations and interactive visualizations, which may provide useful design guidelines for future storytelling and scientific visualization techniques. © 2016 Society for Imaging Science and Technology.",,"Animation; Three dimensional computer graphics; Visualization; Animation generation; Automatic analysis; Design of the experiment; Generation method; Interactive techniques; Interactive visualizations; Scientific simulations; Time-varying data visualization; Data visualization",2-s2.0-85016301094
"Salmi H., Thuneberg H., Vainikainen M.-P.","How do engineering attitudes vary by gender and motivation? Attractiveness of outreach science exhibitions in four countries",2016,"European Journal of Engineering Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953725519&doi=10.1080%2f03043797.2015.1121466&partnerID=40&md5=9b17b424306b1e88a3b1610909af790e","Outreach activities, like mobile science exhibitions, give opportunities to hands-on experiences in an attractive learning environment. We analysed attitudes, motivation and learning during a science exhibition visit, their relations to gender and future educational plans in Finland, Estonia, Latvia and Belgium (N = 1210 sixth-graders). Pupils' performance in a knowledge test improved after the visit. Autonomous motivation and attitudes towards science predicted situation motivation awakened in the science exhibition. Interestingly, the scientist attitude and the societal attitude were clearly separate dimensions. The third dimension was manifested in the engineering attitude typical for boys, who were keener on working with appliances, designing computer games and animations. Scientist and societal attitudes correlated positively and engineering attitude correlated negatively with the future educational plans of choosing the academic track in secondary education. The societal perspective on science was connected to above average achievement. In the follow-up test, these attitudes showed to be quite stable. © 2016 SEFI.","attractiveness of education; Engineering education research; future educational plans; gender differences; hands-on-experience; motivation for learning; science exhibition","Animation; Computer aided instruction; Computer games; Education; Engineering education; Exhibitions; Motivation; Educational plans; Engineering education research; Gender differences; hands-on-experience; Motivation for learning; Engineering exhibitions",2-s2.0-84953725519
"Gibet S., Lefebvre-Albaret F., Hamon L., Brun R., Turki A.","Interactive editing in French Sign Language dedicated to virtual signers: requirements and challenges",2016,"Universal Access in the Information Society",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930535783&doi=10.1007%2fs10209-015-0411-6&partnerID=40&md5=5a89a45ada2306318ada3119a954f71d","Signing avatars are increasingly used as an interface for communication to the deaf community. In recent years, an emerging approach uses captured data to edit and generate sign language (SL) gestures. Thanks to motion editing operations (e.g., concatenation, mixing), this method offers the possibility to compose new utterances, thus facilitating the enrichment of the original corpus, enhancing the natural look of the animation, and promoting the avatar’s acceptability. However, designing such an editing system raises many questions. In particular, manipulating existing movements does not guarantee the semantic consistency of the reconstructed actions. A solution is to insert the human operator in a loop for constructing new utterances and to incorporate within the utterance’s structure constraints that are derived from linguistic patterns. This article discusses the main requirements for the whole pipeline design of interactive virtual signers, including: (1) the creation of corpora, (2) the needed resources for motion recording, (3) the annotation process as the heart of the SL editing process, (4) the building, indexing, and querying of a motion database, (5) the virtual avatar animation by editing and composing motion segments, and (6) the conception of a dedicated user interface according to user’ knowledge and abilities. Each step is illustrated by the authors’ recent work and results from the project Sign3D, i.e., an editing system of French Sign Language (LSF) content (http://sign3d.websourd.org/sltat). © 2015, Springer-Verlag Berlin Heidelberg.","Data-driven synthesis; Interactive editing; Signing avatar","Animation; Computational linguistics; Query processing; Semantics; User interfaces; Data-driven synthesis; Interactive editing; Linguistic patterns; Motion segments; Pipeline design; Semantic consistency; Signing avatars; Structure constraints; Interactive computer graphics",2-s2.0-84930535783
"Trelease R.B.","From chalkboard, slides, and paper to e-learning: How computing technologies have transformed anatomical sciences education",2016,"Anatomical Sciences Education",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966546011&doi=10.1002%2fase.1620&partnerID=40&md5=ac74e55eec8abd48e244d5478e38301f","Until the late-twentieth century, primary anatomical sciences education was relatively unenhanced by advanced technology and dependent on the mainstays of printed textbooks, chalkboard- and photographic projection-based classroom lectures, and cadaver dissection laboratories. But over the past three decades, diffusion of innovations in computer technology transformed the practices of anatomical education and research, along with other aspects of work and daily life. Increasing adoption of first-generation personal computers (PCs) in the 1980s paved the way for the first practical educational applications, and visionary anatomists foresaw the usefulness of computers for teaching. While early computers lacked high-resolution graphics capabilities and interactive user interfaces, applications with video discs demonstrated the practicality of programming digital multimedia linking descriptive text with anatomical imaging. Desktop publishing established that computers could be used for producing enhanced lecture notes, and commercial presentation software made it possible to give lectures using anatomical and medical imaging, as well as animations. Concurrently, computer processing supported the deployment of medical imaging modalities, including computed tomography, magnetic resonance imaging, and ultrasound, that were subsequently integrated into anatomy instruction. Following its public birth in the mid-1990s, the World Wide Web became the ubiquitous multimedia networking technology underlying the conduct of contemporary education and research. Digital video, structural simulations, and mobile devices have been more recently applied to education. Progressive implementation of computer-based learning methods interacted with waves of ongoing curricular change, and such technologies have been deemed crucial for continuing medical education reforms, providing new challenges and opportunities for anatomical sciences educators. Anat Sci Educ 9: 583–602. © 2016 American Association of Anatomists. © 2016 American Association of Anatomists","3D imaging techniques; e-learning; gross anatomy education; historical perspective; medical curriculum; medical education; medical imaging; modeling; review; simulation","anatomy; attitude to computers; computer graphics; computer simulation; curriculum; diagnostic imaging; education; factual database; forecasting; human; Internet; learning; mass communication; social media; teaching; three dimensional imaging; trends; videorecording; vocational education; Anatomy; Attitude to Computers; Computer Graphics; Computer Simulation; Computer-Assisted Instruction; Curriculum; Databases, Factual; Diagnostic Imaging; Diffusion of Innovation; Education, Professional; Forecasting; Humans; Imaging, Three-Dimensional; Internet; Learning; Social Media; Video Recording",2-s2.0-84966546011
"Perez-Monte C.F., Perez M.D., Rizzi S., Piccoli F., Luciano C.","Modelling frame losses in a parallel Alternate Frame Rendering system with a Computational Best-effort Scheme",2016,"Computers and Graphics (Pergamon)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992584907&doi=10.1016%2fj.cag.2016.08.004&partnerID=40&md5=08d305133169f9f9a06c3f0b3cbe3453","Virtual reality (VR) surgical training and presurgical planning require the creation of 3D virtual models of patient anatomy from medical scans (e.g. CT or MRI). Real-time head tracking in VR applications allows users to navigate in the virtual anatomy from any 3D position and orientation. The process of interactively rendering highly detailed 3D volumetric data of anatomical models from a dynamically changing observer׳s perspective is extremely demanding for computational resources. We propose a parallel computing solution to this problem, involving a distributed volume graphics rendering system composed of multiple nodes concurrently working on different frames of the output stream, which are later integrated to form the final animation. In this scenario, it is important to consider frame losses generated by their out-of-order arrivals in the output sequence of 2D images. This paper presents a study of frame losses for a distributed graphics rendering system consisting of multiple GPU-based heterogeneous nodes running in a best-effort rendering scheme and applying an Alternate Frame Rendering technique. We describe a mathematical model of frame losses, as well as a performance evaluation comparing model predictions with experimental results. © 2016 Elsevier Ltd.","Alternate Frame Rendering; Distributed volume rendering; Monte Carlo Method; Parallel and distributed graphic systems; Real time; Virtual reality","Computer graphics; Computerized tomography; Monte Carlo methods; Real time systems; Three dimensional computer graphics; Virtual reality; Volume rendering; Volumetric analysis; Alternate Frame Rendering; Computational resources; Distributed graphics; Heterogeneous nodes; Out-of-order arrival; Parallel com- puting; Presurgical planning; Real time; Distributed computer systems",2-s2.0-84992584907
"Porwal S., Khare S.","Quad Tree-Based Surface Construction of Digital Globe for Real Time Application",2016,"IETE Technical Review (Institution of Electronics and Telecommunication Engineers, India)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014889833&doi=10.1080%2f02564602.2015.1134287&partnerID=40&md5=801b8da1f93803996d8065d27d8a5688","The huge availability of high-resolution geographical data using the space/air borne platforms has made it possible to create and visualize the three-dimensional (3D) model of any part on the Earth. The seamless visualization of the adjacent data in a mosaic manner not only requires the specialized techniques for data representation but also require sophisticated techniques of rendering to meet the requirements of certain applications like flight simulator, missile path animation. The high speed rendering of the 3D frames is the key requirement in such applications where each frame rendering time is bounded. This paper presents a novel technique for efficient representation of the geographical data covering the complete globe and a new methodology of rendering of 3D frames that guarantees each frame construction within the desired time bound. © 2016 IETE.","Digital globe; GIS; quad tree; real time rendering; terrain visualization","Data visualization; Earth (planet); Flight simulators; Geographic information systems; Rendering (computer graphics); Space platforms; Visualization; Data representations; Digital globes; Quad trees; Real-time application; Real-time rendering; Surface construction; Terrain visualization; Three dimensional (3-D) modeling; Three dimensional computer graphics",2-s2.0-85014889833
"Briskin E.S., Leonard A.V.","Energy profile and the open-loop control of the translational motion of the walking machine Cyclone",2016,"Journal of Computer and Systems Sciences International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004066483&doi=10.1134%2fS1064230716060034&partnerID=40&md5=8914ccfb3d208f3f3b4f6bce28d80179","The energy profile of the walking machine Cyclone and the influence of the motion modes on the energy consumption in the case of its translational motion along a straight line is analyzed using computer simulation. The computations are performed in pseudo-real time, and the animation is done using planar geometric primitives. © 2016, Pleiades Publishing, Ltd.",,"Energy utilization; Energy profile; Geometric primitives; Motion modes; Open loop control; Real time; Translational motions; Walking machines; Storms",2-s2.0-85004066483
"Gris I., Rivera D.A., Rayon A., Camacho A., Novick D.","Young merlin: An embodied conversational agent in virtual reality",2016,"ICMI 2016 - Proceedings of the 18th ACM International Conference on Multimodal Interaction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016606691&doi=10.1145%2f2993148.2998534&partnerID=40&md5=57db3f63abe0238b9abcc624caafa485","This paper describes a system for embodied conversational agents developed by Inmerssion and one of the applications-Young Merlin: Trial by Fire -built with this system. In the Merlin application, the ECA and a human interact with speech in virtual reality. The goal of this application is to provide engaging VR experiences that build rapport through storytelling and verbal interactions. The agent is fully automated, and his attitude towards the user changes over time depending on the interaction. The conversational system was built through a declarative approach that supports animations, markup language, and gesture recognition. Future versions of Merlin will implement multi-character dialogs, additional actions, and extended interaction time. © 2016 ACM.","Embodied conversational agents","Human computer interaction; Interactive computer systems; Markup languages; User interfaces; Conversational systems; Embodied conversational agent; Extended interaction; Fully automated; Verbal interaction; Virtual reality",2-s2.0-85016606691
"Michalski A., Stopa M., Miśkowiak B.","Use of multimedia technology in the doctor- patient relationship for obtaining patient informed consent",2016,"Medical Science Monitor",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994607973&doi=10.12659%2fMSM.894147&partnerID=40&md5=99ecc73a67fd77ef9b12031841050369","Patient informed consent for surgery or for high-risk methods of treatment or diagnosis means that unlawful breach of the patient’s personal interests is avoided and the patient accepts the risk of surgery and takes the brunt of it. Patient awareness - their knowledge of the condition and circumstances of continued therapeutic procedure, including offered and available methods of treatment and their possible complications - constitutes a particular aspect of the informed-consent process. The rapid development of technologies and methods of treatment may cause communication problems between the doctor and the patient regarding the scope and method of patient education prior to surgery. The use of multimedia technology (e.g., videos of surgical procedures, computer animation, and graphics), in addition to media used in preoperative patient education, may be a factor in improving the quality of the informed consent process. Studies conducted in clinical centers show that with use of multimedia technology, patients remember more of the information presented. The use of new technology also makes it possible to reduce the difference in the amount of information assimilated by patients with different levels of education. The use of media is a way to improve the quality of preoperative patient education and, at the same time, a step towards their further empowerment in the healing process. © Med Sci Monit, 2016.","Informed consent; Multimedia; Physician-patient relations","arthroscopy; computer graphics; diagnostic procedure; doctor patient relation; empowerment; endoscopic surgery; health care access; human; informed consent; knowledge; laparoscopic surgery; medicolegal aspect; multimedia technology; paternalism; patient education; patient self-determination act; preoperative care; refractive surgery; Review; technology; ulcer healing; urologic surgery; comprehension; multimedia; patient satisfaction; procedures; questionnaire; Comprehension; Humans; Informed Consent; Multimedia; Patient Education as Topic; Patient Satisfaction; Physician-Patient Relations; Preoperative Care; Surveys and Questionnaires",2-s2.0-84994607973
"Ahmed N.","Multi-view RGB-D synchronized video acquisition and temporally coherent 3D animation reconstruction using multiple kinects",2016,"Feature Detectors and Motion Detection in Video Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015162642&doi=10.4018%2f978-1-5225-1025-3.ch007&partnerID=40&md5=54bda29efac14c662641864b85d193d9","This chapter introduces a system for acquiring synchronized multi-view color and depth (RGB-D) video data using multiple off-the-shelf Microsoft Kinect and methods for reconstructing temporally coherent 3D animation from the multi-view RGB-D video data. The acquisition system is very cost-effective and provides a complete software-based synchronization of the camera system. It is shown that the data acquired by this framework can be registered in a global coordinate system and then can be used to reconstruct the 360-degree 3D animation of a dynamic scene. In addition, a number of algorithms to reconstruct a temporally-coherent representation of a 3D animation without using any template model or a-prior assumption about the underlying surface are also presented. It is shown that despite some limitations imposed by the hardware for the synchronous acquisition of the data, a reasonably accurate reconstruction of the animated 3D geometry can be obtained that can be used in a number of applications. © 2017 by IGI Global. All rights reserved.",,"Animation; Cost effectiveness; Synchronization; Three dimensional computer graphics; Video recording; Acquisition systems; Coherent representations; Global coordinate systems; Microsoft kinect; Synchronous acquisition; Template models; Underlying surface; Video acquisitions; Image reconstruction",2-s2.0-85015162642
"Orlov P., Gorshkova K.","Gaze-based interactive comics",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997112324&doi=10.1145%2f2971485.2996751&partnerID=40&md5=2dce8d5f554ccc2eaab9138a7ebfe7d7","This extended abstract presents a gaze-interactive comics, where page design alters based on the coordinates of a user's gaze. We were analyzing the impact of gaze-based interactivity on the user's impression of the comics the plot comprehension. We found that subjects can use gaze-based interaction for comics viewing without prior training. The subjects who were using the gaze-based interactive technique tend to perceive the story in a slightly more optimistic way compared to those who watched the non-interactive version. However, subjects from both groups described the environment and the main character's emotional state similarly. © 2016 ACM.","Animation.; Comics; Eye Tracker; Gaze-Interactive","Animation; Computer games; Stereo vision; Comics; Emotional state; Extended abstracts; Eye trackers; Gaze-based interaction; Gaze-Interactive; Interactive techniques; Interactivity; Human computer interaction",2-s2.0-84997112324
"Menges R., Sengupta K., Kumar C., Staab S.","EyeGUI: A novel framework for eye-controlled user interfaces",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997542994&doi=10.1145%2f2971485.2996756&partnerID=40&md5=279f1a893b7e509f19665cf4d4d84373","The user interfaces and input events are typically composed of mouse and keyboard interactions in generic applications. Eye-controlled applications need to revise these interactions to eye gestures, and hence design and optimization of interface elements becomes a substantial feature. In this work, we propose a novel eyeGUI framework, to support the development of such interactive eye-controlled applications with many signiffcant aspects, like rendering, layout, dynamic modification of content, support of graphics and animation. © 2016 ACM.","Eye Tracking; Eye-Controlled Interfaces; Gaze Input; Interactive Elements; Visual Feedback","Animation; Computer games; Computer graphics; User interfaces; Visual communication; Design and optimization; Dynamic modifications; Eye controlled user interfaces; Eye-tracking; Gaze Input; Interactive elements; Interface elements; Visual feedback; Human computer interaction",2-s2.0-84997542994
"Zátopek J.","The simulation of a non-linear unstable system of motion, utilising the Solid-Works and Matlab/Simulink extended libraries/toolboxes",2016,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016098872&doi=10.1051%2fmatecconf%2f20167602016&partnerID=40&md5=91de7b4764cf104348cfab4e6356215f","This text discusses the use and integration of various support software tools for the purpose of designing the motion control law governing mechanical structures with strongly non-linear behaviour. The detailed mathematical model is derived using Lagrange Equations of the Second Type. The physical model was designed by using SolidWorks 3D CAD software and a SimMechanics library. It extends Simulink with modelling tools for the simulation of mechanical ""multi-domain"" physical systems. The visualization of Simulink outputs is performed using the 3D Animation toolbox. Control law-designed on the basis of the mathematical model, is tested for both models (i.e. mathematical and physical) and the regulatory processes' results are compared. © 2016 The Authors, published by EDP Sciences.",,"Computer aided software engineering; Computer circuits; Control theory; Equations of motion; MATLAB; Three dimensional computer graphics; Lagrange equation; MATLAB /simulink; Mechanical structures; Modelling tools; Nonlinear behaviours; Physical systems; Regulatory process; Unstable system; Computer aided design",2-s2.0-85016098872
"Bousse E., Degueule T., Vojtisek D., Mayerhofer T., Deantoni J., Combemale B.","Execution framework of the GEMOC studio (Tool Demo)",2016,"SLE 2016 - Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, co-located with SPLASH 2016",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006753302&doi=10.1145%2f2997364.2997384&partnerID=40&md5=3d76d395d63e4aeba686346b054d5ac3","The development and evolution of an advanced modeling environment for a Domain-Specific Modeling Language (DSML) is a tedious task, which becomes recurrent with the increasing number of DSMLs involved in the development and management of complex software-intensive systems. Recent efforts in language workbenches result in advanced frameworks that automatically provide syntactic tooling such as advanced editors. However, defining the execution semantics of languages and their tooling remains mostly hand crafted. Similarly to editors that share code completion or syntax highlighting, the development of advanced debuggers, animators, and others execution analysis tools shares common facilities, which should be reused among various DSMLs. In this tool demonstration paper, we present the execution framework offered by the GEMOC studio, an Eclipse-based language and modeling workbench. The framework provides a generic interface to plug in different execution engines associated to their specific metalanguages used to define the discrete-event operational semantics of DSMLs. It also integrates generic runtime services that are shared among the approaches used to implement the execution semantics, such as graphical animation or omniscient debugging.","Debugging; Domain-specific modeling language; Language and modeling workbenches; Model execution","Animation; Computer debugging; Computer programming languages; Program debugging; Semantics; Specification languages; Studios; Syntactics; Domain specific modeling languages; Execution framework; Execution semantics; Language and modeling workbenches; Language workbenches; Model executions; Omniscient debugging; Operational semantics; Modeling languages",2-s2.0-85006753302
"Ibrahim N., Ahmad W.F.W., Shafie A.","A study on design principles and requirements for multimedia application development: MFolktales application for children's education",2016,"2015 International Symposium on Mathematical Sciences and Computing Research, iSMSC 2015 - Proceedings",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995680357&doi=10.1109%2fISMSC.2015.7594055&partnerID=40&md5=9a2b7eeefe474d63952df2056bac4802","MFolktales is a multimedia application that contains Animation Module and interactivity modules which aim to promote Malay folk stories to children. This research is limited to children aged 5 to 7 years old. Therefore, approaches in developing animated multimedia applications are studied so that they can suit the children's interest and at the same time can act as a tool for learning. This paper discusses the study on design principles and requirements for multimedia application development which covers suitable learning theories, learning taxonomy, modules, user interface principles, and usability that are appropriate with the application developed. MFolktales application was developed based on the results of the study. This paper also provides some discussions regarding the guidelines utilized in developing the prototype. Finally, a set of usability questions was given to 30 parents who have children aged between 3 to 12 years old to evaluate the usability level of the developed prototype. The results showed that majority of the respondents gave a positive feedback on the developed MFolktales application. © 2015 IEEE.","animation; child-computer interaction; folktales; mobile application","Animation; Computation theory; User interfaces; Animation modules; Child-computer interactions; Design Principles; folktales; Interactivity; Learning Theory; Mobile applications; Multimedia applications; Education",2-s2.0-84995680357
"Girwidz R.V.","Visualizing dipole radiation",2016,"European Journal of Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994728061&doi=10.1088%2f0143-0807%2f37%2f6%2f065206&partnerID=40&md5=72a796af3e62c440872926bf3d838956","The Hertzian dipole is fundamental to the understanding of dipole radiation. It provides basic insights into the genesis of electromagnetic waves and lays the groundwork for an understanding of half-wave antennae and other types. Equations for the electric and magnetic fields of such a dipole can be derived mathematically. However these are very abstract descriptions. Interpreting these equations and understanding travelling electromagnetic waves are highly limited in that sense. Visualizations can be a valuable supplement that vividly present properties of electromagnetic fields and their propagation. The computer simulation presented below provides additional instructive illustrations for university lectures on electrodynamics, broadening the experience well beyond what is possible with abstract equations. This paper refers to a multimedia program for PCs, tablets and smartphones, and introduces and discusses several animated illustrations. Special features of multiple representations and combined illustrations will be used to provide insight into spatial and temporal characteristics of field distributions - which also draw attention to the flow of energy. These visualizations offer additional information, including the relationships between different representations that promote deeper understanding. Finally, some aspects are also illustrated that often remain unclear in lectures. © 2016 IOP Publishing Ltd.","animations; dipole radiation; half-wave dipole; Hertzian dipole; illustrations; multimedia visualization","Animation; Circular waveguides; Dipole antennas; Electromagnetic fields; Electromagnetic waves; Magnetic fields; Multimedia systems; Dipole radiations; Half-wave dipole; Hertzian dipole; illustrations; Multimedia visualization; Visualization",2-s2.0-84994728061
"Thai T., Polly P.","Exploring the usefulness of adaptive elearning laboratory environments in teaching medical science",2016,"Data Mining And Learning Analytics: Applications in Educational Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017411151&doi=10.1002%2f9781118998205.ch9&partnerID=40&md5=3bd6d46facb6befde972c46011ed055b","This chapter highlights some of the software used in the Department of Pathology at University of New South Wales (UNSW) Australia for learning and teaching that enhances student engagement. In the Department of Pathology, UNSW Australia, a number of different types of software are used to capture data about the way science students learn. An example of this includes the use of electronic portfolio (ePortfolio) to enhance student learning through reflective practice. The pedagogical benefits of ePortfolio use are defined and there are vast opportunities to mine data from student ePortfolios to better understand learning patterns and behavior. More recently, researchers have started to explore student ePortfolio content alongside the objective analytics provided with its use, such as frequency and duration of ePortfolio entries, in order to better understand students' learning patterns. Virtual laboratories (vLabs) are computer-based, interactive laboratory-based learning environments that can include animations, simulations, virtual reality, and other media such as audio/video recordings. © 2016 by John Wiley & Sons, Inc. All rights reserved.","Data mining; Educational software; EPortfolio; Laboratory-based learning environments; Learning patterns; New South Wales Australia; Virtual laboratories",,2-s2.0-85017411151
"Du H., Zhao Y., Han J., Wang Z., Song G.","Data fusion of multiple kinect sensors for a rehabilitation system",2016,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009115421&doi=10.1109%2fEMBC.2016.7591818&partnerID=40&md5=8eea3d878c6bf943295d13d4a284b358","Kinect-like depth sensors have been widely used in rehabilitation systems. However, single depth sensor processes limb-blocking, data loss or data error poorly, making it less reliable. This paper focus on using two Kinect sensors and data fusion method to solve these problems. First, two Kinect sensors capture the motion data of the healthy arm of the hemiplegic patient; Second, merge the data using the method of Set-Membership-Filter (SMF); Then, mirror this motion data by the Middle-Plane; In the end, control the wearable robotic arm driving the patient's paralytic arm so that the patient can interactively and initiatively complete a variety of recovery actions prompted by computer with 3D animation games. © 2016 IEEE.",,"algorithm; computer simulation; devices; human; movement (physiology); rehabilitation; statistics; theoretical model; video game; Algorithms; Computer Simulation; Humans; Models, Theoretical; Movement; Rehabilitation; Statistics as Topic; Video Games",2-s2.0-85009115421
"Aristidou A.","Hand tracking with physiological constraints",2016,"Visual Computer",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991060674&doi=10.1007%2fs00371-016-1327-8&partnerID=40&md5=19a6c51ec4a2bb5e9d71c079e9a14bd6","Articulated hand tracking systems have been commonly used in virtual reality applications, including systems with human–computer interaction or interaction with game consoles; hand pose estimation has various other applications comprising sign language recognition and animation synthesis. The advanced technological achievements in motion capture over the last decade allow data acquisition with high accuracy and low cost. However, due to the high complexity of the human hand, it is still challenging to animate a hand model able to deal in details with the anatomical and physiological constraints of the hand. In this paper, we present a simple and efficient methodology for tracking and reconstructing 3D hand poses. Using an optical motion capture system, where markers are positioned at strategic points, we manage to acquire the movement of the hand and establish its orientation using a minimum number of markers. An Inverse Kinematics solver was then employed to control the postures of the hand, subject to physiological constraints that restrict the allowed movements to a feasible and natural set. The proposed methodology produces smooth and biomechanically correct movements, while the required processing time remains low, enabling an effective real-time hand motion tracking and reconstruction system. © 2016 Springer-Verlag Berlin Heidelberg","Geometric Algebra; Hand Tracking; Inverse Kinematics; Motion Capture; Physiological Constraints","Animation; Computer games; Data acquisition; Gesture recognition; Human computer interaction; Inverse kinematics; Inverse problems; Kinematics; Physiological models; Physiology; Virtual reality; Articulated hand tracking; Geometric Algebra; Hand tracking; Motion capture; Optical motion capture; Physiological Constraints; Reconstruction systems; Sign Language recognition; Palmprint recognition",2-s2.0-84991060674
"Costigan T., Gerdelan A., Carrigan E., McDonnell R.","Improving blendshape performance for crowds with GPU and GPGPU Techniques",2016,"Proceedings - Motion in Games 2016: 9th International Conference on Motion in Games, MIG 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994876227&doi=10.1145%2f2994258.2994275&partnerID=40&md5=21d567d0d133f46ff253314e650ca217","For real-time applications, blendshape animations are usually calculated on the CPU, which are slow to animate, and are therefore generally limited to only the closest level of detail for a small number of characters in a scene. In this paper, we present a GPU based blendshape animation technique. By storing the blendshape model (including animations) on the GPU, we are able to attain significant speed improvements over CPU-based animation. We also find that by using compute shaders to decouple rendering and animation we can improve performance when rendering a crowd animation. Further gains are also made possible by using a smaller subset of blendshape expressions, at the cost of expressiveness. However, the quality impact can be minimised by selecting this subset carefully. We discuss a number of potential metrics to automate this selection. © 2016 Copyright held by the owner/author(s).","Facial animation; Performance","Program processors; Rendering (computer graphics); Based animations; Blendshape animation; Crowd animation; Facial animation; Improve performance; Performance; Real-time application; Speed improvement; Animation",2-s2.0-84994876227
"Sohre N., Guy S.J.","A data-driven method for variation in animated smiles (extended abstract)",2016,"Proceedings - Motion in Games 2016: 9th International Conference on Motion in Games, MIG 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994895350&doi=10.1145%2f2994258.2994290&partnerID=40&md5=c5e424b341065d5d859d0ef6a312bb0d","Animated digital characters play an important role in virtual experiences. In this work, we utilize data from a large scale user study as training data for a generative model for producing a variety of animated smiles. Our method involves a four stage process that samples a variety of facial expressions,and annotates them with perceived happiness from the user study. The expressions are then transformed into a standardized space and used by a non-parametric classifier to predict happiness of new smiles. © 2016 Copyright held by the owner/author(s).","Computer graphics; Data-driven facial animation; Digital character emotion","Computer graphics; Data-driven methods; Digital characters; Extended abstracts; Facial animation; Facial Expressions; Generative model; Non-parametric classifiers; Training data; Animation",2-s2.0-84994895350
"Lucas G., Szablowski E., Gratch J., Feng A., Huang T., Boberg J., Shapiro A.","The effect of operating a virtual doppleganger in a 3D simulation",2016,"Proceedings - Motion in Games 2016: 9th International Conference on Motion in Games, MIG 2016",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994885318&doi=10.1145%2f2994258.2994263&partnerID=40&md5=7275230fcd657d3f5c9b1f7da724d9c8","Recent advances in scanning technology have enabled the widespread capture of 3D character models based on human subjects. Intuition suggests that, with these new capabilities to create avatars that look like their users, every player should have his or her own avatar to play video games or simulations. We explicitly test the impact of having one's own avatar (vs. a yoked control avatar) in a simulation (i.e., maze running task with mines). We test the impact of avatar identity on both subjective (e.g., feeling connected and engaged, liking avatar's appearance, feeling upset when avatar's injured, enjoying the game) and behavioral variables (e.g., time to complete task, speed, number of mines triggered, riskiness of maze path chosen). Results indicate that having an avatar that looks like the user improves their subjective experience, but there is no significant effect on how users perform in the simulation. © 2016 ACM.","3D; Animation; Avatar; Gesture; Scanning; Simulation","Animation; Human computer interaction; Interactive computer graphics; Scanning; 3D characters; 3D simulations; Avatar; Gesture; Human subjects; Running tasks; Simulation; Subjective experiences; Three dimensional computer graphics",2-s2.0-84994885318
"Ravenet B., Bevacqua E., Cafaro A., Ochs M., Pelachaud C.","Perceiving attitudes expressed through nonverbal behaviors in immersive virtual environments",2016,"Proceedings - Motion in Games 2016: 9th International Conference on Motion in Games, MIG 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994834962&doi=10.1145%2f2994258.2994280&partnerID=40&md5=552bdc2ba00eb11153d964a1b31201ab","Virtual Reality and immersive experiences, which allow players to share the same virtual environment as the characters of a virtual world, have gained more and more interest recently. In order to conceive these immersive virtual worlds, one of the challenges is to give to the characters that populate them the ability to express behaviors that can support the immersion. In this work, we propose a model capable of controlling and simulating a conversational group of social agents in an immersive environment. We describe this model which has been previously validated using a regular screen setting and we present a study for measuring whether users recognized the attitudes expressed by virtual agents through the real-time generated animations of nonverbal behavior in an immersive setting. Results mirrored those of the regular screen setting thus providing further insights for improving players experiences by integrating them into immersive simulated group conversations with characters that express different interpersonal attitudes. © 2016 Copyright held by the owner/author(s).","Group simulation; Immersive system; Nonverbal behavior; Virtual agent","Animation; Interactive computer graphics; Group simulation; Immersive environment; Immersive System; Immersive virtual environments; Interpersonal attitudes; Nonverbal behavior; Virtual agent; Virtual worlds; Virtual reality",2-s2.0-84994834962
"Alexanderson S., O'Sullivan C., Beskow J.","Robust online motion capture labeling of finger markers",2016,"Proceedings - Motion in Games 2016: 9th International Conference on Motion in Games, MIG 2016",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994806827&doi=10.1145%2f2994258.2994264&partnerID=40&md5=a022659323d2d056769676ce7d19f8d0","Passive optical motion capture is one of the predominant technologies for capturing high fidelity human skeletal motion, and is a workhorse in a large number of areas such as bio-mechanics, film and video games. While most state-of-the-art systems can automatically identify and track markers on the larger parts of the human body, the markers attached to fingers provide unique challenges and usually require extensive manual cleanup. In this work we present a robust online method for identification and tracking of passive motion capture markers attached to the fingers of the hands. The method is especially suited for large capture volumes and sparse marker sets of 3 to 10 markers per hand. Once trained, our system can automatically initialize and track the markers, and the subject may exit and enter the capture volume at will. By using multiple assignment hypotheses and soft decisions, it can robustly recover from a difficult situation with many simultaneous occlusions and false observations (ghost markers). We evaluate the method on a collection of sparse marker sets commonly used in industry and in the research community. We also compare the results with two of the most widely used motion capture platforms: Motion Analysis Cortex and Vicon Blade. The results show that our method is better at attaining correct marker labels and is especially beneficial for real-time applications. © 2016 Copyright held by the owner/author(s).","Animation; Hand capture; Labeling; Motion capture","Animation; Labeling; Hand capture; Motion capture; Online methods; Optical motion capture; Real-time application; Research communities; Skeletal motions; State-of-the-art system; Human computer interaction",2-s2.0-84994806827
"Zhou K., Liu Z., He G., Chen T., Liu T., Liu C.","GPU-accelerated cloth animation based on module division",2016,"Xitong Fangzhen Xuebao / Journal of System Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012952418&partnerID=40&md5=70830e23d0d4d44a59763fef3b581704","In order to improve the simulation speed of cloth animation, a module division parallel computing method was proposed by studying two kinds of cloth simulation models with dynamics and position based dynamics (PBD). A computing task was divided into a plurality of independent blocks by the way of data block. GPU parallel computing was used within the data block to improve the real-time performance and robustness of the cloth simulation. The applicability and effectiveness of the algorithm were verified under different scenarios and stochastic wind field. Experimental results show that under the same conditions, the proposed method can effectively improve the simulation speed. Moreover, it can meet real-time requirements at higher simulation accuracy. © 2016, The Editorial Board of Journal of System Simulation. All right reserved.","Cloth animation; Dynamic simulation; GPU parallel computer; Module division; Wind field",,2-s2.0-85012952418
"He G., Yang K., Jin Y., Chen Q., Li H., Pan Z.","Interactive illustration technologies for energy stations using Unity3D",2016,"Xitong Fangzhen Xuebao / Journal of System Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013006967&partnerID=40&md5=2fabc7d8d558eebc9c71b338e30f9c60","This paper presents one web-based interactive illustration system for energy stations using Unity3D as render engine. Interaction, scene rendering and data-driven visual analysis are the key technologies for this study. One low-coupling logical framework of virtual illustration is designed for five view layers using state pattern. From the viewpoint of event response and trigger on-demand, one concise human-computer-interaction interface is carried out. High-quality visualization of energy station is realized using Unity3D, which includes dynamic texture, water animation in water pipe, modeling and bake. Json database is used as transfer hub for external data access. Thus the dynamic graphs of real-time data are shown on the web. Implementation of the above design validates the advantages of enhancing the scene realistic and user experience. © 2016, The Editorial Board of Journal of System Simulation. All right reserved.","Data visualization; Energy station illustration; Online interaction; Unity3D; Virtual reality",,2-s2.0-85013006967
"Schulz S., Lier F., Kipp A., Wachsmuth S.","Humotion - A human inspired gaze control framework for anthropomorphic robot heads",2016,"HAI 2016 - Proceedings of the 4th International Conference on Human Agent Interaction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994504560&doi=10.1145%2f2974804.2974827&partnerID=40&md5=873a53f8dd044db82b8693ce2c28cde4","In recent years, an attempt is being made to control robots more intuitive and intelligible by exploiting and integrating anthropomorphic features to boost social human-robot interaction. The design and construction of anthropomorphic robots for this kind of interaction is not the only challenging issue - smooth and expectation-matching motion control is still an unsolved topic. In this work we present a highly configurable, portable, and open control framework that facilitates anthropomorphic motion generation for humanoid robot heads by enhancing state-of-the-art neck-eye coordination with human-like eyelid saccades and animation. On top of that, the presented framework supports dynamic neck offset angles that allow animation overlays and changes in alignment to the robots communication partner while retaining visual focus on a given target. In order to demonstrate the universal applicability of the proposed ideas we used this framework to control the Flobi and the iCub robot head, both in simulation and on the physical robot. In order to foster further comparative studies of different robot heads, we will release all software, based on this contribution, under an open-source license. Copyright © 2016 ACM.",,"Animation; Anthropomorphic robots; Human computer interaction; Machine design; Open source software; Open systems; Robots; Visual servoing; Communication partners; Comparative studies; Design and construction; Eye coordination; Motion generation; Open source license; Social human-robot interactions; State of the art; Human robot interaction",2-s2.0-84994504560
"Zhang S., Dong H., Zhang Z., Wu Q.","The role of control based on three-dimensional human model",2016,"ICCSE 2016 - 11th International Conference on Computer Science and Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994125649&doi=10.1109%2fICCSE.2016.7581685&partnerID=40&md5=370ca3d65b5bb97aa9ea4c6eb13ed4f9","The reproduction of a virtual human's behavior technology has become one of the hot research topics in recent years. This article discusses the problems and solutions might be encountered in the research of generating realistic human behavior animation. First of all, we analysis the content of three-dimensional model file formed with 3DS format how to reproduce an all-round mode. Secondly, we analysis the content of skeleton file in BVH format, reproduces the skeleton information and motion information contained in the file, and forming a skeleton animation. Then, we combine motion data and model of human body, and produce a real-time skinned mesh animation. Eventually, we have developed a system based on OpenGL graphics library and the MFC Framework. The input is the model file produced by three-dimensional modeling software and the skeleton file exported by motion capture equipment, and the output is a model animation. © 2016 IEEE.","3D model; motion control; skeleton animation","Animation; Application programming interfaces (API); Computer graphics; Education computing; Engineering education; Motion control; Musculoskeletal system; Virtual reality; 3-d modeling; Hot research topics; Model animations; Motion information; OpenGL graphics; Problems and Solutions; Three-dimensional human modeling; Three-dimensional model; Behavioral research",2-s2.0-84994125649
"Miyai A., Yamaguchi Y.","New approach to camerawork skills education for 3D/S3D computer graphics animation",2016,"Computers and Graphics (Pergamon)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980350455&doi=10.1016%2fj.cag.2016.07.003&partnerID=40&md5=8bcdd58cb9d3c0719f118edf60618a52","Many vocational schools and universities offer lectures on non-stereoscopic 3D computer graphics (3DCG) animation production, as well as practical 3DCG software operation, modeling, and animation production. However, relatively few of these educational institutions provide lectures on stereoscopic 3D (S3D). To address this gap, we developed two 15-week syllabuses with educational materials, which focused on both knowledge-based and skills-based education about 3DCG animation and S3D computer graphics (S3DCG) animation production, considering the potential employment of students in animation studios. Our investigation confirmed that the knowledge and skills of the subjects improved in this study, so we presented a report on the effectiveness of the educational materials for S3DCG animation production education at the Education Symposium of SIGGRAPH Asia 2015. By developing these educational materials, we reaffirmed the importance of camerawork skills education, which may be regarded as the cornerstone of 3DCG animation and S3DCG animation production. However, camerawork skills education in 3DCG animation classes remains limited in vocational schools and universities at present. We hypothesized that one of the reasons for the paucity of camerawork skills education is the lack of suitable educational materials for practical classes in the use of 3DCG software. Indeed, educational materials that allow teachers to begin camerawork skills education for 3DCG and S3DCG animation production without preparation are greatly lacking. Furthermore, modeling and character animation are regarded as essential before camerawork practice. Camerawork practice can be started immediately if sufficient educational materials are provided. The educational materials that we developed are suitable for S3DCG but also for 3DCG camerawork practice. In this study, we present the camerawork skills education and evaluation methods involved in the educational materials developed for the S3D lectures and for camerawork practical classes in S3DCG animation. We then discuss the experimental classes in which we used the educational materials and we report the results of S3D knowledge tests and camerawork practical tests, which were conducted in order to measure the learning/education outcomes for the participating subjects, as well as the results of a survey that focused on their subjective experiences. The experimental results clearly demonstrated improvements in both the knowledge and skills of subjects, thereby confirming the effectiveness of the camerawork educational materials. We suggest that if students with knowledge of S3D and 3DCG animation are well-practiced in the use of these educational materials, their skills in S3DCG camerawork would improve markedly. © 2016 Elsevier Ltd","Camerawork; Computer graphics; Educational material; Educational outcome; Skills-based; Stereoscopic 3D","Animation; Computer graphics; Education; Interactive computer graphics; Knowledge based systems; Societies and institutions; Stereo image processing; Teaching; Three dimensional computer graphics; 3D computer graphics; Camerawork; Character animation; Educational institutions; Educational materials; Educational outcome; Skills-based; Subjective experiences; Students",2-s2.0-84980350455
"Shang L., Feng X.-B., Zhu D.-M., Wang Z.-Q., Wang Y.-J.","Synthesis of coastal swell animation driven by skeleton",2016,"Ruan Jian Xue Bao/Journal of Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991096051&doi=10.13328%2fj.cnki.jos.005081&partnerID=40&md5=4685de011f8d5f87a1141795939e5a4b","The rapid modeling and controllable animation of large scale water surface and waves have always been hot issues in computer graphics research. However, due to the complexity and irregularity of natural waves, the existing simulation methods of waves cannot make a good tradeoff between computational efficiency and realism. In this paper, a technique is presented to extract features of the wave shape and generate controllable wave animation rapidly. Taking the captured video of outdoor costal wave as input, this technique first uses mathematical morphology algorithms to resolve wave's mask and skeleton from water video sequences as wave's features. Then it employs these features to control the shape of waves by reusing of height field to generate various wave animations. Consequently, the new method can produce controllable swell wave moving patterns under simple interaction with a small computational cost. Experiments show that the presented method can generate natural wave deformation effect with a simple and intuitive control process. © Copyright 2016, Institute of Software, the Chinese Academy of Sciences. All rights reserved.","Fluid animation; Height change; Shape control; Skeleton driven; Wave model","Computational efficiency; Computer graphics; Mathematical morphology; Musculoskeletal system; Fluid animation; Height change; Shape control; Skeleton driven; Wave modeling; Animation",2-s2.0-84991096051
"Milliez A., Guay M., Cani M.-P., Gross M., Sumner R.W.","Programmable Animation Texturing using Motion Stamps",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992626260&doi=10.1111%2fcgf.13004&partnerID=40&md5=948653182b33f7e13e09a6d2cb69e5e8","Our work on programmable animation texturing enhances the concept of texture mapping by letting artists stylize arbitrary animations using elementary animations, instantiated at the scale of their choice. The core of our workflow resides in two components: we first impose structure and temporal coherence over the animation data using a novel radius-based animation-aware clustering. The computed clusters conform to the user-specified scale, and follow the underlying animation regardless of its topology. Extreme mesh deformations, complex particle simulations, or simulated mesh animations with ever-changing topology can therefore be handled in a temporally coherent way. Then, in analogy to fragment shaders that specify an output color based on a texture and a collection of properties defined per vertex (position, texture coordinate, etc.), we provide a programmable interface to the user, letting him or her specify an output animation based on the collection of properties we extract per cluster (position, velocity, etc.). We equip elementary animations with a collection of parameters that are exposed in our programmable system and enables users to script the animated textures depending on properties of the input cluster. We demonstrate the power of our system with complex animated textures created with minimal user input. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Mesh generation; Topology; Based animations; Complex particles; Mesh deformation; Programmable systems; Temporal coherence; Texture coordinates; Texture mapping; Two-component; Animation",2-s2.0-84992626260
"Kuo M.-H., Yang Y.-L., Chu H.-K.","Feature-Aware Pixel Art Animation",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992663755&doi=10.1111%2fcgf.13038&partnerID=40&md5=bae6ac35d4acfddd8ae37d502d5d5270","Pixel art is a modern digital art in which high resolution images are abstracted into low resolution pixelated outputs using concise outlines and reduced color palettes. Creating pixel art is a labor intensive and skill-demanding process due to the challenge of using limited pixels to represent complicated shapes. Not surprisingly, generating pixel art animation is even harder given the additional constraints imposed in the temporal domain. Although many powerful editors have been Designed to facilitate the creation of still pixel art images, the extension to pixel art animation remains an unexplored direction. Existing systems typically request users to craft individual pixels frame by frame, which is a tedious and error-prone process. In this work, we present a novel animation framework tailored to pixel art images. Our system bases on conventional key-frame animation framework and state-of-the-art image warping techniques to generate an initial animation sequence. The system then jointly optimizes the prominent feature lines of individual frames respecting three metrics that capture the quality of the animation sequence in both spatial and temporal domains. We demonstrate our system by generating visually pleasing animations on a variety of pixel art images, which would otherwise be difficult by applying state-of-the-art techniques due to severe artifacts. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Animation; Image processing; Complicated shape; Error-prone process; Existing systems; High resolution image; Labor intensive; Prominent features; State of the art; State-of-the-art techniques; Pixels",2-s2.0-84992663755
"Smith A.R.","The Dawn of Digital Light",2016,"IEEE Annals of the History of Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018465178&doi=10.1109%2fMAHC.2015.51&partnerID=40&md5=0b5b51ae90725307ef4c8d37a329393b","Digital pictures and computers are now inseparable, so it's surprising how generally unremarked their association was in the beginning. Records reveal that the first digital pictures - the first still pictures, videogames, and computer animations - were made on the earliest computers. Historians have noted this before, but individually without a unifying context. This article shows that the original digital pictures were associated with the original computers in the late 1940s and early 1950s. This fresh perspective on digital pictures establishes a different take on the history of early computers and unifies the history of digital light itself. © 1992-2011 IEEE.","computer graphics; digital light; history of computing; image processing","Animation; Computer graphics; Image processing; Computer animation; Digital picture; History of computing; Video game; History",2-s2.0-85018465178
"Wrózyński R., Sojka M., Pyszny K.","The application of GIS and 3D graphic software to visual impact assessment of wind turbines",2016,"Renewable Energy",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966762372&doi=10.1016%2fj.renene.2016.05.016&partnerID=40&md5=18861de334975a63e5dbd71e65df7926","Visibility of wind turbines is one of the most subjective factors influencing the decision on the potential location to build wind turbines. The spatial extent of the visual impact of wind turbines usually covers a wide area. The paper proposes a new method for visual impact assessment of wind turbines. The proposed method uses GIS tools and 3D graphic software for developing three-dimensional models and computer animations. The developed method was verified in the field. The usefulness of this method is presented on the example of the Poznań Metropolis in Poland, where construction of wind turbines is considered. The analyzes related to visual assessment of the effect of wind turbines with a height of 150 m above ground should be performed over a distance reduced to 12 km. Visibility range of wind turbines depends on the position of the observer in relation to the wind turbine. For longitudinal, diagonal and frontal views the visual impact is limited to 4, 10 and 12 km, respectively.The results obtained using the method proposed were compared with those provided by the other methods used to assess the visibility of wind turbines. As a conclusion, the advantages of this method in favor of its popularization were described. © 2016 Elsevier Ltd.","Blender; Poland; Visibility analysis; Visual impact assessment; Wind turbine","Animation; Application programs; Blending; Visibility; Blender; Computer animation; Poland; Spatial extent; Three-dimensional model; Visibility analysis; Visual assessments; Visual impacts; Wind turbines; assessment method; environmental impact; GIS; land use location; software; visibility; visual analysis; wind turbine; Poland [Central Europe]; Poznan [Wielkopolskie]; Wielkopolskie",2-s2.0-84966762372
"Rastner P., Joerg P.C., Huss M., Zemp M.","Historical analysis and visualization of the retreat of Findelengletscher, Switzerland, 1859–2010",2016,"Global and Planetary Change",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985930754&doi=10.1016%2fj.gloplacha.2016.07.005&partnerID=40&md5=fa87cdb99cc716f33247d262ba63679f","Since the end of the Little Ice Age around 1850, glaciers in Europe have strongly retreated. Thanks to early topographic surveys in Switzerland, accurate maps are available, which enable us to trace glacier changes back in time. The earliest map for all of Switzerland that is usable for a detailed analysis is the Dufour map from around 1850 with subsequent topographic maps on a ~ 20 year interval. Despite the large public and scientific interest in glacier changes through time, this historic dataset has not yet been fully utilized for topographic change assessment or visualization of historic glacier extents. In this study, we use eleven historical topographic maps and more recent digital datasets for the region of Zermatt to analyze geometric changes (length, area and volume) of Findelengletscher as well as for creating animations of glacier evolution through time for use in public communication. All maps were georeferenced, the contour lines digitized, and digital elevation models (DEMs) created and co-registered. Additional digital data like the SRTM X-band DEM and high resolution laser scanning data were used to extend the analysis until 2010. Moreover, one independent DEM from aerial photogrammetry was used for comparison. During the period 1859–2010, Findelengletscher lost 3.5 km of its length (6.9 km in 2010), 4.42 ± 0.13 km2 of its area (15.05 ± 0.45 km2 in 2010) and 1.32 ± 0.52 km3 of its volume. The average rate of thickness loss is 0.45 ± 0.042 m yr− 1 for the 151 years period. Four periods with high thickness change from − 0.56 m ± 0.28 yr− 1 (1859–1881), − 0.40 ± 0.08 m yr− 1 (1937–1965), − 0.90 ± 0.31 m yr− 1 (1995–2000) and − 1.18 ± 0.02 m yr− 1 (2000–2005) have been identified. Small positive thickness changes were found for the periods 1890–1909 (+ 0.09 ± 0.46 m yr− 1) and 1988–1995 (+ 0.05 ± 0.24 m yr− 1). During its retreat with intermittent periods of advance, the glacier separated into three parts. The above changes are demonstrated through an animation (available from the supplementary material), which has been created to inform the general public. © 2016 Elsevier B.V.","Computer animation; DEMs; Glacier; Historical maps; Public communication of science","Animation; Glaciers; Maps; Photogrammetry; Visualization; Aerial photogrammetry; Computer animation; DEMs; Digital elevation model; Historical maps; Public communications; Topographic changes; Topographic surveys; Surveying; communication; computer simulation; data set; digital elevation model; glacier dynamics; glacier retreat; historical record; ice thickness; Little Ice Age; map; photogrammetry; Shuttle Radar Topography Mission; spatiotemporal analysis; topographic mapping; visualization; Findel Glacier; Switzerland; Valais; Zermatt",2-s2.0-84985930754
"Mani I.","Animation motion in NarrativeML",2016,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010607534&doi=10.4230%2fOASIcs.CMN.2016.3&partnerID=40&md5=39307c164964511d593ba85aea1a9ac7","This paper describes qualitative spatial representations relevant to cartoon motion incorporated into NarrativeML, an annotation scheme intended to capture some of the core aspects of narrative. These representations are motivated by linguistic distinctions drawn from cross-linguistic studies. Motion is modeled in terms of transitions in spatial configurations, using an expressive dynamic logic with the manner and path of motion being derived from a few basic primitives. The manner is elaborated to represent properties of motion that bear on character affect. Such representations can potentially be used to support cartoon narrative summarization and question-answering. The paper discusses annotation challenges, and the use of computer vision to help in annotation. Work is underway on annotating a cartoon corpus in terms of this scheme. © Inderjeet Mani.","Cinematography; Motion; Narrative; NarrativeML; Qualitative reasoning","Computation theory; Computational methods; Linguistics; Natural language processing systems; Cinematography; Motion; Narrative; NarrativeML; Qualitative reasoning; Computer vision",2-s2.0-85010607534
"Shaw F., Theobald B.-J.","Expressive Modulation of Neutral Visual Speech",2016,"IEEE Multimedia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997241526&doi=10.1109%2fMMUL.2016.63&partnerID=40&md5=ed5ec4d400893b5a12e424a5474aac7c","Expressive speech animation, or expressive visual speech, is the process by which some representation of facial features (graphical, statistical, or otherwise) is smoothly changed over time to articulate verbal speech, convey emotion through facial expression, or express other characteristics such as visual prosody. Used extensively in the production of movies and computer games, current techniques for visual speech animation are slow, laborious, and expensive. Therefore, efforts to automate the complex processes involved are of great interest to these multibillion-dollar industries. In this article, the authors describe a method for transforming speech animation between different emotional expressions. When the same sentence is spoken in two different expressive styles, a large proportion of the two sentences is the same. Intuitively, then, after factoring out timing differences, the residual is the expression. Based on earlier work showing two general categories of facial movements in expressive speech-high-frequency speech components (the content) and low-frequency expressive components (the style)-the authors use independent component analysis (ICA) to factorize these movements and show how the energy for different speaking styles is distributed in this space. They transform speaking style by projecting novel animation curves into the low-dimensional ICA space, redistributing the energy in the independent components, and reconstructing the animation by inverting the projection. As they describe, a single ICA model can be used for factoring multiple expressive styles, and their method works on a variety of data types. Evaluations show that viewers can identify the expressive style generated and have difficulty distinguishing transformed animation from ground truth. Finally, they show how their technique can be used to represent complex blends of expression. © 2016 IEEE.","data analysis; expressive visual speech; graphics; intendent component analysis; multimedia; visual speech animation; visualization","Computer games; Data reduction; Data visualization; Flow visualization; Independent component analysis; Speech; Component analysis; Emotional expressions; Facial Expressions; graphics; Independent component analysis(ICA); Independent components; multimedia; Visual speech; Animation",2-s2.0-84997241526
"Wang D., Ge Y., Yang M., Yuan H., Yang Y., Ning T., Cai J.","Fast simulation of fish schooling under realistic sea water",2016,"ICIC Express Letters, Part B: Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989942251&partnerID=40&md5=9606a412fdb587b27b0178f58e9cfa6f","Fish schooling is an important area of research with relevant developments on biomechanics, game animation, robotics and mathematical modeling. In order to simulate swimming behavior of reality, we present a novel simulation method of fish swimming under realistic sea water. In this paper, using spring-mass system, we simulate fish muscles locomotion and acquire behavioral animation featuring artificial fishes, which can yield realistic individual and collective motions. Also, in order to enhance the realism offish schooling under sea water, we give a GPU-based (Graphic Processing Unit) realistic rendering of sea water via simulation of optical effects. The result shows that we could acquire realistic schooling behavior under sea water and obtain a real-time rendering speed. © 2016 ICIC International.","Fish schooling; Graphic processing unit; Real-time rendering; Sea water; Spring-mass system","Animation; Fish; Rendering (computer graphics); Behavioral animation; Collective motions; Fish schoolings; Graphic processing units; Real-time rendering; Realistic rendering; Spring-mass system; Swimming behavior; Seawater",2-s2.0-84989942251
"Widmer S., Wodniok D., Thul D., Guthe S., Goesele M.","Decoupled Space and Time Sampling of Motion and Defocus Blur for Unified Rendering of Transparent and Opaque Objects",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992535828&doi=10.1111%2fcgf.13041&partnerID=40&md5=8345f91f2aac6770813f8f9c5fed1dd7","We propose a unified rendering approach that jointly handles motion and defocus blur for transparent and opaque objects at interactive frame rates. Our key idea is to create a sampled representation of all parts of the scene geometry that are potentially visible at any point in time for the duration of a frame in an initial rasterization step. We store the resulting temporally-varying fragments (t-fragments) in a bounding volume hierarchy which is rebuild every frame using a fast spatial median construction algorithm. This makes our approach suitable for interactive applications with dynamic scenes and animations. Next, we perform spatial sampling to determine all t-fragments that intersect with a specific viewing ray at any point in time. Viewing rays are sampled according to the lens uv-sampling for depth-of-field effects. In a final temporal sampling step, we evaluate the predetermined viewing ray/t-fragment intersections for one or multiple points in time. This allows us to incorporate all standard shading effects including transparency. We describe the overall framework, present our GPU implementation, and evaluate our rendering approach with respect to scalability, quality, and performance. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.6 [Computer Graphics]: Methodology and Techniques—Graphics data structures and data types; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Raytracing","Computer graphics; Quality control; Rasterization; Three dimensional computer graphics; Bounding volume hierarchies; Construction algorithms; Descriptors; GPU implementation; Graphics data structures and data types; I.3.7 [computer graphics]: three-dimensional graphics and realism; Interactive applications; Interactive frame rates; Rendering (computer graphics)",2-s2.0-84992535828
"Cardona L., Saito S.","Temporally Coherent and Artistically Intended Stylization of Feature Lines Extracted from 3D Models",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992666035&doi=10.1111%2fcgf.13011&partnerID=40&md5=e050300d316120f70b059c4d2153dab6","In this paper, we propose a method to maintain the temporal coherence of stylized feature lines extracted from 3D models and preserve an artistically intended stylization provided by the user. We formally define the problem of combining spatio-temporal continuity and artistic intention as a weighted energy minimization problem of competing constraints. The proposed method updates the style properties to provide real-time smooth transitions from current to goal stylization, by assuring first- and second-order temporal continuity, as well as spatial continuity along each stroke. The proposed weighting scheme guarantees that the stylization of strokes maintains motion coherence with respect to the apparent motion of the underlying surface in consecutive frames. This weighting scheme emphasizes temporal continuity for small apparent motions where the human vision system is able to keep track of the scene, and prioritizes the artistic intention for large apparent motions where temporal coherence is not expected. The proposed method produces temporally coherent and visually pleasing animations without the flickering artifacts of previous methods, while also maintaining the artistic intention of a goal stylization provided by the user. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.3 [Computer Graphics]: Picture/Image Generation—Line and curve generation","Computer vision; Descriptors; Energy minimization problem; Human vision systems; Line and Curve Generation; Smooth transitions; Temporal coherence; Temporal continuity; Underlying surface; Computer graphics",2-s2.0-84992666035
"Bazin J.-C., Kuster C.P., Yu G., Martin T., Jacobson A., Gross M.","Physically Based Video Editing",2016,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992533121&doi=10.1111%2fcgf.13039&partnerID=40&md5=066716bfea35ddeb15ae5cfbd3510235","Convincing manipulation of objects in live action videos is a difficult and often tedious task. Skilled video editors achieve this with the help of modern professional tools, but complex motions might still lack physical realism since existing tools do not consider the laws of physics. On the other hand, physically based simulation promises a high degree of realism, but typically creates a virtual 3D scene animation rather than returning an edited version of an input live action video. We propose a framework that combines video editing and physics-based simulation. Our tool assists unskilled users in editing an input image or video while respecting the laws of physics and also leveraging the image content. We first fit a physically based simulation that approximates the object's motion in the input video. We then allow the user to edit the physical parameters of the object, generating a new physical behavior for it. The core of our work is the formulation of an image-aware constraint within physics simulations. This constraint manifests as external control forces to guide the object in a way that encourages proper texturing at every frame, yet producing physically plausible motions. We demonstrate the generality of our method on a variety of physical interactions: rigid motion, multi-body collisions, clothes and elastic bodies. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.3 [Computer Graphics]: Picture/Image Generation—Line and curve generation","Computer graphics; Videodisks; Descriptors; Line and Curve Generation; Multi-body collisions; Physical behaviors; Physical interactions; Physical parameters; Physically-based simulation; Physics-based Simulation; Video signal processing",2-s2.0-84992533121
"Chimurkar V., Sande V., Thute P., Fulmali D.","Effectiveness of traditional demonstration technique and 3-D animated video: A comparative study",2016,"Journal of Datta Meghe Institute of Medical Sciences University",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016303680&partnerID=40&md5=9113e0f086d8f722d863ac716499b3a3","Introduction : E-learning is the new trend in the field of medical education by which the basic understanding is evaluated with increased effectiveness. Routinely for bone demonstration, large number of students is taken. Nowadays various other methods are used to teach such as problem based learning, case based lectures, modular teaching which are interactive and student centred way of learning. This study draws on the improvement of teaching and learning process by use of 3-D animated video demonstration. The main objectives of this research are to explore the results of the use of videos as an educational tool and comparison between routine demonstration technique and 3-D animated video demonstration technique. We concluded that the confidence and learning process in the students can be enhanced by using the computers and 3-D animated demonstration and the 3-D animation video technique is better than the routine demonstration technique. © 2016, Datta Meghe Institute of Medical Sciences Deemed University. All rights reserved.","3-D animated technique; Kiosk; Video demonstration",,2-s2.0-85016303680
"Shershneva V.A., Shkerina L.V., Sidorov V.N., Sidorova T.V., Safonov K.V.","Contemporary didactics in higher education in Russia",2016,"European Journal of Contemporary Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014042173&doi=10.13187%2fejced.2016.17.357&partnerID=40&md5=383848c03e716c564015e396528ac73f","The article presents the theoretical framework for a competency-based approach in higher education. It shows that the general didactic principles of professional direction, interdisciplinary connections, fundamentalization and informatization form the didactic basis for the competency-based training in university. The article also actualizes the integrated use of effective approaches to training, namely, competency-based, contextual, interdisciplinary, fundamental and subject-information approaches to training, among which the competency-based approach is leading. The basic organizational and pedagogical conditions promoting the formation of competence are defined in the form of the organization of polycontextual modules in training. Besides, the article outlines the ways to enhance the effectiveness of e-learning in the future. © 2016 by Academic Publishing House Researcher.","Computer animation; Contextual; Didactic basis; E-learning; Formation of competence; Fundamental; Interdisciplinary; Organizational and pedagogical conditions; Polycontextual educational module; Subject-information approaches",,2-s2.0-85014042173
"Pilz K.S., Thornton I.M.","Idiosyncratic body motion influences person recognition",2016,"Visual Cognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988329675&doi=10.1080%2f13506285.2016.1232327&partnerID=40&md5=ed895595bf0a28e6ed414014b84db2cb","Person recognition is an important human ability. The main source of information we use to recognize people is the face. However, there is a variety of other information that contributes to person recognition, and the face is almost exclusively perceived in the presence of a moving body. Here, we used recent motion capture and computer animation techniques to quantitatively explore the impact of body motion on person recognition. Participants were familiarized with two animated avatars each performing the same basic sequence of karate actions with slight idiosyncratic differences in the body movements. The body of both avatars was the same, but they differed in their facial identity and body movements. In a subsequent recognition task, participants saw avatars whose facial identity consisted of morphs between the learned individuals. Across trials, each avatar was seen animated with sequences taken from both of the learned movement patterns. Participants were asked to judge the identity of the avatars. The avatars that contained the two original heads were predominantly identified by their facial identity regardless of body motion. More importantly however, participants identified the ambiguous avatar primarily based on its body motion. This clearly shows that body motion can affect the perception of identity. Our results also highlight the importance of taking into account the face in the context of a body rather than solely concentrating on facial information for person recognition. © 2016 Informa UK Limited, trading as Taylor & Francis Group","animation technique; body motion; face recognition; Person recognition",,2-s2.0-84988329675
"Sperber M., Janin D.","FARM 2016 demo summary",2016,"FARM 2016 - Proceedings of the 4th International Workshop on Functional Art, Music, Modelling, and Design, co-located with ICFP 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017131844&doi=10.1145%2f2975980.2975988&partnerID=40&md5=6fd9a96cdfe84b46246a8970d7273174","This is a summary of the demos presented at the 4th ACM SIGPLAN International Workshop on Functional Art, Music, Modelling and Design, prepared prior to the event itself. The submitted abstracts of these demos are available on the FARM 2016 web site at http://functional-art.org/2016/. © 2016 ACM.","Animation; Art; Embedded devices; Functional programming; Livecoding; Music","Animation; Computer music; Embedded device; International workshops; Livecoding; Music; Functional programming",2-s2.0-85017131844
"Moussa W.E., Almalki R.M., Alamoudi M.A., Allinjawi A.","Proposing a 3d interactive visualization tool for learning oop concepts",2016,"2016 13th Learning and Technology Conference, L and T 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991234114&doi=10.1109%2fLT.2016.7562861&partnerID=40&md5=fa936df0cf5f2098aafa22c8974290ff","Object Oriented Programming (OOP) recently became the most influential programming paradigm. Several studies [2, 3, 4] indicated deficiencies in learning introductory OOP courses. In King Abdulaziz University-Saudi Arabia, based on a survey that had been designed and distributed to female students of introductory OOP course, results showed that students faced difficulties in understanding OOP, specifically 47% of students faced difficulties in Polymorphism. Visualization tools visualize the execution of programs, using visual hints, and interactivity to improve the students' understanding in programming concepts. This paper proposes the development of ""OOPVisual"", a 3D interactive visualization tool that will simulate OOP concepts to help students with their understanding. © 2016 IEEE.","3D Interactive Tool; Animation; Drag-and-Drop Technique; Object Oriented Programming; Polymorphism; Visualization","Animation; Education; Engineering education; Flow visualization; Polymorphism; Students; Three dimensional computer graphics; Visualization; Drag and drop; Female students; Interactive tool; Interactive visualization tool; Objectoriented programming (OOP); Programming concepts; Programming paradigms; Visualization tools; Object oriented programming",2-s2.0-84991234114
"Kaji S., Ochiai H.","A concise parametrization of affine transformation",2016,"SIAM Journal on Imaging Sciences",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989329005&doi=10.1137%2f16M1056936&partnerID=40&md5=48f2f720fbb481e358ebe87eeb564a02","Good parametrizations of affine transformations are essential to interpolation, deformation, and analysis of shape, motion, and animation. It has been one of the central research topics in computer graphics. However, there is no single perfect method and each one has both advantages and disadvantages. In this paper, we propose a novel parametrization of affine transformations, which is a generalization to or an improvement of existing methods. Our method adds yet another choice to the existing toolbox and shows better performance in some applications. A C++ implementation is available to make our framework ready to use in various applications. © 2016 Society for Industrial and Applied Mathematics.","Deformation; Interpolation; Matrix exponential and logarithm; Motion analysis; Parametrization of affine transformations; Shape blending","Blending; Computer graphics; Deformation; Interpolation; Motion analysis; Affine transformations; Matrix exponentials; Parametrizations; Ready to use; Research topics; Shape blending; Linear transformations",2-s2.0-84989329005
"Celledoni E., Eslitzbichler M., Schmeding A.","Shape analysis on lie groups with applications in computer animation",2016,"Journal of Geometric Mechanics",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988697021&doi=10.3934%2fjgm.2016008&partnerID=40&md5=3cbebe8598501805cee86aa63981b147","Shape analysis methods have in the past few years become very popular, both for theoretical exploration as well as from an application point of view. Originally developed for planar curves, these methods have been expanded to higher dimensional curves, surfaces, activities, character motions and many other objects. In this paper, we develop a framework for shape analysis of curves in Lie groups for problems of computer animations. In particular, we will use these methods to find cyclic approximations of non-cyclic character animations and interpolate between existing animations to generate new ones. © American Institute of Mathematical Sciences.","Computer animation; Curve matching; Infinite dimensional manifold; Lie groups; Shape analysis",,2-s2.0-84988697021
"Fang N., Guo Y.","Interactive computer simulation and animation for improving student learning of particle kinetics",2016,"Journal of Computer Assisted Learning",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963864098&doi=10.1111%2fjcal.12145&partnerID=40&md5=2eee200774d159d4c29edbdf0bfd95e2","Computer simulation and animation (CSA) has been receiving growing attention and wide application in engineering education in recent years. A new interactive CSA module was developed in the present study to improve student learning of particle kinetics in an undergraduate engineering dynamics course. The unique feature of this CSA module is that it integrates computer visualization with mathematical modeling, so students can directly connect engineering dynamics phenomena to underlying mathematics. A quasi-experimental pretest–post-test research design including a comparison group (n = 65) and an intervention group (n = 77) was implemented to assess to what extent the developed CSA module improved student learning. The results show that this new CSA module increased students' class-average conceptual and procedural learning gains by 29% and 37% respectively. The difference in learning gains between the two groups is statistically significant (Z = −4.526, p = 0.000) based on a nonparametric statistical Mann–Whitney U test. It is found that the improvement of students' conceptual understanding and the improvement of their procedural skills are asymmetrical in this CSA learning environment. The CSA module can serve as an excellent tool to supplement traditional lectures, but cannot fully replace human teachers or tutors in teaching. © 2016 John Wiley & Sons Ltd","computer simulation and animation (CSA); conceptual understanding; engineering dynamics; learning gain; procedural skills",,2-s2.0-84963864098
"Szczuko P.","Simple gait parameterization and 3D animation for anonymous visual monitoring based on augmented reality",2016,"Multimedia Tools and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940056129&doi=10.1007%2fs11042-015-2874-0&partnerID=40&md5=3532e4360fb690e5ae860d84ec041f95","The article presents a method for video anonymization and replacing real human silhouettes with virtual 3D figures rendered on a screen. Video stream is processed to detect and to track objects, whereas anonymization stage employs animating avatars accordingly to behavior of detected persons. Location, movement speed, direction, and person height are taken into account during animation and rendering phases. This approach requires a calibrated camera, and utilizes results of visual object tracking. A procedure for transforming objects visual features and bounding boxes into gait parameters for animated figures is presented. Conclusions and future work perspectives are provided. © 2015, Springer Science+Business Media New York.","Augmented reality; Computer animation; Gait; Privacy; Visual monitoring","Augmented reality; Computer privacy; Data privacy; Image recognition; Object recognition; Rendering (computer graphics); Video streaming; Virtual reality; Calibrated cameras; Computer animation; Gait; Gait parameters; Human silhouette; Visual feature; Visual monitoring; Visual object tracking; Animation",2-s2.0-84940056129
"Barnett A., Shum H.P.H., Komura T.","Coordinated Crowd Simulation With Topological Scene Analysis",2016,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949674448&doi=10.1111%2fcgf.12735&partnerID=40&md5=85c41e1ca8795ae065fcd68cddd8c610","This paper proposes a new algorithm to produce globally coordinated crowds in an environment with multiple paths and obstacles. Simple greedy crowd control methods easily lead to congestion at bottlenecks within scenes, as the characters do not cooperate with one another. In computer animation, this problem degrades crowd quality especially when ordered behaviour is needed, such as soldiers marching towards a castle. Similarly, in applications such as real-time strategy games, this often causes player frustration, as the crowd will not move as efficiently as it should. Also, planning of building would usually require visualization of ordered evacuation to maximize the flow. Planning such globally coordinated crowd movement is usually labour intensive. Here, we propose a simple solution that is easy to use and efficient in computation. First, we compute the harmonic field of the environment, taking into account the starting points, goals and obstacles. Based on the field, we represent the topology of the environment using a Reeb Graph, and calculate the maximum capacity for each path in the graph. With the harmonic field and the Reeb Graph, path planning of crowd can be performed using a lightweight algorithm, such that any blocking of one another's paths is minimized. Comparing to previous methods, our system can synthesize globally coordinated crowd with smooth and efficient movement. It also enables control of the crowd with high-level parameters such as the degree of cooperation and congestion. Finally, the method is scalable to thousands of characters with minimal impact to computation time. It is best applied in interactive crowd synthesis systems such as animation designs and real-time strategy games. © 2015 The Authors Computer Graphics Forum published by John Wiley & Sons Ltd.","I.3.7[Computer Graphics]: Three-Dimensional Graphics and Realism–Animation; motion planning","Algorithms; Animation; Computer graphics; Computer software; Graph theory; Harmonic analysis; Motion planning; Real time systems; Three dimensional computer graphics; Animation designs; Computation time; Computer animation; Crowd movements; Crowd Simulation; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Labour-intensive; Real-time strategy games; Topology",2-s2.0-84949674448
"Kikuchi A., Kawano T.","Discrete biochemistry of DNA: Arithmetic DNA molecules for binary additions, naturally found genetic logic circuits for plant sensing, and DNA-based animation",2016,"Journal of Advanced Computational Intelligence and Intelligent Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990841517&doi=10.20965%2fjaciii.2016.p0671&partnerID=40&md5=0cfd6751c10e4935fc552ac64a6028ac","To date, a number of researchers are seeking for and/or designing novel molecules which function as arithmetic molecular engines. Biomoleculcs such as deoxyribonucleic acid (DNA) and proteins are examples of promising candidate molecules. In the present article, we showed our view that DNA-based molecules could be used as a novel class of platforms for discrete mathematical operations or tools for natural computation. Here, we report on a novel molecular logic circuit combining exclusive disjunction (XOR) gate and conjunction (AND) gate implemented on a single DNA molecule performing arithmetic operations with simple binary numbers through polymerase chain reactions (PCR); which was inspired by previously developed protein-based computing model allowing simple polynomial algebra over fields through algebraic representation of cyclic inter-conversions in the cataly tic modes of a plant enzyme as a cyclic additive group. In addition, we showed that DNA can be used as the platform for image coding and processing leading to DNA-coded animation by using novel PCR-based protocols. Lastly, we discussed the significance of recent attempts in the stream of natural computing and synthetic biological research, by handling DNA and related biomolecules as the media for discrete mathematical operations.","Biocomputing; DNA; Polymerase-chain reaction","Algebra; Animation; Bins; Biomolecules; Chains; Computation theory; Computer circuits; DNA; Enzymes; Gene encoding; Image coding; Logic circuits; Molecular biology; Molecules; Nucleic acids; Proteins; Reconfigurable hardware; Algebraic representations; Arithmetic operations; Bio-computing; Biological research; Mathematical operations; Natural computation; Polynomial algebra; Single DNA molecules; Polymerase chain reaction",2-s2.0-84990841517
"Wei Q., Shan J., Cheng H., Yu Z., Bai L., Zhao H.","A method of 3D human-motion capture and reconstruction based on depth information",2016,"2016 IEEE International Conference on Mechatronics and Automation, IEEE ICMA 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991282102&doi=10.1109%2fICMA.2016.7558558&partnerID=40&md5=76b9bc0c8ecd43f329e741da47b8d20b","During the past decades, motion capture has become a very important role in computer animation. However, real-time, anti-interference and robust motion tracking of video sequences is still very challenging. Kinect is a popular motion sensor which can obtain human motion data. But when taking into practice, there are no adequate implementations on how to extract skeleton data from the depth image, bind skeleton model with motion data. In this paper, we propose a method for human motion capture based on the characteristic of Kinect2, made an improvement based on the traditional method. Finally, we develop a 3D human-motion capture and reconstruction system. A detailed procedure of implementation is demonstrated. Experiments have shown that motions of virtual character are controlled by the real person completely and accurately, and the system has advantages of real-time, low-cost and high accuracy. © 2016 IEEE.","human motion capture; human-computer interaction; Kinect; real time; skeleton data","Animation; Motion analysis; Musculoskeletal system; 3d human motion captures; Computer animation; Human motion capture; Kinect; Real time; Reconstruction systems; skeleton data; Virtual character; Human computer interaction",2-s2.0-84991282102
"Wu X.-J., Ju G.-L.","A markerless facial expression capture and reproduce algorithm",2016,"Tien Tzu Hsueh Pao/Acta Electronica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991250316&doi=10.3969%2fj.issn.0372-2112.2016.09.018&partnerID=40&md5=72e2fa372155b3d3653c6070fdb3d680","This paper presents a markerless facial expression capture and reproduce algorithm. Firstly, an uniform mesh model is built based on the feature points from ASM (Active Shape Model). It can cover 85 percent of the face. Then, a method to capture facial expression based on the face model is proposed. The optical flow tracking is used to track the feature points with particle filter for stablizing the result. The feature points'displacement can drive the overall mesh to deform as the initial value of the mesh tracking. Finally, the captured expression data is used to drive face models with different methods for the models of different dimensions, and then the facial animation can be reconstructed. Experimental results show that the proposed algorithm can capture facial expressions well, and the animation effect is good when mapping the captured expression to 2D cartoon or 3D virtual face models. © 2016, Chinese Institute of Electronics. All right reserved.","Facial animation reconstruction; Facial expression capture; Marker-less tracking","Animation; Digital storage; Mesh generation; Three dimensional computer graphics; Active Shape Models; Animation effects; Expression data; Face modeling; Facial animation; Facial Expressions; Particle filter; Virtual faces; Face recognition",2-s2.0-84991250316
"Avila L., Bailey M.","A Computer Graphics Back-to-School Special",2016,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992160847&doi=10.1109%2fMCG.2016.104&partnerID=40&md5=47dfa0a0a33609c2111926b7987b5837","This article features some of the latest advances and applications in computer graphics technology. © 2016 IEEE.","3D animation; 3D design; Blender; computer graphics; geometric modeling; Scratch; SketchUp; TinkerCAD","Blending; Three dimensional computer graphics; 3-d designs; 3D animation; Blender; Geometric modeling; Scratch; SketchUp; TinkerCAD; Computer graphics",2-s2.0-84992160847
"Aljudaibi N., Bennis Y., Duquennoy-Martinot V., Labbé D., Guerreschi P.","Lengthening Temporalis Myoplasty: Virtual Animation-Assisted Technical Video",2016,"Plastic and Reconstructive Surgery",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983671891&doi=10.1097%2fPRS.0000000000002512&partnerID=40&md5=cff5261e01cbd57a6d842b8ce0f1b805","Lengthening temporalis myoplasty is a well-established procedure for dynamic palliative reanimation of the lip in facial palsy sequelae. The particularity of this technique is that the entire temporal muscle is transferred from the coronoid process to the upper half of the lip without interposition of aponeurotic tissue. To date, no video describing the technique was available. This is the first video describing the entire procedure, from preoperative markings through postoperative rehabilitation. In the video presented herein, the authors craft virtual three-dimensional animations in addition to a live operation on a patient performed by Daniel Labbé, who first described this technique 20 years ago. Copyright © 2016 by the American Society of Plastic Surgeons.",,"child; computer graphics; computer interface; Facial Paralysis; human; innervation; lip; palliative therapy; temporalis muscle; Child; Computer Graphics; Facial Paralysis; Humans; Lip; Palliative Care; Temporal Muscle; User-Computer Interface",2-s2.0-84983671891
"Ben-Zvi N., Bento J., Mahler M., Hodgins J., Shamir A.","Line-Drawing Video Stylization",2016,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947983414&doi=10.1111%2fcgf.12729&partnerID=40&md5=f55b3877531a629ecf5743df7552a75f","We present a method to automatically convert videos and CG animations to stylized animated line drawings. Using a data-driven approach, the animated drawings can follow the sketching style of a specific artist. Given an input video, we first extract edges from the video frames and vectorize them to curves. The curves are matched to strokes from an artist's library, while following the artist's stroke distribution and characteristics. The key challenge in this process is to match the large number of curves in the frames over time, despite topological and geometric changes, allowing to maintain temporal coherence in the output animation. We solve this problem using constrained optimization to build correspondences between tracked points and create smooth sheets over time. These sheets are then replaced with strokes from the artist's database to render the final animation. We evaluate our tracking algorithm on various examples and show stylized animation results based on various artists. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","2D techniques; animation; I.3.3 [Computer Graphics]: Picture/Image Generation—Line and curve generation; image and video processing; image processing; non-photorealistic rendering; rendering","Animation; Computer graphics; Constrained optimization; Image matching; Image processing; 2D techniques; Data-driven approach; Geometric changes; Non-Photorealistic Rendering; Rendering; Temporal coherence; Tracking algorithm; Video stylization; Rendering (computer graphics)",2-s2.0-84947983414
"Lai P., Samson C.","Applications of mesh parameterization and deformation for unwrapping 3D images of rock tunnels",2016,"Tunnelling and Underground Space Technology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965173181&doi=10.1016%2fj.tust.2016.04.009&partnerID=40&md5=8c76319e212c2cb8b947e8c06e1d4ba3","This paper presents analysis on two 3D mesh to 2D map strategies applied to unwrap images of rock tunnels and facilitate visualization of large datasets. First, we examined mesh parameterization algorithms which are used in computer graphics to convert a 3D mesh model to a 2D representation.We found that while these methods were automatic and could provide 2D maps with minimal metric distortion (ie: conservation of lengths in 3D when mapped to 2D), they exhibited twisted shapes and were not intuitive to interpret. Second, we proposed two novel approaches, combining mesh deformation algorithms, which are used in computer animation to reshape a 3D mesh to resemble a 3D plane, and projection onto a 2D plane. We found that while these methods required user interaction and introduced a greater amount of metric distortion, their outputs were fairly intuitive to interpret. To compare the relative merits of mesh parameterization and mesh deformation and projection, the different strategies are applied to a 8.2 m wide by 41 m long by 6.7 m high subsection of a mining tunnel. The metric distortion produced was calculated and their respective output 2D maps are presented and discussed. © 2016 Elsevier Ltd.","3D images; Mesh deformation; Metric distortion; Surface parameterization; Terrestrial laser scanning; Tunnel mapping; Visualization","Animation; Computer graphics; Deformation; Flow visualization; Mesh generation; Parameterization; Visualization; 3-D image; Mesh deformation; Metric distortions; Surface parameterization; Terrestrial laser scanning; Three dimensional computer graphics; deformation; laser method; mapping; parameterization; three-dimensional modeling; tunnel; visualization",2-s2.0-84965173181
"Wawrzinek A., Polthier K.","Integration of generalized B-spline functions on Catmull–Clark surfaces at singularities",2016,"CAD Computer Aided Design",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973138755&doi=10.1016%2fj.cad.2016.05.008&partnerID=40&md5=f86da32f4f729d8be6c934e5854b5088","Subdivision surfaces are a common tool in geometric modelling, especially in computer graphics and computer animation. Nowadays, this concept has become established in engineering too. The focus here is on quadrilateral control grids and generalized B-spline surfaces of Catmull–Clark subdivision type. In the classical theory, a subdivision surface is defined as the limit of the repetitive application of subdivision rules to the control grid. Based on Stam's idea, the labour-intensive process can be avoided by using a natural parameterization of the limit surface. However, the simplification is not free of defects. At singularities, the smoothness of the classically defined limit surface has been lost. This paper describes how to rescue the parameterization by using a subdivision basis function that is consistent with the classical definition, but is expensive to compute. Based on this, we introduce a characteristic subdivision finite element and use it to discretize integrals on subdivision surfaces. We show that in the integral representation the complicated parameterization reduces to a decisive factor. We compare the natural and the characteristic subdivision finite element approach solving PDEs on surfaces. As model problem we consider the mean curvature flow, whereby the computation is done on the step-by-step changing geometry. Â© 2016 Elsevier Ltd","Catmull–Clark subdivision; Isogeometric analysis; PDEs on surfaces; Subdivision finite element; Subdivision surfaces","Animation; Computation theory; Computer graphics; Interpolation; Parameterization; Splines; Catmull-Clark subdivision; Finite-element approach; Generalized B spline function; Integral representation; Isogeometric analysis; Mean curvature flow; PDEs on surfaces; Subdivision surfaces; Finite element method",2-s2.0-84973138755
"Nemanic S., Mills S., Viehdorfer M., Clark T., Bailey M.","The effectiveness of a 3D computerized tutorial to enhance learning of the canine larynx and hyoid apparatus",2016,"Journal of Veterinary Medical Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021849138&doi=10.3138%2fjvme.0815-139R&partnerID=40&md5=37c3e8fe28dd4a8a12f4900818750122","Teaching the anatomy of the canine larynx and hyoid apparatus is challenging because dissection disassembles and/ or damages these structures, making it difficult to understand their three-dimensional (3D) anatomy and spatial interrelationships. This study assessed the effectiveness of an interactive, computerized 3D tutorial for teaching the anatomy of the canine larynx and hyoid apparatus using a randomized control design with students enrolled in the first-year professional program at Oregon State University College of Veterinary Medicine. All first-year students from 2 consecutive years were eligible. All students received the traditional methods of didactic teaching and dissection to learn the anatomy of the canine larynx and hyoid apparatus, after which they were divided into two statistically equal groups based on their cumulative anatomy test scores from the prior term. The tutorial group received an interactive, computerized tutorial developed by the investigators containing 3D images of the canine larynx and hyoid apparatus, while the control group received the same 3D images without the computerized tutorial. Both groups received the same post-learning assessment and survey. Sixty-three first-year students participated in the study, 28 in the tutorial group, and 35 in the control group. Post-learning assessment and survey scores were both significantly higher among students in the computerized tutorial group than those in the control group. This study demonstrates that a 3D computerized tutorial is more effective in teaching the anatomy of the canine hyoid apparatus and larynx than 3D images without a tutorial. Students likewise rated their learning experience higher when using the 3D computerized tutorial. © 2016 AAVMC.","3D animation; Computer-assisted learning; Hyoid apparatus; Larynx","anatomic model; anatomy and histology; animal; computer simulation; controlled study; dog; education; human; hyoid bone; larynx; questionnaire; randomized controlled trial; teaching; three dimensional imaging; veterinary anatomy; Anatomy, Veterinary; Animals; Computer Simulation; Computer-Assisted Instruction; Dogs; Education, Veterinary; Educational Measurement; Humans; Hyoid Bone; Imaging, Three-Dimensional; Larynx; Models, Anatomic; Surveys and Questionnaires",2-s2.0-85021849138
"Valcik J., Sedmidubsky J., Zezula P.","Assessing similarity models for human-motion retrieval applications",2016,"Computer Animation and Virtual Worlds",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940093987&doi=10.1002%2fcav.1674&partnerID=40&md5=3829749d549d28b9710c9e729520197c","The development of motion capturing devices poses new challenges in the exploitation of human-motion data for various application fields, such as computer animation, visual surveillance, sports, or physical medicine. Recently, a number of approaches dealing with motion data have been proposed, suggesting characteristic motion features to be extracted and compared on the basis of similarity. Unfortunately, almost each approach defines its own set of motion features and comparison methods; thus, it is hard to fairly decide which similarity model is the most suitable for a given kind of human-motion retrieval application. To cope with this problem, we propose the human motion model evaluator, which is a generic framework for assessing candidate similarity models with respect to the purpose of the target application. The application purpose is specified by a user in form of a representative sample of categorized motion data. Respecting such categorization, the similarity models are assessed from the effectiveness and efficiency points of view using a set of space-complexity, information-retrieval, and performance measures. The usability of the framework is demonstrated by case studies of three practical examples of retrieval applications focusing on recognition of actions, detection of similar events, and identification of subjects. Copyright © 2015 John Wiley & Sons, Ltd. Copyright © 2015 John Wiley & Sons, Ltd.","action recognition; effectiveness evaluation; human-motion retrieval; motion capture data; similarity model","Animation; Medicine; Sports medicine; Action recognition; Effectiveness evaluation; Human motion retrieval; Motion capture data; Similarity models; Motion estimation",2-s2.0-84940093987
"Destarac M.A., García Cena C.E., Saltarén Pazmiño R.J., Reyes Urbina M.J., López López J., Gómez R.E.","Modeling and Simulation of Upper Brachial Plexus Injury",2016,"IEEE Systems Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922736512&doi=10.1109%2fJSYST.2014.2387426&partnerID=40&md5=282b7f414e5b6ef151d548905743850d","This paper presents the first musculoskeletal model and simulation of an upper plexus brachial injury. From this model, it is possible to analyze forces and movement ranges in order to develop a robotic exoskeleton to improve rehabilitation. The software that currently exists for musculoskeletal modeling is varied and most have advanced features for proper analysis and study of motion simulations. While more powerful computer packages are usually expensive, there are other free and open source packages available that offer different tools to perform animations and simulations and obtain forces and moments of inertia. Among them, Musculoskeletal Modeling Software was selected to construct a model of the upper limb, which has 7° of freedom and 10 muscles. These muscles are important for two of the movements simulated in this paper that are part of the postsurgery rehabilitation protocol. We performed different movement animations that are made using the inertial measurement unit to capture real data from movements made by a human being. We also performed the simulation of forces produced in elbow flexion-extension and arm abduction-adduction of a healthy subject and one with an upper brachial plexus injury in a postoperative state to compare the force that is capable of being produced in both cases. © 2007-2012 IEEE.","Animation; force; modeling; rehabilitation robotics; simulation","Motion analysis; Muscle; Musculoskeletal system; Units of measurement; Inertial measurement unit; Model and simulation; Moments of inertia; Motion simulations; Musculoskeletal model; Open source package; Rehabilitation protocols; Robotic exoskeletons; Open source software",2-s2.0-84922736512
"Nishida G., Garcia-Dorado I., Aliaga D.G.","Example-Driven Procedural Urban Roads",2016,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942279571&doi=10.1111%2fcgf.12728&partnerID=40&md5=01ccc0a988d0dbb30ee51a2d5e25366d","Synthesizing and exploring large-scale realistic urban road networks is beneficial to 3D content creation, traffic animation and urban planning. In this paper, we present an interactive tool that allows untrained users to design roads with complex realistic details and styles. Roads are generated by growing a geometric graph. During a sketching phase, the user specifies the target area and the examples. During a growing phase, two types of growth are effectively applied to generate roads in the target area; example-based growth uses patches extracted from the source example to generate roads that preserve some interesting structures in the example road networks; procedural-based growth uses the statistical information of the source example while effectively adapting the roads to the underlying terrain and the already generated roads. User-specified warping, blending and interpolation operations are used at will to produce new road network designs that are inspired by the examples. Finally, our method computes city blocks, individual parcels and plausible building and tree geometries. We have used our approach to create road networks covering up to 200 km2 and containing over 3500 km of roads. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","example-based modeling; I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling—I.3.6 [Computer Graphics]: Methodology and Techniques; procedural modeling; street modeling","Blending; Complex networks; Motor transportation; Roads and streets; Transportation; Example based; Geometric graphs; Growing phase; Interactive tool; Procedural modeling; Statistical information; Street modeling; Urban road networks; Highway planning",2-s2.0-84942279571
"Sanchez S., De Boissieu P., Gueyraud C., Armingaud D., Guerrier M., Denormandie P.","Information and communication technology and health of the elderly [Technologies de l'information et de la communication et santé des seniors]",2016,"Soins Gerontologie",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019910282&doi=10.1016%2fj.sger.2016.07.003&partnerID=40&md5=220e8f594a87fbfd46aab4b20760e1f9","New technologies offer many advantages, especially in terms of animation in elderly care homes. Consoles and digital tablets used without any medical implication were the subject of a literature review on their impact on the health of the elderly.. © 2016 Elsevier Masson SAS. All rights reserved.","Elderly person; Health; Information and communication technology; Literature review; Physical activity","aged; elderly care; female; human; human experiment; male; physical activity; tablet; biomedical enhancement; exercise; France; geriatric nursing; home for the aged; interpersonal communication; medical informatics; nursing home; patient education; personal digital assistant; quality of life; recreation; self help device; trends; very elderly; video game; Aged; Aged, 80 and over; Biomedical Enhancement; Communication; Computers, Handheld; Exercise; France; Geriatric Nursing; Homes for the Aged; Humans; Medical Informatics; Nursing Homes; Patient Education as Topic; Quality of Life; Recreation; Self-Help Devices; Video Games",2-s2.0-85019910282
"Ning Z., Lei L., Saipeng Z., Lodewijks G.","An efficient simulation model for rack design in multi-elevator shuttle-based storage and retrieval system",2016,"Simulation Modelling Practice and Theory",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979711014&doi=10.1016%2fj.simpat.2016.03.007&partnerID=40&md5=a0720a78869aceb7b523edcc83829e24","A shuttle-based storage and retrieval system (SBS/RS) is a relatively new material-handling facility. A multi-elevator tier-captive SBS/RS is a newly designed subset of such a facility. This new system consists of tier-captive shuttle carriers, multiple elevators with a lifting table, and racks. The storage rack of the system is defined in terms of tiers, columns, and the number and position of the elevators. The aim of this study is to develop an efficient simulation model that can be auto-remodeled for different rack configurations. With this model, it will be easy for warehouse designers to test a large number of rack alternatives and to determine the optimal solution efficiently. Furthermore, the designers can illustrate the solution to shareholders through animation identical to the real system. A simulation case study is presented for a multi- elevator tier-captive SBS/RS containing 81 different rack alternatives. These alternatives are simulated under 15 different retrieval rates within 48 h, and finally, the optimal rack design is found out. We believe that our work will assist warehouse designers in efficiently designing racks of multi- elevator tier-captive SBS/RSs during early technology selection. © 2016 Elsevier B.V.","Efficiency analysis; Multi- elevator tier captive systems; Shuttle based storage and retrieval system; Simulation modeling; Warehousing","Computer simulation; Design; Information retrieval; Materials handling; Storage (materials); Warehouses; Efficiency analysis; Efficient simulation; Material handling; Optimal solutions; Retrieval rate; Storage and retrievals; Technology selection; Warehousing; Elevators",2-s2.0-84979711014
"Manyoky M., Wissen Hayek U., Pieren R., Heutschi K., Grêt-Regamey A.","Evaluating a visual-acoustic simulation for wind park assessment",2016,"Landscape and Urban Planning",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971574802&doi=10.1016%2fj.landurbplan.2016.03.013&partnerID=40&md5=1f4259c2a3afa92449ad56bc716ad5ba","The implementation of wind parks often fails due to lack of public acceptance. Visual-acoustic landscape simulations of wind parks offer a potential instrument for public participation, allowing experiencing the visual and the acoustic landscape impact. However, before such simulations can be implemented in practice, they need to be validated. In this article, we develop and apply an approach to evaluate visual-acoustic simulations for assessing wind park perceptions. The approach compares whether simulations generate similar reactions of respondents as recordings of the same environments. The survey participants made a visual and an acoustic assessment of the landscape represented by recordings and by simulations. The results show that there was nearly no difference in the rating of the annoyance of wind turbine noise between the recordings and the simulation. With regard to the visual landscape assessment the ratings based on the simulations were lower than the ones based on the recordings. The approach indicates aspects of the simulation that differ compared to the recording, such as coherent coloring and animation of landscape elements. The rating differences between the recordings and the simulations of both, the visual and the acoustic perception have to be considered when using the simulations for further studies.Overall, the described approach was successfully applied and contributes to validity testing methods. However, this is a preliminary and exploratory study. A complete test of validity should compare the simulations to the actual environment, which should be further studied. © 2016 Elsevier B.V.","GIS-based 3D visualization; Validation; Visual-acoustic simulation; Wind park perceptions; Wind turbine noise","Geographic information systems; Surveys; Testing; Three dimensional computer graphics; Wind power; Wind turbines; 3D Visualization; Acoustic simulations; Validation; Wind park; Wind turbine noise; Acoustic noise; acoustic method; assessment method; attitudinal survey; GIS; local participation; model validation; noise; park management; perception; public attitude; simulation; visualization; wind turbine",2-s2.0-84971574802
"Sharaf N., Abdennadher S., Frühwirth T.","A rule-based approach for animating Java algorithms",2016,"Proceedings of the International Conference on Information Visualisation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989934231&doi=10.1109%2fIV.2016.55&partnerID=40&md5=77ef4d9f1dc33fd1672a25b9ae339647","Over the past years, visualization of programs has been widely applied. Algorithm animation was proven to aid in teaching and learning. It provides a convenient medium for beginners to a programming language by giving them the ability to visually discover how their programs are running. It also provides experts of a language with a means to have a visual trace utility. Lately, a new approach for adding visualization features into Constraint Handling Rules (CHR) programs was proposed. The new methodology was a dynamic one able to animate different types of algorithms. The work in this paper aims at introducing a revised extension that is able to embed visualization features into Java programs. With the new extension, Java algorithms could be animated without the need of doing any modifications to the code. In addition, the provided technique is still a general one able to animate different kinds of algorithms. © 2016 IEEE.","Algorithm Animation; Constraint Handling Rules; Java Programs; Visual Language","Animation; Computer software; Visual languages; Visualization; Algorithm animation; Constraint Handling Rules; Java program; New approaches; Rule-based approach; Teaching and learning; Java programming language",2-s2.0-84989934231
"Headleand C.J., Teahan W., Cenydd L.A.","Action selection through affective states modelling",2016,"Proceedings of 2016 SAI Computing Conference, SAI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988849723&doi=10.1109%2fSAI.2016.7556024&partnerID=40&md5=cff64635ad3418a7d44c5ef70910f46b","We introduce an action selection framework for the advanced behavioural animation of virtual creatures. In modern creative media, the behavioural animation of characters which act in a believable fashion is an ongoing challenge. Traditional action selection approaches which attempt to make an agent act rationally often fall short of the believability required for the modern consumer. Often the most believable action is not the most rational one, and our judgement of an agent's behaviour may also be based on the perception of its personality. Our approach, Affective Spaces Modelling, addresses these issues by creating a multi-dimensional environment constructed of aspect dimensions, with each aspect dimension representing a linear scale of a single component of the agent's internal state. Affective states can then be modelled by placing them in a single point in this environment. As the agent's state changes within the affective state space, different affects trigger appropriate actions. We demonstrate through a case study how the technique can be used to simulate different types of agent behaviour, operating both individually and as part of a group. Our case studies focus on groups of agents, allowing for the direct comparison of different personalities and examples of behavioural phenomena. © 2016 IEEE.","Action Selection; Affection; Computer Animation; Virtual Creatures","Computer programming; Computer science; Action selection; Affection; Affective state; Computer animation; Internal state; Multi dimensional; Single components; Virtual Creatures; Animation",2-s2.0-84988849723
"Francis L.M., Visalatchi K.C., Sreenath N.","End to end text recognition from natural scene",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997218110&doi=10.1145%2f2980258.2980356&partnerID=40&md5=6863e76f01e5d87e9943b2774efd1f55","The web world is been flooded with multi-media sources such as images, videos, animations and audios, which has in turn made the computer vision researchers to focus over extracting the content from the sources. Scene text recognition basically involves two major steps namely Text Localization and Text Recognition. This paper provides end-To-end text recognition approach to extract the characters alone from the complex natural scene. Using Maximal Stable Extremal Region (MSER) the various objects are localized, using Canny Edge detection method edges are identified, further binary classification is done using Connected-Component method which segregates the text and non-Text objects and finally the stroke analysis method is applied to analyse the style of the character, leading to the character recognization. The Experimental results were obtained by testing the approach over ICDAR2015 dataset, wherein text was able to be recognized from most of the scene images with good precision value. © 2016 ACM.","Connected-component based method; Edge-based method; Scene text localization; Scene text recognition; Stroke-based method","Computer vision; Edge detection; Information science; Statistical tests; Text processing; Binary classification; Canny edge detection; Connected component; Edge-based methods; Multi-media sources; Scene Text; Stroke-based method; Text localization; Character recognition",2-s2.0-84997218110
"Wilson B., Bounds M., Tavakkoli A.","A full-body motion calibration and retargeting for intuitive object manipulation in immersive virtual environments",2016,"2016 IEEE 9th Workshop on Software Engineering and Architectures for Realtime Interactive Systems, SEARIS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987974386&doi=10.1109%2fSEARIS.2016.7551585&partnerID=40&md5=b8422d6eafcc0873aea5cc7df0110e2a","In this paper a system is proposed to combine small finger movements with the large-scale body movements captured from a motion capture system. The strength of the proposed work over previous research is in the real-Time performance of integrating small-scale finger and hand animation with the full-body skeletal animation. This provides a higher degree of immersion and interactivity when compared to more traditional virtual reality systems which use traditional user interfaces. A number of experiments are conducted with humanoid skeletons that are both similar to an actual humane. g. a SWAT officer, and those that are dissimilar-e.g. a Gremlin, to showcase the performance of the proposed approach. © 2016 IEEE.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation; I.3.8[Computer Graphics]: Applications; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual Reality","Animation; Computer graphics; Engineering research; Software engineering; User interfaces; Virtual reality; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; I.3.8 [computer graphics]: Applications; Immersive virtual environments; Motion capture system; Object manipulation; Real time performance; Skeletal animation; Virtual reality system; Three dimensional computer graphics",2-s2.0-84987974386
"Bao S., Porter J., Gokhale A.","Reasoning for CPS Education Using Surrogate Simulation Models",2016,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987956454&doi=10.1109%2fCOMPSAC.2016.175&partnerID=40&md5=26800f94039fa4c993e03b273af1bad6","With developing an affordable, easily accessible and scalable online CPS laboratory to promote CPS education system, we are faced with and focused on a number of cyber-physical challenges including the model design and simulation strategies. The authors provide a complete process to simulate a behavior of a user-design CPS conveyor system. The user-design model is sent to the background, treated offline, and extracted the simulation result and finally feedback to user as an animation. The solution approach has two main parts, as the aspect of the modeling work, complex domain-specific conveyor design are defined in the Generic Modeling Environment (GME), it can be mapped and transformed to the global grid, another domain-specific model, which contains only one kind of node with huge dimension so that all different species of components in complex model are mapped to the typical nodes in grid, and it is easy to operate and simulate the nodes in global grid to fit for the need when multiple experiments being mapped to the grid. In this work, we only concerned the scenario of one experiment. The transformation and mapping process is implemented through Graph Rewriting and Transformation. As a background simulation, the Robocodes code is automatically generated by GME interpreter from global grid and is applied to generate the path logic to transmit the package, according to the package type in each input ports. After acquiring the transmit speed and path, Robocode simulation outputs the coordinate and time information to generate the Java animation. The final Java animation will be feedback to the user side to see the result of package transmission flow. © 2016 IEEE.","Cyber physical system; Domain-specific modeling; Graph Rewriting and Transformation; Robocode; The Generic Modeling Environment","Animation; Application programs; Behavioral research; Conveyors; Embedded systems; Cyber physical systems (CPSs); Domain specific modeling; Generic modeling; Graph rewriting; Robocode; Computer software",2-s2.0-84987956454
"Bloch N., Harel D.","The tumor as an organ: Comprehensive spatial and temporal modeling of the tumor and its microenvironment",2016,"BMC Bioinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983254900&doi=10.1186%2fs12859-016-1168-5&partnerID=40&md5=351695bea36e13cd0dbe443be8b5b78a","Background: Research related to cancer is vast, and continues in earnest in many directions. Due to the complexity of cancer, a better understanding of tumor growth dynamics can be gleaned from a dynamic computational model. We present a comprehensive, fully executable, spatial and temporal 3D computational model of the development of a cancerous tumor together with its environment. Results: The model was created using Statecharts, which were then connected to an interactive animation front-end that we developed especially for this work, making it possible to visualize on the fly the on-going events of the system's execution, as well as the effect of various input parameters. We were thus able to gain a better understanding of, e.g., how different amounts or thresholds of oxygen and VEGF (vascular endothelial growth factor) affect the progression of the tumor. We found that the tumor has a critical turning point, where it either dies or recovers. If minimum conditions are met at that time, it eventually develops into a full, active, growing tumor, regardless of the actual amount; otherwise it dies. Conclusions: This brings us to the conclusion that the tumor is in fact a very robust system: changing initial values of VEGF and oxygen can increase the time it takes to become fully developed, but will not necessarily completely eliminate it. © 2016 The Author(s).","Biological systems; Computational models; Statecharts; Tumor and its microenvironment; Visualization","Biological systems; Computation theory; Computational methods; Diseases; Endothelial cells; Flow visualization; Cancerous tumors; Computational model; Interactive animations; Microenvironments; Spatial and temporal modeling; Statecharts; Tumor growth dynamics; Vascular endothelial growth factor; Tumors; oxygen; vasculotropin A; biological model; computer simulation; disease course; human; metabolism; neoplasm; neovascularization (pathology); pathology; tumor microenvironment; vascularization; Computer Simulation; Disease Progression; Humans; Models, Biological; Neoplasms; Neovascularization, Pathologic; Oxygen; Tumor Microenvironment; Vascular Endothelial Growth Factor A",2-s2.0-84983254900
"Dempsey J.","Enterprising nature: Economics, markets and finance in global biodiversity politics",2016,"Enterprising Nature: Economics, Markets and Finance in Global Biodiversity Politics",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024136408&doi=10.1002%2f9781118640517&partnerID=40&md5=9d4e8fbe7c922dd5cef86d66e96ec0cb","Enterprising Nature explores the rise of economic rationality in global biodiversity law, policy and science. To view Jessica's animation based on the book's themes please visit http://www.bioeconomies.org/enterprising-nature/. Examines disciplinary apparatuses, ecological-economic methodologies, computer models, business alliances, and regulatory conditions creating the conditions in which nature can be produced as enterprising. Relates lively, firsthand accounts of global processes at work drawn from multi-site research in Nairobi, Kenya; London, England; and Nagoya, Japan. Assesses the scientific, technical, geopolitical, economic, and ethical challenges found in attempts to 'enterprise nature'. Investigates the implications of this 'will to enterprise' for environmental politics and policy. © 2016 John Wiley & Sons, Ltd. All rights reserved.",,,2-s2.0-85024136408
"Oda T., Araki K., Larsen P.G.","ViennaTalk and assertch: Building lightweight formal methods environments on pharo 4",2016,"IWST 2016 - Proceedings of the 11th International Workshop on Smalltalk Technologies, in conjunction with the 24th International Smalltalk Joint Conference",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006760116&doi=10.1145%2f2991041.2991045&partnerID=40&md5=51ba5008a8d8ae6ec1286e2ada890710","It is possible to make Integrated Development Environments supporting formal methods that can be as flexible as the support for dynamic programming languages. This paper contributes with a demonstration employing different support environments for the Vienna Development Method Specification Language (VDMSL) and design by contract for visual programming language. This includes ViennaTalk developed on top of Pharo 4 providing Smalltalk-styled LIVE browsers, VDM-SL interpreters, Smalltalk code generators, UI prototyping environments and a prototypeWeb API server to enable rigorous and flexible modeling during exploratory phases of software development. ViennaTalk uses the Slot mechanism in Pharo to test invariant assertions on instance variables in Smalltalk objects generated from VDM-SL specifications. In addition, we present a plugin named Assertch for Phratch, a scratch-clone visual programming environment on top of Pharo 4, that provides assertion blocks for designing and debugging a series of blocks. Both ViennaTalk and Assertch combine flexible live modeling or coding while still supporting rigorous checking. ViennaTalk has been evaluated by experienced professional engineers of VDM-SL while Assertch has been evaluated by undergraduate students of computer science. ViennaTalk and Assertch both demonstrate that Pharo and its contemporary features support rigorous modeling in formal specification languages as well as flexible prototyping in Smalltalk. ©2016 held by owner/author(s).","Lightweight formal methods; Live environment; Specification animation; Validation","Computer programming; Computer systems programming; Dynamic programming; Formal specification; Modeling languages; Software design; Software prototyping; Specification languages; Specifications; Students; Visual languages; Integrated development environment; Lightweight formal methods; Live environment; Specification animations; Validation; Vienna development methods; Visual programming environments; Visual programming languages; Formal methods",2-s2.0-85006760116
"Zhu R., Sang G., Zhao Q.","Discriminative Feature Adaptation for cross-domain facial expression recognition",2016,"2016 International Conference on Biometrics, ICB 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988353684&doi=10.1109%2fICB.2016.7550085&partnerID=40&md5=4c2b61f6dfb4f988b46afa5e08bd37b9","Facial expression recognition is an important problem in many face-related tasks, such as face recognition, face animation, affective computing and human-computer interface. Existing methods mostly assume that testing and training face images are captured under the same condition and from the same population. Such assumption is, however, not valid in real-world applications, where face images could be taken from varying domains due to different cameras, illuminations, or populations. Motivated by recent progresses in domain adaptation, this paper proposes an unsupervised domain adaptation method, called discriminative feature adaptation (DFA), which requires for training a set of labelled face images in the source domain and some additional unlabelled face images in the target domain. It seeks for a feature space to represent face images from different domains such that two objectives are fulfilled: (i) mismatches between the feature distributions of these face images are minimized, and (ii) features are discriminative among these face images with respect to their facial expressions. Compared with existing methods, the proposed method can more effectively adapt discriminative features for recognizing facial expressions in various domains. Evaluation experiments have been done on four public facial expression databases: CK+, JAFFE, PICS, and FEED. The results demonstrate the superior performance of the proposed method over competing methods. © 2016 IEEE.",,"Biometrics; Human computer interaction; Speech recognition; Affective Computing; Different domains; Discriminative features; Evaluation experiments; Facial expression recognition; Facial Expressions; Feature distribution; Human computer interfaces; Face recognition",2-s2.0-84988353684
"Chang H.-T., Peng H.-W., Tsai C.-H.","CUDA-accelerated rendering of fireworks in nearly ultra high definition videos",2016,"Proceedings - 2016 IEEE 2nd International Conference on Multimedia Big Data, BigMM 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987623795&doi=10.1109%2fBigMM.2016.74&partnerID=40&md5=cd2303641e1cf1b48efd1076fab36569","In this paper, a framework of generating dynamic fireworks with a steady scene as the background is proposed. We use the particle system for simulating the firework animation to obtain a video clip, which can then be modified based on physical dynamics and the dissemination of light source. To achieve this goal, the general-purpose computation on graphics processing unit (GPGPU) for rendering and the linked list approach in C/C++ Language are integrated in the proposed method to enhance the computation efficiency. The introduction of a new computing technology termed «compute unified device architecture» (CUDA) is used to achieve higher efficiency and frame rates due to its capability on the parallel computing and memory allocation for display. Finally, the experimental results show that the proposed method significantly enhances the system performance in both the rendering and program execution efficiency. The video frame rate can achieve as high as than in nearly ultra - high definition videos. © 2016 IEEE.","Background illumination; CUDA; Firework; GPU; Particle system; Ultra-high definition video","Big data; C (programming language); Computer graphics; Computer graphics equipment; Consumer electronics; Display devices; Efficiency; Explosives; Image coding; Light sources; List processing languages; Memory architecture; Program processors; Video cameras; Background illumination; CUDA; Firework; Particle systems; Ultra high definitions; Rendering (computer graphics)",2-s2.0-84987623795
"Warriner A.H., Foster P.J., Mudano A., Wright N.C., Melton M.E., Sattui S.E., Calmbach W., Curtis J.R., Kilgore M., Lewis C.E., Pace W., Saag K.G.","A pragmatic randomized trial comparing tablet computer informed consent to traditional paper-based methods for an osteoporosis study",2016,"Contemporary Clinical Trials Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975522165&doi=10.1016%2fj.conctc.2016.02.003&partnerID=40&md5=817451a029868982d0ae598a510cc7d4","Objective Methods to improve informed consent efficiency and effectiveness are needed for pragmatic clinical trials. We compared informed consent using a tablet computer to a paper approach to assess comprehension and satisfaction of patients and clinic staff for a future osteoporosis clinical trial. Methods Nine community-based practices identified and recruited patients to compare the informed consent processes (tablet vs. paper) in a mock osteoporosis clinical trial. The tablet informed consent included an animation summarizing the trial, complete informed consent document, and questions to assess and reinforce comprehension of the study. Participants were women age ≥55 years with ≥1 year of alendronate use. We surveyed participants to assess comprehension and satisfaction and office staff for satisfaction and perceived time demands. Results The nine practices enrolled 33 participants. There was not a significant difference in comprehension between the tablet vs. paper informed consent [mean (SD) tablet: 12.2 (1.0) vs. paper: 11.4 (1.7)]. Office staff preferred the tablet to the paper informed consent for identifying potential study participants (two-sided t-test p = 0.02) despite an increased perceived time spent to complete the tablet process [tablet: 28.3 min (SD 16.3) vs. paper: 19.0 min (SD 6.9); p = 0.08]. Conclusions Although, there were no significant differences in participant satisfaction and comprehension with the tablet informed consent compared to a paper informed consent, patients and office staff trended towards greater satisfaction with the tablet informed consent. Larger studies are needed to further evaluate the utility of electronic informed consent in pragmatic clinical trials. © 2016 Published by Elsevier Inc.","Informed consent; Osteoporosis; Pragmatic clinical trials","alendronic acid; adult; aged; Alabama; Article; Colorado; comprehension; computer; controlled study; female; health care survey; human; informed consent; multicenter study; multiple choice test; osteoporosis; paper; randomized controlled trial; satisfaction; social security; tablet computer; Texas",2-s2.0-84975522165
"Frankjær R., Kitel M.","Flora Luma: A research-oriented artistic exploration of human-vegetal participatory space",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017391600&doi=10.1145%2f2948076.2948115&partnerID=40&md5=a39db8b059aa6d89eee543733617801e","Flora Luma is a plant-controlled installation, developed by the authors. It utilises bioelectrical signals to drive color-animation of self-illuminating objects. Electrical signaling constitutes a part of plant vocabulary, employed for intra- and interspecies communication. Recent findings ascertain plants to be much more perceptive of their environment, than previously thought [2,5]. Terms like plant behaviour and plant intelligence are entering scholarly discourse and have been the subject of both major articles in respected media [3,8] and artistic exploration [10]. Yet, the public is largely unaware of the richness of plant life and communication. Flora Luma is designed to provide an insight into the inner workings of plant life, serving as a mediating device allowing the spectator to directly interact with the plant and receive visible real-time feed-back. Plant and human become hybrid agents jointly creating unique artistic reality. The installation highlights the reciprocal relationship and participatory nature between vegetal and human space. Copyright is held by the owner/author(s).","Flora Luma; Human-plant interaction; Human-plant participation; Human-vegetal space; Interspecies communication; Light art; Mediated interspecies interaction; Non-anthropocentric art; Parliament of beings; Participatory design; Research-oriented artistic exploration","Computer programming; Flora Luma; Human-plant participation; Human-vegetal space; Interspecies interactions; Non-anthropocentric art; Parliament of beings; Participatory design; Plant interactions; Computer applications",2-s2.0-85017391600
"Huang X.-Y.","Jumping space-time - The interpretation of animation shots editing techniques",2016,"2016 International Conference on Applied System Innovation, IEEE ICASI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988521425&doi=10.1109%2fICASI.2016.7539925&partnerID=40&md5=b97fcfd000b5e8b1e1a4bb0d79de03c7","Animation shots editing techniques help to establish distinctive narrative structures and diversified expression purposes of animation. This paper interprets in details the space and time editing logic manipulated in animation shots editing techniques. Also, it summarizes the intrinsic relationship among animation shots editing techniques, narrative sequences and emotions by analyzing the principles, purposes and share of shots space-time editing techniques based on theories and data analysis. The results of analysis are applied to guide animation teaching and creation and to explore the animation expression possibilities in terms of forms and content of animation. © 2016 IEEE.","Shots Logic; Space Editing; Time Editing","Computer circuits; Reconfigurable hardware; Narrative structures; Shots Logic; Space and time; Space Editing; Space time; Time Editing; Animation",2-s2.0-84988521425
"Fechteler P., Paier W., Hilsmann A., Eisert P.","Real-time avatar animation with dynamic face texturing",2016,"Proceedings - International Conference on Image Processing, ICIP",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006829813&doi=10.1109%2fICIP.2016.7532378&partnerID=40&md5=d5ff0b088683631b3652962e16384ef4","In this paper, we present a system to capture and animate a highly realistic avatar model of a user in real-time. The animated human model consists of a rigged 3D mesh and a texture map. The system is based on KinectV2 input which captures the skeleton of the current pose of the subject in order to animate the human shape model. An additional high-resolution RGB camera is used to capture the face for updating the texture map on each frame. With this combination of image based rendering with computer graphics we achieve photo-realistic animations in real-time. Additionally, this approach is well suited for networked scenarios, because of the low per frame amount of data to animate the model, which consists of motion capture parameters and a video frame. With experimental results, we demonstrate the high degree of realism of the presented approach. © 2016 IEEE.","Avatar animation; Capturing; Real-time; Texture","Animation; Computer graphics; Image reconstruction; Textures; Capturing; High resolution; Human shapes; Image based rendering; Motion capture; Photo-realistic animation; Real time; Texture maps; Image processing",2-s2.0-85006829813
"Ward M.","Using animated visualisation in Computer Assisted Language Learning",2016,"Proceedings - 2016 9th International Conference on Human System Interactions, HSI 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992195900&doi=10.1109%2fHSI.2016.7529606&partnerID=40&md5=d087e7dd2eb23866193ef34fad4aa83e","Computer Assisted Language Learning (CALL) uses computers in the language learning process. The design and development of CALL resources is difficult and sometimes the potential of HCI in the process is overlooked. This paper provides an overview of how the CALLIPSO (CALL for Irish for Parents Students and Others) system uses animated visualisation to demonstrate words are pronounced in Irish. Irish is an orthographically deep language and the pronunciation of a word is sometimes not immediately obvious to a learner. The CALLISPO system combines research findings from HCI and user-modelling to provide an interactive learning resource for Irish. © 2016 IEEE.","animation; Computer Assisted Language Learning; Computer Assited Learning; Irish; visualisation","Animation; E-learning; Learning systems; Linguistics; Visualization; Computer assisted language learning; Design and Development; Interactive learning; Irish; Language learning; System use; User Modelling; Computer aided instruction",2-s2.0-84992195900
"Zhao H., Li J.-B., Zeng X.-Y.","Algorithm for coding unit partition in 3D animation using high efficiency video coding based on Canny operator segment",2016,"Journal of Digital Information Management",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991688577&partnerID=40&md5=e79dd6271010e213a188565709bc9824","The involvement of a huge volume of man-made models and frames in 3D digital animations results in high coding costs using high efficiency video coding (HEVC). Studies identified the unique features of textures in 3D models that aids in predicting the depth of coding units (CU). The fast algorithm for CU partition, which was based on the texture features of the 3D models, was proposed to decrease coding complexity and shorten coding time. Canny operator was introduced to facilitate the segmentation of key frames in 3D animation. The optimal depth of the current CU was predicted based on its location and that of adjacent CUs, as well as the CU located at the current position of the reference frame. To reduce prediction errors in complex areas, rate-distortion optimization method was used to conduct precise partition. Compared with the performance of the original high efficiency video coding algorithm, the proposed algorithm shortened encoding time by 39.20% when the peak-signal-to-noise ratio of brightness was decreased by 0.07 dB and the encoding bit rate was increased by 0.84%. These results indicate the practical utility of the proposed algorithm and its excellent performance in improving coding time. © 2016, Digital Information Research Foundation. All rights reserved.","Coding unit; Depth prediction; Fast partition; High efficiency video coding; Texture features of 3D animation","Animation; Codes (symbols); Efficiency; Electric distortion; Encoding (symbols); Forecasting; Image coding; Image segmentation; Optimization; Signal distortion; Signal to noise ratio; Video signal processing; 3D animation; Coding complexity; Coding unit; High-efficiency video coding; Peak signal to noise ratio; Prediction errors; Rate-distortion optimization; Texture features; Three dimensional computer graphics",2-s2.0-84991688577
"Cherchi G., Livesu M., Scateni R.","Polycube Simplification for Coarse Layouts of Surfaces and Volumes",2016,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982084499&doi=10.1111%2fcgf.12959&partnerID=40&md5=5ef76922d51c942f1ad7f3b6b93625ce","Representing digital objects with structured meshes that embed a coarse block decomposition is a relevant problem in applications like computer animation, physically-based simulation and Computer Aided Design (CAD). One of the key ingredients to produce coarse block structures is to achieve a good alignment between the mesh singularities (i.e., the corners of each block). In this paper we improve on the polycube-based meshing pipeline to produce both surface and volumetric coarse block-structured meshes of general shapes. To this aim we add a new step in the pipeline. Our goal is to optimize the positions of the polycube corners to produce as coarse as possible base complexes. We rely on re-mapping the positions of the corners on an integer grid and then using integer numerical programming to reach the optimal. To the best of our knowledge this is the first attempt to solve the singularity misalignment problem directly in polycube space. Previous methods for polycube generation did not specifically address this issue. Our corner optimization strategy is efficient and requires a negligible extra running time for the meshing pipeline. In the paper we show that our optimized polycubes produce coarser block structured surface and volumetric meshes if compared with previous approaches. They also induce higher quality hexahedral meshes and are better suited for spline fitting because they reduce the number of splines necessary to cover the domain, thus improving both the efficiency and the overall level of smoothness throughout the volume. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Geometric algorithms, languages, and systems","Animation; Computational geometry; Computer graphics; Integer programming; Modeling languages; Pipelines; Block decomposition; Block structured; Computational Geometry and Object Modeling; Computer animation; Descriptors; Numerical programming; Optimization strategy; Physically-based simulation; Computer aided design",2-s2.0-84982084499
"Dong Y., Wang Y., Yue J., Hu Z.","Real time 3D facial movement tracking using a monocular camera",2016,"Sensors (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979556449&doi=10.3390%2fs16081157&partnerID=40&md5=bf4e57a3924fb246feab613ef0a62047","The paper proposes a robust framework for 3D facial movement tracking in real time using a monocular camera. It is designed to estimate the 3D face pose and local facial animation such as eyelid movement and mouth movement. The framework firstly utilizes the Discriminative Shape Regression method to locate the facial feature points on the 2D image and fuses the 2D data with a 3D face model using Extended Kalman Filter to yield 3D facial movement information. An alternating optimizing strategy is adopted to fit to different persons automatically. Experiments show that the proposed framework could track the 3D facial movement across various poses and illumination conditions. Given the real face scale the framework could track the eyelid with an error of 1 mm and mouth with an error of 2 mm. The tracking result is reliable for expression analysis or mental state inference. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","3D facial movement; Eyelid; Facial animation; Facial feature points; HCI","Animation; Cameras; Human computer interaction; Regression analysis; 3-D face modeling; Expression analysis; Eyelid; Facial animation; Facial feature points; Facial movements; Illumination conditions; Monocular cameras; Face recognition",2-s2.0-84979556449
"González-Rojas O., Correal D., Camargo M.","ICT capabilities for supporting collaborative work on business processes within the digital content industry",2016,"Computers in Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964691575&doi=10.1016%2fj.compind.2016.04.004&partnerID=40&md5=ecb879504c14bb77c61c0c9398d04cc1","The digital content industry requires the integration of specialized information and communications technology (ICT) capabilities to support collaborative work for planning and executing its business processes. In particular, this knowledge-intensive industry lacks for adequate control on product documentation, inter and intra organizational resources management, and process monitoring which is required for supporting the high demand of projects typically constrained in time, costs, and quality. This paper presents a defined maturity model named DigiCoMM to assess collaboration and interoperability capabilities that are specific to pre-production, production, and post-production processes within the digital content industry. It also presents MONO, a computer-supported collaborative work (CSCW) software for supporting the incremental transition of companies through the different levels of the maturity model. MONO was developed in the context of the DAVID research project (Strategic Programme for the Research and Development of the Colombian Animation and Video Games Industry), during the period of 2012-2015. This model and software were used to assess and support the collaborative capabilities of several animation and video game companies in Colombia. © 2016 Elsevier B.V. All rights reserved.","Computer-supported cooperative work; Digital content industry; Domain-specific capability model","Animation; Computer supported cooperative work; Interactive computer graphics; Process monitoring; Capability model; Digital contents; Information and communications technology; Knowledge-intensive industries; Product documentation; Production process; Research and development; Resources management; Project management",2-s2.0-84964691575
"da Silva Junior J.R., Clua E., Murta L.","Efficient image-aware version control systems using GPU",2016,"Software - Practice and Experience",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932599141&doi=10.1002%2fspe.2340&partnerID=40&md5=cb5c4ad1cd8ef74c2a598d56e1585398","Version control is considered to be a vital component for supporting professional software development. While it has been widely used for textual artifacts, such as source code or documentation, little attention has been given to binary artifacts. This omission can place huge restrictions on projects in the game and media industries as they contain large amounts of binary data, such as images, videos, three-dimensional models, and animations, along with their source code. For these kinds of artifacts, existing strategies such as storing the file as a whole for each revision or saving conventional binary deltas consume significant storage space with duplicate data and, even worse, do not provide any understandable information on which modifications were made. As a response to this problem, this paper introduces a change-set model infrastructure to support version control of image artifacts using a specialized data structure. Additionally, our approach can deal with the maintenance of duplicate nearly identical images through a merge operation. Because of the amount of data that has to be processed, we designed our solution based on a parallel architecture, which permits a massively parallel approach to version control. The paper also compares our approach with some popular open-source version control systems, showing their repository growth in relation to ours as well as the time required to process image artifacts. Finally, we demonstrate that our architecture requires less storage space and runs much faster than current methods. Copyright © 2015 John Wiley & Sons, Ltd. Copyright © 2015 John Wiley & Sons, Ltd.","CUDA; GPU; image; version control","Animation; Bins; Control systems; Digital storage; Open source software; Open systems; Parallel architectures; Software design; Three dimensional computer graphics; CUDA; GPU; Image; Massively parallels; Professional software; Three-dimensional model; Version control; Version control system; Information management",2-s2.0-84932599141
"Litany O., Rodolà E., Bronstein A.M., Bronstein M.M., Cremers D.","Non-Rigid Puzzles",2016,"Computer Graphics Forum",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982142757&doi=10.1111%2fcgf.12970&partnerID=40&md5=1e043eb50ed26a684df2bd48c48cb4fe","Shape correspondence is a fundamental problem in computer graphics and vision, with applications in various problems including animation, texture mapping, robotic vision, medical imaging, archaeology and many more. In settings where the shapes are allowed to undergo non-rigid deformations and only partial views are available, the problem becomes very challenging. To this end, we present a non-rigid multi-part shape matching algorithm. We assume to be given a reference shape and its multiple parts undergoing a non-rigid deformation. Each of these query parts can be additionally contaminated by clutter, may overlap with other parts, and there might be missing parts or redundant ones. Our method simultaneously solves for the segmentation of the reference model, and for a dense correspondence to (subsets of) the parts. Experimental results on synthetic as well as real scans demonstrate the effectiveness of our method in dealing with this challenging matching scenario. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Shape Analysis","Algorithms; Computational geometry; Computer graphics; Deformation; Medical imaging; Medical problems; Computational Geometry and Object Modeling; Dense correspondences; Descriptors; Non-rigid deformation; Reference modeling; Shape correspondences; Shape matching algorithms; Texture mapping; Computer vision",2-s2.0-84982142757
"Augusto I., Monteiro D., Girard-Dias W., Dos Santos T.O., Belmonte S.L.R., De Oliveira J.P., Mauad H., Da Silva Pacheco M., Lenz D., Bittencourt A.S., Nogueira B.V., Dos Santos J.R.L., Miranda K., Guimarães M.C.C.","Virtual reconstruction and three-dimensional printing of blood cells as a tool in cell biology education",2016,"PLoS ONE",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984782974&doi=10.1371%2fjournal.pone.0161184&partnerID=40&md5=e7f83bfd6a5fd8f23522813ab5f4e2d3","The cell biology discipline constitutes a highly dynamic field whose concepts take a long time to be incorporated into the educational system, especially in developing countries. Amongst the main obstacles to the introduction of new cell biology concepts to students is their general lack of identification with most teaching methods. The introduction of elaborated figures, movies and animations to textbooks has given a tremendous contribution to the learning process and the search for novel teaching methods has been a central goal in cell biology education. Some specialized tools, however, are usually only available in advanced research centers or in institutions that are traditionally involved with the development of novel teaching/learning processes, and are far from becoming reality in the majority of life sciences schools. When combined with the known declining interest in science among young people, a critical scenario may result. This is especially important in the field of electron microscopy and associated techniques, methods that have greatly contributed to the current knowledge on the structure and function of different cell biology models but are rarely made accessible to most students. In this work, we propose a strategy to increase the engagement of students into the world of cell and structural biology by combining 3D electron microscopy techniques and 3D prototyping technology (3D printing) to generate 3D physical models that accurately and realistically reproduce a close-to-the native structure of the cell and serve as a tool for students and teachers outside the main centers. We introduce three strategies for 3D imaging, modeling and prototyping of cells and propose the establishment of a virtual platform where different digital models can be deposited by EM groups and subsequently downloaded and printed in different schools, universities, research centers and museums, thereby modernizing teaching of cell biology and increasing the accessibility to modern approaches in basic science. © 2016 Augusto et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"biomedicine; blood cell; cytology; electron microscopy; human; human experiment; imaging; information center; learning; physical model; structure activity relation; teacher; teaching; three dimensional printing; university; animal; blood cell; computer interface; image processing; male; procedures; rat; tomography; Wistar rat; Animals; Blood Cells; Image Processing, Computer-Assisted; Male; Printing, Three-Dimensional; Rats; Rats, Wistar; Tomography; User-Computer Interface",2-s2.0-84984782974
"Scrivener M., de Jong E.E.C., van Timmeren, Pieters T., Ghaye B., Geets X.","Radiomics applied to lung cancer: A review",2016,"Translational Cancer Research",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983288387&doi=10.21037%2ftcr.2016.06.18&partnerID=40&md5=b76ef09340bf8c4ea4daaa1e38465c74","Lung cancers exhibit strong phenotypic differences that can be visualized noninvasively by medical imaging. Radiomics, a concept introduced in 2012, refers to the comprehensive quantification of tumor phenotypes by applying a large number of quantitative image features (watch the animation: https://youtu.be/Tq980GEVP0Y and the website www.radiomics.org). Here, we review the literature related to radiomics for lung cancer. We found 11 papers related to computed tomography (CT) radiomics, 3 to radiomics or texture analysis with positron emission tomography (PET) and 8 relating to PET/CT radiomics. There are two main applications of radiomics, the classification of lung nodules (diagnostic) or prognostication of established lung cancer (theragnostic). There are quite a few methodological issues in most of the reviewed papers. Only 5 studies, out of the 22, were externally validated. Overall, it is clear that radiomics offers great potential in improving diagnosis and patient stratification in lung cancer. It may also have a real clinical impact, as imaging is routinely used in clinical practice, providing an unprecedented opportunity to improve decision support in lung cancer treatment at low cost. © Translational Cancer Research.","Imaging; Lung cancer; Radiomics; Theragnostic","cancer classification; clinical feature; computer assisted emission tomography; computer assisted tomography; diagnostic imaging; human; image processing; image segmentation; lung cancer; meta analysis (topic); oncological parameters; positron emission tomography; radiomics; Review; tumor volume; validation process; workflow",2-s2.0-84983288387
"Bernal Villamarin S.C., Morales D.A.C., Reyes C.A.A., Sanchez C.A.","Application design sign language colombian for mobile devices: VLSCApp (Voice Colombian sign language app) 1.0",2016,"Proceedings of 2016 Technologies Applied to Electronics Teaching, TAEE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992088926&doi=10.1109%2fTAEE.2016.7528378&partnerID=40&md5=a9d29a7a3ae39b7fc8d1b6ebec220f02","Currently in Colombia the Ministry of National Education and the National Institute for the Deaf (INSOR) consider it important that the deaf community for teaching and learning on an equal footing due to the low educational level and the difficulty in accessing social, communication and employment opportunities equity. Which shows the lack of technological tools for the deaf community in constant interaction with the hearing community in order to create the possibility and reduce communication gaps taking advantage of the visual strength of the deaf community. Integrating Colombian sign language as their mother tongue and the written language of Spanish as a second language to form part of their cultural context. For this reason Hotbed of INNOVAPP Research proposes the design of an application for language Colombian motioned for mobile devices where voice recognition for listeners who want to know sign language and recognition of written language for their respective integrates translation animation 3D representation of the letter requested in Colombian Sign Language in order to strengthen the bicultural bilingual model of the deaf community with the hearing community. © 2016 IEEE.","Application for Mobile Devices; Colombian Sign Language; Deaf Community","Audition; Mobile devices; Three dimensional computer graphics; 3d representations; Application design; Deaf Community; Educational levels; Employment opportunities; Sign language; Teaching and learning; Technological tools; E-learning",2-s2.0-84992088926
"Johnson R.A., Solis A.","Using photogrammetry to interpret human action on Neolithic monument boulders in Ireland's Cavan Burren",2016,"Journal of Archaeological Science: Reports",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971393513&doi=10.1016%2fj.jasrep.2016.05.055&partnerID=40&md5=055fb9ef86a2762df6ff615bb19dee99","Digital technology has been increasingly employed in the documentation and analysis of archaeology in the last ten years. We utilized user-friendly digital photogrammetry and animation to assist in the analysis of archaeological evidence in Ireland. Our tools were commercially available software, a consumer-grade hand-held or tripod-supported digital camera, and a personal computer. The method was developed for and has been subsequently used by local archaeological surveyors in an extensive documentation of prehistoric settlement features within the Marble Arch Caves Global Geopark in Ireland. The boulder monuments are unusual in that they are made from glacial erratics whose surfaces display traditional North Atlantic rock art and a new sculpting art form. Pieces making up two boulder monuments were digitally manipulated via animation into what is believed to be their original source stone configurations. Their matching surfaces were studied in detail. The process was employed to demonstrate, non-invasively, how the monuments might have resulted from some actions other than weathering. The analysis supports the hypothesis that humans worked the monuments, which, in turn, supports protection of the monuments for further study. © 2016 Published by Elsevier Ltd.","Automatic 3D reconstruction; Cavan Burren; Neolithic monuments; Neolithic sculpting; Photogrammetry; Virtual manipulation",,2-s2.0-84971393513
"Shoufan A.","Live demonstration of DLD-VISU: An eLearning platform for digital logic design",2016,"Proceedings - IEEE International Symposium on Circuits and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983391344&doi=10.1109%2fISCAS.2016.7527522&partnerID=40&md5=e271f99687344b6b0b1f8b4f976027bb","In this demo we will present DLD-VISU which is a web-based tool for the visualization and animation of digital logic design [1]. Combinatorial circuits can be built using logic gates, multiplexers, decoders, and look-up tables. Various configurations of finite state machines can be selected to define the machine type, the state code, and the flip-flop type. Logic minimization with the K-map approach and the Quine McCluskey scheme is also supported. The tools help students practice related topics in digital logic design courses. Also, instructors can use the tools to efficiently generate and verify examples for lecture notes or for homework problems and assignments. The tools support self-assessment and reflect the student learning process using learning curves. DLD-VISU, that was developed in collaboration between Khalifa University and Technische Universität Darmstadt, has been used in teaching digital logic design since Fall 2013 with a positive impact on students' motivation and learning. © 2016 IEEE.",,"Combinatorial circuits; Curricula; Design; E-learning; Flip flop circuits; Logic design; Logic Synthesis; Reconfigurable hardware; Students; Table lookup; Teaching; Digital logic design; E-learning platforms; Learning curves; Logic minimization; Quine-McCluskey; Self assessment; Student learning process; Web-based tools; Computer circuits",2-s2.0-84983391344
"Uchida T., Umeda S., Azuma M., Miyazaki T., Kato N., Hiruma N., Inoue S., Nagashima Y.","Provision of emergency information in sign language CG animation over integrated broadcast-broadband system",2016,"IEEE International Symposium on Broadband Multimedia Systems and Broadcasting, BMSB",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982170448&doi=10.1109%2fBMSB.2016.7521930&partnerID=40&md5=848248ed332fa61e37c883eda53939f9","As part of an effort to expand broadcasting services based on Japanese Sign Language (JSL), we are investigating various types of JSL-based service for delivering information to people whose first language is JSL. In this report, we present a JSL computer graphics (CG) prototype system using Japan's integrated broadcast-broadband (IBB) framework, Hybridcast. Delivery of JSL CG contents using the Internet enables JSL CG animation to be displayed in conjunction with a broadcast program on second screen devices such as smartphones and tablets. The signals providing emergency information are triggered by reception of an event message (EM) embedded in the transport stream (TS) transmitted over the air. Testing showed that emergency earthquake information can be provided by JSL CG animation within 2 seconds of EM reception. It also showed that local government evacuation instructions corresponding to the user's residence (based on location information stored in the TV set) can be displayed on a second screen device. Despite the dependence of the drawing speed on the performance of the hardware and web browser, the proposed system is a promising way to provide information services in JSL. © 2016 IEEE.","Animation; Computer graphics; IPTV; Sign language; TV broadcasting","Animation; Broadcasting; Computational linguistics; Computer graphics; Information services; Multimedia systems; Television broadcasting; Broadband systems; Broadcasting service; Emergency information; Japanese sign languages; Location information; Sign language; Transport streams; TV broadcasting; IPTV",2-s2.0-84982170448
"Hayashi M., Shishikui Y., Bachelder S., Nakajima M.","An attempt of mimicking TV news program with full 3DCG - Aiming at the Text-Generated TV system",2016,"IEEE International Symposium on Broadband Multimedia Systems and Broadcasting, BMSB",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982166339&doi=10.1109%2fBMSB.2016.7521902&partnerID=40&md5=ab90b2fc2ae2e78cdebf765f8c712676","We have been studying and developing a new television system based on a methodology which delivers text-based scripts through the Internet representing visual contents instead of transmitting visual content in a format of video data. Such a Text-Generated TV System is achieved by the technology called TVML (TV program Making Language) enabling to create TV-program-like computer graphics animation automatically from script. One of the problems in our development is how to establish the scheme of TV program production with TVML to get quality contents like in a real TV broadcast. Our approach to the problem is to analyze the real TV program and to mimic it with TVML. We first choose a reference TV program then analyze it in many aspects. Based on the acquired knowledge, we then transfer those findings to CG production made using TVML to make a copy of the original TV show as faithful as possible. The objective of the attempt is to reveal the essential elements which would be needed to obtain a full-CG TV program with quality. In this paper, we describe the mimicking process of the news show, the result of the TVML production with a comparison to the original and the evaluation result that we conducted with testers. Finally, we discuss the pros and cons of the CG production applied to produce news show and have shed light on the problems. © 2016 IEEE.","CG; intelligent coding; TV broadcasting; TVML; video production","Broadcasting; Computer graphics; Multimedia systems; Television systems; Video recording; Essential elements; Evaluation results; intelligent coding; Quality content; TV broadcasting; TVML; Video production; Visual content; Television broadcasting",2-s2.0-84982166339
"Fonseca J.A.S., Kravtsov D., Sarafopoulos A., Zhang J.J.","Enhancement of 3D character animations through the use of automatically generated guidelines inspired by traditional art concepts",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985993356&doi=10.1145%2f2945078.2945114&partnerID=40&md5=71d2a2ac5569c1bb89273540d6901345","Effective communication through character animation depends on the recognition of the performed body expressions. The creation of the right body postures is crucial for character animation in the context of animated films and games, as it allows for conveying the right set of emotions to the viewer. Audience needs to be able to identify familiar features mainly based on their own experiences, which allows the viewer to relate and feel empathy to observed characters. It is, therefore, crucial for the animator to accurately create the right posture and expressive body motion, during the posing phase of the animation process.","Body expression; Character posing; Computer animation","Computer graphics; Interactive computer graphics; Motion pictures; 3D character animation; Automatically generated; Body expression; Body postures; Character animation; Character posing; Computer animation; Effective communication; Animation",2-s2.0-84985993356
"Kazi R.H., Grossman T., Umetani N., Fitzmaurice G.","SKUID: Sketching dynamic drawings using the principles of 2D animation",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986226563&doi=10.1145%2f2897839.2927410&partnerID=40&md5=cf2357a9492c0369ea0479c5a8c77ff0","Skuid is a sketching tool for crafting animated illustrations that contain the exaggerated dynamics of stylized 2D animations. Skuid provides a set of motion amplifiers which implement a set of established principles of 2D animation. These amplifiers break down a complex animation effect into independent, understandable chunks. Each amplifier imposes deformations to an underlying grid, which in turn updates the corresponding strokes. Users can combine these amplifiers at will when applying them to an existing animation, promoting rapid experimentation. Skuid leverages the freeform nature of sketching, allowing users to rapidly sketch, record motion, explore exaggerated dynamics using the amplifiers, and fine- Tune their animations. Practical results confirm that users with no prior experience in animation can produce expressive animated illustrations quickly and easily with Skuid. © 2016 Copyright held by the owner/author(s).","Motion amplifiers; Principles of animation; Sketching","Computer graphics; Interactive computer graphics; 2D animation; Animation effects; Break down; Freeforms; Motion amplifier; Prior experience; Sketching; Sketching tools; Animation",2-s2.0-84986226563
"Hessler M., Talbot J.","AutoSpline: Animation controls only when and where you need them",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986199011&doi=10.1145%2f2897839.2927439&partnerID=40&md5=3868aa9aaa90f7cfe4f2854eeeb1592b","Unsimulated character animation of items like ropes or snakes is challenging in the amount of articulation required and the degrees of freedom needing control. At Pixar we developed a powerful new system for animating highly directible curves: AutoSpline. This system is designed to give animators enormous control, without the overhead of managing every aspect of every control when only simple shapes or motions are required. We accomplished this by providing the ability to switch sets of controls between manual and automatic modes on a frame-by-frame basis. Controls can also be dynamically repositioned per frame so that animators can focus the available controls where highest detail is needed for any given shape or motion. The AutoSpline architecture also includes advanced constraint abilities, simplifying historically difficult interactions between the flexible object and other objects in the scene. While these features made it feasible to animate the many- Tentacled Hank in Pixar's Finding Dory as a primary character, AutoSpline was built as a general solution. Early versions were successfully used in Pixar's Inside Out and The Good Dinosaur. Notably, it inspired a similar tool at ILM, used on Star Wars: The Force Awakens. © 2016 Copyright held by the owner/author(s).","Animated spline; Automatic shape; Time varying","Computer graphics; Degrees of freedom (mechanics); Interactive computer graphics; Animation control; Automatic mode; Automatic shape; Character animation; Flexible object; Frame-by-frame basis; General solutions; Time varying; Animation",2-s2.0-84986199011
"Dosé F., Cachelin A.","MotionGraphix: A 2.5D stereoscopic animation system on your iPad",2016,"ACM SIGGRAPH 2016 Appy Hour, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984653646&doi=10.1145%2f2936744.2936748&partnerID=40&md5=7c40888cc65beb7f8dbe01e2bf4a5f27","MotionGraphix is the first stereoscopic 2.5D animation system for the iPad. It combines powerful, professional-level animation features like keyframing and algorithmic motions with a wide variety of graphic element types, from text or animated sprites to particle systems and replicators. MotionGraphix includes a set of ready-to-use motion templates, a variety of sprites, or cutout images, and some background images. These elements, in conjunction with the inline help system and online tutorials, make MotionGraphix easy to learn, while the depth of features make it suitable for producing professional quality animations. Copyright is held by the owner/author(s).","2.5D; Animation; Sprite; Stereoscopic","Animation; Computer graphics; Hand held computers; Stereo image processing; 2.5D; Animation systems; Background image; Graphic elements; Particle systems; Professional levels; Sprite; Stereoscopic; Interactive computer graphics",2-s2.0-84984653646
"Jordan M., Constantine K.","Coda: The cultural effects of queueing at disney animation",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986220311&doi=10.1145%2f2897839.2927420&partnerID=40&md5=d38ca67309fb40770ae7484d159b8212","When we began designing the new queueing system for Walt Disney Animation Studios, we had a simple goal in mind: Take some shell commands, run them on some remote machines, and return the results. What we thought would be a six month project evolved into an eight year journey that helped revolutionize the culture at our studio, and built a world class queueing system capable of executing millions of tasks per day. Three key features of Coda, automated render wrangling, localized job priority, and advanced desktop rendering, have helped to encourage a culture of trust and collaboration, both amongst the different shows competing for queue resources, and between the production and technology organizations in the studio. © 2016 Copyright held by the owner/author(s).","Batch queueing; Renderfarm; Scheduling; Studio culture","Animation; Computer graphics; Interactive computer graphics; Queueing networks; Rendering (computer graphics); Scheduling; Studios; Animation studios; Batch queueing; Cultural effects; Queueing system; Remote machines; Renderfarm; Shell command; Walt Disney; Queueing theory",2-s2.0-84986220311
"Moser L., Corral D., Roble D.","As-rigid- As-possible deformation transfer for facial animation",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986182451&doi=10.1145%2f2897839.2927411&partnerID=40&md5=a6708065b975e4d76583cdd9c5e70583","We present a novel tool for transferring facial motion capture performance between significantly different characters. This work combines the shape deformation techniques of Deformation Transfer (DT) and As-Rigid-As-Possible (ARAP) into a single formulation by defining rigidity over triangle edge sets as opposed to spokes. Further, it improves them by adding non-uniform rigidity using paintable weights. We examine three important use cases for the tool: Adding physically plausible behavior where animation is not available; fixing animation transfer artifacts; and providing plausible deformation around manipulated vertices. By combining Deformation Transfer and As-Rigid-As-Possible, this tool allows users to control the balance between animation fidelity and physically plausible deformation. © 2016 Copyright held by the owner/author(s).","ARAP; As-rigid-As-possible; Deformation transfer","Animation; Computer graphics; Interactive computer graphics; Rigidity; ARAP; Deformation transfer; Edge-sets; Facial animation; Facial motion capture; Non-uniform; Shape deformation; Deformation",2-s2.0-84986182451
"Entem E., Barthe L., Cani M.-P., Van De Panne M.","From drawing to animation-ready vector graphics",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985910563&doi=10.1145%2f2945078.2945130&partnerID=40&md5=00f0f4491599fb380019410da2e2b3a4","We present an automatic method to build a layered vector graphics structure ready for animation from a clean-line vector drawing of an organic, smooth shape. Inspiring from 3D segmentation methods, we introduce a new metric computed on the medial axis of a region to identify and quantify the visual salience of a sub-region relative to the rest. This enables us to recursively separate each region into two closed sub-regions at the location of the most salient junction. The resulting structure, layered in depth, can be used to pose and animate the drawing using a regular 2D skeleton. © 2016 Copyright held by the owner/author(s).","Drawing edition; Shape segmentation; Vector drawing analysis","Animation; Computer graphics; Interactive computer graphics; Vectors; 3D segmentation; Automatic method; Medial axis; Shape segmentation; Sub-regions; Vector graphics; Visual salience; Drawing (graphics)",2-s2.0-84985910563
"Sato S., Dobashi Y., Nishita T.","Combining multiple flow fields for editing existing fluid animations",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986005399&doi=10.1145%2f2945078.2945140&partnerID=40&md5=2f95d6584ed6430aee51a820a7aada11","In this paper, we develop a method for synthesizing desired flow fields by combining existing multiple flow fields. Our system al-lows the user to specify arbitrary regions of the precomputed flow fields and combine them to synthesize a new flow field. In order to maintain plausible physical behavior, we ensure the incompressibility for the combined flow field. To address this, we use stream functions for representing the flow fields. However, there exist discontinuities at the boundaries between the combined flow fields, resulting in unnatural animation of fluids. In order to remove the discontinuities, we apply Poisson image editing to the stream functions. © 2016 Copyright held by the owner/author(s).","Combining multiple flow fields; Fluid; Incompressible","Computer graphics; Fluids; Interactive computer graphics; Combined flow; Fluid animation; Incompressible; Multiple flows; Physical behaviors; Poisson image editing; Streamfunctions; Flow fields",2-s2.0-84986005399
"Nieto J.R., Facey T., Brugnot S.","A flexible rigging framework for VFX and feature animation",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986229317&doi=10.1145%2f2897839.2927463&partnerID=40&md5=24b5fd3e281d6c8fcb8170eab78d9e7e","We present the work recently undertaken to ensure that Pinocchio, our long-standing, production-proven modular rigging platform, can meet the demands of both VFX and Animated Features. By transitioning to a fully modular, DCC- Agnostic framework we enable rigs to be built across a number of host applications and leverage a variety of evaluation back-ends; this in turn allows us to target different stages in our pipeline more efficiently, by offering high performance to animators and easy prototyping to riggers, while retaining the ability to share assets with other companies if needed. Furthermore this approach involves comparatively small upfront development and artist training costs. © 2016 Copyright held by the owner/author(s).","Animation; DCC- Agnostic; Fabric; KL; Rigging","Animation; Computer graphics; Fabrics; DCC- Agnostic; Different stages; Rigging; Training costs; Interactive computer graphics",2-s2.0-84986229317
"Keim H., Simmons M., Teece D., Reisweber J., Drakeley S.","Art-Directable procedural vegetation in disney's zootopia",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986230683&doi=10.1145%2f2897839.2927469&partnerID=40&md5=a2217278cfd8b72bf55778cc96858daa","With six distinct habitats integrated into one mammalian metropolis, early artwork for Zootopia displayed a large appetite for diverse vegetation. Our flexible toolset for procedural vegetation allowed us to easily customize the system to provide the required variation through new growth and animation module features, while maintaining art-directable control. We enriched the vegetation animation tools and workflows to support various levels of interaction with the characters and environment. To address the geometric complexity produced by all of this variation, we implemented various instancing schemes to allow the renderer to re-use as much geometry as possible. © 2016 Copyright held by the owner/author(s).","Procedural animation; Procedural geometry; Vegetation","Animation; Computer graphics; Geometry; Interactive computer graphics; Mammals; Animation modules; Animation tools; Geometric complexity; Procedural animation; Toolsets; Work-flows; Vegetation",2-s2.0-84986230683
"Schvartzman S.C., Romeo M.","Example-based data optimization for facial simulation",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985920478&doi=10.1145%2f2945078.2945151&partnerID=40&md5=38f12f3d85ddae8c689a6c26c78a324d","Digital characters are common in modern films visual effects and the demand for digital actors has increased during the past few years. The success of digitally created actors is related to their believability and, in particular, the realism of the animation and simulation of their faces. Facial expressions in computer graphics are commonly obtained through linear vertex interpolation techniques such as blend shapes. These enable high artistic control and fast interaction, but cannot properly reproduce collisions or other physical phenomena such as gravity and inertia. These effects can be achieved by applying simulation techniques over the animated facial geometry (e.g. muscle simulation), but could potentially alter the look of the desired facial expression and produce inconsistencies with the work approved in animation. Moreover, animating such muscle rigs can be very cumbersome.","Data optimization; Facial animation; Physically-based simulation","Animation; Computer graphics; Muscle; Animation and simulations; Data optimization; Digital characters; Facial animation; Facial Expressions; Interpolation techniques; Physically-based simulation; Simulation technique; Interactive computer graphics",2-s2.0-84985920478
"McGowen V., Geigel J.","Automatic blend shape creation for facial motion capture",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985939918&doi=10.1145%2f2945078.2945122&partnerID=40&md5=fd1da9b66d675825cd4b5d17937b902f","Blend shape animation is one of the most common methods for facial animation used by animators. Creation of effective blend shapes is an investment as they can take a very long time to create, but once finished, help with consistency in animation. As this is a prime animation method, its extensive process can be off-putting to newcomers. This project is focused on creating a system that will automate the blend shape creation process. The resulting blend shapes could be used in a blend shape based facial motion capture system (eg. [Weise et al. 2011]). The goal of this application is to produce a comparable result to that of blend shapes done by hand for student projects.","Blend shape animation; Motion capture; Rigging","Computer graphics; Interactive computer graphics; Creation process; Facial animation; Facial motion capture; Motion capture; Rigging; Shape based; Student project; Animation",2-s2.0-84985939918
"Turchet F., Romeo M., Fryazinov O.","Physics-aided editing of simulation-ready muscles for visual effects",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985914326&doi=10.1145%2f2945078.2945158&partnerID=40&md5=ad18caa649b576ec2346c5cd89303dbf","Recent developments in character rigging and animation shape the computer graphics industry in general and visual effects in particular. Advances in deformation techniques, which include linear blend skinning, dual quaternion skinning and shape interpolation, meet with sophisticated muscle and skin simulations to produce more realistic results. Effects such as skin sliding, wrinkling and contact of subcutaneous fat and muscles become possible when simulating the anatomy of human-like characters as well as creatures in feature films. One of the main techniques adopted nowadays in the industry is the Finite Element Method (FEM) for deformable objects. Despite the life-like results, the setup cost to generate and tweak volumetric anatomical models for a FEM solver is not only very high, but it cannot easily guarantee the quality of the models either, in terms of simulation requirements. In a production environment in fact (see Fig. 1), models often require additional processing in order to be ready for FEM simulations. For example, self-intersections or interpenetrations in rest pose may result in unwanted forces from the collision detection and response algorithms that affect negatively the simulation at its start.","Muscle simulation; Physics based animation","Animation; Computer graphics; Deformation; Interactive computer graphics; Motion pictures; Muscle; Collision detection; Deformation techniques; Muscle simulation; Physics-based animation; Production environments; Response algorithms; Self-intersections; Shape interpolation; Finite element method",2-s2.0-84985914326
[No author name available],"Learning human body shapes in motion",2016,"ACM SIGGRAPH 2016 Courses, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985945777&doi=10.1145%2f2897826.2927326&partnerID=40&md5=5fc2a8d48d8de73ae4c9273b71ff072b","Accurately representing and animating the human body in 3D is critical for games, special effects and virtual reality. Previously, this required extensive hand animation. Today realistic 3D avatars can be learned from thousands of 3D scans. This course takes participants through the process of learning and using a high quality 3D model of the human body. © 2016 Copyright held by the owner/author(s).",,"Animation; Computer graphics; Interactive computer graphics; Three dimensional computer graphics; 3-d modeling; 3-d scans; 3D Avatars; Hand animation; High quality; Human bodies; Process of learning; Virtual reality",2-s2.0-84985945777
"Palmer S., Litaker K.","Artist friendly level-of-detail in a fur-filled world",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986212728&doi=10.1145%2f2897839.2927466&partnerID=40&md5=58aac9ab6ba7905437b90113c8b510dd","The geometric complexity required to create a city filled with furry animals inWalt Disney Animation Studios' Zootopia necessitated a new approach to level-of-detail for our in-house primitive generator, XGen. The characters spanned the breadth of the animal kingdom, from a mouse to an elephant, and each presented challenges with scale and fur quality. Early test scenes proved unmanageable to render with even a few characters and we knew some sequences called for thousands of them. To address this, we updated XGen's underlying pruning algorithm, refreshed the user interface, and developed a new wedge rendering tool designed to help streamline the fine- Tuning of level-of-detail settings. These updates provided quick and informative visual feedback to the artists and aided in optimizing scene generation time and memory use. © 2016 Copyright held by the owner/author(s).","Animation; Level of detail; Rendering","Animals; Animation; Computer graphics; Rendering (computer graphics); User interfaces; Visual communication; Animal kingdom; Animation studios; Geometric complexity; Level of detail; Pruning algorithms; Rendering; Scene generation; Visual feedback; Interactive computer graphics",2-s2.0-84986212728
"Yuan Y., Mi L., Liu T., Shen Z.","Storytelling in VR - Light Chaser's VR short film SENT",2016,"ACM SIGGRAPH 2016 VR Village, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983527090&doi=10.1145%2f2929490.2930998&partnerID=40&md5=307ed76cebd2e782242a800304801f75","Light Chaser Animation is an animation studio based in Beijing, and our goal is to create world-class CG animation content. Sent is our second work in virtual reality and our first VR story short film. Lately, some key figures in the CG field have questioned the viability of narrative storytelling in the VR medium. Sent is our first attempt in answering the question. This 5-minute, 40-second short tells the story of an emoji ""Goodbye."" The narrative begins inside the phone of a boy who is having a quarrel with his girlfriend. Behind the chat screen, all kinds of emoji characters are gathered and vie to be chosen and applied to the conversation. When the boy selects ""Goodbye,"" the emoji embarks upon a magical journey that would turn things in surprising ways for all. Copyright is held by the owner/author(s).","Storytelling; Virtual reality","Animation; Computer graphics; Motion pictures; Virtual reality; Animation studios; Key figures; Storytelling; World class; Interactive computer graphics",2-s2.0-84983527090
"Boehs G.E., Vieira M.L.H.","Non-humanoid creature performance fromhuman acting",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985995025&doi=10.1145%2f2945078.2945080&partnerID=40&md5=4381aced7d36515fbb9dccb4395a1df2","We propose a framework for using human acting as input for the animation of non-humanoid creatures; captured motion is classified using machine learning techniques, and a combination of pre-existing clips and motion retargeting are used to synthetize new motions. This should lead to a broader use of motion capture. Copyright is held by the owner/author(s).","Creature animation; Machine learning; Motion retargeting; Performance capture","Animation; Artificial intelligence; Computer graphics; Interactive computer graphics; Machine learning techniques; Motion capture; Motion retargeting; Performance capture; Learning systems",2-s2.0-84985995025
"Asahina W., Iwamoto N., Shum H.P.H., Morishima S.","Automatic dance generation system considering sign language information",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985930967&doi=10.1145%2f2945078.2945101&partnerID=40&md5=e9e245fa8f0f47b715409b1033deff5d","In recent years, thanks to the development of 3DCG animation editing tools (e.g. MikuMikuDance), a lot of 3D character dance animation movies are created by amateur users. However it is very difficult to create choreography from scratch without any technical knowledge. Shiratori et al. [2006] produced the dance automatic generation system considering rhythm and intensity of dance motions. However each segment is selected randomly from database, so the generated dance motion has no linguistic or emotional meanings. Takano et al. [2010] produced a human motion generation system considering motion labels. However they use simple motion labels like ""running"" or ""jump"", so they cannot generate motions that express emotions. In reality, professional dancers make choreography based on music features or lyrics in music, and express emotion or how they feel in music. In our work, we aim at generating more emotional dance motion easily. Therefore, we use linguistic information in lyrics, and generate dance motion.","Linguistic information; Motion analysis; Sign dance","Animation; Computer graphics; Linguistics; Motion analysis; Animation editing; Automatic Generation; Express emotions; Generation systems; Human motions; Linguistic information; Sign dance; Sign language; Interactive computer graphics",2-s2.0-84985930967
"Matsuda L., Lurie S., Staub J.","The making of inner workings",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986192058&doi=10.1145%2f2897839.2936730&partnerID=40&md5=20d811ac837f01c27ca4fa8e6567bcac","From implementing the stylized design and motion of characters made from both rectilinear shapes (Paul, the brain, office crowd) and lyrical ones (the heart, beach crowd), to animated internal organ characters residing within an exterior human shell, to 2D animation projected on a CG character's forehead, Inner Workings was an ambitious short film project that provided countless visual and technical challenges for the Inner Workings team. © 2016 Copyright held by the owner/author(s).","Animation; Design; Short film","Animation; Computer graphics; Design; Motion pictures; 2D animation; Internal organs; Technical challenges; Interactive computer graphics",2-s2.0-84986192058
"Edwards M., Walvoord D., Armstrong R., Parkhill G., Potter D., Bocek-Rivele E., Ho T.C., Li J.X., Wood K.","Kung Fu Panda 3: Mandarin lip-sync reanimation process and pipeline",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986188669&doi=10.1145%2f2897839.2927407&partnerID=40&md5=24e75499db1d7ab6bc6cfdeb8ab3cd6d","For Kung Fu Panda 3 we produced an alternate version reanimated with Mandarin dialog, the first of its kind. This presented unique production challenges for both DreamWorks Animation (DWA) and Oriental DreamWorks (ODW), as each has their own pipeline and toolset. With the goal of achieving the same quality level across both versions within budget and schedule, workflows and tools were developed to effectively track, transfer and unpack the necessary data between sites. © 2016 Copyright held by the owner/author(s).","China; Coproduction; Feature animation; Film; Lip-sync; Reanimation","Animation; Budget control; Computer graphics; Films; Pipelines; Resuscitation; China; Co-production; Lip sync; Production challenges; Quality levels; Reanimation; Toolsets; Work-flows; Interactive computer graphics",2-s2.0-84986188669
"Curtis C., Eisenmann D., Guerrab R.E., Stafford S.","The making of pearl, a 360° Google spotlight story",2016,"ACM SIGGRAPH 2016 VR Village, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983484175&doi=10.1145%2f2929490.2956565&partnerID=40&md5=4874b0cdb7d74e91658ac4cd8881f690","Pearl is a short VR film directed by Patrick Osborne, winner of the 2015 Academy Award for his animated short film Feast. Our challenge: create a 360° non-linear streaming interactive animated film with a strongly art-directed non-photorealistic look, with naturalistic character animation tightly synchronized to an original song, and a story that collapses decades into minutes through montage, and make it run in real time on a wide range of devices, from mobile phones to VR headgear. No problem!. Copyright is held by the owner/author(s).","360° video; Animation; Interactive storytelling; Mobile; Non-photorealistic rendering ambisonic audio; Virtual reality","Animation; Color image processing; Computer graphics; Motion pictures; Virtual reality; Character animation; Interactive storytelling; Mobile; Non linear; Non-Photorealistic Rendering; Original songs; Photo-realistic; Real time; Interactive computer graphics",2-s2.0-84983484175
"Curtis C., Eisenmann D., El Guerrab R., Stafford S.","The making of Pearl, a 360° Spotlight Story",2016,"ACM SIGGRAPH 2016 Appy Hour, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984601465&doi=10.1145%2f2936744.2956678&partnerID=40&md5=e5baec86546922177a57a11c24e607bf","Pearl is a short VR film directed by Patrick Osborne, winner of the 2015 Academy Award for his animated short film Feast. Our challenge: create a 360° non-linear streaming interactive animated film with a strongly art-directed non-photorealistic look, with naturalistic character animation tightly synchronized to an original song, and a story that collapses decades into minutes through montage, and make it run in real time on a wide range of devices, from mobile phones to VR headgear. No problem! Copyright is held by the owner/author(s).","360° Video; Ambisonic audio; Animation; Interactive storytelling; Mobile; Non-photorealistic rendering; Virtual reality","Animation; Color image processing; Computer graphics; Motion pictures; Virtual reality; Ambisonic audio; Character animation; Interactive storytelling; Mobile; Non linear; Non-Photorealistic Rendering; Original songs; Photo-realistic; Interactive computer graphics",2-s2.0-84984601465
"Barbieri S., Garau N., Hu W., Xiao Z., Yang X.","Enhancing character posing by a sketch-based interaction",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985916268&doi=10.1145%2f2945078.2945134&partnerID=40&md5=750f98ec647218dd019e2443a71731b0","Sketch as the most intuitive and powerful 2D design method has been used by artists for decades. However it is not fully integrated into current 3D animation pipeline as the difficulties of interpreting 2D line drawing into 3D. Several successful research for character posing from sketch has been presented in the past few years, such as the Line of Action [Guay et al. 2013] and Sketch Abstractions [Hahn et al. 2015]. However both of the methods require animators to manually give some initial setup to solve the corresponding problems. In this paper, we propose a new sketch based character posing system which is more flexible and efficient. It requires less input from the user than the system from [Hahn et al. 2015]. The character can be easily posed no matter the sketch represents a skeleton structure or shape contours.","Sketch-based posing","Aluminum; Animation; Computer graphics; 2D line drawing; 3D animation; Design method; Fully integrated; Shape contours; Skeleton structure; Sketch-based interactions; Sketch-based posing; Interactive computer graphics",2-s2.0-84985916268
"El-Ali M., Tong L., Richards J., Nguyen T., Ros A.L., Joseph N.M.","Zootopia crowd pipeline",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986213395&doi=10.1145%2f2897839.2927467&partnerID=40&md5=a9026aba4032e8091a0c68df09a085dd","Disney's 55th feature animated film Zootopia takes place in a modern animal metropolis. Bringing this bustling city to life required creating a universe in which moose drive cars, lions take selfies and wildebeest herds roam the sidewalks. Many different species of animals of various sizes and proportions inhabit this city and interact with each other as well as objects and vehicles in their environment, creating some unprecedented challenges for our crowd pipeline. This required us to rethink how we approach the crowd toolset. We needed to develop tools flexible enough to handle such a wide variety of cases. Building off of the work done on Big Hero 6 [Hamed et al. 2015], a modular design was constructed in which a reliable core set the foundation over which tools could be developed and abstracted, providing the framework for artists to easily construct tools and be able to build on each other's work and tackle increasingly complex tasks effectively. © 2016 Copyright held by the owner/author(s).","Crowds; Modular design; Pipeline; Procedural animation","Animals; Animation; Computer graphics; Motion pictures; Pipelines; Complex task; Core set; Crowds; Modular designs; Procedural animation; Toolsets; Interactive computer graphics",2-s2.0-84986213395
"Feinberg M.A., Song K.-B., Lim I.-T.","KineMaster - Pro video editing on android",2016,"ACM SIGGRAPH 2016 Appy Hour, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984612100&doi=10.1145%2f2936744.2956677&partnerID=40&md5=50af9ae8757c7a064eda4f7bbcab5c5f","Nearly ubiquitous support for hardware accelerated H.264 video encoding and decoding on mobile SoCs has paved the way for non-linear video editing (NLVE) on smartphones. With KineMaster, we endeavor to implement the most commonly used features from desktop NLVE and make them available in a mobile environment. To support professional quality use-cases, precision editing and rapid preview are critical features; however, the mobile environment presents a number of unique challenges. Mobile devices typically have limited memory and storage, meaning that pre-rendering techniques such as caching preview or RAM-preview are not viable. To solve this problem, we have applied real-time computer graphics techniques (such as those found in video game engines) to provide real-time preview and rendering in an area where pre-rendering is traditionally used. User interface presented a further challenge. Typical approaches to precision editing in a desktop environment require a mouse, keyboard or specialized input hardware and do not translate well to a multi-touch interface. A common solution, clearly unsuitable for KineMaster, is to limit the features available on mobile, delegating the precision work to the desktop. Working with limited screen real-estate and limited by the need to have large, finger-sized touch zones, we experimented with a number of different user interface concepts, minimizing depth to make up for the lack of shortcut keys, while at the same time keeping the main interface uncluttered. Usability testing and analytics data from the field have helped us to fine-tune the interface. Features we have developed for KineMaster include a variety of transition and filter effects, color lookup table (LUT) filters, Chroma key (green screen), precise volume envelope control over time, multi-layer support (video, image, text, handwriting, overlays), and layer key frame animation. Today, our users include mobile journalists and other video editing professionals. Current development work includes an updated rendering engine implementing a scene-graph approach which allows users significantly greater flexibility in combining visual effects within a project; a new material implementation which enables users or third-parties to express customized scene-fragment at the material level; and support for 3rd party items generated in 3d authoring tools such as 3D Studio Max. Copyright is held by the owner/author(s).","Mobile video; NLVE; Video editing","Android (operating system); Animation; Computer games; Computer graphics; Computer hardware; Digital storage; Hardware; Interactive computer graphics; Mobile devices; Random access storage; Reconfigurable hardware; Table lookup; Three dimensional computer graphics; Touch screens; User interfaces; Video signal processing; Videodisks; Color look-up tables; Hardware-accelerated; Mobile environments; Mobile video; Multi-touch interfaces; NLVE; Real time computer graphics; Video editing; Rendering (computer graphics)",2-s2.0-84984612100
"Cantwell B., Warner P., Koperwas M., Bhat K.","ILM facial performance capture",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986216592&doi=10.1145%2f2897839.2927438&partnerID=40&md5=26c9c2b9424cd3335d6b572b37a5823a","Industrial Light & Magic utilized facial capture technology on a massive scale to bring more than two dozen computer-generated characters to life in the new Warcraft, Teenage Mutant Ninja Turtles, and Star Wars films. Here we present our flexible proprietary facial capture system which was used to faithfully translate all the subtle nuances, lip movements, and saccades of over 1200 facial performances onto editable, artist-friendly animation rigs, and ultimately the big screen. © 2016 Copyright held by the owner/author(s).","Animation; Creature; Facial capture; Human","Animation; Computer graphics; Motion pictures; Three dimensional computer graphics; Capture system; Computer generated characters; Creature; Facial capture; Human; Lip movements; Performance capture; Star wars; Interactive computer graphics",2-s2.0-84986216592
"Stuyck T., Dutré P.","Model predictive control for robust art-directable fluids",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985909455&doi=10.1145%2f2945078.2945088&partnerID=40&md5=9d45aaf2a823b2dc9cb08ed7014b7440","Physics-based animation has become an important tool in computer graphics and is essential in recreating realistic looking natural phenomena. Researchers have been looking for tools to control passive simulations that allow artists to easily modify the simulation to best suit the artistic requirements. However, fluid motion is very hard to predict and it is very difficult, if not impossible, to achieve specific behavior just by altering the global variables. Active control of the simulation will be necessary to achieve this goal.","Fluid Control; Fluid Simulation; Model Predictive Control; Trajectory Tracking","Computer graphics; Interactive computer graphics; Active control; Fluid control; Fluid motions; Fluid simulations; Global variables; Natural phenomena; Physics-based animation; Trajectory tracking; Model predictive control",2-s2.0-84985909455
"Stuyck T., Dutré P.","Sculpting fluids: A new and intuitive approach to art-directable fluids",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985906116&doi=10.1145%2f2945078.2945089&partnerID=40&md5=b6fea0ff4444c69e72dfff1f11a0783c","Fluid simulations are very useful for creating physically based water effects in computer graphics but are notoriously hard to control. In this talk we propose a novel and intuitive animation technique for fluid animations using interactive direct manipulation of the simulated fluid inspired by clay sculpting. Artists can simply shape the fluid directly into the desired visual effect whilst the fluid still adheres to its physical properties such as surface tension and volume preservation. Our approach is faster and much more intuitive compared to previous work which relies on indirect approaches such as providing reference geometry or density fields. It makes it very easy, even for novice users, to modify simulations ranging from enlarging splashes or altering droplet shapes to adjusting the flow of a large fluid body. The sculpted fluid shapes are incorporated into the simulation using guided re-simulation using control theory instead of simply using geometric deformations resulting in natural-looking animations. © 2016 Copyright held by the owner/author(s).","Direct manipulation; Fluid control","Computer graphics; Animation techniques; Direct manipulation; Fluid control; Fluid simulations; Geometric deformations; Physically based; Simulated fluids; Volume preservation; Interactive computer graphics",2-s2.0-84985906116
"Mackiewicz L., Melendez F.","Loving vincent: Guiding painters through 64.000 frames",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986199892&doi=10.1145%2f2897839.2927394&partnerID=40&md5=f0cfa27609d05916d0a79860fd87fdda","In this talk we present our workflow for the first feature length oilpainted animation movie Loving Vincent. The production involved more than 50 painters, which produced near 64.000 paintings. The magnitude of the project required us to designed new workflows and tools for the artists in order to ease their decision making process and reduce their fatigue. We developed a method to produce animation guidelines from the original filmed footage, designed special work stations, and provide the material in several useful forms to the painters. The result of this pipeline is a unique look for the first movie of its kind. We present the insights we learned during this production and the tools and processes specifically developed for this film. © 2016 Copyright held by the owner/author(s).","Animation; Pipeline; Production","Animation; Computer graphics; Decision making; Pipelines; Production; Decision making process; Work station; Work-flows; Interactive computer graphics",2-s2.0-84986199892
"Ishimuroya M., Kanai T.","Adding visual details based on low-resolution energy cascade ratios for smoke simulation",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985961219&doi=10.1145%2f2945078.2945094&partnerID=40&md5=30143c0a23ad2610329c0eebdc540981","We propose a method for adding visual details to fluid animation while reducing noisy appearances. In grid-based fluid simulations, an issue is that while highly detailed fluids with small eddies can be obtained by increasing the number of grid cells, it costs much more computational time. To address this, various methods for adding details (or up-scaling resolutions) have been proposed. Those methods can generate fine animations quickly by adding high-frequency noises or external forces to coarse simulation results. However, those methods typically generate tiny eddies on a whole surface of fluid and the result appears too noisy. In this paper, we consider the distribution of kinetic energy in the spatial frequency domain and then apply it to two existing methods for adding details. By using our method, noises or external forces can be added to the appropriate positions of fluids and consequently natural-looking details can be achieved. © 2016 Copyright held by the owner/author(s).","Energy cascade; Vorticity confinement; Wavelet turbulence","Computer graphics; Frequency domain analysis; Kinetic energy; Kinetics; Vorticity; Computational time; Energy cascade; Fluid animation; Fluid simulations; High-frequency noise; Smoke simulation; Spatial frequency domains; Vorticity confinement; Interactive computer graphics",2-s2.0-84985961219
"Kautzman R., Wise B., Yu M., Karlsson P., Hessler M., Wong A.","Finding hank: Or how to sim an octopus",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986211942&doi=10.1145%2f2897839.2927458&partnerID=40&md5=ee0ee0c0d34b7c0c6e908b18ff6dbef4","The grumpy septapus Hank from Finding Dory presented our teams with a huge challenge. His charm immediately insured he would receive plenty of screen time, and his complexity meant we would need a host of techniques to bring him to the screen. Building on an already complex animation rig, the simulation team was tasked with adding flesh and skin simulation effects as well as tackling the serious challenge of Hank's suckers and Mantle behavior. © 2016 Copyright held by the owner/author(s).","Animation; Simulation","Animation; Computer graphics; Screen time; Simulation; Simulation effects; Interactive computer graphics",2-s2.0-84986211942
"Li D.","Towards real-time insect motion capture",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985964555&doi=10.1145%2f2945078.2945115&partnerID=40&md5=cfec260e30433f42360106f594be8025","It is currently possible to reliably motion-track humans and some animals, but not possible to track insects using standard motion tracking techniques. By programming a virtual prototype rig/skeleton for the insects small scale creatures will be able to be tracked in real time. Possible applications include behavioural research of animals and entertainment industry, e.g., when realistic insect motion simulation is needed and insects cannot be outfitted with sensors like humans for animation in movies or games. © 2016 Copyright held by the owner/author(s).","Frameworks; Kinect; Life sciences; Motion capture; OpenCV; OpenGL; Processing; Real-time","Animals; Animation; Application programming interfaces (API); Behavioral research; Computer graphics; Processing; Software prototyping; Frameworks; Kinect; Life-sciences; Motion capture; OpenCV; OpenGL; Real time; Interactive computer graphics",2-s2.0-84985964555
"Burley B., Fajardo M., Keller A., Leprince P., Van Swaaij M., Tabellion E., Reed M.","What makes a production renderer in 2016!",2016,"ACM SIGGRAPH 2016 Panels, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985995374&doi=10.1145%2f2927383.2927384&partnerID=40&md5=d8de055942d88998c2739347907e267c","Even a casual search turns up many renderers that call themselves ""production renderer"" - some of them relatively unknown, others known to be of very high standard. In addition to these sources, many of the large studios have their own renderers, investing significantly into the resources required to develop this technology. This panel explores the reasons that this is the case, and what it means to call a product ""production-ready"".","Animation; Film production; Rendering","Animation; Computer graphics; Interactive computer graphics; Film production; High standards; Rendering; Rendering (computer graphics)",2-s2.0-84985995374
"Mokhov S.A., Song M., Llewellyn J., Zhang J., Charette A., Wu R., Ge S.","Real-time collection and analysis of 3-kinect v2 skeleton data in a single application",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985916939&doi=10.1145%2f2945078.2945131&partnerID=40&md5=a890fce31d09baa13838a61fafc5d23f","It was not possible to do reliable 3D skeletal tracking with the currently publicly available inexpensive consumer grade hardware/software tools, such as depth cameras and their SDKs using multiple of such sensors in a single application (e.g., a game, motion recording for animation, or 3D scanning). We successfully attached 3 Kinect v2 sensors to a single application to track skeletal data without using Microsoft's Kinect 2 SDK.We created a new toolkit-MultiCamTk++ for 3 or more Kinects v2 with skeleton support in C++. It is a successor of our previous version,MultiCamTk, done in Processing/Java that had no skeletal tracking. We achieve high resiliency and good frame rate even if 1-2 Kinects are disconnected at runtime. We are able to receive the skeleton data from the multiple sources to correlate the coordinates for spatial 3D user tracking. © 2016 Copyright held by the owner/author(s).","3D sekeletal tracking; Frameworks; Libfreenect2; Motion capture; Multi Kinect v2; OpenCV; OpenGL; Real-time","Animation; Application programming interfaces (API); Computer graphics; Musculoskeletal system; Frameworks; Libfreenect2; Motion capture; Multi Kinect v2; OpenCV; OpenGL; Real time; Interactive computer graphics",2-s2.0-84985916939
"Soga A., Yazaki Y., Umino B., Hirayama M.","Body-part motion synthesis system for contemporary dance creation",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Posters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985955426&doi=10.1145%2f2945078.2945107&partnerID=40&md5=c676f4b0d61c7cea18110f1e47fe58cd","We developed a body-part motion synthesis system (BMSS) that allows users to create short choreographies by synthesizing body-part motions and to simulate them in 3D animation. This system automatically provides various short choreographies. First, users select a base motion and body-part categories. Then the system automatically selects and synthesizes body-part motions to the base motion. The system randomly determined the synthesis timings of the selected motions. Users can use the composed sequences as references for dance creation, learning, and training. We experimentally evaluated our system's effectiveness for supporting dance creation with four professional choreographers of contemporary dance. From our experiment results, we basically verified the usability of BMSS for choreographic creation. © 2016 Copyright held by the owner/author(s).","Choreography; Contemporary dance; Creation; Motion synthesis","Computer graphics; 3D animation; Base motion; Body parts; Choreography; Contemporary dance; Creation; Motion synthesis; Interactive computer graphics",2-s2.0-84985955426
"Peddie J., Fonseka E., Akeley K., Mangan M., Debevec P., Raphael M.","A vision for computer vision: Emerging technologies",2016,"ACM SIGGRAPH 2016 Panels, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986000850&doi=10.1145%2f2927383.2933233&partnerID=40&md5=19f5a7ebac114be3b5a803987b247487","Computer vision is a rapidly evolving discipline. It includes methods for acquiring, processing, and understanding still images and video to model, replicate, and sometimes, exceed human vision and perform useful tasks. Computer vision will be commonly used for a broad range of services in upcoming devices, and implemented in everything from movies, smartphones, cameras, drones and more. Demand for CV is driving the evolution of image sensors, mobile processors, operating systems, application software, and device form factors in order to meet the needs of upcoming applications and services that benefit from computer vision. The resulting impetus means rapid advancements in: • visual computing performance • object recognition effectiveness • speed and responsiveness • power efficiency • video image quality improvement • real-time 3D reconstruction • pre-scanning for movie animation • image stabilization • immersive experiences • and more⋯ Comprised of innovation leaders of computer vision, this panel will cover recent developments, as well as how CV will be enabled and used in 2016 and beyond.","3D scanning and reconstruction; Computational camera; Computer vision; Mobile processing; Video image quality","Application programs; Cameras; Computer graphics; Computer vision; Image processing; Image quality; Image reconstruction; Interactive computer graphics; Object recognition; Three dimensional computer graphics; Video signal processing; 3D-scanning; Computational cameras; Emerging technologies; Image stabilization; Mobile processors; Real-time 3D reconstruction; Video image qualities; Visual computing; Computer operating systems",2-s2.0-84986000850
"Caldwell C.","Story: It's not just for writers⋯ anymore: Course Notes",2016,"ACM SIGGRAPH 2016 Courses, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985947521&doi=10.1145%2f2897826.2927306&partnerID=40&md5=c89eb7e7cc2a2fd262ee398b7cace3e6","This course has been designed for technical directors, artists, animators, modelers, programmers, and designers whose work is essential in making ""the story"" come to life. This information can be particularly useful when communicating with screenwriters, directors, producers, and supervisors. This course answers the question ""what is story?"" (and you don't even have to take a course in screenwriting). Entertaining with numerous clips to show how this has been used in animation and VFX. The purpose is to take the mystery out of ""what is story"" for those programmers, artists, and game designers whose work is essential in making Animation, VFX, and Games successful. The attendees will know the basic elements of story, so the next time a producer or director talk about what they want for the story, they will know what specific story benchmarks the producer/director are trying to meet in connecting emotionally with an audience. This course will build from the knowledge that story ""is a sequence of events (acts) that builds to a climax⋯."" and then lays out the universal elements of story that make up plot, character development, and narrative structure. This course emphasizes story elements in context (i.e. theme, character, setting, conflict etc.) and their relationship to classic story structure (i.e. setup, inciting incident, rising action, climax, resolution etc.). It analyzes conflict (i.e. internal, external, environmental), turning points, cause & effect, archetype vs stereotypes, inciting incident, and how choice defines character. In all stories there must be questions raised: What is at stake (i.e. survival, safety, love, esteem, etc.)? What is going to motivate (inciting incident) the main character (protagonist)? Will that be enough to move them from the ordinary (where they are comfortable) to go out into a different world (where the action takes place)?, and How will the character ""change""(necessary for all dramatic stories)? These are just a few of the storytelling elements necessary to structure a solid story. This course is for all whose work makes the story better but their job isn't creating the story. © 2016 Copyright held by the owner/author(s).",,"Computer graphics; Interactive computer graphics; Basic elements; Game designers; In contexts; Narrative structures; Sequence of events; Turning points; Animation",2-s2.0-84985947521
"Lin W.-C., Zafar N.B., Zhou E.N.J.","Pyramid coordinates for deformation with collision handling",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986212981&doi=10.1145%2f2897839.2927400&partnerID=40&md5=e7de773706760441146b16ae134b7ba8","We present an efficient implementation of the reconstruction of pyramid coordinates which are used for the deformation of animated characters. By reformulating the pyramid coordinates as an optimization problem with one-ring neighborhood constraints, we can solve the problem using an efficient projective solver. This greatly improves the overall performance, and makes it easier to incorporate other geometric constraints. Collisions between the deformed and kinematic geometries are handled using a two-pass methodology. By resolving collisions before applying pyramid coordinate constraints, we obtain a consistent result after the constraint projection. Dynamic simulation is also possible by modeling proper constraints and projection operators under the same framework. © 2016 Copyright held by the owner/author(s).","Animation; Deformation; Dynamics; Rigging","Animation; Computer graphics; Deformation; Dynamics; Optimization; Animated characters; Constraint projections; Efficient implementation; Geometric constraint; Optimization problems; Projection Operator; Pyramid coordinates; Rigging; Interactive computer graphics",2-s2.0-84986212981
"Muto W., Paquin M.-A., Sanghrajka N., Gordon S., Bradshaw M.","Wham! building deadpool's freeway chase",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986197549&doi=10.1145%2f2897839.2927419&partnerID=40&md5=c54028a32d6baa685a3d31fa9327018b","The high-speed chase sequence in Deadpool encompassed one hundred shots of new challenges for the team at Atomic Fiction. The action had to move through many miles of densely populated fictional city, leaving a trail of destruction in its wake. The pipeline team developed novel approaches across the VFX production workflow to deal with a sequence of this scale and complexity. © 2016 Copyright held by the owner/author(s).","Animation; Big data; Cloud rendering; Destruction; Layout; Pipeline; Simulation","Animation; Big data; Computer graphics; Pipelines; Cloud rendering; Destruction; High Speed; Layout; Production workflows; Simulation; Interactive computer graphics",2-s2.0-84986197549
"Aliaga D.G., Demir I., Benes B., Wand M.","Inverse procedural modeling of 3D models for virtual worlds",2016,"ACM SIGGRAPH 2016 Courses, SIGGRAPH 2016",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985993372&doi=10.1145%2f2897826.2927323&partnerID=40&md5=892e89dc61b4c9770d9cbc313fa23d1b","This course presents a collection of state-of-the-art approaches for modeling and editing of 3D models for virtual worlds, simulations, and entertainment, in addition to real-world applications. The first contribution of this course is a coherent review of inverse procedural modeling (IPM) (i.e., proceduralization of provided 3D content). We describe different formulations of the problem as well as solutions based on those formulations. We show that although the IPM framework seems under-constrained, the state-of-the-art solutions actually use simple analogies to convert the problem into a set of fundamental computer science problems, which are then solved by corresponding algorithms or optimizations. The second contribution includes a description and categorization of results and applications of the IPM frameworks. Moreover, a substantial part of the course is devoted to summarizing different domain IPM frameworks for practical content generation in modeling and animation. © 2016 Copyright held by the owner/author(s).","Architectural modeling; Generative content; Geometry processing; Inverse procedural modeling; Procedural modeling; Shape; Shape analysis; Shape editing; Similarity detection","Computer graphics; Constrained optimization; Curricula; Interactive computer graphics; Inverse problems; Virtual reality; Architectural modeling; Generative content; Geometry processing; Procedural modeling; Shape; Shape analysis; Shape editing; Similarity detection; Three dimensional computer graphics",2-s2.0-84985993372
"Pieḱe R.","Rendering fast & furious: Supercharged in stereo for a 400ft curved screen",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986190541&doi=10.1145%2f2897839.2927395&partnerID=40&md5=53d08e314fbc4ba218f7a35a7ac5c82d","For Fast & Furious: Supercharged, we were required to produce a 90-second shot which would be projected in stereo on an enormous \-shaped screen surrounding an audience in a series of long tram cars at Universal Studios Hollywood. This raised three main technical challenges: Anticipating the projection warping and inverting it at render- Time, artistically recomposing the perceived depth of the scene to provide a better audience experience, and ensuring a consistent stereoscopic effect. To overcome these challenges, we developed a custom camera representation which allowed the camera to change its location and orientation over the domain of the rendered image, independent of any temporally-based motion for blurring. This further necessitated modifications to both our animation and rendering workflows, as well as a new validation process to emulate the viewing experience. © 2016 Copyright held by the owner/author(s).","Camera projection; Pipeline; Theme park rides","Cameras; Computer graphics; Interactive computer graphics; Pipelines; Stereo image processing; Camera projection; Hollywood; Rendered images; Technical challenges; Theme park; Validation process; Work-flows; Rendering (computer graphics)",2-s2.0-84986190541
"Jiang C., Schroeder C., Teran J., Stomakhin A., Selle A.","The material point method for simulating continuum materials",2016,"ACM SIGGRAPH 2016 Courses, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985896388&doi=10.1145%2f2897826.2927348&partnerID=40&md5=11ea95e97c0727c0457f47a123743f47","Simulating the physical behaviors of deformable objects and fluids has been an important topic in computer graphics. While the Lagrangian Finite Element Method (FEM) is widely used for elasto-plastic solids, it usually requires additional computational components in the case of large deformation, mesh distortion, fracture, self-collision and coupling between materials. Often, special solvers and strategies need to be developed for a particular problem. Recently, the hybrid Eulerian/Lagrangian Material Point Method (MPM) was introduced to the graphics community. It uses a continuum description of the governing equations and utilizes user-controllable elasto-plastic constitutive models. The hybrid nature of MPM allows using a regular Cartesian grid to automate treatment of self-collision and fracture. Like other particle methods such as Smoothed Particle Hydrodynamics (SPH), topology change is easy due to the lack of explicit connectivity between Lagrangian particles. Furthermore, MPM allows a grid-based implicit integration scheme that has conditioning independent of the number of Lagrangian particles. MPM also provides a unified particle simulation framework similar to Position Based Dynamics (PBD) for easy coupling of different materials. The power of MPM has been demonstrated in a number of recent papers for simulating various materials including elastic objects, snow, lava, sand and viscoelastic fluids. It is also highly integrated into the production framework of Walt Disney Animation Studios and has been used in featured animations including Frozen, Big Hero 6 and Zootopia. © 2016 Copyright held by the owner/author(s).",,"Computer graphics; Deformation; Elastoplasticity; Fracture; Hydrodynamics; Interactive computer graphics; Lagrange multipliers; Computational components; Continuum description; Elastoplastic constitutive model; Elastoplastic solids; Implicit integration; Material point methods; Smoothed particle hydrodynamics; Vis-coelastic fluids; Finite element method",2-s2.0-84985896388
"Byun D.J., Mansfield J., Velazquez C.","Delicious looking ice cream effects with non-simulation approaches",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986215047&doi=10.1145%2f2897839.2927445&partnerID=40&md5=5ce7b89b7a03f1ab1a2699c05078c6f9","Simulations provide us with physically correct motions and believable features for effects elements. However, when creating more stylized and unique effects animation, we frequently need more artdirectible and manageable tool sets. This session presents a detailed overview of specific non-simulation based approaches we developed for the ice cream effects in Disney's Zootopia. And we will discuss their benefits and productivity. © 2016 Copyright held by the owner/author(s).","2d drawovers; Deformer; Ice cream; Non-simulation","Computer graphics; 2d drawovers; Deformer; Ice creams; Non-simulation; Simulation approach; Simulation based approaches; Toolsets; Interactive computer graphics",2-s2.0-84986215047
"Kallmann M., Kapadia M.","Geometric and discrete path planning for interactive virtual worlds",2016,"ACM SIGGRAPH 2016 Courses, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986005730&doi=10.1145%2f2897826.2927310&partnerID=40&md5=76c1a622278e976111dcc969e1e07b35","Path planning and navigation are indispensable components for controlling autonomous agents in interactive virtual worlds. Given the growing demands on the size and complexity of modern virtual worlds, a number of new techniques have been developed for achieving intelligent navigation for the next generation of interactive multi-agent simulations. This course reviews the evolution of the several related techniques, from classical planning algorithms and computational geometry techniques to more advanced topics with focus on recent developments from the work of the authors. The covered topics range from discrete search and geometric representations to planning under different types of constraints and harnessing the power of graphics hardware in order to address Euclidean shortest paths and discrete search for multiple agents under limited time budgets. The use of planning algorithms beyond path planning is also discussed in the areas of crowd animation and whole-body motion planning for virtual characters. © 2016 Copyright held by the owner/author(s).","Anytime dynamic search; Discrete search; Navigation; Navigation meshes; Path finding; Path planning; Shortest paths","Autonomous agents; Budget control; Computational geometry; Computer graphics; Geometry; Graph theory; Interactive computer graphics; Multi agent systems; Navigation; Virtual reality; Discrete search; Dynamic search; Euclidean shortest path; Geometric representation; Intelligent navigation; Multi agent simulation; Path finding; Shortest path; Motion planning",2-s2.0-84986005730
"Schwank A., James C.J., Micilotta T.","The trees of the jungle book",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986214278&doi=10.1145%2f2897839.2927428&partnerID=40&md5=e41589deb610e6d1dbaa150af00bccd1","For Disney's live action remake of The Jungle Book, we were required to build a jungle comprised of photorealistic trees, vines and other plantlife. We leveraged SpeedTree [IDV 2016] and Fabric Engine [Fabric Engine 2016] to create more than two hundred unique trees and vines that were used in the mid- And background of the jungle. To maximize the tree look quality, we created high resolution trunks and branches in Maya and included these during the node-based configuration stage in SpeedTree. Moreover, with each tree having approximately one million leaves, the leaves were approximated with cards and later replaced by high resolution leaf model configurations during the render process; this reduced model complexity, facilitated technical animation, and ultimately enabled us to handle the vastness of the jungle. © 2016 Copyright held by the owner/author(s).","Leaves; Pipeline; Speedtree; Trees","Computer graphics; Engines; Interactive computer graphics; Pipelines; High resolution; Leaves; Live actions; Model configuration; Photo-realistic; Reduced model; Speedtree; Trees; Forestry",2-s2.0-84986214278
"Ogawa D., Tanabe K., Yem V., Hachisu T., Kajimto H.","HapTONE: Haptic instrument for enriched musical play",2016,"ACM SIGGRAPH 2016 Emerging Technologies, SIGGRAPH 2016",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984644952&doi=10.1145%2f2929464.2929477&partnerID=40&md5=305f53b7390d9a680985b33d69d111aa","This paper describes a novel music entertainment system that draws on auditory, tactile and visual senses. HapTONE presents players with high-fidelity vibrotactile sensations, not only after pressing the keyboard but also during the pressing operation itself. We developed keyboard type instrument that composed of key unit which is structured a vibrator and a distance sensor. This instrument reproduces the touch sensation of a keyboard, stringed, wind, percussion or non-musical instrument. We describe three applications of HapTONE that include: 1) the accurate replication of percussion instruments; 2) playing of pseudo-stringed instruments, and 3) synchronized vibration with animation. HapTONE is a musical entertainment system for players themselves using auditory, tactile and visual senses. Copyright is held by the owner/author(s)","Haptic; Musical instrument; Vibrotactile","Computer graphics; Interactive computer graphics; Distance sensors; Entertainment systems; Haptic; High-fidelity; Percussion instruments; Touch sensation; Vibrotactile; Vibrotactile sensations; Musical instruments",2-s2.0-84984644952
"Wrenninge M., Rice M.","Volume modeling techniques in the good dinosaur",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986182347&doi=10.1145%2f2897839.2927397&partnerID=40&md5=7cbf44d02093047b3d70c6b3eb33c5e1","In a recent paper, we introduced the Reves volume modeling algorithm [Wrenninge 2016]. Pixar's latest animation film, The Good Dinosaur, was the first production to use the system, and this submission aims to show the tool in practical use. Although Reves is designed to produce temporal volumes, it is a flexible and powerful volume modeling tool for static volumes as well. Two key aspects of Reves are its use of an intermediate rasterization representation (microvoxels), and is its scalability. The microvoxel representation means that a wide variety of input primitives can be handled, with efficient SIMD execution of shaders. The scalability provides consistent behavior to the user: At low resolutions feedback is fast and small primitives antialias consistently, and at high resolutions memory use is well controlled. This, together with robust shader and coverage antialising, means that the system can be relied on to produce consistent results at any given output resolution. For the user, it means fast interactive feedback that closely matches final quality. © 2016 Copyright held by the owner/author(s).","Cloud modeling; Cloud rendering; Multiple scattering","Algorithms; Behavioral research; Computer graphics; Feedback; Multiple scattering; Rasterization; Scalability; Antialising; Cloud modeling; Cloud rendering; High resolution; Interactive feedback; Low resolution; Practical use; Volume modeling; Interactive computer graphics",2-s2.0-84986182347
"Legros B., Corvazier C.","Circle tracing for subsurface scattering",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986218319&doi=10.1145%2f2897839.2927451&partnerID=40&md5=a2eac1157e2581e8ad02127c426d471f","Rendering of translucent materials such as skin, marble or wax is a requirement for animation and visual effects production, either photo realistic or non photo realistic styles. Monte-Carlo integra- Tion of light transport by simulating scattering events of light within the translucent medium is prohibitive and difficult to parametrize for artistically driven applications. Light transport in a medium is modeled as a BSSRDF that char- Acterizes the propagation of light from an entry point xi to an exit point x. Lo = ∫M ∫Ω f(x, n, ωo, xi, ni, ωi)LicosθdΩ,dxi We assume f = fs(∥x - xi∥) ∗ ft(n, ωo, ni, ωi) as the product of a scattering profile function and a transmission function. [King et al. 2013] proposed a disk based sampling technique to importance sample the fs term. We propose in this presentation a different strategy that samples points on the surface at an exact distance, even on non flat surfaces, and doesn't require additional strategies that would potentially result in no sample at all. © 2016 Copyright held by the owner/author(s).","Importance sampling; Ray tracing; Subsurface scattering","Computer graphics; Importance sampling; Interactive computer graphics; Light transmission; Ray tracing; Visibility; Light transport; Propagation of lights; Sampling technique; Scattering events; Scattering profiles; Subsurface scattering; Translucent materials; Transmission function; Surface scattering",2-s2.0-84986218319
"Romeo M., Chan R., Chen J.-R., Fisher G.","The jungle book: Management, caching and preview of many animals",2016,"SIGGRAPH 2016 - ACM SIGGRAPH 2016 Talks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986199839&doi=10.1145%2f2897839.2927414&partnerID=40&md5=33324616f11c6ca353b7fc1bf09b6946","The creation of the visual effects for The Jungle Book was characterized by shots with many different animals (the largest shot had 207 creatures). These animals interacted with each other and the movements of some were related to or affected by the movements of others. Because of this, each character needed to be animated with a notion of the movement of the surrounding animals. Unfortunately, given the complexity of each character mesh and rig, it was not possible to load, visualize or animate large numbers of characters at once. At MPC, we developed a system that integrates our Rigging, Animation and Crowd pipeline and technology to enable the caching and fast previewing of animated characters in complex shots within Maya. This way artists could animate one animal, while the other animals were displayed at a reasonable playback speed. Furthermore, the system enabled artists to easily switch across different levels of detail (LOD) of the characters. We provide performance evaluation from production data for loading and playback of different amounts of characters. © 2016 Copyright held by the owner/author(s).","Automation; Crowds; Pipeline; Visual effects","Automation; Computer graphics; Interactive computer graphics; Pipelines; Animated characters; Crowds; Levels of detail; Playback speed; Production data; Visual effects; Animals",2-s2.0-84986199839
[No author name available],"ACM SIGGRAPH 2016 Courses, SIGGRAPH 2016",2016,"ACM SIGGRAPH 2016 Courses, SIGGRAPH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985997822&partnerID=40&md5=a15772d7036dd342aef731eca548fa62","The proceedings contain 18 papers. The topics discussed include: a practical introduction to frequency analysis of light transport; HDR content creation: creative and technical challenges; geometric and discrete path planning for interactive virtual worlds; inverse procedural modeling of 3D models for virtual worlds; haptic technologies for direct touch in virtual reality; human-centered design for VR interactions; CGAL ? the computational geometry algorithms library; Fourier analysis of numerical integration in Monte Carlo rendering: theory and practice; computational tools for 3D printing; physically based sound for computer animation and virtual environments; modeling plant life in computer graphics; learning human body shapes in motion; the quest for the ray tracing API; vector field processing on triangle meshes; and the material point method for simulating continuum materials.",,,2-s2.0-84985997822
"Jacobs J., Barbic J., Edwards E., Doran C., Van Straten A.","How to build a human: Practical physics-based character animation",2016,"Proceedings - DigiPro 2016: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984646949&doi=10.1145%2f2947688.2947698&partnerID=40&md5=199d33f1ab34d330499d6ca5ae5dab78","We present state-of-the-art character animation techniques for generating realistic anatomical motion of muscles, fat, and skin. Physics-based character animation uses computational resources in lieu of exhaustive artist effort to produce physically realistic images and animations. This principle has already seen widespread adoption in rendering, fluids, and cloth simulation. We believe that the savings in manpower and improved realism of results provided by a physics- and anatomy-based approach to characters cannot be matched by other techniques. Over the past year we have developed a physics-based character toolkit at Ziva Dynamics and used it to create a photo-realistic human character named Adrienne. We give an overview of the workflow used to create Adrienne, from modeling of anatomical bodies to their simulation via the Finite Element Method. We also discuss practical considerations necessary for effective physics-based character animation. © 2016 Copyright held by the owner/author(s).","Anatomy; Biomechanics; Character animation; Finite Element Method; Muscle; Physics-based animation; Tissue","Animation; Biomechanics; Interactive computer graphics; Muscle; Tissue; Anatomy; Character animation; Cloth simulation; Computational resources; Photo-realistic; Physics-based animation; Realistic images; State of the art; Finite element method",2-s2.0-84984646949
"Mathee H., Haux B.","Portable real-time character rigs for virtual reality experiences",2016,"Proceedings - DigiPro 2016: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984628527&doi=10.1145%2f2947688.2947694&partnerID=40&md5=018d274db51b609eeee4984dd11f91e6","In this presentation we describe a work-in-progress approach to a portable character animation pipeline for real-time scenarios that can dramatically reduce iteration time and also increase character quality and flexibility. Simply put, it is a What You Rig and Animate (in the DCC app) is What You Get (in the VR experience) approach. Our implementation involves using the python-based Kraken tool to generate a rig that can run in Autodesk Maya® and also a version that can be executed by Fabric Engine within Unreal Engine®. By essentially running the same full rig both in Maya and Unreal, we are able to maintain film-quality characters that keep the same richness and animation control. Portable characters have their rigs defined in a way that allows them to run in any environment while maintaining the full flexibility and functionality of the original control and deformation rig, which in turn allows for artistic intent to be preserved at all stages. © 2016 Copyright held by the owner/author(s).","Character rigging; Real-time animation","Animation; Engines; Interactive computer graphics; Virtual reality; Animation control; Autodesk mayas; Character animation; Character rigging; Film quality; Real-time animations; Virtual reality experiences; Work in progress; Quality control",2-s2.0-84984628527
"Pepper J., Seitschek K., Farnsworth I., Kerley L., Turhan C., Messineo C., Clark J.","Cross departmental collaboration for FX driven animation in ""Alice through the looking glass""",2016,"Proceedings - DigiPro 2016: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984620308&doi=10.1145%2f2947688.2947700&partnerID=40&md5=cdc0ac24bbf9fa39ca3f2fe7c13d27b9","Alice Through The Looking Glass was a movie that required controllable, highly stylized natural phenomena as a core ingredient of some of it's major VFX sequences. Sony Pictures Imageworks developed various cross-departmental collaboration techniques to achieve this surreal aesthetic on two major, heavily featured effects. Specifically these were the Rust and Oceans Of Time effects. This paper will detail different examples of integrating unusual pipeline and workflow methods for these high concept ideas. In the case of Oceans of Time, the traditional workflow from front end to back end was either circumvented or inverted entirely because of the unconventional nature of the effects involved. For the rust, while the workflow was more linear in the traditional manner, the work between departments had to overlap to a significantly greater extent than is typical. For both sets of sequences, reasons for certain production decisions will be outlined, as well as some of the benefits and issues presented as a result. © 2016 Copyright held by the owner/author(s).",,"Glass; Interactive computer graphics; Core ingredients; Front end; Natural phenomena; Production decisions; Sony Pictures Imageworks; Time effect; Mirrors",2-s2.0-84984620308
"Penney D.","Volumetric clouds in the VR movie, Allumette",2016,"Proceedings - DigiPro 2016: ACM SIGGRAPH Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984623208&doi=10.1145%2f2947688.2947699&partnerID=40&md5=3180e3d4d68318fa8d6ad6b5abe6a97d","Allumette is an immersive, highly emotional, and visually complex virtual reality movie that takes place in a city floating amongst clouds. The story unfolds around you, and as the viewer, you are free to experience the action from a perspective of your choosing. This means you can move around and view the clouds from all angles, while the set and characters interact intimately with the landscape. This type of set is a formidable challenge for traditional animated films where you have huge resources and hours to render each frame, which makes achieving the look and feel of immersive clouds in VR uncharted territory full of difficult challenges. Existing lightweight techniques for real time clouds, such as using geometric shells with translucency shaders, and sprite-based methods, have a combination of poor quality and bad performance in VR, which led us to seek novel methods to tackle the problem. For Allumette, we first modeled clouds in virtual reality by painting cloud shells using a proprietary modeling tool, then used a third party procedural modeling package to create and light the cloud voxel grids. Finally, these grids were exported with a custom file format, and rendered using a ray marcher in our game engine. The resulting clouds take .6ms per eye to render, and immerse the viewer in our cloud city. © 2016 Copyright held by the owner/author(s).","Real-time rendering; Volume rendering; Volumetric modeling","Animation; Motion pictures; Virtual reality; Volume rendering; File formats; Game Engine; Modeling tool; Novel methods; Procedural modeling; Real-time rendering; Third parties; Volumetric modeling; Interactive computer graphics",2-s2.0-84984623208
"Seol Y., Ma W.-C., Lewis J.P.","Creating an actor-specific facial rig from performance capture",2016,"Proceedings - DigiPro 2016: ACM SIGGRAPH Digital Production Symposium",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984605085&doi=10.1145%2f2947688.2947693&partnerID=40&md5=f862616a507caf418e2d8d327b7c7774","Creating a high quality blendshape rig usually involves a large amount of effort from skilled artists. Although current 3D reconstruction technologies are able to capture accurate facial geometry of the actor, it is still very difficult to build a production-ready blendshape rig from unorganized scans. Removing rigid head motion and separating mixed expressions from the captures are two of the major challenges in this process. We present a technique that creates a facial blendshape rig based on performance capture and a generic face rig. The customized rig accurately captures actor-specific face details while producing a semantically meaningful FACS basis. The resulting rig faithfully serves both artist friendly keyframe animation and high quality facial motion retargeting in production. © 2016 Copyright held by the owner/author(s).","Capture; Face; Facial rig; Performance","Interactive computer graphics; 3D reconstruction; Capture; Face; Facial geometry; Facial motions; Facial rig; Performance; Performance capture; Computer keyboards",2-s2.0-84984605085
"Wisessing P., Dingliana J., McDonnell R.","Perception of lighting and shading for animated virtual characters",2016,"Proceedings of the ACM Symposium on Applied Perception, SAP 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012016434&doi=10.1145%2f2931002.2931015&partnerID=40&md5=63418c87b7f8ee4ad029e7cac2a8e214","The design of lighting in Computer Graphics is directly derived from cinematography, and many digital artists follow the conventional wisdom on how lighting is set up to convey drama, appeal, or emotion. In this paper, we are interested in investigating the most commonly used lighting techniques to more formally determine their effect on our perception of animated virtual characters. Firstly, we commissioned a professional animator to create a sequence of dramatic emotional sentences for a typical CG cartoon character. Then, we rendered that character using a range of lighting directions, intensities, and shading techniques. Participants of our experiment rated the emotion, the intensity of the performance, and the appeal of the character. Our results provide new insights into how animated virtual characters are perceived, when viewed under different lighting conditions. © 2016 Copyright held by the owner/author(s).","Animation; Computer graphics; Lighting; Perception; Rendering; Virtual character","Animation; Computer graphics; Rendering (computer graphics); Sensory perception; Cartoon characters; Lighting conditions; Rendering; Virtual character; Lighting",2-s2.0-85012016434
"Spicker M., Arellano D., Schaller U., Rauh R., Helzle V., Deussen O.","Emotion recognition in autism spectrum disorder: Does stylization help?",2016,"Proceedings of the ACM Symposium on Applied Perception, SAP 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012014531&doi=10.1145%2f2931002.2931004&partnerID=40&md5=966bcdd8b547a1bd97275e7525aeaa14","We investigate the effect that stylized facial expressions have on the perception and categorization of emotions by participants with high-functioning Autism Spectrum Disorder (ASD) in contrast to two control samples: one with Attention-Deficit/Hyperactivity Disorder (ADHD), and one with neurotypically developed peers (NTD). Realtime Non-Photorealistic Rendering (NPR) techniques with different levels of abstraction are applied to stylize two animated virtual characters performing expressions for six basic emotions. Our results show that the accuracy rates of the ASD group were unaffected by the NPR styles and reached about the same performance as for the characters with realistic-looking appearance. This effect, however, was not seen in the ADHD and NTD groups. © 2016 Copyright held by the owner/author(s).","Autism spectrum disorder; Emotion recognition; Facial animation; Non-photorealistic rendering","Computer graphics; Diseases; Speech recognition; Autism spectrum disorders; Emotion recognition; Facial animation; Facial Expressions; Levels of abstraction; Non-Photorealistic Rendering; Real-time non-photorealistic rendering; Virtual character; Behavioral research",2-s2.0-85012014531
"Polys N.F., Gurjarpadhye A.A.","Tradeoffs in multi-channel microscopy volume visualization: An initial evaluation",2016,"Proceedings of the 21st International Conference on Web3D Technology, Web3D 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983507399&doi=10.1145%2f2945292.2945323&partnerID=40&md5=8ec440b2161c2c545e6a0ee3b15e95ee","In this paper, we describe two different pipelines for visualizing multi-channel cell image volumes. We obtained six different multi-channel three-dimensional cell image datasets from the Cell Image Library (CIL); a freely-Accessible online public repository of cell images. We processed these sets to create Segmented and Iso-Surface volume renderings. These two visualization pipelines were used to create animations such that same data can be viewed using both approaches side-by-side. A survey involving 50 anonymous participants was conducted to assess the suitability of Segmented or Iso-Surface volume rendering for the perception of proximity, connectivity and containment of two or more structures in a given volume. The Iso-Surface rendering was a winning choice for judging estimates of Proximity and Connectivity, while both approaches were rated equally useful for judgments of Containment in the 6 datasets tested. © 2016 ACM.","Cell Imaging; Extensible 3D (X3D); Volume Visualization; Web3D","Cells; Cytology; Data visualization; Pipelines; Surveys; Visualization; Volume rendering; Cell imaging; Extensible 3d; Multi channel; Public repositories; Side by sides; Visualization pipeline; Volume visualization; Web3D; Three dimensional computer graphics",2-s2.0-84983507399
"Flam D.L., Gomide J.V.B., Araujo A.D.A.","Development of an Open Source Software for Real Time Optical Motion Capture",2016,"Proceedings - 18th Symposium on Virtual and Augmented Reality, SVR 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986232233&doi=10.1109%2fSVR.2016.28&partnerID=40&md5=8da043ad49924d41b17eafe6003fb38c","This paper discusses the development and release of an open source real time motion capture system for character animation, the OpenMoCap. The software carries out the entire pipeline for acquisition of motion data and its output in appropriate formats to modeling and animation software. OpenMoCap uses the passive optical capture technique to follow markers positions in a scene across the time, and its development is based on digital image analysis techniques. The defined architecture is designed for real time motion recording and is flexible and modular. It allows the addition of new optimized modules for specific functions, as an interface to virtual and augmented reality headsets, different cameras sets and markerless motion capture, taking advantage of the existing ones. In order to obtain quantitative results to assess the software and the created motion capture workflow, OpenMoCap was compared with a commercial optical motion capture system. The performance of the three most used trackers was also evaluated with OpenMoCap The present version of the software is available to download at GitHub. In this paper, the architecture, construction modules and performance comparison are discussed with the scope to present the software as a choice to input motion data to virtual and augmented reality applications. © 2016 IEEE.","motion capture techniques; open source software development; tracking and sensing; virtual and augmented reality input","Animation; Application programs; Augmented reality; Computer software; Motion estimation; Open systems; Software design; Software engineering; Character animation; Digital image analysis; Markerless motion capture; Modeling and animation; Motion capture; Optical motion capture; Performance comparison; Virtual and augmented reality; Open source software",2-s2.0-84986232233
"Ismail I., Sunar M.S., Qian H.W., Arsad M.A.M.","3D character motion deformation technique for motion style alteration",2016,"Proceedings of the 2015 4th International Conference on Interactive Digital Media, ICIDM 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983375646&doi=10.1109%2fIDM.2015.7516341&partnerID=40&md5=270a019bb19eedcc9ddc785af330e592","Realistic humanoid character movement is very important for the application of in the computer games and animations. However, 3D character pose has a very high dimensional data together with joint rotation, body position and orientation. This paper demonstrates a technique in deforming various motion styles from normal to strong and to exaggeration mode by deforming specific pose from 3D character motion input on the computer animation system. This method allows the humanoid character to generate new motion from original motion respond and naturally based on user's motion input. Unlike the current 3D humanoid character motion editor, our method produces a realistic final result and simulates smooth humanoid motion style based on simple user interface control. © 2015 IEEE.","3D Character; Humanoid motion; motion alteration; motion deformation; Motion style","Animation; Clustering algorithms; Computer games; Deformation; Digital storage; Human computer interaction; User interfaces; 3D characters; Humanoid motion; motion alteration; Motion deformation; Motion styles; Motion compensation",2-s2.0-84983375646
"Hilsmann A.","Towards image-based modelling, editing and rendering",2016,"Optics InfoBase Conference Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019516834&doi=10.1364%2fCOSI.2016.CTh3B.3&partnerID=40&md5=b7ed7a4656275bdc9362371ca13fa495","Capturing and rendering real world objects and scenes with high visual quality has been one of the main topics in Computer Vision and Graphics in the last decades. Often,we do not only wish to display the captured content but also modify it, interact with it and experience it in an immersive way. Classic Computer Graphics modelling and rendering provides the freedom of modification and animation, but often lacks visual realism, especially if real-time constraints should be met. Also, modelling often involves enormous manual work and rendering and animation require costly physical simulations. Recent approaches directly capture real world objects and scenes and infer object characteristics from the captured data.Furthermore, more and more image-based modeling techniques have been developed in order to meet both the requirements of realistic appearance and animation, especially for complex objects. This is where Computer Vision and Graphics meet. In this talk, I will give an overview on ongoing works covering the whole processing chain from capturing, image and video analysis and understanding to image-based modelling, editing and rendering. © 2016 Optical Society of America. © OSA 2016.",,"Animation; Computer graphics; Computer vision; Image segmentation; Video signal processing; Graphics modelling; Image-based modeling; Image-based modelling; Object characteristics; Optical Society of America; Physical simulation; Real time constraints; Real-world objects; Rendering (computer graphics)",2-s2.0-85019516834
"Murakami R., Muranaka N.","Study support system of character drawing considering feeling evaluation",2016,"Proceedings of The International Symposium on Multiple-Valued Logic",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981322869&doi=10.1109%2fISMVL.2016.34&partnerID=40&md5=f5c410c6746324218374964e023f2b5d","In the evaluation of the art, the evaluation depends on the examiner. However, in the evaluation like learning, obvious evaluation standard is nothing in this time. Also, the inflexible binary computer cannot do evaluation (multiple-valued logic) like human. Therefore, authors already presented about some drawing support systems of self-education type for beginner. And, that motif is human character. In first research report, scoring evaluation method was ""total of 3 items"". However, this method had no elasticity to be able to evaluate ""position shifting"" or ""similar drawing"". Therefore, in this research, we reconsider the item of the drawing evaluation and we propose the character drawing study support system which can do the feeling evaluation like the human with having strictness and an elasticity. © 2016 IEEE.","Animation; character drawing; comics; evaluation; humanity-feeling; illustrations","Animation; Computer circuits; Elasticity; Reconfigurable hardware; comics; evaluation; Evaluation standard; humanity-feeling; illustrations; Multiple valued logic; Position shifting; Research reports; Many valued logics",2-s2.0-84981322869
"Ueno M., Fukuda K., Mori N.","Can computers create comics and animations?",2016,"Computational and Cognitive Approaches to Narratology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014199080&doi=10.4018%2f978-1-5225-0432-0.ch006&partnerID=40&md5=4b2e138900092c5e4db5480777b812b1","The objective of this chapter is to develop a method for generating and analyzing creative work by using computers. In this chapter, novels, comics, and animations are considered representative creative work because the main method for representing creative work is the use of natural language and pictures. These works focus on interesting issues, which can be explained by computational approaches to narratology. In this chapter, the authors discuss the following three topics. First, a method of semi-automatic story generation by agent-based simulation is presented. Second, methods of generating and analyzing comics on the basis of the features of pictures and stories used are described. Third, the authors introduce a method of estimating the difficulties of translating a storyboard into original pictures in the process of creating animations. © 2016 by IGI Global. All rights reserved.",,,2-s2.0-85014199080
"Glauser O., Ma W.-C., Panozzo D., Jacobson A., Hilliges O., Sorkine-Hornung O.","Rig animation with a tangible and modular input device",2016,"ACM Transactions on Graphics",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979964894&doi=10.1145%2f2897824.2925909&partnerID=40&md5=83fb166801301b162d0dc17fcf982416","We propose a novel approach to digital character animation, combining the benefits of tangible input devices and sophisticated rig animation algorithms. A symbiotic software and hardware approach facilitates the animation process for novice and expert users alike. We overcome limitations inherent to all previous tangible devices by allowing users to directly control complex rigs using only a small set (5-10) of physical controls. This avoids oversimplification of the pose space and excessively bulky device configurations. Our algorithm derives a small device configuration from complex character rigs, often containing hundreds of degrees of freedom, and a set of sparse sample poses. Importantly, only the most influential degrees of freedom are controlled directly, yet detailed motion is preserved based on a pose interpolation technique. We designed a modular collection of joints and splitters, which can be assembled to represent a wide variety of skeletons. Each joint piece combines a universal joint and two twisting elements, allowing to accurately sense its configuration. The mechanical design provides a smooth inverse kinematics-like user experience and is not prone to gimbal locking. We integrate our method with the professional 3D software Autodesk Maya® and discuss a variety of results created with characters available online. Comparative user experiments show significant improvements over the closest state-of-the-art in terms of accuracy and time in a keyframe posing task. © 2016 Copyright held by the owner/author(s).","Animation system; Skeletal deformation; Tangible input","Degrees of freedom (mechanics); Digital devices; Interactive computer graphics; Inverse kinematics; Inverse problems; Knobs; Locks (fasteners); Mechanics; User interfaces; Animation algorithms; Animation systems; Device configurations; Digital characters; Mechanical design; Pose interpolation; Software and hardwares; Tangible input; Animation",2-s2.0-84979964894
"Hoyet L., Olivier A.-H., Kulpa R., Pettré J.","Perceptual effect of shoulder motions on crowd animations",2016,"ACM Transactions on Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980037411&doi=10.1145%2f2897824.2925931&partnerID=40&md5=80e032e351e5ce13c81b6edcd84d97f2","A typical crowd engine pipeline animates numerous moving characters according to a two-step process: global trajectories are generated by a crowd simulator, whereas full body motions are generated by animation engines. Because interactions are only considered at the first stage, animations sometimes lead to residual collisions and/or characters walking as if they were alone, showing no sign to the influence of others. In this paper, we investigate the value of adding shoulder motions to characters passing at close distances on the perceived visual quality of crowd animations (i.e., perceived residual collisions and animation naturalness). We present two successive perceptual experiments exploring this question where we investigate first, local interactions between two isolated characters, and second, crowd scenarios. The first experiment shows that shoulder motions have a strong positive effect on both perceived residual collisions and animation naturalness. The second experiment demonstrates that the effect of shoulder motions on animation naturalness is preserved in the context of crowd scenarios, even though the complexity of the scene is largely increased. Our general conclusion is that adding secondary motions in character interactions has a significant impact on the visual quality of crowd animations, with a very light impact on the computational cost of the whole animation pipeline. Our results advance crowd animation techniques by enhancing the simulation of complex interactions between crowd characters with simple secondary motion triggering techniques. © 2016 ACM.","Crowd simulation; Human animation; Interactions; Perception","Beam plasma interactions; Engines; Interactive computer graphics; Pipelines; Sensory perception; Animation pipeline; Computational costs; Crowd Simulation; Full-body motions; Global trajectories; Human animation; Local interactions; Perceptual effects; Animation",2-s2.0-84980037411
"Bai Y., Kaufman D.M., Liu C.K., Popović J.","Artist-directed dynamics for 2D animation",2016,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979987732&doi=10.1145%2f2897824.2925884&partnerID=40&md5=bb2aeb0a4c0316c968c413bf5f92dde9","Animation artists enjoy the benefits of simulation but do not want to be held back by its constraints. Artist-directed dynamics seeks to resolve this need with a unified method that combines simulation with classical keyframing techniques. The combination of these approaches improves upon both extremes: simulation becomes more customizable and keyframing becomes more automatic. Examining our system in the context of the twelve fundamental animation principles reveals that it stands out for its treatment of exaggeration and appeal. Our system accommodates abrupt jumps, large plastic deformations, and makes it easy to reuse carefully crafted animations. © 2016 ACM.","Animation; Deformation; Simulation","Deformation; Interactive computer graphics; 2D animation; Animation principles; Customizable; Keyframing; Large plastic deformation; Simulation; Unified method; Animation",2-s2.0-84979987732
"Wang C., Shi F., Xia S., Chai J.","Realtime 3D eye gaze animation using a single RGB camera",2016,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992583&doi=10.1145%2f2897824.2925947&partnerID=40&md5=2fd8d3a5a92517b6a64397794a98a0ef","This paper presents the first realtime 3D eye gaze capture method that simultaneously captures the coordinated movement of 3D eye gaze, head poses and facial expression deformation using a single RGB camera. Our key idea is to complement a realtime 3D facial performance capture system with an efficient 3D eye gaze tracker. We start the process by automatically detecting important 2D facial features for each frame. The detected facial features are then used to reconstruct 3D head poses and large-scale facial deformation using multi-linear expression deformation models. Next, we introduce a novel user-independent classification method for extracting iris and pupil pixels in each frame. We formulate the 3D eye gaze tracker in the Maximum A Posterior (MAP) framework, which sequentially infers the most probable state of 3D eye gaze at each frame. The eye gaze tracker could fail when eye blinking occurs. We further introduce an efficient eye close detector to improve the robustness and accuracy of the eye gaze tracker. We have tested our system on both live video streams and the Internet videos, demonstrating its accuracy and robustness under a variety of uncontrolled lighting conditions and overcoming significant differences of races, genders, shapes, poses and expressions across individuals. © 2016 ACM.","3D eye gaze tracking; Facial animation and control; Facial performance capture","Animation; Cameras; Deformation; Eye movements; Feature extraction; Interactive computer graphics; Three dimensional computer graphics; Tracking (position); Video streaming; Classification methods; Coordinated movement; Eye gaze tracking; Facial animation; Facial deformations; Lighting conditions; Maximum a posteriors; Performance capture; Face recognition",2-s2.0-84979992583
"Cao C., Wu H., Weng Y., Shao T., Zhou K.","Real-time facial animation with image-based dynamic avatars",2016,"ACM Transactions on Graphics",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980047577&doi=10.1145%2f2897824.2925873&partnerID=40&md5=4387a2cb73630fe19ab0a9b1f2bc76c2","We present a novel image-based representation for dynamic 3D avatars, which allows effective handling of various hairstyles and headwear, and can generate expressive facial animations with finescale details in real-time. We develop algorithms for creating an image-based avatar from a set of sparsely captured images of a user, using an off-the-shelf web camera at home. An optimization method is proposed to construct a topologically consistent morphable model that approximates the dynamic hair geometry in the captured images. We also design a real-time algorithm for synthesizing novel views of an image-based avatar, so that the avatar follows the facial motions of an arbitrary actor. Compelling results from our pipeline are demonstrated on a variety of cases. © 2016 ACM.","Face tracking; Facial animation; Hair modeling; Imagebased rendering; Virtual avatar","Animation; Face recognition; Interactive computer graphics; Optimization; Topology; Face Tracking; Facial animation; Hair model; Image based rendering; Virtual avatar; Three dimensional computer graphics",2-s2.0-84980047577
"Le B.H., Hodgins J.K.","Real-time skeletal skinning with optimized centers of rotation",2016,"ACM Transactions on Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980023829&doi=10.1145%2f2897824.2925959&partnerID=40&md5=c0dba9b0be5697950f3e8423e0faef2d","Skinning algorithms that work across a broad range of character de- signs and poses are crucial to creating compelling animations. Currently, linear blend skinning (LBS) and dual quaternion skinning (DQS) are the most widely used, especially for real-time applications. Both techniques are efficient to compute and are effective for many purposes. However, they also have many well-known artifacts, such as collapsing elbows, candy wrapper twists, and bulging around the joints. Due to the popularity of LBS and DQS, it would be of great benefit to reduce these artifacts without changing the animation pipeline or increasing the computational cost significantly. In this paper, we introduce a new direct skinning method that addresses this problem. Our key idea is to pre-compute the optimized center of rotation for each vertex from the rest pose and skinning weights. At runtime, these centers of rotation are used to interpolate the rigid transformation for each vertex. Compared to other direct skinning methods, our method significantly reduces the artifacts of LBS and DQS while maintaining real-time performance and backwards compatibility with the animation pipeline. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Blending; Real-time animation; Skeletal animation; Skinning","Algorithms; Blending; Interactive computer graphics; Pipelines; Center of rotation; Computational costs; Real time performance; Real-time animations; Real-time application; Rigid transformations; Skeletal animation; Skinning; Animation",2-s2.0-84980023829
"Edwards P., Landreth C., Fiume E., Singh K.","JALI: An animator-centric viseme model for expressive lip synchronization",2016,"ACM Transactions on Graphics",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980018592&doi=10.1145%2f2897824.2925984&partnerID=40&md5=e97ea9b562d05d8049dd3f31caed66e2","The rich signals we extract from facial expressions imposes high expectations for the science and art of facial animation. While the advent of high-resolution performance capture has greatly improved realism, the utility of procedural animation warrants a prominent place in facial animation workflow. We present a system that, given an input audio soundtrack and speech transcript, automatically generates expressive lip-synchronized facial animation that is amenable to further artistic refinement, and that is comparable with both performance capture and professional animator output. Because of the diversity of ways we produce sound, the mapping from phonemes to visual depictions as visemes is manyvalued. We draw from psycholinguistics to capture this variation using two visually distinct anatomical actions: Jaw and Lip, where sound is primarily controlled by jaw articulation and lower-face muscles, respectively. We describe the construction of a transferable template JALI 3D facial rig, built upon the popular facial muscle action unit representation FACS. We show that acoustic properties in a speech signal map naturally to the dynamic degree of jaw and lip in visual speech. We provide an array of compelling animation clips, compare against performance capture and existing procedural animation, and report on a brief user study. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Audio-visual speech; Facial animation; Lip synchronization; Procedural animation; Speech synchronization","Acoustic properties; Computer keyboards; Interactive computer graphics; Muscle; Signal processing; Speech; Synchronization; Audio-visual speech; Facial animation; Lip synchronization; Procedural animation; Speech synchronization; Animation",2-s2.0-84980018592
"Won J., Lee J.","Shadow theatre: Discovering human motion from a sequence of silhouettes",2016,"ACM Transactions on Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979995643&doi=10.1145%2f2897824.2925869&partnerID=40&md5=1fdf20b9cfa41bae8dbc3bc8cad58220","Shadow theatre is a genre of performance art in which the actors are only visible as shadows projected on the screen. The goal of this study is to generate animated characters, the shadows of which match a sequence of target silhouettes. This poses several challenges. The motion of multiple characters are carefully coordinated to form a target silhouette on the screen, and each character's pose should be stable, balanced, and plausible. The resulting character animation should be smooth and coherent spatially and temporally. We formulate the problem as nonlinear constrained optimization with objectives, which were designed to generate plausible human motions. Our optimization algorithm was primarily inspired by the heuristic strategies of professional shadow theatre actors. Their know-how was studied and then incorporated into our optimization formulation. We demonstrate the effectiveness of our approach with a variety of target silhouettes and 3D fabrication of the results. ©: 2016 ACM.","2D silhouettes; Animation authoring; Character animation; Multi-character coordination; Shadow art; Shadow play; Shadow theatre; Shadows","Algorithms; Animation; Constrained optimization; Interactive computer graphics; Optimization; Technology transfer; 2D silhouettes; Character animation; Multi-character coordination; Shadow art; Shadow play; Shadow theatre; Shadows; Theaters",2-s2.0-84979995643
"Klár G., Gast T., Pradhana A., Fu C., Schroeder C., Jiang C., Teran J.","Drucker-prager elastoplasticity for sand animation",2016,"ACM Transactions on Graphics",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979987642&doi=10.1145%2f2897824.2925906&partnerID=40&md5=ed39b1c369aa25d928ca187a64450232","We simulate sand dynamics using an elastoplastic, continuum assumption. We demonstrate that the Drucker-Prager plastic flow model combined with a Hencky-strain-based hyperelasticity accurately recreates a wide range of visual sand phenomena with moderate computational expense. We use the Material Point Method (MPM) to discretize the governing equations for its natural treatment of contact, topological change and history dependent constitutive relations. The Drucker-Prager model naturally represents the frictional relation between shear and normal stresses through a yield stress criterion. We develop a stress projection algorithm used for enforcing this condition with a non-associative flow rule that works naturally with both implicit and explicit time integration. We demonstrate the efficacy of our approach on examples undergoing large deformation, collisions and topological changes necessary for producing modern visual effects. © 2016 Copyright held by the owner/author(s).","APIC; Elastoplasticity; Granular; MPM; Sand","Elasticity; Elastoplasticity; Interactive computer graphics; Plasticity; Topology; Yield stress; APIC; Computational expense; Constitutive relations; Explicit time integration; Granular; Material point methods; Non-associative flows; Projection algorithms; Sand",2-s2.0-84979987642
"Agrawal S., Van De Panne M.","Task-based Locomotion",2016,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979986879&doi=10.1145%2f2897824.2925893&partnerID=40&md5=b6ab2c6a203de2721bb13d7478b1f654","High quality locomotion is key to achieving believable character animation, but is often modeled as a generic stepping motion between two locations. In practice, locomotion often has task-specific characteristics and can exhibit a rich vocabulary of step types, including side steps, toe pivots, heel pivots, and intentional foot slides. We develop a model for such types of behaviors, based on task-specific foot-step plans that act as motion templates. The footstep plans are invoked and optimized at interactive rates and then serve as the basis for producing full body motion. We demonstrate the production of high-quality motions for three tasks: whiteboard writing, moving boxes, and sitting behaviors. The model enables retargeting to characters of varying proportions by yielding motion plans that are appropriately tailored to these proportions. We also show how the task effort or duration can be taken into account, yielding coarticulation behaviors. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Human locomotion; Motion capture","Animation; Character animation; Co-articulation; Full-body motions; Human locomotions; Interactive rates; Motion capture; Motion templates; Sitting behavior; Interactive computer graphics",2-s2.0-84979986879
"Choi B., BlancoI Ribera R., Lewis J.P., Seol Y., Hong S., Eom H., Jung S., Noh J.","SketchiMo: Sketch-based motion editing for articulated characters",2016,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980006567&doi=10.1145%2f2897824.2925970&partnerID=40&md5=eae59b87f678d2d9e7a3a22f9b908525","We present SketchiMo, a novel approach for the expressive editing of articulated character motion. SketchiMo solves for the motion given a set of projective constraints that relate the sketch inputs to the unknown 3D poses. We introduce the concept of sketch space, a contextual geometric representation of sketch targets-motion properties that are editable via sketch input-that enhances, right on the viewport, different aspects of the motion. The combination of the proposed sketch targets and space allows for seamless editing of a wide range of properties, from simple joint trajectories to local parent-child spatiotemporal relationships and more abstract properties such as coordinated motions. This is made possible by interpreting the user's input through a new sketch-based optimization engine in a uniform way. In addition, our view-dependent sketch space also serves the purpose of disambiguating the user inputs by visualizing their range of effect and transparently defining the necessary constraints to set the temporal boundaries for the optimization. © 2016 ACM.","Articulated character motion; Character animation; Motion editing; Sketch-based interface","Animation; Interactive computer graphics; Motion compensation; Character animation; Character motion; Geometric representation; Motion editing; Optimization engine; Projective constraints; Sketch based Interface; Spatio-temporal relationships; Motion picture editing machines",2-s2.0-84980006567
"Holden D., Saito J., Komura T.","A deep learning framework for character motion synthesis and editing",2016,"ACM Transactions on Graphics",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980028529&doi=10.1145%2f2897824.2925975&partnerID=40&md5=d2b3b8120c14619d17ed8e9b183b8a18","We present a framework to synthesize character movements based on high level parameters, such that the produced movements respect the manifold of human motion, trained on a large motion capture dataset. The learned motion manifold, which is represented by the hidden units of a convolutional autoencoder, represents motion data in sparse components which can be combined to produce a wide range of complex movements. To map from high level parametersto the motion manifold, we stack a deep feedforward neural network on top of the trained autoencoder. This network is trained to produce realistic motion sequences from parameters such as a curve over the terrain that the character should follow, or a target location for punching and kicking. The feedforward control network and the motion manifold are trained independently, allowing the user to easily switch between feedforward networks according to the desired interface, without re-training the motion manifold. Once motion is generated it can be edited by performing optimizationin the space of the motion manifold. This allows for imposing kinematic constraints, or transforming the style of the motion, while ensuring the edited motion remains natural. As a result, the system can produce smooth, high quality motion sequences without any manual pre-processing of the training data.","Autoencoder; Character animation; Convolutional neural networks; Deep learning; Human motion; Manifold learning","Animation; Convolution; Feedforward neural networks; Interactive computer graphics; Learning systems; Neural networks; Switching circuits; Auto encoders; Character animation; Convolutional neural network; Deep learning; Human motions; Manifold learning; Complex networks",2-s2.0-84980028529
"Chien E., Chen R., Weber O.","Bounded distortion harmonic shape interpolation",2016,"ACM Transactions on Graphics",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980016029&doi=10.1145%2f2897824.2925926&partnerID=40&md5=be2c939692f04fd2f247adab9444fafe","Planar shape interpolation is a classic problem in computer graphics. We present a novel shape interpolation method that blends C∞ planar harmonic mappings represented in closed-form. The intermediate mappings in the blending are guaranteed to be locally injective C∞ harmonic mappings, with conformal and isometric distortion bounded by that of the input mappings. The key to the success of our method is the fact that the blended differentials of our interpolated mapping have a simple closed-form expression, so they can be evaluated with unprecedented efficiency and accuracy. Moreover, in contrast to previous approaches, these differentials are integrable, and result in an actual mapping without further modification. Our algorithm is embarrassingly parallel and is orders of magnitude faster than state-of-the-art methods due to its simplicity, yet it still produces mappings that are superior to those of existing techniques due to its guaranteed bounds on geometric distortion. © 2016 ACM.","Animation; Bounded distortion; Harmonic mappings; Injective mappings; Shape deformation; Shape interpolation","Animation; Blending; Computer graphics; Gears; Harmonic analysis; Interactive computer graphics; Interpolation; Bounded distortions; Harmonic mappings; Injective mapping; Shape deformation; Shape interpolation; Mapping",2-s2.0-84980016029
"Zhu H., Liu X., Wong T.-T., Heng P.-A.","Globally optimal toon tracking",2016,"ACM Transactions on Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980002617&doi=10.1145%2f2897824.2925872&partnerID=40&md5=f2b4192bda58ccd931ccb13d8aec1547","The ability to identify objects or region correspondences between consecutive frames of a given hand-drawn animation sequence is an indispensable tool for automating animation modification tasks such as sequence-wide recoloring or shape-editing of a specific animated character. Existing correspondence identification methods heavily rely on appearance features, but these features alone are insufficient to reliably identify region correspondences when there exist occlusions or when two or more objects share similar appearances. To resolve the above problems, manual assistance is often required. In this paper, we propose a new correspondence identification method which considers both appearance features and motions of regions in a global manner. We formulate correspondence likelihoods between temporal region pairs as a network flow graph problem which can be solved by a well-established optimization algorithm. We have evaluated our method with various animation sequences and results show that our method consistently outperforms the state-of-the-art methods without any user guidance. © 2016 Copyright held by the owner/author(s).","Region correspondence; Toon tracking","Algorithms; Flow graphs; Interactive computer graphics; Optimization; Animated characters; Graph problems; Identification method; Indispensable tools; Optimization algorithms; Region correspondence; Shape editing; State-of-the-art methods; Animation",2-s2.0-84980002617
"Xu H., Barbič J.","Pose-space subspace dynamics",2016,"ACM Transactions on Graphics",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979994129&doi=10.1145%2f2897824.2925916&partnerID=40&md5=44fb5b33ade04ab2c5d963e61c321877","We enrich character animations with secondary soft-tissue Finite Element Method (FEM) dynamics computed under arbitrary rigged or skeletal motion. Our method optionally incorporates pose-space deformation (PSD). It runs at milliseconds per frame for complex characters, and fits directly into standard character animation pipelines. Our simulation method does not require any skin data capture; hence, it can be applied to humans, animals, and arbitrary (real-world or fictional) characters. In standard model reduction of three-dimensional nonlinear solid elastic models, one builds a reduced model around a single pose, typically the rest configuration. We demonstrate how to perform multi-model reduction of Finite Element Method (FEM) nonlinear elasticity, where separate reduced models are precomputed around a representative set of object poses, and then combined at runtime into a single fast dynamic system, using subspace interpolation. While time-varying reduction has been demonstrated before for offline applications, our method is fast and suitable for hard real-time applications in games and virtual reality. Our method supports self-contact, which we achieve by computing linear modes and derivatives under contact constraints. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Character rigging; FEM; Model reduction; Physically based simulation; Posespace; Real-time; Secondary motion","Animation; Interactive computer graphics; Virtual reality; Character rigging; Model reduction; Physically-based simulation; Posespace; Real time; Secondary motion; Finite element method",2-s2.0-84979994129
"Jones B., Thuerey N., Shinar T., Bargteil A.W.","Example-based plastic deformation of rigid bodies",2016,"ACM Transactions on Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980011805&doi=10.1145%2f2897824.2925979&partnerID=40&md5=31f80d5aa6251204211c9b6c5b57f56a","Physics-based animation is often used to animate scenes containing destruction of near-rigid, man-made materials. For these applications, the most important visual features are plastic deformation and fracture. Methods based on continuum mechanics model these materials as elastoplastic, and must perform expensive elasticity computations even though elastic deformations are imperceptibly small for rigid materials. We introduce an example-based plasticity model based on linear blend skinning that allows artists to author simulation objects using familiar tools. Dynamics are computed using an unmodified rigid body simulator, making our method computationally efficient and easy to integrate into existing pipelines. We introduce a flexible technique for mapping impulses computed by the rigid body solver to local, example-based deformations. For completeness, our method also supports prescoring based fracture. We demonstrate the practicality of our method by animating a variety of destructive scenes. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Deformation; Example-based Simulation; Local Blending; Plasticity; Rigid Body Simulation; Skinning","Blending; Continuum mechanics; Deformation; Fracture; Interactive computer graphics; Plastic deformation; Plasticity; Computationally efficient; Continuum mechanics models; Deformation and fracture; Example based; Man made material; Physics-based animation; Rigid-body simulations; Skinning; Rigid structures",2-s2.0-84980011805
"Langlois T.R., Zheng C., James D.L.","Toward animating water with complex acoustic bubbles",2016,"ACM Transactions on Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980022382&doi=10.1145%2f2897824.2925904&partnerID=40&md5=58098537be62d81e0b17461b33fac3e2","This paper explores methods for synthesizing physics-based bubble sounds directly from two-phase incompressible simulations of bubbly water flows. By tracking fluid-air interface geometry, we identify bubble geometry and topological changes due to splitting, merging and popping. A novel capacitance-based method is proposed that can estimate volume-mode bubble frequency changes due to bubble size, shape, and proximity to solid and air interfaces. Our acoustic transfer model is able to capture cavity resonance effects due to near-field geometry, and we also propose a fast precomputed bubble-plane model for cheap transfer evaluation. In addition, we consider a bubble forcing model that better accounts for bubble entrainment, splitting, and merging events, as well as a Helmholtz resonator model for bubble popping sounds. To overcome frequency bandwidth limitations associated with coarse resolution fluid grids, we simulate micro-bubbles in the audio domain using a power-law model of bubble populations. Finally, we present several detailed examples of audiovisual water simulations and physical experiments to validate our frequency model. © 2016 Copyright held by the owner/author(s).","Acoustic bubbles; Acoustic transfer; Fluid animation; Sound synthesis","Air; Geometry; High energy physics; Interactive computer graphics; Merging; Acoustic transfer; Fluid animation; Frequency band width; Helmholtz resonators; Incompressible simulations; Near-field geometry; Physical experiments; Sound synthesis; Phase interfaces",2-s2.0-84980022382
"Falkner K., Falkner N., Szabo C., Vivian R.","Applying validated pedagogy to MOOCs: An introductory programming course with media computation",2016,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979780529&doi=10.1145%2f2899415.2899429&partnerID=40&md5=932d418b15c5c1ee368a79626b5dcbed","Significant advances have been made in the learning and teaching of Introductory Programming, including the integration of active and contextualised learning pedagogy. However, Massively Open Online Courses (MOOCs), where Computer Science and, more specifically, introductory programming courses dominate, do not typically adopt such pedagogies or lessons learned from more traditional learning environments. Moreover, the improvement of learning within the MOOC context in terms of discipline-specific pedagogy, and the improvement of student learning outcomes and processes have not been studied in depth. This paper reports findings from a foundation programming skills MOOC that supports the learning of fundamental Computer Science concepts and the development of programming skills through a media computation approach, based upon digital artworks and animations. In this paper, we explore the course activity data as well as a sample of students' source code submissions to investigate their engagement with the course and the quality and development of their programming skill over the six weeks of the course duration.","CS101; Introductory programming; Massively open online course (MOOC); Online learning","Computer aided instruction; Computer programming; Curricula; Education; Education computing; Engineering education; Engineering research; Students; Teaching; CS101; Introductory programming; Introductory programming course; Learning and teachings; Online learning; Open online course; Student learning outcomes; Traditional learning; E-learning",2-s2.0-84979780529
"Prada F., Kazhdan M., Chuang M., Collet A., Hoppe H.","Motion graphs for unstructured textured meshes",2016,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979987513&doi=10.1145%2f2897824.2925967&partnerID=40&md5=9a560afc13a9f9650ef276a4df2d12f8","Scanned performances are commonly represented in virtual environments as sequences of textured triangle meshes. Detailed shapes deforming over time benefit from meshes with dynamically evolving connectivity. We analyze these unstructured mesh sequences to automatically synthesize motion graphs with new smooth transitions between compatible poses and actions. Such motion graphs enable natural periodic motions, stochastic playback, and user-directed animations. The main challenge of unstructured sequences is that the meshes differ not only in connectivity but also in alignment, shape, and texture. We introduce new geometry processing techniques to address these problems and demonstrate visually seamless transitions on high-quality captures. © 2016 Copyright held by the owner/author(s).","Looping; Markov chain; Seamless transitions; Shape morphing; Shape similarity; Stochastic motion; Video textures","Interactive computer graphics; Markov processes; Stochastic systems; Virtual reality; Looping; Seamless transition; Shape morphing; Shape similarity; Stochastic motion; Video textures; Directed graphs",2-s2.0-84979987513
"Miyashita L., Ishihara K., Watanabe Y., Ishikawa M.","ZoeMatrope: A system for physical material design",2016,"ACM Transactions on Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979971937&doi=10.1145%2f2897824.2925925&partnerID=40&md5=900dfe0a2d17e0a8fcef73e44ce39eeb","Reality is the most realistic representation. We introduce a material display called ZoeMatrope that can reproduce a variety of materials with high resolution, dynamic range and light field reproducibility by using compositing and animation principles used in a zoetrope and a thaumatrope. With ZoeMatrope, the quality of the material is equivalent to that of real objects and the range of expressible mate-rials is diversified by overlaying a set of base materials in a linear combination. ZoeMatrope is also able to express spatially-varying materials, and even augmented materials such as materials with an alpha channel. In this paper, we propose a method for selecting the optimal material set and determining the weights of the linear com-bination to reproduce a wide range of target materials properly. We also demonstrate the effectiveness of this approach with the devel-oped system and show the results for various materials. © 2016 ACM.","Diffuse; Material composition; Specular; Strobe light; Thaumatrope; Zoetrope","Interactive computer graphics; Diffuse; Material compositions; Specular; Thaumatrope; Zoetrope; Field emission displays",2-s2.0-84979971937
"Azevedo V.C., Batty C., Oliveira M.M.","Preserving geometry and topology for fluid flows with thin obstacles and narrow gaps",2016,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980042058&doi=10.1145%2f2897824.2925919&partnerID=40&md5=b0e163d94d110668da0e40afcdb0006f","Fluid animation methods based on Eulerian grids have long struggled to resolve flows involving narrow gaps and thin solid features. Past approaches have artificially inflated or voxelized boundaries, although this sacrifices the correct geometry and topology of the fluid domain and prevents flow through narrow regions. We present a boundary-respecting fluid simulator that overcomes these challenges. Our solution is to intersect the solid boundary geometry with the cells of a background regular grid to generate a topologically correct, boundary-conforming cut-cell mesh. We extend both pressure projection and velocity advection to support this enhanced grid structure. For pressure projection, we introduce a general graph-based scheme that properly preserves discrete incompressibility even in thin and topologically complex flow regions, while nevertheless yielding symmetric positive definite linear systems. For advection, we exploit polyhedral interpolation to improve the degree to which the flow conforms to irregular and possibly non-convex cell boundaries, and propose a modified PIC/FLIP advection scheme to eliminate the need to inaccurately reinitialize invalid cells that are swept over by moving boundaries. The method naturally extends the standard Eulerian fluid simulation framework, and while we focus on thin boundaries, our contributions are beneficial for volumetric solids as well. Our results demonstrate successful one-way fluid-solid coupling in the presence of thin objects and narrow flow regions even on very coarse grids. © 2016 Copyright held by the owner/author(s).","Boundaries; Coupling; Cut-cell; Fluids; Thin solids","Advection; Cells; Couplings; Cytology; Flow graphs; Fluids; Geometry; Graphic methods; Interactive computer graphics; Linear systems; Semiconductor insulator boundaries; Topology; Cut cells; Fluid simulators; Fluid-solid coupling; Grid structures; Moving boundaries; Solid boundaries; Symmetric positive definite linear systems; Thin solids; Flow of fluids",2-s2.0-84980042058
"Makohon I., Cetin M., Nguyen D.T., Ng M.","Hungarian optimum assignment algorithm with Java computer animation",2016,"Conference Proceedings - IEEE SOUTHEASTCON",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980009969&doi=10.1109%2fSECON.2016.7506731&partnerID=40&md5=8e75b9bdda0214f7d4c4e29de2383501","The classical, popular Hungarian algorithm for solving the optimum assignment problems (with its broad engineering/science applications) has been well-documented in the literature. Other (more efficient) variations of the Hungarian algorithm have also been extensively studied by the research communities. In this paper, the basic Hungarian algorithm is revisited, with the ultimate goal of developing a useful, user friendly, attractive Java computer animation for effectively teaching this basic/important optimum assignment algorithm. The final product from this work will help both the students and their instructor to not only mastering this technical subject, but also provide valuable tool for obtaining the solutions for homework assignments, class examinations, self-assessment tools, etc. A demo video of the Hungarian Algorithm's animation and result can be viewed online from any web browser using the website provided in reference [9]. © 2016 IEEE.","Animation; Hungarian Algorithm; Java; Optimum Assignment","Animation; Combinatorial optimization; Assignment algorithms; Assignment problems; Homework assignments; Hungarian algorithm; Java; Optimum Assignment; Research communities; Self-assessment tools; Algorithms",2-s2.0-84980009969
"Larboulette C., Gibet S.","I am a tree: Embodiment using physically based animation driven by expressive descriptors of motion",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979788968&doi=10.1145%2f2948910.2948939&partnerID=40&md5=1cd837ad93f60dee9bdd0c4e9b659f69","Expressive representation of human movement has given rise to various static or dynamic artistic creations, whether they take into account specific postures or motion sequences. In this paper we are interested in the expressive qualities of motion and how these qualities influence the evolution of a 3D simulated system. The embodiment of this system takes the form of a non-anthropomorphic structure (non-human appearance) whose behavior expresses the emotional content of the original human motion. Expressive descriptors are extracted from a sequence of theatrical movements executed with different emotional states and used to dynamically control a mass-spring system coupled to a particle system as well as its rendering. The framework allows for the exploration of different sets of motion descriptors and mappings to the parameters of the 3D simulation. The resulting animations are discussed and evaluated through perceptual studies. © 2016 ACM.","Animation; Descriptors; Embodiment; Expressive; Motion; Perception; Simulation","Computer applications; Computer programming; Sensory perception; Descriptors; Embodiment; Expressive; Motion; Simulation; Animation",2-s2.0-84979788968
"Wilson B., Bounds M., Tavakkoli A.","Hand motion calibration and retargeting for intuitive object manipulation in immersive virtual environments",2016,"Proceedings - IEEE Virtual Reality",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979790823&doi=10.1109%2fVR.2016.7504779&partnerID=40&md5=2d6b9e8253778a700b0e0353d312b2a8","In this paper a system is proposed to combine small finger movements with the large scale body movements captured from a motion capture system. The strength of the proposed work over previous research is in the real-time and natural interactions that the virtual hands have with their environment. By being able to conform to physics, the virtual hands feel like virtual extensions of one's own hands. This provides a higher degree of immersion and interactivity when compared to more traditional virtual reality systems. © 2016 IEEE.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Animation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual Reality; I.3.8 [Computer Graphics]: Applications","Computer graphics; Virtual reality; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; I.3.8 [computer graphics]: Applications; Immersive virtual environments; Motion capture system; Natural interactions; Object manipulation; Virtual reality system; Three dimensional computer graphics",2-s2.0-84979790823
"Wheatland N., Abdullah A., Neff M., Jorg S., Zordan V.","Analysis in support of realistic timing in animated fingerspelling",2016,"Proceedings - IEEE Virtual Reality",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979743193&doi=10.1109%2fVR.2016.7504777&partnerID=40&md5=65d5b173fe50364b6bed2250ae162be6","American Sign Language (ASL) fingerspelling is the act of spelling a word letter-by-letter when a specific sign does not exist to represent it. Synthesizing intelligible ASL, which includes fingerspelling as an integral part, is important to create signing virtual characters for training and communicating in virtual environments or further applications. The rhythm and speed of fingerspelling play a large role in how well fingerspelling is understood. Using motion capture technologies, we record fingerspelling and analyze timing information about letters in the words. Our goal is to identify fingerspelling timing information and use it to create fingerspelling animations that are natural and understandable. © 2016 IEEE.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Animation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual Reality","Computer graphics; Virtual reality; American sign language; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Integral part; Motion capture; Timing information; Virtual character; Three dimensional computer graphics",2-s2.0-84979743193
"Dallaire-Côté M., Charbonneau P., Côté S.S.-P., Aissaoui R., Labbe D.R.","Animated self-avatars for motor rehabilitation applications that are biomechanically accurate, low-latency and easy to use",2016,"Proceedings - IEEE Virtual Reality",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979771439&doi=10.1109%2fVR.2016.7504706&partnerID=40&md5=28df44d77c6688c82a8ec5357e2a0dab","The emerging use of self-avatars for physical and motor rehabilitation leads to specific requirements for their real-time animation that combine properties from the fields of computer graphics and of biomechanics. We present a method for animating a self-avatar in real-time that allows for high-fidelity representation of whole-body kinematics using anatomical and reproducible bone-segment definition. The method requires little setup time and has low motion-to-photon latency. © 2016 IEEE.","Animation; forward kinematics; rehabilitation; self-avatar","Animation; Biomechanics; Computer graphics; Kinematics; Virtual reality; Bone segments; Forward kinematics; High-fidelity; Low latency; Motor rehabilitation; Real-time animations; self-avatar; Set-up time; Patient rehabilitation",2-s2.0-84979771439
"Fnaiech N., Jendoubi A., Zoghlami M., Bacha F.","Continuation power flow of voltage stability limits and a three dimensional visualization approach",2016,"16th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering, STA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979658569&doi=10.1109%2fSTA.2015.7505122&partnerID=40&md5=af31393fc8ea03713c8053ce8d98ca78","This paper describes the continuation power flow method used in studies of voltage stability limits. In this work we were improve that the point of voltage limit will changes with loading parameter. However, we used this method in order to analyses voltage collapse. It is based on a predictor-corrector algorithm. We applied this method to an example of nine bus system known as WSCC 9 bus-system. A comparative analysis of the results of simulations with tow packages (Matlab and Power System Analysis Toolbox) is duly drawn. In the other hand, in this paper we discuss the efficacy of the Three-dimensional visualization approach in studies of voltage stability limits. © 2015 IEEE.","Continuation method; Continuation power flow; PSAT (Power System Analysis Toolbox); Three-dimensional visualization and animation","Automation; MATLAB; Process control; Systems analysis; Three dimensional computer graphics; Visualization; Voltage measurement; Voltage stabilizing circuits; Comparative analysis; Continuation method; Continuation power flow; Continuation power flow method; Power system analysis; Predictor-corrector algorithm; Three dimensional visualization; Voltage stability limits; Electric load flow",2-s2.0-84979658569
"Argelaguet F., Hoyet L., Trico M., Lécuyer A.","The role of interaction in virtual embodiment: Effects of the virtual hand representation",2016,"Proceedings - IEEE Virtual Reality",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979784150&doi=10.1109%2fVR.2016.7504682&partnerID=40&md5=f909eff61611c236f201e6a199ffec3e","How do people appropriate their virtual hand representation when interacting in virtual environments? In order to answer this question, we conducted an experiment studying the sense of embodiment when interacting with three different virtual hand representations, each one providing a different degree of visual realism but keeping the same control mechanism. The main experimental task was a Pick-and-Place task in which participants had to grasp a virtual cube and place it to an indicated position while avoiding an obstacle (brick, barbed wire or fire). An additional task was considered in which participants had to perform a potentially dangerous operation towards their virtual hand: place their virtual hand close to a virtual spinning saw. Both qualitative measures and questionnaire data were gathered in order to assess the sense of agency and ownership towards each virtual hand. Results show that the sense of agency is stronger for less realistic virtual hands which also provide less mismatch between the participant's actions and the animation of the virtual hand. In contrast, the sense of ownership is increased for the human virtual hand which provides a direct mapping between the degrees of freedom of the real and virtual hand. © 2016 IEEE.","H.5.2 [Information Interfaces and Presentation]: User Interfaces - Evaluation/Methodology; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual Reality","Computer graphics; Degrees of freedom (mechanics); Textile industry; Three dimensional computer graphics; User interfaces; Control mechanism; Direct mapping; H.5.2 [information interfaces and presentation]: user interfaces evaluation/methodology; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Pick and place; Questionnaire data; Sense of agencies; Visual realism; Virtual reality",2-s2.0-84979784150
"Petresin V.","Extending methods of composition and performance for live media art through markerless voice and movement interfaces: An artist perspective",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979742032&doi=10.1145%2f2948910.2948920&partnerID=40&md5=21d7110074a37766bfcbd73ee1e812f1","Transmediation of movement, body data and sound to mor-phogenetic processes links the trigger and response offscreen, and moves away from wearable tracking devices to gesture and AI. Workflow for composing and designing with movement and voice for media opera may be developed within a single workspace implementing principles of cross modal perception and particle simulations in animation softwares, as has been demonstrated using case studies of experimental practice using 3D film, light, voice, soundscapes and movement to compose and modulate the artistic experience in real time.","Digital design; Embodiment; Media opera; Modulated reality; Movement; Movement description; Vocal performance","Computer applications; Computer programming; Digital designs; Embodiment; Media opera; Modulated reality; Movement; Movement description; Vocal performance; Acoustics",2-s2.0-84979742032
"Bevilacqua F., Caramiaux B., Françoise J.","Perspectives on real-time computation of movement coarticulation",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979743481&doi=10.1145%2f2948910.2948956&partnerID=40&md5=9d4de63e88b12d5e1189249e1b2f9107","We discuss the notion of movement coarticulation, which has been studied in several fields such as motor control, music performance and animation. In gesture recognition, movement coarticulation is generally viewed as a transition between ""gestures"" that can be problematic. We propose here to account for movement coarticulation as an informative element of skilled practice and propose to explore computational modeling of coarticulation. We show that established probabilistic models need to be extended to accurately take into account movement coarticulation, and we propose research questions towards such a goal.","Coarticulation; Gesture; Motor primitives; Movement; Recognition","Computer applications; Computer programming; Co-articulation; Gesture; Motor primitives; Movement; Recognition; Gesture recognition",2-s2.0-84979743481
"Lai I.K.W., Lu T.-W.","How to improve the university–industry collaboration in Taiwan's animation industry? Academic vs. industrial perspectives",2016,"Technology Analysis and Strategic Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958541302&doi=10.1080%2f09537325.2016.1141404&partnerID=40&md5=e2e0aa02573f371da48b725a8f683321","This study demonstrates the use of importance–performance analysis (IPA) to prioritise the motivators that can facilitate university–industry collaboration in the animation industry in Taiwan. This study confirms that financial supports and education are still major reasons for academia to participate in the university–industry collaboration. Reducing costs and obtaining human training are the reasons for animation firms to join the university–industry collaboration. However, by comparing the results of IPA for academia and industry, this study recommends four common interest motivators from both academic and industrial perspectives and where efforts should be concentrated. Research facilities, external competencies, talents, and innovation capacity are very important for the animation industry of Taiwan. © 2016 Taylor & Francis.","animation industry; Importance–performance analysis; innovation capacity; motivator; university–industry collaboration","academic performance; computer industry; education policy; financial provision; performance assessment; university sector; Taiwan",2-s2.0-84958541302
"Kim S., Kang D., Yoon K.","Human-friendly stylization of video content using simulated colored paper mosaics",2016,"New Review of Hypermedia and Multimedia",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963537912&doi=10.1080%2f13614568.2016.1152320&partnerID=40&md5=b6736fc01f6a78ec52e8c4fc8ea7803c","Video content is used extensively in many fields. However, in some fields, video manipulation techniques are required to improve the human-friendliness of such content. In this paper, we propose a method that automatically generates animations in the style of colored paper mosaics, to create human-friendly, artistic imagery. To enhance temporal coherence while maintaining the characteristics of colored paper mosaics, we also propose a particle video-based method that determines coherent locations for tiles in animations. The proposed method generates evenly distributed particles, which are used to produce animated tiles via our tile modeling process. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","human-centric content; Non-photorealistic rendering; stylized animation; temporal coherence","Computer graphics; A-particles; Distributed particles; Human-centric; Human-friendly; Non-Photorealistic Rendering; Temporal coherence; Video contents; Video manipulations; Video recording",2-s2.0-84963537912
"de Oliveira M.L., Galembeck E.","Mobile Applications in Cell Biology Present New Approaches for Cell Modelling",2016,"Journal of Biological Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944929608&doi=10.1080%2f00219266.2015.1085428&partnerID=40&md5=2b00cfef50eb978962047b42ec66e377","Cell biology apps were surveyed in order to identify whether there are new approaches for modelling cells allowed by the new technologies implemented in tablets and smartphones. A total of 97 apps were identified in 3 stores surveyed (Apple, Google Play and Amazon), they are presented as: education 48.4%, games 26.8% and medicine 15.4%. The apps were arranged by representation similarities of the cell models, and then the groups were nominated. The name of each one was based in recurrent terms on the apps descriptions and the definition is grounded in the literature. Thus, we categorized those apps in six modelling groups, not mutually exclusive: 32% three-dimensional, 25% bi-dimensional, 14% realistic, 14% animation, 11% scale and 4% playful. Each model has unique characteristics. Three-dimensional models can present proportional scales of organelles that allow immersion in the cell model. Realistic models and animations can be used to explore the dynamics of the cell functioning. The cell models designed for smartphones and tablets bring handling capabilities not found in computers and notebooks; they also have the potential to deliver content with high levels of interactivity and are accessible anytime and anywhere. Regarding the applicability of the cell models available in the apps, this paper offers some suggestions of classroom use based on the features of the models and examples found in the literature. © 2015 Society of Biology.","Cell biology; Cell modelling; Mobile applications; Mobile learning",,2-s2.0-84944929608
"Liang X., Yuan C.","Derivation of 3D cloud animation from geostationary satellite images",2016,"Multimedia Tools and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937605060&doi=10.1007%2fs11042-015-2738-7&partnerID=40&md5=6bc1d3f7677c9fed34758393a902b194","Large-scale cloud animation is crucial to TV weather presentation, weather observer training and video products. In this paper, a physically based system is presented for the derivation of time-varying 3D clouds from geostationary satellite images. Cloud properties are derived from a set of meteorological models while the clouds are rendered by graphics models, the proposed method thus presents a new modeling methodology, which integrates the reality of the data with the realistic visual feeling. In particular, image pixels are first classified into cloud-free, water cloud, ice cloud, thin cirrus cloud in terms of their spectral signature. Then, cloud top surface, cloud bottom surface and cloud extinction are generated by applying different combinations of images. Finally, clouds are rendered under various light directions or view directions. The results have indicated that the proposed method can yield a realistic and approximately valid clouds with similar appearance to those in the input satellite images. © Springer Science+Business Media New York 2015.","3D cloud animation; Geostationary satellite image; Meteorological models; Physically based system; Weather presentation","Animation; Balloons; Clouds; Rendering (computer graphics); Satellites; Bottom surfaces; Cloud properties; Light direction; Meteorological models; Modeling methodology; Physically based; Satellite images; Spectral signature; Geostationary satellites",2-s2.0-84937605060
"Wang P., Pan Z., Li W.","Recent advances in compression of human motion capture data",2016,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977280293&partnerID=40&md5=f33c260d2a83d398ca79ccab5e5a82a0","Data-driven character animation is a hot research topic in computer graphics. It relies on data reusing of pre-captured motion data. Therefore, it is very important to compress the motion capture (mocap) data effectively and in real time for easy storing and transmitting. This paper introduces the latest research results of mocap compression from the view of eliminating data redundancy in temporal, spatial and compound segmental level. First, it gives an overview of the fundamental compression pipeline, and presents a guideline for classifying mocap data compression methods. Then, revisits and discusses the recently developed mocap data compression schemes from the view point of data redundancy reduction. Finally, gives some discussions on possible directions for future works in mocap data compression. © 2016, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Character animation; Data-driven animation; Motion capture data; Motion compression","Animation; Computer graphics; Redundancy; Character animation; Compression methods; Compression scheme; Data-driven animation; Hot research topics; Human motion capture data; Motion capture data; Motion compression; Data compression",2-s2.0-84977280293
"Wagner K.B., Jang I.-G.","The 3-D Animated Codescape: Imperfection and Digital Labor Zones in Wall-E (2008) and Wreck-It Ralph (2012)",2016,"Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977575258&doi=10.1177%2f1746847716638267&partnerID=40&md5=3eeaba1019a28aa76e4ce217146356a4","Live-action film and video games share a presence and convergence in each media's visuality and narrative storytelling; this is especially apparent over the last four decades - from Tron (1982) to Run Lola Run (1998) to The Beach (2000) and now 'machinima' as new computational genre cinema via Minecraft (2014). To complicate matters, only recently are cinema and video games now tropes in 3-D computer animation, with films such as Wall-E (Andrew Stanton, 2008) and Wreck-It Ralph (Rich Moore, 2012) absorbing these cultural relations. In this article, the authors explicate on two interwoven yet separable themes in the Walt Disney/Pixar films. First, they theorize aspects of the 'imperfect aesthetic' as connected to an audience and industry's desire to aesthetically 'deskill' - as explained in John Roberts's article 'Art after deskilling' (2010) - the image of its characters, in the process making the characters more vulnerable and thus more endearing. This imperfect aesthetic is typically associated with avant-garde animation or animated shorts, yet to link imperfection to 3-D computer animation illustrates a new visual tendency since the 2000s. Second, they draw on the scholarship of Maurizio Lazzarato to relate immaterial labor to what each character does in their animated worlds, what they call 'digital labor zones': the Wall-E robot is prone to affective labor while in Wreck-It Ralph, Ralph, the goofy villain, begins to question the reasons for his rampaging behavior and the labor behind such actions. © The Author(s) 2016.","3-D computer animation; codescape; deskilling; digital labor zones; film and video games; imperfect aesthetic; John Roberts; Wall-E; Wreck-It Ralph",,2-s2.0-84977575258
"Gao L., Lai Y.-K., Liang D., Chen S.-Y., Xia S.","Efficient and flexible deformation representation for data-driven surface modeling",2016,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009165723&doi=10.1145%2f2908736&partnerID=40&md5=3aa65f877ef3b1f3ecc3eb119f257676","Effectively characterizing the behavior of deformable objects has wide applicability but remains challenging. We present a new rotation-invariant deformation representation and a novel reconstruction algorithm to accurately reconstruct the positions and local rotations simultaneously. Meshes can be very efficiently reconstructed from our representation by matrix predecomposition, while, at the same time, hard or soft constraints can be flexibly specified with only positions of handles needed. Our approach is thus particularly suitable for constrained deformations guided by examples, providing significant benefits over state-of-The-Art methods. Based on this, we further propose novel data-driven approaches to mesh deformation and non-rigid registration of deformable objects. Both problems are formulated consistently as finding an optimized model in the shape space that satisfies boundary constraints, either specified by the user, or according to the scan. By effectively exploiting the knowledge in the shape space, our method produces realistic deformation results in real-Time and produces high quality registrations from a template model to a single noisy scan captured using a low-quality depth camera, outperforming state-of-The-Art methods. Categories and Subject Descriptors: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation; I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling-Surface representation.",,"Computational geometry; Computer graphics; Mesh generation; Three dimensional computer graphics; Computational Geometry and Object Modeling; Constrained deformations; Flexible deformation; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Nonrigid registration; Realistic deformations; Reconstruction algorithms; State-of-the-art methods; Deformation",2-s2.0-85009165723
"Jain E., Sheikh Y., Hodgins J.","Predicting Moves-on-Stills for Comic Art Using Viewer Gaze Data",2016,"IEEE Computer Graphics and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982085170&doi=10.1109%2fMCG.2016.74&partnerID=40&md5=4e158683813cfd0e20011a667d3a4b8d","Comic art consists of a sequence of panels of different shapes and sizes that visually communicate the narrative to the reader. The move-on-stills technique allows such still images to be retargeted for digital displays via camera moves. Today, moves-on-stills can be created by software applications given user-provided parameters for each desired camera move. The proposed algorithm uses viewer gaze as input to computationally predict camera move parameters. The authors demonstrate their algorithm on various comic book panels and evaluate its performance by comparing their results with a professional DVD. © 2016 IEEE.","animation; comic art; computer graphics; eye tracking; image generation; motion pictures; moves-on-stills; picture generation; visual attention","Animation; Application programs; Behavioral research; Cameras; Computer graphics; comic art; Eye-tracking; Image generations; moves-on-stills; picture generation; Visual Attention; Motion pictures",2-s2.0-84982085170
"Teichert C.","Risk-free transition into the internet of things with process simulation [Prozesssimulation als basis fur die umstellung auf industrie 4.0]",2016,"Elektrowaerme International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013846488&partnerID=40&md5=55b7ad4d5bf522d718f46657657951eb","Compared to the global market the German industry is slightly behind in the transition process to the internet of things. Nevertheless, the question seems not to be if but when and how this will happen. How can industrial facilities be transformed while avoiding risks and investments as much as possible? The answer is process simulation, which combines all exciting features of modern computer technology - incredible calculation power and beautiful animation. You can validate your line or factory concept with its total dynamic behavior or compare various scenarios under the same conditions -Take the risk out of change!.",,"International trade; Risk perception; Computer technology; Dynamic behaviors; Global market; Industrial facilities; IS process; Process simulations; Risk free; Transition process; Internet of things",2-s2.0-85013846488
"Kim D.J.","Facial expression recognition using ASM-based post-processing technique",2016,"Pattern Recognition and Image Analysis",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984910910&doi=10.1134%2fS105466181603010X&partnerID=40&md5=284c7ec2d7d9ea5b08daa5cfea49ea14","Facial expression recognition is a challenging field in numerous researches, and impacts important applications in many areas such as human-computer interaction and data-driven animation, etc. Therefore, this paper proposes a facial expression recognition system using active shape model (ASM) landmark information and appearance-based classification algorithm, i.e., embedded hidden Markov model (EHMM). First, we use ASM landmark information for facial image normalization and weight factors of probability resulted from EHMM. The weight factor is calculated through investigating Kullback-Leibler (KL) divergence of best feature with high discrimination power. Next, we introduce the appearance-based recognition algorithm for classification of emotion states. Here, appearance-based recognition means the EHMM algorithm using two-dimensional discrete cosine transform (2D-DCT) feature vector. The performance evaluation of proposed method was performed with the CK facial expression database and the JAFFE database. As a result, the method using ASM information showed performance improvements of 6.5 and 2.5% compared to previous method using ASM-based face alignment for CK database and JAFFE database, respectively. © 2016, Pleiades Publishing, Ltd.","facial expression recognition","Classification (of information); Database systems; Discrete cosine transforms; Hidden Markov models; Human computer interaction; Information use; Markov processes; Appearance-based recognition; Classification algorithm; Classification of emotions; Embedded hidden Markov models; Facial expression recognition; Kullback-Leibler divergence; Post-processing techniques; Two-dimensional Discrete Cosine Transform (2D-DCT); Face recognition",2-s2.0-84984910910
"Thoret E., Aramaki M., Gondre C., Ystad S., Kronland-Martinet R.","Eluding the physical constraints in a nonlinear interaction sound synthesis model for gesture guidance",2016,"Applied Sciences (Switzerland)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981489480&doi=10.3390%2fapp6070192&partnerID=40&md5=fa26120918bba6ed27c60c7b2a104e03","In this paper, a flexible control strategy for a synthesis model dedicated to nonlinear friction phenomena is proposed. This model enables to synthesize different types of sound sources, such as creaky doors, singing glasses, squeaking wet plates or bowed strings. Based on the perceptual stance that a sound is perceived as the result of an action on an object we propose a genuine source/filter synthesis approach that enables to elude physical constraints induced by the coupling between the interacting objects. This approach makes it possible to independently control and freely combine the action and the object. Different implementations and applications related to computer animation, gesture learning for rehabilitation and expert gestures are presented at the end of this paper. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","Friction sounds; Gesture guidance; Intuitive control",,2-s2.0-84981489480
"Naka T., Ishida T.","Dynamic motion analysis of gesture interaction",2016,"Handbook of Research on Human-Computer Interfaces, Developments, and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014199146&doi=10.4018%2f978-1-5225-0435-1.ch002&partnerID=40&md5=5ad2564e02cd50308360abbfccfbcec6","In human communication, nonverbal information such as gestures and facial expressions often plays a greater role than language, and an increasing number of devices are designed to be intuitively controlled by gestures. However, there are some disadvantages of this intuitive interaction. One of the chief problems is that these devices have difficulty in distinguishing between unconscious and intentional gestures; they tend to respond erroneously to unconscious movements. In this chapter, authors propose a new gesture analysis method based on the dynamic model. They focused on the ""exaggerated gestures"" that are effectively used in, such as Japanese Kabuki, effectively used in Disney's animation, and tried to identify their common features and effects. They noted the ""preparation"" or ""follow-through"" motions just before and after the emphasized actions and each behavior can be quantified by the undershoot and overshoot value of changes in torque. These methods can provide important knowledge for analyzing features and distinguishing intentions when interacting with gestures. © 2016 by IGI Global. All rights reserved.",,"Computer science; Computers; Common features; Dynamic motion analysis; Facial Expressions; Gesture analysis; Gesture interaction; Human communications; Intuitive interaction; Non-verbal information; Motion analysis",2-s2.0-85014199146
"Vasilakis A.A., Fudos I., Antonopoulos G.","PPS: Pose-to-pose skinning of animated meshes",2016,"ACM International Conference Proceeding Series",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978878204&doi=10.1145%2f2949035.2949049&partnerID=40&md5=1fe2ccf8812c89e5eb84598df2f42415","In computer graphics, animation comprebion is ebential for efficient storage, streaming and reproduction of animated meshes. Previous work has presented efficient techniques for comprebion using skinning transformations to derive the animated mesh from a reference pose. We present a poseto-pose approach to skinning animated meshes by observing that only small deformation variations will normally occur between consecutive poses. The transformations are applied so that a new pose is derived by deforming the geometry of the previous pose, thus maintaining temporal coherence in the parameter space, reducing approximation error and facilitating forward propagated editing of arbitrary poses. © 2016 ACM.","Comprebion; Editing; Skinning; Temporal Coherency","Deformation; Approximation errors; Comprebion; Editing; Parameter spaces; Skinning; Small deformations; Temporal coherence; Temporal coherency; Computer graphics",2-s2.0-84978878204
"Pócsová J., Mojžišová A., Takáč M.","Application of the visualization techniques in engineering education",2016,"Proceedings of the 2016 17th International Carpathian Control Conference, ICCC 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979529978&doi=10.1109%2fCarpathianCC.2016.7501166&partnerID=40&md5=db5486b69e1b195815856b17d23747c8","In this paper, we will describe a possible way of learning mathematics at the Technical University of Kosice. The basic idea of our proposal is an implementation of the interactive presentations, 3D visualizations and animations in the functions of several variables. This proposal is realized using Javascript and WebGL and consists of some solved exercises which represent a learning unit. Innovative solutions, which are presented in this paper, contain: links to video tutorials, visualization, help text and animation. This solution offers an innovative look at one of possible way of education. © 2016 IEEE.","3D animations; Education; Javascript; visualizations; WebGL","Education; High level languages; Visualization; 3D animation; Functions of several variables; Innovative solutions; Interactive presentation; Javascript; Technical universities; Visualization technique; WebGL; Three dimensional computer graphics",2-s2.0-84979529978
"Sawant S.","Essential E learning tools, techniques and open courseware for E learners and trainers",2016,"Human Development and Interaction in the Age of Ubiquitous Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014046765&doi=10.4018%2f978-1-5225-0556-3.ch007&partnerID=40&md5=fdfcefd186a437d66b477922554ceb56","E-learning includes several types of media that deliver text, audio, images, animation, and streaming video, and includes technology applications and processes such as audio or video tape, satellite TV, CD-ROM, and computer-based learning, as well as local intranet/extranet and web-based learning. E learning is a learner-friendly mode of learning, offering alternative, self-paced and personalised ways of studying. The present chapter explains the synchronous and asynchronous mode of e learning with its features. It also defines and summarises the impact of open source software on teaching and learning process. The numerous open source e learning tools are discussed with examples such as Open source LMS, Open source authoring tools, Open source audio editing software, Open source social bookmarking tools, Open source CMS etc. It also throws light on free e learning tools useful in e learning such as Slideshare, Youtube, Wikis, RSS, Wordpress etc. The search engines especially for academic purpose and for Open CourseWear are also discussed in the chapter. It identifies open courseware around the world spanning various subjects. The chapter concludes with e learning initiatives in India. © 2016 by IGI Global. All rights reserved.",,"Computer aided instruction; E-learning; Learning systems; Media streaming; Open source software; Open systems; Search engines; Software engineering; Teaching; Websites; Computer-based learning; Open Courseware; Social bookmarking; Streaming videos; Synchronous and asynchronous modes; Teaching and learning; Technology application; Web based learning; Education",2-s2.0-85014046765
"Liu X., Raj R.K., Liu C., Pantaleev A.","Incorporating service-oriented programming into the computer science curriculum",2016,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983273862&partnerID=40&md5=672d9b75a479b0072bbcfc647b89194f","In modern computing and engineering programs, new course materials need to be added regularly in a flexible manner. The concept of course modules has been suggested as one approach to doing this; a course module, which is a self-contained unit of curriculum such as a lab or teaching component, can be included into existing courses without requiring substantial course or program modifications. In this paper, the authors describe their experiences in incorporating new curricula into computer science and engineering curricula at their three institutions, including Rochester Institute of Technology, Howard University, and SUNY at Oswego. The relatively new paradigm of Service-Oriented Programming (SOP) was introduced into their programs using course modules. SOP is a relatively new programming paradigm in which software applications are wrapped as web services, which can be used as building blocks for developing new software applications. Leveraging ubiquitous Internet access and intensive standardization efforts, SOP boosts software and resource reuse. Driven by the benefits of SOP, the number and variety of web services are currently offered online. ProgrammableWeb, one of the largest public API registry, lists over 14,000 web services in various categories, such as weather, social, travel, education, music, and animation. It also lists over 6,000 software applications developed by using public web services, i.e., service mashups. Although such web services represent an attractive opportunity for incorporation in undergraduate CS and SE curricula, few if any of today's freshman and sophomore students in these majors know anything about the concepts underlying web services. When available, courses covering aspects of web services are primarily offered to undergraduate seniors or graduate students. To include SOP in undergraduate CS and SE curricula, this paper describes the design and development of these SOP course modules, their implementation in their three institutions over the past three years, assessment and evaluation of the implementation, and some lessons about the incorporation of new coursework into computing and engineering curricula. © American Society for Engineering Education, 2016.",,,2-s2.0-84983273862
"Wang S.-L.","Free body diagrams with animated GIF files",2016,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983315878&partnerID=40&md5=75b1f34c24abbb1032763d5d9a226a3c","A free body diagram (FBD) is a graphic representation in which all connecting bodies have been removed, or the body is ""freed"" from connecting bodies, to shows all forces acting on the body. Drawing a FBD is important in force analysis as it facilitates writing equations of equilibrium of a mechanical system to determine unknown forces and moments. Drawing a FBD correctly is thus an important skill for an engineering student. Many students have troubles drawing FBDs as there are insufficient examples in the textbooks, especially in the junior and senior level design courses. Over the years, the author has created many FBDs to assist students' learning. In this paper, the author presents several examples using animated GIF files to guide students to develop FBDs step by step, and these animated GIF files can be easily incorporated in a PowerPoint presentation. Because animation will only work on a computer, screen shots of these animation files are shown in this paper, and the process of creating them is explained. © American Society for Engineering Education, 2016.","Animated GIF; Free body diagram (FBD); Machine design; Statics",,2-s2.0-84983315878
"Martino N., Ghanem A.","Innovative approach to teaching applied structures courses",2016,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983261257&partnerID=40&md5=78e8587cab167fd78b84e8a2b6540f44","Developing new ways for teaching structures courses to engineering students, in addition to those in an alternate major (construction management, architecture, etc.) is a staple in the curriculum. One of the most common techniques used by instructors to demonstrate various concepts is by using props. While those can be effective, instructors are looking for a more digital approach that students can learn and replicate on their own. Current cohorts of students are incredibly tech savvy, and have the ability to quickly understand how to use computer programs, and the like. The advantages of knowing computer-aided applications include; increasing students' credentials while adding skills needed to attract future employers, and that students can call upon these tools in their future (after college) for help with finding the solution to a difficult problem. Firstly, this paper presents the methodology used to develop interactive images, using SolidWorks and Microsoft PowerPoint to help students better visualize and understand concepts associated with structures courses. Next, the paper discusses the effectiveness of these tools by providing the results of two student surveys. The first survey asked a cohort of students currently enrolled in a structural analysis course to rate their understanding of a list of topics associated with structural analysis and previous engineering mechanics courses. That cohort of students was then presented with a limited subset of digital animations developed using SolidWorks and Microsoft PowerPoint and was asked to complete the same survey again. One month of time existed between the two surveys. The difference in the two surveys showed an increased level of understanding in every assessed category, based on the students' perception and attitude towards the interactive images. A direct assessment of exam grades also displayed the effectiveness of these tools. © American Society for Engineering Education, 2016.",,,2-s2.0-84983261257
"Karunaratne M.","Impact of piggybacked MATLAB in C-programming course",2016,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983238524&partnerID=40&md5=8053a43ec2f252e3525c84c83122f071","Today, an increasing number of scientists and engineers are spending more and more of their work hours in front of the computer. Electronic and semiconductor industry are making capable and inexpensive portable consumer devices as evident from smart phones and tablets that are coming out to the market at an accelerated phase. Manufactures have made attempts to launch hobby industries around inexpensive electronics, particularly processor boards, with more capabilities and easy to program systems such as Raspberry Pi. For individual developer or capable consumer those devices offer customization to a level that was never seen before. However, such customizations require development of computer programs to control the devices and data streams. When electrical and computer engineers are trained, it is becoming more imperative that nearly all acquire some level of computer programming skills to effectively function as engineers in their careers. The nature of work performed in industry changes as they progress in careers. Lack of programming ability and experience may challenge their opportunities for technical and even managerial advancements. For example, a senior engineer without programming experience would not become a project manager if that project requires a significant amount of software to be developed in house. At this university, electrical engineering technology (EET) and computer engineering technology (CET) majors always take one semester course on computer programming so they can be effective in using embedded controllers and other programmable devices, later in their curricula or in industry after graduation. It is a C based programming course with few projects appropriate for second year engineering technology students. CET majors further study Java, Ada, and C flavored languages in their curricula. EET majors do not have opportunity to learn other languages although some of them would program - using proprietary languages-Programmable Logic Controllers (PLCs) after graduation in industrial settings. Several of follow on courses taken by both majors require them to use MATLAB as a problem solving tool in advanced circuit theory and control systems theory courses. Several years ago at this university, students had been learning basic MATLAB on their own, and then learned advance features such as control and signal processing toolboxes with help from instructors in follow-on courses. Instructors in the upper level classes could only make limited efforts to help students learn MATLAB. Their efforts are geared toward actual subject contents which are heavy in abstract concepts and mathematics. The author introduced MATLAB in C programming course in the fall of 2012 with the intent of reducing the future burden of learning its basics on their own. That experience has already been published3 by the author. This paper discusses the continuing experience in having MATLAB as an additional programming tool to sophomore level students who are learning programming in C language as their main objective. They still learn advanced concepts and toolboxes in higher level courses. An additional benefit expected and clearly seen over the years is that MATLAB reinforces concepts taught in C such as loops, indexing, conditionals, input/outputs, storage and file management, data and program structures, etc. Also, learning it at this stage to create animation programs provides incentives and variety to further practice algorithm development and problem solving skills. Practice of such skills is essential to become competent programmers. In addition to the findings already discussed in the previous paper, this paper presents survey results from students in several follow-on courses after they have taken this basic C course with piggybacked MATLAB content. The conclusion provides feedback from students as they progress through follow on courses clarifying the cost-benefit of the enhancements done to the basic C programming course a few years back. © American Society for Engineering Education, 2016.",,,2-s2.0-84983238524
"Chakraborty P., Hossain A., Pillarisetty V.","Designing and assembling of a programmable logiccontrols (PLC) laboratory trainer and advanced research setup",2016,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983340437&partnerID=40&md5=5252263e12a724a1b916ca7f6554b74d","A Programmable Logic Controller (PLC) is an industrialized computer control system that constantly monitors the state of input devices and makes decisions based upon a custom program to control the state of output devices. Almost any production line, machine function, or process can be greatly enhanced using this type of control system. However, the biggest benefit in using a PLC is the ability to change and replicate the operation or process while collecting and communicating vital information. It is also a modular system. It can be mixed and matched the types of Input and Output devices to best suit of any laboratory application and industrial control application. Training setup consists of an industrial grade PLC, Variable Frequency Drives, Servomotors coupled with drives, induction motors, Human Machine Interface (HMI), industrial networking capabilities, and many other ancillaries. The setup can be used for demonstrating the principles of programmable controllers and sequence control systems, advanced cam profile and advanced computation for controlling industrial processes. It is suitable for training both basic and advanced principles of PLC. Industrial grade PLC components are permanently mounted on the panel; it is also coupled, activated and controlled with numerous configurations such as with Variable Frequency Drive (VFD), servo drive, servo Motor, and induction motor, along with Human Machine Interface (HMI). This Laboratory Trainer and research setup system is fully integrated with PLC Motion Animation software that will help students observe and understand the control logic behind the operation of industrial PLCs. The software tool can be used as an offline and online animation tool with its collection of sample HMI applications. The trainer can be used alternately for operation and control of industrial manufacturing processes. The example ladder logic program in the trainer describes the methods of running servomotor and servo drive that are widely used in almost every industry where automation is required. Smart vision checking system which is used for sorting and many other purposes can also be interfaced with the setup. This setup has at least two VFD to control various functions of induction motor. Such as conveyor speed, acceleration, and many other motion related aspects of an induction motor. The combination of software and hardware offers practical and effective trainer and research engine for industrial control and manufacturing. Also help students to know about smart vision checking system, servo drive, servomotor, induction motor, Variable Frequency Drive (VFD), HMI, industrial networking, and interfacing with real world packaging machines. In addition, one of the main advantages of this trainer setup panel is its modular capability. This trainer setup can be modified, coupled with any industry related control system that might need in the future for training purpose. Above all, this laboratory training and control panel setup is performed in two stages. First, the machine design and electrical control for the entire operational process is conducted and then the study of effectiveness of re-configurable and portable Programmable logic controller system with proper statistical analysis. © American Society for Engineering Education, 2016.",,,2-s2.0-84983340437
"McDermott T.E., Clark R.M.","Improving a flipped electromechanical energy conversion course",2016,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983353607&partnerID=40&md5=5b5bbc2eda9d350d9321bb5798ff8159","Our University's Electrical and Computer Engineering Department has offered an elective course in Electric Machinery for decades. With increasing focus on renewable energy and power electronics in the curriculum, we felt the need to modernize this course so that it provides a better learning experience and appeals to more students. Over a period of two terms, we updated the hardware lab equipment, designed new hardware lab experiments, added new computer modeling experiments, and added power electronics content. This produced excellent student evaluations and good learning outcomes in fall 2013. In fall 2014 we ""flipped"" the course, with mixed results. Instructor-student interaction did increase, but there was no significant improvement in exam or lab outcomes, and the student evaluations decreased significantly from the non-flipped version in fall 2013. Some students preferred the flipped format, but they were outnumbered by those who did not. We seemed to fix something that wasn't broken. This paper will focus on continuing course format changes to improve both outcomes and student evaluations. Only the successful flipped classroom elements were retained for fall 2015. In the spring 2015 term, 134 video screencast example problems were added to the instructor's teaching of Linear Circuits & Systems 2. The addition of optional video content yielded significant improvements in both outcomes and evaluations, compared to the instructor's previous teaching of Linear Circuits & Systems 1. This suggested use of video content to supplement, but not replace, in-person teaching of new material, as in a blended classroom. Therefore, in the fall 2015 term, Electric Machinery was offered with supplemental video content. The course schedule also changed. The class now meets for two 75-minute lecture periods and one two-hour lab period per week, versus the one-evening-per-week class session in the past. The instructor also incorporated two items from the ASEE National Effective Teaching Institute (NETI-1) summer 2015 offering. The first new element is detailed learning objectives, which are presented as study guides, amounting to six full pages of objectives for the course. The second new element is a ""scaffolded"" handout for each class, encouraging students to actively complete content and take notes. In addition, the instructor has added animations using the ANSYS Maxwell software that serve as demonstrations for students during the software labs. Students also complete short online quizzes before class to promote preparation. Thus, our fall 2015 class has assumed a blended classroom format, in which face-to-face and technology-enhanced instruction are used together. We evaluated this classroom for the degree of active learning, problem solving, student collaboration, and instructor-to-student interaction using a structured behavioral observation protocol known as the Teaching Dimensions Observation Protocol (TDOP). We compare our observational results between fall 2014 and fall 2015 to formally assess differences in classroom practices. Impacts on student final exam performance and student evaluations are also discussed. © American Society for Engineering Education, 2016.",,,2-s2.0-84983353607
"Kirshenbaum N., Robertson S.","Set&Motion: Tool for authoring interactive stories with sensors and actuators",2016,"Proceedings of IDC 2016 - The 15th International Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985930328&doi=10.1145%2f2930674.2935988&partnerID=40&md5=173a28ad383dc2a4a82f0db293292d4c","Children participating in animatronic puppet show workshops are tasked with hands-on activities that exercise both creative and technical skills culminating in a unique learning experience. In this paper, we describe Set&Motion, an authoring tool that supports the creation of animatronic puppet shows. It supports capturing sound and describing the puppet's animation for any animatronic show.In addition, users can create more complex story flows and allow viewers to interact with the show using sensors embedded in the puppet or its surroundings. It promotes the use of a state diagram to describe non-linear storylines, and may be useful for Computer Science education.","Animatronic workshop; Authoring tool; Interactive storytelling by children; State diagrams","Education computing; Animatronic workshop; Authoring tool; Computer Science Education; Interactive stories; Interactive storytelling; Learning experiences; Sensors and actuators; State diagram; Education",2-s2.0-84985930328
"Pence I., Siseci Cesmeli M., Cetisli B.","Using the implicit polynomial curves and 3L method for simple animation of the two dimensional shapes [Iki Boyutlu Sekillerde Kapali Cebirsel Egriler ve 3L Yöntemi ile Basit Animasyon]",2016,"2016 24th Signal Processing and Communication Application Conference, SIU 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982816247&doi=10.1109%2fSIU.2016.7496170&partnerID=40&md5=87a05f849ba233fefd271567fc50bdda","Today, for two or three dimensional modelling of objects, common algorithms such as spline curves and triangulation methods are being used. However, while these methods are able to well express the objects visually, since they approach the objects as a composition of a large number of small pieces, they are not able to cognisably put forth the mathematical expression of the object as a whole. The most notable method in the literature, in order to express the objects with a single equation is implicit algebraic curves, and 3L method as a way to realize the more sensitive effects of these curves. In this study, coefficients of 2 dimensional images which are modelled using 3L method are changed in order to carry out a small animation in this process. Experimental study results show that the variation of the coefficients, change the final results of the model and demonstrated the feasibility of this process for animation. © 2016 IEEE.","3L method; animation; implicit polynomial curves; modelling","Algorithms; Animation; Models; Polynomial approximation; Signal processing; Three dimensional computer graphics; 2 - Dimensional; Algebraic curves; Implicit polynomial curves; L method; Mathematical expressions; Single equation; Three dimensional modelling; Triangulation method; Algebra",2-s2.0-84982816247
"Ekmen B., Ekenel H.K.","Real time animated facial expression transfer [Gerçek Zamanli Animasyonlastirilmis Yüz Ifadesi Aktarimi]",2016,"2016 24th Signal Processing and Communication Application Conference, SIU 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982821802&doi=10.1109%2fSIU.2016.7495959&partnerID=40&md5=addc18f7a2181160aac60a82ea2b2621","Realistic animation of an expressive human face has been a great challenge in computer graphics due to the human perception of human faces. It is a complex, costly and time-consuming process requiring a great detail in many aspects. In this paper, a three-stage method is presented that simplifies the creation of realistic facial animations by transferring the expressions from 2D videos onto 3D models with a joint-based system on a real-time basis. The first stage covers the preparation of the model with a joint-based rig for the transfer. The second includes the real time tracking of a human face with a single camera to obtain 2D positions of facial landmarks. Also it covers the transfer of 3D relative movement data to animate the prepared model by moving the respective joints. The last stage covers the recording of animation using a partially automated key-framing technique. The presented method provides a fast, easy to use and affordable system that produces visually satisfying facial animations. © 2016 IEEE.","expression transfer; facial animation; facial tracking; performance-driven animation","Animation; Computer graphics; Face recognition; Expression transfers; Facial animation; Facial Expressions; Facial tracking; Performance-driven; Real time tracking; Relative movement; Three-stage method; Signal processing",2-s2.0-84982821802
"Keçeci S., Erzin E., Yemez Y.","Analysis of JestKOD database using affective state annotations [JestKOD Veritabaninin Duygu Durum Etiketlemelerini Kullanarak Analizi]",2016,"2016 24th Signal Processing and Communication Application Conference, SIU 2016 - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982787194&doi=10.1109%2fSIU.2016.7495919&partnerID=40&md5=e3a18e1ace0eb217e30cf65a31af5f2b","Gesticulation, together with the speech, is an important part of natural and affective human-human interaction. Analysis of gesticulation and speech is expected to help designing more natural human-computer interaction (HCI) systems. We build the JestKOD database, which consists of speech and motion capture recordings of dyadic interactions. In this paper we describe our annotation efforts and present the evaluations that we performed on the annotations of the JestKOD database. These evaluations suggest important findings for usability of the JestKOD database in analysis and modeling of HCI systems. © 2016 IEEE.","affective state tracking; animation; computer-human interaction; Gesticulation; machine learning; speech","Animation; Artificial intelligence; Database systems; Learning systems; Signal processing; Speech; Affective state; Analysis and modeling; Computer Human Interaction; Dyadic interaction; Gesticulation; Human-human interactions; Motion capture; Natural human computer interactions; Human computer interaction",2-s2.0-84982787194
"Speicher M., Gröber L., Haluska J., Hegemann L., Hoffmann I., Gehring S., Krüger A.","The audience in the role of the conductor: An interactive concert experience",2016,"PerDis 2016 - Proceedings of the 5th ACM International Symposium on Pervasive Displays",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979747789&doi=10.1145%2f2914920.2940335&partnerID=40&md5=b6e90757db7b1005b9c8af8950215d16","The work we present is an interdisciplinary collaboration between the Saarland University Orchestra and students of media computer science. The main goal was to create an opportunity for the audience of a live event to engage and have an active influence on the course and mood of the event itself. Our concept was tested and implemented as part of the end of semester concert where an animation - projected on large public display - was musically supported by a live orchestra. The audience of that concert was able to influence the order as well as the mood of the musical pieces by the use of a web application on their mobile phone, and could so take actively part of show.","Interactive concert; Mobile interaction; Public display","Display devices; Human computer interaction; Interactive concert; Interdisciplinary collaborations; Mobile interaction; Musical pieces; Public display; WEB application; E-learning",2-s2.0-84979747789
"Coenen J., Wouters N., Vande Moere A.","Synchronized wayfinding on multiple consecutively situated public displays",2016,"PerDis 2016 - Proceedings of the 5th ACM International Symposium on Pervasive Displays",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979774262&doi=10.1145%2f2914920.2929906&partnerID=40&md5=632f786dfb41e2df7d9d17272dfc1e0e","Our built environment is becoming increasingly equipped with public displays, many of which are networked and share the same physical location. In spite of their ubiquitous presence and inherent dynamic functionalities, the presence of multiple public displays is often not exploited, such as to solve dynamic wayfinding challenges in crowded or complex spaces. Hence, we have studied how signage can be animated onto multiple consecutively located public displays in combination with other content. This paper reports on an in-the-wild evaluation study in a real-world, metropolitan train station in order to identify the most promising design strategies to: 1) provide the notion of spatial directionality by way of animation; 2) support concurrent viewing of wayfinding with other content types, and 3) convey a sense of urgency. Our results indicate that spatially distributed animated patterns may be used to convey directions under specific spatial conditions and content combination strategies, yet their impact is limited and highly dependent on the visibility of the animated patterns on individual screens and across multiple displays. © 2016 ACM.","Advertising; Evaluation study; In-the-wild field study; Navigation; Networked public display; Public display; Public space; Railway station; Wayfinding","Human computer interaction; Marketing; Navigation; Evaluation study; Field studies; Public display; Public space; Railway stations; Way-finding; Display devices",2-s2.0-84979774262
"Stavroulia K.-E., Ruiz-Harisiou A., Manouchou E., Georgiou K., Sella F., Lanitis A.","A 3D virtual environment for training teachers to identify bullying",2016,"Proceedings of the 18th Mediterranean Electrotechnical Conference: Intelligent and Efficient Technologies and Services for the Citizen, MELECON 2016",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979294107&doi=10.1109%2fMELCON.2016.7495417&partnerID=40&md5=eacdd2a766348e79674e96d332efc690","Incidents involving bullying in schools present a difficult challenge for educators who need to identify potentially dangerous behaviors in comparison to 'innocent' types of interstudent interactions. In this paper we investigate the use of a dedicated Virtual Reality application as a means of training educators to identify alarming bullying activities. The Virtual Reality environment simulates a typical middle school, where different bullying-related incidents take place. The virtual environment is visualized using a Virtual Reality headset in conjunction with eye tracking techniques that facilitate user interaction. In order to make realistic animations that resemble human motions, state of the art motion tracking equipment was used for generating realistic avatar movements. According to the scenario of the application, the user witness different types of student behavior and he/she has to take decisions on how to control and deal with the situation. The prototype was tested by active teachers who reported that the incidents within the simulation were similar to real life experiences and suggested that the application could be used in teacher training education providing inexperienced teachers feedback on how to recognize and manage bullying. © 2016 IEEE.","bullying; teacher training; virtual learning environments","Computer aided instruction; Education; Personnel training; Teaching; Virtual reality; 3-D virtual environment; bullying; Life experiences; State of the art; Teacher training; Virtual learning environments; Virtual-reality environment; Virtual-reality headsets; E-learning",2-s2.0-84979294107
"Wang H., Li X., Ding M., Han J., Dong L., Yangcheng Z., Yu C.","Research on co-simulation system of omni intelligent mobile equipment",2016,"2015 IEEE 12th International Conference on Electronic Measurement and Instruments, ICEMI 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978285832&doi=10.1109%2fICEMI.2015.7494393&partnerID=40&md5=6320ead7b402d756662d8de1355b49ef","A novel method of co-simulation is proposed to raise the exploration efficiency of driver and control circuit (D&CC) which is the electric part of Omni intelligent mobile equipment (OIME) with four freedoms. A three-dimension model of it is established for kinematic and dynamic simulation by using the dynamic simulation software Adams and consequently, the software interface with inputs and outputs is configured and exported from Adams, which is used to achieve the communication between MATLAB/Simulink software and Adams software. The control model of co-simulation system is set up through a variety of Simulink blocks, which is able to collect and handle the four different signals from D&CC and output to the interface. Consequently, the model of OIME in Adams is controlled by D&CC timely and directly via control model and software interface. Meanwhile, the whole simulation process is cooperatively controlled through Graphical User Interface (GUI) of MATLAB software and wireless remote-controller determining the four outputs of D&CC. The simulation results indicate that the co-simulation system of OIME has preferable and awesome animation effects, and the accuracy of D&CC is also validated simultaneously. © 2015 IEEE.","co-simulation; driver and control circuit; omni intelligent mobile equipment; simulink","Computer control; Computer software; Controllers; Electric control equipment; Electric machine control; Equipment; Graphical user interfaces; Reconfigurable hardware; Remote control; User interfaces; Control circuits; Cosimulation; Graphical user interfaces (GUI); Matlab/Simulink software; Mobile equipments; Simulink; Software interfaces; Three dimension modeling; MATLAB",2-s2.0-84978285832
"Li J., Peters T.J., Jordan K.E., Zaffetti P.","Computational topology: Isotopic convergence to a stick knot",2016,"Topology and its Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963625966&doi=10.1016%2fj.topol.2016.03.032&partnerID=40&md5=628077924e033948641ba35610a30ccb","Computational topology is a vibrant contemporary subfield and this article integrates knot theory and mathematical visualization. Previous work on computer graphics developed a sequence of smooth knots that were shown to converge point wise to a piecewise linear (PL) approximant. This is extended to isotopic convergence, with that discovery aided by computational experiments. Sufficient conditions to attain isotopic equivalence can be determined a priori. These sufficient conditions need not be tight bounds, providing opportunities for further optimizations. The results presented will facilitate further computational experiments on the theory of PL knots (also known as stick knots), where this theory is less mature than for smooth knots. © 2016 Elsevier B.V.","Computer animation; Isotopy; Knot; Molecular simulation",,2-s2.0-84963625966
"Supalo C.A.","ConfChem Conference on Interactive Visualizations for Chemistry Teaching and Learning: Concerns Regarding Accessible Interfaces for Students Who Are Blind or Have Low Vision",2016,"Journal of Chemical Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974815685&doi=10.1021%2facs.jchemed.5b00603&partnerID=40&md5=c5c293063fd0748dd63aacd291e2f7fa","This communication summarizes one of the invited papers to the Interactive Visualizations for Chemistry Teaching and Learning ACS CHED Committee on Computers in Chemical Education online ConfChem held May 8-June 4, 2015. It focuses on concerns of the current societal paradigm as it pertains to virtual simulations and visual animations today, and addresses matters pertaining to the usability of such constructs by students who are blind or visually impaired (BVI). Further, it addresses concerns with the importance of providing equal access to visual information in the teaching of chemistry concepts and comments on the dynamic nature of the teaching profession. © 2016 The American Chemical Society and Division of Chemical Education, Inc.","Computer-Based Learning; Curriculum; First-year Undergraduate/General; High School/Introductory Chemistry; History/Philosophy; Internet/Web-Based Learning; Multimedia-Based Learning; Professional Development; Student-Centered Learning",,2-s2.0-84974815685
"Kelly R.M., Akaygun S.","Insights into How Students Learn the Difference between a Weak Acid and a Strong Acid from Cartoon Tutorials Employing Visualizations",2016,"Journal of Chemical Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974832047&doi=10.1021%2facs.jchemed.6b00034&partnerID=40&md5=7408e2d53b045252ea269b5340397997","This article summarizes an investigation into how Flash-based cartoon video tutorials featuring molecular visualizations affect students' mental models of acetic acid and hydrochloric acid solutions and how the acids respond when tested for electrical conductance. Variation theory served as the theoretical framework for examining how students compared and contrasted their understanding of weak and strong acids to the tutorials. Specifically, students' ability to recognize variation between their mental models and the events portrayed in the videos was examined through picture construction exercises and semistructured interview questions focused on metacognitive monitoring. Interestingly, the items noticed as being in variance were items that were emphasized by still image representation in the tutorials prior to showing the visualizations. Mechanistic items, specifically movement of ionic species toward electrodes, were replicated in students' drawings only if they were explicitly conveyed, but students were not inclined to mention them as features in variance with their initial understanding. Overall, scaffolding animations in a cartoon context with explicit connections between experimental evidence and the submicroscopic level resulted in students being proficient at replicating what they explicitly observed both structurally and mechanistically. © 2016 The American Chemical Society and Division of Chemical Education, Inc.","Acids/Bases; Chemical Education Research; Computer-Based Learning; Electrochemistry; First-Year Undergraduate/General; High-School/Introductory Chemistry; Misconceptions/Discrepant Events; Qualitative Analysis; Solutions/Solvents",,2-s2.0-84974832047
"Tasker R.","ConfChem Conference on Interactive Visualizations for Chemistry Teaching and Learning: Research into Practice - Visualizing the Molecular World for a Deep Understanding of Chemistry",2016,"Journal of Chemical Education",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974824075&doi=10.1021%2facs.jchemed.5b00824&partnerID=40&md5=561b7ee348d53c6bde6e5c9cbba56fa7","A deep understanding of chemistry requires internal visualization of structures and processes at the molecular level to rationalize observable chemical and physical properties, and make sense of chemistry symbolism and mathematical relationships. The paper argues that accurate mental models of the molecular world are needed to address the student misconceptions described in the literature, and describes the potential and limitations of the VisChem animations to develop useful mental models. A constructivist learning design has been developed and evaluated as a best-practice strategy for effectively using the VisChem resources for learning. This communication summarizes one of the invited papers to the Interactive Visualizations for Chemistry Teaching and Learning ACS CHED Committee on Computers in Chemical Education online ConfChem held from May 8 to June 4, 2015. The lively discussions that followed addressed the difficulty of showing the crucial role of ion hydration without producing cognitive overload, the need to build a visual literacy through repeated and progressive use of molecular animations, and the complementary nature of animations and simulations to portray the molecular world. © 2016 The American Chemical Society and Division of Chemical Education, Inc.","Aqueous Solution Chemistry; Constructivism; First-Year Undergraduate/General; Misconceptions/Discrepant Events; Molecular Modeling; Multimedia-Based Learning",,2-s2.0-84974824075
"Kothiya S.V., Dutt A., Mistree K.B.","Real time object tracking for high performance system using GPGPU",2016,"Proceedings - IEEE International Conference on Information Processing, ICIP 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979210416&doi=10.1109%2fINFOP.2015.7489441&partnerID=40&md5=d0e7675007f2019d43b447bb90b1a881","Real time object tracking is the process of locating moving objects over time using the camera in video sequences in real time. The objective of object tracking is to associate target objects in consecutive video frames. Object tracking requires location and shape or features of objects in the video frames. Every tracking algorithm needs to detect moving object. So object detection is the preceding step of object tracking in computer vision applications. After that, detected object can be extracted by the feature of moving object to track that moving object into video scene. It is challenging task in image processing to track the objects into consecutive frames. Various challenges can arise due to complex object motion, irregular shape of object, occlusion of object to object and object to scene and real time processing requirements. Object tracking has a variety of uses, some of which are: surveillance and security, traffic monitoring, video communication, robot vision and animation. © 2015 IEEE.","Block matching; Feacture extraction; Gaussian mixture; GPGPU; Video surveillance","Color image processing; Computer vision; Image matching; Image processing; Information science; Motion analysis; Program processors; Security systems; Target tracking; Tracking (position); Video signal processing; Block Matching; Computer vision applications; Gaussian mixtures; GPGPU; High performance systems; Real-time object tracking; Video communications; Video surveillance; Object detection",2-s2.0-84979210416
"Iglesias A., Gálvez A.","Memetic electromagnetism algorithm for surface reconstruction with rational bivariate Bernstein basis functions",2016,"Natural Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973601930&doi=10.1007%2fs11047-016-9562-5&partnerID=40&md5=0fa9696f17e2dae177373d77da66547d","Surface reconstruction is a very important issue with outstanding applications in fields such as medical imaging (computer tomography, magnetic resonance), biomedical engineering (customized prosthesis and medical implants), computer-aided design and manufacturing (reverse engineering for the automotive, aerospace and shipbuilding industries), rapid prototyping (scale models of physical parts from CAD data), computer animation and film industry (motion capture, character modeling), archaeology (digital representation and storage of archaeological sites and assets), virtual/augmented reality, and many others. In this paper we address the surface reconstruction problem by using rational Bézier surfaces. This problem is by far more complex than the case for curves we solved in a previous paper. In addition, we deal with data points subjected to measurement noise and irregular sampling, replicating the usual conditions of real-world applications. Our method is based on a memetic approach combining a powerful metaheuristic method for global optimization (the electromagnetism algorithm) with a local search method. This method is applied to a benchmark of five illustrative examples exhibiting challenging features. Our experimental results show that the method performs very well, and it can recover the underlying shape of surfaces with very good accuracy. © 2016 Springer Science+Business Media Dordrecht","Electromagnetism algorithm; Local search; Memetic approach; Rational surfaces; Surface reconstruction","Algorithms; Animation; Biomedical engineering; Computer aided design; Digital storage; Global optimization; Local search (optimization); Magnetic film storage; Magnetic resonance; Magnetic storage; Medical imaging; Optimization; Rational functions; Reverse engineering; Shipbuilding; Archaeological site; Digital representations; Electromagnetism algorithms; Local search; Local search method; Memetic approach; Meta-heuristic methods; Shipbuilding industry; Surface reconstruction; electromagnetic field; experimental model; noise; sampling",2-s2.0-84973601930
"Thulesen T.N., Petersen H.G.","RobWorkPhysicsEngine: A new dynamic simulation engine for manipulation actions",2016,"Proceedings - IEEE International Conference on Robotics and Automation",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977491717&doi=10.1109%2fICRA.2016.7487354&partnerID=40&md5=1e8c1bd39975d28e9f10842ce049d155","Simulation in robotics is often based on physics engines developed for computer games and animation. These engines are inaccurate due to the applied first order numerical integration and because their ways to resolve redundant contacts lead to contact forces that are distributed in a physically unreasonable way among multiple contacts. In this paper, we present a new physics engine that resolves these flaws by designing and implementing a second order integration method, and by a new way of defining the contact-force resolution problem. We illustrate the improvement over state-of-the-art engines by a number of experiments. The new engine is proven to be particularly suitable for simulating tight fitting assembly operations where multiple contacts occur between the objects involved. © 2016 IEEE.",,"Animation; Computer games; Engines; Assembly operations; Contact forces; Integration method; Multiple contacts; Numerical integrations; Physics engine; Second orders; State of the art; Robotics",2-s2.0-84977491717
"Peszor D., Wojciechowska M.","Facial expression reconstruction on the basis of selected vertices of triangle mesh",2016,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984535924&doi=10.1063%2f1.4951963&partnerID=40&md5=365147524dab8cd1e417148135660682","Facial expression reconstruction is an important issue in the field of computer graphics. While it is relatively easy to create an animation based on meshes constructed through video recordings, this kind of high-quality data is often not transferred to another model because of lack of intermediary, anthropometry-based way to do so. However, if a high-quality mesh is sampled with sufficient density, it is possible to use obtained feature points to encode the shape of surrounding vertices in a way that can be easily transferred to another mesh with corresponding feature points. In this paper we present a method used for obtaining information for the purpose of reconstructing changes in facial surface on the basis of selected feature points. © 2016 Author(s).","facial animation; facial expressions; reconstruction; vertices selection",,2-s2.0-84984535924
"Colombo S., Garzotto F., Gelsomini M., Melli M., Clasadonte F.","Dolphin sam: A smart pet for children with intellectual disability",2016,"Proceedings of the Workshop on Advanced Visual Interfaces AVI",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977151355&doi=10.1145%2f2909132.2926090&partnerID=40&md5=5c1a28d5b32e92457cead26f042bccfc","Our research aims at helping children with intellectual disability (ID) to ""learn through play"" by interacting with digitally enriched physical toys. Inspired by the practice of Dolphin Therapy (a special form of Pet Therapy) and, specifically, by the activities that ID children perform at Dolphinariums, we have developed a ""smart"" stuffed dolphin called SAM that engages children in a variety of play tasks. SAM emits different stimuli (sound, vibration, and light) with its body in response to children's manipulation. Its behavior is integrated with lights and multimedia animations or video displayed in the ambient and can be customized by therapists to address the specific needs of each child. © 2016 Copyright held by the owner/author(s).","Arduino; Autism; Children; Intellectual disability; Pet therapy; Smart object","Interfaces (computer); Arduino; Autism; Children; Intellectual disability; Smart objects; Dolphins (structures)",2-s2.0-84977151355
"Degenbaev U., Eisinger J., Ernst M., Mcilroy R., Payer H.","Idle time garbage collection scheduling",2016,"Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975789688&doi=10.1145%2f2908080.2908106&partnerID=40&md5=603c328c1115f7d9f5daec9182b15997","Efficient garbage collection is increasingly important in today's managed language runtime systems that demand low latency, low memory consumption, and high throughput. Garbage collection may pause the application for many milliseconds to identify live memory, free unused memory, and compact fragmented regions of memory, even when employing concurrent garbage collection. In animation-based applications that require 60 frames per second, these pause times may be observable, degrading user experience. This paper introduces idle time garbage collection scheduling to increase the responsiveness of applications by hiding expensive garbage collection operations inside of small, otherwise unused idle portions of the application's execution, resulting in smoother animations. Additionally we take advantage of idleness to reduce memory consumption while allowing higher memory use when high throughput is required. We implemented idle time garbage collection scheduling in V8, an open-source, production JavaScript virtual machine running within Chrome.We present performance results on various benchmarks running popular webpages and show that idle time garbage collection scheduling can significantly improve latency and memory consumption. Furthermore, we introduce a new metric called frame time discrepancy to quantify the quality of the user experience and precisely measure the improvements that idle time garbage collection scheduling provides for a WebGL-based game benchmark. Idle time garbage collection scheduling is shipped and enabled by default in Chrome. © 2016 ACM.","Browser technology; Garbage collection; Javascript; Memory management; Scheduling; Virtual machines; Web applications","Animation; Benchmarking; Computational linguistics; Computer programming languages; High level languages; Java programming language; Open source software; Refuse collection; Scheduling; Throughput; Browser technologies; Garbage collection; Javascript; Memory management; Virtual machines; WEB application; Multitasking",2-s2.0-84975789688
"Papaefthymiou M., Hildenbrand D., Papagiannakis G.","An inclusive Conformal Geometric Algebra GPU animation interpolation and deformation algorithm",2016,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970959802&doi=10.1007%2fs00371-016-1270-8&partnerID=40&md5=6b7f027d081d790e6bde02f9cffd4575","In the last years, Geometric Algebra with its Euclidean, Homogeneous and Conformal models attracts the research interest in many areas of Computer Science and Engineering and particularly in Computer Graphics as it is shown that they can produce more efficient and smooth results than other algebras. In this paper, we present an all-inclusive algorithm for real-time animation interpolation and GPU-based geometric skinning of animated, deformable virtual characters using the Conformal model of Geometric Algebra (CGA). We compare our method with standard quaternions, linear algebra matrices and dual-quaternions blending and skinning algorithms and we illustrate how our CGA-GPU inclusive skinning algorithm can provide as smooth and more efficient results as state-of-the-art previous methods. Furthermore, the elements of CGA that handle transformations (CGA motors) can support translation, rotation and dilation(uniform scaling) of joints under a single, GPU-supported mathematical framework and avoid conversion between different mathematical representations in contrast to quaternions and dual-quaternions that support only rotation and rotation–translation, respectively. Hence, our main novelty is the replacement of different types of algebras, and their in-between conversions between CPU and GPU, such as linear algebra matrices, quaternions, dual-quaternions and Euler angles for animation interpolation and skinning with a single mathematical representation, the CGA motors which can optimally handle the composition of translation, rotation and scaling joint transformations and interpolations. Employing latest CGA code generators, we provide a sample implementation of our algorithm running natively in a vertex shader program on modern GPUs for typical deformable virtual character simulations. © 2016, Springer-Verlag Berlin Heidelberg.","Animation; Animation Blending; Conformal model; Geometric Algebra; GPU-based skinning; Skinning; Virtual Character Simulation; Virtual Reality","Algebra; Algorithms; Animation; Automatic programming; Blending; Computer graphics; Deformation; Geometry; Interpolation; Linear algebra; Linear transformations; Matrix algebra; Program processors; Rotation; Virtual reality; Computer science and engineerings; Conformal Geometric Algebra; Geometric Algebra; Gpu-based; Mathematical frameworks; Mathematical representations; Skinning; Virtual character simulation; Mathematical transformations",2-s2.0-84970959802
"Kim T.H., Lee J., Kim C.-H.","Physics-inspired controllable flame animation",2016,"Visual Computer",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968593878&doi=10.1007%2fs00371-016-1267-3&partnerID=40&md5=02768364df7cdd6b216e5ad3c054bb87","We propose a novel method conceptualized from the properties of physics where in particular the shape of a flame is determined by temperature that enables a control mechanism for the intuitive shaping of a flame. We focused on a trade-off issue from computer graphics whereby the turbulent flow that expresses the characteristics of the flame has a tendency to shift continuously, whereas the velocity constraints that contain a fluid within a target shape have a tendency to force movement in a particular direction. Trade-off made it difficult for animation designers to maintain a flame within the intended target shape. This paper resolves the issue by enabling the flame to be controlled without any velocity constraints by using the following two techniques: First, we model the temperature and force of the explosion generated by the combustion of explosive gaseous fuel and apply it to certain regions. Second, we expand the space of the interface between the fuel and the burned products, classifying that space into four regions and controlling the target shape of the flame by delicate adjustments to the temperature in each region. Experiments show that the flame maintains the appearance of dynamic movement while preserving the detailed 3D shapes specified by the scene designers. © 2016, Springer-Verlag Berlin Heidelberg.","Flame animation; Fluid control; Physics inspired; Temperature control","Animation; Computer graphics; Economic and social effects; Electron emission; Temperature control; Burned products; Control mechanism; Dynamic movements; Fluid control; Gaseous Fuel; Target shape; Temperature and force; Velocity constraints; Combustion",2-s2.0-84968593878
"Shao X., Zhao W.","Multi-precision hybrid model for elastic deformation and interaction simulation",2016,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975073423&partnerID=40&md5=9f4e720f8c70680b292947ff64f35df0","The simulation of elastic deformation is an important research topic in computer animation. However, it is always a big challenge to improve the computational efficiency while ensuring the reality. This paper presents a multi-precision hybrid model to simulate the elastic deformation and interaction efficiently. The model divides the computational space into physical deformation area and geometric deformation area according to user-defined ratio, and realizes the stable coupling of two different areas by the hybrid processing of computation nodes at the interface. A virtual node cutting method is used to stably and smoothly cut the physical deformation area, and an adaptive boundary particle sampling method is proposed to simulate stable fluid-solid coupling. The results demonstrate that the proposed model can control the efficiency and precision of the elastic deformation by adjusting the user-defined ratio, and satisfy the requirements of stability and efficiency in the virtual reality interaction and fluid-solid coupling. © 2016, Institute of Computing Technology. All right reserved.","Elastic deformation; Finite element method; Interaction simulation; Multi-precision hybrid model; Shape matching","Animation; Computational efficiency; Efficiency; Elastic deformation; Virtual reality; Computer animation; Fluid-solid coupling; Geometric deformations; Hybrid model; Interaction simulations; Physical deformation; Shape matching; Virtual reality interactions; Finite element method",2-s2.0-84975073423
"Tang Z., Hou J.","Speech-driven articulator motion synthesis with deep neural networks",2016,"Zidonghua Xuebao/Acta Automatica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977271435&doi=10.16383%2fj.aas.2016.c150726&partnerID=40&md5=594dd3746b1d5ab6a88e0d93512de390","This paper implements a deep neural networks (DNN) approach for speech-driven articulator motion synthesis, which is applied to speech-driven talking avatar animation synthesis. We realize acoustic-articulatory mapping by DNN. The input of the system is acoustic speech and the output is the estimated articulatory movements on a three-dimensional avatar. First, through comparison on the performance between ANN and DNN under a series of parameters, the optimal network is obtained. Second, for diffierent context acoustic length configurations, the number of hidden layer units is tuned for best performance. So we get the best context length. Finally, we select the optimal network structure and realize the avatar animation by using the articulatory motion trajectory information output from the DNN to control the articulator motion synthesis. The experiment proves that the method can vividly and efficiently realize talking avatar animation synthesis. Copyright © 2016 Acta Automatica Sinica. All rights reserved.","Deep neural networks (DNN); Motion synthesis; Speech-driven; Talking avatar","Animation; Speech; Structural optimization; Animation synthesis; Deep neural networks; Hidden-layer units; Motion synthesis; Motion trajectories; Optimal network structure; Optimal networks; Talking avatar; Three dimensional computer graphics",2-s2.0-84977271435
"Krompiec P., Park K., Liang D., Lee C.","Deformable strokes towards temporally coherent video painting",2016,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968546890&doi=10.1007%2fs00371-016-1256-6&partnerID=40&md5=e85ad6e1300ea8ccfda9da6d7556ad29","We present an automatic and robust technique for creating non-photorealistic rendering (NPR) and animation, starting from a video that depicts the shape details and follows the motion of underlying objects. We generate NPR from the initial frame of the source video using a greedy algorithm for stroke placements and models, in combination with a saliency map and a flow-guided difference-of-Gaussian filter. Our stroke model uses a set of triangles whose vertices are particles and whose edges are springs. Using a physics-based framework, the generated and rendered strokes are translated, rotated and deformed by forces exerted from the sequential frames. External forces acting on strokes are calculated according to temporally and spatially smoothed per-pixel optical flow vectors. After simulating each frame, we delete unnecessary strokes and add new strokes for disappearing and appearing objects, but only if necessary to avoid popping and scintillation. Our framework automatically generates the coherent animation of rendered strokes, preserving the appearance details and animating strokes along with the underlying objects. This had been difficult to achieve with previous user-guided methods and automatic but limited transformations methods. © 2016, Springer-Verlag Berlin Heidelberg.","Deformable strokes; Non-photorealistic rendering; Temporal coherency; Video painting","Animation; Computer graphics; Deformation; Deformable strokes; External force; Gaussian filters; Greedy algorithms; Non-Photorealistic Rendering; Physics-based; Robust technique; Temporal coherency; Rendering (computer graphics)",2-s2.0-84968546890
"Rai S., Chaudhuri M.","Exploiting dynamic reuse probability to manage shared last-level caches in CPU-GPU heterogeneous processors",2016,"Proceedings of the International Conference on Supercomputing",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978488587&doi=10.1145%2f2925426.2926266&partnerID=40&md5=e355d4f1f3cdaa3943b349a8863f7752","Recent commercial chip-multiprocessors (CMPs) have integrated CPU as well as GPU cores on the same die. In today's designs, these cores typically share parts of the memory system resources. However, since the CPU and the GPU cores have vastly different resource requirements, challenging resource partitioning problems arise in such heterogeneous CMPs. In one class of designs, the CPU and the GPU cores share the large on-die last-level SRAM cache. In this paper, we explore mechanisms to dynamically allocate the shared last-level cache space to the CPU and GPU applications in such designs. A CPU core executes an instruction progressively in a pipeline generating memory accesses (for instruction and data) only in a few pipeline stages. On the other hand, a GPU can access different data streams having different semantic meanings and disparate access patterns throughout the rendering pipeline. Such data streams include input vertex, pixel depth, pixel color, texture map, shader instructions, shader data (including shader register spills and fills), etc.. Without carefully designed last-level cache management policies, the CPU and the GPU data streams can interfere with each other leading to significant loss in CPU and GPU performance accompanied by degradation in GPU-rendered 3D animation quality. Our proposal dynamically estimates the reuse probabilities of the GPU streams as well as the CPU data by sampling portions of the CPU and GPU working sets and storing the sampled tags in a small working set sample cache. Since the GPU application working sets are typically very large, for this working set sample cache to be effective, it is custom-designed to have large coverage while requiring few tens of kilobytes of storage. We use the estimated reuse probabilities to design shared last-level cache policies for handling hits and misses to reads and writes from both types of cores. Studies on a detailed heterogeneous CMP simulator show that compared to a state-of-the-art baseline with a 16 MB shared last-level cache, our proposal can improve the performance (frame rate or execution cycles, as applicable) of eighteen GPU workloads spanning DirectX and OpenGL game titles as well as CUDA applications by 12% on average and up to 51% while improving the performance of the co-running quad-core CPU workload mixes by 7% on average and up to 19%. © 2016 ACM.","CPU-GPU integration; Shared last-level cache; Temporal reuse","Animation; Application programming interfaces (API); Data communication systems; Design; Digital storage; Distributed computer systems; Intelligent control; Pipelines; Pixels; Probability; Semantics; Static random access storage; Heterogeneous CMP; Heterogeneous cmps; Heterogeneous processors; Last-level caches; Rendering pipelines; Resource partitioning; Resource requirements; Temporal reuse; Rendering (computer graphics)",2-s2.0-84978488587
"Lee R.-R., Lo Y., Chu H.-K., Chang C.-F.","A simulation on grass swaying with dynamic wind force",2016,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966480742&doi=10.1007%2fs00371-016-1263-7&partnerID=40&md5=0f473294ac196690455d60acdf3c66b8","Grass swaying simulation with respect to wind force plays an important role in the outdoor scene design of video games and animations. However, the complex and dynamic interactions between grass and wind largely hinder the existing approaches from generating physically plausible simulation in real-time performance. Therefore, common approaches compromise by either rendering still meadow or simply adopting a procedural method for simulating the grass motion. In this work, we present a simple yet effective grass model that enables the real-time simulation of grass swaying mimicking real-world grass motions under dynamic wind force. We characterize each individual grass using a simple polyline model with four vertices derived from the control knots of a cubic Bezier curve describing the real grass shape. The grass dynamics is modeled by applying a combination of swinging, bending and twisting motions to the polyline model in response to the input wind force. The deformed grass model is then passed to the shader pipeline to synthesize grass blades for the rendering. Experimental results show that our system not only achieves real-time performance in simulation and rendering, but also scales well to large grass field such as a meadow. © 2016, Springer-Verlag Berlin Heidelberg.","Grass swaying; Grid-based fluid dynamics; Real time; Simulation","Animation; Cubic Bezier curve; Dynamic interaction; Grass swaying; Grid-based; Real time; Real time performance; Real time simulations; Simulation; Rendering (computer graphics)",2-s2.0-84966480742
"Krcadinac U., Jovanovic J., Devedzic V., Pasquier P.","Textual Affect Communication and Evocation Using Abstract Generative Visuals",2016,"IEEE Transactions on Human-Machine Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949943718&doi=10.1109%2fTHMS.2015.2504081&partnerID=40&md5=35cf506e2e44520c9ff29648027171df","In order to facilitate interaction in computer-mediated communication and enrich user experience in general, we introduce a novel textual emotion visualization approach, grounded in generative art and evocative visuals. The approach is centered on the idea that affective computer systems should be able to relate to, communicate, and evoke human emotions. It maps emotions identified in the text to evocative abstract animation. We examined two visualizations based on our approach and two common textual emotion visualization techniques, chat emoticons and avatars, along three dimensions: emotion communication, emotion evocation, and overall user enjoyment. Our study, organized as repeated measures within-subject experiment, demonstrated that in terms of emotion communication, our visualizations are comparable with emoticons and avatars. However, our main visualization based on abstract color, motion, and shape proved to be the best in evoking emotions. In addition, in terms of the overall user enjoyment, it gave results comparable with emoticons, but better than avatars. © 2015 IEEE.","Communications applications; computer applications in arts and humanities; computer applications in social and behavioral sciences; computer graphics applications; multimedia; natural language processing; user interfaces","Visualization; Affective computer; Computer mediated communication; Generative art; Repeated measures; Subject experiment; Three dimensions; User experience; Visualization technique; Abstracting",2-s2.0-84949943718
"Mackenzie S., Stenport A.W.","Contemporary experimental feminist Sámi documentary: The first person politics of Liselotte Wajstedt and Elle- Máijá Tailfeathers",2016,"Journal of Scandinavian Cinema",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012260334&doi=10.1386%2fjsca.6.2.169_1&partnerID=40&md5=b54b4dcbb6c25180a140f7695f8e9040","This article examines two experimental documentary feminist Sámi films by Liselotte Wajstedt and Elle-Máijá Tailfeathers. Their works deploy experimental techniques such as cell and computer animation, time-lapse photography and superimposition, along with autobiographical voice-overs, thereby challenging many dominant tropes of Sámi filmmaking, including the preponderance of realism and cultural revivalist narratives. Through ‘first person’ filmmaking, Wajstedt’s Sami Daughter Yoik (2007) and Tailfeathers’ Rebel (2014) and Colonial Gaze Sámi Artists’ Collective (co-directed with Nango, 2012) explore the hybridity of identity, trauma, cultural memory and the status of documentary films as artistic practice. The films are situated within larger recent developments in Sámi filmmaking, including initiatives by the International Sámi Film Institute. This article reframes the perimeters of both Sámi and Scandinavian documentary filmmaking in the twenty-first century. © 2016 Intellect Ltd Article.","Cultural memory work; Documentary; Feminism; First person film; Indigenous studies; Sámi; The Arctic; Video art",,2-s2.0-85012260334
"Stoev L., Uzunova M., Kozak D., Stoić A.","Preparation of video lectures for distance education [Priprema video predavanja za obrazovanje na daljinu]",2016,"Tehnicki Vjesnik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975260045&doi=10.17559%2fTV-20150226124944&partnerID=40&md5=4804d48ca2a221ac5ee9e715cfec74cf","In this paper the application of the software product Camtasia Studio 8 and some developments of the authors when preparing video lectures for distance education are presented. The developed films are in several languages and are accessible in the Internet. Regular and part-time students may study them in details using a computer or a smartphone in time and place most convenient for them. The selected information in the video lectures is presented much faster and accurately compared to the traditional methods for teaching, which saves time. There are included animations with comments, simulations and inserted video clips to visualize the presented material. The authors work in collaboration on a new project for international cooperation under CEEPUS program for preparation of video lectures and exercises in German and English for students studying in the partner universities. © 2016, Strojarski Facultet. All rights reserved.","Distance education; e-learning; Internet; Video-lectures","Application programs; Distance education; E-learning; International cooperation; Internet; Students; New projects; Part-time students; Saves time; Software products; Video clips; Video lectures; Education",2-s2.0-84975260045
"Eisenmann J., Lewis M., Paren R.","Spatiotemporal ideation and generation with interactive evolutionary design",2016,"Leonardo",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970968855&doi=10.1162%2fLEON_a_01102&partnerID=40&md5=ee0ef15e889ebd37da12a957c7fcf80c","Interactive evolutionary design tools enable human intuition and creative decision-making in high-dimensional design domains while leaving technical busywork to the computer. Current evolutionary algorithms for interactive design tools accept only feedback about entire design candidates, not their parts, which can lead to user fatigue. This article describes several case studies in which designers used an enhanced interactive evolutionary design tool with regionof- interest feedback for character animation tasks. This enhanced interactive evolutionary design tool is called the Interactive Design with Evolutionary Algorithms and Sensitivity (IDEAS) tool. Designers’ feedback and narratives about their experiences with the tool show that interactive evolutionary algorithms can be made suitable for the ideation and generation of digital assets, even in time-varying domains. © 2016 ISAST.",,,2-s2.0-84970968855
"Widiarto W., Hariadi M., Yuniarno E.M.","Shot segmentation of video animation to generate comic strip based on key frame selection",2016,"Proceedings - 5th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978877489&doi=10.1109%2fICCSCE.2015.7482202&partnerID=40&md5=54d6290e549df494a49c834d6f4f9238","Video summary aims to facilitate the process of browsing and retrieval of video. Selecting key frames from each segment shot is one way of summarizing video. Selection of key frames is done by comparing the histogram of each frame to determine the distance between two consecutive frames. Determines the distance between the two frames used Euclidean distance method. If the distance of two frames does not exceed the specified number, then the frame is considered to be Similar. If the distance of two frames exceeds the limit, then the frame is considered to be dissimilar. If two frames are dissimilar, then shot segmentation is considered changed. Each segment is taken two key frames, the first frame and last frame of each segment. Two key frame (per segment) were selected randomly one to serve as a comic strip. Comic strip sequentially collected to be displayed on one page, one page is formed of a comic strip that consists of four. A collection of some pages will form into a comic book. © 2015 IEEE.","comic strip; key frame; selection; similar; summarizing video","Computer programming; Computer science; Control; Engineering; Industrial engineering; Comic strips; Key frames; selection; similar; summarizing video; Control systems",2-s2.0-84978877489
"Magrez H., Salmi K., Ziyyat A.","Interactive simulations for teaching and learning differential equations",2016,"2016 International Conference on Information Technology for Organizations Development, IT4OD 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978160646&doi=10.1109%2fIT4OD.2016.7479266&partnerID=40&md5=9da250b688b71bf97adb948097b679cd","In this paper, we present some interactive simulations developed mainly for educational purposes in physics, mathematics, and engineering. A new horizon of understanding some concepts via interactive animations has opened a new research dimension in the learning theory. In this work, our interest is focused on the design of interactive and didactic simulations for teaching and learning differential equations. The code is written in ActionScript/Flash to enjoy all the benefits of this technology in the multimedia field, Internet and mobile phones (smartphones and tablets). This powerful tool stimulates students' interest to understand/learn abstract mathematical concepts in physics. These simulations provide additional insight for concepts that need a lot of resources and time. These simulations are applied in e-learning environments and engineering education. © 2016 IEEE.","Didactic; Differential equations; e-learning; ICT in education; Simulation","Cellular telephone systems; Computer aided instruction; Differential equations; Education; Teaching; Didactic; E-learning environment; Interactive animations; Interactive simulations; Mathematical concepts; Simulation; Students' interests; Teaching and learning; E-learning",2-s2.0-84978160646
"Wahab R.A., Al-Alaiwat S.","Student's attitudes towards online assignment submission at college of health sciences, University of Bahrain",2016,"Proceedings - 2015 5th International Conference on e-Learning, ECONF 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978698625&doi=10.1109%2fECONF.2015.44&partnerID=40&md5=eeaf947632f622bce9881365a534af6c","Technology has made a significant impact on assessment, including its use to automate assignment submission. All processes in the workflow-submission of assignments, assessment, and feedback given are performed using electronic files. Online assignment submission was introduced at the College of Health Sciences (CHS), University of Bahrain (UoB) in 2008 through the Learning Management System. This research attempts to answer two questions: Firstly, what are the perceptions of the CHS instructors and students about the use of online assignment submission? Secondly, what challenges do instructors and students encounter in using online assignment submission at the CHS? One hundred and forty (140) students from different programs at the College have participated in this study. Ninety six (96%) of the CHS students had very good computer skills and e-learning experience and 63% of the students reported familiarity with online assignments during their study period at the CHS. Eighty percent (80%) of students prefer to submit and to get their assignments grades online. Also, eighty three percent (83%) think that online assignment submission is quicker than the hard copy submission. Eight (8) teaching faculty from the Integrated Sciences Department participated in the interviews. The interview results revealed that although most teaching faculty have good skills in using computers and its applications, they prefer to use traditional teaching methods with increased dependence on computer applications. They also believe that the Web based programs with supporting materials such as online assignments, animations, and videos support the teaching process and make learning more enjoyable. © 2015 IEEE.","Assignment feedback; Learning Management System; On-line assignment; Student perception","E-learning; Education; Teaching; ITS applications; Learning management system; Line assignments; Online assignments; Student perceptions; Supporting material; Teaching process; Web based projects; Students",2-s2.0-84978698625
"Yu X., Yang J., Luo L., Li W., Brandt J., Metaxas D.","Customized expression recognition for performance-driven cutout character animation",2016,"2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977650130&doi=10.1109%2fWACV.2016.7477449&partnerID=40&md5=48156d34fdf6feda473d46971f474b60","Performance-driven character animation enables users to create expressive results by performing the desired motion of the character with their face and/or body. However, for cutout animations where continuous motion is combined with discrete artwork replacements, supporting a performance-driven workflow has some unique requirements. To trigger the appropriate artwork replacements, the system must reliably detect a wide range of customized facial expressions that are challenging for existing recognition methods, which focus on a few canonical expressions (e.g., angry, disgusted, scared, happy, sad and surprised). Also, real usage scenarios require the system to work in realtime with minimal training. In this paper, we propose a novel customized expression recognition technique that meets all of these requirements. We first use a set of handcrafted features combining geometric features derived from facial landmarks and patch-based appearance features through group sparsity-based facial component learning. To improve discrimination and generalization, these handcrafted features are integrated into a custom-designed Deep Convolutional Neural Network (CNN) structure trained from publicly available facial expression datasets. The combined features are fed to an online ensemble of SVMs designed for the few training sample problem and performs in realtime. To improve temporal coherence, we also apply a Hidden Markov Model (HMM) to smooth the recognition results. Our system achieves state-of-the-art performance on canonical expression datasets and promising results on our collected dataset of customized expressions. © 2016 IEEE.",,"Animation; Computer vision; Hidden Markov models; Markov processes; Neural networks; Character animation; Continuous motions; Convolutional neural network; Expression recognition; Facial Expressions; Recognition methods; State-of-the-art performance; Temporal coherence; Face recognition",2-s2.0-84977650130
"Wang Z., Feng Y., Liu S., Xiao J., Yang X., Zhang J.J.","A 3D human motion refinement method based on sparse motion bases selection",2016,"ACM International Conference Proceeding Series",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986275085&doi=10.1145%2f2915926.2915943&partnerID=40&md5=bed00487391387322a6920b4d6aa0a4c","Motion capture (MOCAP) is an important technique that is widely used in many areas such as computer animation, film industry, physical training and so on. Even with professional MOCAP system, the missing marker problems always occur. Motion refinement is an essential preprocessing step for MOCAP data based applications. Although many existing approaches for motion refinement have been developed, it is still a challenging task due to the complexity and diversity of human motion. A data driven based motion refinement method is proposed in this paper, which modifies the traditional sparse coding process for special task of motion recovery from missing parts. Meanwhile, the objective function is derived by taking both statistical and kinematical property of motion data into account. Poselet model and moving window grouping are applied in the proposed method to achieve a fine-grained feature representation, which preserves the embedded spatial-Temporal kinematic information. 5 motion dictionaries are learnt for each kind of poselet from training data in parallel.The motion refine problem is finally solved as an 1-minimization problem. Compared with several state-of-Art motion refine methods, the experimental result shows that our approach outperforms the competitors. © 2016 ACM.","Dictionary learning; Missing marker; Motion capture refinement; Partlet model","Computer applications; Computer programming; Computer animation; Dictionary learning; Feature representation; Kinematic information; Missing Markers; Motion capture; Objective functions; Pre-processing step; Animation",2-s2.0-84986275085
"Carreno-Medrano P., Gibet S., Marteau P.-F.","From expressive end-effector trajectories to expressive bodily motions",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986276525&doi=10.1145%2f2915926.2915941&partnerID=40&md5=5aa906625ea18638fa4375927dc75f1e","Recent results in the affective computing sciences point towards the importance of virtual characters capable of conveying affect through their movements. However, in spite of all advances made on the synthesis of expressive motions, almost all of the existing approaches focus on the translation of stylistic content rather than on the generation of new expressive motions. Based on studies that show the importance of end-effector trajectories in the perception and recognition of affect, this paper proposes a new approach for the automatic generation of affective motions. In this approach, expressive content is embedded in a low-dimensional manifold built from the observation of end-effector trajectories. These trajectories are taken from an expressive motion capture database. Body motions are then reconstructed by a multi-chain Inverse Kinematics controller. The similarity between the expressive content of MoCap and synthesized motions is quantitatively assessed through information theory measures. © 2016 ACM.","Bodily Motions; Computer Animation; Dimensionality Reduction; Expressive Motions; Inverse Kinematics; Motion Synthesis","Computation theory; End effectors; Information theory; Inverse kinematics; Kinematics; Trajectories; Bodily Motions; Computer animation; Dimensionality reduction; Expressive Motions; Motion synthesis; Animation",2-s2.0-84986276525
"Oh J., Lee Y., Kim Y., Jin T., Lee S., Lee S.-H.","Hand contact between remote users through virtual avatars",2016,"ACM International Conference Proceeding Series",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986302326&doi=10.1145%2f2915926.2915947&partnerID=40&md5=5e5108d335d7ae6f54e100a943672a4b","We present an avatar animation technique for a telepresence system that allows for the hand contact, especially handshaking, between remote users. The key idea is that, while the avatar follows the remote user's motion normally, it modifies the motion to create and maintain hand contact with the local user when the two users try to engage hand contact. To this end, we develop the support vector machine (SVM)-based classifiers to recognize the users' intention for contact interaction, and online motion generation method to create realistic image sequence of an avatar to realize the continuous contact with the user. A user study has been conducted to verify the effect of our method on the social telepresence. © 2016 ACM.","3D Telepresence; Avatar interaction; Character animation; Contact interaction","Animation; Support vector machines; Visual communication; Animation techniques; Avatar interaction; Character animation; Contact interaction; Motion generation; Realistic images; Tele-presence systems; Telepresence; Three dimensional computer graphics",2-s2.0-84986302326
"Matsuyama K., Konno K.","A framework for manipulating multi-perspective image using a parametric surface",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986253649&doi=10.1145%2f2915926.2915946&partnerID=40&md5=57dca7ca690ae53a4c89535a071f4095","We have designed a framework for manipulating multi-perspective images. In this paper, we present (1) an accelerated multiperspective rendering method, (2) a parametric surface based multi-perspective camera control method and (3) an interface to manipulate multi-perspective images. Our camera control method can express transition of camera parameters by deforming the parametric surface and manipulating control points. Our rendering method performs about 2.5 times faster than the previous method at best. We also show two application examples utilizing our methods. © 2016 ACM.","Interact With 3D objects; Multi-Perspective Images; Projection Methods; Real-Time Rendering","Animation; Cameras; Parametric devices; Three dimensional computer graphics; 3D object; Application examples; Camera control methods; Multi-perspective image; Parametric surfaces; Projection method; Real-time rendering; Rendering methods; Rendering (computer graphics)",2-s2.0-84986253649
"Boulic R., Evci U., Molla E., Pisupati P.","One step from the locomotion to the stepping pattern",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986301981&doi=10.1145%2f2915926.2915949&partnerID=40&md5=a3248d9ee825dfc176a35aa1b3445093","The locomotion pattern is characterized by a translation displacement mostly occurring along the forward frontal body direction, whereas local repositioning with large re-orientations, i.e. stepping, may induce translations both along the frontal and the lateral body directions (holonomy). We consider here a stepping pattern with initial and final null speeds within a radius of 40% of the body height and re-orientation up to 180°. We propose a robust step detection method for such a context and identify a consistent intra-subject behavior in terms of the choice of starting foot and the number of steps. © 2016 ACM.","Holonomic trajectory.; Locomotion; Stepping","Biped locomotion; Computer applications; Computer programming; Holonomic; Holonomy; Locomotion patterns; Re-orientation; Step detection; Stepping; Translation displacements; Animation",2-s2.0-84986301981
"Kimmel B.W., Baranoski G.V.G.","Practical acceleration strategies for the predictive visualization of fading phenomena",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986275116&doi=10.1145%2f2915926.2915945&partnerID=40&md5=65116c68446d9e41086ac86cf915c006","Appearance changes caused by light exposure provide im-portant cues that impart a sense of realism to a computer-generated scene. For instance, a carpet may fade or wood may turn yellow over time as a result of many years of light exposure. In this paper, we analyse the key performance and accuracy trade-offs associated with the physically-based simulation of these phenomena. This analysis may be used to guide the selection of simulation parameters in order to achieve optimal color-Accuracy and minimize runtime. We also propose a practical method to enable the predictive vi-sualization of these phenomena within applications requiring interactive rates with minimal loss of accuracy. The effec-tiveness of the proposed techniques is demonstrated through simulations and image sequences depicting fading and yel-lowing caused by several years of exposure to light.","Natural phenomena; Physically-based simulation; Visualiza-Tion","Economic and social effects; Acceleration strategies; Computer generated; Interactive rates; Loss of accuracy; Natural phenomena; Physically-based simulation; Practical method; Simulation parameters; Animation",2-s2.0-84986275116
"Kochanowicz J., Tan A.-H., Thalmann D.","Modeling human-like non-rationality for social agents",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986269537&doi=10.1145%2f2915926.2915951&partnerID=40&md5=d5cf31e56ec20ab3116bbee35b385208","Humans are not rational beings. Deviations from rationality in human thinking are currently well documented [25] as non-reducible to rational pursuit of egoistic benefit or its occasional distortion with temporary emotional excitation, as it is often assumed. This occurs not only outside conceptual reasoning or rational goal realization but also subconsciously and often in certainty that they did not and could not take place in my case'. Non-rationality can no longer be perceived as a rare affective abnormality in otherwise rational thinking, but as a systemic, permanent quality, 'a design feature' of human cognition. While social psychology has systematically addressed non-rationality of human cognition (including its non-emotional aspects) for decades [63]. It is not the case for computer science, despite obvious relevance for individual and group behavior modeling. This paper proposes brief survey of work in computational disciplines related to human-like non-rationality modeling including: Social Signal Processing, Cognitive Architectures, Affective Computing, Human-Like Agents and Normative Multi-Agent Systems. It attempts to establish a common terminology and conceptual frame for this extremely interdisciplinary issue, reveal assumptions about non-rationality underlying the discussed models and disciplines, their current limitations and potential in contributing to solution. Finally, it also presents ideas concerning possible directions of development, hopefully contributing to solution of this challenging issue.","Affective computing;cognitive architectures; Irrationality; Multi-Agent systems; Rationality; Social simulation","Animation; Cognitive systems; Computer architecture; Signal processing; Software agents; Affective Computing; Cognitive architectures; Current limitation; Human-like agents; Irrationality; Rationality; Social signal processing; Social simulations; Multi agent systems",2-s2.0-84986269537
"Zhang J., Thalmann N.M., Zheng J.","Combining memory and emotion with dialog on social companion: A review",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986253592&doi=10.1145%2f2915926.2915952&partnerID=40&md5=ceb92efed3fba22135dcdfe5c456d50c","In the coming era of social companions, many researches have been pursuing natural dialog interactions and longterm relations between social companions and users. With respect to the quick decrease of user interests after the first few interactions, various emotion and memory models are developed and integrated with social companions for better user engagement. This paper reviews related works in the effort of combining memory and emotion with natural language dialog on social companions. We separate these works into three categories: (1) Affective system with dialog, (2) Task-driven memory with dialog, (3) Chat-driven memory with dialog. In addition, we discussed limitations and challenging issues to be solved. Finally, we also introduced our framework of social companions. © 2016 ACM.","Affective Computing; Episodic Memory; Natural Language Dialog; Social Companion","Human computer interaction; Affective Computing; Episodic memory; Memory models; Natural languages; Social Companion; Three categories; User engagement; User interests; Animation",2-s2.0-84986253592
"Casas D., Feng A., Alexander O., Fyffe G., Debevec P., Ichikari R., Li H., Olszewski K., Suma E., Shapiro A.","Rapid photorealistic blendshape modeling from RGB-D sensors",2016,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986267324&doi=10.1145%2f2915926.2915936&partnerID=40&md5=4e00f5f15196523125f31937c990585a","Creating and animating realistic 3D human faces is an important element of virtual reality, video games, and other areas that involve interactive 3D graphics. In this paper, we propose a system to generate photorealistic 3D blendshape-based face models automatically using only a single consumer RGB-D sensor. The capture and processing requires no artistic expertise to operate, takes 15 seconds to capture and generate a single facial expression, and approximately 1 minute of processing time per expression to transform it into a blendshape model. Our main contributions include a complete end-To-end pipeline for capturing and generating photorealistic blendshape models automatically and a registration method that solves dense correspondences between two face scans by utilizing facial landmarks detection and optical flows. We demonstrate the effectiveness of the proposed method by capturing different human subjects with a variety of sensors and puppeteering their 3D faces with real-Time facial performance retargeting. The rapid nature of our method allows for just-in-Time construction of a digital face. To that end, we also integrated our pipeline with a virtual reality facial performance capture system that allows dynamic embodiment of the generated faces despite partial occlusion of the user's real face by the head-mounted display. © 2016 ACM.","Animation; Blendshapes; Face modeling; RGB-D","Animation; Face recognition; Helmet mounted displays; Pipelines; Virtual reality; Blendshapes; Dense correspondences; Face modeling; Facial Expressions; Head mounted displays; Partial occlusions; Performance capture; Registration methods; Three dimensional computer graphics",2-s2.0-84986267324
"Podkosova I., Urbanek M., Kaufmann H.","A hybrid sound model for 3D audio games with real walking",2016,"ACM International Conference Proceeding Series",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986249774&doi=10.1145%2f2915926.2915948&partnerID=40&md5=2de976839c4d592c545cf0436fac3ac8","Spatialized audio is the only output that players receive in audio games. In order to provide a realistic view of the environment, it has to be of superior quality in terms of immersion and realism. Complex sound models can be used to generate realistic sound effects, including reections and reverb. An implementation of a hybrid sound model based on the ODEON approach is introduced and adapted for realtime sound calculations. This model is evaluated and compared to a baseline model usually used in audio games in a user study in a virtual reality environment. The results show that the implemented hybrid model allows players to adjust to the game faster and provides them more support in avoiding virtual obstacles in simple room geometries than the baseline model. © 2016 ACM.","Audio games; Virtual reality","Animation; Audio acoustics; Virtual reality; Audio games; Baseline models; Complex sounds; Room geometries; Sound modeling; Spatialized audio; Virtual obstacle; Virtual-reality environment; Three dimensional computer graphics",2-s2.0-84986249774
"Kuster C.P., Ranieri N., Bazin J.-C., Martin T., Laffont P.-Y., Popa T., Gross M.","An immersive bidirectional system for life-size 3D communication",2016,"ACM International Conference Proceeding Series",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986266765&doi=10.1145%2f2915926.2915931&partnerID=40&md5=11df04d10e56ab3910ecfd7875d9f8bf","Telecommunication and video conferencing are an integral part of modern society with implications in many aspects of everyday life. However, compared to a meeting in person, the sense of presence is still limited in electronic communication. In this paper, we present a novel system for life-size 3D telecommunication. It is designed to create an immersive user experience by seamlessly embedding a remote conversation partner into the local environment. To achieve this, users are captured in 3D by hybrid (color+depth) sensors and displayed on a life-size transparent 3D display. We have built two instances of this system in Zurich and Singapore. They form a complete and fully functional prototype enabling bidirectional communication in real-Time over a long distance. We further demonstrate alternative hardware setups, which make our system exible and adaptable to different usage scenarios.","3D displays; 3D video processing; Telecommunication; Telepresence systems","Animation; Display devices; Telecommunication; Video conferencing; Video signal processing; Visual communication; 3-D displays; 3-D videos; Bi-directional communication; Bidirectional system; Electronic communications; Functional Prototypes; Sense of presences; Tele-presence systems; Three dimensional computer graphics",2-s2.0-84986266765
[No author name available],"2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016",2016,"2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977668427&partnerID=40&md5=4f4e00c55dc82af984c5bd5bcd90d933","The proceedings contain 189 papers. The topics discussed include: optimal feature learning and discriminative framework for polarimetric thermal to visible face recognition; discovery of facial motions using deep machine perception; customized expression recognition for performance-driven cutout character animation; going deeper in facial expression recognition using deep neural networks; discriminative FaceTopics for face recognition via latent Dirichlet allocation; can we still avoid automatic face detection?; OpenFace: an open source facial behavior analysis toolkit; correlation filter cascade for facial landmark localization; face recognition using deep multi-pose representations; effect of illicit drug abuse on face recognition; unconstrained face verification using deep CNN features; frontal to profile face verification in the wild; and capturing facial videos with kinect 2.0: a multithreaded open source tool and database.",,,2-s2.0-84977668427
"Shoufan A.","Epistemic fidelity and cognitive constructivism in DLD-VISU",2016,"IEEE Global Engineering Education Conference, EDUCON",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994585621&doi=10.1109%2fEDUCON.2016.7474642&partnerID=40&md5=be5b969167328a91710bdffd5fbcbc41","DLD-VISU is web-based tools for the visualization and animation of digital logic design. Combinatorial circuits can be built using logic gates, multiplexers, decoders, and look-up tables. Various configurations of finite state machines can be selected to define the machine type, the state code, and the flip-flop type. Logic minimization with the K-map approach and the Quine McCluskey scheme is also supported. The tools help students practice related topics in digital logic design courses. Also, instructors can use the tools to efficiently generate and verify examples for lecture notes or for homework problems and assignments. The tools support self-assessment and reflect the student learning process using learning curves. DLD-VISU that was developed in collaboration between Khalifa University and Technische Universität Darmstadt, has been used in teaching digital logic design since Fall 2013 with a positive impact on student's motivation and learning. The paper outlines the main features of DLD-VISU with focus on the pedagogical concepts in the design of these tools. © 2016 IEEE.","cognitive constructivism; digital logic design; eLearning; Epistemic fidelity; visualization","Combinatorial circuits; Computer circuits; Curricula; Education; Engineering education; Flip flop circuits; Flow visualization; Logic design; Logic Synthesis; Reconfigurable hardware; Students; Table lookup; Teaching; Visualization; cognitive constructivism; Digital logic design; Epistemic fidelity; Learning curves; Logic minimization; Self assessment; Student learning process; Web-based tools; E-learning",2-s2.0-84994585621
"Mahato N.K., Montuelle S., Cotton J., Williams S., Thomas J., Clark B.","Development of a morphology-based modeling technique for tracking solid-body displacements: Examining the reliability of a potential MRI-only approach for joint kinematics assessment",2016,"BMC Medical Imaging",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969582293&doi=10.1186%2fs12880-016-0140-1&partnerID=40&md5=5ed3e2e388bd2891363e1d33ea48b139","Background: Single or biplanar video radiography and Roentgen stereophotogrammetry (RSA) techniques used for the assessment of in-vivo joint kinematics involves application of ionizing radiation, which is a limitation for clinical research involving human subjects. To overcome this limitation, our long-term goal is to develop a magnetic resonance imaging (MRI)-only, three dimensional (3-D) modeling technique that permits dynamic imaging of joint motion in humans. Here, we present our initial findings, as well as reliability data, for an MRI-only protocol and modeling technique. Methods: We developed a morphology-based motion-analysis technique that uses MRI of custom-built solid-body objects to animate and quantify experimental displacements between them. The technique involved four major steps. First, the imaging volume was calibrated using a custom-built grid. Second, 3-D models were segmented from axial scans of two custom-built solid-body cubes. Third, these cubes were positioned at pre-determined relative displacements (translation and rotation) in the magnetic resonance coil and scanned with a T1 and a fast contrast-enhanced pulse sequences. The digital imaging and communications in medicine (DICOM) images were then processed for animation. The fourth step involved importing these processed images into an animation software, where they were displayed as background scenes. In the same step, 3-D models of the cubes were imported into the animation software, where the user manipulated the models to match their outlines in the scene (rotoscoping) and registered the models into an anatomical joint system. Measurements of displacements obtained from two different rotoscoping sessions were tested for reliability using coefficient of variations (CV), intraclass correlation coefficients (ICC), Bland-Altman plots, and Limits of Agreement analyses. Results: Between-session reliability was high for both the T1 and the contrast-enhanced sequences. Specifically, the average CVs for translation were 4.31 % and 5.26 % for the two pulse sequences, respectively, while the ICCs were 0.99 for both. For rotation measures, the CVs were 3.19 % and 2.44 % for the two pulse sequences with the ICCs being 0.98 and 0.97, respectively. A novel biplanar imaging approach also yielded high reliability with mean CVs of 2.66 % and 3.39 % for translation in the x- and z-planes, respectively, and ICCs of 0.97 in both planes. Conclusions: This work provides basic proof-of-concept for a reliable marker-less non-ionizing-radiation-based quasi-dynamic motion quantification technique that can potentially be developed into a tool for real-time joint kinematics analysis. © 2016 Mahato et al.","Back pain; Dynamic sequence; MRI; Scientific rotoscoping; Stereophotogrammetry","biomechanics; devices; human; image processing; nuclear magnetic resonance imaging; procedures; radiostereometric analysis; reproducibility; software; Biomechanical Phenomena; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Radiostereometric Analysis; Reproducibility of Results; Software",2-s2.0-84969582293
"Lin L., Atkinson R.K., Savenye W.C., Nelson B.C.","Effects of visual cues and self-explanation prompts: empirical evidence in a multimedia environment",2016,"Interactive Learning Environments",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902707307&doi=10.1080%2f10494820.2014.924531&partnerID=40&md5=f99af98f119c88f5478fbd0b6f48f0d2","The purpose of this study was to investigate the impacts of visual cues and different types of self-explanation prompts on learning, cognitive load, and intrinsic motivation in an interactive multimedia environment that was designed to deliver a computer-based lesson about the human cardiovascular system. A total of 126 college students were randomly assigned in equal numbers (N = 21) to one of the six conditions in a 2 × 3 factorial design with visual cueing (cueing vs. no cueing) and type of self-explanation prompts (prediction prompts vs. reflection prompts vs. no prompts) as the between-subjects factors. The results revealed that (a) participants presented with cued animations had significantly higher learning outcome scores than their peers who viewed uncued animations, and (b) cognitive load and intrinsic motivation had different impacts on learning outcomes due to the moderation effect of cueing. The results suggest that the cues may not only enhance learning, but also indirectly impact learning, cognitive load, and intrinsic motivation. © 2014 Informa UK Limited, trading as Taylor & Francis Group.","cognitive load; intrinsic motivation; multimedia learning; self-explanation prompt; visual cueing",,2-s2.0-84902707307
"Basori A.H., Alkawaz M.H., Saba T., Rehman A.","An overview of interactive wet cloth simulation in virtual reality and serious games",2016,"Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006202810&doi=10.1080%2f21681163.2016.1178600&partnerID=40&md5=8aac06400def5b814302d81e2704dbd3","Cloth simulation is an area of research in domain of computer graphics, that assists actors/actress to wear such clothes that seem real using animated techniques. In this paper, we discuss a panoramic overview on computer graphics cloth simulation and modelling techniques such as firstly geometrical methods which utilise geometrical equations to generate cloth-like visualisations without taking into account the cloth apparent characteristics, secondly these approaches in dynamic cloth simulation are connected to fabric engineering field including three types which are the mass-spring model, particle-based system and elastically deformable model and thirdly hybrid methods that combine physical and geometrical methods essentially to arrive at a more complex simulation model are highlighted. The advance cloth simulation which stated that the cloth simulation is a mixture of a many methods and strategies, which involves mechanical simulation, statistical integration, collision recognition, constraints, and rendering approaches for creating clothes is discussed. Physical modelling phase and collision handling phase are critically inspected. The interaction between fluids and rigid and elastic bodies that boosts the complexity of fluids’ motion is discussed.. © 2016 Informa UK Limited, trading as Taylor & Francis Group","Cloth animation; cloth modelling; fluid interaction; modelling techniques",,2-s2.0-85006202810
"Yoon S., Kapadia M., Sahu P., Pavlovic V.","Filling in the blanks: Reconstructing microscopic crowd motion from multiple disparate noisy sensors",2016,"2016 IEEE Winter Applications of Computer Vision Workshops, WACVW 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977608498&doi=10.1109%2fWACVW.2016.7470118&partnerID=40&md5=3e2edfb1d15977a0a495941a4aa93e53","Tracking the movement of individuals in a crowd is an indispensable component to reconstructing crowd movement, with applications in crowd surveillance and data-driven animation. Typically, multiple sensors are distributed over wide area and often they have incomplete coverage of the area or the input introduces noise due to the tracking algorithm or hardware failure. In this paper, we propose a novel refinement method that complements existing crowd tracking solutions to reconstruct a holistic view of the microscopic movement of individuals in a crowd, from noisy tracked data with missing and even incomplete information. Central to our approach is a global optimization based trajectory estimation with modular objective functions. We empirically demonstrate the potential utility of our approach in various scenarios that are standard in crowd dynamic analysis and simulations.",,"Global optimization; Analysis and simulation; Crowd surveillance; Data-driven animation; Incomplete information; Microscopic movements; Objective functions; Refinement methods; Trajectory estimation; Computer vision",2-s2.0-84977608498
"Zubrzycki M., Raczkowski J.","Surface Tension and Wettability Modeling for Flowing Liquids",2016,"Proceedings - Computer Graphics, Imaging and Visualization: New Techniques and Trends, CGiV 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973667730&doi=10.1109%2fCGiV.2016.12&partnerID=40&md5=0a5cec53fcc5376491e78061b85c8a78","The presented simulation model of surface tension and wettability based on physical properties of liquids is designed for use in computer graphics. Due to the relatively small surface tension forces the model is useful for simulating liquid of small volume such as droplets. This model can be used in conjunction with various fluid simulation methods, one of the most popular - Marker and Cell - has been selected for this paper. The paper describes also a simple and rapid method of determining the liquid surface as a mesh of triangles. The presented method improves the final visual effect and is well suited for determining the surface of the droplets. The simulation method was applied to create realistic animations of flowing liquid droplets of different types. © 2016 IEEE.","animation; computational fluid dynamics; liquid simulation; liquid surface; natural phenomena","Animation; Computational fluid dynamics; Computer graphics; Drops; Liquids; Surface tension; Visualization; Wetting; Flowing liquid; Fluid simulations; Liquid simulations; Liquid surface; Marker-and-cell; Natural phenomena; Simulation model; Surface tension force; Fluids",2-s2.0-84973667730
"Yu J., Xie Z., Huang D., Ding Y., Tang S., Ma L.","Real-time 2.5D facial cartoon animation based on pose and expression estimation",2016,"Proceedings - 2015 International Conference on Virtual Reality and Visualization, ICVRV 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978523956&doi=10.1109%2fICVRV.2015.62&partnerID=40&md5=50546d5c3d916b675d52cf851764d26b","In this paper, a real-time facial animation system is presented, that captures live facial expressions and poses from user, and uses them to animate a synthetic 2.5D cartoon character (Avatar) in real-time. Compared to existing 3D Avatar systems, the 2.5D cartoon models are easier to create than full 3D model, and the cartoon-style drawings are more popular among young people. Our system requires only an ordinary PC camera, and the initialization is fully automatic. We established a mapping from real-time facial motion to the atomic motion parameters of the cartoon model by pose and expression estimation. The animation is driven by these parameters in the way of blend shape interpolation. © 2015 IEEE.","Avatar; Blendshape; Cartoon; Facial animation","Animation; Virtual reality; Visualization; Avatar; Blendshape; Cartoon; Cartoon animation; Cartoon characters; Facial animation; Facial Expressions; Shape interpolation; Three dimensional computer graphics",2-s2.0-84978523956
"Kazi R.H., Grossman T., Umetani N., Fitzmaurice G.","Skuid: Sketching dynamic illustrations using the principles of 2D animation",2016,"Conference on Human Factors in Computing Systems - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015078051&doi=10.1145%2f2858036.2858386&partnerID=40&md5=7a992628bb8518f3fe69abd2afff1ea0","We present Skuid, a sketching tool for crafting animated illustrations that contain the exaggerated dynamics of stylized 2D animations. Skuid provides a set of motion amplifiers which implement a set of established principles of 2D animation. These amplifiers break down a complex animation effect into independent, understandable chunks. Each amplifier imposes deformations to an underlying grid, which in turn updates the corresponding strokes. Users can combine these amplifiers at will when applying them to an existing animation, promoting rapid experimentation. Skuid leverages the freeform nature of sketching, allowing users to rapidly sketch, record motion, explore exaggerated dynamics using the amplifiers, and fine-tune their animations. Practical results confirm that users with no prior experience in animation can produce expressive animated illustrations quickly and easily with Skuid. © 2016 ACM.","Amplifiers; Principles of animation; Sketching; Stylized","Amplifiers (electronic); Human computer interaction; Human engineering; 2D animation; Animation effects; Break down; Motion amplifier; Prior experience; Sketching; Sketching tools; Stylized; Animation",2-s2.0-85015078051
"Momeni A., Rispoli Z.","Dranimate: Paper becomes tablet, drawing becomes animation",2016,"Conference on Human Factors in Computing Systems - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014640761&doi=10.1145%2f2851581.2890267&partnerID=40&md5=1b334dcdb90b0698d20afd8abfea44e7","Dranimate is an interactive animation system that allows users to rapidly and intuitively rig and control animations based on a still image or drawing using hand gestures. Dranimate combines two complementary methods of shape manipulation: bone-joint-based physics simulation and the as-rigid-as-possible deformation algorithm. Dranimate also introduces a number of designed interactions created around the metaphor of an image on a tablet screen replacing a physical drawing. The interactions focus the users attention on the animated content, as opposed to computer keyboard, mouse, or tablet surface while enabling natural and intuitive interactions with personalized digital content. © 2016 Authors.","Animation; Gestural control; Mobile; Playful; Puppetry","Human computer interaction; Human engineering; Complementary methods; Gestural control; Interactive animations; Intuitive interaction; Mobile; Playful; Puppetry; Shape manipulation; Animation",2-s2.0-85014640761
"Haworth B., Khayatkhoei M., Usman M., Kapadia M., Berseth G., Faloutsos P.","Towards computer assisted crowd aware architectural design",2016,"Conference on Human Factors in Computing Systems - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014671036&doi=10.1145%2f2851581.2892360&partnerID=40&md5=d81be2ec92dc9c8ab54096e1e209979b","We present a preliminary exploration of an architectural optimization process towards a computational tool for designing environments (e.g., building floor plans). Using dynamic crowd simulators we derive the fitness of architectural layouts. The results of the simulation are used to provide feedback to a user in terms of crowd animation, aggregate statistics, and heat maps. Our approach automatically optimizes the placement of environment elements to maximize the flow of the crowd, while satisfying constraints that are imposed by the user (e.g., immovable walls or support bearing structures). We take steps towards user-in-the-loop optimization and design of an environment by applying an adaptive refinement approach to reduce the search space of the optimization. We perform a small scale user study to obtain early feedback on the performance and quality of our method in contrast with a manual approach. © 2016 Authors.","Architectural optimization; Crowd simulation; User-in-the-loop design","Human computer interaction; Human engineering; Adaptive refinement; Computational tools; Computer assisted; Crowd animation; Crowd Simulation; Loop design; Loop optimizations; Support bearings; Architectural design",2-s2.0-85014671036
"Hohenstein J., Khan H., Canfield K., Tung S., Cano R.P.","Shorter wait times: The effects of various loading screens on perceived performance",2016,"Conference on Human Factors in Computing Systems - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014640978&doi=10.1145%2f2851581.2892308&partnerID=40&md5=7e4c26ebf16a4c275c785ac2d2f9de70","Loading screens are unavoidable in modern software applications, and providing graphical user feedback during wait times is a well-established way to increase perceived performance. Previous research has indicated that perceived performance is essential to the success of an application, and progress bars have been specifically shown to decrease perceived wait time. This study is the first to examine the effect of animated loading screens on perceived wait time as compared to the popular progress bar. Study participants compared a progress bar with both a passive and interactive animation. Results suggest that with an interactive animation, perceived wait time is shorter and user satisfaction is higher than with a progress bar or passive animation. © 2016 Authors.","Design; Human factors; Loading; Perceived performance; Perception","Animation; Application programs; Design; Human engineering; Loading; Sensory perception; Interactive animations; Perceived performance; Software applications; User feedback; User satisfaction; Wait time; Human computer interaction",2-s2.0-85014640978
"Merz B., Tuch A.N., Opwis K.","Perceived user experience of Animated transitions in mobile user interfaces",2016,"Conference on Human Factors in Computing Systems - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014619475&doi=10.1145%2f2851581.2892489&partnerID=40&md5=fb7c8392fd86f5952088d9780b20a7c4","Animated transitions are an important part of graphical user interface design practice. They can help to guide users' attention and highlight changes in the interface. However, there is only little empirical research on how such animated transitions influence the users' perception of an interface. We therefore aim to investigate how different animation principles for animated transitions in mobile applications influence perceived user experience. In this late breaking work we present the results of a pilot study in which we tested the suitability of different animated transitions for our main study. Moreover, we outline a tentative design and procedure of the main study. We plan to recruit over 250 participants that will rate different styles of animated transitions in regard to perceived pragmatic and hedonic quality. Our findings are expected to provide insights in users' perception of animation styles and therefore to have implications for graphical user interface design practice. © 2016 Authors.","Animated transitions; User experience; User interface design","Animation; Graphical user interfaces; Human computer interaction; Human engineering; Animated transitions; Animation principles; Empirical research; Mobile applications; Mobile user interface; User experience; User interface designs; Users' perception; User interfaces",2-s2.0-85014619475
"Tiab J., Hornbæk K.","Understanding affordance, system state, and feedback in shape-changing buttons",2016,"Conference on Human Factors in Computing Systems - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015023145&doi=10.1145%2f2858036.2858350&partnerID=40&md5=9033ecb857fe40f59ff2454cff111e7f","Research on shape-changing interfaces has explored various technologies, parameters for shape changes, and transformations between shapes. While much is known about how to implement these variations, it is unclear what affordance they provide, how users understand their relation to the underlying system state, and how feedback via shape change is perceived. We investigated this by studying how 15 participants perceived and used 13 shape-changing buttons. The buttons covered several aspects of affordance, system state, and feedback, including invite-to-touch movements, two styles of transition animation, and two actuation technologies. Participants explored and interacted with the buttons while thinking aloud. The results show that affordances are hard to communicate clearly with shape change; while some movements invited actions, others were seen as a malfunction. The best clue as to button state was provided by the position of the button in combination with vibration. Linear transition animation for changes in button state was the best received form of shape-change feedback. We discuss also how these findings can inform the design of shape-changing interfaces more generally. © 2016 ACM.","Affordance; Empirical study; Feedback; Shape-changing interfaces; System state","Animation; Fasteners; Feedback; Human computer interaction; Human engineering; Actuation technologies; Affordances; Empirical studies; Linear transitions; System state; Transition animation; Underlying systems; Various technologies; Interface states",2-s2.0-85015023145
"Kazi R.H., Grossman T., Mogk C., Schmidth R., Fitzmaurice G.","ChronoFab: Fabricating motion",2016,"Conference on Human Factors in Computing Systems - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015047880&doi=10.1145%2f2858036.2858138&partnerID=40&md5=fa5095472d6470bb7512b9c1ae5dd061","We present ChronoFab, a 3D modeling tool to craft motion sculptures, tangible representations of 3D animated models, visualizing an object's motion with static, transient, ephemeral visuals that are left behind. Our tool casts 3D modeling as a dynamic art-form by employing 3D animation and dynamic simulation for the modeling of motion sculptures. Our work is inspired by the rich history of stylized motion depiction techniques in existing 3D motion sculptures and 2D comic art. Based on a survey of such techniques, we present an interface that enables users to rapidly explore and craft a variety of static 3D motion depiction techniques, including motion lines, multiple stroboscopic stamps, sweeps and particle systems, using a 3D animated object as input. In a set of professional and non-professional usage sessions, ChronoFab was found to be a superior tool for the authoring of motion sculptures, compared to traditional 3D modeling workflows, reducing task completion times by 79%. © 2016 ACM.","Animation; Fabrication; Motion sculpture","Animation; Fabrication; Human engineering; 3-d modeling; 3D animation; 3D modeling tools; Animated models; Completion time; Motion sculpture; Particle systems; Work-flows; Human computer interaction",2-s2.0-85015047880
"Everitt A., Taher F., Alexander J.","ShapeCanvas: An exploration of Shape-changing content generation by members of the public",2016,"Conference on Human Factors in Computing Systems - Proceedings",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015076765&doi=10.1145%2f2858036.2858316&partnerID=40&md5=4aae844b622778686865755a435be482","Shape-changing displays - visual output surfaces with physically-reconfigurable geometry - provide new challenges for content generation. Content design must incorporate visual elements, physical surface shape, react to user input, and adapt these parameters over time. The addition of the 'shape channel' significantly increases the complexity of content design, but provides a powerful platform for novel physical design, animations, and physicalizations. In this work we use ShapeCanvas, a 4×4 grid of large actuated pixels, combined with simple interactions, to explore novice user behavior and interactions for shape-change content design. We deployed ShapeCanvas in a café for two and a half days and observed users generate 21 physical animations. These were categorized into seven categories and eight directly derived from people's personal interest. This paper describes these experiences, the generated animations and provides initial insights into shape-changing content design. © 2016 ACM.","Content design; Physical animation; Shape-changing displays; User interaction","Graphical user interfaces; Human computer interaction; Human engineering; Content design; Physical design; Reconfigurable; Shape-changing displays; Surface shape; User interaction; Visual elements; Visual outputs; Behavioral research",2-s2.0-85015076765
"Bakhshi S., Shamma D.A., Kennedy L., Song Y., De Juan P., Kaye J.","Fast, cheap, and good: Why Animated GIFs engage us",2016,"Conference on Human Factors in Computing Systems - Proceedings",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997514830&doi=10.1145%2f2858036.2858532&partnerID=40&md5=85bd1209e25780bb8a6b9ee1c7d50aa9","Animated GIFs have been around since 1987 and recently gained more popularity on social networking sites. Tumblr, a large social networking and micro blogging platform, is a popular venue to share animated GIFs. Tumblr users follow blogs, generating a feed of posts, and choose to ""like"" or to ""reblog"" favored posts. In this paper, we use these actions as signals to analyze the engagement of over 3.9 million posts, and conclude that animated GIFs are significantly more engaging than other kinds of media. We follow this finding with deeper visual analysis of nearly 100k animated GIFs and pair our results with interviews with 13 Tumblr users to find out what makes animated GIFs engaging. We found that the animation, lack of sound, immediacy of consumption, low bandwidth and minimal time demands, the storytelling capabilities and utility for expressing emotions were significant factors in making GIFs the most engaging content on Tumblr. We also found that engaging GIFs contained faces and had higher motion energy, uniformity, resolution and frame rate. Our findings connect to media theories and have implications in design of effective content dashboards, video summarization tools and ranking algorithms to enhance engagement. © 2016 ACM.","Animated GIFs; Content analysis; Regression analysis; Social media analysis; Tumblr; Visual analysis","Computation theory; Human computer interaction; Human engineering; Regression analysis; Animated GIFs; Content analysis; Social media analysis; Tumblr; Visual analysis; Social networking (online)",2-s2.0-84997514830
"Demir I., Kehrer J., Westermann R.","Screen-space silhouettes for visualizing ensembles of 3D isosurfaces",2016,"IEEE Pacific Visualization Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973621338&doi=10.1109%2fPACIFICVIS.2016.7465271&partnerID=40&md5=830e608ad2b60a4d81db9b0a0ff62ed8","Visualizing sets of isosurfaces from 3D scalar ensemble fields is a difficult task due to inherent occlusion effects, yet it is often required to analyze the uncertainty represented by such an ensemble. In this paper, we present a novel visualization technique for ensembles of isosurfaces based on screen-space silhouettes. By using silhouettes, the displayed information is reduced to avoid occlusions, yet the major shape of the surfaces can be maintained. Our approach preserves spatial coherence and does not make any assumption about the underlying surface distribution. By providing additional mechanisms, i.e., picking, clustering, cutting and animation, we enable the user to explore an ensemble of surfaces interactively. © 2016 IEEE.","I.3.3 [Computer Graphics]: Picture/Image Generation - Display algorithms","Computer graphics; Uncertainty analysis; 3-D scalar; I.3.3 [computer graphics]: Picture/image generation- display algorithms; Iso surface; Novel visualizations; Occlusion effect; Screen space; Spatial coherence; Underlying surface; Visualization",2-s2.0-84973621338
"Lee W., Kim H., Ahn J.","Three-dimensional rearrangement of single atoms using actively controlled optical microtraps",2016,"Optics Express",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964872500&doi=10.1364%2fOE.24.009816&partnerID=40&md5=64e926ac9367e9bcec283112e7d55c30","We propose and demonstrate three-dimensional rearrangements of single atoms. In experiments performed with single 87Rb atoms in optical microtraps actively controlled by a spatial light modulator, we demonstrate various dynamic rearrangements of up to N = 9 atoms including rotation, 2D vacancy filling, guiding, compactification, and 3D shuffling. With the capability of a phase-only Fourier mask to generate arbitrary shapes of the holographic microtraps, it was possible to place single atoms at arbitrary geometries of a few μm size and even continuously reconfigure them by conveying each atom. For this purpose, we loaded a series of computer-generated phase masks in the full frame rate of 60 Hz of the spatial light modulator, so the animation of phase mask transformed the holographic microtraps in real time, driving each atom along the assigned trajectory. Possible applications of this method of transformation of single atoms include preparation of scalable quantum platforms for quantum computation, quantum simulation, and quantum many-body physics. © 2016 Optical Society of America.",,"Atoms; Computer generated holography; Holography; Quantum chemistry; Quantum computers; Arbitrary geometry; Arbitrary shape; Compactification; Computer generated; Micro-traps; Quantum simulations; Single atoms; Spatial light modulators; Light modulators",2-s2.0-84964872500
"Hyun K., Lee K., Lee J.","Motion grammars for character animation",2016,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971281847&doi=10.1111%2fcgf.12815&partnerID=40&md5=c8eb6b4f6be2e4377889ab78b8455434","The behavioral structure of human movements is imposed by multiple sources, such as rules, regulations, choreography, habits, and emotion. Our goal is to identify the behavioral structure in a specific application domain and create a novel sequence of movements that abide by structure-building rules. To do so, we exploit the ideas from formal language, such as rewriting rules and grammar parsing, and adapted those ideas to synthesize the three-dimensional animation of multiple characters. The structured motion synthesis using motion grammars is formulated in two layers. The upper layer is a symbolic description that relates the semantics of each individual's movements and the interaction among them. The lower layer provides spatial and temporal contexts to the animation. Our multi-level MCMC (Markov Chain Monte Carlo) algorithm deals with the syntax, semantics, and spatiotemporal context of human motion to produce highly-structured, animated scenes. The power and effectiveness of motion grammars are demonstrated in animating basketball games from drawings on a tactic board. Our system allows the user to position players and draw out tactical plans, which are animated automatically in virtual environments with three-dimensional, full-body characters. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Behavioral research; Formal languages; Markov processes; Semantics; Syntactics; Virtual reality; Basketball games; Character animation; Human movements; Markov Chain Monte-Carlo; Motion synthesis; Multiple source; Symbolic description; Three-dimensional animations; Animation",2-s2.0-84971281847
"Barrielle V., Stoiber N., Cagniart C.","BlendForces: A dynamic framework for facial animation",2016,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971321482&doi=10.1111%2fcgf.12836&partnerID=40&md5=66abef783c2325bb5dcd9a47990ad147","In this paper we present a new paradigm for the generation and retargeting of facial animation. Like a vast majority of the approaches that have adressed these topics, our formalism is built on blendshapes. However, where prior works have generally encoded facial geometry using a low dimensional basis of these blendshapes, we propose to encode facial dynamics by looking at blendshapes as a basis of forces rather than a basis of shapes. We develop this idea into a dynamic model that naturally combines the blendshapes paradigm with physics-based techniques for the simulation of deforming meshes. Because it escapes the linear span of the shape basis through time-integration and physics-inspired simulation, this approach has a wider expressive range than previous blendshape-based methods. Its inherent physically-based formulation also enables the simulation of more advanced physical interactions, such as collision responses on lip contacts. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Animation; Collision response; Dynamic framework; Facial animation; Facial geometry; Low dimensional; Physical interactions; Physically based; Time integration; Dynamics",2-s2.0-84971321482
"Li G., Ouyang Y., Wei G., Zhang Z., Mao A.","Enhanced rig-space simulation",2016,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969601798&doi=10.1002%2fcav.1705&partnerID=40&md5=cac2ab6aeb2f251727679e06891b139c","Rig-space physics a finite element method(FEM) based simulation technique that aims at adding secondary motion on a character while maintaining seamless cooperation with traditional animation pipelines. We enhance the rig-space physics by introducing several techniques, including general field interaction, proportional-derivative control, and improved material control. This allows an animator to perform various interferences to the simulation process and create more abundant animation effects. Moreover, we also improve the numerical stability of the simulation algorithm by prepending a conjugate gradient procedure. We allow user to define various fields, which are not necessarily conservative, on the mesh model to be simulated. We introduce proportional-derivative control to specify target rig-parameter trajectories and strength of control forces and therefore are able to trace the target trajectories as an entity. We improve the numerical stability for some tricky situations by prepending a conjugate gradient procedure to the original algorithm. © 2016 John Wiley & Sons, Ltd.","computer animation; parametric space; physically based modeling; rigging; secondary motion","Animation; Conjugate gradient method; Computer animation; Parametric spaces; Physically based modeling; rigging; Secondary motion; Finite element method",2-s2.0-84969601798
"Tonneau S., Al-Ashqar R.A., Pettré J., Komura T., Mansard N.","Character contact re-positioning under large environment deformation",2016,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971268501&doi=10.1111%2fcgf.12817&partnerID=40&md5=e5ebb915ea46936112f79061bfd026b1","Character animation based on motion capture provides intrinsically plausible results, but lacks the flexibility of procedural methods. Motion editing methods partially address this limitation by adapting the animation to small deformations of the environment. We extend one such method, the so-called relationship descriptors, to tackle the issue of motion editing under large environment deformations. Large deformations often result in joint limits violation, loss of balance, or collisions. Our method handles these situations by automatically detecting and re-positioning invalidated contacts. The new contact configurations are chosen to preserve the mechanical properties of the original contacts in order to provide plausible support phases. When it is not possible to find an equivalent contact, a procedural animation is generated and blended with the original motion. Thanks to an optimization scheme, the resulting motions are continuous and preserve the style of the reference motions. The method is fully interactive and enables the motion to be adapted on-line even in case of large changes of the environment. We demonstrate our method on several challenging scenarios, proving its immediate application to 3D animation softwares and video games. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Deformation; Motion picture editing machines; Three dimensional computer graphics; Character animation; Joint limits; Motion capture; Motion editing; Optimization scheme; Procedural animation; Small deformations; Support phasis; Animation",2-s2.0-84971268501
"Choi J.-I., Kim S.-J., Kim C.-H., Lee J.","Let's be a virtual juggler",2016,"Computer Animation and Virtual Worlds",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979493634&doi=10.1002%2fcav.1701&partnerID=40&md5=c1b330a60ad113927703979311cf9298","Juggling, which uses both hands to keep several objects in the air at once, is admired by anyone who sees it. However, skillful real-world juggling requires long, hard practice. Therefore, we propose an interesting method to enable anyone to juggle skillfully in the virtual world. In the real world, the human motion has to follow the motion of the moving objects; in the virtual world, the objects' motion can be adjusted together with the human motion. By using this freedom, we have generated a juggling avatar that can follow the user's motion. The user simply makes juggling-like motions in front of a motion sensor. Our system then searches for juggling motions that closely match the user's motions and connects them smoothly. We then generate moving objects that both satisfy the laws of physics and are synchronized with the synthesized motion of the avatar. In this way, we can generate a variety of juggling animations by an avatar in real time. We propose an interesting method to enable anyone to juggle skillfully in the virtual world. The user simply makes juggling-like motions in front of a motion sensor. Our system then searches for juggling motions that closely match the user's motions and connects them smoothly. We then generate moving objects that both satisfy the laws of physics and are synchronized with the synthesized motion of the avatar. © 2016 John Wiley & Sons, Ltd.","character animation; handling objects; physics-based animation; real-time motion control; virtual reality","Animation; Interactive computer graphics; Character animation; Handling objects; Laws of physics; Motion sensors; Moving objects; Physics-based animation; Real-time motion; Virtual worlds; Virtual reality",2-s2.0-84979493634
"Sommer-Trembo C., Zimmer C., Jourdan J., Bierbach D., Plath M.","Predator experience homogenizes consistent individual differences in predator avoidance",2016,"Journal of Ethology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959152624&doi=10.1007%2fs10164-016-0460-1&partnerID=40&md5=c5ecd2648d5fc6ff1963bc03bb503d79","In the presence of predators, many prey species exhibit immediate behavioral responses like the avoidance of risky areas, which imposes opportunity costs, for instance, in the form of reduced foraging. Thus, prey species should be able to discriminate between different predator types and adjust their response to the imminent predation risk. In our current study, we evaluated the relative importance of innate versus learned components of predator recognition and avoidance in the guppy (Poecilia reticulata). We used a feral guppy population occurring in Germany and compared avoidance reactions of each focal individual towards both coevolved piscine predators from their original distribution range and novel, presently co-occurring predator species. Wild-caught, predator-experienced as well as laboratory-reared, predator-naïve individuals showed strong avoidance responses towards all predator animations. Avoidance was stronger in small-bodied than in large-bodied individuals in both cohorts; however, this effect was significant only in predator-naïve fish. Moreover, wild-caught individuals showed a significantly higher within-individual variance (across the six predator species) along with a lower among-individual variance in predator avoidance, which resulted in a lower behavioral repeatability in this cohort. Our results suggest that consistent individual differences in risk-taking behavior (also referred to as the personality trait ‘boldness’) are modified by predator exposure and learning about predators. © 2016, Japan Ethological Society and Springer Japan.","Animal personality; Computer animation; Learning; Poecilia reticulata; Predator recognition; Risk-taking behavior",,2-s2.0-84959152624
"Garrido P., Zollhöfer M., Casas D., Valgaerts L., Varanasi K., Pérez P., Theobalt C.","Reconstruction of personalized 3D face rigs from monocular video",2016,"ACM Transactions on Graphics",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971500820&doi=10.1145%2f2890493&partnerID=40&md5=afb376a96be2021b813c0831a5a9e0e2","We present a novel approach for the automatic creation of a personalized high-quality 3D face rig of an actor from justmonocular video data (e.g., vintage movies). Our rig is based on three distinct layers that allow us to model the actor's facial shape as well as capture his person-specific expression characteristics at high fidelity, ranging from coarse-scale geometry to finescale static and transient detail on the scale of folds and wrinkles. At the heart of our approach is a parametric shape prior that encodes the plausible subspace of facial identity and expression variations. Based on this prior, a coarse-scale reconstruction is obtained by means of a novel variational fitting approach.We represent person-specific idiosyncrasies, which cannot be represented in the restricted shape and expression space, by learning a set of medium-scale corrective shapes. Fine-scale skin detail, such as wrinkles, are captured from video via shading-based refinement, and a generative detail formation model is learned. Both the medium- and fine-scale detail layers are coupled with the parametric prior by means of a novel sparse linear regression formulation. Once reconstructed, all layers of the face rig can be conveniently controlled by a low number of blendshape expression parameters, as widely used by animation artists.We show captured face rigs and their motions for several actors filmed in different monocular video formats, including legacy footage from YouTube, and demonstrate how they can be used for 3D animation and 2D video editing. Finally, we evaluate our approach qualitatively and quantitatively and compare to related state-of-the-art methods. © 2016 ACM.","3D model fitting; Blendshapes; Corrective shapes; Facial animation; Shape-from-shading; Video editing","Animation; Video signal processing; Videodisks; 3d model fittings; Blendshapes; Corrective shapes; Facial animation; Shape from shading; Video editing; Three dimensional computer graphics",2-s2.0-84971500820
"Avril Q., Ribet S., Ghafourzadeh D., Dionne O., Ramachandran S., De Lasa M., Fallahdoust S., Paquette E.","Animation setup transfer for 3D characters",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971254714&doi=10.1111%2fcgf.12816&partnerID=40&md5=fe8df2562ed8fa78227965f11bab0544","We present a general method for transferring skeletons and skinning weights between characters with distinct mesh topologies. Our pipeline takes as inputs a source character rig (consisting of a mesh, a transformation hierarchy of joints, and skinning weights) and a target character mesh. From these inputs, we compute joint locations and orientations that embed the source skeleton in the target mesh, as well as skinning weights to bind the target geometry to the new skeleton. Our method consists of two key steps. We first compute the geometric correspondence between source and target meshes using a semi-automatic method relying on a set of markers. The resulting geometric correspondence is then used to formulate attribute transfer as an energy minimization and filtering problem. We demonstrate our approach on a variety of source and target bipedal characters, varying in mesh topology and morphology. Several examples demonstrate that the target characters behave well when animated with either forward or inverse kinematics. Via these examples, we show that our method preserves subtle artistic variations; spatial relationships between geometry and joints, as well as skinning weight details, are accurately maintained. Our proposed pipeline opens up many exciting possibilities to quickly animate novel characters by reusing existing production assets. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Computational geometry; Geometry; Inverse kinematics; Mesh generation; Musculoskeletal system; Pipelines; Topology; Energy minimization; Filtering problems; Joint locations; Mesh topologies; Production assets; Semiautomatic methods; Spatial relationships; Target character; Inverse problems",2-s2.0-84971254714
"Franklin L., Plaisant C., Minhazur Rahman K., Shneiderman B.","TreatmentExplorer: An interactive decision aid for medical risk communication and treatment exploration",2016,"Interacting with Computers",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966350799&doi=10.1093%2fiwc%2fiwu043&partnerID=40&md5=94633d3d0dface6760b304f2492084c4","Medical treatments carry unique benefits and risks which patients must understand in order to decide which option is best for them. Prior research has demonstrated that patients are ill-equipped to understand the statistical information presented to them through standard decision aids. We describe a prototype decision aid, TreatmentExplorer, which supports patients' needs by presenting treatment outcome, onset of symptoms and treatment side effects using a novel graphic representation with staged animation and text-only narration. Our prototype also illustrates the use of a data-driven personalization approach by using electronic health record data. We report on expert reviews, a pilot study ($n=24$) and a main study ($n=42$), which characterize the benefits of TreatmentExplorer over a text-only decision aid as well as a version without staged animation, and conclude with guidelines for designers. © 2014 The Author 2014. Published by Oxford University Press on behalf of The British Computer Society.","animations; graphics systems and interfaces; health care information systems; information visualization; risk communication; user studies","Animation; Health risks; Information systems; Medical computing; Patient treatment; Graphics systems; Health care information system; Information visualization; Risk communication; User study; Decision support systems",2-s2.0-84966350799
"Yang L., Xu T., Wu E.","Animating strokes in drawing process of chinese ink painting",2016,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973390032&partnerID=40&md5=5b5103a79979beaebd1fa16883a713fb","By generating reproducible brush strokes of Chinese ink painting, we propose an animation tool for lively displaying its real drawing process. Contrasted with previous work, we automatically extract this trajectory from the outlines of the shapes to draw and model the brush footprints; first an input image is decomposed into brush strokes. Then we estimate the brush trajectory with shape descriptions and build a brush footprint model to measure the quality of the trajectory constrained by the variation along a stroke of the draw process parameters (e.g., location, size, and orientation). Finally, the trajectories are dynamically rendered into brush strokes with our real-time rendering model. It is particularly useful for appreciation and education of Chinese ink painting. © 2016, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Brush trajectory; Chinese ink painting; Non-photorealistic rendering; Real-time rendering","Computer graphics; Trajectories; Animation tools; Drawing process; Footprint modeling; Ink paintings; Non-Photorealistic Rendering; Process parameters; Real-time rendering; Shape description; Rendering (computer graphics)",2-s2.0-84973390032
"Günther T., Rohmer K., Rössl C., Grosch T., Theisel H.","Stylized caustics: Progressive rendering of animated caustics",2016,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971300519&doi=10.1111%2fcgf.12827&partnerID=40&md5=e1f1b5007b88de0ec78e802dc4446d56","In recent years, much work was devoted to the design of light editing methods such as relighting and light path editing. So far, little work addressed the target-based manipulation and animation of caustics, for instance to a differently-shaped caustic, text or an image. The aim of this work is the animation of caustics by blending towards a given target irradiance distribution. This enables an artist to coherently change appearance and style of caustics, e.g., for marketing applications and visual effects. Generating a smooth animation is nontrivial, as photon density and caustic structure may change significantly. Our method is based on the efficient solution of a discrete assignment problem that incorporates constraints appropriate to make intermediate blends plausibly resemble caustics. The algorithm generates temporally coherent results that are rendered with stochastic progressive photon mapping. We demonstrate our system in a number of scenes and show blends as well as a key frame animation. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Animation; Combinatorial optimization; Photons; Stochastic systems; Assignment problems; Irradiance distribution; Key frames; Marketing application; Photon densities; Progressive photon mappings; Progressive rendering; Visual effects; Rendering (computer graphics)",2-s2.0-84971300519
"De Sainte Croix M.M., Gauld D., Forgie A.H., Lowe R.","Three-dimensional imaging of human cutaneous forearm bite marks in human volunteers over a 4 day period",2016,"Journal of Forensic and Legal Medicine",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962558324&doi=10.1016%2fj.jflm.2016.02.003&partnerID=40&md5=c6d116efbf3e8922b15b34e35eec3399","Introduction Human bite marks are often sustained during sexual, domestic or child abuse. Currently, analysis of these marks involves digital photography techniques along with an expert forensic odontologist opinion. Photographs often focus closely on the bite mark and give little context to the anatomical location of the injury. Due to variation in camera models and expertise of the photographer, photograph quality can affect its interpretation. Additionally, it can sometimes be days between injury and examination, allowing the injury pattern and colour to alter, making it harder to analyse. Aim To investigate if a 3D imaging technique, creating a time-lapse image of a bite mark in three dimensions, can provide context to the injury in terms of nature and location, and also allow analysis of the change in appearance of a bite mark over time. Method Participants had an experimental bite mark produced on their forearm by dental casts mounted on a dental articulator. The forearms were photographed immediately following the bite, and at intervals of 3, 6, 24, 48, 72 and 96 h. A DI3D® (Dimensional Imaging 3D) photogrammetry system and Autodesk Maya 2015® software was used to create a 3D animation from the images obtained. The clearest, long lasting bite mark injuries were selected for animation, enabling the 3D imaging technique to be used optimally. Results 3D time-lapse animations were successfully created with the ability to be viewed on most electronic devices. With further refinement this technique could be valuable in a number of areas. We anticipate animations produced in this way to have significant benefit to the presentation of photographic evidence in a court setting, and in age estimation of injuries. © 2016 Elsevier Ltd and Faculty of Forensic and Legal Medicine. All rights reserved.","3D; Animation; Bite marks; Human; Imaging; Time-lapse","adult; age determination; Article; bite; clinical article; color; controlled study; dental articulator; facial recognition; female; human; injury; male; normal human; photography; three dimensional imaging; time lapse imaging; young adult; bite; dental procedure; dentistry; diagnostic imaging; forearm injury; image processing; photogrammetry; software; time factor; Bites, Human; Dental Models; Female; Forearm Injuries; Forensic Dentistry; Healthy Volunteers; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Male; Photogrammetry; Software; Time Factors",2-s2.0-84962558324
"Brandt C., Von Tycowicz C., Hildebrandt K.","Geometric flows of curves in shape space for processing motion of deformable objects",2016,"Computer Graphics Forum",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971260504&doi=10.1111%2fcgf.12832&partnerID=40&md5=ddb217944211b5aa4a2c0b4a6113829d","We introduce techniques for the processing of motion and animations of non-rigid shapes. The idea is to regard animations of deformable objects as curves in shape space. Then, we use the geometric structure on shape space to transfer concepts from curve processing in ℝn to the processing of motion of non-rigid shapes. Following this principle, we introduce a discrete geometric flow for curves in shape space. The flow iteratively replaces every shape with a weighted average shape of a local neighborhood and thereby globally decreases an energy whose minimizers are discrete geodesics in shape space. Based on the flow, we devise a novel smoothing filter for motions and animations of deformable shapes. By shortening the length in shape space of an animation, it systematically regularizes the deformations between consecutive frames of the animation. The scheme can be used for smoothing and noise removal, e.g., for reducing jittering artifacts in motion capture data. We introduce a reduced-order method for the computation of the flow. In addition to being efficient for the smoothing of curves, it is a novel scheme for computing geodesics in shape space. We use the scheme to construct non-linear ""Bézier curves"" by executing de Casteljau's algorithm in shape space. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Animation; Deformation; Geometry; Iterative methods; Rigid structures; Deformable object; Deformable shapes; Discrete geodesic; Geometric structure; Local neighborhoods; Motion capture data; Reduced-order methods; Smoothing filters; Curve fitting",2-s2.0-84971260504
"Li R., Yu J., Luo C., Wang Z.","3D visualization method for tongue movements in pronunciation",2016,"Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975142571&doi=10.16451%2fj.cnki.issn1003-6059.201605001&partnerID=40&md5=b459953116cd19c26d134852848df5b9","Problem of 3D visualization of tongue movements in pronunciation is studied. Firstly, a precise 3D tongue model according to magnetic resonance imaging scan data is built. Based on the 3D tongue model, the electromagnetic articulometer(EMA) data collected from three points on tongue dorsum surface are used as the driven data. The mass spring technique is used to realize realistic tongue movements in pronunciation. To evaluate the effect of modeling and synthesis methods for tongue movements, the computer graphics techniques are employed to simulate the detailed effect of the tongue movements. Finally, the simulation results are compared with X-ray video of the motion characteristics of articulators for Mandarin Chinese recorded by a pronunciation specialist. The experimental result shows the proposed method achieves precise and realistic results of 3D tongue movements and it has a wide application prospect. © 2016, Science Press. All right reserved.","3D visual speech animation; Collision handling; Tongue modeling; Tongue movement simulation",,2-s2.0-84975142571
"Yang M., Jiang J., Tao J., Mu K., Li H.","Emotional head motion predicting from prosodic and linguistic features",2016,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960113533&doi=10.1007%2fs11042-016-3405-3&partnerID=40&md5=685e3820b59a1d2344754c38b1a864a2","Emotional head motion plays an important role in human-computer interaction (HCI), which is one of the important factors to improve users’ experience in HCI. However, it is still not clear how head motions are influenced by speech features in different emotion states. In this study, we aim to construct a bimodal mapping model from speech to head motions, and try to discover what kinds of prosodic and linguistic features have the most significant influence on emotional head motions. A two-layer clustering schema is introduced to obtain reliable clusters from head motion parameters. With these clusters, an emotion related speech to head gesture mapping model is constructed by a Classification and Regression Tree (CART). Based on the statistic results of CART, a systematical statistic map of the relationship between speech features (including prosodic and linguistic features) and head gestures is presented. The map reveals the features which have the most significant influence on head motions in long or short utterances. We also make an analysis on how linguistic features contribute to different emotional expressions. The discussions in this work provide important references for realistic animation of speech driven talking-head or avatar. © 2016, Springer Science+Business Media New York.","Head gesture; Prosody clustering; Visual prosody","Classification (of information); Computational linguistics; Human computer interaction; Mapping; Speech; Classification and regression tree; Emotional expressions; Head gestures; Human computer interaction (HCI); Linguistic features; Prosody clustering; Speech-driven talking heads; Visual prosody; Linguistics",2-s2.0-84960113533
"Ding Z., Zhang S.","Flower solid modeling based on sketches",2016,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973387084&partnerID=40&md5=816979ad916ebab471b0ad6d434dbdf0","The geometry of current flower modeling method is not waterproof. We propose a method to model flowers of solid shape. Our method separates individual flower modeling and inflorescence modeling procedures into structure and geometry modeling. We incorporate interactive editing gestures to allow user to edit structure parameters freely onto structure diagram. Furthermore, our method uses free-hand sketching techniques to allow users to create and edit 3D geometrical elements freely and easily. The final step is to automatically merge all independent 3D geometrical elements into a single waterproof mesh. Experiments show that this solid modeling approach is promising. Using our approach, novice users can create vivid flower models easily and freely. The generated flower model is waterproof. It can have applications in visualization, animation and toys and decorations if printed out on 3D rapid prototyping devices. © 2016, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Constrained Delaunay triangulation; Floral diagram; Freehand sketching; Gesture; Inflorescence","Geometry; Vegetation; Waterproofing; Constrained Delaunay triangulation; Floral diagram; Freehand sketching; Gesture; Inflorescence; Three dimensional computer graphics",2-s2.0-84973387084
"Chang C.-S., Chu H.-K., Mitra N.J.","Interactive videos: Plausible video editing using sparse structure points",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971246323&doi=10.1111%2fcgf.12849&partnerID=40&md5=5aae6ed496580d4ba8f39d75bfb568ce","Video remains the method of choice for capturing temporal events. However, without access to the underlying 3D scene models, it remains difficult to make object level edits in a single video or across multiple videos. While it may be possible to explicitly reconstruct the 3D geometries to facilitate these edits, such a workflow is cumbersome, expensive, and tedious. In this work, we present a much simpler workflow to create plausible editing and mixing of raw video footage using only sparse structure points (SSP) directly recovered from the raw sequences. First, we utilize user-scribbles to structure the point representations obtained using structure-from-motion on the input videos. The resultant structure points, even when noisy and sparse, are then used to enable various video edits in 3D, including view perturbation, keyframe animation, object duplication and transfer across videos, etc. Specifically, we describe how to synthesize object images from new views adopting a novel image-based rendering technique using the SSPs as proxy for the missing 3D scene information. We propose a structure-preserving image warping on multiple input frames adaptively selected from object video, followed by a spatio-temporally coherent image stitching to compose the final object image. Simple planar shadows and depth maps are synthesized for objects to generate plausible video sequence mimicking real-world interactions. We demonstrate our system on a variety of input videos to produce complex edits, which are otherwise difficult to achieve. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Image reconstruction; Three dimensional computer graphics; Coherent images; Image based rendering; Interactive video; Multiple inputs; Point representations; Structure from motion; Structure-preserving; Video sequences; Image processing",2-s2.0-84971246323
"Turker H.T., Coskun H., Mertayak C.","Innovative experimental model and simulation method for structural dynamic concepts",2016,"Computer Applications in Engineering Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977865461&doi=10.1002%2fcae.21720&partnerID=40&md5=39f3c0efd2c811b64e2209e636f9be5b","In this study, different methods to teach and visualize the motion of a single degree of freedom system for engineering undergraduate and graduate students and professionals are described. The examined concepts include the P-Δ effect in a single degree of freedom system. First, the theoretical background is given. Then, an experimental setup was used to verify the theory. The experimental setup consists of a steel saw with a height, h and stiffness k. An additional mass is put on top of steel saw. A new simple method to find period of a Single Degree of Freedom model is introduced. Using an acoustic method in a new way, period of the oscillating saw is determined. By digitally processing the captured acoustic waves, the period characteristics of the system are calculated. A simulation tool is also developed using MathematicaÂ® software. The simulation provided the users a way to visualize the motion of the system in time along with simple animations. These simple experimental setup and simulation tool provided convenient and useful approaches to demonstrate the concepts including the P-Δ effect in a single degree of freedom system. Â© 2016 Wiley Periodicals, Inc.","acoustic; education; gravity effect; oscillation; simulation","Acoustics; Computer software; Education; Education computing; Sailing vessels; Sawing; Saws; Structural dynamics; Students; Engineering undergraduates; Experimental modeling; Graduate students; Gravity effects; Oscillation; Simulation; Single degree of freedom models; Single degree of freedom systems; Degrees of freedom (mechanics)",2-s2.0-84977865461
"Günther T., Schulze M., Friederici A., Theisel H.","Visualizing Volcanic Clouds in the Atmosphere and Their Impact on Air Traffic",2016,"IEEE Computer Graphics and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969706142&doi=10.1109%2fMCG.2015.121&partnerID=40&md5=88fb914b49b14ead7bfe853ff7e3492e","Volcanic eruptions are not only hazardous in the direct vicinity of a volcano, but they also affect the climate and air travel for great distances. This article sheds light on the Grímsvötn, Puyehue-Cordón Caulle, and Nabro eruptions in 2011. The authors study the agreement of the complementary satellite data, reconstruct sulfate aerosol and volcanic ash clouds, visualize endangered flight routes, minimize occlusion in particle trajectory visualizations, and focus on the main pathways of Nabro's sulfate aerosol into the stratosphere. The results here were developed for the 2014 IEEE Scientific Visualization Contest, which centers around the fusion of multiple satellite data modalities to reconstruct and assess the movement of volcanic ash and sulfate aerosol emissions. Using data from three volcanic eruptions that occurred in the span of approximately three weeks, the authors study the agreement of the complementary satellite data, reconstruct sulfate aerosol and volcanic ash clouds, visualize endangered flight routes, minimize occlusion in particle trajectory visualizations, and focus on the main pathways of sulfate aerosol into the stratosphere. This video provides animations of the reconstructed ash clouds. © 2016 IEEE.","computer graphics; IEEE Scientific Visualization Contest; satellite data; scientific visualization; volcanic eruptions","Aerosols; Air transportation; Clouds; Computer graphics; Data visualization; Flight paths; Satellites; Sulfur compounds; Visualization; IEEE Scientific Visualization Contest; Multiple satellites; Particle trajectories; Satellite data; Sulfate aerosols; Volcanic ash clouds; Volcanic clouds; Volcanic eruptions; Volcanoes",2-s2.0-84969706142
"Fan B., Xie L., Yang S., Wang L., Soong F.K.","A deep bidirectional LSTM approach for video-realistic talking head",2016,"Multimedia Tools and Applications",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944699627&doi=10.1007%2fs11042-015-2944-3&partnerID=40&md5=cf2647765c23ac6ed066446a854f0696","This paper proposes a deep bidirectional long short-term memory approach in modeling the long contextual, nonlinear mapping between audio and visual streams for video-realistic talking head. In training stage, an audio-visual stereo database is firstly recorded as a subject talking to a camera. The audio streams are converted into acoustic feature, i.e. Mel-Frequency Cepstrum Coefficients (MFCCs), and their textual labels are also extracted. The visual streams, in particular, the lower face region, are compactly represented by active appearance model (AAM) parameters by which the shape and texture variations can be jointly modeled. Given pairs of the audio and visual parameter sequence, a DBLSTM model is trained to learn the sequence mapping from audio to visual space. For any unseen speech audio, whether it is original recorded or synthesized by text-to-speech (TTS), the trained DBLSTM model can predict a convincing AAM parameter trajectory for the lower face animation. To further improve the realism of the proposed talking head, the trajectory tiling method is adopted to use the DBLSTM predicted AAM trajectory as a guide to select a smooth real sample image sequence from the recorded database. We then stitch the selected lower face image sequence back to a background face video of the same subject, resulting in a video-realistic talking head. Experimental results show that the proposed DBLSTM approach outperforms the existing HMM-based approach in both objective and subjective evaluations. © 2015, Springer Science+Business Media New York.","Active appearance model; Long short-term memory; Recurrent neural network; Talking head; Visual speech synthesis","Brain; Computer vision; Image recognition; Mapping; Recurrent neural networks; Speech recognition; Speech synthesis; Trajectories; Active appearance models; Long short term memory; Mel frequency cepstrum coefficient (MFCCs); Nonlinear mappings; Objective and subjective evaluations; Shape and textures; Talking heads; Visual speech synthesis; Audio acoustics",2-s2.0-84944699627
"Jeschke S.","Generalized diffusion curves: An improved vector representation for smooth-shaded images",2016,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971320529&doi=10.1111%2fcgf.12812&partnerID=40&md5=b49999b3e7c2f4eb170139d5700732ec","This paper generalizes the well-known Diffusion Curves Images (DCI), which are composed of a set of Bezier curves with colors specified on either side. These colors are diffused as Laplace functions over the image domain, which results in smooth color gradients interrupted by the Bezier curves. Our new formulation allows for more color control away from the boundary, providing a similar expressive power as recent Bilaplace image models without introducing associated issues and computational costs. The new model is based on a special Laplace function blending and a new edge blur formulation. We demonstrate that given some user-defined boundary curves over an input raster image, fitting colors and edge blur from the image to the new model and subsequent editing and animation is equally convenient as with DCIs. Numerous examples and comparisons to DCIs are presented. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Color; Interpolation; Laplace transforms; Boundary curves; Color control; Color gradients; Computational costs; Expressive power; Generalized diffusion; Laplace functions; Vector representations; Curve fitting",2-s2.0-84971320529
"Liu Z., Wu X., Zheng Q.","A survey of dynamic network visualization and visual analysis",2016,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973279103&partnerID=40&md5=bb4a639953fa654a6683c7bccc63578e","Most of the various network data which come from computer, communication and social relationship application has the dynamic character. Compared with static network, dynamic network with the added time dimension lead to more challenge for data visualization and analysis. Based on the existing references, we consider dynamic graph model as dynamic network and summarize three visualization standards for it. According to different time dimension mapping method, we firstly deeply analyze and compare animation, timeline and hybrid techniques for basic dynamic network visualization. Secondly we extend to describe new multivariate scale and large dynamic network visualization. Furthermore based on combing visual analysis purpose and specific task requirement, visual analysis technique in different application is discussed. Finally we discuss the future research direction on this topic. © 2016, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Dynamic graph; Dynamic network; Time-varying graph; Visual analysis; Visualization","Data visualization; Flow visualization; Visualization; Dynamic graph; Dynamic network; Future research directions; Large dynamic networks; Social relationships; Time-varying graphs; Visual analysis; Visualization and analysis; Time varying networks",2-s2.0-84973279103
"Goldade R., Batty C., Wojtan C.","A practical method for high-resolution embedded liquid surfaces",2016,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971242706&doi=10.1111%2fcgf.12826&partnerID=40&md5=8691ccc210d45873751c789c2b1411c4","Combining high-resolution level set surface tracking with lower resolution physics is an inexpensive method for achieving highly detailed liquid animations. Unfortunately, the inherent resolution mismatch introduces several types of disturbing visual artifacts. We identify the primary sources of these artifacts and present simple, efficient, and practical solutions to address them. First, we propose an unconditionally stable filtering method that selectively removes sub-grid surface artifacts not seen by the fluid physics, while preserving fine detail in dynamic splashing regions. It provides comparable results to recent error-correction techniques at lower cost, without substepping, and with better scaling behavior. Second, we show how a modified narrow-band scheme can ensure accurate free surface boundary conditions in the presence of large resolution mismatches. Our scheme preserves the efficiency of the narrow-band methodology, while eliminating objectionable stairstep artifacts observed in prior work. Third, we demonstrate that the use of linear interpolation of velocity during advection of the high-resolution level set surface is responsible for visible grid-aligned kinks; we therefore advocate higher-order velocity interpolation, and show that it dramatically reduces this artifact. While these three contributions are orthogonal, our results demonstrate that taken together they efficiently address the dominant sources of visual artifacts arising with high-resolution embedded liquid surfaces; the proposed approach offers improved visual quality, a straightforward implementation, and substantially greater scalability than competing methods. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Error correction; Interpolation; Liquids; Correction techniques; Free-surface boundary conditions; Higher-order velocity; Linear Interpolation; Lower resolution; Practical solutions; Unconditionally stable; Visual qualities; Numerical methods",2-s2.0-84971242706
"Li S., Li S., Li J.Z., Geng L.","A Hybrid Paradigm for Modeling, Simulation and Analysis of Brand Virality in Social Media",2016,"Proceedings - 2015 6th International Conference on Intelligent Systems Design and Engineering Applications, ISDEA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969746007&doi=10.1109%2fISDEA.2015.16&partnerID=40&md5=0ef2b5b4b338d55083ce6320def01e87","Enhancing brand awareness through online social networks is increasingly pivotal to business success. This paper is concerned with a hybrid paradigm for modeling, simulation and analysis of brand virality in social media. In particular, mathematical models and graphical animation are proposed and formulated to represent the spread and viral process of a brand over social Web and mobile networks. Simulation prototype are also created to illustrate relevant ideas and concepts. Furthermore, a fuzzy logic-based framework is developed to evaluate the effectiveness and efficiency of brand virality. Our work provides a solid foundation for further investigation in this field. © 2015 IEEE.","Brand virality; fuzzy logic; intelligent software agent; modeling; simulation; social media","Computer circuits; Computer software; Fuzzy logic; Intelligent systems; Models; Reconfigurable hardware; Social networking (online); Systems analysis; Brand virality; Effectiveness and efficiencies; Graphical animation; Intelligent software agent; On-line social networks; simulation; Simulation and analysis; Social media; Software agents",2-s2.0-84969746007
"Saalfeld P., Glager S., Beuing O., Grundmann M., Preim B.","3D sketching on interactively unfolded vascular structures for treatment planning",2016,"2016 IEEE Symposium on 3D User Interfaces, 3DUI 2016 - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974530731&doi=10.1109%2f3DUI.2016.7460073&partnerID=40&md5=860ea99cedef3d95d7f77a906169f4ba","In clinical practice, sketches support physicians in treatment planning. For example, they are employed as direct annotations in medical image data. However, this approach leads to occlusions in case of spatially complex 3D representations of anatomical structures such as vascular systems. To overcome this limitation, we developed a framework which enables the physician to create annotations by freely sketching in 3D environment. We solve the problem of occlusions by an animated representation of the original and unfolded vascular structure with interactive unfolding. For this, we use a semi-immersive stereoscopic display and a stylus with ray-based interaction techniques. © 2016 IEEE.","I.3.6 [COMPUTER GRAPHICS]: Methodology and Techniques - Interaction techniques; I.3.7 [COMPUTER GRAPHICS]: Three-Dimensional Graphics and Realism - Animation; J.3 [LIFE AND MEDICAL SCIENCES]: Medical information systems","Cardiovascular system; Computer graphics; Medical imaging; Medical information systems; Stereo image processing; User interfaces; 3d representations; Anatomical structures; I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction techniques; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Interaction techniques; Life and medical science; Stereoscopic display; Vascular structures; Three dimensional computer graphics",2-s2.0-84974530731
"O'Rourke E., Peach E., Dweck C.S., Popović Z.","Brain points: A deeper look at a growth mindset incentive structure for an educational game",2016,"L@S 2016 - Proceedings of the 3rd 2016 ACM Conference on Learning at Scale",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969983764&doi=10.1145%2f2876034.2876040&partnerID=40&md5=5443e8b6c4e8ba3dd24c49effa7a2a43","Student retention is a central challenge in systems for learning at scale. It has been argued that educational video games could improve student retention by providing engaging experiences and informing the design of other online learning environments. However, educational games are not uniformly effective. Our recent research shows that player retention can be increased by using a brain points incentive structure that rewards behaviors associated with growth mindset, or the belief that intelligence can grow. In this paper, we expand on our prior work by providing new insights into how growth mindset behaviors can be effectively promoted in the educational game Refraction. We present results from an online study of 25,000 children who were exposed to five different versions of the brain points intervention. We find that growth mindset animations cause a large number of players to quit, while brain points encourage persistence. Most importantly, we find that awarding brain points randomly is ineffective; the incentive structure is successful specifically because it rewards desirable growth mindset behaviors. These findings have important implications that can support the future generalization of the brain points intervention to new educational contexts. © 2016 ACM.","Educational games; Growth mindset; Incentive structures","Animation; Computer aided instruction; Education; Human computer interaction; Educational context; Educational game; Educational video games; Incentive structure; Online learning environment; Online studies; Recent researches; Student retention; Students",2-s2.0-84969983764
"Imaad S.M., Wajid B., Chaudhary I.U., Sarwar A.","Stem5: An initiative shaping the STEM narrative in Pakistan",2016,"ISEC 2016 - Proceedings of the 6th IEEE Integrated STEM Education Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969926618&doi=10.1109%2fISECon.2016.7457522&partnerID=40&md5=92f931d7f6815f6cc95000537dbe0db6","stem5 is a STEM education initiative based at University of Engineering & Technology (UET) at Lahore, Pakistan. The initiative aims to rejuvenate STEM education in Pakistan by engaging university faculty and students in outreach activities targeted towards underprivileged students studying in the public school system. Volunteers include faculty, researchers and students from across various engineering disciplines of the university. This paper presents an overview of the two main outreach activities being conducted under the umbrella of stem5 - science outreach program at public primary schools and summer coding camps for public secondary school students. The science outreach program has been in operation since 2013 and is currently underway in a total of 9 schools in the cities of Lahore and Faisalabad. The summer coding camp is a new addition and was held in Lahore in the summer of 2015. The basic purpose of such camps is to introduce computer science and programming to young students by creating animations and games using Scratch. We conclude by discussing future directions and suggest how the current work may be adopted by other universities in Pakistan to enable synergistic efforts that may influence the narrative for STEM education reform in the country. © 2016 IEEE.","computer science; inquiry-based learning; public education; STEM","Animation; Computer games; Computer programming; Computer science; Education computing; Engineering education; Societies and institutions; STEM (science, technology, engineering and mathematics); Students; Teaching; Engineering disciplines; Inquiry-based learning; Outreach activity; Outreach programs; Primary schools; Public education; Public schools; Secondary schools; Education",2-s2.0-84969926618
"Ban X., Wang X., He L., Zhang Y., Wang L.","Adaptively stepped SPH for fluid animation based on asynchronous time integration",2016,"Neural Computing and Applications",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964389183&doi=10.1007%2fs00521-016-2286-8&partnerID=40&md5=cf62e0faa9f168daebd2eac603e189d9","We present a novel adaptive stepping scheme for SPH fluids, in which particles have their own time steps determined from local conditions, e.g. courant condition. These individual time steps are constrained for global convergence and stability. Fluid particles are then updated asynchronously. The approach naturally allocates computing resources to visually complex regions, e.g. regions with intense collisions, thereby reducing the overall computational time. The experiments show that our approach is more efficient than the standard method and the method with globally adaptive time steps, especially in highly dynamic scenes. © 2016 The Natural Computing Applications Forum","Adaptive SPH; Asynchronous; Fluid simulation; Individual time steps","Computer programming; Computer science; Adaptive SPH; Adaptive time step; Asynchronous; Computational time; Courant conditions; Fluid simulations; Global conver-gence; Individual time steps; Hydrodynamics",2-s2.0-84964389183
"Rahman R.A., Hassan A., Hashimm H., Zan M.M.M.","On the use of animated media in communicating the abstract concepts of computer networking: A preliminary survey",2016,"2015 IEEE 7th International Conference on Engineering Education, ICEED 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982804453&doi=10.1109%2fICEED.2015.7451514&partnerID=40&md5=55720f54108f6bc86a6564dd71f23d3a","Advanced and abstract concepts of engineering and sciences are difficult to teach using traditional media such as whiteboards and still slides. In the computer networking classroom, teachers have the challenging task of communicating abstract ideas and concepts such as the Open Systems Interconnect Model (OSI Model), Message Encapsulation, Protocol Stacks and many others. Modern teaching methods such as case studies, laboratory experience, visiting real-world scenarios and story-telling are commonly and easily practiced. In this paper we identify the challenges faced by teachers of computer networking in Malaysian polytechnics and study how animated media can be a most valuable tool to use in communicating the abstract and advanced concepts of computer communication to students in this institutions. We discuss some preliminary ideas on the development of animated and interactive media for teaching computer networking and elucidate the benefits of using animated media. © 2015 IEEE.","Animation; Cisco; Competent; Network Systems","Animation; Computer networks; Education; Education computing; Engineering education; Open systems; Cisco; Competent; Computer Communications; Computer networking; Interconnect modeling; Laboratory experiences; Network systems; Real-world scenario; Teaching",2-s2.0-84982804453
"Shen J., Yang J.","Automatic Human Animation for Non-Humanoid 3D Characters",2016,"Proceedings - 2015 14th International Conference on Computer-Aided Design and Computer Graphics, CAD/Graphics 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971477059&doi=10.1109%2fCADGRAPHICS.2015.31&partnerID=40&md5=2ac413a0c07feded35e852eea8c8fdd8","In this paper, we propose a system, that automatically transfers human body motion captured from an ordinary video camera to an unknown 3D character mesh. In our system, no manual intervention is required for specifying the internal skeletal structure or defining how the mesh surfaces deform. A sparse graph is generated from the input polygons based on their connectivity and geometric distributions. To estimate articulated body parts in the video, a progressive particle filter is used for identifying correspondences. We anticipate our proposed system can bring animation to a new audience with a more intuitive user interface. © 2015 IEEE.","3D animation; Motion transfer; Pose tracking","Animation; Computer aided design; Mesh generation; Probability distributions; User interfaces; Video cameras; 3D animation; Geometric distribution; Human body motion; Intuitive user interface; Manual intervention; Motion transfer; Pose tracking; Skeletal structures; Computer graphics",2-s2.0-84971477059
"Yang M., Li X., Yang G., Wu E.","A New Surface Tension Formulation for SPH",2016,"Proceedings - 2015 14th International Conference on Computer-Aided Design and Computer Graphics, CAD/Graphics 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971469704&doi=10.1109%2fCADGRAPHICS.2015.11&partnerID=40&md5=10535fd16962ada96c68dfd3a2c31f6c","In this paper, a new surface tension formulation is presented for Smoothed Particle Hydrodynamics in fluid simulation, especially small-scale detailed fluid animation. The surface tension formulation is decomposed into three processes: (1) mesh smoothing exploited a Lagrangian operator in a volume-preserved way, (2) surface tension computation between the original mesh and smoothed mesh, (3) surface tension transfer from mesh vertices onto their neighbor particles. Experimental results show that the proposed surface tension formulation is effective and efficient for realistic simulations. © 2015 IEEE.","Fluid simulation; Smoothed particle hydrodynamics; Surface tension","Computer aided design; Fluid dynamics; Hydrodynamics; Mesh generation; Surface tension; Fluid animation; Fluid simulations; Lagrangian operator; Mesh smoothing; Original meshes; Realistic simulation; Small scale; Smoothed particle hydrodynamics; Computer graphics",2-s2.0-84971469704
"Qian K., Yang X., Zhang J., Wang M.","An Adaptive Spherical Collision Detection and Resolution Method for Deformable Object Simulation",2016,"Proceedings - 2015 14th International Conference on Computer-Aided Design and Computer Graphics, CAD/Graphics 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971385374&doi=10.1109%2fCADGRAPHICS.2015.15&partnerID=40&md5=813ca6939247225ae945b5b92f32bfef","Collision detection and resolution are of great importance to physically based animation. Real time responses are essential for many applications, which largely rely on the efficiency of localising the potentially colliding geometry and calculating the polygon intersections. It is an extremely heavy computation task using the existing polygon based methods, especially for deformable objects. To improve this issue, we present an implicit circumsphere based collision detection and resolution method for deformable objects which takes into consideration both local geometry features and the material properties. Our method approximates the mesh in question with an implicit circumsphere surface, which is used to perform finest level collision detection and resolution instead of the original polygonal mesh. The dynamic deformation as a result of collision is determined by both the geometry and the material properties of the surface. Due to the simplicity of sphere overlap test, our method is not only computationally efficient, but also stable and comparatively accurate, outperforming the existing methods in overall performance. Our implicit circumsphere method can also provide better prevention to collision tunnelling than existing methods. Besides, this method is compatible with all existing broad phase and narrow phase collision query techniques. © 2015 IEEE.","Circumsphere; Collision Detection and Resolution; Deformable Object; Implicit Surface; Position Based Dynamics","Color image processing; Computer aided design; Computer graphics; Geometry; Mesh generation; Object detection; Circumsphere; Collision detection; Computationally efficient; Deformable object; Dynamic deformation; Implicit surfaces; Physically-based animation; Real time response; Deformation",2-s2.0-84971385374
"Hu C., Chen X., Chen S.","Application research on children's indoor fire escape education system based on virtual reality technology",2016,"Xitong Fangzhen Xuebao / Journal of System Simulation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966429462&partnerID=40&md5=6cd8fefb7d1b00a0d915282f1ea473ed","It is significant to study children's fire escape education in the virtual reality. The existing fire escape educations for children mostly adopt the ways of watching books and videos, lacking vitality and interactivity. According to the psychological characteristics of children, the models for virtual fire scene and the virtual character were built using the 3Ds Max. Based on Virtools platform, a game style of children's indoor fire escape education system was designed, with the integration of human-computer interaction, voice, smoke, and animation demo. Users experience the fire escape by auditory, visual and virtual behavior, with controlling virtual character to escape from the virtual fire scene via keyboard or mouse. Experimental results show that the system can make children learn the knowledge of fire escape more interested and more firmly, and also has a good effect on the fire escape education. © 2016, The Editorial Board of Journal of System Simulation. All right reserved.","3Ds Max; Fire escape; Virtools; Virtual reality",,2-s2.0-84966429462
"Yekti B.","Comparative aesthetic study between three-dimensional (3D) stop-motion animation and 3D computer graphic animation: Towards physicality and tactility, perfection and imperfection",2016,"CONMEDIA 2015 - International Conference on New Media 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969584445&doi=10.1109%2fCONMEDIA.2015.7449143&partnerID=40&md5=bdaaa651127d57dee478ae988977bf4b","This essay provides a comparative study on aesthetic between 3D stop-motion animation and 3D Computer graphic animation. These two animation forms produced in different pipelines and outcomes. Highlighting key aesthetic principles of animation and fueled by statements that written by Power who underlines the importance of expressiveness in animation and engagement of viewer's emotion, author draws two clusters for comparing these two animation practices. The first cluster explores physicality and tactility; and the second cluster discusses perfection and imperfection of both animation practices. This essay aimed to contribute insight on comparative study of aesthetic between diverse animation forms from technical, visual and craft perspectives that have not yet explored by academic or practicing animators. © 2015 IEEE.","3D animation; aesthetic; comparative study; computer animation; stop motion","Three dimensional computer graphics; 3D animation; 3D computer graphics; aesthetic; Comparative studies; Computer animation; Stop-motion animations; Threedimensional (3-d); Animation",2-s2.0-84969584445
[No author name available],"CONMEDIA 2015 - International Conference on New Media 2015",2016,"CONMEDIA 2015 - International Conference on New Media 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969492218&partnerID=40&md5=ed658ed816128e994a992e1ae3efdc1f","The proceedings contain 15 papers. The topics discussed include: the maturity level of information technology governance of online cosmetics business; projection technique for creating 3D computer generated assets of Borobudur temple virtual reality; the use of computational medium for visualization and simulation in healthcare architectural design; comparative aesthetic study between three-dimensional (3D) stop- motion animation and 3d computer graphic animation towards physicality and tactility, perfection and imperfection; developing a wireless touch screen switch panel connected with ZigBee; Zleap: application for wireless sensor network (ZigBee) learning tool; improving performance of intrusion detection system using openCL based general-purpose computing on graphic processing unit (GPGPU); Utar NOC: adaptive network on chip architecture platform; and a scalable and configurable multiprocessor system-on-chip (MPSOC) virtual platform for hardware and software co-design and co-verification.",,,2-s2.0-84969492218
"Benedetto M., Gagliardi A., Buonocunto P., Buttazzo G.","An Android application for head tracking",2016,"Proceedings of the ACM Symposium on Applied Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975811085&doi=10.1145%2f2851613.2851930&partnerID=40&md5=1c7df38233ed844fdffb85885febc6bc","This paper presents a head-tracking system based on an inertial sensor that sends rotation data to an Android application in charge of recording and visualizing data in real time. Data are sent via wireless channel using Bluetooth Low Energy communication and are processed to provide a realistic real-time 3D animation of the user head. © 2016 ACM.","Head tracking; IMU; Multitasking application; Real-time operating system","Computer operating systems; 3D animation; Android applications; Bluetooth low energies (BTLE); Head tracking; Head tracking system; Inertial sensor; Real time operating system; Wireless channel; Android (operating system)",2-s2.0-84975811085
"Fung A., Kelly P., Tait G., Greig P.D., McGilvray I.D.","Creating an animation-enhanced video library of hepato-pancreato-biliary and transplantation surgical procedures",2016,"Journal of Visual Communication in Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976321225&doi=10.1080%2f17453054.2016.1182474&partnerID=40&md5=88f7a5e0af046239f75b55c9c5c39fef","The potential for integrating real-time surgical video and state-of-the art animation techniques has not been widely applied to surgical education. This paper describes the use of new technology for creating videos of liver, pancreas and transplant surgery, annotating them with 3D animations, resulting in a freely-accessible online resource: The Toronto Video Atlas of Liver, Pancreas and Transplant Surgery (http://tvasurg.ca). The atlas complements the teaching provided to trainees in the operating room, and the techniques described in this study can be readily adapted by other surgical training programmes. © 2016 The Institute of Medical Illustrators.","Computer animation; diagnostic imaging; education; hepato-pancreato-biliary; medical art and illustration; medical education; multimedia; transplant surgery; video",,2-s2.0-84976321225
"Burn A.","Making machinima: animation, games, and multimodal participation in the media arts",2016,"Learning, Media and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948163962&doi=10.1080%2f17439884.2015.1107096&partnerID=40&md5=fcb98c56e60bf4d46eb46f6351a0f3b9","In the project discussed in this article, 30 11-year olds made an animated film in the machinima style, influenced by both film and game culture, and using a 3-D animation software tool, Moviestorm. The processes and products of the project will be analysed using a social semiotic/multimodal approach, exploring the social interests behind the integration of visual design, music, voice acting, story-writing, and animation which characterise the project. The outcomes suggest a need to move beyond established thinking and practice in media literacy practice and research in three ways. Firstly, we need to develop moving image education to recognise new genres and cultures. Secondly, we need to recognise that such productions are intensely multimodal, involving music, drama, story-writing, and visual design. Thirdly, such projects demand connected pedagogy across media, literacy, music, drama, computer science, and art. © 2015 Informa UK Limited, trading as Taylor & Francis Group.","animation; film; kineikonic; media arts education; multimodality",,2-s2.0-84948163962
"Huang Y.-H., Chuang T.-Y.","Technology-assisted sheltered instruction: instructional streaming video in an EFL multi-purpose computer course",2016,"Computer Assisted Language Learning",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960256735&doi=10.1080%2f09588221.2014.1000933&partnerID=40&md5=2cc7d0f8ce69da5868d04786a90b25dc","Content-based instruction (CBI) has been widely adopted for decades. However, existing CBI models cannot always be effectively put into practice, especially for learners of lower English proficiency in English as a foreign language (EFL) context. This study examined an animation design course adopting CBI to promote reading abilities of English majors at a technology university in Taiwan. CBI usually adds challenges in cognitive and linguistic learning, especially for English majors in computer courses. Different from other CBI courses, this course dealt with multiple situations: multi-approaches (CBI and task-based instruction); multi-skills (Flash animation software skills- various animation effects; language skills-computer vocabulary and reading comprehension); multi-level learners (various English language proficiency levels – mostly low proficiency level; computer abilities; learning styles), and a large class taught by one instructor. Simply employing CBI cannot solve such complex problems. Therefore, instructional streaming video was applied as a learner-directed scaffold and a technological facilitator. A control group and an experimental group comprised 117 and 121 English majors taking this course for one semester respectively. Both groups were taught with English materials but the later were additionally provided with instructional streaming video (ISV). Qualitative and quantitative data were collected from classroom observations, interviews, exams, and semester-end questionnaires from both groups to examine whether ISV facilitated instructor teaching and student learning. Results show that the experimental group significantly performed better in reading comprehension, reading speed, acceptance, attention, and exams, as well as easing teaching difficulties. Drawn upon empirical results, a technology-assisted sheltered model was generated for EFL multi-purpose courses. © 2016, 2015 Taylor & Francis.","content-based instruction; sheltered instruction; streaming video; technology-assisted language learning",,2-s2.0-84960256735
"Ahmed N., Khalifa S.","Time-coherent 3D animation reconstruction from RGB-D video",2016,"Signal, Image and Video Processing",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940944210&doi=10.1007%2fs11760-015-0813-1&partnerID=40&md5=7015e122483846b3390612f80ec8ff8a","We present a new method to reconstruct a time-coherent 3D animation from RGB-D video data using unbiased feature point sampling. Given RGB-D video data, in the form of a 3D point cloud sequence, our method first extracts feature points using both color and depth information. Afterward, these feature points are used to match two 3D point clouds in consecutive frames independent of their resolution. Our new motion vector-based dynamic alignment method then fully reconstructs a spatio-temporally coherent 3D animation. We perform extensive quantitative validation using a novel error function, in addition to the standard techniques in the literature, and compared our method to existing methods in the literature. We show that despite the limiting factors of temporal and spatial noise associated to RGB-D data, it is possible to extract temporal coherence to faithfully reconstruct a temporally coherent 3D animation from RGB-D video data. © 2015, Springer-Verlag London.","3D animation; 3D video; RGB-D video; Temporally coherent 3D animation","Animation; Video recording; 3-D videos; 3D animation; Depth information; Dynamic alignment; Quantitative validation; RGB-D video; Temporal and spatial; Temporal coherence; Three dimensional computer graphics",2-s2.0-84940944210
"Liang H., Liang R., Song M., He X.","Coupled Dictionary Learning for the Detail-Enhanced Synthesis of 3-D Facial Expressions",2016,"IEEE Transactions on Cybernetics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927545850&doi=10.1109%2fTCYB.2015.2417211&partnerID=40&md5=700f60cf8278019546412d3ac70d7a70","The desire to reconstruct 3-D face models with expressions from 2-D face images fosters increasing interest in addressing the problem of face modeling. This task is important and challenging in the field of computer animation. Facial contours and wrinkles are essential to generate a face with a certain expression; however, these details are generally ignored or are not seriously considered in previous studies on face model reconstruction. Thus, we employ coupled radius basis function networks to derive an intermediate 3-D face model from a single 2-D face image. To optimize the 3-D face model further through landmarks, a coupled dictionary that is related to 3-D face models and their corresponding 3-D landmarks is learned from the given training set through local coordinate coding. Another coupled dictionary is then constructed to bridge the 2-D and 3-D landmarks for the transfer of vertices on the face model. As a result, the final 3-D face can be generated with the appropriate expression. In the testing phase, the 2-D input faces are converted into 3-D models that display different expressions. Experimental results indicate that the proposed approach to facial expression synthesis can obtain model details more effectively than previous methods can. © 2015 IEEE.","Coupled dictionary; expression synthesis; landmark; local coordinate coding (LCC)","Animation; Face recognition; 3-D face modeling; 3-d facial expressions; Computer animation; Dictionary learning; Facial expression synthesis; Local coordinate; Radius basis function; Testing phase; Three dimensional computer graphics; algorithm; anatomy and histology; diagnostic imaging; face; facial expression; human; machine learning; physiology; procedures; three dimensional imaging; Algorithms; Face; Facial Expression; Humans; Imaging, Three-Dimensional; Machine Learning",2-s2.0-84927545850
"Adamo-Villani N., Dib H.N.","A study of the effects of teaching avatars on students' learning of surveying mathematics",2016,"International Journal of Information and Communication Technology Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960932907&doi=10.4018%2fIJICTE.2016040101&partnerID=40&md5=caa047474006feb795e24e98630fb567","The paper reports a research study aimed at investigating the appeal and pedagogical efficacy of animated teaching avatars. Specifically, the goal of the study was to determine whether animated characters could be effective and engaging teachers in the context of undergraduate surveying mathematics. The study included two forms of evaluation: formative and summative. Findings from the formative evaluation with forty-four undergraduate students show that three animated lectures delivered by a teaching avatar that speaks, gestures and points to a virtual board were perceived as engaging and useful for learning surveying mathematics concepts and procedures. Results of the summative evaluation with fifty-two undergraduate students show that watching the animated avatar lectures led to an increase in subjects' mathematical competence by 31%. The study also compared the animated avatar lectures to interactive 2D visualizations illustrating equivalent surveying math concepts. Findings show that watching the teaching avatar lectures led to significantly higher learning gains. Copyright © 2016, IGI Global.","Computer animation; Educational technologies; Mathematics education; Surveying; Teaching avatars","Animation; Education; Educational technology; Surveying; Surveys; Teaching; 2-D visualizations; Animated characters; Computer animation; Formative evaluation; Higher learning; Mathematics education; Research studies; Undergraduate students; Students",2-s2.0-84960932907
"Karavirta V., Shaffer C.A.","Creating Engaging Online Learning Material with the JSAV JavaScript Algorithm Visualization Library",2016,"IEEE Transactions on Learning Technologies",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978950545&doi=10.1109%2fTLT.2015.2490673&partnerID=40&md5=56e7dc6c869fc87b05cff3feac15758b","Data Structures and Algorithms are a central part of Computer Science. Due to their abstract and dynamic nature, they are a difficult topic to learn for many students. To alleviate these learning difficulties, instructors have turned to algorithm visualizations (AV) and AV systems. Research has shown that especially engaging AVs can have an impact on student learning of DSA topics. Until recently, most AV systems were Java-based systems. But, the popularity of Java has declined and is being supplanted by HTML5 and JavaScript content online. In this paper, we present JSAV: the JavaScript AV development library. JSAV goes beyond traditional AV library support for displaying standard data structures components, to provide functionality to simplify creation of AVs on many engagement levels including interactive exercises. We describe the growing body of content created with JSAV and summarize our three years of experience and research results from using JSAV to build content that supports CS education. © 2008-2011 IEEE.","Active Electronic Textbooks; Algorithm Animation; Data Structure and Algorithm Visualizations; HTML5; Hypertextbook; Interactive Courseware; JSAV","Algorithms; Computer aided instruction; Data structures; E-learning; High level languages; HTML; Visualization; Algorithm animation; Algorithm visualization; Courseware; Electronic textbooks; HTML5; Hypertextbook; JSAV; Learning algorithms",2-s2.0-84978950545
"Gosselin C., Schreiber L.-T.","Kinematically Redundant Spatial Parallel Mechanisms for Singularity Avoidance and Large Orientational Workspace",2016,"IEEE Transactions on Robotics",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961325545&doi=10.1109%2fTRO.2016.2516025&partnerID=40&md5=bb4de1806780dc99b81ef01e55d4a4af","This paper introduces a novel architecture of kinematically redundant parallel mechanisms. This family of mechanisms is similar to the well-known Gough-Stewart platform, and it retains its advantages, i.e., the members connecting the base to the moving platform are only subjected to tensile/compressive loads. The proposed architecture exploits kinematic redundancy to avoid singularities and extend the rotational workspace. The novel kinematic architecture is described, and the associated kinematic relationships are developed. Based on the derivation of the Jacobian matrices, it is shown that the singularities of this type of mechanism are governed by the orientation of passive links connecting the redundant legs to the platform. Grassmann geometry is then used to demonstrate that, given some simple geometric assumptions on the architecture, all singularities can be avoided by exploiting the kinematic redundancy. The orientational workspace is then discussed, and a graphical representation is provided for an example architecture comprising nine actuators, whose orientational workspace is shown to be very large. The translational workspace is also studied. Example trajectories are given in order to illustrate the capabilities of the mechanism to produce very large rotation angles without encountering singularities. Computer animations of the trajectories are provided in a multimedia extension of the paper. © 2015 IEEE.","Gough-Stewart (GS) platform; orientational workspace; parallel mechanism; redundancy; singularity avoidance","Animation; Jacobian matrices; Mechanisms; Motion control; Redundancy; Redundant manipulators; Graphical representations; Grassmann geometries; Kinematic redundancy; Large rotation angles; Multimedia extensions; Proposed architectures; Singularity avoidance; Spatial parallel mechanism; Kinematics",2-s2.0-84961325545
"Zheng X.-W., Li Y., Liu H., Duan H.-C.","A study on a cooperative character modeling based on an improved NSGA II",2016,"Multimedia Tools and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921883316&doi=10.1007%2fs11042-015-2476-x&partnerID=40&md5=303033b2fca8002c10ade73b53137458","Different animation characters are loved by people at different ages, in different countries and from different background, which implies the difficulties of designing characters that might be loved by many. Grouping different designers together by computer networks or the Internet is surely a good solution to design a character with expected popularity. This paper presents a character modeling method based on an improved non-dominated sorting genetic algorithm II (CMIN). CMIN borrows ideas from biological evolution, especially from multi-objective genetic algorithm (MOGA) and is formalized as a procedure for character modeling. CMIN adopts binary tree data structure to express transformation rules which are used to diversify character models and uses crossover and mutation operators of genetic algorithm to generate new rules. CMIN also adopts cooperative multi-objective evaluation on generated characters. The objectives are designed to embody both qualitative and quantitative aspects of character personalities, which are assigned by different cooperative designers and calculated automatically by computers respectively. The incorporation of qualitative and quantitative evaluation is formally realized by introducing a MOGA framwork. A multi-objective evaluation-based cooperative character modeling system (MOCMS) was developed to verify the proposed CMIN. Representative case studies demonstrate that the proposed method can evolve character models according to the designers’ intentions and preferences and generate creative character models far beyond man’s own imagination. © 2015, Springer Science+Business Media New York.","ACIS rules; Character modeling; Cooperative evaluation; Multi-objective; NSGA II","Animation; Binary trees; Bioinformatics; Biology; Design; Genetic algorithms; Metadata; ACIS rules; Character modeling; Cooperative evaluation; Multi objective; NSGA-II; Trees (mathematics)",2-s2.0-84921883316
"Ayesh A., Arevalillo-Herráez M., Ferri F.J.","Towards psychologically based personalised modelling of emotions using associative classifiers",2016,"International Journal of Cognitive Informatics and Natural Intelligence",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980002529&doi=10.4018%2fIJCINI.2016040103&partnerID=40&md5=8a94a518398131d71f99ebf70e8b3da6","Learning environments, among other user-centred applications, are excellent candidates to trial Computational Emotions and their algorithms to enhance user experience and to expand the system usability. However, this was not feasible because of the paucity in affordable consumer technologies that support the requirements of systems with advanced cognitive capabilities. Microsoft Kinect provides an accessible and affordable technology that can enable cognitive features such as facial expressions extraction and emotions detection. However, it comes with its own additional challenges, such as the limited number of extracted Animation Units (AUs). This paper presents a new approach that attempts at finding patterns of interaction between AUs, and between AUs and a given emotion. By doing so, the authors aim to reach a mechanism to generate a dynamically personified set of rules relating AUs and emotions. These rules will implicitly encode a person's individuality in expressing one's emotions. Copyright © 2016, IGI Global.","Emotion modeling; Kinect; Personified adaptive interfaces; Sentiment analysis; User-centred emotion detection","Computer aided instruction; Face recognition; User interfaces; Adaptive interface; Emotion detection; Emotion modeling; Kinect; Sentiment analysis; Cognitive systems",2-s2.0-84980002529
"Miao T., Guo X., Wen W., Xiao B., Lu S.","Three dimensional visual simulation method of crop disease state based on image",2016,"Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963569099&doi=10.11975%2fj.issn.1002-6819.2016.07.025&partnerID=40&md5=fe8d9b3ac491dbbe9c1004471ece8b94","Simulation of three-dimensional (3D) crop scene infected by crop disease is a tough task, because the related appearance data information is difficult to obtain. To obtain specific disease appearance information, careful bacteria culture and continuous observation may be needed with long-time experimental work and precise environmental control. This paper presents a general method to simulate the appearance transition of crop leaves infected by common diseases based on existing image in the Internet. We assume that a disease image contains some key appearance information in the process of disease infection. Based on this assumption, a set of static properties are extracted from image including shape and color of disease spots on the crop surface, and meanwhile the relevant dynamic transition processes of these properties are also deduced. For analyzing color transition, K-MEANS is firstly used to classify the color vectors of pixels in disease image into 8 categories and the average color vector of each category is computed which is called disease color feature vector. Then, these 8 vectors are sorted based on their proportions of green channel. To get a continual color aging simulation result, 7 linear functions are generated by interpolation between adjacent vectors. Finally, 141 discrete color vectors are sampled from these functions and used to generate the disease color transition texture. In order to obtain dynamic morphogenesis process of disease spot, the threshold segmentation method is firstly applied to segment the disease spot pixels from the pixels of normal crop leaves. Then a gray value is computed for each disease spot pixel based on the mimimum Euclidean distance between pixel's color vector and each disease color feature vector. These gray values of each disease spot pixel are recorded into the texture called morphogenesis texture. The distribution of disease spot on the crop organ surface is complex and random. A interactive interface tool has been developed for designing the distribution. With the tool, users can put some morphogenesis textures onto any location of the crop 3D models and change the size and direction of morphogenesis textures according to users' experience. The operating result is also saved as the texture called distribution texture. The disease color transition texture and distribution texture contain the necessary dynamic appearance information of disease spot and are used in the visualization step. For simulating a dynamic and continual appearance transition process of crop disease, a group of degree parameters for arbitrary 3D position on the crop surface are applied to generate the disease appearance which is computed using the distribution texture and the interactive parameter called general disease degree parameter. With the general degree parameter, user can get a simulation result under any infected state. In order to better define the disease appearance, we decompose it into the symptom appearance for describing the ageing status of the crop organ and the mildew layer appearance caused by the accumulation of mycelium. We consider the crop organ as a homogeneous structure and use the isotropic ward BRDF (bidirectional reflectance distribution function) model to simulate the symptom appearance. The diffuse reflection of ward model at arbitrary position on crop is selected from the color transition texture based on the degree parameter of this 3D position. In order to simulate the volumetric nature of the mildew layers, the shell model is integrated into our approach and the attributes of shell model are all controlled by the degree parameter. We have realized the algorithm in this paper using OpenGL, and found that the method can realistically render the appearance of the crop infected by the disease using only one or a few images. Our strategy is to use existing disease image from Internet to generate plant disease 3D animation, and it can solve the problem of the lack of related apparent data information of plant diseases. This research can provide a powerful tool to produce animations for agricultural science training. © 2016, Chinese Society of Agricultural Engineering. All right reserved.","Crops; Digital plant; Diseases; Models; Pest control; Three dimensional","Application programming interfaces (API); Color; Crops; Diseases; Distribution functions; Environmental management; Fungi; Image processing; Internet; Models; Morphology; Pest control; Pixels; Plants (botany); Three dimensional computer graphics; Vectors; Visualization; BRDF (bidirectional reflectance distribution function); Continuous observation; Digital plant; Distribution of disease; Dynamic transition process; Interactive interfaces; Threedimensional (3-d); Threshold segmentation; Disease control",2-s2.0-84963569099
"Goto M., Yoshii K., Nakano T.","Songle Widget: Making Animation and Physical Devices Synchronized with Music Videos on the Web",2016,"Proceedings - 2015 IEEE International Symposium on Multimedia, ISM 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969640817&doi=10.1109%2fISM.2015.64&partnerID=40&md5=24f7cb3c5b4bc467a11a80a716db3367","This paper describes a web-based multimedia development framework, Songle Widget, that makes it possible to control computer-graphic animation and physical devices such as lighting devices and robots in synchronization with music publicly available on the web. To avoid the difficulty of time-consuming manual annotation, Songle Widget makes it easy to develop web-based applications with rigid music synchronization by leveraging music-understanding technologies. Four types of musical elements (music structure, hierarchical beat structure, melody line, and chords) have been automatically annotated for more than 920,000 songs on music-or video-sharing services and can readily be used by music-synchronized applications. Since errors are inevitable when elements are annotated automatically, Songle Widget takes advantage of a user-friendly crowdsourcing interface that enables users to correct them. This is effective when applications require error-free annotation. We made Songle Widget open to the public, and its capabilities and usefulness have been demonstrated in seven music-synchronized applications. © 2015 IEEE.","multimedia control; music synchronization; music understanding; web service","Animation; Synchronization; Websites; Lighting devices; Manual annotation; Music structures; Music synchronizations; Music understanding; Physical devices; Web-based applications; Web-based multimedia; Web services",2-s2.0-84969640817
"Gazerani N., Ahmad R., Forouzani S., Gazerani N.","Developing a teaching framework to support software inspection",2016,"Conference Proceedings of 2015 2nd International Conference on Knowledge-Based Engineering and Innovation, KBEI 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971408180&doi=10.1109%2fKBEI.2015.7436026&partnerID=40&md5=355ba8ae62be369f2515acb2e795ff56","The objective of inspection process is to reduce the cost by finding and removing defects earlier. In recent years, there have been a number of attempts to further increase inspection efficiency by the introduction of tool support and resulting in a number of prototype systems. However, many software engineers suffer from lack of background knowledge and experience on software inspections and its techniques. The purpose of the study is to investigate the possible ways to teach software inspection processes in both sides of concepts and practice to Software engineering students. So, we offered a teaching framework to make software engineering students have a deep understanding on software inspection and to improve their practical abilities. The framework consists of three parts: general guidelines, specific guidelines and learning activity. In addition, there are two parts of general guidelines: Software inspection concept and Software inspection technique. Specific guidelines include Software inspection process and applying technique on Software inspection process. The third part includes conceptual samples, collaboration in practice, work sample and assessment for improving practical skills and abilities. Based on the teaching framework, a software support tool is designed and developed using interactive feature such as combining text, sound, graphic, images and animation. It is evaluated by software engineering students in University of Malaya to show positive impact of framework on teaching software inspections. © 2015 IEEE.","guidelines and teaching framework; software inspection","Computer software selection and evaluation; Engineering research; Knowledge based systems; Software engineering; Students; Back-ground knowledge; guidelines and teaching framework; Inspection efficiency; Inspection process; Interactive features; Software engineering students; Software inspection; Software inspection techniques; Inspection",2-s2.0-84971408180
"Wood E., Baltrušaitis T., Morency L.-P., Robinson P., Bulling A.","Learning an appearance-based gaze estimator from one million synthesised images",2016,"Eye Tracking Research and Applications Symposium (ETRA)",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975298409&doi=10.1145%2f2857491.2857492&partnerID=40&md5=503376b5766f5a3d6a85fd1319b5c8f5","Learning-based methods for appearance-based gaze estimation achieve state-of-the-art performance in challenging real-world settings but require large amounts of labelled training data. Learningby-synthesis was proposed as a promising solution to this problem but current methods are limited with respect to speed, appearance variability, and the head pose and gaze angle distribution they can synthesize. We present UnityEyes, a novel method to rapidly synthesize large amounts of variable eye region images as training data. Our method combines a novel generative 3D model of the human eye region with a real-time rendering framework. The model is based on high-resolution 3D face scans and uses real-time approximations for complex eyeball materials and structures as well as anatomically inspired procedural geometry methods for eyelid animation. We show that these synthesized images can be used to estimate gaze in difficult in-the-wild scenarios, even for extreme gaze angles or in cases in which the pupil is fully occluded. We also demonstrate competitive gaze estimation results on a benchmark in-the-wild dataset, despite only using a light-weight nearestneighbor algorithm. We are making our UnityEyes synthesis framework available online for the benefit of the research community. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","3D morphable model; Appearance-based gaze estimation; Learning-bysynthesis; Real-time rendering","Rendering (computer graphics); Three dimensional computer graphics; 3D Morphable model; Gaze estimation; Learning-based methods; Learning-bysynthesis; Nearest-neighbor algorithms; Real-time rendering; Research communities; State-of-the-art performance; Image processing",2-s2.0-84975298409
"Xu C.F., Zhou X.C.","Three-dimensional Animation Technology in Showing the Application of the Art of Design",2016,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963612315&doi=10.1051%2fmatecconf%2f20164402044&partnerID=40&md5=e0f29a6fbff3e6f789c2b231ee180fd4","The three dimensional animation technology is a new technology in recent years with the development of computer hardware and software technology and produce; exhibition design art is accompanied by stages in the development of human society politics, economy and the gradual formation of art. This paper mainly studies animation how to promote and enhance the artistic design and industrial product design from the technical means of 3D, architectural exhibition as a starting point, to integration and innovation between the two studies, which reflects the perfect combination of technology and art. © Owned by the authors, published by EDP Sciences, 2016.",,"Animation; Computer hardware; Design; Product design; Software engineering; Artistic designs; Hardware and software; Human society; Industrial product; Three-dimensional animations; Exhibitions",2-s2.0-84963612315
"Xu L., He W.","The Office Software Learning and Examination System Design Based on Fragmented Learning Idea",2016,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963565223&doi=10.1051%2fmatecconf%2f20164402085&partnerID=40&md5=22623a0c3b57adfdf1a3e272dc67b1c2","Fragmented learning is that through the segmentation of learning content or learning time, make learners can use the fragmented time for learning fragmentated content, have the characteristics of time flexibility, learning targeted and high learning efficiency. Based on the fragmented learning ideas, combined with the teaching idea of micro class and interactive teaching, comprehensive utilization of flash animation design software,.NET development platform, VSTO technology, multimedia development technology and so on, design and develop a system integrated with learning, practice and examination of the Office software, which is not only conducive to the effective and personalized learning of students, but also conducive to the understanding the students' situation of teachers, and liberate teachers from the heavy labor of mechanical, focus on promoting the formation of students' knowledge system. © Owned by the authors, published by EDP Sciences, 2016.","Fragmented thought; Micro class; Office software; Operating practice system","Education; Students; Teaching; Comprehensive utilizations; Development platform; Fragmented thought; Micro class; Multimedia development; Office softwares; Operating practices; Personalized learning; Computer software",2-s2.0-84963565223
"Liu J., Zhang Q., Tang C.","Base mesh extraction for different 3D faces based on ellipse fitting",2016,"Proceedings of 2015 IEEE Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966340292&doi=10.1109%2fIAEAC.2015.7428563&partnerID=40&md5=954018b581778d1fa0c1d73ef7f12dd9","Extracting base mesh for different 3D faces is a crucial and fundamental problem in 3D facial correspondence research. Establishing 3D facial correspondence can contribute to many computer graphics tasks and applications such as statistical 3D face model building, facial animation, and facial texture transferring, etc, but it suffers from the fact that different 3D faces usually have inconsistent boundaries and irregular representation. In this paper, we propose a novel method to extract 3D face base mesh for different 3D faces. The proposed method is fully automatic, and its main observation is that the ellipsoidal area around the five sense organs of 3D faces is the consistently matched area between different 3D faces. To extract the ellipsoidal area, we present two main approaches: (1) locating elliptical boundary points, (2) ellipse fitting and base mesh extraction. In the first approach, we present ways to determine the facial midline and the iso-curves which are parallel and perpendicular to the facial midline. During analyzing the facial midline and the iso-curves, we define a modified resultant force and its signed resultant force strength, then use them to locate the positions of a series of elliptical boundary points. In the second approach, we use these elliptical boundary points to fit an ellipse in the 2D representation of the 3D face scan by solving an over determined system of equations in the least square sense. Finally we use the fitted ellipse to extract the 3D face base mesh. We evaluate our method and compare it with other methods which are mostly related to ours in a large scale publicly available 3D face data set, BJUT-3D face database. The experimental results show that our method is robust and effective, and achieves better performance than existing methods. © 2015 IEEE.","3D faces; base mesh; ellipse fitting; elliptical boundary points; facial midline","Computer graphics; Extraction; Geometry; Mesh generation; 3D faces; base mesh; Boundary points; Ellipse fitting; facial midline; Three dimensional computer graphics",2-s2.0-84966340292
"Aouiti N., Jemni M., Semreen S.","Arab gloss annotation system for Arabic Sign Language",2016,"2015 5th International Conference on Information and Communication Technology and Accessibility, ICTA 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988328563&doi=10.1109%2fICTA.2015.7426932&partnerID=40&md5=7c03558bb419351072fcf9f5f8e202e4","Sign Language (SL) is a native language for deaf person which are about 70 million around the world. 17 million of this community are only in Arabic world. Despite the very important number of deaf people, Arabic Sign Language (ArSL) suffers from the lack of rules and grammatical structure that is required for the construction of an ArSL sentence. In this context, our work, as a part of the project WebSign [1] developed in Latice laboratory, aims to define an intermediate text representation based on gloss annotation system to transcribe ArSL. WebSign is a Web application. It is based on the technology of avatar (animation in virtual world). The input of the system is a text in natural language. The output is a real-time and online interpretation in sign language [2][3]. This interpretation is constructed thanks to a dictionary of word and signs. In fact, this work is an annotation system that's used to express many types of linguistic information like: type of the sentence, topic of the sentence and location of the sign. © 2015 IEEE.","Arabic Sign Language; Gloss Annotation System; transcrption","Interactive computer graphics; Transportation; Virtual reality; Annotation systems; Arabic sign language; Grammatical structure; Linguistic information; Native language; Natural languages; Text representation; transcrption; Natural language processing systems",2-s2.0-84988328563
"Li M., Liu S.","Integrating Animation-Based Inspection into Formal Design Specification Construction for Reliable Software Systems",2016,"IEEE Transactions on Reliability",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938783879&doi=10.1109%2fTR.2015.2456853&partnerID=40&md5=4ea50f879185d3bf29d47760adc86c60","Software design has been well recognized as an important means to achieve high reliability, and formal specification can help enhance the quality of design. However, communications between the designer and the user can become difficult via formal specifications due to the potentially complex mathematical expressions in the specification. This difficulty may lead to the situation where the user may not be closely involved in the process of constructing the specification for quality assurance. To allow formal specification to play more effective roles in software design, we put forward a new approach to deal with this problem in this paper. The approach is characterized by integrating specification animation-based inspection into the process of constructing formal design specifications. We discuss the underlying principle of the approach by explaining how specification animation is utilized as a reading technique for inspection to validate, and then evolve, the current specification towards a satisfactory one. We describe a prototype software tool for the method, and present a case study to show how the method supported by the tool works in practice. © 2015 IEEE.","Formal specification; specification animation; specification evolution; verification and validation","Animation; Computer software; Inspection; Quality assurance; Software design; Software prototyping; Software reliability; Specifications; High reliability; Mathematical expressions; Prototype software; Quality of design; Reading techniques; Software systems; Specification animations; Underlying principles; Formal specification",2-s2.0-84938783879
"Tang W., Wan T.R., Huang D.","Interactive thin elastic materials",2016,"Computer Animation and Virtual Worlds",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930536011&doi=10.1002%2fcav.1666&partnerID=40&md5=55258b564e288c3beb08e88a48cd31d3","Despite great strides in past years are being made to generate motions of elastic materials such as cloth and biological skin in virtual world, unfortunately, the computational cost of realistic high-resolution simulations currently precludes their use in interactive applications. Thin elastic materials such as cloth and biological skin often exhibit complex nonlinear elastic behaviors. However, modeling elastic nonlinearity can be computationally expensive and numerically unstable, imposing significant challenges for their use in interactive applications. This paper presents a novel simulation framework for simulating realistic material behaviors with interactive frame rate. Central to the framework is the use of a constraint-based multi-resolution solver for efficient and robust modeling of the material nonlinearity. We extend a strain-limiting method to work on deformation gradients of triangulated surface models in three-dimensional space with a novel data structure. The simulation framework utilizes an iterative nonlinear Gauss-Seidel procedure and a multilevel hierarchy structure to achieve computational speedups. As material nonlinearity are generated by enforcing strain-limiting constraints at a multilevel hierarchy, our simulation system can rapidly accelerate the convergence of the large constraint system with simultaneous enforcement of boundary conditions. The simplicity and efficiency of the framework makes simulations of highly realistic thin elastic materials substantially fast and is applicable of simulations for interactive applications. Copyright © 2015 John Wiley & Sons, Ltd.","cloth simulation; computer animation; computer games; interactive virtual reality applications","Animation; Bioinformatics; Computer games; Elasticity; Interactive computer graphics; Interactive devices; Iterative methods; Materials properties; Virtual reality; Cloth simulation; Computer animation; High resolution simulations; Interactive applications; Interactive frame rates; Interactive virtual reality; Non-linear elastic behavior; Triangulated surface model; Biological materials",2-s2.0-84930536011
"Hess S., Fischer S., Taborsky B.","Territorial aggression reduces vigilance but increases aggression towards predators in a cooperatively breeding fish",2016,"Animal Behaviour",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978955248&doi=10.1016%2fj.anbehav.2016.01.008&partnerID=40&md5=1feee0221159ba2d057e67a1816f08d7","In many species, aggressive individuals outcompete their less aggressive conspecifics for resources such as food and access to mates. Nevertheless, variation in aggression is maintained in populations, but the underlying mechanisms are not well understood. Here we tested the hypothesis that aggressive behaviours compromise the antipredator behaviour of prey, which would link aggressive behaviours to a cost of predation. We presented computer-animated images of predators to the cooperatively breeding cichlid fish Neolamprologus pulcher either during territorial contests with a group of territory intruders or when the test fish were alone. We investigated their response latencies and the behaviour directed towards predator images. We found that test fish responded to the predator images significantly later during territorial contests than when they were alone. Moreover, during territorial contests, response latencies of test fish increased with increasing levels of aggression towards conspecifics. Test fish also responded more aggressively to the predator images during territorial contests than when they were alone. During territorial contests, fish that responded later to the predator images were more aggressive towards these images. Our findings suggest that territorial contests compromised the ability of prey to respond quickly to predators. However, we propose that increased aggression towards predators might increase survival chances of prey during predator encounters in nature, and it may thus compensate for costs incurred by delayed predator responses during territorial contests. To test this hypothesis experiments under natural predation regimes that examine the relationship between predation risk, territorial and antipredator aggression are required. © 2016 The Association for the Study of Animal Behaviour","antipredator behaviour; cichlid fish; computer animation; predation risk; territory defence; trade-off","aggression; cichlid; computer simulation; conspecific; hypothesis testing; predation risk; predator; predator-prey interaction; prey availability; survival; territoriality; vigilance; Cichlidae; Neolamprologus pulcher",2-s2.0-84978955248
"Lu D., Zhu D., Wang Z., Gao J.","Efficient level of detail for texture-based flow visualization",2016,"Computer Animation and Virtual Worlds",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930074526&doi=10.1002%2fcav.1664&partnerID=40&md5=6bb377ddd1a9f50914b8cd220e2afc61","In this paper, we present an efficient level of detail algorithm for texture-based flow visualization. Our goal is to enhance visual perception and performance and generate smooth animation. To achieve our goal, we first model an adaptive input texture taking into account flow patterns to output view-dependent high-quality images. Then, we compute field lines only from sparse sampling points of the input noise texture for outputting volume line integral convolution textures and skip empty space utilizing two quantized binary histograms. To improve image quality, we implement anti-aliasing through adjusting the line integral convolution step size and thickness of trajectory lines with an opacity function. We further extend our solution to unsteady flow. Flow structures and evolution are clearly shown through smooth animation achieved with coherent evolution of particles, handling of discontinuous flow lines, and spatio-temporal linear constraint of the underlying noise volume. In the result section, we show high-quality level of detail of three-dimensional texture-based flow visualization with high performance. We also demonstrate that our algorithm can achieve smooth evolution for unsteady flow with spatio-temporal coherence. Copyright © 2015 John Wiley & Sons, Ltd.","efficient acceleration; level of detail; noise optimization; smooth animation; texture-based visualization","Algorithms; Animation; Anti-aliasing; Compressed sensing; Convolution; Textures; Three dimensional computer graphics; Unsteady flow; Visualization; Discontinuous flow; High quality images; Level of detail; Line integral convolution; Linear constraints; Noise optimization; Smooth evolutions; Visual perception; Flow visualization",2-s2.0-84930074526
"Lu G., Chen L., Luo W.","Real-time crowd simulation integrating potential fields and agent method",2016,"ACM Transactions on Modeling and Computer Simulation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964528964&doi=10.1145%2f2885496&partnerID=40&md5=d82f59527b1c71f854d4aac5674af190","Crowd simulation is studied extensively in computer graphics, animation, and safety. A real-time crowd simulator has been developed based on potential fields and agent approach in this article. This simulator produces realistic complex heterogeneous motion and improves the simulation rates by at least 32% in comparison with the potential field results. The model of this simulator can efficiently tackle the problems in global optimal navigation, collision avoidance, and dynamic interaction; furthermore, it allows an agent to make independent decisions. © 2016 ACM.","Agent; Animation; Crowd dynamics; Crowd simulation; Human behavior; Potential field; Types of simulation","Agents; Animation; Computer graphics; Simulators; Crowd dynamics; Crowd Simulation; Human behaviors; Potential field; Types of simulation; Behavioral research",2-s2.0-84964528964
"Pirovano M., Mainetti R., Baud-Bovy G., Lanzi P.L., Borghese N.A.","Intelligent Game Engine for Rehabilitation (IGER)",2016,"IEEE Transactions on Computational Intelligence and AI in Games",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963786139&doi=10.1109%2fTCIAIG.2014.2368392&partnerID=40&md5=99c0c33dc701259ef52657b31b0c935e","Computer games are a promising tool to support intensive rehabilitation. However, at present, they do not incorporate the supervision provided by a real therapist and do not allow safe and effective use at a patient's home. We show how specifically tailored computational intelligence based techniques allow extending exergames with functionalities that make rehabilitation at home effective and safe. The main function is in monitoring the correctness of motion, which is fundamental in avoiding developing wrong motion patterns, making rehabilitation more harmful than effective. Fuzzy systems enable us to capture the knowledge of the therapist and to provide real-time feedback of the patient's motion quality with a novel informative color coding applied to the patient's avatar. This feedback is complemented with a therapist avatar that, in extreme cases, explains the correct way to carry out the movements required by the exergames. The avatar also welcomes the patient and summarizes the therapy results to him/her. Text to speech and simple animation improve the engagement. Another important element is adaptation. Only the proper level of challenge exercises can be both effective and safe. For this reason exergames can be fully configured by therapists in terms of speed, range of motion, or accuracy. These parameters are then tuned during exercise to the patient's performance through a Bayesian framework that also takes into account input from the therapist. A log of all the interaction data is stored for clinicians to assess and tune the therapy, and to advise patients. All this functionality has been added to a classical game engine that is extended to embody a virtual therapist aimed at supervising the motion, which is the final goal of the exergames for rehabilitation. This approach can be of broad interest in the serious games domain. Preliminary results with patients and therapists suggest that the approach can maintain a proper challenge level while keeping the patient motivated, safe, and supervised. © 2014 IEEE.","Bayes methods; fuzzy systems; game engine; patient rehabilitation; virtual feedback; virtual therapist","Animation; Artificial intelligence; Computer games; Fuzzy systems; Interactive computer graphics; Patient treatment; Real time systems; Bayes method; Bayesian frameworks; Challenge levels; Game Engine; Real-time feedback; Rehabilitation at homes; Virtual feedback; virtual therapist; Patient rehabilitation",2-s2.0-84963786139
"Wang Y., Tree J.E.F., Walker M., Neff M.","Assessing the impact of hand motion on virtual character personality",2016,"ACM Transactions on Applied Perception",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964545816&doi=10.1145%2f2874357&partnerID=40&md5=56ffc1b67c01ba6be5a796500c3d4ed0","Designing virtual characters that are capable of conveying a sense of personality is important for generating realistic experiences, and thus a key goal in computer animation research. Though the influence of gesture and body motion on personality perception has been studied, little is known about which attributes of hand pose and motion convey particular personality traits. Using the ""Big Five"" model as a framework for evaluating personality traits, this work examines how variations in hand pose and motion impact the perception of a character's personality. As has been done with facial motion, we first study hand motion in isolation as a requirement for running controlled experiments that avoid the combinatorial explosion of multimodal communication (all combinations of facial expressions, arm movements, body movements, and hands) and allow us to understand the communicative content of hands. We determined a set of features likely to reflect personality, based on research in psychology and previous human motion perception work: shape, direction, amplitude, speed, and manipulation. Then we captured realistic hand motion varying these attributes and conducted three perceptual experiments to determine the contribution of these attributes to the character's personalities. Both hand poses and the amplitude of hand motion affected the perception of all five personality traits. Speed impacted all traits except openness. Direction impacted extraversion and openness. Manipulation was perceived as an indicator of introversion, disagreeableness, neuroticism, and less openness to experience. From these results, we generalize guidelines for designing detailed hand motion that can add to the expressiveness and personality of characters. We performed an evaluation study that combined hand motion with gesture and body motion. Even in the presence of body motion, hand motion still significantly impacted the perception of a character's personality and could even be the dominant factor in certain situations. © 2016 ACM.","Conversational and non-verbal behavior; Evaluation; Hand motion; Personality","Psychology computing; Sensory perception; Combinatorial explosion; Controlled experiment; Conversational and non-verbal behavior; Evaluation; Facial Expressions; Hand motion; Multimodal communications; Personality; Animation",2-s2.0-84964545816
"Likhachev I.V., Balabaev N.K., Galzitskaya O.V.","Available instruments for analyzing molecular dynamics trajectories",2016,"Open Biochemistry Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971639715&doi=10.2174%2f1874091X01610010001&partnerID=40&md5=b79c8fa40d7eb9ba667f44964c662d2d","Molecular dynamics trajectories are the result of molecular dynamics simulations. Trajectories are sequential snapshots of simulated molecular system which represents atomic coordinates at specific time periods. Based on the definition, in a text format trajectory files are characterized by their simplicity and uselessness. To obtain information from such files, special programs and information processing techniques are applied: from molecular dynamics animation to finding characteristics along the trajectory (versus time). In this review, we describe different programs for processing molecular dynamics trajectories. The performance of these programs, usefulness for analyses of molecular dynamics trajectories, strong and weak aspects are discussed. © Likhachev et al.","Analysis; MD program; MD trajectory; Protein conformation; Silico experiment","Alchemy 2000; CMView; computer program; computer system; DockSearch; gromacs; HyperChem; information processing; MoDyp; molecular dynamics; namd; priority journal; QuteMol; Review; simulation; spartan; tamd; visual molecular dynamics; WhatIF Project",2-s2.0-84971639715
"Nikolai J., Bennett G.","Stillness, breath and the spine - Dance performance enhancement catalysed by the interplay between 3D motion capture technology in a collaborative improvisational choreographic process",2016,"Performance Enhancement and Health",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952054907&doi=10.1016%2fj.peh.2015.11.003&partnerID=40&md5=0dde37536d1fbade1931e22cc2789d95","We propose that Motion Capture (MoCap) in dance is part of, but distinct from, the traditional use of film or video as an archival and indexical instrument. Furthermore in the move from the recording of framed and temporally consistent slices of linear film or video 'footage' to the collection of profoundly mutable digital data utilising an Omniscient Frame, there is a fundamental conceptual shift in the creative re-shaping of the performance through a shared choreographic process. In the improvised choreographic and live performance process, qualitative differences in evaluating MoCap were identified. Study #1 (2015) is a collaborative screendance work by the authors, dancer (Author One), and digital artist (Author two). This piece utilises 3D Motion Capture technology and 3D digital animation software as part of a series of dance and moving image experiments. MoCap offers enhanced perspectives towards compositional awareness and evaluation between live and digital platforms. The human movement material produced in response to the MoCap technology optimises the potential of the technology and the human, moving body, with a catalysing force. We propose that what is transferred from live to digital via the omniscient motion capture camera informs what we see towards creative possibilities. We identify that the live performer as movement data does manifest as digital presence. We propose that we can view dance data and that this does aid performance - not towards quantitative evaluation but in capturing specific, human movement qualities towards qualitative artistic evaluation and critique. © 2015 Elsevier Ltd.","Creative screendance output; Interdisciplinary collaboration; Live and digital dance-making; Motion capture; Performance enhancement; Qualitative evaluation","awareness; breathing; catalysis; computer program; dancing; human; motion; quantitative study; spine",2-s2.0-84952054907
"Lefor A.K., Maeno M.","Preparing scientific papers, posters, and slides",2016,"Journal of Surgical Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958793849&doi=10.1016%2fj.jsurg.2015.09.020&partnerID=40&md5=3eb2267f92c77eccea10951bab51edff","Publications and presentations are important in academic medicine. The ability to present information in a standard fashion is critically important. Papers, posters, and slides must be prepared appropriately to maximize their chance of being accepted. The first step is to use word processing software correctly. English language usage must conform to standard scientific English usage. Abbreviations should be avoided as much as possible. Numerical data must be presented with the appropriate number of significant figures. The first step in preparing a paper is to decide the target journal. Papers should always be written in 12 point Times New Roman font, while slides and posters should be in Arial or Helvetica. The Results section must contain actual data with appropriate statistical analysis. Take great care to prepare figures and tables according to the journal's instructions. Posters must be prepared to allow easy reading at a distance of 2m. Use a white background and dark letters. The majority of the area of your poster should be Results, and there is no need to include the abstract or references on a poster. Slide presentations should be limited to about one slide for each minute of the talk. Avoid the use of animations and excessive use of color. Do not use abbreviations on slides. Following these simple guidelines will meet the requirements of most journals and allow your audience to appreciate the data on your posters and slides. © 2015 Association of Program Directors in Surgery.","scientific paper; scientific poster; slide presentation; word processing","Article; automation; computer program; human; language; practice guideline; priority journal; publication; scientific literature; medical research; publication; publishing; writing; Biomedical Research; Humans; Publications; Publishing; Writing",2-s2.0-84958793849
"Eriksson K., Andersson P.A., Strimling P.","Moderators of the disapproval of peer punishment",2016,"Group Processes and Intergroup Relations",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958156325&doi=10.1177%2f1368430215583519&partnerID=40&md5=b8475c29a481e8f54d7e3529378044be","Recent studies have found disapproval of peer punishment of norm violations. This seems puzzling, given the potential benefits peer punishers contribute to the group. We suggest part of the answer is that peer punishers tend to come across as aggressive and as such may be viewed as more problematic than beneficial to have around. We used simple computer animations of geometric shapes to enact 15 precise variations of social sanctions against a norm violator. More than 1,800 subjects were recruited to watch an animation and judge the behavior and character of the animated agents. They also completed a trait aggression measure. Across the variations peer punishment was typically disapproved of, especially when severe or openly aggressive, and especially by subjects low on trait aggression. We conclude that there seems to be a social norm against peer punishment and that dislike of aggressiveness seems to be part of the reason why. © 2015, © The Author(s) 2015.","peer punishment; social control; social judgment; social norms; trait aggression",,2-s2.0-84958156325
"Egorova O., Shcherbinin D.","Creating technical heritage object replicas in a virtual environment",2016,"Frontiers of Mechanical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959496350&doi=10.1007%2fs11465-016-0363-4&partnerID=40&md5=0fc6ad338b257c7383098c83fa53fe7a","The paper presents innovative informatics methods for creating virtual technical heritage replicas, which are of significant scientific and practical importance not only to researchers but to the public in general. By performing 3D modeling and animation of aircrafts, spaceships, architectural-engineering buildings, and other technical objects, the process of learning is achieved while promoting the preservation of the replicas for future generations. Modern approaches based on the wide usage of computer technologies attract a greater number of young people to explore the history of science and technology and renew their interest in the field of mechanical engineering. © 2016, Higher Education Press and Springer-Verlag Berlin Heidelberg.","3D document; history of science and technology; mechanism and machine science (MMS); popularization; replica; technical knowledge; virtual environment",,2-s2.0-84959496350
"Kapadia M., Xianghao X., Nitti M., Kallmann M., Coros S., Sumner R.W., Gross M.","Precision: Precomputing environment semantics for contact-rich character animation",2016,"Proceedings - 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D 2016",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964811395&doi=10.1145%2f2856400.2856404&partnerID=40&md5=ebf037a8bf9b985e743d4d809fc2cdd1","The widespread availability of high-quality motion capture data and the maturity of solutions to animate virtual characters has paved the way for the next generation of interactive virtual worlds exhibiting intricate interactions between characters and the environments they inhabit. However, current motion synthesis techniques have not been designed to scale with complex environments and contact-rich motions, requiring environment designers to manually embed motion semantics in the environment geometry in order to address online motion synthesis. This paper presents an automated approach for analyzing both motions and environments in order to represent the different ways in which an environment can afford a character to move. We extract the salient features that characterize the contact-rich motion repertoire of a character and detect valid transitions in the environment where each of these motions may be possible, along with additional semantics that inform which surfaces of the environment the character may use for support during the motion. The precomputed motion semantics can be easily integrated into standard navigation and animation pipelines in order to greatly enhance the motion capabilities of virtual characters. The computational efficiency of our approach enables two additional applications. Environment designers can interactively design new environments and get instant feedback on how characters may potentially interact, which can be used for iterative modeling and refinement. End users can dynamically edit virtual worlds and characters will automatically accommodate the changes in the environment in their movement strategies. © 2016 Copyright held by the owner/author(s).","Character animation; Contactrich motion; Environment semantics","Computational efficiency; Interactive computer graphics; Iterative methods; Semantics; Three dimensional computer graphics; Virtual reality; Animation pipeline; Automated approach; Character animation; Complex environments; Contactrich motion; Environment geometry; Motion capture data; Virtual character; Animation",2-s2.0-84964811395
"Han S., Sander P.V.","Triangle reordering for reduced overdraw in animated scenes",2016,"Proceedings - 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964813435&doi=10.1145%2f2856400.2856408&partnerID=40&md5=457cf7e91be1c5cb8d5c299cf2ac9f8f","We introduce an automatic approach for optimizing the triangle rendering order of animated meshes with the objective of reducing overdraw while maintaining good post-transform vertex cache efficiency. Our approach is based on prior methods designed for static meshes. We propose an algorithm that clusters the space of viewpoints and key frames. For each cluster, we generate a triangle order that exhibits satisfactory vertex cache efficiency and low overdraw. Results show that our approach significantly improves overdraw throughout the entire animation sequence while only requiring a few index buffers. We expect that this approach will be useful for games and other real-time rendering applications that involve complex shading of articulated characters. © 2016 ACM.","Depth sorting; Overdraw reduction; Real-time rendering","Animation; Computer graphics; Efficiency; Interactive computer graphics; Rendering (computer graphics); Automatic approaches; Key frames; Real-time rendering; Vertex cache; Three dimensional computer graphics",2-s2.0-84964813435
"Kontopoulos D.G., Vlachakis D., Tsiliki G., Kossida S.","Structuprint: A scalable and extensible tool for two-dimensional representation of protein surfaces",2016,"BMC Structural Biology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959091392&doi=10.1186%2fs12900-016-0055-7&partnerID=40&md5=b317ccfd0574868aaf9a80b9d055b279","Background: The term 'molecular cartography' encompasses a family of computational methods for two-dimensional transformation of protein structures and analysis of their physicochemical properties. The underlying algorithms comprise multiple manual steps, whereas the few existing implementations typically restrict the user to a very limited set of molecular descriptors. Results: We present Structuprint, a free standalone software that fully automates the rendering of protein surface maps, given - at the very least - a directory with a PDB file and an amino acid property. The tool comes with a default database of 328 descriptors, which can be extended or substituted by user-provided ones. The core algorithm comprises the generation of a mould of the protein surface, which is subsequently converted to a sphere and mapped to two dimensions, using the Miller cylindrical projection. Structuprint is partly optimized for multicore computers, making the rendering of animations of entire molecular dynamics simulations feasible. Conclusions: Structuprint is an efficient application, implementing a molecular cartography algorithm for protein surfaces. According to the results of a benchmark, its memory requirements and execution time are reasonable, allowing it to run even on low-end personal computers. We believe that it will be of use - primarily but not exclusively - to structural biologists and computational biochemists. © 2016 Kontopoulos et al.","Molecular cartography; Protein surfaces; Structural biology; Surface comparison; Visualization","amino acid; protein; Escherichia coli protein; amino acid composition; Article; computer program; controlled study; data analysis; molecular dynamics; protein analysis; protein database; protein structure; quality control; Structuprint; algorithm; chemistry; computer interface; protein conformation; software; surface property; Algorithms; Escherichia coli Proteins; Protein Conformation; Software; Surface Properties; User-Computer Interface",2-s2.0-84959091392
"Yun C., Panahi H., Deng Z.","A multidisciplinary, multifaceted approach to improve the computer science based game design education: Methodology and assessment",2016,"SIGCSE 2016 - Proceedings of the 47th ACM Technical Symposium on Computing Science Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968548130&doi=10.1145%2f2839509.2844582&partnerID=40&md5=623ee2154e0e9c6069cac6d4f5af8b29","In this paper, we introduce a multidisciplinary and multifaceted pedagogical approach to enhance game design education in computer science curriculum and assess its effectiveness using outcomes from Microsoft US and World Imagine Cup competitions in the game design category. We offer team project-based courses that cover multiple disciplines such as computer science, art and animation, game design, production, and business and entrepreneurship. Our students gain fundamental knowledge and skills from the multidisciplinary approach and utilize them to undergo a systematic game development process over two semesters. We also implement a unique grading system that includes ranking duels to promote the competitiveness among students which ultimately improves the quality of every game designed in our courses. We successfully demonstrate the effectiveness of our approach with results from the Microsoft Imagine Cup competitions - dozens of our student teams have been nationally and internationally recognized in the past eight consecutive years. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Computer Science; Education; Games Design; Imagine Cup","Animation; Computer science; Curricula; Design; Education; Education computing; Engineering education; Grading; Software design; Students; Teaching; Computer science curricula; Game development; Grading system; Imagine Cup; Multi-disciplinary approach; Multi-faceted approach; Multiple disciplines; Pedagogical approach; Computer games",2-s2.0-84968548130
"Chwif L., Pereira W.I., Montevechi J.A.B.","Are visually appealing simulation models preferable?",2016,"Proceedings - Winter Simulation Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962861022&doi=10.1109%2fWSC.2015.7408220&partnerID=40&md5=67ee57980e9a23d3e13fadf66399a6b9","In the early days of computer simulation, models were mostly developed in Fortran, and there was no graphical animation. Due mainly to increasing graphical capabilities of operational systems, simulation was integrated with animation, setting a new standard in simulation software. The objective of this article is to explore this issue, first making a literature review and then trying to answer the question depicted in the title. It first demonstrates a methodology to evaluate whether a simulation model can be considered attractive; then, in a practical study, we try to correlate this attractiveness factor to the model's preference. The conclusions were very promising, showing that attractiveness is one factor that does interfere in model's preference. © 2015 IEEE.",,"Animation; Graphical animation; Literature reviews; One-factor; Operational systems; Simulation model; Simulation software; Computer software",2-s2.0-84962861022
"Chen L.-H., Hsieh W.-F., Lin J.-Y., Wang C.-H., Takama Y., Chen Y.-S.","Synthesizing a NPR navigating animation based on Route Recommendation",2016,"TAAI 2015 - 2015 Conference on Technologies and Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964225145&doi=10.1109%2fTAAI.2015.7407099&partnerID=40&md5=95d3e6385f57eda30c79b01c2fd4b5b6","As science and technology continue to progress, we are getting used to utilize these new information technologies for the convenience of our daily lives. For example, Google Map and Open Street Map have become very popular and important tools for viewing street maps in recent years. © 2015 IEEE.","computer graphics; information visualization; navigating animation; non-photorealistic rendering; open source; route recommendation; street view","Animation; Artificial intelligence; Color image processing; Information systems; Daily lives; Google maps; Information visualization; Non-Photorealistic Rendering; Open sources; route recommendation; Science and Technology; Street maps; Computer graphics",2-s2.0-84964225145
"Lv P., Xu M., Yang B., Li M., Zhou B.","Data-driven humanlike reaching behaviors synthesis",2016,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959507139&doi=10.1016%2fj.neucom.2015.10.118&partnerID=40&md5=9164cc962e748d8d91bcd57673a6b480","Reaching is one of the most important behaviors in our daily life and has attracted plenty of researchers to work on it both in computer animation and robot research area. However, existing proposed methods either lack of flexibility or their results are not so convincing. In this paper, we present a novel controller-based framework for reaching motion synthesis. Our framework consists of four stationary controllers to generate concrete reaching motion and three transition controllers to stitch these stationary controllers automatically. For each stationary controller, it can either be applied alone or combined with other stationary controllers. Due to this design, our method can imitate the inherent tentative process for human reaching effectively. And our controller is able to generate continuous reaching motion based on virtual character's previous status with no need to start from one same initial pose. Moreover, we involve an important gaze simulation model into each controller, which can guarantee the consistency between the head and hand movement. The experiments show that our framework is very easy to be implemented and can generate natural-looking reaching motion in real-time. © 2015 Elsevier B.V.","Controller; Data-driven; Optimization; Reaching; Transition","Animation; Optimization; Synthesis (chemical); Computer animation; Data driven; Hand movement; Reaching; Reaching motion; Simulation model; Transition; Virtual character; Controllers; Article; biological model; conceptual framework; control system; eye hand coordination; gaze; hand movement; head movement; methodology; motor coordination; motor performance; priority journal; simulation; virtual reality",2-s2.0-84959507139
"Guo X., Wang J., Yang Y., Zhang X., Xu G.","Active and passive training system of lower limb rehabilitation based on virtual reality",2016,"Hsi-An Chiao Tung Ta Hsueh/Journal of Xi'an Jiaotong University",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960907562&doi=10.7652%2fxjtuxb201602021&partnerID=40&md5=b563486c72d4db9d16ebf2cf8026bdde","Aiming at the problems such as low participation in the traditional lower limb rehabilitation training and being unable to produce the active movement intention, a lower limb rehabilitation training system based on virtual reality is designed. Following the theories of human brain mirror neurons and neural plasticity, real-time data communication and feedback processing are realized with Matlab and Labview software. Combining with the method for virtual reality modeling and animation script editing and exerting effect on the patient central nervous system through 3D visual and auditory, a closed information transmission loop is constructed to achieve the active and passive synergistic stimulation of the damaged nerve center to stimulate the brain motor area of mirror neurons and to strengthen the independent movement intention. The results show that the system is able to assist patients to complete rehabilitation training of active and passive mode, and provides patients with the depth of the living environment of the virtual visual interaction, which greatly enhance the rehabilitation training for patients with damaged neural stimulation, and improve the training efficiency and positive initiative. © 2016, Editorial Office of Journal of Xi'an Jiaotong University. All right reserved.","Lower limb rehabilitation training system; Virtual reality; Visual interaction","Computer programming languages; Electrophysiology; MATLAB; Mirrors; Neuromuscular rehabilitation; Virtual reality; Central nervous systems; Information transmission; Lower limb; Real-time data communication; Rehabilitation training; Training efficiency; Virtual reality modeling; Visual interaction; Patient rehabilitation",2-s2.0-84960907562
"Jeong W.","The usability study on the multicultural children’s book project of the National Library for Children and Young Adults (NLCY) in Korea",2016,"Digital Library Perspectives",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015310855&doi=10.1108%2fDLP-07-2015-0009&partnerID=40&md5=278b1eff29f17832b104a28a2430b6a9","Purpose – The purpose of this study is to identify usability issues on a storytelling digital library with six languages provided by the National Library for Children and Young Adults (NLCY) in Korea, and to provide suggestions for future improvement to create a better interface. Design/methodology/approach – In this study, usability issues at the multicultural children’s book project Web site of the NLCY were identified, with comparison between the previous interface and the current one, based on the findings of established literature on children’s use of computer applications and web interface. Findings – Suggestions for improvements include brighter colors, bigger fonts and graphics, more lively animation and sound, easier navigation, consistent interface, summary availability, better organization of information and labeling and multilingual searching and browsing function. A user study is being planned for future development. Originality/value – There is a great value in making 400 children’s books available to the public at the NLCY digital library in six different languages with their original pictures animated and their stories performed in a storytelling mode. However, to provide more pleasant access to the valuable site, particularly for children users, there is much room for improvement in terms of the user interface. Based on these findings, a user study is being planned for future development, which should be more intuitive for users, particularly children. © 2016, © Emerald Group Publishing Limited.","Children’s digital libraries; Children’s interaction with computers; Digital libraries; Human computer interaction; Usability; User interface","Human computer interaction; Usability engineering; User interfaces; Design/methodology/approach; Future improvements; National libraries; Organization of informations; Usability; Usability studies; Web interface; Young adults; Digital libraries",2-s2.0-85015310855
"Saputra M.R.U., Nugroho K.A.","Learn-to-read application for remediation of dyslexic children based on multisensory approach",2016,"Proceedings - 2015 4th International Conference on Instrumentation, Communications, Information Technology and Biomedical Engineering, ICICI-BME 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963988118&doi=10.1109%2fICICI-BME.2015.7401366&partnerID=40&md5=ef0c3711595df80951f2785201701b95","This paper describes learn-to-read application for assisting therapist/teacher in conducting remediation programme of dyslexic children. The application is developed in Indonesian language for 5-7 years old dyslexic. Based on multisensory approach, the application is designed to utilize all of sensory receptors of dyslexic hence incorporating visual-audio feedback and supporting tactile-kinesthetic interaction. The contents of the application is comprehensive by including pre-reading and specific skill for dyslexic's daily life (such as short-term memory and directionality) in addition to reading skills. Implemented using Windows Presentation Foundation technology, the application provides smooth animation and nice graphic to engage and attract dyslexic attention. Adapted from Heuristic Evaluation, testing by dyslexic experts (n = 6) results in high scores of usability of user interface (4.113, scale of 5) and content of the application (4.078, scale of 5). © 2015 IEEE.","computer desktop application; dyslexia; multisensory; reading and learning problems; remediation","Biomedical engineering; Pollution; Remediation; Audio feedbacks; Desktop applications; dyslexia; Heuristic evaluation; Indonesian languages; Learning problem; Multisensory; Short term memory; User interfaces",2-s2.0-84963988118
"Yang Y., Chen J., Zhan Y., Wang X., Wang J., Liu Z.","Low level segmentation of motion capture data based on cosine distance",2016,"Proceedings - 2015 3rd International Conference on Computer, Information and Application, CIA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969796254&doi=10.1109%2fCIA.2015.14&partnerID=40&md5=07542eaf675c87a0df768a8d4db98089","3D motion capture is to track and record human movements. In recent years, it has been applied into many fields, such as human computer interaction, animation, etc. Low-level segmentation of motion capture data is of significance to the various applications of 3D motion capture, however, due to the high dimensionality of motion capture data, traditional low-level segmentation methods can hardly work out a suitable segmentation for motion capture data. In order to solve this problem, a low-level temporal segmentation algorithm based on cosine distance is proposed, hierarchical clustering is explored so that similar velocity vectors are clustered together according to the cosine distance in a progressive way, the center of each cluster is updated as the vector derived with linear regression, the segment boundaries are determined as the point when the cosine distance between adjacent velocity vectors is greater than 1 (angle>90 degrees). We have conducted experiments on the motion capture database provided by Carnegie Mellon University (CMU), the experiment results show that the performance of the proposed method is optimistic. © 2015 IEEE.","Cosine distance; Hierarchical clustering; Low level segmentation; Motion capture","Computer science; Computers; Carnegie Mellon University; Cosine distance; Hier-archical clustering; High dimensionality; Motion capture; Segmentation methods; Segmentation of motions; Temporal segmentations; Human computer interaction",2-s2.0-84969796254
"Hayashi M., Bachelder S., Nakajima M.","Open Framework Facilitating Automatic Generation of CG Animation from Web Site",2016,"Proceedings - 2015 International Conference on Cyberworlds, CW 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964260526&doi=10.1109%2fCW.2015.11&partnerID=40&md5=14e61cb7a75929aea61a4cad847ca256","We have been studying and developing the system which enables to generate Computer Graphics Animation (CGA) automatically by processing HTML data of Web site. In this paper, we propose an open framework to facilitate this. The framework is functioning all at a server side, obtaining the HTML, converting it to a script describing the CGA story and updating the script. And at a client side, a user accesses the script on the server to visualize it by using real-time CG character with synthesized voice, camera work, superimposing, sound file playback etc. We have constructed the framework on the server and deployed the substantial engines to convert Web sites to CGAs. This paper describes the detail of the framework and also shows some example projects providing automatically generated News show, Talk show and personal Blog visualization. © 2015 IEEE.","animation; media conversion; scripting langauge; text visualization","Animation; Computer graphics; HTML; Visualization; Websites; Automatic Generation; Automatically generated; Camera works; Client sides; Media conversion; Open frameworks; scripting langauge; Text visualization; Data handling",2-s2.0-84964260526
"Punchimudiyanse M., Meegama R.G.N.","3D signing avatar for Sinhala Sign language",2016,"2015 IEEE 10th International Conference on Industrial and Information Systems, ICIIS 2015 - Conference Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964671833&doi=10.1109%2fICIINFS.2015.7399026&partnerID=40&md5=26ec4d6046fc6625ed387f03ff7cde55","A sign language possesses multi-posture and single posture signs that require animation of bones on demand in a 3D signing avatar. Fingerprinting is used for representing unknown words character by character. Ordering and sequencing of signs corresponding to the words/phrases of a natural language are the most essential features of animating a sign language. This paper presents a multi-facet 3D avatar and an animation system for Sinhala Sign language (SSL) which supports the definition and animation of sign gestures without video sequencing or motion capture hardware. The animation system animates upper body of the avatar and consists of 29 bones per arm. Speed and uniformity of the sign gesture animation is achieved by automatically calculating the intermediate and transitional sequences of arm movements of signs within a given number of frames, or with a user defined displacement value per bone. Avatar animation system also supports the definition of fingerprinting signs, with a user defined tag set corresponding to the alphabet of any given sign language. Presented prototype consists of 200 known signs and 40 fingerprinting signs of SSL defined in its sign database and having the capability of animating any sentence in Sinhala language in SSL. © 2015 IEEE.","3D Signing avatar; Animation framework; Sinhala Sign Language","Animation; Bone; Computational linguistics; Information systems; Animation systems; Displacement value; Essential features; Gesture animation; Natural languages; Sign language; Signing avatars; Video sequencing; Three dimensional computer graphics",2-s2.0-84964671833
"Iglesias A., Galvez A., Collantes M.","Bat Algorithm for Curve Parameterization in Data Fitting with Polynomial Bézier Curves",2016,"Proceedings - 2015 International Conference on Cyberworlds, CW 2015",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964282419&doi=10.1109%2fCW.2015.27&partnerID=40&md5=2bbf8632d85a590f6cd91b993225b01c","A very important issue in many applied fields is to construct the fitting curve that approximates a given set of data points optimally in the sense of least-squares. This problem arises in a number of areas, such as computer-aided design and manufacturing (CAD/CAM), virtual reality, medical imaging, computer graphics, computer animation, and many others. Since the problem consists of minimizing the least-squares fitting error, it can be formulated as an optimization problem. Unfortunately, it is also a highly nonlinear, over-determined, multivariate continuous optimization problem. As a consequence, classical mathematical methods cannot solve it in its generality. Clearly, there is a need for more general techniques to tackle this issue. A critical step in this process is to obtain a suitable parameterization of the data points. In this context, this paper introduces a new method to obtain an optimal solution for the parameterization problem of the least-squares fitting Bézier curve. Our approach is based on a powerful nature-inspired optimization method called bat algorithm, which has been recently introduced to solve hard continuous optimization problems. In spite of these remarkable features for optimization, the bat algorithm has never been applied in the context of data fitting for geometric modeling or computer graphics. To analyze the performance of this approach, it has been applied to some simple yet illustrative examples of Bézier curves with satisfactory results. © 2015 IEEE.","bat algorithm; Bézier curve; curve parameterization; data fitting; Nature-inspired techniques; reverse engineering","Algorithms; Animation; Computer aided design; Computer graphics; Data handling; Least squares approximations; Medical imaging; Optimization; Parameter estimation; Parameterization; Reverse engineering; Virtual reality; Bat algorithms; Continuous optimization problems; Data fittings; Least squares fitting; Mathematical method; Nature-inspired techniques; Optimization method; Optimization problems; Curve fitting",2-s2.0-84964282419
"Zanata R.","Particle System",2016,"Proceedings - 2015 International Conference on Cyberworlds, CW 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964294687&doi=10.1109%2fCW.2015.17&partnerID=40&md5=820ded6f8c3de43ea83a4f9c11def917","In this paper we examine the project of a PARTICLE SYSTEM and the approaches to the NUI (Natural User Interface) applied to a multimedia interactive installation done with Processing1 and Supercollider2. Supercollider is a programming language for real time audio synthesis and algorithmic composition. Processing is an open source programming language and environment for people who want to create images, animations, and interactions"". It is designed to be used by artists, therefore does not require deep programming knowledge and it makes the task of practical implementation of ideas rather simple and immediate. It is very close to Java language but the possibility to implement interaction and 2D/3D graphics or animation of a particle system is much more easy. A particle system is a collection of many minute particles that together represent a fuzzy object. Over a period of time, particles are generated into a system, move and change from within the system, and die from the system. © 2015 IEEE.","Audiovideo; Multimedia; Particle; Processing; Supercollider","Algorithmic languages; Computational linguistics; Computer programming languages; Open source software; Particles (particulate matter); Processing; User interfaces; Algorithmic compositions; Audiovideo; Interactive installations; Multimedia; Natural user interfaces; Open-source programming; Programming knowledge; SuperCollider; Java programming language",2-s2.0-84964294687
"Lu Y., Sheng Y., Zhang G.","Instant Messenger with Personalized 3D Avatar",2016,"Proceedings - 2015 International Conference on Cyberworlds, CW 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964197743&doi=10.1109%2fCW.2015.25&partnerID=40&md5=c52f33d6e7dd4daa08fae839283bcbb5","Instant Messengers (IM) have become popular online chat tools in cyber worlds. The existing IMs mainly rely on text, audio, and video for user conversation and communication. The pure text chat is monotonous, while the video chat only occurs when users have their webcoms installed and wish to see each other. In this paper, we propose a new IM with personalized 3D Avatars, and present a prototype of this system. Through our IM, the user can synthesize a personalized 3D avatar by just inputting a 2D self face image. Expressions of the avatar are synthesized by a group of predefined phonemes and visemes, and driven by a text-to-visual speech engine. Moreover, our system supports 3D avatar decoration. During online chat, text is input through the text-to-visual speech engine to drive the generation of voice and animation for the 3D avatar. Tests have demonstrated that our IM with personalized 3D avatars can enhance the fun and vividness of online chat experience. © 2015 IEEE.","3D avatar; 3D face synthesis; Instant Messenger; text to visual speech engine","Engines; Social networking (online); Telecommunication services; 3-D face synthesis; 3D Avatars; Chat tools; Face images; Instant messengers; System supports; Text chat; Text to visual speech; Three dimensional computer graphics",2-s2.0-84964197743
"Chen X., Feng J., Bechmann D.","Mesh Sequence Morphing",2016,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959203059&doi=10.1111%2fcgf.12718&partnerID=40&md5=a500fc6f092814a5403bbf1f9990ebc3","Morphing is an important technique for the generation of special effects in computer animation. However, an analogous technique has not yet been applied to the increasingly prevalent animation representation, i.e. 3D mesh sequences. In this paper, a technique for morphing between two mesh sequences is proposed to simultaneously blend motions and interpolate shapes. Based on all possible combinations of the motions and geometries, a universal framework is proposed to recreate various plausible mesh sequences. To enable a universal framework, we design a skeleton-driven cage-based deformation transfer scheme which can account for motion blending and geometry interpolation. To establish one-to-one correspondence for interpolating between two mesh sequences, a hybrid cross-parameterization scheme that fully utilizes the skeleton-driven cage control structure and adapts user-specified joint-like markers, is introduced. The experimental results demonstrate that the framework, not only accomplishes mesh sequence morphing, but also is suitable for a wide range of applications such as deformation transfer, motion blending or transition and dynamic shape interpolation. Morphing is an important technique for the generation of special effects in computer animation. However, an analogous technique has not yet been applied to the increasingly prevalent animation representation, i.e. 3D mesh sequences. In this paper, a technique for morphing between two mesh sequences is proposed to simultaneously blend motions and interpolate shapes. Based on all possible combinations of the motions and geometries, a universal framework is proposed to recreate various plausible mesh sequences. To enable a universal framework, we design a skeleton-driven cage-based deformation transfer scheme which can account for motion blending and geometry interpolation. © 2015 The Eurographics Association and John Wiley & Sons Ltd.","cross-parameterization; deformation transfer; mesh sequence morphing; mesh sequence representation","Animation; Blending; Deformation; Interpolation; Musculoskeletal system; Computer animation; Control structure; Cross-parameterization; Deformation transfer; Mesh sequence representation; Morphing; Motion blending; Shape interpolation; Mesh generation",2-s2.0-84959203059
"Förger K., Takala T.","Animating with style: defining expressive semantics of motion",2016,"Visual Computer",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958913457&doi=10.1007%2fs00371-015-1064-4&partnerID=40&md5=a7985c76a4f091256c5e1ad39d03e312","Actions performed by a virtual character can be controlled with verbal commands such as ‘walk five steps forward’. Similar control of the motion style, meaning how the actions are performed, is complicated by the ambiguity of describing individual motions with phrases such as ‘aggressive walking’. In this paper, we present a method for controlling motion style with relative commands such as ‘do the same, but more sadly’. Based on acted example motions, comparative annotations, and a set of calculated motion features, relative styles can be defined as vectors in the feature space. We present a new method for creating these style vectors by finding out which features are essential for a style to be perceived and eliminating those that show only incidental correlations with the style. We show with a user study that our feature selection procedure is more accurate than earlier methods for creating style vectors, and that the style definitions generalize across different actors and annotators. We also present a tool enabling interactive control of parametric motion synthesis by verbal commands. As the control method is independent from the generation of motion, it can be applied to virtually any parametric synthesis method. © 2015, Springer-Verlag Berlin Heidelberg.","Computer animation; Feature extraction; Feature selection; Human motion; Motion style; Motion synthesis; Style vector; Verbal description of motion style","Animation; Feature extraction; Semantics; Vector spaces; Vectors; Computer animation; Expressive semantics; Human motions; Interactive control; Motion styles; Motion synthesis; Parametric synthesis; Selection procedures; Motion control",2-s2.0-84958913457
"Huang Y.-J., Chan S.-Y., Lin W.-C., Chuang S.-Y.","Making and animating transformable 3D models",2016,"Computers and Graphics (Pergamon)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939547543&doi=10.1016%2fj.cag.2015.07.014&partnerID=40&md5=473034f9fc9e23f482c8ebc9256c912f","Abstract Transformable models are 3D models whose shapes can be changed by rotating or translating their component parts. They have a variety of applications in our daily lives, being used in film props and sets, robots, furniture, tools, and toys. Successful transformable models, however, are challenging to create. In this paper, we present a new approach to designing and animating a transformable model, in which a source model is optimally segmented based on a target model and skeleton provided by users, and the motion of transformation is mapped from the source to target models. Our experimental results indicate that our system can transform a 3D model plausibly. © 2015 Elsevier Ltd.","Character animation; Segmentation; Transformable models","Computer graphics; Human computer interaction; Image segmentation; 3-d modeling; 3D models; Character animation; Component part; Daily lives; New approaches; Source modeling; Target model; Animation",2-s2.0-84939547543
"Aparajeya P., Leymarie F.F.","Point-based medialness for 2D shape description and identification",2016,"Multimedia Tools and Applications",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960337734&doi=10.1007%2fs11042-015-2605-6&partnerID=40&md5=91e85dc7748cacdbfaa2cec804f63e81","We propose a perception-based medial point description of a natural form (2D: static or in articulated movement) as a framework for a shape representation which can then be efficiently used in biological species identification and matching tasks. Medialness is defined by adapting and refining a definition first proposed in the cognitive science literature when studying the visual attention of human subjects presented with articulated biological 2D forms in movement, such as horses, dogs and humans (walking, running). In particular, special loci of high medialness for the interior of a form in movement, referred to as “hot spots”, prove most attractive to the human perceptual system. We propose an algorithmic process to identify such hot spots. In this article we distinguish exterior from interior shape representation. We further augment hot spots with extremities of medialness ridges identifying significant concavities (from outside) and convexities (from inside). Our representation is strongly footed in results from cognitive psychology, but also inspired by know-how in art and animation, and the algorithmic part is influenced by techniques from more traditional computer vision. A robust shape matching algorithm is designed that finds the most relevant targets from a database of templates by comparing feature points in a scale, rotation and translation invariant way. The performance of our method has been tested on several databases. The robustness of the algorithm is further tested by perturbing the data-set at different levels. © 2015, Springer Science+Business Media New York.","2D shape analysis; Dominant points; Information retrieval; Medialness representation; Planar articulated movement; Shape compression","Algorithms; Animation; Behavioral research; Image processing; Information retrieval; Technology transfer; 2D shape; Dominant points; Medialness; Planar articulated movement; Shape compression; Computer vision",2-s2.0-84960337734
"Hou W., Guo L.","Virtual network embedding for hybrid cloud rendering in optical and data center networks",2016,"Science China Information Sciences",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953247751&doi=10.1007%2fs11432-015-5378-7&partnerID=40&md5=b59c9880473bcf12a4f256d1f90c71dc","Animation rendering consumes massive computation time, therefore cloud rendering is emerging as a solution. Cloud rendering runs over the Data Center Network (DCN) and consolidates heterogeneous DC resources into a single cloud renderfarm, where plentiful computing resources can sufficiently accelerate any rendering process. And if one user wants to get a quick animation result, a high-speed optical interconnection is an urgent requirement, thus cloud rendering needs a convergence of Optical and DCN (ODCN) as the substrate network. In the ODCN supporting cloud rendering, each rendering task will be successfully handled only when we embed its virtual network into the cloud renderfarm. But because a virtual network includes virtual machines and virtual lightpaths, we must simultaneously perform the node-level mapping between virtual machine and server, as well as link-level mapping between virtual lightpath and fiber link(s). In addition, the joint implementation of the Photorealistic cloud Rendering (PR) and Non-Photorealistic cloud Rendering (NPR) should be considered to exhibit the unique animation effect with the low mapping cost. In this paper, considering the unique characteristic of hybrid cloud rendering, we flexibly select routing strategies according to the rendering task type. We then utilize server consolidation and traffic grooming to achieve node- and link-level mappings, respectively, thus building a mapping-cost-aware cloud renderfarm that includes multiple virtual networks. The mathematical formulation is also made with a bound analysis. Especially for the lower bound, we analyze the least number of servers and wavelengths (i.e., mapping cost) consumed by hybrid cloud rendering. In terms of heuristics, according to the processing order of rendering tasks, Smaller Virtual Resource First (SVRF) and Manycast Routing First (MRF) algorithms are proposed by us. In SVRF, NPR tasks are first tackled and then PR tasks follow. MRF is a reverse process of SVRF. The simulation results demonstrate the effectiveness of our methods in reducing the mapping cost because the heuristic solution well matches the lower bound. © 2016, Science China Press and Springer-Verlag Berlin Heidelberg.","hybrid cloud rendering; lower bound; mapping cost; optical and data center network; virtual network embedding","Animation; Costs; Heuristic methods; Java programming language; Mapping; Optical communication; Data center networks; Heuristic solutions; Hybrid clouds; Joint implementation; Lower bounds; Mathematical formulation; Server consolidation; Virtual network embedding; Distributed computer systems",2-s2.0-84953247751
"Noll A.M.","Early digital computer art at bell telephone laboratories, incorporated",2016,"Leonardo",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955460584&doi=10.1162%2fLEON_a_00830&partnerID=40&md5=24620f333ce70fb84bf1068bc27f03c8","This article is a history of the digital computer art and animation developed and created at Bell Telephone Laboratories, Incorporated, 1962–1968. Still and animated images in two dimensions and in stereographic pairs were created and used in investigations of aesthetic preferences, in film titles, in choreography, and in experimental artistic movies. Interactive digital computer music software was extended to the visual domain, including a real-time interactive system. Some of the artworks generated were exhibited publicly in various art venues. This article emphasizes work in digital programming. This pioneering work at Bell Labs was a significant contribution to digital art. © A. Michael Noll 2014.",,,2-s2.0-84955460584
"Patterson D.","Interactive 3D web applications for visualization of world health organization data",2016,"ACM International Conference Proceeding Series",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962542234&doi=10.1145%2f2843043.2843477&partnerID=40&md5=f6a772482ebd86ec2552bef87b980bde","This paper describes the design and implementation of an interactive web application titled ""3DImpact"" that accesses World Health Organization (WHO) data, in conjunction with geographic location based data, and using WebGL based 3D graphics visualizes the resulting information. The information is presented in the form of a 3D globe highlighting, through responsive 3D animation, the time based dataset targeted. The application was designed with the intention of being usable as a generic web visualization tool, to take WHO information, across a range of topics and present that to the web user in an interactive 3D form. An experimental trial of 31 participants was carried out and involved each participant using three different forms of web-based presentation of WHO data. These forms included the Control - raw statistical data (numbers and tables), 2DChart-2D map based chart of data, and the 3DImpact interactive 3D globe. The results from the experimental trial indicated that the 3DImpact interactive visualization was statistically significantly rated as more engaging and more informative than either of the other systems. Users highlighted the 3D nature of the information (world health data being presented on a globe of the world) as a significant feature but also highlighted the fact that the use of depth in the 3D tool allowed them to more easily see locations where there were significant spikes in impact and this advantage appeared to play a key role in the 3D tools preference over its flat 2D counterparts. These results indicate that the use of 3D web based applications for the visualization of world health data, in differing fields through the reusable nature of the tool, offer the potential to enhance the users interaction with the data. Copyright 2016 ACM.","3D data visualization; 3D user interface; Human computer interaction; Web application; World health data","Computer software reusability; Data visualization; Health; Human computer interaction; User interfaces; Visualization; Websites; World Wide Web; 3D data; 3D user interface; Design and implementations; Health data; Interactive visualizations; Interactive web applications; WEB application; World Health Organization; Three dimensional computer graphics",2-s2.0-84962542234
"Du X., Zhang L., Zhang Y.","Artistic style deformation for cartoon character",2016,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959895495&partnerID=40&md5=8e1ecb7819d39e862f0083013b67f6b1","Artistic styles reusing is a commonly used method for the fast creation of cartoons. Computer graphics deformation techniques further promote the creation of cartoon more automatic and intelligent. Based on the study of the artistic creation of cartoons, this paper presents a method for reusing artistic deformation styles by combining shape deformation with the artistic style reusing techniques. First of all, the solution selects the deformation area of the cartoon character from a user and generates the free-form deformation control points to control the deformation of the selected area. Then, the deformation is implemented by changing the positions of the control points or applying the stylized deformation template. Grading strategy and free-form deformation also contribute to the deformation. Finally, a new character is generated with its style similar to the template. Experimental results show that the proposed method has obvious operability and automaticity compared with the traditional methods such as manual adjusting weights and repainting. The method can be applied to fast drawing of cartoon, animation, and other non-photorealistic rendering applications. © 2016, Institute of Computing Technology. All right reserved.","Artistic style; Cartoon deformation; Free-form deformation; Template deformation","Color image processing; Computer graphics; Grading; Artistic creations; Artistic style; Cartoon characters; Deformation areas; Deformation techniques; Free-form deformation; Non-Photorealistic Rendering; Shape deformation; Deformation",2-s2.0-84959895495
"Zhou F., De La Torre F.","Generalized Canonical Time Warping",2016,"IEEE Transactions on Pattern Analysis and Machine Intelligence",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962071073&doi=10.1109%2fTPAMI.2015.2414429&partnerID=40&md5=c35662277e424b5fbfcd2264026ada9d","Temporal alignment of human motion has been of recent interest due to its applications in animation, tele-rehabilitation and activity recognition. This paper presents generalized canonical time warping (GCTW), an extension of dynamic time warping (DTW) and canonical correlation analysis (CCA) for temporally aligning multi-modal sequences from multiple subjects performing similar activities. GCTW extends previous work on DTW and CCA in several ways: (1) it combines CCA with DTW to align multi-modal data (e.g., video and motion capture data); (2) it extends DTW by using a linear combination of monotonic functions to represent the warping path, providing a more flexible temporal warp. Unlike exact DTW, which has quadratic complexity, we propose a linear time algorithm to minimize GCTW. (3) GCTW allows simultaneous alignment of multiple sequences. Experimental results on aligning multi-modal data, facial expressions, motion capture data and video illustrate the benefits of GCTW. The code is available at http://humansensing.cs.cmu.edu/ctw. © 1979-2012 IEEE.","Canonical correlation analysis; Dynamic time warping; Multi-modal sequence alignment","Clustering algorithms; Correlation methods; Modal analysis; Motion analysis; Activity recognition; Canonical correlation analysis; Dynamic time warping; Linear combinations; Linear-time algorithms; Quadratic complexity; Sequence alignments; Simultaneous alignment; Temporal logic; algorithm; human; image processing; movement (physiology); physiology; procedures; time factor; videorecording; Algorithms; Humans; Image Processing, Computer-Assisted; Movement; Time Factors; Video Recording",2-s2.0-84962071073
"Rylski B., Czerny M., Südkamp M., Siepe M., Beyersdorf F.","The TEVAR App: A contemporary guide to thoracic endovascular aortic repair",2016,"Interactive Cardiovascular and Thoracic Surgery",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960336711&doi=10.1093%2ficvts%2fivv310&partnerID=40&md5=f79fb970de57efe3ec070d6b8bc97c7c","There is a growing number of devices used for thoracic endovascular aortic repair (TEVAR). The designs of stent grafts and their delivery systems differ substantially. The success of TEVAR is based on the correct use of stent graft delivery systems, the identification and understanding of radiopaque markers, and the stent graft's accurate placement. In this brief communication, we introduce the TEVAR App - a novel guide for thoracic endovascular aortic repair. It is a tool that provides key information that is quick to access and easy to understand on the thoracic aortic stent grafts currently available. It includes instructions for use, animations demonstrating the stent grafts' deployment, troubleshooting information, size tables, the locations of radiopaque markers, stent graft and delivery system photos, chest X-rays, and information on magnetic resonance safety and compatibility. Furthermore, it contains the TEVAR Calculator, which assists one in planning stent graft size according to individual aortic dimensions and oversizing factors. The TEVAR App is cost-free, and its development has not been supported financially by any industry. It is a non-profit project that aims to educate and help physicians performing TEVARs. © The Author 2015.","Aneurysm; Aorta; Dissection; Thoracic endovascular aortic repair","accuracy; aortic aneurysm endovascular graft; Article; computer program; endovascular aneurysm repair; equipment design; human; medical information; mobile application; outcome assessment; priority journal; program development; smartphone; thoracic endovascular aortic repair application",2-s2.0-84960336711
"Lawonn K., Glaßer S., Vilanova A., Preim B., Isenberg T.","Occlusion-free Blood Flow Animation with Wall Thickness Visualization",2016,"IEEE Transactions on Visualization and Computer Graphics",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946607169&doi=10.1109%2fTVCG.2015.2467961&partnerID=40&md5=e43b2b18eefc6bd1ba7dd888dbf904c4","We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool. © 1995-2012 IEEE.","Aneurysm; Biomedical imaging; Blood; Data visualization; Morphology; Surface morphology; Visualization","Blood; Data visualization; Hemodynamics; Medical imaging; Morphology; Risk assessment; Surface morphology; Visualization; Aneurysm; Biomedical imaging; Illustrative techniques; Interactive data exploration; Medical researchers; Occlusion problems; Real-time rendering; Visualization tools; Flow visualization; adult; aneurysm; biological model; blood flow velocity; computer graphics; female; human; male; middle aged; pathophysiology; physiology; procedures; three dimensional imaging; Adult; Aneurysm; Blood Flow Velocity; Computer Graphics; Female; Humans; Imaging, Three-Dimensional; Male; Middle Aged; Models, Cardiovascular",2-s2.0-84946607169
"Butkiewicz T., Stevens A.H.","Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces",2016,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946593553&doi=10.1109%2fTVCG.2015.2467962&partnerID=40&md5=dc8a265e1952a08d318de0fe9cefd977","Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudocontour lines induced by banded color scales convey the same benefits. © 1995-2012 IEEE.","Animation; Color; Sea surface; Shape; Surface texture; Three-dimensional displays; Visualization","Animation; Color; Flow visualization; Human engineering; Surface waters; Color scale; Contour line; Rate of change; Sea surfaces; Shape; Surface textures; Terrain surfaces; Three-dimensional display; Three dimensional computer graphics; bioengineering; computer graphics; female; human; male; procedures; surface property; task performance; three dimensional imaging; Computer Graphics; Female; Human Engineering; Humans; Imaging, Three-Dimensional; Male; Surface Properties; Task Performance and Analysis",2-s2.0-84946593553
"Abbasloo A., Wiens V., Hermann M., Schultz T.","Visualizing Tensor Normal Distributions at Multiple Levels of Detail",2016,"IEEE Transactions on Visualization and Computer Graphics",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946607192&doi=10.1109%2fTVCG.2015.2467031&partnerID=40&md5=be63ae5d3c5e32a091dbb47dfaf02972","Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics. © 1995-2012 IEEE.","Anisotropic magnetoresistance; Covariance matrices; Data visualization; Eigenvalues and eigenfunctions; Image color analysis; Tensile stress; Uncertainty","Anisotropy; Covariance matrix; Data visualization; Eigenvalues and eigenfunctions; Enhanced magnetoresistance; Normal distribution; Stresses; Tensile stress; Uncertainty analysis; Visualization; Volume rendering; Covariance matrices; Direct volume rendering; Image color analysis; Interactive exploration; Mathematical descriptions; Multiple levels of detail; Uncertainty; Wealth of information; Tensors; anatomy and histology; brain; computer graphics; diffusion weighted imaging; human; image processing; normal distribution; procedures; Brain; Computer Graphics; Diffusion Magnetic Resonance Imaging; Humans; Image Processing, Computer-Assisted; Normal Distribution",2-s2.0-84946607192
"Alabbasi H., Gradinaru A., Moldoveanu F., Moldoveanu A.","Human motion tracking & evaluation using Kinect V2 sensor",2016,"2015 E-Health and Bioengineering Conference, EHB 2015",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978036306&doi=10.1109%2fEHB.2015.7391465&partnerID=40&md5=16502c3815f8b227b7a13824549e9cf7","Microsoft Kinect V2 sensor is a motion sensing device that provides to the users a facility to interact with computers and game consoles through many ways like natural movement, gestures or spoken commands. This technology allowed many researchers and companies to develop real-time applications in various fields like healthcare, sports training, facial emotion detection, gaming, security, 3D reconstruction, motion recognition and many other. In this paper, we presented an approach to handle the problem of human body motion skeletal tracking with application in medical rehabilitation and sports training by using capabilities of the latest version of the Microsoft Kinect sensor. © 2015 IEEE.","Kinect; Motion tracking; Skeletal Animation","Animation; Computer games; Sports; Target tracking; Human body motion; Human motion tracking; Kinect; Microsoft Kinect sensors; Motion recognition; Motion tracking; Real-time application; Skeletal animation; Motion analysis",2-s2.0-84978036306
"Watanabe R., Yamaguchi K., Sakamoto Y.","Fast calculation method of computer generated hologram animation for viewpoint parallel shift and rotation using Fourier transform optical system",2016,"Applied Optics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962218063&doi=10.1364%2fAO.55.00A167&partnerID=40&md5=fc4a855d582b873631b210206dca2d84","Computer generated hologram (CGH) animations can be made by switching many CGHs on an electronic display. Some fast calculation methods for CGH animations have been proposed, but one for viewpoint movement has not been proposed. Therefore, we designed a fast calculation method of CGH animations for viewpoint parallel shifts and rotation. A Fourier transform optical system was adopted to expand the viewing angle. The results of experiments were that the calculation time of our method was over 6 times faster than that of the conventional method. Furthermore, the degradation in CGH animation quality was found to be sufficiently small. © 2016 Optical Society of America.",,"Animation; Electron holography; Holograms; Holographic displays; Optical systems; Calculation time; Computer generated holograms; Conventional methods; Electronic display; Fast calculations; Shift-and; Viewing angle; Computer generated holography",2-s2.0-84962218063
"Perikos I., Hatzilygeroudis I.","Embodied coversational agents: A methodology for learning to express facial emotions",2016,"IISA 2015 - 6th International Conference on Information, Intelligence, Systems and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963860818&doi=10.1109%2fIISA.2015.7388109&partnerID=40&md5=8ad1c068bd94e7e63adedf2c3f7b7969","Embodied Conversational Agents (ECAs) constitute a special type of agents which can simulate verbal and non-verbal behaviors in order to achieve more natural interaction with humans. In this paper, we present a methodology that can be used to assist an ECA to generate and express facial emotions by properly deforming its facial characteristics. The methodology has been implemented on Greta agent and consists of two main stages. Initially, facial expressions are generated by Greta by setting random values to the Facial Animation Parameters (FAPs). Then, a Multi-Layer Perceptron Neural Network (MLPNN) is trained, based on the parameters of the facial deformation of the expressions and the corresponding expert's annotations, to model and recognize the emotional content of new facial expressions. The expressions used for the training of the MLPNN were emotionally annotated by a human expert, who had determined for each one whether it is a neutral or an emotional expression and in case it is an emotional, had specified the emotions it conveys and their strength. In this approach, Greta can generate new facial expressions, recognize the emotional content of each one, and implement the facial expression of the desired emotional state. The evaluation study conducted showed very encouraging results. © 2015 IEEE.","Affective Computing; Embodied Conversational Agents (ECAs); Facial Animation Parameters (FAPs); Human Computer Interaction; Neural Networks","Animation; Deformation; Human computer interaction; Network layers; Neural networks; User interfaces; Affective Computing; Embodied conversational agent; Emotional expressions; Facial animation parameters; Facial deformations; Multi layer perceptron neural networks (MLPNN); Natural interactions; Nonverbal behavior; Face recognition",2-s2.0-84963860818
"Han Y., Zuo Q., Qi Y.","Smoke simulation with user specified details",2016,"Proceedings of 2015 IEEE International Conference on Computer and Communications, ICCC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963983963&doi=10.1109%2fCompComm.2015.7387569&partnerID=40&md5=28f8e4724b30120d3b57187953a08724","Fluid flowing with small-scale details is involved in many games or animation effects. This paper aims to add such small-scale details to fast smoke simulation. In the paper, the whole smoke motion is divided into two parts: a low-resolution motion field and a high-resolution detail motion field, both of which are handled respectively and then combined with each other. The low-resolution motion field is obtained by physical simulation, during which the velocity field is stored and calculated on a coarse grid. The high-resolution detail motion field is gained through two ways. The first is by texture synthesis from an input example texture. The second is translating a small image containing simple contours to a detailed motion field. In both ways, the generation of detail motion field needs to be done only once before the low-resolution motion simulation, while the combination is executed each frame during smoke simulation. In the paper, experiments with varieties of inputs are made on two-dimension grids. Results have shown the method introduced in this paper feasible and efficient. © 2015 IEEE.","motion field; simple contours; smoke simulation; texture synthesis","Animation; Computer graphics; Fluid dynamics; Velocity; Animation effects; High-Resolution Details; Motion fields; Motion simulations; Physical simulation; simple contours; Smoke simulation; Texture synthesis; Smoke",2-s2.0-84963983963
"Yu J., Jiang C., Luo C.-W., Li R., Wang Z.-F.","A real-time 3D hair animation system for human-computer interaction",2016,"2015 12th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966524914&doi=10.1109%2fFSKD.2015.7382312&partnerID=40&md5=7c73e1cbbc8936ba90f949a1a68b1401","In view of the 3D hair animation for human computer interaction, a real-time hair animation system is proposed based on the physical model. Firstly, the spring hinge coefficients of joints are transformed from the blending stiffness by combining the large deflection deformation model and spring hinge model, and then the traditional hair strand motion model, which is only applicable to the straight hair, is extended to the complicated hair motion. Secondly, by presenting hairs with large number of particles and dividing the hair space into some sub-spaces as well, the hair-hair interaction is simulated by estimating the possibilities of particle collisions according to the density of particles in a sub-space based on some constraint conditions. Finally, after simulating of the collision between hair and body, the hair animation is synthesized. The experimental results demonstrated the system can synthesize realistic and complicated hair motion in real-time. © 2015 IEEE.","hair animation; hair-body interaction; hair-hair interaction; Human computer interaction","Animation; Blending; Fuzzy systems; Animation systems; Constraint conditions; Density of particles; hair-body interaction; hair-hair interaction; Large deflection; Motion modeling; Particle collision; Human computer interaction",2-s2.0-84966524914
"Xiao L., Liu F., Wang Y.","Research of computer-generated algorithms for traditional Chinese realistic paintings based on 3D model",2016,"Proceedings - 2015 Chinese Automation Congress, CAC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966668532&doi=10.1109%2fCAC.2015.7382601&partnerID=40&md5=8786b76e0e6c3045e7250ab307b5bb6a","Non-photorealistic rendering (NPR) is becoming a research hotspot in the field of computer graphics in recent years. There have been a lot of achievements about computer algorithm for western paintings. It is still at a preliminary stage for Chinese paintings. The only related work is about freehand brushwork in traditional Chinese paintings instead of traditional Chinese realistic paintings. A novel algorithm for computer-generated Chinese realistic paintings based on 3D models is proposed in this paper. Getting started with the imported STL file of flowers, topological relations among their geometric elements are constructed, and then a polygon mesh model of flowers is reconstructed. With the extraction of information including contours, projected outlines and feature curves of petals with the appropriate algorithms, a fine traditional Chinese realistic painting is obtained with projection and coloration algorithms. Furthermore, a simple mechanics model is used to simulate the flowers swaying in the wind, thus a computer animation for traditional Chinese realistic painting is produced. © 2015 IEEE.","Computer animation; Computer graphics; Non-photorealistic rendering; Traditional Chinese realistic painting","Algorithms; Animation; Color image processing; Computer graphics; Painting; Rendering (computer graphics); Topology; Computer animation; Computer generated; Extraction of information; Geometric elements; Mechanics modeling; Non-Photorealistic Rendering; Topological relations; Traditional Chinese painting; Three dimensional computer graphics",2-s2.0-84966668532
"Chen C., Zhang Y., Xu P., Lan S., Li S., Zhang Y.","Real-time 3D facial expression control based on performance",2016,"2015 12th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966551245&doi=10.1109%2fFSKD.2015.7382135&partnerID=40&md5=5e0fbaf8e7f1a4aec474184f91e9839b","Performance-driven facial expression animation is one of the researching highlight in computer animation. In this paper, a method is proposed to control 3D facial expression animations in real time. The skeleton based on skinning was adopted for an efficient control of the deformation of the face model. Kinect was used as a capture device to get the depth and color images of the performers that help to obtain the animation units in candide-3. The animation unites smoothed by moving average filter were used to control the translation and rotation of skeletons, which produced a good result of the facial animations. © 2015 IEEE.","facial enpression; kinect; realtime; skeleton based 3D animation","Fuzzy systems; Musculoskeletal system; 3-d facial expressions; 3D animation; Computer animation; facial enpression; kinect; Moving average filter; Performance-driven; Real time; Animation",2-s2.0-84966551245
"He G.-F., Peng S.-J., Liu X.","Motion Capture Behavior Recognition via Neighborhood Preserving Dictionary Learning",2016,"Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964411203&doi=10.1109%2fSMC.2015.476&partnerID=40&md5=9f6d58a20e2ea53bca7e0ef233de5e9b","Behavior recognition from large available motion capture data has received wide attention in the computer animation community and is growing increasingly important in recent years. In this paper, we present an efficient motion capture behavior recognition approach via neighborhood preserving dictionary learning. First, we normalize all the motion sequences in the database to make the motion to be comparable. Then, the neighborhood preserving property is exploited using Iterative Nearest Neighbors algorithm and subsequently added as a constraint condition for discriminative dictionary learning, whereby the raw motion frame can be represented as a compact set of atoms consisting of neighborhood preserving characteristics. Finally, the recognition result can be efficiently obtained by sparse coding based classification scheme. Extensive experiments tested on publicly available motion capture databases have demonstrated the accuracy and effectiveness of the proposed approach. © 2015 IEEE.","Behavior recognition; discriminative dictionary learning; Iterative Nearest Neighbor; motion capture data; neighborhood preserving property","Animation; Cybernetics; Iterative methods; Behavior recognition; Discriminative dictionaries; Motion capture data; Nearest neighbors; neighborhood preserving property; Behavioral research",2-s2.0-84964411203
"Barresi G., Olivieri E., Caldwell D.G., Mattos L.S.","Brain-Controlled AR Feedback Design for User's Training in Surgical HRI",2016,"Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964558191&doi=10.1109%2fSMC.2015.200&partnerID=40&md5=ec8009a0ffd33cad5b9caf28b758b227","Brain-computer interfaces (BCIs) offer high potential for enhancing training in many tasks, especially those that require maintaining high levels of concentration such as surgery. Training focus and attention can play a critical role in surgery since concentration on the task at hand is fundamental to prevent life-Threatening errors. In this paper we propose a new method for concentration training in the context of robot-Assisted laser microsurgery associated to a feedback design that makes the interaction more intuitive. This approach couples augmented reality (AR) features to both BCI-based on-line measurement of the user's mental focus and the control of the surgical robot. The methodology is described as a brain-controlled augmented reality (BcAR) training system. AR is used to maintain the surgeon's perceptual contact with the real operating setting, while focus stimulation is provided by modifying features of an AR item based on real-Time monitoring of the user's mental state. In this research a low-cost EEG device is used and the BcAR is implemented in the form of an AR scalpel that behaves as a ""retractable"" knife according to the user's mental focus: low concentration levels retract the knife and prevent cutting. This design provides directional compatibility between the AR feedback animation and the spontaneous motion of user's attention along the AR tool, resulting in an intuitive system with real impact on the training outcome. This is demonstrated through user trials and comparison with training based on simple AR feedback (no EEG). Results demonstrate the potential of the approach, showing a significant improvement in post-Training task execution time without any detriment to user experience. Subjective questionnaires also confirmed the critical role of directional compatibility in the AR feedback. Such findings allow the identification of further improvements and novel potential applications of this interaction paradigm. © 2015 IEEE.","Augmented Reality; Brain-Computer Interfaces; Human-Robot Interaction; Surgery; Training; User Interfaces","Augmented reality; Cybernetics; Human computer interaction; Human robot interaction; Interfaces (computer); Machine design; Personnel training; Robotic surgery; Robots; Surgery; Surgical equipment; Surveys; User interfaces; Brain computer interfaces (BCIs); Directional compatibilities; Feed-back designs; Interaction paradigm; Low concentration levels; On-line measurement; Real time monitoring; Training Systems; Brain computer interface",2-s2.0-84964558191
"Ahmed F., Paul P.P., Gavrilova M., Alhajj R.","Weighted Fusion of Bit Plane-Specific Local Image Descriptors for Facial Expression Recognition",2016,"Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964550155&doi=10.1109%2fSMC.2015.324&partnerID=40&md5=4f24d7314fe70eca23f652b539beafef","Automated recognition of facial expression has attracted significant attention in recent years due to its potential applicability in security and surveillance, human computer interaction, social robotics, and animation. This paper presents a new facial expression recognition method that utilizes bit plane specific local image description in a weighted score level fusion. The motivation is to utilize bit plane slicing to highlight the contribution of a particular bit plane made to the holistic facial appearance, which is then used in a weighted score level fusion in order to boost the recognition performance. A new local image descriptor is proposed specifically to extract local features from bit plane representations that utilizes Fisher linear discriminant to maximize the inter-class distance, while minimizing the intra-class variance. Two well-known facial expression databases, namely the Cohn-Kanade (CK) and the Japanese female facial expression (JAFFE) database have been used to evaluate the performance of the proposed method against existing facial appearance descriptors, such as local binary pattern (LBP), local ternary pattern (LTP), local directional pattern (LDP), and linear discriminant analysis (LDA). Experiments with a total of seven prototypic facial expressions show promising results for the proposed method, as compared with the other existing methods. © 2015 IEEE.","bit plane slicing; Facial expression recognition; local binary pattern; local image description; score level fusion","Binary images; Bins; Cybernetics; Discriminant analysis; Human computer interaction; Human robot interaction; Image fusion; Robotics; Bit-plane slicing; Facial expression recognition; Local binary patterns; Local image descriptions; Score-level fusion; Face recognition",2-s2.0-84964550155
"Iglesias A., Galvez A., Collantes M.","A bat algorithm for polynomial Bèzier surface parameterization from clouds of irregularly sampled data points",2016,"Proceedings - International Conference on Natural Computation",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960360071&doi=10.1109%2fICNC.2015.7378134&partnerID=40&md5=afc5b7bdb57e3d95019ab4ac66f91a0c","This paper presents a novel method for polynomial Bézier surface parameterization from clouds of irregularly sampled data points. This problem is a crucial step in surface reconstruction for reserve engineering, a field with very important applications in many industrial and technological domains such as computer-aided design (CAD), computer aided manufacturing (CAM), virtual reality, computer graphics, medical imaging, computer animation, and many others. Regrettably, it is also a high-dimensional, nonlinear, over-determined, continuous optimization problem. As a consequence, classical mathematical methods fail to solve it in its generality. Our approach is based on a powerful nature-inspired optimization method called bat algorithm, which has been recently proposed to solve hard continuous optimization problems. To analyze the performance of our approach, it has been applied to three illustrative examples of irregularly sampled Bézier surfaces. The numerical and visual results confirm the excellent performance of this method even for clouds of strong irregular patterns, a very challenging issue for many other optimization techniques. © 2015 IEEE.","bat algorithm; data fitting; irregular sampling; Nature-inspired techniques; reverse engineering; surface parameterization; surface reconstruction","Algorithms; Animation; Computer aided design; Computer aided manufacturing; Computer graphics; Medical imaging; Numerical methods; Parameter estimation; Parameterization; Reverse engineering; Surface reconstruction; Virtual reality; Bat algorithms; Data fittings; Irregular sampling; Nature-inspired techniques; Surface parameterization; Optimization",2-s2.0-84960360071
"Zhang Y., Chen H., Zhu Z., Dong X., Cui H.","Small files storing and computing optimization in Hadoop parallel rendering",2016,"Proceedings - International Conference on Natural Computation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960400358&doi=10.1109%2fICNC.2015.7378174&partnerID=40&md5=bf9d0f6cb8203f48e7e288179b693072","The Hadoop framework has been widely used in the animation industry to build a large scale, high performance parallel render system. However, Hadoop Distributed File System (HDFS) and MapReduce programming model are designed to manage large files and suffer performance penalty while rendering and storing small RIB files in rendering system. Therefore, method that merging small RIB files based on two intelligent algorithms is proposed to solve the problem. The method uses Particle Swarm Optimization (PSO) and Support Vector Machine (SVM) to choose the optimal merge value for any scene file, by mainly considering the rendering time, memory limitation and other indicators. Then, the method takes advantage of frame-to-frame coherence to merge RIB files at an interval way with the optimal merge value. Finally, the proposed method is compared with the naive method under three different render scenes. Experimental results show that the proposed method significantly reduces the number of RIB files and render tasks, and improves the storage efficiency and computing efficiency of RIB Files. © 2015 IEEE.","Hadoop; PSO; rendering system; small files; SVM","Distributed computer systems; Efficiency; File organization; Mergers and acquisitions; Particle swarm optimization (PSO); Support vector machines; Frame-to-frame coherence; Hadoop; Hadoop distributed file system (HDFS); Intelligent Algorithms; Map-reduce programming; Performance penalties; Rendering system; Small files; Rendering (computer graphics)",2-s2.0-84960400358
"Uosaki N., Matsushita K., Suzuki H.","Supporting JFL Learners with User Customized Kanji Learning System Using Computer Graphics",2016,"Proceedings - 2015 IIAI 4th International Congress on Advanced Applied Informatics, IIAI-AAI 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964409647&doi=10.1109%2fIIAI-AAI.2015.251&partnerID=40&md5=db60ece93a329842ba09338391cdce6c","This paper describes the development and evaluation of a user adaptive kanji learning system for JFL (Japanese as a foreign language) learners. Japanese language education for international students is an emergent issue in Japan. Especially learning kanji is a real challenge for them. Therefore we have tried to implement our newly developed kanji learning system, which received good reputations when introduced it into an elementary school, to a Japanese language class for non-native speakers. A pilot evaluation was conducted in order to find which aspects of our system to be modified to fit for JSL learners. The result of the pilot evaluation reveals that the participants' feedback was not good compared with that of elementary school children, especially about computer animations and fun factor. A user-unfriendliness about its navigation has been found. Our future works include the improvement of computer animations, the implementation of English navigation and the summary dashboards for reviewing. © 2015 IEEE.","computer graphics; e-learning; JFL (Japanese as a Foreign Language); kanji; language learning; learning system","Animation; Computational linguistics; Computer graphics; E-learning; Information science; Computer animation; Elementary schools; Foreign language; International students; kanji; Language education; Language learning; Non-native speakers; Learning systems",2-s2.0-84964409647
"Ibrahim N., Fatimah W., Ahmad W., Shafie A.","User Experience Study on Folktales Mobile Application for Children's Education",2016,"Proceedings - NGMAST 2015: The 9th International Conference on Next Generation Mobile Applications, Services and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964577881&doi=10.1109%2fNGMAST.2015.73&partnerID=40&md5=24753a45a7814004e1efb127e177c318","Early exposure to devices such as smart phones and tablets among children as a learning tool has been very common nowadays. Learning using devices like iPads and tablets can stimulate children's motivation and concentration. Therefore, evaluation and measurement of user experience for mobile learning application become crucial. There were some studies have been done in order to get feedback from users in terms of comparing the application and getting perception rather than observing the quality of the application. This paper presented the study on evaluation of user experience for folktales mobile application called MFolktales by implementing user experience questionnaire tools. The objective of this study is to access the significance and impact of the MFolktales mobile application towards end users. The MFolktales mobile application has been developed based on a validated conceptual model, and the study includes the analysis and the definition of the design principles and requirements. This application contains an animation story module and several games modules which aim to promote Malay folk stories to children. This research is limited to children aged 5 to 7 years old. The prototype was tested on 15 kindergarten students from KEMAS (Community Development Department). As the results, the MFolktales got the positive impression in user perception and achieved as a good product in relative quality. © 2015 IEEE.","education; human computer interaction; mobile application; user experience","Animation; Computer aided instruction; Education computing; Human computer interaction; Mobile computing; Mobile telecommunication systems; Smartphones; Community development; Conceptual model; Design Principles; Evaluation of users; Mobile applications; Relative qualities; User experience; User perceptions; Education",2-s2.0-84964577881
"Mohamad A.F.H., Mohd Supian J.J., Md Ribuan M.S.","Digital congkak: The art, play and experience framework",2016,"ACM IMCOM 2016: Proceedings of the 10th International Conference on Ubiquitous Information Management and Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965071428&doi=10.1145%2f2857546.2857636&partnerID=40&md5=0e1dbe4562afa233c22dacceef5dc589","Congkak is one of the most unique heritage form of traditional game in Malaysia. Unfortunately, this traditional heritage game is slowly being extinct. Thus, this research will focus on developing an interactive digital Congkak application using visual graphics, framework, interactive media and animation. This paper will also describes and evaluates the experiences gathered while using a scenario-based player study to inform pervasive computer game design. © 2016 ACM.","Congkak; Framework; Game design; Heritage; Interactive media","Animation; Human computer interaction; Information management; Congkak; Framework; Game design; Heritage; Interactive media; Computer games",2-s2.0-84965071428
"Cho S., Sato H.","Examination of Transformation Technique from Real World to ANIME World",2016,"Proceedings - 2015 International Conference on Computer Application Technologies, CCATS 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964781204&doi=10.1109%2fCCATS.2015.40&partnerID=40&md5=59abe6464c52c37ba23af4325a2ef273","This paper presents the results of transformation technique from real world to animation world. The animation rarely just adopts real information. In many cases, a creator converts it into a form suitable for an animation. We examined the cause about transformation of information from the real world to the animation world in a past study. Approach of the existing transformation: Approach to apply the expression of the animation to a video, Approach to transform real movement data into data for animations, Approach to transform real model data to the model data for animations. From these approaches, we examined a transformation method. By these approaches, I concluded that the exaggeration of the characteristic was an important element. We converted real information into a form suitable for an animation under the condition and concluded that I could use it. The condition is a judgment and the choice of the characteristic. © 2015 IEEE.","animation; ANIME; cartoon; Computer graphics","Animation; Computer graphics; ANIME; cartoon; Model data; Movement datum; Real models; Real-world; Transformation methods; Transformation techniques; Metadata",2-s2.0-84964781204
"Murdoch S.","Agent-oriented modelling in the production of 3D character animation",2016,"Studies in Australasian Cinema",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961207772&doi=10.1080%2f17503175.2015.1133486&partnerID=40&md5=3953291515e7ce23a84336760677503d","With the explosion of 3D character animation across contemporary screen media, more people, disciplines and technologies are now engaging with its production. Explicit representations of computer animation processes help facilitate engagement at a high level, however fail to convey the depth of specialised creative techniques, technical processes and discipline language that is prevalent during the act of animating. This paper introduces the Mk I production model, a conceptual process which through its novel use of the software engineering methodology agent-oriented modelling, conveys such specialised attributes within an explicit process for producing 3D character animation. To gather insights into how this model is used and perceived by animators within a production environment, it was entrenched within a large undergraduate student animation project named Gunter's Fables, where it was positioned as the principal device to inform animators of the production process and their expected activity. The project management team also used the model in weekly peer review sessions as a basis to evaluate animation, and to convey progress and achievement with a colour rating scale. Upon completion of the production phase, the project's 12 student animators successfully delivered 41 short, 10-15 second 3D character animation scenarios that were deemed to be of a consistent and fit for purpose quality. Findings from regular sweatbox review sessions and questionnaires suggest that further investigation and iterative development of the model may improve user engagement with the process. However, the model's demonstrated ability to inform a depth of production process supports the notion that this novel production concept presents a way forward in the communication and production of 3D character animation, and allied animation activities. © 2016 Taylor & Francis.","3D animation; agent-oriented modelling; production process",,2-s2.0-84961207772
"Yilmazyildiz S., Read R., Belpeame T., Verhelst W.","Review of Semantic-Free Utterances in Social Human–Robot Interaction",2016,"International Journal of Human-Computer Interaction",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953281304&doi=10.1080%2f10447318.2015.1093856&partnerID=40&md5=b4f517a7306fd8dd674d22622c770b34","As a young and emerging field in social human–robot interaction (HRI), semantic-free utterances (SFUs) research has been receiving attention over the last decade. SFUs are an auditory interaction means for machines that allow emotion and intent expression, which are composed of vocalizations and sounds without semantic content or language dependence. Currently, SFUs are most commonly utilized in animation movies (e.g., R2-D2, WALL-E, Despicable Me), cartoons (e.g., “Teletubbies,” “Morph,” “La Linea”), and computer games (e.g., The Sims) and hold significant potential for applications in HRI. SFUs are categorized under four general types: Gibberish Speech (GS), Non-Linguistic Utterances (NLUs), Musical Utterances (MU), and Paralinguistic Utterances (PU). By introducing the concept of SFUs and bringing multiple sets of studies in social HRI that have never been analyzed jointly before, this article addresses the need for a comprehensive study of the existing literature for SFUs. It outlines the current grand challenges, open questions, and provides guidelines for future researchers considering to utilize SFU in social HRI. Copyright © Taylor & Francis Group, LLC.",,"Animation; Computational linguistics; Computer games; Linguistics; Semantics; Auditory interaction; Grand Challenge; Multiple set; Non-linguistic utterances; Paralinguistic; Robot interactions; Semantic content; Social hri; Human robot interaction",2-s2.0-84953281304
"Díaz L.M., Gaytán-Lugo L.S.","Computer animation as a vehicle for teaching computational thinking",2016,"IFIP Advances in Information and Communication Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986296724&doi=10.1007%2f978-3-319-44447-5_6&partnerID=40&md5=ec6c30e32b4d8e46ffcdea0ff24304b0","Several platforms and programming languages exist nowadays designed and built to help educators introduce kids and youngsters into computational thinking. Some of them employ visual elements as the primary output of code in order to provide an immediate and engaging feedback for students. Computer animations, digital drawings and videogames are common products in these environments. With the rising popularity of animated films, children and teenagers may find more attractive to enroll in computer animation courses than in computer programming ones. Based in our own experience conducting computer animation workshops, we believe that this interest can be combined with the aforementioned introductory programming environments to introduce students to both computational thinking and computer animation as complementary subjects. In this paper we will present a general strategy to accomplish this based on what we call animation patterns. © IFIP International Federation for Information Processing 2016.","Animation patterns; Computational thinking; Computer animation; Programming languages","Computer programming; Computer programming languages; Motion pictures; Teaching; Computational thinkings; Computer animation; Digital drawings; Introductory programming; Primary outputs; Video game; Visual elements; Animation",2-s2.0-84986296724
"Ren Y.","An optimization method for computer animation develpoment projects",2016,"International Journal of Simulation: Systems, Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991515530&doi=10.5013%2fIJSSST.a.17.15.20&partnerID=40&md5=855984b4b380c409e65269ba01fcc445","Because the optimization of computer animation development projects is an important factor which cannot be ignored, different optimization methods have different costs: the use of good quality computing resources is high, while the use of common resources is low. Users make their choices based on consideration of budget as well as waiting time. To solve the problem, we propose a double fitness particle swarm optimization algorithm (DFPSO) based on time and cost constraints. In the algorithm, both the complete time of all tasks and the cost in computer animation trajectory planning control are used as scheduling objectives. Through this algorithm, the proposed optimization method not only shortens total task completion time but also costs less. © 2016, UK Simulation Society. All rights reserved.","Computer animation trajectory planning control; Computing resources; Optimization method","Animation; Budget control; Costs; Particle swarm optimization (PSO); Computer animation; Computing resource; Cost constraints; Development project; Optimization method; Particle swarm optimization algorithm; Task completion time; Trajectory Planning; Optimization",2-s2.0-84991515530
"Hou D.","Research on the diving simulation system on three dimensional computer animation",2016,"International Journal of Signal Processing, Image Processing and Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031837730&doi=10.14257%2fijsip.2016.9.12.26&partnerID=40&md5=f5b5472ec9924af187aea023ab6d1be0","Three dimensional computer animation and motion simulation is an important means of technical analysis and diagnosis of sports training techniques. Springboard diving simulation system is researched in this paper by using three-dimensional computer assisted animation, and the human body model suitable of the system is established. Then we used free deformation method based on NURBS deformed to achieve the body’s joint movement. Three-dimensional human body model and its motion model are established in the computer by introducing computational geometry. At last, the simulation system is realized by using OpenGL graphical programming interface, and the position difference simulation of the platform is carried out in the system. The visual effect and real-time motion of the human body model is performance good in this paper, and it has a high application value to the guiding practice. © 2016 SERSC.","Computer assisted; Diving simulation system; Human body model; Three-dimensional animation","Application programming interfaces (API); Computational geometry; Computer graphics; Human form models; Computer assisted; Computer assisted animations; Graphical programming; High application value; Human body modeling; Motion simulations; Simulation systems; Three-dimensional animations; Animation",2-s2.0-85031837730
"Lee S., Yan J.","The Potential of a Text-Based Interface as a Design Medium: An Experiment in a Computer Animation Environment",2016,"Interacting with Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960433829&doi=10.1093%2fiwc%2fiwu036&partnerID=40&md5=631d5704fd25817da78ffb5cbba54ce5","Since the birth of the concept of direct manipulation, the graphical user interface has been the dominant means of controlling digital objects. In this research, we hypothesize that the benefits of a text-based interface involve multiple tradeoffs, and we explore the potential of text as a medium of design from three perspectives: (i) the perceived level of control of the designed object, (ii) a tool for realizing creative ideas and (iii) an effective form for a highly learnable user interface. Our experiment in a computer animation environment shows that (i) participants did feel a high level of control of characters, (ii) creativity was both restricted and facilitated depending on the task and (iii) natural language expedited the learning of a new interface language. Our research provides experimental proof of the effect of a text-based interface and offers guidelines for the design of future computer-aided design applications. © 2014 The Author.","computer-aided design; Graphics systems and interfaces; multimedia content creation; natural language interfaces","Computational linguistics; Computer aided design; Design; Graphical user interfaces; High level languages; Natural language processing systems; User interfaces; Computer animation; Direct manipulation; Graphics systems; Interface languages; Multimedia contents; Natural language interfaces; Natural languages; Text-based interfaces; Animation",2-s2.0-84960433829
"Zhang T.","Research on interactive creation of Japanese animation film music under the background of computer multimedia technology",2016,"RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001850103&partnerID=40&md5=ecc58ac5bdc060a9db3da00faa9eca66","The development of computer multimedia technology, especially the development of musical instrument digital interface, which has brought a revolution in the field of music. In this paper, the author analyzes the interactive creation of Japanese animation film music under the background of computer multimedia technology. Multimedia music system brings great convenience to music creation, from the creation perspective, the composing is no longer stay in piano, when the musical ideas generated, it can be directly made into the sound and stored in the sequencer. At the same time, the author analyzes the style of Japanese animation film music creation, and summarizes the art function of film music. © AISTI 2016.","Animation music; Computer multimedia; Interactive creation; Sequencer software","Animation; Electronic musical instruments; Multimedia systems; Musical instruments; Art functions; Computer multimedias; Interactive creation; Music creation; Musical instrument digital interfaces; Computer music",2-s2.0-85001850103
"Huan C., Chen J.","A study on college computer software application courses teaching based on flipped classroom: Take ""flash animation design"" course as an example",2016,"Journal of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994318677&doi=10.3923%2fjse.2016.328.337&partnerID=40&md5=c37d11ee6be2d8994b4ec06fcd672548","Background: ""Enhancing student's ability of practice and innovation"" is a great task to implement quality education, improve education quality and build a harmonious socialist society. As the foundation of knowledge and technological innovation system, it is the responsibility of college to develop the advanced specialized talents with innovative spirit and practical ability. This study focuses on the teaching of computer software application courses in colleges and to seek the effective way to cultivate student's ability for practice and innovation through promoting the teaching reform. Materials and Methods: With the wide application of information technology represented by computer in all fields of life and work, the courses of computer application has become an important part of the training of talents. Strong practice and innovation of computer applications, making these courses has obvious advantages in cultivating student's practical and innovative ability. On the basis of the investigation of the current situation of teaching, taking reform of teaching mode as the breakthrough point, the study introduced the flipped classroom into the teaching of software applications course. Combined course characteristics with strong practicality and originality in application, the study built a new teaching model, which is mainly composed of three interrelated teaching composition with support of network teaching platform: Autonomous learning before class, training for internalization in class, after-school to strengthen and promote learning. According to the teaching model, took ""Flash animation design"" as an example to carry out the teaching design and implementation. Results: The practice test and investigation proved that the model is beneficial to help student master knowledge and skills, improve the student's learning interest, meet the needs of student's individual learning and help to cultivate the practical and innovative ability. Conclusion: The study aimed on reform of teaching mode, introduced the flipped classroom into the teaching of software applications course and constructed a new teaching model and provide a beneficial reference for similar courses teaching reform and exploration on the effective ways of cultivating college student's practical and innovative ability. © 2016 Chenglin Huan and Jianwei Chen.","Autonomous learning task; Flash animation design; Flipped classroom; Software application courses; Teaching model","Animation; Application programs; Computer software; Curricula; Education; Education computing; Personnel training; Students; Autonomous learning; Flash animations; Flipped classroom; Software applications; Teaching model; Teaching",2-s2.0-84994318677
"Tao Y.","Production and application of animations for behavior cultivation of college students using multimedia computer",2016,"RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011066976&partnerID=40&md5=cdef391dc8a910d8cd3e5e235fc74e71","Computer is now an essential in our everyday life and work. Multimedia computers can synthesize multimedia materials like text, image, sound, animation and video, set logical relationship between these materials and realize humancomputer interaction. Taking the animation for behavior cultivation of college students made by Qujing Normal University for an example, this paper studies the development of advertising animation with multimedia computers. Made by a number of the most commonly used multimedia software, the advertising animation is witty and teaches civilized behaviors to students so that they can get rid of bad habits and strive to become civilized students.","Animation; Multimedia computer; Production","Animation; Education; Marketing; Production; Bad habits; College students; Logical relationships; Multimedia materials; Multimedia software; Students",2-s2.0-85011066976
"Ji Y., Zhang S.","Integration and application of animation production simplification in a VR virtual reality teaching system",2016,"International Journal of Emerging Technologies in Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994840338&doi=10.3991%2fijet.v11i10.6267&partnerID=40&md5=176be310a7e582c50cdab2dd85e906f5","This study designed a teaching system based on the animation model, which focuses on VR virtual reality technology and incorporates the improved computer animation modeling technique. The whole system is composed of three main parts, including the front-end animation model, the rear-end background model and the dynamic audio model. In particular, the use of the simplified animation technology makes it easy to operate the system. On this basis, this study followed the idea of comparing experimental teaching to test the results of applying this system in the experimental class and the control class in the course of 3D animation production. The results confirmed that the system has a positive effect in enhancing students' interest in learning, practical ability, maturity of space cognition and so on.","3D animation; Animation production; Simplification; VR virtual technology","E-learning; Teaching; Virtual reality; 3D animation; Animation modeling; Computer animation; Experimental teachings; Simplification; Students' interests; Virtual reality technology; Virtual technology; Animation",2-s2.0-84994840338
"Hou Y., Yang L.","The application of computer vision and machine learning technology in 3D human animation",2016,"International Journal of Simulation: Systems, Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994624484&doi=10.5013%2fIJSSST.a.17.24.02&partnerID=40&md5=2bd82f36085ebaad8aa8eec42368a2bd","Face detection and recognition tracking technology is an important issue in the field of robot vision research. Feature extraction and matching algorithm based on SURF can deal with the problem of matching between the two images, which are translation, rotation and affine transformation. This paper introduces the SURF algorithm basic principles, and the combination of the algorithm and the cascade classifier used in face detection and recognition. Then we use open source function library programming with the XBOX360 visual sensor Kinect image acquisition in the laboratory, which has yielded very good results for face recognition. The experiments show that the SURF algorithm has strong robustness to the change of face size, rotation and illumination. © 2016, UK Simulation Society. All rights reserved.","Cascade classifier; Face detection; SURF","Artificial intelligence; Classification (of information); Computer vision; Feature extraction; Image acquisition; Image matching; Learning systems; Open source software; Affine transformations; Cascade classifiers; Face detection and recognition; Feature extraction and matching; Machine learning technology; Strong robustness; SURF; Tracking technology; Face recognition",2-s2.0-84994624484
"Somova T.","Polynomial guidance laws and animation for in-flight support of a satellite attitude determination and control system",2016,"23rd Saint Petersburg International Conference on Integrated Navigation Systems, ICINS 2016 - Proceedings",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979599400&partnerID=40&md5=119f5878fb2ca97ecee9e7a6098beb7b","We consider problems of synthesis of the vector polynomial attitude guidance laws for a land-survey satellite and an inflight support of the satellite attitude determination and control system with the use of computer animation of its motion. We have presented the results on the efficiency of the developed algorithms.","Control; Guidance; In-flight support; Land-survey satellite","Air navigation; Animation; Control; Control system synthesis; Control systems; Electronic guidance systems; Flight control systems; Navigation; Navigation systems; Satellites; Surveys; Attitude guidances; Computer animation; Flight support; Guidance laws; Land surveys; Satellite attitude; Computer control systems",2-s2.0-84979599400
"Sotozaki M., Dobashi Y., Yamamoto T.","Creating endless water flow animation using particle data",2016,"VISIGRAPP 2016 - Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968831250&partnerID=40&md5=5c8dd1b65a0e76e0b2b331a5b387a028","In this paper, we propose an efficient method for synthesizing water animation such as waterfall or rivers using particle-based simulation. Recently, physically based simulation has become a popular technique to create realistic animation of natural phenomena in many applications, e.g. commercial films, movies and games. Particularly, there is a growing demand on synthesizing realistic animation of fluids, such as water. However, realistic fluid animation requires a high computational cost. Some applications requiring real time performances, such as games, cannot afford such a high computational cost. In this paper, we propose an efficient method for creating endless animations of water flow using particle data generated by fluid simulation. We store a set of dynamic particles in a database and use them repeatedly to produce endless animations. © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Endless Animation; Natural phenomena; Particle-based Simulation; River; Water","Computation theory; Computer graphics; Computer vision; Flow of water; Hydraulics; Rivers; Water; Water resources; Computational costs; Endless animations; Fluid animation; Fluid simulations; Natural phenomena; Particle-based simulation; Physically-based simulation; Real time performance; Animation",2-s2.0-84968831250
"Ramírez-López A., Muñoz D.F., Romero-Hernández S., López-Ramírez S.","Computational methods for the animation of heat transfer evolution and steel solidification",2016,"VISIGRAPP 2016 - Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968830777&partnerID=40&md5=97afeadfeaa00978250d6130953ddcfb","This work shows the use of some basic animation techniques to develop a computer simulator capable to display the heat transfer of steel during a continuous casting process. This is the most popular method to produce steel in big bulks. Nevertheless, continuous casting involves the interaction of complex heat transfer phenomena such as conduction, radiation and forced convection, and appropriate algorithms with graphical tools must be developed to display thermal and solidification profiles according to temperature values. Here a 2D model was applied for calculation purposes; nevertheless the animation techniques employed allowed us to display a 3D representation. Furthermore, additional enhancements were created to show the internal thermal behaviour. A math model provided a good approach for process simulation and the animation procedures were successfully tested to provide a good visual display. © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Algorithms for Animation; Computer Simulation; Continuous Casting; Industrial Processes","Animation; Computation theory; Computer graphics; Computer simulation; Computer vision; Continuous casting; Solidification; Animation techniques; Computer simulators; Continuous casting process; Industrial processs; Process simulations; Steel solidification; Temperature values; Transfer phenomenon; Heat transfer",2-s2.0-84968830777
"Cruz Ruiz A.L., Pontonnier C., Pronost N., Dumont G.","Muscle-Based Control for Character Animation",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970971236&doi=10.1111%2fcgf.12863&partnerID=40&md5=c8863c814e83497cfd7b855eac22d1d1","Muscle-based control is transforming the field of physics-based character animation through the integration of knowledge from neuroscience, biomechanics and robotics, which enhance motion realism. Since any physics-based animation system can be extended to a muscle-actuated system, the possibilities of growth are tremendous. However, modelling muscles and their control remains a difficult challenge. We present an organized review of over a decade of research in muscle-based control for character animation, its fundamental concepts and future directions for development. The core of this review contains a classification of control methods, tables summarizing their key aspects and popular neuromuscular functions used within these controllers, all with the purpose of providing the reader with an overview of the field. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Computer animation; Motion control; Motion synthesis; Musculoskeletal simulation; Physics-based animation",,2-s2.0-84970971236
"Liu Y., Li J.","Visual representation and application of 3D animation",2016,"Journal of Computational and Theoretical Nanoscience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015183166&doi=10.1166%2fjctn.2016.5829&partnerID=40&md5=b2af687164b170966619e3a0e34ac101","Automatic generation algorithm of shadow is one of the focal and difficult problems in the transitional process of the productionmode from traditional hand drawing to computer-assisted production of the two-dimensional animation. Considering this problem, research status on the aspect of automatic generation of shadow and shadow processing process of traditional are analyzed at present; and a kind of automatic generation algorithm of shadow based on two-dimensional vector graphics is proposed, and adopted with the shadow casting technique and introduced with modeling surface of different angles of two-dimensional animation through defining spot light source, which realizes the automatic generation of inner shadow and outer shadow of two-dimensional modeling, is applied in actual animation production and gains a good effect. © 2016 American Scientific Publishers All rights reserved.","3D animation; Automatic; Computer-assisted; O two-dimensional animation; Traditional hand drawing; Visual representation","Light sources; 3D animation; Automatic; Automatic Generation; Casting techniques; Computer assisted; Transitional process; Two dimensional model; Visual representations; Animation",2-s2.0-85015183166
"Kumar D., Vanualailai J.","Low bandwidth video streaming using FACS, facial expression and animation techniques",2016,"VISIGRAPP 2016 - Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968754803&partnerID=40&md5=e398e4aed33b0a2ebe79b9fddc98b5db","In this paper we describe an easy to use real-time 3D facial expression and animation system that takes the creation of individual facial expressions to the atomic level. That is instead of generating and recording known facial expressions we propose a mechanism that will allow us to create and store each atomic facial distortion. We can then combine some of these singular distortions to create meaningful expressions. FACS Action Units (AUs) is one such technique that describes the simplest visible movement, which cannot be decomposed into more basic ones. We use this as the basis for creating these atomic facial distortions. The Waters muscle based facial model has been used and extended to allow the user to calibrate and record each facial deformation as described in FACS AUs. The user can then create any facial expression by simply stating the series of AUs and its degree of activation in a controlled fashion. These features all form part of the Facial Animation System (FAS). Our FAS is implemented in such a way that enables it to be used as a low bandwidth video streaming player - a real time facial animation player driven only by FACS AUs transmitted as plain text over TCP sockets. © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Facial Animation; Facial Expression; FACS; Low Bandwidth; Video Streaming","Animation; Atoms; Bandwidth; Computer graphics; Computer vision; Face recognition; Video streaming; 3-d facial expressions; Animation techniques; Facial animation; Facial deformations; Facial Expressions; FACS; Low-bandwidth; Muscle-based facial model; Computer keyboards",2-s2.0-84968754803
"Ito T., Misue K.","A visualization technique using loop animations",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978849052&doi=10.1007%2f978-3-319-40349-6_14&partnerID=40&md5=ab8b509b1b57e6aa7e02d6c350f8e936","Animation extends the dimensions of spaces for visual representations by adding a temporal dimension. Although various techniques using animation have been proposed, most of them use a temporal dimension in the representation space only for representing temporal data. To represent quantitative data, an animation technique is proposed. A short animation played repeatedly is called a “loop animation.” The frequency of loop animations can represent quantitative data. Four variations of loop animations were designed and an experiment was conducted to evaluate their accuracy in representing quantitative data. In the experiment, loop animations were compared with static visual representations. The results showed that animations, in which either marks were spun or sizes were vibrated, were more accurate than visual representations using brightness and area. © Springer International Publishing Switzerland 2016.","Loop animation; Visualization","Animation; Flow visualization; Visualization; Animation techniques; Quantitative data; Representation space; Temporal Data; Temporal dimensions; Visual representations; Visualization technique; Human computer interaction",2-s2.0-84978849052
"Patel P., Gupta H., Chaudhuri P.","TraceMove: A data-assisted interface for sketching 2D character animation",2016,"VISIGRAPP 2016 - Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968883516&partnerID=40&md5=075269129c51d3a7d2c48fc42a7848b2","In this paper we present TraceMove, a system to help novice animators create 2D, hand-drawn, character animation. The system and interface assists not only in sketching the character properly but also in animating it. A database of image frames, from recorded videos of humans performing various motions, is used to provide pose silhouette suggestions as a static pose hint to the users as they draw the character. The user can trace and draw over the generated suggestions to create the sketch of the pose. Then the sketch of the next frame of the animation being drawn is automatically generated by the system as a moving pose hint. In order to do this, the user marks the skeleton of the character in a single sketched pose, and a motion capture database is used to predict the skeleton for the subsequent frame. The sketched pose is then deformed according to the predicted skeleton pose. Furthermore, the sketch generated by the system for any frame can always be edited by the animator. This lets novice artists and animators generate hand-drawn 2D animated characters with minimal effort. © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Data-assisted; Hand-drawn Character Animation; Sketch-based System","Computer graphics; Computer vision; Drawing (graphics); Musculoskeletal system; Animated characters; Automatically generated; Character animation; Data-assisted; Hand-drawn; Image frames; Motion capture; Sketch-based System; Animation",2-s2.0-84968883516
"Guinea B., Alaguero M., Melgosa F., Bustillo A.","Using a short video animation to assist with the diagnosis of sleep disorders in young children",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976638398&doi=10.1007%2f978-3-319-40651-0_2&partnerID=40&md5=007df1fef1c213da52d7320368e08720","A short video animation is designed to mitigate the fears of children admitted to hospital for the diagnosis of their sleep disorders. The video animation was produced following recommendations from medical staff involved in the diagnosis. Images taken from the animation decorated the hospital ward, to bring the video characters to life in the children’s minds. Finally, standard diagnosis of sleep disorders was performed by means of polysomnography on two groups of children: a reference and an evaluation group. Both parents and children responded to questionnaires that measured their satisfaction and the perception of their experiences. Preliminary findings extracted from the polysomnography showed that the videos helped to relax nervous children, especially sensitive to the hospital environment, and shortened Sleep Onset Latency and Non-REM latency. Besides, the responses to the questionnaires suggested that the video also reassured the parents whose moods helped the children to accept their hospitalization. © Springer International Publishing Switzerland 2016.","Blender; Children; Polysomnography; Short video animation; Sleep disorders","Augmented reality; Computer graphics; Diagnosis; Hospitals; Sleep research; Surveys; Virtual reality; Blender; Children; Polysomnography; Sleep disorders; Video animation; Animation",2-s2.0-84976638398
"Normoyle A., Jörg S.","The effect of animation controller and avatar on player perceptions",2016,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003846656&doi=10.1002%2fcav.1731&partnerID=40&md5=9a6f407a60d2555bb60eb6dd05f69056","Real-time animation controllers are fundamental for animating characters in response to player input in digital games. However, the design of such controllers requires making trade-offs between the naturalness of the character's motions and the promptness of the character's response. In this paper, we investigate the effects of such trade-offs on the players' enjoyment, control, satisfaction, and opinion of the character in a simple platform game. In our first experiment, we compare three controllers having the same responsiveness, but varying levels of naturalness. In the second experiment, we compare three controllers having increasing realism at the expense of responsiveness. In our third experiment, we keep motion naturalness and responsiveness constant but vary the avatar. Not surprisingly, our least responsive controller negatively affects players' performance and perceived ability to control the character. However, we also find that players are most satisfied with their own performance using our least natural controller, that differences in animation can significantly alter players' enjoyment with responsiveness being equal, that players do not report increased motion quality with our most natural controller, although viewers outside of the game context do, and that the avatar model affected the perception of the character but not players' enjoyment or perceived realism. © 2016 John Wiley & Sons, Ltd.","Controller; Digital games; Motion quality; Perception; Responsiveness; Virtual character","Animation; Commerce; Computer games; Economic and social effects; Interactive computer graphics; Sensory perception; Digital games; Perceived realisms; Player perception; Real-time animations; Responsiveness; Trade off; Virtual character; Controllers",2-s2.0-85003846656
"Sharaf N., Abdennadher S., Frühwirth T.","A rule-based approach to teach mathematics using animation",2016,"CEUR Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984924341&partnerID=40&md5=18ece384fa96c7b6c64a9dcbea3bff6c","There are different available methodologies for teaching mathematics to children. Teachers use different approaches. Some of the exiting approaches include engaging students with different activities and games. Computer games/tools have been proven effective with teaching mathematics. The aim of the paper is to provide teachers with no background in Computer Science with a utility that enables them to build their own games. In this way, teachers will be able to customize games according to the principles they want their students to learn.","Constraint handling rules; Learning; Mathematics; Program animation; Visualization","Animation; Computer games; Computer programming languages; Flow visualization; Mathematical techniques; Teaching; Constraint Handling Rules; Engaging students; Learning; Program animation; Rule-based approach; Education",2-s2.0-84984924341
"Pence T.B., Dukes L.C., Hodges L.F.","Animation validation of obese virtual pediatric patients using a FLACC pain scale",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978828798&doi=10.1007%2f978-3-319-39907-2_53&partnerID=40&md5=8c578ee60e52093832251e38c9ab8de1","We report on an experiment conducted to validate the nonverbal behaviors of our virtual patients as described by the standardized Face, Legs, Activity, Cry, Consolabiltiy scale [1] in relation to whether the virtual patient’s gender or obesity has an affect on the participants’ ability to correctly detect those animations. The results of this experiment provide insight into the feasibility of using a standardized pain scale as a method to validate virtual patients animations. © Springer International Publishing Switzerland 2016.","Simulation training; Virtual character animation; Virtual characters; Virtual environment; Virtual patients","Animation; Human computer interaction; Nonverbal behavior; Pediatric patients; Simulation training; Virtual character; Virtual patients; Virtual reality",2-s2.0-84978828798
"Bai R., Hou Q., Wang J., Gong Y.","Facial animation based on 2D shape regression",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006900481&doi=10.1007%2f978-3-319-48896-7_4&partnerID=40&md5=1579b88ec0e1a1540124fe163e911d81","We present a facial animation system for ordinary singlecameral videos based on 2D shape regression. Unlike some prior facial animation techniques, our system doesn’t need complex equipment. The system consists of firstly a Cascade Multi-Channel Convolutional Neural Network (CMC-CNN) model to accurately detect facial landmarks from 2D video frames. Based on these detected 2D points, the facial motion parameters, including the head pose and facial expressions, are recovered. Then the system animates a bone-driven 3D avatar with the facial motion parameters. Experiments show that our system can accurately detect facial landmarks and the animation results are visually plausible and similar to the user’s facial motion. © Springer International Publishing AG 2016.","3D avatars; Facial animation; Video tracking","Animation; Complex networks; Neural networks; Three dimensional computer graphics; 3D Avatars; Complex equipment; Convolutional neural network; Facial animation; Facial Expressions; Facial landmark; Facial motions; Video tracking; Face recognition",2-s2.0-85006900481
"Yang M., Ma X.","The interaction design research about 3D demo animation in smart home",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978857973&doi=10.1007%2f978-3-319-39862-4_8&partnerID=40&md5=32f99a22474120743acf40e1a1469781","In recent years, with the rapid development of technology, people’s living standards are generally improved and have played a very important role in our future life. Nowadays, we live in a fast-paced era that leaded by information, the heavy and boring instructions inevitably become a kind of burden before using appliances. In addition, it is a painful sorrow among the children, the old or the special people. However, the rise of 3D demo animation solves the problems very well. It exhibits the products from all aspects by the form of animation. Besides, in order to make users have more direct experiences, some film design companies put the interaction technology into it. It is direct interaction that brings users a combined feel of novelty, favor and trust, at the same time, it reduces the distance between products and users. So, products made by animation as well as interaction design should be explained from users’ view when design the 3D demo animation of smart home, which can make demo animation be more functional and interesting through some simple actions such as click, lither to let users know and use the appliance cheerfully. The interaction design of the 3D demo animation not only pay attention to the different gender region different requirements of age groups, but also study the different needs of special populations. It notices their needs on the basis of general design. This article lists some excellent 3D animation works at home and abroad, which display the products and the unique cultural image of the corporate by the way of interaction. This passage researches the physiological and psychological characteristics of the users when they touch the new product, then, it analyzes the design principle of the 3D demo animation as well as the users’ experiences. In the end, this paper not only make a analysis but also make a summary on the shortcomings of the interaction design. At the same time, it puts forward direction and suggestions for improvement of interaction design. © Springer International Publishing Switzerland 2016.","Demo animation; Interaction design; Users’ experiences","Animation; Automation; Design; Intelligent buildings; Product design; Design Principles; Direct experience; Direct interactions; General designs; Interaction design; Interaction technology; Living standards; Psychological characteristics; Human computer interaction",2-s2.0-84978857973
"Olejnik M., Szajerman D., Napieralski P.","Physically based area lighting model for real-time animation",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989890961&doi=10.1007%2f978-3-319-46418-3_7&partnerID=40&md5=b3c98efb1099d11f4a440aa12db6a214","Physically based rendering is not a new concept and it has been pursued in the scientific fields for a long time. However, it has not been until recently that the new generation of game consoles allowed more expensive algorithms to be adapted and computed in real-time constraints. In this paper, we analyse methods of approximating the lighting received from geometrical emitters (area lights) and compare them to the ground truth reference model computed through the Monte Carlo numerical integration algorithm. © Springer International Publishing AG 2016.",,"Animation; Computer graphics; Lighting; Monte Carlo methods; Numerical methods; Lighting model; Numerical-integration algorithms; Physically based; Physically based rendering; Real time constraints; Real-time animations; Reference modeling; Scientific fields; Computer vision",2-s2.0-84989890961
"Liu L.-L., Pang Y., Hu Z.-L.","Application of spectrogram analysis in traditional vocal music teaching and multimedia animation vocal music teaching",2016,"International Journal of Emerging Technologies in Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006355001&doi=10.3991%2fijet.v11i11.6242&partnerID=40&md5=23b37a4296426097d5e9b510d16f5ce6","The spectrogram analysis technology via computer application makes voice visualized, realizes the integrated teaching mode of ""mouth to ear- nose"", and improves the teaching quality of vocal music.The technology gives a dynamic map of singing respiration and singing organs, and the singing process is specified by the harmony search algorithm. This technology solves problems of shallow breathing, slurred speech and incorrect use of resonant cavity. The spectrogram analysis visualizes vocal music teaching, improves students' abilities of singing, practice and innovation.","Multimedia animation vocal music teaching; Spectrogram analysis; Traditional vocal music teaching","Animation; Spectrographs; Dynamic maps; Harmony search algorithms; Integrated teaching; Multimedia animation; Practice and innovations; Spectrograms; Teaching quality; Vocal music; Quality control",2-s2.0-85006355001
"Ravikumar S., Davidson C., Kit D., Campbell N., Benedetti L., Coskerk D.","Reading between the dots: Combining 3D markers and FACS classification for high-quality blendshape facial animation",2016,"Proceedings - Graphics Interface",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031749998&partnerID=40&md5=d7fc0d9710235fe251e61cb7cb77ed51","Marker based performance capture is one of the most widely used approaches for facial tracking owing to its robustness. In prac-tice, marker based systems do not capture the performance with complete fidelity and often require subsequent manual adjustment to incorporate missing visual details. This problem persists even when using larger number of markers. Tracking a large number of markers can also quickly become intractable due to issues such as occlusion, swapping and merging of markers. We present a new approach for fitting blendshape models to motion-capture data that improves quality, by exploiting information from sparse make-up patches in the video between the markers, while using fewer mark-ers. Our method uses a classification based approach that detects FACS Action Units and their intensities to assist the solver in pre-dicting optimal blendshape weights while taking perceptual quality into consideration. Our classifier is independent of the performer; once trained, it can be applied to multiple performers. Given per-formances captured using a Head Mounted Camera (HMC), which provides 3D facial marker based tracking and corresponding video, we fit accurate, production quality blendshape models to this data resulting in high-quality animations.","Blend-shapes; Face animation; Facial performance capture; Motion capture","Animation; Face animation; Head mounted Camera; Marker-based tracking; Motion capture; Motion capture data; Perceptual quality; Performance capture; Production quality; Computer keyboards",2-s2.0-85031749998
"Ji Y., Liu Y.","Development of an intelligent teaching system based on 3D technology in the course of digital animation production",2016,"International Journal of Emerging Technologies in Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000899982&doi=10.3991%2fijet.v11i09.6116&partnerID=40&md5=88cbb90ea952f3f73819ed9514266f97","In recent years, with the rapid development of 3D digital technology based on computers and the Internet, human beings have realized visual, 3D observation of the real world. The visual, 3D characteristic of this technology completely conforms to the teaching objective of the digital animation course. Thus, it is profoundly and practically significant to develop an intelligent 3D teaching system and apply it in the course of digital animation production. Through using digital animation production as the experimental course, this study comparatively analyzed the different teaching effect of using the intelligent 3D teaching system in the course of digital animation production, and provided theoretical and statistical supports for the application of that system in the course of digital animation production and college education.","3D; Development; Digital animation production; Intelligent teaching system","Animation; Curricula; Teaching; College education; Development; Digital technologies; Experimental course; Intelligent teaching systems; Teaching effects; Teaching objectives; Teaching systems; E-learning",2-s2.0-85000899982
"Manteaux P.-L., Wojtan C., Narain R., Redon S., Faure F., Cani M.-P.","Adaptive Physically Based Models in Computer Graphics",2016,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978196209&doi=10.1111%2fcgf.12941&partnerID=40&md5=f80ed34d35979cb2c329dd6b3f0305c9","One of the major challenges in physically based modelling is making simulations efficient. Adaptive models provide an essential solution to these efficiency goals. These models are able to self-adapt in space and time, attempting to provide the best possible compromise between accuracy and speed. This survey reviews the adaptive solutions proposed so far in computer graphics. Models are classified according to the strategy they use for adaptation, from time-stepping and freezing techniques to geometric adaptivity in the form of structured grids, meshes and particles. Applications range from fluids, through deformable bodies, to articulated solids. Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Adaptivity; I.3.7 Computer GraphicsThree-Dimensional Graphics and Realism-Animation; Physically based animation","Animation; Adaptive models; Adaptive solution; Adaptivity; Deformable bodies; Freezing techniques; Physically based models; Physically-based animation; Physically-based Modelling; Computer graphics",2-s2.0-84978196209
"Chen L., Li L.","Optimization of animation curve generation based on hermite spline interpolation",2016,"International Journal of Multimedia and Ubiquitous Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970976494&doi=10.14257%2fijmue.2016.11.5.31&partnerID=40&md5=f4bd7608f01c254823fae7d1c05135d9","Computer animation is the combination of computer graphics and art field. In computer animation design, the adjustment of route for the animation object movement is a time consuming work for the designers. It is not only related to the generation of motion path curve, but also related to the speed smoothness of key frames. Based on the methodology of Hermite spline interpolation, this paper proposes a method to adjust the curve tangent vector length by considering the parameter of key frame, and use this method to relieve the unevenness of animation speed. Experimental results demonstrate that this method can improve the movement effect of animation route design efficiently. © 2016 SERSC.","Animation movement curve; Hermite spline; Spline interpolation",,2-s2.0-84970976494
"Correia N.N.","Paths to engagement combining sound, animation and interactivity: A comparative evaluation of three net art projects",2016,"International Journal of Arts and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976865345&doi=10.1504%2fIJART.2016.077236&partnerID=40&md5=7386b4d0b560f21ca65a6f7caa50522f","This paper compares three net art projects combining sound and animation by the author and André Carrilho (under the name Video Jack): AVOL, Master and Margarita and AV Clash. They follow a development path aiming to create projects enabling integrated audiovisual creativity that are flexible, intuitive, playful to use and engaging to experience. The comparative evaluation of the projects focuses on the analysis of the answers to an online questionnaire. The projects are also contextualised with related works. The methodology for the research is presented, with an emphasis on experience-focused human-computer interaction perspectives. The results of the questionnaire are then discussed. Conclusions are reached regarding the development path, showing that AV Clash has been more successful than previous projects in reaching its objectives, but that it still contains several weaknesses. Strengths detected in previous projects AVOL and Master and Margarita are analysed. Finally, paths for future development are presented. © 2016 Inderscience Enterprises Ltd.","Animation; Audiovisual; Creativity; Engagement; Evaluation; Experience focused; HCI; Human-computer interaction; Interactivity; Multi-sensorial; Net art; New media art; Sound; Usability; Visual music","Acoustic waves; Animation; Surveys; Audiovisual; Creativity; Engagement; Evaluation; Experience focused; Interactivity; Multi-sensorial; Net art; New media art; Usability; Visual music; Human computer interaction",2-s2.0-84976865345
"Abdul-Massih M., Yoo I., Benes B.","Motion Style Retargeting to Characters With Different Morphologies",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962835842&doi=10.1111%2fcgf.12860&partnerID=40&md5=ffc576179fc66cf41eeb2356c3783573","We present a novel approach for style retargeting to non-humanoid characters by allowing extracted stylistic features from one character to be added to the motion of another character with a different body morphology. We introduce the concept of groups of body parts (GBPs), for example, the torso, legs and tail, and we argue that they can be used to capture the individual style of a character motion. By separating GBPs from a character, the user can define mappings between characters with different morphologies. We automatically extract the motion of each GBP from the source, map it to the target and then use a constrained optimization to adjust all joints in each GBP in the target to preserve the original motion while expressing the style of the source. We show results on characters that present different morphologies to the source motion from which the style is extracted. The style transfer is intuitive and provides a high level of control. For most of the examples in this paper, the definition of GBP takes around 5 min and the optimization about 7 min on average. For the most complicated examples, the definition of three GBPs and their mapping takes about 10 min and the optimization another 30 min. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Animation retargeting; Animation systems; Animation w/constraints; Different morphologies; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation; Motion control","Animation; Computer control systems; Computer graphics; Constrained optimization; Mapping; Motion control; Three dimensional computer graphics; Animation systems; Body parts; Character motion; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Motion styles; Source motion; Morphology",2-s2.0-84962835842
"Andaluz V.H., Sánchez J.S., Chamba J.I., Romero P.P., Chicaiza F.A., Varela Aldas J., Quevedo W.X., Gallardo C., Cepeda L.F.","Unity3D virtual animation of robots with coupled and uncoupled mechanism",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976628189&doi=10.1007%2f978-3-319-40621-3_6&partnerID=40&md5=c14613232f53266d681752919582b3ec","This paper presents the development of the animation of robots in virtual reality environments, whose mechanisms can be coupled -the movement relies on mechanical principles-; and uncoupled mechanisms, i.e., the degrees of freedom are controlled independently via a control unit. Additionally, the present phases to transfer the design of a robot developed in a CAD tool to a virtual simulation environment without being lost the physical characteristics of the original design are showed, for which it is considered the various types of motions that the robot can perform depending on the design. Finally, shows the results obtained from the simulation of motion of a robot hexapod 18DOF and Theo Jansen mechanism. © Springer International Publishing Switzerland 2016.","Coupled and uncoupled mechanism; Robot simulation; Unity3D; Virtual reality","Animation; Augmented reality; Computer aided design; Computer graphics; Degrees of freedom (mechanics); Machine design; Mechanisms; Robots; Control unit; Mechanical principles; Original design; Physical characteristics; Robot simulations; Unity3d; Virtual simulation environments; Virtual-reality environment; Virtual reality",2-s2.0-84976628189
"Spinillo C.G.","Animation on how to take medicines: A study of electronic patient leaflets in Brazil",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977495140&doi=10.1007%2f978-3-319-40355-7_62&partnerID=40&md5=cc7f274329ed3b8f0f6af39e529632bc","Animation has been proved to facilitate content learning. However, in Brazil the electronic Patient Information Leaflets (e-PILs) do not employ animation, but static images, to show medicine usage to patients. By considering animation a beneficial communication resource to PILs, a study was conducted with 80 participants on comprehension and simulated tasks of using the medicines: vaginal cream, insulin syringe, inhaler and nasal spray. The results ratified the assumption, however, suggest that (a) participants’ perception of their understanding and task performance are related to their satisfaction with the animation, and (b) there is a gap between users’ understanding of medicine animation and their task performance when using a medicine. Recommendations are proposed based upon the literature and the outcomes of the study. © Springer International Publishing Switzerland 2016.","Animation; Comprehension; Medicine usage; Task performance","Human computer interaction; Communication resources; Comprehension; Patient information; Static images; Task performance; Animation",2-s2.0-84977495140
"Rumman N.A., Fratarcangeli M.","State of the art in skinning techniques for articulated deformable characters",2016,"VISIGRAPP 2016 - Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968758003&partnerID=40&md5=676eb975df6a0904ff2acc5a1ce9f108","Skinning is an indispensable component of the content creation pipeline for character animation in the context of feature films, video games, and in the special effects industry. Skinning techniques define the deformation of the character skin for every animation frame according to the current state of skeletal joints. In this state of the art report, we focus on the existing research in the areas of skeleton-based deformation, volume preserving techniques and physically based skinning methods. We also summarize the recent research in deformable and soft bodies simulations for articulated characters, and discuss various geometric and examples-based approaches. © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Character Animation; Physics-Based Animation; Skeleton-Based Animation; Skinning","Computer graphics; Computer vision; Deformation; Motion pictures; Musculoskeletal system; Based animations; Character animation; Content creation; Physically based; Physics-based animation; Recent researches; Skinning; Volume-preserving; Animation",2-s2.0-84968758003
"Ryu C.-S., Jang J.-H.","Proposal for local pose animation system for games using iClone",2016,"Information (Japan)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960412889&partnerID=40&md5=923213c4f16e86d2b09902c6f2098b42","Amidst the rapid changes in media, such as the introduction of various smart devices (e.g., smartphones and tablet personal computers), and the improvements in hardware performance and development of new platforms, the animation field is recognizing the need for an animation system that provides high-end images and enables easy and convenient animation production. Although there are various animation production tools for producing appropriate content, learning character modeling, mapping, rigging, etc., prior to producing animation is considerably time-consuming, and a separate animation system is required for producing animation. This paper aims to describe iClone as an animation system appropriate for smart device-based games. A local pose animation system for games was suggested by creating an avatar for game animation using character-based animation, editing motion by editing clothing and accessories, and compressing data appropriately into a smart device with gaming capability. © 2016 International Information Institute.","Animation; Avatar; Character; Game; iClone",,2-s2.0-84960412889
"Kada M., Wichmann A., Filippovska Y., Hermes T.","Animation strategies for smooth transformations between discrete lods of 3D building models",2016,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981164613&doi=10.5194%2fisprsarchives-XLI-B2-413-2016&partnerID=40&md5=67f9c8a24402b57cca727025351f506e","The cartographic 3D visualization of urban areas has experienced tremendous progress over the last years. An increasing number of applications operate interactively in real-time and thus require advanced techniques to improve the quality and time response of dynamic scenes. The main focus of this article concentrates on the discussion of strategies for smooth transformation between two discrete levels of detail (LOD) of 3D building models that are represented as restricted triangle meshes. Because the operation order determines the geometrical and topological properties of the transformation process as well as its visual perception by a human viewer, three different strategies are proposed and subsequently analyzed. The simplest one orders transformation operations by the length of the edges to be collapsed, while the other two strategies introduce a general transformation direction in the form of a moving plane. This plane either pushes the nodes that need to be removed, e.g. during the transformation of a detailed LOD model to a coarser one, towards the main building body, or triggers the edge collapse operations used as transformation paths for the cartographic generalization.","3D; Animation; Building; Levels of detail; Multiple representations; Visualization","Animation; Buildings; Flow visualization; Mapping; Remote sensing; Three dimensional computer graphics; Topology; Visualization; 3D building models; Cartographic generalization; Levels of detail; Multiple representation; Smooth transformation; Topological properties; Transformation paths; Transformation process; Mathematical transformations",2-s2.0-84981164613
"Aktasx A.Z., Orcxun E.","A survey of computer game development",2016,"Journal of Defense Modeling and Simulation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966621658&doi=10.1177%2f1548512914554405&partnerID=40&md5=c96e3a8a87c18f32a37aad20bfdeb895","A computer game is special software to run on a computer for enjoyment and education. A computer game interacts with a user interface and generates audio-visual feedback. In this article computer games and the relevant processes and methodologies for their development were surveyed. Basically a computer game consists of design elements and technical components. The players, stories, rules, objectives, procedures, conflicts and challenges are the design elements of a computer game. They all have conflicts and challenges and have effects over gameplay. In addition to design elements, there are technical components that may be grouped into four as ‘the render engine and rendering pipeline’, ‘physics engine and physics-related techniques’, ‘game codes’ and ‘artwork contents’. Fixed-function pipeline and flexible pipeline are the render engine and rendering pipeline. Physics engine and physics-related techniques are collision detection, ray casting, etc. Game codes are for game mechanics, artificial intelligence, scenario creation and management. Artwork contents have game level, three-dimensional models, twodimensional maps for shaders, skeletal animation and audio assets. The major objective of the study to be reported in this article was to apply all these methodologies, techniques and tools on a case problem after studying design elements and technical components. © The Author(s) 2014.","Game design; Game development; Real-time strategy game; Three-dimensional computer game","Animation; Artificial intelligence; Design; Engines; Interactive computer graphics; Pipeline codes; Pipelines; Rendering (computer graphics); Software design; Surveys; Three dimensional computer graphics; User interfaces; Visual communication; Collision detection; Computer game development; Game design; Game development; Real-time strategy games; Techniques and tools; Three-dimensional model; Two-dimensional map; Computer games",2-s2.0-84966621658
"Tavares P.C., Henriques P.R., Gomes E.F.","Computer-supported techniques to increase students engagement in programming",2016,"CSEDU 2016 - Proceedings of the 8th International Conference on Computer Supported Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979500163&partnerID=40&md5=edc0bf3f2d59fcae1ab578d93b115e54","One of the main reasons that justify the student's failure in (introductory) programming courses is the lack of motivation that impacts on the knowledge acquisition process, affecting learning results. As soon as students face the difficulties concerning the development of algorithms or the coding in a programming language, they give up and do not try harder to solve other problems; they think it is a demanding activity and feel frustrated. In this paper we describe in detail an experiment conducted to verify the effectiveness, in terms of the increase in motivation and in knowledge acquisition, of combining program Animation tools with the immediate feedback provided by Automatic Evaluations Systems. Copyright © 2016 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved.","Animation; Automatic Evaluation; Feedback; Learning; Programming; Students","Animation; Computer programming; E-learning; Education; Feedback; Knowledge acquisition; Mathematical programming; Motivation; Automatic evaluation; Immediate feedbacks; Learning; Program animation; Programming course; Students",2-s2.0-84979500163
"Li T.-H., Chen K.-S.","A Wiimote 3D localization scheme without channel constraints",2016,"Advances in Intelligent Systems and Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946616246&doi=10.1007%2f978-3-319-23923-1_84&partnerID=40&md5=543260d90653f8f36b939dd6eae86aae","A novel 3D Wiimote localization scheme with no channel constraints has been proposed for smart living or computer animation applications. This scheme utilizes two Wiimotes for performing stereo range finding and an Arduino- based IR LED switching for breaking the constraint on available channels. By controlling the switching of IR LED units sequentially, the equivalent available channels can be extended with a trade off in system bandwidth. This Wiimote-based 3D localization system can detect more IR LEDs than the number of original channels and each IR LED can be identified correctly even if it passes through a shelter. A testing system is also setup for evaluating the performance on the 3D localization and IR LED switching control. The preliminary results indicate that the position of IR LEDs can be accurately detected and the system can identify IR LEDs without channel constraints. This novel localization system is expected to have a great potential on applications such as mobile robots monitoring or human motion capture for animations. © Springer International Publishing Switzerland 2016.","3D localization; Arduino-based IR LED control; Wiimote","Animation; Economic and social effects; Range finding; 3D localization; Available channels; Channel constraints; Computer animation; Human motion capture; Localization schemes; Localization system; Wiimote; Object recognition",2-s2.0-84946616246
"Zilly F., Ziegler M., Keinert J., Schöberl M., Foessel S.","Computational imaging for stop-motion animated video productions",2016,"SMPTE Motion Imaging Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974846313&partnerID=40&md5=11baeec1325261c94c6dd2c397cb2411","Creating movies using stop-motion technology remains a fascinating approach for storytelling even in the era of digital cinema. A huge number of professional and semiprofessional clips that were produced as fan art can be watched on Internet video platforms and serve as testimonial for the unbroken interest in unleashing creative potential using this technology. However, producing content using stop motion remains a cumbersome task that raises production costs, especially for full-length movies. Consequently, a trend can be observed even for successful television series that were originally produced using stop motion in which the production scheme was changed to computer animation. Against this background, we propose a production scheme for stop-motion-animated movies that has the potential to lower the production costs while increasing the quality of the resulting content. By using a static multicamera array and algorithms from the field of computational imaging, our technology allows artistic effects to be created in the post-production that are difficult to realize using conventional stop-motion production methods. Our approach allows changing the depth of field, smoothly moving the camera along virtual camera paths, and upsampling the frame rate of the stop-motion video in high quality. All effects are computed and applied in post-production, while all intrinsic and extrinsic parameters of the cameras remain static during the whole production. To demonstrate the practicability, results are shown from a stop-motion video that has been produced using the proposed approach. Copyright © Fraunhofer IIS.",,"Animation; Arts computing; Cameras; Motion pictures; Artistic effects; Computational imaging; Computer animation; Creative potentials; Intrinsic and extrinsic parameters; Motion technology; Production methods; Production schemes; Motion analysis",2-s2.0-84974846313
"Vilouras A., Heidari H., Navaraj W.T., Dahiya R.","At-home computer-aided myoelectric training system for wrist prosthesis",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978251005&doi=10.1007%2f978-3-319-42324-1_28&partnerID=40&md5=01a0a8536e7f18b9f28866409e9326d0","Development of tools for rehabilitation and restoration of the movement after amputation can benefit from the real time interactive virtual animation model of the human hand. Here, we report a computer-aided training/learning system for wrist disarticulated amputees, using the open source integrated development environment called “Processing”. This work also presents the development of a low-cost surface Electro-MyoGraphic (sEMG) interface, which is an ideal tool for training and rehabilitation applications. The processed sEMG signals are encoded after digitization to control the animated hand. Experimental results demonstrate the effectiveness of the sEMG control system in acquiring sEMG signals for real-time control. Users have also the ability to connect their prostheses with the training system and observe its operation for a more explicit demonstration of movements. © Springer International Publishing Switzerland 2016.","Computer-aided; Control prosthesis; SEMG; Training system","Artificial limbs; Myoelectrically controlled prosthetics; Open systems; Prosthetics; Real time control; Virtual reality; Web services; Animation modeling; Computer aided; Computer aided trainings; Integrated development environment; Open sources; Rehabilitation and restoration; SEMG; Training Systems; Computer control systems",2-s2.0-84978251005
"Ebrahimi M.R., Gorjian Z., Niakan M., Naseri S., Eradi S., Amori N.","The effect of the computer animationillustrator as a graphic software on the pre-school children's creativity appraisal",2016,"International Journal of Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011320565&doi=10.3923%2fijscomp.2016.397.400&partnerID=40&md5=af0c4e3d3f31b5e2f927ef8a90976a6b","This research investigated the effect of the computer animation illustrator on the creativity of pre-school children in Abadan, Iran. Creativity is supposed as a goal that makes people to think. It is a complicated issue which helps the individuals make ideas, insights and speculation to reconstruct their thoughts in any disciplines. Creative education requires children to think from the earliest days of their life. Thus, this study was going to discover the computer animation illustrator on their creativity. This research was a cross sectional research dealt with 34-six year old children. They were trained through 90-min sessions conducted by trained instructors. The test of Form-A of torrancepictorial creativity was given to the children before and after treatment. Results showed that training of children through animation illustrator could significantly enhance children's creativity. © Medwell Journals, 2016.","Animation; Computer; Creativity; Illustrator; Pre-school; Torrance-form a",,2-s2.0-85011320565
"Oshita M., Senju Y.","Generating hand motion from body motion based on hand pose estimation",2016,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986317471&doi=10.1002%2fcav.1730&partnerID=40&md5=1dc9c482b50520e0dbf36e73d59ecb64","In this paper, we propose a method to generate hand motion from full-body motion. We assume that hand pose can be estimated from full-body pose. We use a support vector machine to choose one of four key hand poses based on the full-body pose. The training model is constructed from a number of full-body motions with manually specified hand-pose keyframes. The output poses are synthesized to include the generated continuous hand motion. We realize smooth transitions between key hand poses and add small movements of fingers for generating plausible hand motions. Because our method does not require future poses, it is valid for both on-line and off-line animation. Our experimental results show that our model is applicable to a wide range of full-body motions. © 2016 John Wiley & Sons, Ltd.","Computer animation, hand motion, machine learning, pattern recognition","Animation; Artificial intelligence; Learning systems; Body motions; Full body; Full-body motions; Hand motion; Hand pose estimations; Key-frames; Smooth transitions; Training model; Pattern recognition",2-s2.0-84986317471
"Zhao M., Yuan Y., Shi Z., Zhao J., Wang Y.","An efficient approach to the construction of motion graphs",2016,"International Journal of Applied Electromagnetics and Mechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009241574&doi=10.3233%2fJAE-162130&partnerID=40&md5=d6608828aace27f74dc46f92fc0fa0ec","A novel approach to the construction of motion graphs based on a new similarity measurement method is proposed in this paper. The main contributions of this paper are: i) to improve the accuracy of motion similarity computing, a new similarity measurement method is presented which combines frame distance based on dynamic time warping (DTW) with uniform warping window and motion distance based on motion features; ii)to avoid illogical jump of standard motion graph, a new automatic construction strategy of motion graphs based on similarity of motion clips is proposed, transition points of which are matched based on the path with the minimum cost and motions are synthesized based on motion transition points. Experimental results based on the CMU MoCap human motion database show that the proposed method can confirm the logical correctness and naturalness in the junction of two human locomotion sequences and its efficiency is two or three times faster than the standard motion graph.","Computer animation; interpolation; motion capture; motion graph; motion synthesis","Animation; Interpolation; Motion estimation; Automatic construction; Computer animation; Human motion database; Logical correctness; Motion capture; Motion graph; Motion synthesis; Similarity measurements; Transition flow",2-s2.0-85009241574
"Lemercier S., Auberlet J.-M.","Towards more behaviours in crowd simulation",2016,"Computer Animation and Virtual Worlds",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957429072&doi=10.1002%2fcav.1629&partnerID=40&md5=d81dd08250a416e8a6b9ac20dc3b7460","While collision avoidance has been the most active topic in pedestrian simulation, the modelling of other kinds of behaviours appears to be essential for better realism. Thus higher cognitive levels of perception and behaviour improve simulation quality. Furthermore, giving an agent the possibility to choose the nature of its interactions with the others can not only improve simulation realism but also bring heterogeneity in the simulated population because each agent individually perceives the situation according to its own characteristics. In this paper, we aim at providing the pedestrian agent the ability to obtain an individual representation of the environment that allows him to adapt its behaviour according to the situation. We base our work on the analysis and interpretation of the environment, which makes the agent decide the behaviour it is going to adopt. We focus on two kinds of behaviours, following and group avoidance behaviours, and on their integration in classical avoidance simulations. We integrate recent works about following behaviour and propose to model interactions directly with groups of people instead of individuals. We aim at providing perception rules totally independent from the collision avoidance model used in the simulation. Because of the improved perception process, we observe emerging speed waves, group behaviours and lane formation in our simulations. Our results demonstrate the interest of modelling such behaviours to obtain more realistic simulations and show that specific patterns and collective behaviours emerge when using several types of behaviours in simulations. Copyright © 2015 John Wiley & Sons, Ltd.","computer animation; model development; multi-agent systems","Animation; Collision avoidance; Multi agent systems; Avoidance behaviour; Collective behaviour; Collision avoidance models; Computer animation; Model development; Pedestrian simulation; Realistic simulation; Simulation quality; Behavioral research",2-s2.0-84957429072
"Sung M.","Controlling flock through normalized radial basis function interpolation",2016,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952038286&doi=10.1007%2f978-3-319-17314-6_57&partnerID=40&md5=f1351a57766250f511cc99378eeb1612","This chapter introduces a controllable real-time flocking simulation framework through a vector field based on normalized radial basis function. During the design process, the framework subdivides the entire simulating environment into small cells, a so-called grid structure, and then assigns a vector per each cell, which represents a 2D vector field. The vectors of the field are automatically calculated by specifying a set of control vectors which are used for interpolating all vectors on the field. The interpolation scheme is based on normalized radial basis function. Once the construction of vector field is done, at the low level, flocks are simulated by following the vector field in the grid structure. Throughout this process, the position of individual agents is updated and collisions between the flock and the static obstacles are avoided by emitting a repulsive vector around the obstacles on the field. Interindividual collisions are also handled through fast lattice-bin method which can minimize the number of comparisons for detecting collisions. © Springer International Publishing Switzerland 2016.","Computer animation; Flocking; Radial basis functions","Animation; Functions; Heat conduction; Image segmentation; Interpolation; Radial basis function networks; Computer animation; Flocking; Flocking simulation; Individual agent; Interpolation schemes; Normalized radial basis functions; Radial basis functions; Static obstacles; Vectors",2-s2.0-84952038286
"Sung M.","3D motion editing through B-spline fitting with constraints",2016,"Lecture Notes in Electrical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951992312&doi=10.1007%2f978-3-319-17314-6_22&partnerID=40&md5=e1bb82c6b96f8802b942cd3552806b62","This paper proposes a novel motion editing algorithm that uses human motion capture data for animating 3D characters. First, the algorithm fits the 2D root joint trajectory with the cubic B-Spline through least-square minimization. In this process, it finds the optimal number of control points based on an error threshold. Once it gets n control points, users are allowed to change the positions of control points, which is able to create a new trajectory. The new trajectory is then fed into the original motion so that it is modified to reflect the new trajectory. To find exact parameter t of the spline curve representing root joint position, the algorithm performed the arc-length parameterization on the curve. Since the motions are forced to change the root joint positions, the result may violate the fidelity of the original motions, which may cause some artifacts such as foot skating. To fix them, the IK (Inverse Kinematics) solver is applied to motions to change the limb orientation. Although the IK solver can change the orientation of original motions, if the differences between the modified trajectory and original trajectory are too big, then the result motion produces awkward poses over times. In order to prevent them, our algorithm puts constraints on the control points of curve automatically so that users are able to edit the trajectory freely without considering whether it produces natural motions or not. © Springer International Publishing Switzerland 2016.","3D motion editing; Computer animation; Motion capture","Animation; Interpolation; Inverse kinematics; Joints (anatomy); Motion picture editing machines; Splines; Trajectories; 3D motion; B-spline fittings; Computer animation; Human motion capture data; Joint trajectories; Least square minimization; Motion capture; Natural motions; Algorithms",2-s2.0-84951992312
"Brunner S., Ricks B., Egbert P.K.","Realistic crowds via motion capture and cell marking",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978215765&doi=10.1007%2f978-3-319-41778-3_7&partnerID=40&md5=131775e1f1140b2ccc0428878fc0f49d","Ever since the first use of crowds in films and video games there has been an interest in larger, more efficient and more realistic simulations of crowds. Most crowd simulation algorithms are able to satisfy the viewer from a distance but when inspected from close up the flaws in the individual agent’s movements become noticeable. One of the bigger challenges faced in crowd simulation is finding a solution that models the actual movement of an individual in a crowd. This paper simulates a more realistic crowd by using individual motion capture data as well as traditional crowd control techniques. By augmenting traditional crowd control algorithms with the use of motion capture data for individual agents, we can simulate crowds that mimic more realistic crowd motion, while maintaining real-time simulation speed. © Springer International Publishing Switzerland 2016.","Computer animation; Crowd simulation; Motion capture","Animation; Deformation; Software agents; Computer animation; Crowd control; Crowd Simulation; Individual agent; Motion capture; Motion capture data; Real time simulations; Realistic simulation; Algorithms",2-s2.0-84978215765
"Liu X., Xu Y., Zhai X., Xu W.","Research on motion simulation of trees model in wind filed",2016,"International Journal of Control and Automation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975290483&doi=10.14257%2fijca.2016.9.5.36&partnerID=40&md5=0299a7d2e51d4606fefd2f52465f6129","With the development of computer animation and demands for gaming, the motion simulation of trees in wind filed has become one of the research hotspots. In order to better simulate the 3D motion of trees to wind filed in the natural environment, this paper proposes a method to establish real-time animation visualization of trees in the wind. The research focus is making the process of performance of ranches swaying motion become more real, layered modeling was carried out on the branches and combining the theory of fractal iteration for simulation, making the effect of wind field on the branches can carry on the hierarchical structure to analysis and calculation in detailed, so as to achieve good swing results. This paper implements a dynamic simulation demonstration system of trees in the wind based on fractal iteration system to be consistent with branches in the wind with the nature of the scene. Therefore it can generate both satisfied visual effects and dynamic images that meet the real-time requirements. © 2016 SERSC.","Animation simulation; Tree modeling; Trees sawing; Wind field","Animation; Fractals; Iterative methods; Three dimensional computer graphics; Analysis and calculations; Hierarchical structures; Natural environments; Real time requirement; Real-time animations; Theory of fractals; Tree modeling; Wind field; Forestry",2-s2.0-84975290483
"Cai J., Lin F., Seah H.S.","Graphical simulation of deformable models",2016,"Graphical Simulation of Deformable Models",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029080879&doi=10.1007%2f978-3-319-51031-6&partnerID=40&md5=e4b4648881a61a497596bcef3d3150dd","This book covers dynamic simulation of deformable objects, which is one of the most challenging tasks in computer graphics and visualization. It focuses on the simulation of deformable models with anisotropic materials, one of the less common approaches in the existing research. Both physically-based and geometrically-based approaches are examined. The authors start with transversely isotropic materials for the simulation of deformable objects with fibrous structures. Next, they introduce a fiber-field incorporated corotational finite element model (CLFEM) that works directly with a constitutive model of transversely isotropic material. A smooth fiber-field is used to establish the local frames for each element. To introduce deformation simulation for orthotropic materials, an orthotropic deformation controlling frame-field is conceptualized and a frame construction tool is developed for users to define the desired material properties. The orthotropic frame-field is coupled with the CLFEM model to complete an orthotropic deformable model. Finally, the authors present an integrated real-time system for animation of skeletal characters with anisotropic tissues. To solve the problems of volume distortion and high computational costs, a strain-based PBD framework for skeletal animation is explained; natural secondary motion of soft tissues is another benefit. The book is written for those researchers who would like to develop their own algorithms. The key mathematical and computational concepts are presented together with illustrations and working examples. It can also be used as a reference book for graduate students and senior undergraduates in the areas of computer graphics, computer animation, and virtual reality. Academics, researchers, and professionals will find this to be an exceptional resource. © Springer International Publishing Switzerland 2016.","Anisotropic material; Computer animation; Computer graphics; Deformable model; Dynamics; Finite element method; Geometrical modeling; Graphical simulation; Position based dynamics; Virtual reality",,2-s2.0-85029080879
"Chen Y.-J., Wu J.-L.","A computer-aided articulation learning system for subjects with articulation disorders",2016,"Engineering Computations (Swansea, Wales)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989924079&doi=10.1108%2fEC-08-2015-0235&partnerID=40&md5=32251d77bc27fcee421af30c0f8ebd44","Purpose - Articulation errors substantially reduce speech intelligibility and the ease of spoken communication. Moreover, the articulation learning process that speech-language pathologists must provide is time consuming and expensive. The purpose of this paper, to facilitate the articulation learning process, is to develop a computer-aided articulation learning system to help subjects with articulation disorders. Design/methodology/approach - Facial animations, including lip and tongue animations, are used to convey the manner and place of articulation to the subject. This process improves the effectiveness of articulation learning. An interactive learning system is implemented through pronunciation confusion networks (PCNs) and automatic speech recognition (ASR), which are applied to identify mispronunciations. Findings - Speech and facial animations are effective for assisting subjects in imitating sounds and developing articulatory ability. PCNs and ASR can be used to automatically identify mispronunciations. Research limitations/implications - Future research will evaluate the clinical performance of this approach to articulation learning. Practical implications - The experimental results of this study indicate that it is feasible for clinically implementing a computer-aided articulation learning system in learning articulation. Originality/value - This study developed a computer-aided articulation learning system to facilitate improving speech production ability in subjects with articulation disorders. © 2016 Emerald Group Publishing Limited.","Articulation disorder; Articulation learning; Automatic speech recognition; Facial animation","Computer aided instruction; Learning systems; Speech; Speech communication; Speech intelligibility; Automatic speech recognition; Clinical performance; Confusion networks; Design/methodology/approach; Facial animation; Interactive learning systems; Speech language pathologists; Speech production; Speech recognition",2-s2.0-84989924079
"Sun Q.","The application of polygon modeling method in the maya persona model shaping",2016,"Revista Tecnica de la Facultad de Ingenieria Universidad del Zulia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011985271&doi=10.21311%2f001.39.12.37&partnerID=40&md5=ca4e46b348bf0a8cfadb275e51ceff5d","Computer graphics is a new industry derived from the computer technology. With the high development of science and technology, because of the accuracy and real artistic effect of three-dimensional animation, it has become a new trend of development. As a key part of three-dimensional animation, model creation has occupied an important position in the animation. To make the animated character image more plump and realistic, it has a high demand for the character model shaping. As a traditional modeling method, Maya modeling method has a unique advantage in the organism model creation. This paper systematically expounded the polygon modeling features and usability techniques of persona modeling. It aimed to make the model creation much more standardized and professionally.","Computer graphics; Modeling method; Polygon; Three-dimensional","Animation; Computer graphics; Geometry; Animated characters; Computer technology; Development of science and technologies; Model method; Polygon; Three-dimensional animations; Traditional models; Usability techniques; Three dimensional computer graphics",2-s2.0-85011985271
"Zatopek J.","Simulation and visualisation of a laboratory model by support software tools connection",2016,"Annals of DAAAM and Proceedings of the International DAAAM Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010767304&doi=10.2507%2f27th.daaam.proceedings.108&partnerID=40&md5=a96acf3f7bce98f36a940516cfd9e797","This article introduces the possibilities of the simulation and visualisation of the ""Twin-Rotor MIMO System"" laboratory model outputs by means of various support software tools. The 3D model of the system, (used for simulation and visualisation), is designed in SolidWorks 3D CAD software. Matlab/Simulink with extension libraries like Simscape and 3D Animation - (formerly Virtual Reality Toolbox), is used for 3D visualisation and simulation. The 3D Animation toolbox is only used for the visualisation of the mathematical and real models. The Simscape library - on the other hand, is used for the validation of the reverse control of the derived mathematical models correctness and for simulation and analysis purposes as a suitable substitution for real models. As a result of this, these supporting software tools streamline the overall suggested controls - from analysis to presentation of the results.","3D Animation; Matlab/simulink; Motion control; Simscape; Simulation; Visualisation","Animation; Computer aided software engineering; Computer software; Digital libraries; MATLAB; MIMO systems; Motion control; Virtual reality; Visualization; 3D animation; 3D Visualisation; Laboratory models; MATLAB /simulink; Simscape; Simulation; Simulation and analysis; Twin Rotor MIMO System; Computer aided design",2-s2.0-85010767304
"MacDorman K.F., Chattopadhyay D.","Reducing consistency in human realism increases the uncanny valley effect; increasing category uncertainty does not",2016,"Cognition",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943185939&doi=10.1016%2fj.cognition.2015.09.019&partnerID=40&md5=e0dcea7b6be8b96fabc3afe0046b4d66","Human replicas may elicit unintended cold, eerie feelings in viewers, an effect known as the uncanny valley. Masahiro Mori, who proposed the effect in 1970, attributed it to inconsistencies in the replica's realism with some of its features perceived as human and others as nonhuman. This study aims to determine whether reducing realism consistency in visual features increases the uncanny valley effect. In three rounds of experiments, 548 participants categorized and rated humans, animals, and objects that varied from computer animated to real. Two sets of features were manipulated to reduce realism consistency. (For humans, the sets were eyes-eyelashes-mouth and skin-nose-eyebrows.) Reducing realism consistency caused humans and animals, but not objects, to appear eerier and colder. However, the predictions of a competing theory, proposed by Ernst Jentsch in 1906, were not supported: The most ambiguous representations-those eliciting the greatest category uncertainty-were neither the eeriest nor the coldest. © 2015 The Authors.","Anthropomorphism; Computer animation; Face perception; Photorealism","adult; Article; classification; cognition; computer model; confusion (uncertainty); ego; eye; eyebrow; eyelash; female; forced choice method; human; human experiment; male; mouth; normal human; nose; prediction; priority journal; skin; stimulus response; task performance; visual stimulation; facial recognition; perception; physiology; uncertainty; young adult; Adult; Facial Recognition; Female; Humans; Male; Social Perception; Uncertainty; Young Adult",2-s2.0-84943185939
"Chattopadhyay D., MacDorman K.F.","Familiar faces rendered strange: Why inconsistent realism drives characters into the uncanny valley",2016,"Journal of Vision",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994030800&doi=10.1167%2f16.11.7&partnerID=40&md5=291a275c41d5a2fd578f78d457cd8b97","Computer-modeled characters resembling real people sometimes elicit cold, eerie feelings. This effect, called the uncanny valley, has been attributed to uncertainty about whether the character is human or living or real. Uncertainty, however, neither explains why anthropomorphic characters lie in the uncanny valley nor their characteristic eeriness. We propose that realism inconsistency causes anthropomorphic characters to appear unfamiliar, despite their physical similarity to real people, owing to perceptual narrowing. We further propose that their unfamiliar, fake appearance elicits cold, eerie feelings, motivating threat avoidance. In our experiment, 365 participants categorized and rated objects, animals, and humans whose realism was manipulated along consistencyreduced and control transitions. These data were used to quantify a Bayesian model of categorical perception. In hypothesis testing, we found reducing realism consistency did not make objects appear less familiar, but only animals and humans, thereby eliciting cold, eerie feelings. Next, structural equation models elucidated the relation among realism inconsistency (measured objectively in a twodimensional Morlet wavelet domain inspired by the primary visual cortex), realism, familiarity, eeriness, and warmth. The fact that reducing realism consistency only elicited cold, eerie feelings toward anthropomorphic characters, and only when it lessened familiarity, indicates the role of perceptual narrowing in the uncanny valley.","Anthropomorphism; Computer animation; Face perception; Familiarity; Gabor kernels; Perceptual narrowing; Threat avoidance","Bayes theorem; computer simulation; facial recognition; female; human; male; perception; physiology; uncertainty; vision; young adult; Bayes Theorem; Computer Simulation; Facial Recognition; Female; Humans; Male; Perceptual Masking; Uncertainty; Visual Perception; Young Adult",2-s2.0-84994030800
"Hong Y.-J., Nam G.P., Choi H., Cho J., Kim I.-J.","3-dimensional face from a single face image with various expressions",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978865106&doi=10.1007%2f978-3-319-39862-4_19&partnerID=40&md5=f7a67bd50bcafcdb8c3b148365d641ce","Generating a user-specific 3D face model is useful for a variety of applications, such as facial animation, games or movie industries. Recently, there have been spectacular developments in 3D sensors, however, accurately recovering the 3D shape model from a single image is a major challenge of computer vision and graphics. In this paper, we present a method that can not only acquire a 3D shape from only a single face image but also reconstruct facial expression. To accomplish this, a 3D face database with a variety of identities and facial expressions was restructured as a data array which was decomposed for the acquisition of bilinear models. With this model, we represent facial variances as two kinds of elements: expressions and identities. Then, target face image is fitted to 3D model while estimating its expression and shape parameters. As application example, we transferred expressions to reconstructed 3D models and naturally applied new facial expressions to show the efficiency of the proposed method. © Springer International Publishing Switzerland 2016.","3D face reconstruction; Bilinear models; Facial animation","Animation; Computer vision; Face recognition; Human computer interaction; 3-D face modeling; 3d face database; 3D face reconstruction; Application examples; Bilinear models; Facial animation; Facial Expressions; Shape parameters; Three dimensional computer graphics",2-s2.0-84978865106
"Zhai X., Hou F., Qin H., Hao A.","Inverse Modelling of Incompressible Gas Flow in Subspace",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965117666&doi=10.1111%2fcgf.12861&partnerID=40&md5=7e21341d6b1c63c298a6e2ccbdda8a30","This paper advocates a novel method for modelling physically realistic flow from captured incompressible gas sequence via modal analysis in frequency-constrained subspace. Our analytical tool is uniquely founded upon empirical mode decomposition (EMD) and modal reduction for fluids, which are seamlessly integrated towards a powerful, style-controllable flow modelling approach. We first extend EMD, which is capable of processing 1D time series but has shown inadequacies for 3D graphics earlier, to fit gas flows in 3D. Next, frequency components from EMD are adopted as candidate vectors for bases of modal reduction. The prerequisite parameters of the Navier-Stokes equations are then optimized to inversely model the physically realistic flow in the frequency-constrained subspace. The estimated parameters can be utilized for re-simulation, or be altered toward fluid editing. Our novel inverse-modelling technique produces real-time gas sequences after precomputation, and is convenient to couple with other methods for visual enhancement and/or special visual effects. We integrate our new modelling tool with a state-of-the-art fluid capturing approach, forming a complete pipeline from real-world fluid to flow re-simulation and editing for various graphics applications. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","EMD; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Animation; Model reduction; Parameter estimation","Computer graphics; Constrained optimization; Flow of gases; Inverse problems; Modal analysis; Parameter estimation; Signal processing; Three dimensional computer graphics; Vectors; Controllable flow; Empirical Mode Decomposition; Estimated parameter; Frequency components; Graphics applications; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Inverse modelling; Model reduction; Navier Stokes equations",2-s2.0-84965117666
"Cetinaslan O., Orvalho V.","Localized verlet integration framework for facial models",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978285995&doi=10.1007%2f978-3-319-41778-3_1&partnerID=40&md5=720868e3d7b88152c624b44c6f33f28e","Traditional Verlet integration frameworks have been successful with their robustness and efficiency to simulate deformable bodies ranging from simple cloth to geometrically complex solids. However, the existing frameworks deform the models as a whole. We present a Verlet integration framework which provides local surface deformation on the selected area of the mesh without giving any global deformation impact to the whole model. The framework is specifically designed for facial surfaces of the cartoon characters in computer animation. Our framework provides an interactive selection of the deformation influence area by using geodesic distance computation based on heat kernel. Additionally, the framework exploits the geometric constraints for stretching, shearing and bending to handle the environmental interactions such as collision. The proposed framework is robust and easy to implement since it is based on highly accurate geodesic distance computation and solving the projected geometric constraints. We demonstrate the benefits of our framework with the results obtained from various facial models to present its potential in terms of practicability and effectiveness. © Springer Science+Business Media Singapore 2016.","Deformable bodies; Facial animation; Geodesic distance; Mesh deformation; Physically-based animation","Animation; Geodesy; Mesh generation; Deformable bodies; Facial animation; Geodesic distances; Mesh deformation; Physically-based animation; Deformation",2-s2.0-84978285995
"Day T.D.","Why Simulation? An Interesting Case Study",2016,"SAE Technical Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017638036&doi=10.4271%2f2016-01-1484&partnerID=40&md5=cf8c4cae0b2990cac62247dc20375c3a","This paper presents an example application for vehicle dynamics simulation software. This example investigates the validity of the vehicle motion presented in the famous car chase scene from the 1968 movie Bullitt. In this car chase, a 1968 Ford Mustang, driven by Det. Frank Bullitt of the San Francisco Police Department, is chasing a criminal driving a 1968 Dodge Charger through the streets of the Russian Hill district of San Francisco. The purpose of the simulation was to reconstruct the chase scene to determine the level of realism in the movie, in terms of conformance to Newton's Laws of motion. To produce the simulation, several city blocks of the pertinent area of the city were surveyed and exemplar vehicles were measured and inspected. Three-dimensional computer models of the scene and vehicles were built. The movie footage was analyzed to determine vehicle speeds and driver inputs. The event was then simulated using three-dimensional vehicle dynamics simulation software. The results of the simulation confirmed the vehicles could not have navigated through the course at the speeds shown in the movie. It was determined that the vehicles' speeds in the movie were at least 20 percent faster than the actual speeds of the vehicles when they were driven down Russian Hill. The chase scene could be duplicated using animation software (as opposed to simulation software), but the vehicles' speeds in the animation would be 20 percent or more too high, and the error could go undetected. This example demonstrates an important benefit of simulation, which requires adherence to the laws of physics, in the analysis of vehicle dynamics presentations. This paper provides the details of the procedures and resulting simulations, as well as the basis for the above conclusions. © Copyright 2016 SAE International.",,"Animation; Application programs; Dynamics; Motion pictures; Speed; Vehicles; Animation softwares; Computer models; Laws of physics; Newton's laws of motion; Simulation software; Vehicle dynamics; Vehicle dynamics simulation; Vehicle motion; Computer software",2-s2.0-85017638036
"Dawood S., Hicks Y., Marshall D.","Speech-driven facial animation using manifold relevance determination",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996868047&doi=10.1007%2f978-3-319-48881-3_57&partnerID=40&md5=224b6f6fd5fee1c92b37a85e1ff2951d","In this paper, a new approach to visual speech synthesis using a joint probabilistic model is introduced, namely the Gaussian process latent variable model trimmed with manifold relevance determination model, which explicitly models coarticulation. One talking head dataset is processed (LIPS dataset) by extracting visual and audio features from the sequences. The model can capture the structure of data with extremely high dimensionality. Distinguishable visual features can be inferred directly from the trained model by sampling from the discovered latent points. Statistical evaluation of inferred visual features against ground truth data is obtained and compared with the current state-of-the-art visual speech synthesis approach. The quantitative results demonstrate that the proposed approach outperforms the stateof-the-art technique. © Springer International Publishing Switzerland 2016.",,"Principal component analysis; Speech synthesis; Gaussian Processes; High dimensionality; Joint probabilistic; Latent variable modeling; Quantitative result; State-of-the-art techniques; Statistical evaluation; Visual speech synthesis; Computer vision",2-s2.0-84996868047
"Drewes H.","Movengine—developing a movement language for 3D visualization and composition of dance",2016,"Springer Tracts in Advanced Robotics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948417664&doi=10.1007%2f978-3-319-25739-6_5&partnerID=40&md5=93ee2344b5c5b52c081834805e3faed1","MOVement-oriented animation Engine (MovEngine) is a software library, which was originally developed within a research project conducted at Salzburg University from 2008 until early 2013. One of the objectives in this project was to create a computer application which aids research in re-constructing dance through animated movement sequences, utilizing a movement language based on existing systems of movement notation. Since 2012 the software—in its current developmental stage—is being tested and integrated into movement notation studies at Folkwang University of the Arts in Essen and its development is continued within an MA course in Movement Notation/Movement Analysis at the university. The software allows to create a three-dimensional, animated representation of movement based on a variety of sources and facilitates the exploration of possible variations in the movement material. This new unique and methodologically highly potential technological tool provides the possibility to access referential material on dance and to transfer/translate the referentiality into visuality, thus revealing the motoric and kinetic aspects of the material. While the goal of the original project was focused on historic dance research, the employed technical approach may be also applied in a variety of other contexts, e. g. in creating learning tools, in automated animated visualization of movement notation scores or in generating robotic movement. MovEngine gains a high degree of flexibility by extending traditional key frame animation techniques with a system of movement orientated instructions, which are based on principles of movement analysis as known from systems of movement notation (Eshkol Wachman Movement Notation and Kinetography Laban). This paper outlines the key features of MovEngine by describing the role of movement notation principles in the generation of animated movement. © Springer International Publishing Switzerland 2016.",,"Animation; Computational linguistics; Curricula; Software testing; Visualization; Animation techniques; Degree of flexibility; Developmental stage; Movement analysis; Movement notation; Robotic movements; Software libraries; Technological tools; Three dimensional computer graphics",2-s2.0-84948417664
"Saha S., Halder S.","Virtual manipulation: An on-screen interactive visual design for science learning",2016,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959017288&doi=10.1007%2f978-81-322-2752-6_29&partnerID=40&md5=b46eedadb093a51b519d8bc5552b4e59","Interactivity in e-learning environment is an innovative approach in teaching-learning. Predominantly theoretical justification of interactive learning environment has been discussed on the basis of the process of visual and auditory information in the memory system emphasizing the result oriented perspective in the sense that they have given importance on computer response to learner action rather than learner activity and engagement in computer programming. However, by definition interactivity is described as ‘to act’. In this view point the present research attempts to explore the effectiveness of enactment by manipulating virtual features in interactive visualization when compared with visual animation. To investigate the effectiveness of different visual condition researchers have developed two different types of instructional module (interactive virtual manipulation and animated visual). Total 360 students have been selected to implement the study with different matching criteria. MANOVA is conducted to find out the group difference in different condition. Result showed a momentous mean difference in different condition i.e., in virtual manipulation (execution of action) condition where student perform virtually in the on-screen object better than animation (observed action) in respect to various learning outcome. Result is discussed critically from several theoretical focal points. © Springer India 2016.","E-learning; Enactment; Interactive design; Motor encoding; Multimedia learning; Virtual manipulation","Animation; Computer aided instruction; Computer programming; Computer systems programming; Computer vision; Design; Information systems; Learning systems; Systems analysis; Visualization; E-learning environment; Enactment; Innovative approaches; Interactive design; Interactive learning environment; Interactive visualizations; Multi-media learning; Virtual manipulation; E-learning",2-s2.0-84959017288
"Gao L., Chen S.-Y., Lai Y.-K., Xia S.","Data-Driven Shape Interpolation and Morphing Editing",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989225423&doi=10.1111%2fcgf.12991&partnerID=40&md5=92df7bff569e18ae948b6f455893c18a","Shape interpolation has many applications in computer graphics such as morphing for computer animation. In this paper, we propose a novel data-driven mesh interpolation method. We adapt patch-based linear rotational invariant coordinates to effectively represent deformations of models in a shape collection, and utilize this information to guide the synthesis of interpolated shapes. Unlike previous data-driven approaches, we use a rotation/translation invariant representation which defines the plausible deformations in a global continuous space. By effectively exploiting the knowledge in the shape space, our method produces realistic interpolation results at interactive rates, outperforming state-of-the-art methods for challenging cases. We further propose a novel approach to interactive editing of shape morphing according to the shape distribution. The user can explore the morphing path and select example models intuitively and adjust the path with simple interactions to edit the morphing sequences. This provides a useful tool to allow users to generate desired morphing with little effort. We demonstrate the effectiveness of our approach using various examples. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Data-driven; I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling-object representations; Morphing editing; Shape interpolation; Shape space","Animation; Computational geometry; Computer graphics; Deformation; Data driven; Morphing; Object modelling; Shape interpolation; Shape space; Interpolation",2-s2.0-84989225423
"Pokorný P., Mazáčová M.","A 3D visualization design and realization of otrokovice in the nineteen-thirties",2016,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964758535&doi=10.1007%2f978-3-319-33622-0_8&partnerID=40&md5=947767d9c6a8449742f789dbbd2a8195","This paper briefly describes a visualization method of the Otrokovice Municipality in the Nineteen-thirties. The rapid growth of this town began at the beginning of the 20th century, and in 1938, Otrokovice had around 8000 inhabitants. Many building plans, cadastral maps and historical photographs are preserved from this period. This is the reason why a rendering set in these years was created. All of the collected information was chronologically sorted, and on this basis, a 3D visualization of the Otrokovice town center was created. To begin with, a terrain model of Otrokovice was created, based on the altitude values published on the Internet. All buildings and accessories were separately modeled (the standard polygonal representation was used) and textured by the UV mapping technique. Then, a more complex 3D scene from the individual models and accessories was created. The visualization output is performed by rendered images and animations in these years. © Springer International Publishing Switzerland 2016.","3D visualization; Animation; Computer graphics; Modeling; Rendering; Texturing","Animation; Application programs; Computer graphics; Intelligent systems; Models; Rendering (computer graphics); Software engineering; Texturing; Visualization; 3D Visualization; Cadastral maps; Individual models; Polygonal representation; Rendered images; Rendering; Terrain Modeling; Visualization method; Three dimensional computer graphics",2-s2.0-84964758535
"Wan M., Li Y., Hu J.","Innovation and practice of teaching reform of college mathematics course under the background of information technology",2016,"RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001754612&partnerID=40&md5=5fc14fded42361399e9f66e756517f56","The integration of information technology and college mathematics curriculum is becoming a hot issue in information technology education. The application of modern information technology has led to the development of educational level, which has formed the core of the modern educational technology, such as multimedia, network and artificial intelligence. By using multimedia software in mathematics teaching, it could increase the intuitive, experimental, interesting, and reduce the difficulty of learning. The integration of information technology and mathematics curriculum can make full use of the advantages of modern information technology, and make computer technology as a teaching aid. Survey has proved that students are more likely to accept dynamic multimedia teaching, and multimedia teaching helps to improve mathematics teaching efficiency. © AISTI 2016.","Animation music; Computer multimedia; Interactive creation; Sequencer software","Artificial intelligence; Computer music; Curricula; Education; Computer multimedias; Information technology education; Interactive creation; Mathematics curricula; Mathematics teachings; Modern educational technologies; Modern information technologies; Practice of teachings; Teaching",2-s2.0-85001754612
"Zhang J., Kan M., Shan S., Chen X.","Occlusion-free face alignment: Deep Regression Networks coupled with de-corrupt autoencoders",2016,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986292815&partnerID=40&md5=3682661d73091899016cca03610193ab","Face alignment or facial landmark detection plays an important role in many computer vision applications, e.g., face recognition, facial expression recognition, face animation, etc. However, the performance of face alignment system degenerates severely when occlusions occur. In this work, we propose a novel face alignment method, which cascades several Deep Regression networks coupled with De-corrupt Autoencoders (denoted as DRDA) to explicitly handle partial occlusion problem. Different from the previous works that can only detect occlusions and discard the occluded parts, our proposed de-corrupt autoencoder network can automatically recover the genuine appearance for the occluded parts and the recovered parts can be leveraged together with those non-occluded parts for more accurate alignment. By coupling de-corrupt autoencoders with deep regression networks, a deep alignment model robust to partial occlusions is achieved. Besides, our method can localize occluded regions rather than merely predict whether the landmarks are occluded. Experiments on two challenging occluded face datasets demonstrate that our method significantly outperforms the state-of-the-art methods.",,"Alignment; Computer vision; Learning systems; Pattern recognition; Regression analysis; Computer vision applications; Face alignment; Face animation; Facial expression recognition; Facial landmark detection; Occlusion-free; Partial occlusions; State-of-the-art methods; Face recognition",2-s2.0-84986292815
"Lorenz M., Spranger M., Riedel T., Pürzel F., Wittstock V., Klimant P.","CAD to VR-A Methodology for the Automated Conversion of Kinematic CAD Models to Virtual Reality",2016,"Procedia CIRP",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968808312&doi=10.1016%2fj.procir.2015.12.115&partnerID=40&md5=9456ffeb9729779b36bbf24b9a661a9b","Driven by the challenges of Industry 4.0 seamless data integration and conversion becomes an even more pressing topic than it already has been in the past. In this context virtual technologies such as Virtual Reality (VR) and Augmented Reality (AR) will play a defining role when it comes down to speed up the development process of new products, factory planning and supporting the workforce with novel intelligent assistance systems to keep up with the faster growing product diversity, especially in the face of the demographic challenge. The key enabling technology to foster this development is the seamless and automated integration of all product data defined in the CAD systems into VR/AR systems. Currently, there is still a major gap in this data integration when more than just plain geometry should be transferred, especially outside of the software ecosphere of a CAD system provider. Considerable effort by VR experts has to be put in to reduce the use case specific complexity of models and to rebuild the already in the CAD system defined kinematic mechanisms and animation. Whilst these obstacles were hindering SMEs in the past to participate of the benefits that virtual technologies provide, this cannot be afforded any longer. In this paper we will outline a CAD and VR system independent workflow for an automated model complexity reduction, animation and kinematic mechanism adoption. We do this by defining light weighted system interfaces and showing solution concepts for each area of the conversion problem. Finally, we verify the presented method on a proof of concept implementation. © 2016 The Authors.","Computer aided design (CAD); Engineering; Kinematic model; Virtual reality","Animation; Augmented reality; Automation; Data handling; Data integration; Engineering; Industrial research; Kinematics; Manufacture; Virtual reality; Automated modeling; Development process; Enabling technologies; Intelligent assistances; Kinematic mechanism; Kinematic model; Solution concepts; Virtual technology; Computer aided design",2-s2.0-84968808312
"Cortés-Dávalos A., Mendoza S.","Augmented reality-based groupware for editing 3D surfaces on mobile devices",2016,"Proceedings - 2016 International Conference on Collaboration Technologies and Systems, CTS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016991317&doi=10.1109%2fCTS.2016.63&partnerID=40&md5=3f0a980550ea420edc8c26b2513d81b6","In this paper, we propose a novel groupware that uses Augmented Reality (AR) technology to facilitate the task of collaboratively editing 3D surfaces on mobile devices. In digital animations and video games, 3D surfaces are widely employed to model geometric assets, e.g., mountains on a landscape. However, even if a single surface commonly needs to be created and modified by a group of collaborators, most of the 3D content creation applications are essentially single-user. In addition, 3D surfaces are visualized in 2D projections, causing confusion to new users when imagining their shape in 3D. In our proposal, we use AR technology to help collaborators to easily understand the shape of the surface's 3D representation, and we provide them with the basic editing tools to intuitively modify its shape. In this way, the proposed groupware is able to support a new collaborative setting in which a group of collocated participants, each one using a mobile device, can concurrently modify a surface, while visualizing it in their own real environment by means of AR In order to support synchronous face-to-face collaboration, we implement an object sharing scheme, which is enough in practice according to the results obtained from tests conducted with groups of collaborators. © 2016 IEEE.","3D surfaces editing; Augmented reality-based groupware; Object sharing scheme; Synchronous face to face collaboration","Animation; Augmented reality; Computer software; Groupware; Mobile devices; 2D projections; 3d representations; 3D surface; Collaborative settings; Editing tools; Face to face; Real environments; Sharing schemes; Three dimensional computer graphics",2-s2.0-85016991317
"Krings S., Leuschel M.","SMT solvers for validation of B and Event-B models",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977527654&doi=10.1007%2f978-3-319-33693-0_23&partnerID=40&md5=4cf826772539c037da894cdac7ecc69d","We present an integration of the constraint solving kernel of the ProB model checker with the SMT solver Z3.We apply the combined solver to B and Event-B predicates, featuring higher-order datatypes and constructs like set comprehensions. To do so we rely on the finite set logic of Z3 and provide a new translation from B to Z3, better suited for constraint solving. Predicates can then be solved by the two solvers working hand in hand: constraints are set up in both solvers simultaneously and (intermediate) results are transferred. We thus combine a constraint logic programming based solver with a DPLL(T) based solver into a single procedure. The improved constraint solver finds application in many validation tasks, from animation of implicit specifications, to test case generation, bounded and symbolic model checking on to disproving of proof obligations. We conclude with an empirical evaluation of our approach focusing on two dimensions: comparing low and high-level encodings of B as well as comparing pure ProB to ProB combined with Z3. © The Author(s) 2016.","Animation; B-Method; Event-B; SMT","Animation; Codes (symbols); Computer circuits; Computer programming languages; Formal methods; Logic programming; Reconfigurable hardware; Surface mount technology; B method; Constraint Logic Programming; Constraint solvers; Empirical evaluations; Event-B; Higher-order datatypes; Symbolic model checking; Test case generation; Model checking",2-s2.0-84977527654
"Zarrad A.","A Dynamic Platform for Developing 3D Facial Avatars in a Networked Virtual Environment",2016,"International Journal of Computer Games Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960984270&doi=10.1155%2f2016%2f8489278&partnerID=40&md5=47cb1a131ed2fd827d62dfb9a9cb65d0","Avatar facial expression and animation in 3D collaborative virtual environment (CVE) systems are reconstructed through a complex manipulation of muscles, bones, and wrinkles in 3D space. The need for a fast and easy reconstruction approach has emerged in the recent years due to its application in various domains: 3D disaster management, virtual shopping, and military training. In this work we proposed a new script language based on atomic parametric action to easily produce real-time facial animation. To minimize use of the game engine, we introduced script-based component where the user introduces simple short script fragments to feed the engine with a new animation on the fly. During runtime, when an embedded animation is required, an xml file is created and injected into the game engine without stopping or restarting the engine. The resulting animation method preserves the real-time performance because the modification occurs not through the modification of the 3D code that describes the CVE and its objects but rather through modification of the action scenario that rules when an animation happens or might happen in that specific situation. © 2016 Anis Zarrad.",,"Disaster prevention; Disasters; Three dimensional computer graphics; Virtual reality; 3D collaborative virtual environments; Action scenarios; Disaster management; Facial Expressions; Military training; Networked virtual environments; Real time performance; Virtual shopping; Animation",2-s2.0-84960984270
"Parikesit G.O.F.","Digital 3D Wayang Kulit images",2016,"International Journal of Arts and Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021296680&doi=10.1504%2fIJART.2016.081333&partnerID=40&md5=fb540943c0955b53fdf40b4d924f374c","Recently, several shadow puppetry artists and engineers have developed optical methods to stereoscopically display shadow images in three dimensions. In this paper we report the application of digital image synthesis to mimic the stereoscopic shadow images, particularly the images relevant to the UNESCO-listed art of Wayang Kulit from Indonesia. The digital images are synthesised by computing the coloured shadow images that the puppets would cast on the screen, while the animation is done by computing the motion of the images under puppet translation and rotation. The resulting digital images can be used in virtual shadow puppetry or in computer animated games involving 3D Wayang Kulit scenes. Copyright © 2016 Inderscience Enterprises Ltd.","Digital image synthesis; Stereoscopic shadow images; Wayang Kulit puppetry","Animation; Computer games; Stereo image processing; Animated games; Digital image; Optical methods; Shadow images; Shadow puppetries; Synthesised; Three dimensions; Wayang Kulit puppetry; Image processing",2-s2.0-85021296680
"Li Y.-H., Hu Y.-T., Shen J., Preda M., Drexler A., Sosoiu C., Stanculescu D.F., Liu P., Ye J.","Ultrafast facial tracker using generic cameras with applications in intelligent lifestyle",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978882387&doi=10.1007%2f978-3-319-39907-2_23&partnerID=40&md5=80dfa841e77a0b692c79d74148e26ae3","The core of Human-Computer Interaction (HCI) is to analyze and understand the user’s intension, which can be mostly manifested from the facial movement and expression of the user. Hence, the stage facial detection and tracking is extremely important in an user-friendly interface between human and computer. In ULSee, we developed an ultrafast markerless facial tracking system which is robust to variation in environmental lighting, pose and occlusion. It can be run at a speed of 10 ms/frame on an iPhone 6S system. With such accuracy and speed, it can be used to support many intelligent HCI applications. In this work, we envision an intelligent lifestyle in the future that can be built upon the basis of the ULSee’s ultrafast markerless facial tracker, ranging from virtual reality, augmented reality, real-time facial recognition and driver drowsiness detection. We believe, that through the joint force between ULSee’s world-class tracker and our clients, more user-awareness HCI application will be invented and a new lifestyle will arise. © Springer International Publishing Switzerland 2016.","Driver; Drowsiness detection; Facial recognition; Markerless facial tracking; Real-time avatar animation","Augmented reality; Face recognition; Interactive computer graphics; Virtual reality; Driver; Drowsiness detection; Facial recognition; Facial tracking; Real time; Human computer interaction",2-s2.0-84978882387
"Lin E.C.-H.","A research on multi-dimensional multi-attribute string matching mechanism for 3D motion databases",2016,"Lecture Notes in Electrical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007545170&doi=10.1007%2f978-981-10-0539-8_57&partnerID=40&md5=20557c17da8ff9845d04681b4ffb1392","Due to the development of computer technology and the mature development of 3D motion capture technology, the applications of 3D motion databases become more and more important. How to analysis the huge data stored in the database and efficiently retrieved the matched data is an important research issue. 3D animation design is one of the important applications of 3D motion databases. Based on our teaching experience, the bottleneck of the students' learning of 3D animation is the motion animation of the 3D characters. Therefore, the 3D motion database can be used to assist the design of the motion for 3D characters. However, it is still a difficult problem because of the high complexity of the matching mechanism and the difficult of user interface design. In this paper, the 3D motion data can be represented as multi-dimensional multi-attribute sequences while the corresponding index structures and query processing mechanism are proposed for efficiently processing the 3D motion queries. Moreover, Microsoft Kinect is used in this project as the user interface. The captured data can be used as the user query and the further comparison will be performed to find the matched motion data. © Springer Science+Business Media Singapore 2016.","3D motion database; Index structure; Kinect; Query processing","Animation; Database systems; Query processing; 3D motion; Computer technology; Index structure; Kinect; Matching mechanisms; Multi dimensional; Teaching experience; User interface designs; User interfaces",2-s2.0-85007545170
"Ban Y., Sun H.-Y., Wang X.-N., Li M.-J.","Research and application of emergency plan in dynamic evolvement simulation system based on Gis",2016,"International Journal of Simulation: Systems, Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006166561&doi=10.5013%2fIJSSST.a.17.43.04&partnerID=40&md5=c9ffac6d3ec1011a5300e31193aef6b9","In order to satisfy the requirement of visual emergency plan compilation and revision, a new method plotting elements integrated with animation is presented based on static structure model and spatiotemporal data model. Emergency plan can be compiled by coordinating consultation and deduced cross-platform. Symbol library and animations are designed. Furthermore, plotting elements can be added remarks, video and audio, and remarks can be converted into audio. The system is developed and a case is provided to prove the methods of being scientific, rational and effective. © 2016, UK Simulation Society. All rights reserved.","Animation; Consultation; Deduction; Situation plotting; Spatiotemporal data model","Computer simulation; Consultation; Deduction; Emergency plans; nocv1; Research and application; Simulation systems; Situation plotting; Spatio-temporal data modeling; Static structures; Animation",2-s2.0-85006166561
"Izdebski Ł., Sawicki D.","Easing functions in the new form based on Bézier curves",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989934370&doi=10.1007%2f978-3-319-46418-3_4&partnerID=40&md5=d5d88b7ce69a90013470336b6a9022c2","The transition problem is one of the important problems of animation. The Penners easing functions solve this successfully. There are some well known and widely used approximations of these functions where Bézier curves have been used. However, the transition functions, obtained by such approximation differ substantially from the original. We proposed new form of approximation in the paper. Two class of easing functions are discussed. In first simple approximation allows obtaining sufficient effects. In the second the easing function is divided into two symmetric parts where the approximation is done. For every approximation the root mean square error (RMSE) has been determined and the animated transition using new solution is analyzed. The new approximation allows obtaining better RMSE as well as better visual effects in animation. © Springer International Publishing AG 2016.","CSS; Easing function; Keyframing; Transition; Tweening function","Animation; Computer vision; Animated transitions; Keyframing; New forms; Root mean square errors; Transition; Transition functions; Transition problems; Visual effects; Mean square error",2-s2.0-84989934370
"Song H., Neff M.","A parameterized schema for representing complex gesture forms",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994504542&doi=10.1007%2f978-3-319-47665-0_48&partnerID=40&md5=db1abbf2848d3b7061ae3bc827e251d1","Gestures can take on complex forms that convey both pragmatic and expressive information. When creating virtual agents, it is necessary to make fine grained manipulations of these forms to precisely adjust the gesture’s meaning to reflect the communicative content an agent is trying to deliver, character mood and spatial arrangement of the characters and objects. This paper describes a gesture schema that affords the required, rich description of gesture form. Novel features include the representation of multiphase gestures consisting of several segments, repetitions of gesture form, a map of referential locations and a rich set of spatial and orientation constraints. In our prototype implementation, gestures are generated from this representation by editing and combining small snippets of motion captured data to meet the specification. This allows a very diverse set of gestures to be generated from a small set of input data. Gestures can be refined by simply adjusting the parameters of the schema. © Springer International Publishing AG 2016.","Animation frameworks; Behavior planning; Composite gesture representation; Generation; Language; Virtual agent","Artificial intelligence; Computer science; Computers; Behavior planning; Generation; Gesture representations; Language; Virtual agent; Intelligent virtual agents",2-s2.0-84994504542
"Grahovac M., Chang Y., Wang S., Xu Y., Wang J., Bliss B., Edwards K., Landau K., Zhou C.","Development of the interactive steel manufacturing visualization application",2016,"AISTech - Iron and Steel Technology Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980050609&partnerID=40&md5=58708ce988f8604b28ce8b602d8cf9e7","Steel making involves many complicated processes. It was not easy to understand the entire process and all of the complicated equipment involved to produce a single steel product. To improve the understanding of how steel is made, the Association for Iron and Steel Technology (AIST) created a project referred to as the ""Steel Wheel."" AIST's goal was to make available on its website sets of 3Dimensional models and animations to demonstrate the processes of steel making as an effective method of virtual training. The basis of the many different processes would be the image created by AIST called ""The Making, Shaping and Treating of Steel Wheel."" The aim of the project was to provide a simple and direct way to show the processes and make them easier to understand. With 3D models and animations, people without any professional steel industry background could understand what the equipment looks like and how it works. A software called Autodesk 3DS Max® was used to create the models. Once the models and animations were finished, they were made available on AIST's website to show the many processes of steelmaking. © 2016 by AIST.","3D modeling; Animation; Steel manufacturing; Virtual training; Visualization; Web design","Animation; E-learning; Flow visualization; Gears; Iron; Manufacture; Three dimensional computer graphics; Visualization; Web Design; Websites; Wheels; 3-d modeling; 3Dimensional models; Association for iron and steel technologies; Single steel; Steel manufacturing; Steel wheels; Virtual training; Visualization application; Steelmaking",2-s2.0-84980050609
"Ahmadi R., Hili N., Jweda L., Das N., Ganesan S., Dingel J.","Run-time monitoring of a Rover: MDE research with open source software and low-cost hardware",2016,"CEUR Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019610792&partnerID=40&md5=d5739cb64367b79ca7fb75abc725af5f","This paper is an experience report on how we conducted research in run-time model monitoring with Open Source Software (OSS) and low-cost hardware. We demonstrate our experience using a Rover system case study, where we modelled its control logic, generated code, and collected traces of the running code to visually monitor the execution. We used open source tools throughout the project: Papyrus-RT for modeling and animation, LTTng for collecting execution traces, and Trace Compass for parsing the collected traces. Copyright © 2016 held by the author(s).","Model driven engineering; Open source tools; Real-Time; Run-time monitoring","Computer software; Education; Embedded systems; Engineering education; Hardware; Open systems; Software engineering; Execution trace; Experience report; Low cost hardware; Model-driven Engineering; Modeling and animation; Open source tools; Real time; Runtime Monitoring; Open source software",2-s2.0-85019610792
"Fernandez-Cervantes V., Stroulia E., Hunter B.","A grammar-based framework for rehabilitation exergames",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990026557&doi=10.1007%2f978-3-319-46100-7_4&partnerID=40&md5=e053f8e7a3b68b3796ef397473a86ddf","Numerous serious exergames advocate the use of engaging avatars to motivate a consistent exercise regimen. However, the process of specifying the prescribed exercise, implementing it as avatar animation, and developing an accurate feedback-providing mechanism is complex and requires a high level of expertise in game engines, control languages, and hardware devices. Furthermore, in the context of rehabilitation exergames, the requirements for accurate assessment and timely and precise feedback can be quite stringent. At the same time, the Kinect™ motion-capture sensor offers a natural interface to game consoles, and its affordability and wide availability represents a huge opportunity for at-home exergames. In this paper, we describe our work towards a system that envisions to simplify the process of developing rehabilitation exergames with Kinect™. The system relies on a language for specifying postures and movements between them, and includes an editor that enables rehabilitation therapists to specify the prescribed exercise, by editing a demonstration of the exercise. This exercise-specification grammar is used to drive the animation of an avatar and the provision of quality feedback, by comparing the player’s postures (as captured by the Kinect™) against those of the coaching avatar and the grammar. © IFIP International Federation for Information Processing 2016.","Interface; Kinect-based gameplay; Rehabilitation; Serious games","Feedback; High level languages; Interactive computer graphics; Interfaces (materials); Patient rehabilitation; Game consoles; Game Engine; Gameplay; Hardware devices; Motion capture; Natural interfaces; Quality feedbacks; Serious games; Animation",2-s2.0-84990026557
"Webery C., Stammingerz M.","Topological triangle sorting for predefined camera paths",2016,"VMV 2016 - Vision, Modeling and Visualization",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019642251&doi=10.2312%2fvmv.20161354&partnerID=40&md5=afa07afdce59956b5d26b55affb550b0","We present a preprocessing pipeline for triangle meshes that topologically sorts all triangles for a given camera and scene animation in front-to-back or back-to-front order. This allows us to efficiently render a given animation without depth buffer, and to include transparency. We also remove non-contributing triangles, thus improving render time, especially when applying anti-aliasing. To this end we first record the visible triangles of a sequence of frames. For every frame we create a directed graph storing occlusion information. After a topological sort of this graph, all triangles are sorted properly. The contribution of this paper is the reduction of redundancy by merging the graphs of all frames. The result of our pipeline is a single sorted index buffer, over which we slide a window that yields sorted index buffers for each single frame. Circular dependencies are broken by placing duplicates of the affected triangles in the index buffer. Our sliding window then displays only frame specific triangles in their proper order. We conclude by demonstrating the benefits of removing invisible triangles and disabling the hardware visibility test. © 2016 The Author(s) Eurographics Proceedings © 2016 The Eurographics Association.",,"Animation; Anti-aliasing; Cameras; Directed graphs; Pipelines; Rendering (computer graphics); Visualization; Depth buffer; Reduction of redundancy; Single frames; Sliding Window; Topological sort; Triangle mesh; Topology",2-s2.0-85019642251
"Șorlei I.S., Cernat A.E., Rizescu C.I., Rizescu D.","The study of slider crank mechanism using MATLAB and SCILAB",2016,"Romanian Review Precision Mechanics, Optics and Mechatronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006007907&partnerID=40&md5=0a1c9a9139f4f46fe40c692ec377bd40","The study presents a comparison between a graphic simulation of a slider crank mechanism developed both in Matlab and Scilab environments. Also some remarks, concerning the software’s efficiency and an economic analysis efficiency-cost of the two software, are presented in this study which have an identical use/purpose. Mainly, the idea of materialization of such a work has come out of necessity of programs usage that imply low purchase costs. From the point the view of acquisition, SCILAB is a free software through the licence CeCIILL (CEA CNRS INRIA Logiciel Libre). Both programs, MATLAB and SCILAB, can achieve certain accounts, can employ matrix and implement utility programs the difference between them are the used functions, because some of them don't match. MATLAB is a broader program from the point of view of functions against SCILAB, but from the point of view of cost software SCILAB is the advantageous solution. Using SCILAB software in achieving performance and make an animation of the sliding crank mechanism, it was noticed that the only differences between this program and MATLAB are certain functions with different syntaxes. In the present study it stands out in particular that both software are similar in terms of programming language and interface. Each environment has advantages and disadvantages and their use is identical in terms of performances compared to results. Considering that SCILAB environment uses a particular programming language MATLAB is much used in industry and academia worldwide. The study of present paper can be enhanced with new researches concerning the description and functionality of the programs as well as the presentation and improvement of the toolbox sites belonging SCILAB program, in order to achieve more complex animation in terms of the movement mechanisms. © 2016, Editura Cefin. All Rights Reserved.","Leverage; MATLAB; SCILAB; Simulation; Slider crank mechanism","Animation; Computer programming languages; Cost benefit analysis; Costs; Economic analysis; Efficiency; Crank mechanism; Graphic simulation; Leverage; Movement mechanism; Purchase cost; SCILAB; Simulation; Slider-crank mechanism; MATLAB",2-s2.0-85006007907
"Ranaweera R., Cohen M.","Gestural interface for conducting virtual concerts",2016,"IEEJ Transactions on Electronics, Information and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997078157&doi=10.1541%2fieejeiss.136.1567&partnerID=40&md5=f61c4ec5d33afc29af81e4857da84412","We have created a mixed reality concert application using Alice, a 3d rapid prototyping programming environment, in which musical instruments are arranged around a virtual conductor (in this case the user) located at their center. A user-conductor can use a smartphone as a simplified baton, pointing at a preferred instrument and tapping a button to start playing. The volume and panning of a selected instrument can be adjusted by simply tilting and rolling the smartphone. When selected, an instrument is jiggled or its components dilated and contracted, and a spotlight illuminates it until the instrument is muted, providing conductor and audience with visual cues about the ensemble. Unlike other systems, ours does not require user or equipment to be placed at specific locations (contrasted with Kinect, Wii sensors, or camera-based tracking systems), and there is no issue regarding room lighting (such as digital camera-based tracking systems or Kinect), nor interference with other players or obstacles. The goal of using different equipment as a conductor's baton is to allow nonexpert users to lead a realtime concert within a cyberworld. Synchronization of gestures with music and animation has been one of the biggest challenges in many systems we surveyed, although ours showed only minimal delays. We compared user experience with a contemporary commercial game, receiving acceptable ratings from the participants. © 2016 The Institute of Electrical Engineers of Japan.","Animation; Computer music; Gesture interpretation; Mixed reality","Computer music; Signal encoding; Smartphones; Software prototyping; Tracking (position); Virtual reality; Different equipment; Gestural interfaces; Gesture interpretation; Mixed reality; Programming environment; Specific location; Tracking system; User experience; Animation",2-s2.0-84997078157
"Wressnegger C., Yamaguchi F., Arp D., Rieck K.","Comprehensive analysis and detection of flash-based malware",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979226369&doi=10.1007%2f978-3-319-40667-1_6&partnerID=40&md5=4222ec2200ba98297f944b7c99e2041d","Adobe Flash is a popular platform for providing dynamic and multimedia content on web pages. Despite being declared dead for years, Flash is still deployed on millions of devices. Unfortunately, the Adobe Flash Player increasingly suffers from vulnerabilities, and attacks using Flash-based malware regularly put users at risk of being remotely attacked. As a remedy, we present Gordon, a method for the comprehensive analysis and detection of Flash-based malware. By analyzing Flash animations at different levels during the interpreter’s loading and execution process, our method is able to spot attacks against the Flash Player as well as malicious functionality embedded in ActionScript code. To achieve this goal, Gordon combines a structural analysis of the container format with guided execution of the contained code, a novel analysis strategy that manipulates the control flow to maximize the coverage of indicative code regions. In an empirical evaluation with 26,600 Flash samples collected over 12 consecutive weeks, Gordon significantly outperforms related approaches when applied to samples shortly after their first occurrence in the wild, demonstrating its ability to provide timely protection for end users. © Springer International Publishing Switzerland 2016.","Adobe flash; Classification; Malware","Classification (of information); Codes (symbols); Computer crime; Websites; Adobe flash; Analysis strategies; Comprehensive analysis; Empirical evaluations; Execution process; Flash animations; Multimedia contents; Popular platform; Malware",2-s2.0-84979226369
"Yeh M.-L., Liu Y.-Q., Lin P.-H.","Design and application of the illustrations of Zhuangzi",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978924482&doi=10.1007%2f978-3-319-40093-8_40&partnerID=40&md5=9be1e59a350197cb84622eb474c68e97","Zhuangzi is a Chinese cultural treasure. Zhuangzi is of inestimable value due to its preservation of ancient mythological material, its literary and philosophical innovation, its eccentric imagery and rich creativity, and the strong narrative quality of its many allegories. It was often the subject of illustrations in classical works. Efforts to preserve the messages of Zhuangzi, to transform its abstract ideas into tangible forms as illustrations, and to excavate its treasures have proven to be a great struggle. The present study uses the notion of “Poetic techniques of shape-spirit transformation” proposed by Yeh et al. (2011) as its primary reference point. In her theory of the form and essence of traditional Chinese paintings, she first takes inventory to conduct a comparative analysis of modern illustrations derived from Zhuangzi, and then advances a further step toward creating a design model for transforming the artistry of Zhuangzi into illustrations. © Springer International Publishing Switzerland 2016.","Animation; Application; Illustrations; Transformation; Zhuangzi","Animation; Applications; Design; Philosophical aspects; Comparative analysis; Design and application; Design modeling; Illustrations; Reference points; Traditional Chinese painting; Transformation; Zhuangzi; Human computer interaction",2-s2.0-84978924482
"Moreland J., Zaraliakos J., Wu B., Wang J., Guo J., Feng Z., Zhou M., Block M., Zhou C.","Interactive training for fall protection and crane safety",2016,"AISTech - Iron and Steel Technology Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980390917&partnerID=40&md5=bfd491fd4a291e00a1b9698d42f6a716","Ironmaking and steelmaking are hazardous processes. Fall protection is an area of safety that requires thorough understanding of the hazard and safety equipment. Selecting incorrect or damaged fall protection equipment, or choosing incorrect anchor points can result in fatality. A web-based interactive 3D simulator is being created to provide an engaging experience for trainees to accompany more traditional training materials. The simulator gives the trainee a welding task at height, and they must select and inspect proper equipment, and select proper anchor points on a man lift and at the location of the work. Unsafe choices in the simulator result in the trainee""s avatar being subjected to a fall, resulting in injury or death. The project is also modifying a related simulator that was previously developed for Crane Safety. AISTech 2016 Proceedings. © 2016 by AIST.","3D; Animation; Hazard; Safety; Simulation; Training; Visualization","Accident prevention; Animation; Cranes; Equipment; Flow visualization; Hazards; Simulators; Three dimensional computer graphics; Anchor point; Fall protection; Hazardous process; Interactive training; Safety equipments; Simulation; Training material; Welding tasks; Personnel training",2-s2.0-84980390917
"Pohl M., Endl H., Fels U.","Animated scatterplot - Analysis of time- Oriented data of diabetes patients",2016,"Studies in Health Technology and Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971597307&doi=10.3233%2f978-1-61499-645-3-191&partnerID=40&md5=fd3200a7fcde7a677d256d4ae3f708f2","Animated scatterplot visualizations promise to be useful tools for analyzing trends in time-oriented data. We evaluated such a visualization for the analysis of time-oriented medical data. We found 10 medical professionals to test the software which visualizes clinical diabetes patient cohorts. To analyze the usability of the software, the methods ""Thinking Aloud"" and structured interviews were used. Results show that animated scatterplots do support medical professionals in their daily work, in contrast to more negative results of scientific research in the past. © 2016 The authors and IOS Press.","Animation; Evaluation; Information visualization; Medical data; Time; Time-oriented data","clinical study; computer program; diabetic patient; human; structured interview; thinking",2-s2.0-84971597307
"Alduán I., Tena A., Otaduy M.A.","DYVERSO: A Versatile Multi-Phase Position-Based Fluids Solution for VFX",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986000593&doi=10.1111%2fcgf.12992&partnerID=40&md5=15f908af156cd53399b4c2ef2d7260b4","Many impressive fluid simulation methods have been presented in research papers before. These papers typically focus on demonstrating particular innovative features, but they do not meet in a comprehensive manner the production demands of actual VFX pipelines. VFX artists seek methods that are flexible, efficient, robust and scalable, and these goals often conflict with each other. In this paper, we present a multi-phase particle-based fluid simulation framework, based on the well-known Position-Based Fluids (PBF) method, designed to address VFX production demands. Our simulation framework handles multi-phase interactions robustly thanks to a modified constraint formulation for density contrast PBF. And, it also supports the interaction of fluids sampled at different resolutions. We put special care on data structure design and implementation details. Our framework highlights cache-efficient GPU-friendly data structures, an improved spatial voxelization technique based on Z-index sorting, tuned-up simulation algorithms and two-way-coupled collision handling based on VDB fields. Altogether, our fluid simulation framework empowers artists with the efficiency, scalability and versatility needed for simulating very diverse scenes and effects. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Animation; Fluid modelling","Animation; Computer graphics; Collision handling; Data structure design; Different resolutions; Fluid modelling; Fluid simulations; Phase interactions; Simulation algorithms; Simulation framework; Data structures",2-s2.0-84986000593
"Katayama N., Takatsu R., Inoue T., Shigeno H., Okada K.-I.","Efficient generation of conductor avatars for the concert by multiple virtual conductors",2016,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988493709&doi=10.1007%2f978-981-10-2618-8_4&partnerID=40&md5=cf678ab55c261c35fee8524253b77d42","In orchestra performance, a single conductor directs all the players in the real world. However no restriction is applied when designing a virtual conductor in the virtual world. Thus a virtual conductor system that employed multiple virtual conductors has been proposed. The system assigns each virtual conductor to each musical instrument part, making players’ performance better and more easier. Generation of the multiple conductor avatars is, however, still an issue of the system. It needs much time and work. In this paper, we propose a efficient virtual-conductor-avatar generation system. The time needed is surprisingly reduced while keeping the quality of the virtual-conductor avatars. © Springer Science+Business Media Singapore 2016.","Generating animation; Individualize; Supporting musical performance; Virtual conductor","Virtual reality; Conductor systems; Generation systems; Individualize; Musical performance; Real-world; Virtual conductor; Virtual worlds; Interactive computer graphics",2-s2.0-84988493709
"Bruneau J., Pettré J.","EACS: Effective Avoidance Combination Strategy",2016,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989350575&doi=10.1111%2fcgf.13066&partnerID=40&md5=9ef1f7e6542a48f6d4ea54b1aed0e29c","When navigating in crowds, humans are able to move efficiently between people. They look ahead to know which path would reduce the complexity of their interactions with others. Current navigation systems for virtual agents consider long-term planning to find a path in the static environment and short-term reactions to avoid collisions with close obstacles. Recently some mid-term considerations have been added to avoid high density areas. However, there is no mid-term planning among static and dynamic obstacles that would enable the agent to look ahead and avoid difficult paths or find easy ones as humans do. In this paper, we present a system for such mid-term planning. This system is added to the navigation process between pathfinding and local avoidance to improve the navigation of virtual agents. We show the capacities of such a system using several case studies. Finally we use an energy criterion to compare trajectories computed with and without the mid-term planning. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Animation; Human simulation","Animation; Computer graphics; Case-studies; Combination strategies; Energy criterion; Human simulation; Long term planning; Static and dynamic obstacles; Static environment; Virtual agent; Navigation systems",2-s2.0-84989350575
"Shi S.","Computer english teaching model based on multimedia platform",2016,"International Journal of Emerging Technologies in Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990175192&doi=10.3991%2fijet.v11i08.6050&partnerID=40&md5=ffad63bb0b1b20a4dac4cb58b803c863","Currently, multimedia-assisted foreign language teaching is a topic of high interest in the field of foreign language teaching. The combination between multimedia and foreign language teaching enables the teaching activity to integrate functions, such as words, phrases, sounds, images, figures and animations which can arouse and stimulate the students' enthusiasm and initiative as well as improve the teaching efficiency. However, the insufficient study of current foreign language teaching on both of the theories and practices of the multimedia-assisted foreign language teaching results in an unsatisfactory outcome of the multimedia- assisted teaching utilized by many foreign language teachers in middle school. Based on the knowledge and analysis of the status quo of the multimedia-assisted foreign language teaching and its design, this paper systematically discusses its contents of listening, speaking, reading and writing as well as its design, aiming at promoting teachers to spontaneously use the multimedia in the foreign language teaching, taking the maximum advantage of the multimediaassisted teaching.","computer English teaching; Multimedia platform; System development; Teaching method","English teaching; Foreign language teaching; Multimedia assisted teachings; Multimedia platforms; System development; Teaching activities; Teaching efficiencies; Teaching methods; Teaching",2-s2.0-84990175192
"Yüzen A., Karamete A.","Computer assisted educational material preparation for fourth grade primary school students' english language class in teaching numbers",2016,"European Journal of Contemporary Education",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008204032&doi=10.13187%2fejced.2016.15.94&partnerID=40&md5=e0aa4386f7ab6357f434a950f545d1ac","In this study, using ADDIE instructional design model, it is aimed to prepare English language educational material for 4th grade primary students to teach them numbers. At the same time, ARCS model of motivation's attention, relevance and satisfaction phases are also taken into consideration. This study also comprises of Design Based Research which includes design, theory and application processes. The first phase of the ADDIE method is the analysis where there is a discussion with primary school English language teachers so as to determine the topic, the content and the target groups. During the design phase; objectives, strategies, activities, assessments, and methods of learning are determined to organize and present the content on the basis of learning objectives. In the development phase; images, animations and user interface are created in accordance with students' ages. Additionally, sounds including the pronunciation of digits and numbers are created and the codes of the visual scenarios that are designed are written in ActionScript 2.0 in Adobe Flash CS3 Professional. At the implementation phase, some of the target group students are tested with prototype material that has been implemented. In the classroom, students learn both the pronunciation and the spelling of the numbers. After checking their spelling and typing errors of numbers with quizzes, the students repeat what they have learned and then they take the spelling quizzes. The program checks the misspelled words. Students who correctly complete the quizzes are entitled to have one flag. And when they have all the flags (4 flag), they receive a certificate of achievement. With this rewarding technique, it is intended to raise the motivation of the students. Finally, at the evaluation step, the observed problems in the materials are revised. At every stage of the process, expert evaluations are consulted. With this study that is based on ADDIE instructional designed model and ARCS motivational model, it is expected that students enjoy learning pronunciation and the spelling of the numbers in a semigame environment. © 2016 by Academic Publishing House.","ADDIE instructional design model; ARCS motivational model; Computer assisted english education; English pronunciation of numbers; Instructional design",,2-s2.0-85008204032
"Adamo-Villani N., Lestina J., Anasingaraju S.","Does character’s visual style affect viewer’s perception of signing avatars?",2016,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956689947&doi=10.1007%2f978-3-319-28883-3_1&partnerID=40&md5=ada27f256d8238a8c8cdd2c958167978","The paper reports a study that aimed to determine whether character’s visual style has an effect on how signing avatars are perceived by viewers. The stimuli of the study were two polygonal characters that presented two different visual styles: stylized and realistic. Each character signed four sentences. Forty-seven participants with experience in American Sign Language (ASL) viewed the animated signing clips in random order via web survey. They (1) identified the signed sentences (if recognizable), (2) rated their legibility, and (3) rated the appeal of the signing avatar. Findings show that while character’s visual style does not have an effect on subjects’ perceived legibility of the signs and sign recognition, it has an effect on their interest in the character. The stylized signing avatar was perceived as more appealing than the realistic one. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2016.","Deaf education; Sign language animation; Signing avatars","Computational linguistics; Online systems; Pattern recognition; Surveys; American sign language; Deaf educations; Sign language; Sign recognition; Signing avatars; Web surveys; E-learning",2-s2.0-84956689947
[No author name available],"International Conference on Computer Vision and Graphics, ICCVG 2016",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989884627&partnerID=40&md5=a13f4e7deeabb9beaee438e1f4b09014","The proceedings contain 58 papers. The special focus in this conference is on Computer Graphics, Perception and Image Quality. The topics include: generation of complex underground systems for application in computer games with schematic maps and L-systems; texture based quality assessment of 3D prints for different lighting conditions; pseudo in version fractals; perceptual experiments optimisation by initial database reduction; physically based area lighting model for real-time animation; calibration of structural similarity index metric to detect artefacts in game engines; generalized depth-of-field light-field rendering; anisotropic diffusion for smoothing; comparison and evaluation of first derivatives estimation; linear spectral mixture analysis of hyperspectral images with atmospheric distortions; simple and efficient method of low-contrast grayscale image binarization; single image haze removal using single pixel approach based on dark channel prior with fast filtering; saliency enhanced decolorization; depth guided detection of salient objects; minimal interaction touchless text input with head movements and stereo vision; depth estimation based on maximization of a posteriori probability; automatically analyzing interpersonal closeness in photo albums; component-based ethnicity identification from facial images; face photo-sketch transformation and population generation; similarity measures for face images; optimization of numerical calculations of geometric features of a curve describing preprocessed X-ray images of bones as a starting point for syntactic analysis of finger bone contours; application of the point distance histogram to the automatic identification of people by means of digital dental radiographic images and the use of interpolation methods for nonlinear mapping.",,,2-s2.0-84989884627
"Amidon P., Ebert M.","Computer science approach to learning astrophysics: Student develops open source software for astronomy curriculum",2016,"Proceedings of the International Astronautical Congress, IAC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016449004&partnerID=40&md5=78472fcdc7aeff945b06dfd0440b6fa9","Computer science and programming skills are essential for 21st century research and technology development and can enhance traditional curriculum to give students the opportunity to develop a technical background in any fundamental research area. We present an experience report in which one high school student, while learning astrophysics, develops a computational system to statistically produce Hertzsprung-Russell diagrams from a probabilistic description of stellar formation and modern theories of stellar evolution. This provided a setting which motivated the student to develop a deeper understanding of the relevant areas of astrophysics in particular; we hope that following a similar plan can help other students develop both an understanding of astrophysics and an interest in the application of modern computational tools to the field. The computationally-inexpensive nature of this technique allowed the student to work only with readily-available resources; this should also make it easy to reproduce our results. The student's simulation software, along with detailed documentation, has therefore been made available under the GNU General Public License, version 3.0; in an educational setting, our publicly-released materials can be used as scaffolding for an interdisciplinary project based on our methods. In addition, since our system works by evolving stars through time to reach a final HR diagram, we believe that visualizations of the intermediate time-steps can be combined into educationally-useful images and animations detailing the process of star evolution through the HR diagram. These visualizations should be simple to produce from our open-source system, as we have included a debugging tool designed to create these animations. Using this software, a student can visualize Hertzsprung-Russell diagrams over time and stellar evolution, developing skills relevant for professional research in the field of Astrophysics.",,,2-s2.0-85016449004
[No author name available],"3rd International Conference on Augmented Reality, Virtual Reality, and Computer Graphics, AVR 2016",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976618817&partnerID=40&md5=6c82f5f54cc7312ed6c94f59d4b05fa1","The proceedings contain 31 papers. The special focus in this conference is on Applications of VR/AR in Medicine. The topics include: A novel tabletop and tablet-based display system to support learner-centric ophthalmic anatomy education; using a short video animation to assist with the diagnosis of sleep disorders in young children; configurable software framework for 2D/3D video see-through displays in medical applications; application of a new wearable augmented reality video see-through display to aid percutaneous procedures in spine surgery; challenges in the effectiveness of image tagging using consumer-grade brain-computer interfaces; new opportunities and challenges; improving endovascular intraoperative navigation with real-time skeleton-based deformation of virtual vascular structures; a wearable augmented reality platform for telemedicine; development of a low-cost obstetric simulator; interactive painting and lighting in dynamic multi-projection mapping; a virtual reality environment for teaching purposes; a VR-WEB-BIM for the future maintenance of Milan’s cathedral; a virtual experience across the buried history; improved way findings for archaeological parks through mobile augmented reality; augmenting smart objects for cultural heritage; the presentation of heterogeneous data using hybrid platform; automatic analysis of eye-tracking data for augmented reality applications and immersive learning environment for visual arts.",,,2-s2.0-84976618817
[No author name available],"VISIGRAPP 2016 - Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",2016,"VISIGRAPP 2016 - Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968918559&partnerID=40&md5=0aac7d49b5e1e415112e713c4a7d5a0b","The proceedings contain 35 papers. The topics discussed include: efficient culling techniques for interactive deformable NURBS surfaces on GPU; multi-class error-diffusion with blue-noise property; re-parameterization of a deformation model for non-rigid registration; generating straight outlines of 2D point sets and holes using dominant directions or orthogonal projections; hessian eigenfunctions for triangular mesh parameterization; an external memory algorithm for the minimum enclosing ball problem; 3D geometric primitive alignment revisited; a digital hand to mimic human hand in real time operation; geometric approach to estimation of volumetric distortions; computational methods for the animation of heat transfer evolution and steel solidification; and customized 3D clothes modeling for virtual try-on system based on multiple kinects.",,,2-s2.0-84968918559
[No author name available],"3rd International Conference on Augmented Reality, Virtual Reality, and Computer Graphics, AVR 2016",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976606584&partnerID=40&md5=e634614b5e6f620ca220e0565e095020","The proceedings contain 38 papers. The special focus in this conference is on Virtual Reality, Augmented and Mixed Reality. The topics include: Simulation of tsunami impact upon coastline; design and implementation of a low cost virtual rugby decision making interactive; immersive virtual reality-based simulation to support the design of natural human-robot interfaces for service robotic applications; multi-resolution visualisation of geographic network traffic; methodology for efficiency analysis of VR environments for industrial applications; unity3D virtual animation of robots with coupled and uncoupled mechanism; a scalable cluster-rendering architecture for immersive virtual environments; the effect of emotional narrative virtual environments on user experience; user based intelligent adaptation of five in a row game for android based on the data from the front camera; a framework for schema-driven exploratory portal; the perception of object material in a virtual environment; facial landmarks for forensic skull-based 3D face reconstruction; virtual reality applications with oculus rift and 3D sensors; a reconfigurable platform for immersive visualization; virtual reality for product development in manufacturing industries; virtual reality pave the way for better understand untouchable research results; visualization of the renewable energy resources; transparency of a bilateral tele-operation scheme of a mobile manipulator robot; unity3d-matlab simulator in real time for robotics applications; mobile augmented reality based annotation system and a framework for outdoor mobile augmented reality and its application to mountain peak detection.",,,2-s2.0-84976606584
[No author name available],"4th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2016 held as part of 18th International Conference on Human-Computer Interaction, HCI International 2016",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978891154&partnerID=40&md5=d0bd33398cb7c6457fcf7b7e64908813","The proceedings contain 45 papers. The special focus in this conference is on Developing Smart Environments, Recognition Techniques in Ambient Intelligence, Tracking, Human Behavior in Smart Environments and Affect in Intelligent Environments. The topics include: Towards ubiquitous services design and development approach; exploring design for multi-device, multi-environment and multimodal connected experiences; investigating low-cost wireless occupancy sensors for beds; user interface design for ambient assisted living systems; establishing guidelines for user quality of experience in ubiquitous systems; towards big data interactive visualization in ambient intelligence environments; end-user development tools for the smart home; the interaction design research about 3d demo animation in smart home; a formal model for context-aware semantic augmented reality systems; memory and learning neural circuits correlated with the creative processes in design; data-driven smart home system for elderly people based on web technologies; a unified framework for remote collaboration using interactive AR authoring and hands tracking; exploring machine learning object classification for interactive proximity surfaces; machine learning and location fingerprinting to improve UX in a ubiquitous application; exploring the ergonomic issues of user-defined mid-air gestures for interactive product exhibition; facial tracking-assisted hand pointing technique for wall-sized displays; user-independent face landmark detection and tracking for spatial AR interaction; mid-air gestures for virtual modeling with leap motion and mental model development using collaborative 3d virtual environments.",,,2-s2.0-84978891154
"Yalcin N.A., Vatansever F.","A web-based virtual power electronics laboratory",2016,"Computer Applications in Engineering Education",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955215282&doi=10.1002%2fcae.21673&partnerID=40&md5=445db2043fd8b757d1552cd269df9c8a","In the science and engineering, supporting theoretical knowledge with practical information is crucial. Thus, there are laboratory courses together with theoretical lectures in engineering education. However, laboratory applications can't give expected successful results because of insufficient laboratory environment of educational institutions, excessive number of students etc. Depending on the developments in the computer field, concepts such as computer aided education, computer-assisted learning, computer-aided engineering have gained importance. In the carried out study, remote accessible virtual laboratory consisting of six modules is designed for power electronics courses. Realized software which can run online or offline and includes almost forty circuits (rectifiers, dc-dc converters, ac-ac converters, dc-ac converters, power supplies) belongs to power electronics field. Detailed analysis and applications can be realized with the virtual laboratory which also contains description of subjects, animations, online support, environment for preparing lab reports etc. The software is available in Uludag University, 111 undergraduate students and 17 faculty members tested it separately without requesting their personal information. Obtained results from two questionnaires are evaluated here. © 2015 Wiley Periodicals, Inc.","computer-assisted learning (CAL); distance learning; power electronics; virtual laboratory","AC-AC power converters; Application programs; Computer aided engineering; Computer aided instruction; DC-DC converters; Distance education; Education; Electric inverters; Electric rectifiers; Engineering education; Laboratories; Power electronics; Rectifying circuits; Social networking (online); Software testing; Students; Surveys; Teaching; Computer assisted learning; Computer-aided education; Educational institutions; Laboratory environment; Power electronics course; Science and engineering; Undergraduate students; Virtual laboratories; E-learning",2-s2.0-84955215282
"Reinert B., Ritschel T., Seidel H.-P.","Animated 3D creatures from single-view video by skeletal sketching",2016,"Proceedings - Graphics Interface",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031742294&partnerID=40&md5=a825a3ff2cf5b3627589ca01c63fbbca","Extraction of deformable 3D geometry is not accessible to casual users, as it either requires dedicated hardware or vast manuet alffort. Inspired by the recent success of semi-automatic 3D reconstruction from a single image, we introduce a sketch-based extraction technique that allows a fast reconstruction of a dynamic articulated shape from a single video. We model the shape as a union of generalized cylinders deformed by an animation of their axes, representing the ""limbs"" of the articulated shape. The axes are acquired from strokes sketched by the user on top of a few key frames. Our method bypasses the meticulous effort required to establish dense correspondences when applying common structure from motion techniques for shape reconstruction. Instead, we produce a plausible shape from the fusion of silhouettes over multiple frames. Reconstruction is performed at interactive rates, allowing interaction and refinement until the desired quality is achieved.","I.4.6 [image processing and computer vision]: Segmentation-pixel classification; I.4.8 [image processing and computer vision]: Scene analysis-tracking","Computer vision; Extraction; Image processing; Image segmentation; Dedicated hardware; Dense correspondences; Extraction techniques; Fast reconstruction; Generalized cylinders; I.4.8 [Image Processing and Computer Vision]: Scene Analysis - Tracking; Pixel classification; Shape reconstruction; Three dimensional computer graphics",2-s2.0-85031742294
"Cui R., Liu M., Liu M.","Facial expression recognition based on ensemble of mulitple CNNs",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992451583&doi=10.1007%2f978-3-319-46654-5_56&partnerID=40&md5=4e2e1e79211c502ac0f019f06fc7ec1f","Automatic recognition of facial expression is an important task in many applications such as face recognition and animation, human-computer interface and online/remote education. It is still challenging due to variations of expression, background and position. In this paper, we propose a method for facial expression recognition based on ensemble of multiple Convolutional Neural Networks (CNNs). First, the face region is extracted by a face detector from the pre-processed image. Second, five key points are detected for each image and the face images are aligned by two eye center points. Third, the face image is cropped into local eye and mouth regions, and three CNNs are trained for the whole face, eye and mouth regions, individually. Finally, the classification is made by ensemble of the outputs of three CNNs. Experiments were carried for recognition of six facial expressions on the Extended Cohn-Kanade database (CK+). The results and comparison show the proposed algorithm yields performance improvements for facial expression recognition. © Springer International Publishing AG 2016.","Convolutional networks; Facial expression; Machine learning; Machine vision","Artificial intelligence; Biometrics; Computer vision; Convolution; Human computer interaction; Learning systems; Neural networks; Automatic recognition; Cohn-Kanade database; Convolutional networks; Convolutional neural network; Facial expression recognition; Facial Expressions; Human computer interfaces; Processed images; Face recognition",2-s2.0-84992451583
"Chen Q., Zhigang C., Xin P., Yang W., Chuanbin G.","Potential new method of design for reconstruction of complicated mandibular defects: A virtual deformable mandibular model",2016,"British Journal of Oral and Maxillofacial Surgery",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950279967&doi=10.1016%2fj.bjoms.2015.11.029&partnerID=40&md5=3b5be2515f6ace851641851aa7d85ecd","The treatment of complicated mandibular defects, including misshaped and missing bones, is challenging, and the success of reconstruction depends to a large extent on the formulation of a precise surgical plan. There is still no ideal preoperative method of design for reconstruction to deal with large, cross-midline, mandibular, segmental defects. We have built a virtual deformable mandibular model (VDMM) with 3-dimensional animation software. Sixteen handles were set on the model, and these could be easily controlled with a computer mouse to change the morphology of the deformable mandibular model. The computed tomographic (CT) data from 10 normal skulls was used to validate the adjustability of the VDMM. According to the positions of the mandibular fossa of the temporomandibular joint, the maxillary dental arch, and the craniomaxillofacial profile, the model could be adjusted to an ideal contour, which was coordinated with the skull. The VDMM was then adjusted further according to the morphology of the original mandible. A 3-dimensional comparison was made between the model of the deformed mandible and the original mandible. Using 16 control handles, the VDMM could be adjusted to a new outline, which was similar in shape to the original mandible. Within 3 mm deviation either way, the absolute mean distribution of deviation between the contour of the deformed model and the original mandible was 92.5%. The VDMM might be useful for preoperative design of reconstruction of complicated mandibular defects. © 2015 The British Association of Oral and Maxillofacial Surgeons. Published by Elsevier Ltd. All rights reserved.","Computer aided design; Deformable mandible model; Mandibular defect; Reconstruction","adult; Article; clinical article; computer aided design; computer assisted tomography; female; human; image reconstruction; jaw malformation; male; mandible; orthognathic surgery; temporomandibular joint; tooth arch; young adult; jaw disease; mandible reconstruction; patient care planning; software; surgery; Computer-Aided Design; Humans; Mandible; Mandibular Diseases; Mandibular Reconstruction; Patient Care Planning; Software; Temporomandibular Joint",2-s2.0-84950279967
"Chumacero-Polanco E.A., Yang J.","A review on human motion prediction in sit to stand and lifting tasks",2016,"Proceedings of the ASME Design Engineering Technical Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007560092&doi=10.1115%2fDETC2016-59891&partnerID=40&md5=e57cd5c52c3057abe9d80d944a44f13e","Human-like motion prediction and simulation is an important task with many applications in fields such as occupational-biomechanics, ergonomics in industrial engineering, study of biomechanical systems, prevention of musculoskeletal disorders, computer-graphics animation of articulated figures, prosthesis and exoskeletons design as well as design and control of humanoid robots, among others. In an effort to get biomechanical insight in many human movements, extensive work has been conducted over the last decades on human-motion prediction of tasks as: walking, running, jumping, standing from a chair, reaching and lifting. This literature review is focused on the STS motion and the LLM. STS is defined as the process of rising from a chair to standing up position without losing stability balance, it is the most ubiquitous and torque-demanding daily labor and it is closely related to other capabilities of the human body. LLM is defined as the activity of raising a load, generally a box, from a low to a higher position while stability is maintained, this task produces a high number of incidences of low-back pain and injuries in many industrial and domestic activities. In order to predict STS and LLM, two methods have been identified: these are the OBMG method and the CBMG method. Copyright © 2016 by ASME.","Human motion prediction; Optimization; Predictive dynamics; Sit to stand and lifting motions; Skeletal models","Anthropomorphic robots; Biomechanics; Computer control systems; Computer graphics; Design; Ergonomics; Exoskeleton (Robotics); Machine design; Medical problems; Optimization; Biomechanical systems; Human motions; Musculoskeletal disorders; Occupational biomechanics; Predictive dynamics; Rising from a chair; Sit-to-stand; Skeletal models; Forecasting",2-s2.0-85007560092
"Duan Y., Huang W., Chang H., Chen W., Zhou J., Teo S., Su Y., Chui C.K., Chang S.","Volume preserved mass-spring model with novel constraints for soft tissue deformation",2016,"IEEE Journal of Biomedical and Health Informatics",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971670324&doi=10.1109%2fJBHI.2014.2370059&partnerID=40&md5=31956e189ac33f15e70c1ebb844c9c34","An interactive surgical simulation system needs to meet three main requirements, speed, accuracy, and stability. In this paper, we present a stable and accurate method for animating mass-spring systems in real time. An integration scheme derived from explicit integration is used to obtain interactive realistic animation for a multiobject environment. We explore a predictor-corrector approach by correcting the estimation of the explicit integration in a poststep process. We introduce novel constraints on positions into the mass-spring model (MSM) to model the nonlinearity and preserve volume for the realistic simulation of the incompressibility. We verify the proposed MSM by comparing its deformations with the reference deformations of the nonlinear finite-element method. Moreover, experiments on porcine organs are designed for the evaluation of the multiobject deformation. Using a pair of freshly harvested porcine liver and gallbladder, the real organ deformations are acquired by computed tomography and used as the reference ground truth. Compared to the porcine model, our model achieves a 1.502 mm mean absolute error measured at landmark locations for cases with small deformation (the largest deformation is 49.109 mm) and a3.639 mm mean absolute error for cases with large deformation (the largest deformation is 83.137 mm). The changes of volume for the two deformations are limited to 0.030% and 0.057%, respectively. Finally, an implementation in a virtual reality environment for laparoscopic cholecystectomy demonstrates that our model is capable to simulate large deformation and preserve volume in real-time calculations. © 2014 IEEE.",,"Computerized tomography; Deformation; Integration; Real time systems; Virtual reality; Explicit integration; Laparoscopic cholecystectomy; Nonlinear finite element method; Real-time calculations; Realistic simulation; Soft tissue deformation; Surgical simulation systems; Virtual-reality environment; Finite element method; calculation; computer assisted tomography; controlled study; gallbladder; human; human experiment; laparoscopic cholecystectomy; liver; nonlinear system; organ; porcine model; soft tissue; spring; virtual reality; algorithm; animal; biological model; computer simulation; elasticity; finite element analysis; image processing; physiology; pig; procedures; tomography; Algorithms; Animals; Cholecystectomy, Laparoscopic; Computer Simulation; Elasticity; Finite Element Analysis; Gallbladder; Image Processing, Computer-Assisted; Liver; Models, Biological; Swine; Tomography",2-s2.0-84971670324
"Liew T.W., Tan S.-M.","Virtual agents with personality: Adaptation of learner-agent personality in a virtual learning environment",2016,"2016 11th International Conference on Digital Information Management, ICDIM 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014361862&doi=10.1109%2fICDIM.2016.7829758&partnerID=40&md5=cffa067effe78db74f8172320defe581","Virtual agents are artificial intelligent artifacts that mimic natural conversations with users. The media equation posits that human-agent interaction mirrors the social cues prevalent in human-to-human relationship. As such, personality adaptation-convergence (similarity-attraction) and divergence (complementary-attraction) in human-agent interaction have been explored, particularly in the context of e-commerce, robot and scenario-based simulation. The present work extends prior studies by investigating personality adaptation in learner-agent interaction with respect to a virtual learning system. Pursuant to this goal, an introverted and an extroverted pedagogical agent were developed, as operationalized through vocal and animation parameters, and were then assessed by forty introverted and forty extraverted learners in a 2 (agent personality type) X 2 (learner personality type) experiment. The results of this study provided clear evidences in support of the complementary-attraction principle; emotional and motivational aspects of learning were significantly enhanced when the pedagogical agent exhibited personality (extraversion type) that complemented the learner's own. Theoretical and practical implications are discussed in this paper. © 2016 IEEE.","artificial intelligence; complementary-attraction; human-computer interaction; media equation; pedagogical agent; personality; similiarity-attraction; virtual agent; virtual learning environment","Artificial intelligence; Computer aided instruction; Human computer interaction; Human robot interaction; Information management; Intelligent virtual agents; Learning systems; Virtual reality; complementary-attraction; Media equation; Pedagogical agents; personality; similiarity-attraction; Virtual agent; Virtual learning environments; E-learning",2-s2.0-85014361862
"Lok B.","Training with virtual operating room teammates to influence team behaviors",2016,"Proceedings - 2016 International Conference on Collaboration Technologies and Systems, CTS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016990802&doi=10.1109%2fCTS.2016.115&partnerID=40&md5=43b8f2a891be99dc9798e92fe575cfde","Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care? In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room. We will examine the latest research into simulating healthcare teams with mixed reality humans. Mixed reality humans are virtual humans that can share the same physical space as the user. These virtual humans combine interactive graphics, natural language processing, artificial intelligence, human-computer interaction, and data mining to create in situ learning experiences. In these learning experiences, critical care personnel can work to improve teamwork with life-sized interactive virtual team-mates [1]. These learning experiences can also help implement best-practices to address address difficult teamwork concepts such as authority gradients, conflict negotiation, empathy and critical thinking [2][3]. Our research team (Samsun Lampotang, Anesthesia Department, University of Florida, Adam Wendling, Anesthesia Department, University of Florida, and Casey White, College of Medicine, University of Virginia) has developed VR hardware and software platforms to create compelling experiences for users to work on teams with mixed reality humans (MRHs). MRHs are virtual humans that can inhabit the user's physical space [4]. The MRH virtual team members can respond to the user's speech and actions and respond with natural speech and gestures. The virtual team members cannot physically interact with the environment. However, they can present realistic personalities and role-play the roles of operating room teammates, such as surgeons, anesthesiologists, nurses, and surgical technicians. The virtual team members combine the benefits of dynamic visuals of virtual humans with the physicality of mannequins (Figure 1). (Figure Presented) The virtual teammates are composed of comprise a minitower desktop for computation, networking, and rendering, a 40′ TV for display, and a Microsoft Kinect® (version 2) for tracking. All of these components are mounted onto a TV stand. Additionally, a Sennheiser DW-Pro 1 wireless headset is used for speech capture. ANDI's torso, arms, and head are rendered using a virtual human model from Autodesk's Character Generator. The virtual teammate's legs were physical and were composed of shoes and pants filled with stuffing. The physical props were used to integrate the virtual teammate into the user's space. A series of studies evaluated the social presence impact of ANDI design decisions and the current system configuration was shown to provide a virtual teammate with which participants reported a high sense of presence [5]. The virtual teammates' audio responses are pre-recorded by voice talent, and gestures are generated using motion capture and professionally key-framed animations. The virtual teammates can gaze at whoever is speaking, and intermittently glance at the other team members. They also blink and mimic idle motions when not speaking. We will examine results from studies evaluating the perception of virtual teammates, lessons learned in integrating such systems into hospital training, and areas for future research. © 2016 IEEE.","Healthcare; Team training; Virtual humans","Anesthesiology; Computer graphics; Data mining; E-learning; Health care; Human computer interaction; In situ processing; Intensive care units; Natural language processing systems; Nursing; Operating rooms; Personnel training; Rendering (computer graphics); Communication skills; Hardware and software; NAtural language processing; System configurations; Team training; University of Florida; University of Virginia; Virtual humans; Virtual reality",2-s2.0-85016990802
"Kazaine I.","Software for creation of electronic materials",2016,"Engineering for Rural Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976596244&partnerID=40&md5=f87a22633272938de6130c3855eeb85b","Educational institutions more often are using e-learning systems in the study process. Therefore, more and more students are offered learning materials in electronic format. Creation of Electronic Materials is mainly based on the knowledge of the Information technology (IT) teacher, and as a result e-learning material is usually published as presentation or PDF document. However, the e-learning environment allows the use of a much wider spectrum: HTML documents, video or audio materials, animations, etc. The research summarized software that can be used for development of electronic materials. The research offers recommendations of software selection for material development that are based on the most popular media elements: text, image, animation, audio and video. The given recommendations may be useful for teachers, who are not directly related to the IT field.","E-learning; Electronic materials; Multimedia","Computer aided instruction; Computer software selection and evaluation; Education; Regional planning; Teaching; E-learning environment; E-learning materials; Educational institutions; Electronic materials; Learning materials; Material development; Multimedia; Software selection; E-learning; electronic equipment; knowledge; learning; multimedia; software; teacher training",2-s2.0-84976596244
"Gianmarco Cherchi, Marco Livesu, Riccardo Scateni","Polycube simplification for coarse layouts of surfaces and volumes",2016,"Eurographics Symposium on Geometry Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020086233&doi=10.1111%2fcgf.12959&partnerID=40&md5=bad074f89a75beb3033927c2f4fa0b3d","Representing digital objects with structured meshes that embed a coarse block decomposition is a relevant problem in applications like computer animation, physically-based simulation and Computer Aided Design (CAD). One of the key ingredients to produce coarse block structures is to achieve a good alignment between the mesh singularities (i.e., the corners of each block). In this paper we improve on the polycube-based meshing pipeline to produce both surface and volumetric coarse block-structured meshes of general shapes. To this aim we add a new step in the pipeline. Our goal is to optimize the positions of the polycube corners to produce as coarse as possible base complexes. We rely on re-mapping the positions of the corners on an integer grid and then using integer numerical programming to reach the optimal. To the best of our knowledge this is the first attempt to solve the singularity misalignment problem directly in polycube space. Previous methods for polycube generation did not specifically address this issue. Our corner optimization strategy is efficient and requires a negligible extra running time for the meshing pipeline. In the paper we show that our optimized polycubes produce coarser block structured surface and volumetric meshes if compared with previous approaches. They also induce higher quality hexahedral meshes and are better suited for spline fitting because they reduce the number of splines necessary to cover the domain, thus improving both the efficiency and the overall level of smoothness throughout the volume. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Categories and subject descriptors (according to ACM CCS): I.3.5 [computer graphics]: Computational geometry and object modeling; Geometric algorithms, languages, and systems",,2-s2.0-85020086233
"Antonowicz M., Kajzer A., Kajzer W.","Application of reverse engineering in supporting the treatment of pectus carinatum",2016,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976519896&doi=10.1007%2f978-3-319-39904-1_19&partnerID=40&md5=b0bc6da0d33b718bb6780b6379e8f4cc","This paper presents the application of reverse engineering in supporting the design and modelling of the personalised prototype of the orthotic bracing in the treatment of pectus carinatum. 3D scans of the normal thoracic cage were used, which were necessary to simulate pectus carinatum. Based on the scans, the skeletal system of the pectus carinatum and the normal skeletal system were designed. In summary, it can be stated that it was possible to design the personalised external stabiliser and produce an animation of the principle of its operation. © Springer International Publishing Switzerland 2016.","3D scan; Pectus bracing; Pectus carinatum; Reverse engineering","Computer programming; Computer science; 3-d scans; Pectus bracing; Pectus carinatum; Skeletal system; Stabiliser; Reverse engineering",2-s2.0-84976519896
"Li Y., Zou Y., Zhu W., Deng J., Huo W.","Motor rotor unit composite die design and WEDM programming of stamping dies (convex-concave mould)",2016,"Key Engineering Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945219094&doi=10.4028%2fwww.scientific.net%2fKEM.667.487&partnerID=40&md5=308d21a603818c8c566d47c4beaa7de1","This paper introduces motor rotor blanking die design process through specific terms of the process of stamping all. Mould design process is for structural analysis and process analysis of the parts diagram, based on it to determine the technology methods, select the structure of the mould, and make a necessary calculation to determine stock layout and the size of the work part. And choose a suitable punching machine. Finally, choose the parts from the manual of mould. This design also includes the use of AutoCAD software mapping die assembly and major parts map using UG and Pro/E software for 3D solid modeling and animation design simulation process. In addition, the punch and die processing choose WEDM and Programming. So consider the structural design of WEDM of the specific methods to avoid the conflict between design and processing, and guarantee the production reasonable. © (2016) Trans Tech Publications, Switzerland.","Composite die; Programming; Sheet; Simulation; WEDM","Computer aided design; Computer software; Design; Mathematical programming; Molds; Stamping; Structural design; 3D solid model; AutoCAD software; Pro/E software; Process analysis; Punching machine; Sheet; Simulation; WEDM; Dies",2-s2.0-84945219094
"Tzionas D., Gall J.","Reconstructing articulated rigged models from RGB-D videos",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006014897&doi=10.1007%2f978-3-319-49409-8_53&partnerID=40&md5=7cde131d435dfbc3e0f3e6bbfec121cd","Although commercial and open-source software exist to reconstruct a static object from a sequence recorded with an RGB-D sensor, there is a lack of tools that build rigged models of articulated objects that deform realistically and can be used for tracking or animation. In this work, we fill this gap and propose a method that creates a fully rigged model of an articulated object from depth data of a single sensor. To this end, we combine deformable mesh tracking, motion segmentation based on spectral clustering and skeletonization based on mean curvature flow. The fully rigged model then consists of a watertight mesh, embedded skeleton, and skinning weights. © Springer International Publishing Switzerland 2016.","Deformable tracking; Kinematic model learning; Mean curvature flow; Rigged model acquisition; Skeletonization; Spectral clustering","Clustering algorithms; Computer graphics; Computer vision; Deformation; Kinematics; Mesh generation; Open systems; Software engineering; Kinematic model; Mean curvature flow; Model acquisition; Skeletonization; Spectral clustering; Open source software",2-s2.0-85006014897
"Luo D., Luo R., Wang L.","Naturalness judgement of L2 English through dubbing practice",2016,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994274933&doi=10.21437%2fInterspeech.2016-623&partnerID=40&md5=061fdde8c356fd060fe973dae729a78e","This Study investigates how different prosodic features affect native speakers' perception of L2 English spoken by Chinese students through dubbing, or re-voicing practice on video clips. Learning oral foreign language through dubbing on movie or animation clips has become very popular in China. In this practice, learners try to reproduce utterances as closely as possible to the original speech by closely matching lip movements on the clips. The L2 utterances before and after substantial dubbing practices were recorded and categorized according to different prosodic error patterns. Objective acoustic features were extracted and analyzed with naturalness scores based on perceptual experiment. Experimental results show that stress and timing play key roles in native speakers' perception of naturalness. With the practice of dubbing, prosodic features, especially timing, can be considerably improved and thus the naturalness of the reproduced utterances increases. Copyright © 2016 ISCA.","Dubbing; Foreign accent; L2 English; Naturalness; Prosodic assessment; Stress; Timing","Speech processing; Stresses; Computer applications; Computer simulation; Dubbing; Foreign accents; L2 English; Naturalness; Prosodic assessment; Timing; Speech communication",2-s2.0-84994274933
"Rhodin H., Robertini N., Casas D., Richardt C., Seidel H.-P., Theobalt C.","General automatic human shape and motion capture using volumetric contour cues",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990053240&doi=10.1007%2f978-3-319-46454-1_31&partnerID=40&md5=7f87b7d57cd0b5e889df4f80caa16864","Markerless motion capture algorithms require a 3D body with properly personalized skeleton dimension and/or body shape and appearance to successfully track a person. Unfortunately, many tracking methods consider model personalization a different problem and use manual or semi-automatic model initialization, which greatly reduces applicability. In this paper, we propose a fully automatic algorithm that jointly creates a rigged actor model commonly used for animation-skeleton, volumetric shape, appearance, and optionally a body surface - and estimates the actor’s motion from multi-view video input only. The approach is rigorously designed to work on footage of general outdoor scenes recorded with very few cameras and without background subtraction. Our method uses a new image formation model with analytic visibility and analytically differentiable alignment energy. For reconstruction, 3D body shape is approximated as a Gaussian density field. For pose and shape estimation, we minimize a new edge-based alignment energy inspired by volume ray casting in an absorbing medium. We further propose a new statistical human body model that represents the body surface, volumetric Gaussian density, and variability in skeleton shape. Given any multi-view sequence, our method jointly optimizes the pose and shape parameters of this model fully automatically in a spatiotemporal way. © Springer International Publishing AG 2016.",,"Computer vision; Motion estimation; Rendering (computer graphics); Automatic algorithms; Background subtraction; Gaussian density; Human body modeling; Image formation models; Markerless motion capture; Shape parameters; Volume ray casting; Musculoskeletal system",2-s2.0-84990053240
"Thomas D., Taniguchi R.-I.","Augmented blendshapes for real-time simultaneous 3D head modeling and facial motion capture",2016,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986288211&partnerID=40&md5=6ea66dfc2226cb6f6f9fc4a8b6e4d445","We propose a method to build in real-time animated 3D head models using a consumer-grade RGB-D camera. Our framework is the first one to provide simultaneously comprehensive facial motion tracking and a detailed 3D model of the user's head. Anyone's head can be instantly reconstructed and his facial motion captured without requiring any training or pre-scanning. The user starts facing the camera with a neutral expression in the first frame, but is free to move, talk and change his face expression as he wills otherwise. The facial motion is tracked using a blendshape representation while the fine geometric details are captured using a Bump image mapped over the template mesh. We propose an efficient algorithm to grow and refine the 3D model of the head on-the-fly and in real-time. We demonstrate robust and high-fidelity simultaneous facial motion tracking and 3D head modeling results on a wide range of subjects with various head poses and facial expressions. Our proposed method offers interesting possibilities for animation production and 3D video telecommunications.",,"Algorithms; Cameras; Computer vision; Face recognition; Motion analysis; Pattern recognition; 3D head model; Face expressions; Facial Expressions; Facial motion capture; Facial motions; Geometric details; High-fidelity; Rgb-d cameras; Three dimensional computer graphics",2-s2.0-84986288211
"Salvaneschi G., Amann S., Proksch S., Mezini M.","An empirical study on program comprehension with reactive programming",2016,"Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016241413&partnerID=40&md5=a239952f229d97ee131ffe221fd30fe9","Starting from the first investigations with strictly functional languages, reactive programming has been proposed as the programming paradigm for reactive applications. The advantages of designs based on this style over designs based on the Observer design pattern have been studied for a long time. Over the years, researchers have enriched reactive languages with more powerful abstractions, embedded these abstractions into mainstream languages - including object-oriented languages - and applied reactive programming to several domains, like GUIs, animations, Web applications, robotics, and sensor networks. However, an important assumption behind this line of research - That, beside other advantages, reactive programming makes a wide class of otherwise cumbersome applications more comprehensible - has never been evaluated. In this paper, we present the design and the results of the first empirical study that evaluates the effect of reactive programming on comprehensibility compared to the traditional object-oriented style with the Observer design pattern. Results confirm the conjecture that comprehensibility is enhanced by reactive programming. In the experiment, the reactive programming group significantly outperforms the other group.","Controlled experiment; Program comprehension; Reactive programming","Abstracting; Computer programming; Computer systems programming; Functional programming; Robot programming; Sensor networks; Software engineering; Controlled experiment; Empirical studies; Functional languages; Observer design patterns; Program comprehension; Programming paradigms; Reactive languages; Reactive programming; Object oriented programming",2-s2.0-85016241413
"Qadri M.A.J., Reid S., Cook R.G.","Complex conditional control by pigeons in a continuous virtual environment",2016,"Journal of the Experimental Analysis of Behavior",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010952286&doi=10.1002%2fjeab.190&partnerID=40&md5=1309b990e3d1d7f8a82008dc59e3a57d","We tested two pigeons in a continuously streaming digital environment. Using animation software that constantly presented a dynamic, three-dimensional (3D) environment, the animals were tested with a conditional object identification task. The correct object at a given time depended on the virtual context currently streaming in front of the pigeon. Pigeons were required to accurately peck correct target objects in the environment for food reward, while suppressing any pecks to intermixed distractor objects which delayed the next object's presentation. Experiment 1 established that the pigeons’ discrimination of two objects could be controlled by the surface material of the digital terrain. Experiment 2 established that the pigeons’ discrimination of four objects could be conjunctively controlled by both the surface material and topography of the streaming environment. These experiments indicate that pigeons can simultaneously process and use at least two context cues from a streaming environment to control their identification behavior of passing objects. These results add to the promise of testing interactive digital environments with animals to advance our understanding of cognition and behavior. © 2016 Society for the Experimental Analysis of Behavior","context control; object identification; occasion setting; pigeons; virtual reality; visual tracking","animal; association; cognition; computer interface; discrimination learning; environment; instrumental conditioning; male; pigeons and doves; recognition; vision; Animals; Cognition; Columbidae; Conditioning, Operant; Cues; Discrimination Learning; Environment; Male; Recognition (Psychology); User-Computer Interface; Visual Perception",2-s2.0-85010952286
"Aouiti N., Jemni M.","Classifiers in Arab gloss annotation system for Arabic sign language",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978862914&doi=10.1007%2f978-3-319-41267-2_56&partnerID=40&md5=6c394a0500aed210eddc2c8cfcc6d594","As we know deaf people present about 70 million of the person in the word. 17 million of this community is only in Arabic word. Therefore this community of person require more and more attention from researchers and precisely SLMT (Sign Language Machine Translation) researchers to be able to practice their natural right which is communication with other person. In this context the research laboratory LaTICE of the University of Tunis lunched science many years the project WebSign [1] aiming to translate automatically a written text to sign language whatever the language as input (English, French, Arabic, etc.). WebSign is a Web application. It is based on the technology of avatar (animation in virtual world). The input of the system is a text in natural language. The output is a real-time and online interpretation in sign language. This interpretation is constructed thanks to a dictionary of word and signs. The creation of this dictionary can be made in an incremental way by users who propose signs corresponding to words [2]. Our work as a part of this project aims to develop a translation module from Arabic text to Sign Language to be integrated in the WebSign project. This module offers to Arab Deaf and hearing people a tool facilitating their communication. Anyone can use this tool to translate an Arabic written text to Arabic Sign Language (ArSL). In fact in this level, it’s very useful to define a transcription system for Arabic Sign Language based on Arabic Gloss. This intermediate annotation system is a textual representation of sign language that covers the different parameters of the sign with a simplified representation to avoid the complexity of understanding [3]. © Springer International Publishing Switzerland 2016.","Arabic gloss annotation system; ArSL; Machine translation","Audition; Computational linguistics; Computer aided language translation; Interactive computer graphics; Research laboratories; Virtual reality; Annotation systems; Arabic sign language; ArSL; Machine translations; Natural languages; Sign language machine translation; Textual representation; WEB application; Translation (languages)",2-s2.0-84978862914
"Zhou Y.","Application of automatic choreography software based on virtual technology in the gymnastics teaching",2016,"International Journal of Emerging Technologies in Learning",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971572633&doi=10.3991%2fijet.v11i05.5692&partnerID=40&md5=462ce7908f57de650cd4c76ce016926f","This research designed simulation system of gymnastics automatic choreography software. To successfully design the gymnastics movements, experiment adopted solutions based on key frame spline interpolation calculation which managed to solve the problem of location deviation; quaternion interpolation algorithm was adopted to solve the rotation problem of the subject and the body, which made the modified action by computer auxiliary choreography system completely returned to virtual figure animation. In addition, for coordination of dance and audio, this paper established movement fragments library based on sentiment types, proposed viable approach of synchronized audio and video model. Teaching experience was conducted in the gymnastics course of physical education at the University and achieved good results.","Choreography software; Gymnastic courses; Multimedia teaching; Virtual technology","Application programs; Computer software; Interpolation; Gymnastic courses; Multimedia teachings; Physical education; Quaternion interpolation; Simulation systems; Spline interpolation; Teaching experience; Virtual technology; Teaching",2-s2.0-84971572633
"Mao A., Gao P., Mao A., Song Y., Yu J.","The design and realization of a popular science long corridor based on 3D stereo technology",2016,"International Journal of Multimedia and Ubiquitous Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977119755&doi=10.14257%2fijmue.2016.11.6.23&partnerID=40&md5=fef6fed854ae1358b0a62e86ee2f8a60","Through the design and technical realization of a popular science long corridor based on 3D stereo technology, three hot applications of 3D technology including 3D folding technology, 3D holographic imaging technology and 3D printing technology were introduced in the paper. The three techniques as a whole in the popular science long corridor display the method to decrease the realization cost of the popular science long corridor. The interactive part of the two-dimensional animation was added into the popular science long corridor to reflect truly the effect of the computer technology integrating application. © 2016 SERSC.","3D holographic; 3D printing; 3D stereo technology; Stereo folding","Holography; Imaging techniques; Printing; 3-D printing; 3D holographic; 3d stereos; 3D technology; Computer technology; Holographic imaging technology; Stereo folding; Technical realization; 3D printers",2-s2.0-84977119755
"Litany O., Rodolà E., Bronstein A.M., Bronstein M.M., Cremers D.","Non-rigid puzzles",2016,"Eurographics Symposium on Geometry Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020122083&doi=10.1111%2fcgf.12970&partnerID=40&md5=8d1248e338cc270a2d0a7c22ba305538","Shape correspondence is a fundamental problem in computer graphics and vision, with applications in various problems including animation, texture mapping, robotic vision, medical imaging, archaeology and many more. In settings where the shapes are allowed to undergo non-rigid deformations and only partial views are available, the problem becomes very challenging. To this end, we present a non-rigid multi-part shape matching algorithm. We assume to be given a reference shape and its multiple parts undergoing a non-rigid deformation. Each of these query parts can be additionally contaminated by clutter, may overlap with other parts, and there might be missing parts or redundant ones. Our method simultaneously solves for the segmentation of the reference model, and for a dense correspondence to (subsets of) the parts. Experimental results on synthetic as well as real scans demonstrate the effectiveness of our method in dealing with this challenging matching scenario. © 2016 The Eurographics Association and John Wiley & Sons Ltd.","Categories and subject descriptors (according to ACM CCS): I.3.5 [computer graphics]: Computational geometry and object modeling; Shape analysis",,2-s2.0-85020122083
"Moldovan R., Orza B., Mihon D., Porumb C., Meza S.","External resource annotation framework and its applications in e-learning",2016,"Interaction Design and Architecture(s)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013074399&partnerID=40&md5=2ecb59d950fbe44cb6757355f4371777","Rich Internet Applications that enable new ways of interaction with digital objects within multimedia scenes become important for educational communities. Such new ways of advanced human-computer interaction, in its different forms match the needs of formal education as well as lifelong learning in medicine, architecture, construction or cultural heritage management. This paper presents innovative multimedia annotation methods based on advanced human-computer interaction and (a)synchronous interpersonal collaboration features, focusing on e-learning activities. They have been implemented within eRAF (External Resource Annotation Framework) with the scope of going beyond the existing solutions by introducing new annotation types using external resources. Thus, anyone can easily annotate the own resources with additional information such as real-time handwriting, text and animation, or even audio/video sequences stored into public data repositories, or recorded adhoc, in order to create value-added interactive content.","Annotation; E-learning; Framework; Human-computer interaction; Interactive training; Mobile agent; Multimedia; Video collaboration",,2-s2.0-85013074399
"Nemec R., Berkova A., Hubalovsky S.","The use of method of multidisciplinary approach, modeling and simulation in learning of gear ratios",2016,"International Journal of Mathematics and Computers in Simulation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956685913&partnerID=40&md5=57300e7d8f6d46218ebd2ff04bda268d","This paper presents the development of Set for Measuring the Transfer Gears and its use in science classes in conjunction with teaching computer technology supported by interactive geometric software. The goal of developing measurement transfer kits for gears demonstration of speed gears is to show the real speed of the individual gears in relation to the number of gears to pupils of science. For better understanding, the animations of gears, drawings of various kinds of gears and gear teeth in interactive geometry software were used. Several school science subjects were involved in this project and their collaboration resulted in improved results of pupils in these subjects. © 2016, North Atlantic University Union. All rights reserved.","Computer aided experiment; DAQ; GeoGebra; Measurement system; Teaching science",,2-s2.0-84956685913
"Stahl K., Altakrouri B., Burmeister D., Schrader A.","Documentation generation tool for motion-based interactions",2016,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978198683&doi=10.1007%2f978-3-319-40542-1_22&partnerID=40&md5=3426c781687f7cd5378c9672fc08432f","Human Computer Interaction based on gestures offers enormous potential for designing ergonomic user interfaces in future smart environments. Although gestures can be perceived as very natural, the specific gesture set of a given dedicated interface might be complex and require some kind of self-description of expected body movements. We have therefore developed a machine-readable XML-based model of Labanotation, a camera-based movement analysis engine for automatic model creation, as well as a graphical editor for supporting manual design of gestures. In this paper, we present a tool for automatic generation of multimodal human-readable gesture documentation based on the XMLmodel. Currently, the tool supports text and 3D model animation and can be expanded to other modalities. © Springer International Publishing Switzerland 2016.","Documentation; Gesture interfaces; Labanotation","Abstracting; System program documentation; User interfaces; Automatic Generation; Automatic modeling; Generation tools; Gesture interfaces; Graphical editors; Labanotations; Movement analysis; Smart environment; Human computer interaction",2-s2.0-84978198683
"Dąbrowski K.","Simulations of accelerations and velocities of the robot’s arm",2016,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983138423&doi=10.1007%2f978-3-319-26886-6_4&partnerID=40&md5=b54842e2929f123b7a7f616b7449e76d","Project of program realizing reciprocal kinematic exercise is the entrance to researches of robots arm’s power. The C++ based program counts accelerations and velocities of robot arms based on position between the end of arm and the level of the ground. Using different versions of the inverted kinematic problems, the ranges of errors are calculated. For the demand of the user the animation of robot arms movements might be played in slow motion. © Springer International Publishing Switzerland 2016.","Acceleration; Range of error; Robot arm; Robot movement; Velocity","Acceleration; C++ (programming language); Computer software; Kinematics; Robotic arms; Velocity; Kinematic problems; Robot arms; Robot movements; Slow motion; Robots",2-s2.0-84983138423
"Suresh R., Audithan S.","Automated recognition system for facial expression based on the fusion of spatial and frequency domain features",2016,"ARPN Journal of Engineering and Applied Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000842681&partnerID=40&md5=b2f8656fb65ae0105360cba1a1cee71b","The development of facial expression recognition system proliferates now-a-days due to its various fields of application such as Human Computer Interaction (HCI), behavioral studies, facial nerve grading in medicine, automated tutoring system, synthetic face animation, and robotics. Among the various behavioral traits such as voice and gaits, facial expression is the most and effectual communicative way of humans. It is also a natural, non-verbal and non-intrusive communicative source. In this study, multidirectional approach based robust and automated facial expression recognition system is proposed. Contourlet transform is adopted as multi resolution and multi directional approach for feature computation along with Discriminative Robust Local Ternary Pattern (DRLTP) and Gray Level Co-occurrence Matrix (GLCM). On account of classification K-Nearest Neighbor (KNN) classifier is used based on city block distance measure. The standard Japanese Female Facial Expression (JAFFE) database is utilized to evaluate the performance of the proposed algorithm. Experimental result shows that the proposed system achieves satisfactory performance of over 91%. © 2006-2016 Asian Research Publishing Network (ARPN).","Contourlet transform; Discriminative robust local ternary pattern; Facial expression recognition; Gray level co-occurrence matrix; Human computer interaction",,2-s2.0-85000842681
"Jaafar F., Fauzi F.H.A., Ramli W.N.R.W.","Enhancement on visual communication for preschool education using transmedia approach",2016,"International Colloquium of Art and Design Education Research (i-CADER 2014)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955333972&doi=10.1007%2f978-981-287-332-3_46&partnerID=40&md5=1684ed68645f49f58784802b9d5a8cc4","This study will be focusing on the component of preschool curriculum developed by the Ministry of Education. The component of preschool curriculum will be constructed digitally using transmedia approach. Throug this study it is our hope that a fun learning environment can be actualized by exposing the students with such approach. The utilization of different media also hopes to encourage constructive learning and collaborative classroom discussion which in turn can hopefully make learning more playful but at the same time structured. This paper will also discuss the many problems in transferring a certain curriculum module using animation approach. © Springer Science+Business Media Singapore 2015.","NPE (National Philosophy of Education); Preschool curriculum; Transmedia; Visual communication","Computer aided instruction; Curricula; Visual communication; Constructive learning; Learning environments; Ministry of Education; NPE (National Philosophy of Education); Preschool education; Transmedia; Education",2-s2.0-84955333972
"Zhang N., Ogawa K.","Proposal of Chinese tourist support system to enjoy the holy land pilgrimage in Japan",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978826699&doi=10.1007%2f978-3-319-40093-8_48&partnerID=40&md5=6d8bfda3a7ffa602193b964458de8489","Many Chinese get familiar with Japan via comics, animations, movies or dramas; especially some scenes in these works were actually drawn on real life. Recently, touring to these places is an on-going new reason for visiting Japan. However, finding the scenes from the real world without a guide is very difficult, and collecting the information about the location of scenes always cost plenty of time on Internet. This paper clarifies the conditions of designing a new media system to raise Chinese tourists’ joyfulness out of the holy pilgrimage trip, and proposes a new media system to support them to record and share distinct routes for location of scenes. © Springer International Publishing Switzerland 2016.","Chinese tourist; Holy land; Japanese culture; Location of scenes; Pilgrimage; Record; Seichi Junrei","Location; Chinese tourists; Japanese cultures; Pilgrimage; Record; Seichi Junrei; Human computer interaction",2-s2.0-84978826699
"Ling C., Bock J.S., Goodwin L., Cole Jackson G., Floyd M.K.","Comparison of two visualization tools in supporting comprehension of data trends",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978805252&doi=10.1007%2f978-3-319-40349-6_16&partnerID=40&md5=bf2f3766fd68be03e9539fa77c8071a8","This study compares two commonly used visualization tools, Gapminder and Tableau Public at simple and integrated level, to assess which tool better support user comprehension of data trends in a large dataset. Forty-seven participants were presented with a data set through Gapminder or Tableau Public at either a simple or integrated level. Then each participant was asked to answer questions about what they observed, showing their understanding of the information as well as rate ease-of-use of the tool. The results show that use of animation in Gapminder helped users comprehend data trends, whereas designs that assume prior geographical knowledge of users hampered their performance. Participants achieved higher accuracy with the graphs rated as easier to use. The results suggest that design of visualization tools should use familiar visual features and consider ease-of-use factor to assist user’s comprehension of data trend. © Springer International Publishing Switzerland 2016.","Data trend comprehension; Data visualization; Display complexity; Ease of use","Human computer interaction; Visualization; Data set; Data trend; Ease-of-use; Large dataset; Visual feature; Visualization tools; Data visualization",2-s2.0-84978805252
"Mughal M.F., Luo M.R., Wang Y., Xu L., Safdar M.","Calibration of 3D images in terms of spectral reflectance",2016,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951977171&doi=10.1007%2f978-981-10-0072-0_6&partnerID=40&md5=9da361ae94d80331951dc0db9e484a35","Recently, 3D image processing has become widespread in the various applications such as medical, animation, and graphics communication. There exist a number of techniques to transform 2D images into 3D. The purpose of this study was to develop a set of procedure to achieve precise color reproduction in cross-media color reproduction for 3D images and to simulate images under different illuminants. A 3dMD® system was used to capture images of 3D objects. A polynomial model-based camera characterization was implemented. To further enhance the scope of research, different 3D images were transformed into the spectral images via two different methods, principal component analysis (PCA) and Wiener. The spectral images were then used to transform images under different illuminants. Finally, a simulation of the appearance of 3D images on a display under different illuminants was successfully achieved. © Springer Science+Business Media Singapore 2016.","3D imaging; 3dMD; Method; PCA; Spectral reflectance; Weiner","Medical image processing; Medical imaging; Packaging materials; Principal component analysis; Reflection; Spectroscopy; Three dimensional computer graphics; Visual communication; 3D imaging; 3dMD; Method; PCA; Spectral reflectances; Weiner; Image processing",2-s2.0-84951977171
"Arce D., Retamozo S., Aguilar R., Castañeda B.","A mixed methodology for detailed 3D modeling of architectural heritage",2016,"Structural Analysis of Historical Constructions: Anamnesis, diagnosis, therapy, controls - Proceedings of the 10th International Conference on Structural Analysis of Historical Constructions, SAHC 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002050089&partnerID=40&md5=fc1236f73a94297321c318979f1331f3","Three dimensional modeling has become an important tool for applications including record keeping, virtual reality and structural analysis of architectural heritage. Laser scanning and photogrammetry are the two most-used techniques. Whereas the former provides a fast and accurate model, the required equipment is bulky and difficult to position. Therefore, it cannot provide a complete model of the monument. The latter technique uses a digital camerawhich can be used manually, located on a drone or on top of supporting structures. Hence, this versatile technique can generate complete 3D models at the expense of larger processing times. This work proposes a mixed approach for digitization of architectural heritage combining the data from laser scanning and photogrammetry. This approach is applied in three churches of the Andean-Baroque Route. The results show high-detailed 3D digital models which subsequently can be used for generating architectural drawings, 3D solid models, walk-through videos and animations. © 2016 Taylor & Francis Group, London.",,"Architectural design; Architecture; Laser applications; Photogrammetry; Records management; Structural analysis; Surface analysis; Virtual reality; 3D digital models; Accurate modeling; Architectural heritage; Laser scanning; Mixed approach; Processing time; Supporting structure; Three-dimensional model; Three dimensional computer graphics",2-s2.0-85002050089
"Zeng X., Sang X., Chen D., Wang P., Guo N., Yan B., Wang K.","An interactive VR system based on full-body tracking and gesture recognition",2016,"Proceedings of SPIE - The International Society for Optical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011419277&doi=10.1117%2f12.2247808&partnerID=40&md5=b069fec784a6115dc2b9e2a2b40aa7fb","Most current virtual reality (VR) interactions are realized with the hand-held input device which leads to a low degree of presence. There is other solutions using sensors like Leap Motion to recognize the gestures of users in order to interact in a more natural way, but the navigation in these systems is still a problem, because they fail to map the actual walking to virtual walking only with a partial body of the user represented in the synthetic environment. Therefore, we propose a system in which users can walk around in the virtual environment as a humanoid model, selecting menu items and manipulating with the virtual objects using natural hand gestures. With a Kinect depth camera, the system tracks the joints of the user, mapping them to a full virtual body which follows the move of the tracked user. The movements of the feet can be detected to determine whether the user is in walking state, so that the walking of model in the virtual world can be activated and stopped by means of animation control in Unity engine. This method frees the hands of users comparing to traditional navigation way using hand-held device. We use the point cloud data getting from Kinect depth camera to recognize the gestures of users, such as swiping, pressing and manipulating virtual objects. Combining the full body tracking and gestures recognition using Kinect, we achieve our interactive VR system in Unity engine with a high degree of presence. © 2016 SPIE.","full-body tracking; gesture recognition; human-centered interaction; Microsoft Kinect; natural user interface; Unity3D; virtual reality; walking-in place","Cameras; Engines; Hand held computers; Optical design; User interfaces; Virtual reality; Full-body tracking; human-centered interaction; Microsoft kinect; Natural user interfaces; Unity3d; Walking-in-place; Gesture recognition",2-s2.0-85011419277
"Li Q., Wu W., Xu L., Huang J., Feng M.","A statistics based prediction method for rendering application",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994493327&doi=10.1007%2f978-3-319-47099-3_6&partnerID=40&md5=136c81f14e749e74527085c9aa8ef0c6","As an interesting commercial application, rendering plays an important role in the field of animation and movie production. Generally, render farm is used to rendering mass images concurrently according to the independence among frames. How to scheduling and manage various rendering jobs efficiently is a significant issue for render farm. Therefore, the prediction of rendering time for frames is relevant for scheduling, which offers the reference and basis for scheduling method. In this paper a statistics based prediction method is addressed. Initially, appropriate parameters which affect the rendering time are extracted and analyzed according to parsing blend formatted files which offers a general description for synthetic scene. Then, the sample data are gathered by open source software Blender and J48 classification algorithm is used for predicting rendering time. The experimental results show that the proposed method improve the prediction accuracy about 60% and 75.74% for training set and test set, which provides reasonable basis for scheduling jobs efficiently and saving rendering cost. © IFIP International Federation for Information Processing 2016.","Classification; Prediction; Render farm; Rendering; Statistics","Classification (of information); Forecasting; Open source software; Open systems; Scheduling; Software engineering; Statistics; Classification algorithm; Commercial applications; General description; Movie production; Prediction accuracy; Prediction methods; Rendering; Scheduling methods; Rendering (computer graphics)",2-s2.0-84994493327
"Sigitov A., Staadt O., Hinkenjann A.","Distributed unity applications evaluation of approaches",2016,"Communications in Computer and Information Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978938283&doi=10.1007%2f978-3-319-40548-3_23&partnerID=40&md5=81e41f7b7539644acbd77d2f1c319d36","There is a need for rapid prototyping tools for large, high-resolution displays (LHRDs) in both scientific and commercial domains. That is, the area of LHRDs is still poorly explored and possesses no established standards, thus developers have to experiment a lot with new interaction and visualization concepts. Therefore, a rapid prototyping tool for LHRDs has to undertake two functions: ease the process of application development, and make an application runnable on a broad range of LHRD setups. The latter comprises a challenge, since most LHRDs are driven by multiple compute nodes and require distributed applications. Unity engine became a popular tool for rapid prototyping, since it eases the development process by means of a visual scene editor, animation libraries, input device libraries, graphical user interface libraries etc. However, it will charge developers with a high fee in order to make an application LHRD compatible. In our previous work, we developed an extension for Unity engine that allows to run Unity applications on LHRDs. In this work we consider different static vs. dynamic camera/world conditions of distributed applications; and propose and evaluate different Unity specific approaches within the scope of 2D and 3D applications for these scenarios. The primary focus of the evaluation lays on world state synchronization, which is a common issue in distributed applications. © Springer International Publishing Switzerland 2016.","Distributed rendering; High-resolution displays; Large; Unity","Engines; Graphical user interfaces; Human computer interaction; Libraries; Rapid prototyping; User interfaces; Application development; Distributed applications; Distributed rendering; High resolution display; Large; Rapid prototyping tool; State synchronization; Unity; Software prototyping",2-s2.0-84978938283
"Ji P., Tian F., Liu S., Chen G.","3D streamline visualization for irregular flow field data",2016,"Journal of Computational and Theoretical Nanoscience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015195158&doi=10.1166%2fjctn.2016.6062&partnerID=40&md5=a9f0122fcf8329adc109204100a7a598","For the streamline visualization of 3D flow field datasets, the placement and perception of streamlines are a vital aspect. This paper presents a tetrahedron-basedmethod for streamlines generation in irregular flow field. Based on spatial-distribution factor, we place seeds in the largest empty area to avoid short streamline and blank area. With the help of tetrahedral grid, we get multi-resolution lines model to observe different streamline details. To enhance the perception of streamline visualization in virtual environment, we apply animation and opacity strategies to the streamlines.We also map the scalar features such as velocity, direction, to the appearance of streamlines. Taking the Princeton Ocean Model (POM) computing data as an application example, we achieve smooth and dynamic rending results to show the features of irregular flow field data. Finally, we detail an efficient GPU implementation of transforming line segments to cylinders with opacity and color features. The results show that our method works effectively in visualizing the irregular flow field data and presenting the features of the ocean currents. © 2016 American Scientific Publishers All rights reserved.","3D streamline; GPU; Irregular flow field data; Visualization","Flow fields; Flow visualization; Graphics processing unit; Ocean currents; Opacity; Three dimensional computer graphics; Virtual reality; Visualization; 3D flow field; 3D streamline; Application examples; Color features; GPU implementation; Irregular flow field data; Princeton ocean model; Tetrahedral grids; Data visualization",2-s2.0-85015195158
"Roels R., Meştereagă P., Signer B.","An interactive source code visualisation plug-in for the mindxpres presentation platform",2016,"Communications in Computer and Information Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959241861&doi=10.1007%2f978-3-319-29585-5_10&partnerID=40&md5=ceed7760dc9dec187a30f0422b3126cc","Nowadays, the teaching of programming concepts and algorithms is often conducted via slideware such as PowerPoint or Keynote, with the instructor going through a sequential series of slides showing static pieces of program code. As outlined in this paper, such a slidewarebased approach has its limitations in terms of the authoring as well as the delivery of content for a programming course. Nevertheless, there is a rich body of research on how to best teach programming concepts and algorithms where it has been shown that this process very much depends on the mental models developed by scholars when learning how to program. Based on this existing body of research, we derived a number of requirements for an improved source code visualisation and presentation in slideware tools. We present an interactive source code visualization plug-in for the MindXpres presentation platform, which addresses these requirements and introduces a number of innovative concepts for an interactive visualisation of source code. Based on two concrete examples showing how our solution can be used for the teaching of recursion by means of a recursion tree or to explain sorting algorithms by using animation, we illustrate the extensibility and flexibility of the presented interactive source code visualisation approach. Ultimately, the presented solution should help in reinforcing a student’s mental model about a presented algorithm and improve the knowledge transfer of presentations delivered in programming courses. © Springer International Publishing Switzerland 2016.","Presentation-based teaching; Programming; Slideware","Algorithms; Codes (symbols); Cognitive systems; Computer programming languages; Curricula; E-learning; Education computing; Knowledge management; Mathematical programming; Visualization; Interactive visualisation; Knowledge transfer; Programming concepts; Programming course; Slideware; Sorting algorithm; Source code visualizations; Teaching-of-programming; Teaching",2-s2.0-84959241861
"Vauderwange O., Wozniak P., Javahiraly N., Curticapean D.","A blended learning concept for an engineering course in the field of color representation and display technologies",2016,"Proceedings of SPIE - The International Society for Optical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006952946&doi=10.1117%2f12.2237612&partnerID=40&md5=bb4dda0f5cb3be8b3fda03dc029ad64b","The Paper presents the design and development of a blended learning concept for an engineering course in the field of color representation and display technologies. A suitable learning environment is crucial for the success of the teaching scenario. A mixture of theoretical lectures and hands-on activities with practical applications and experiments, combined with the advantages of modern digital media is the main topic of the paper. Blended learning describes the didactical change of attendance periods and online periods. The e-learning environment for the online period is designed toward an easy access and interaction. Present digital media extends the established teaching scenarios and enables the presentation of videos, animations and augmented reality (AR). Visualizations are effective tools to impart learning contents with lasting effect. The preparation and evaluation of the theoretical lectures and the hands-on activities are stimulated and affects positively the attendance periods. The tasks and experiments require the students to work independently and to develop individual solution strategies. This engages and motivates the students, deepens the knowledge. The authors will present their experience with the implemented blended learning scenario in this field of optics and photonics. All aspects of the learning environment will be introduced. © 2016 SPIE.","Active learning; Blended learning; Education; Education in optics and photonics; Hands-on optics","Augmented reality; Computer aided instruction; Curricula; Digital storage; Display devices; Education; Field emission displays; Students; Teaching; Technical presentations; Active Learning; Blended learning; Design and Development; Display technologies; E-learning environment; Education in optics; Hands-on optics; Learning environments; Engineering education",2-s2.0-85006952946
"Dingli A., Mifsud N.","Holographic humans",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978803905&doi=10.1007%2f978-3-319-39907-2_28&partnerID=40&md5=9e2df679eaa6d5af568e6e479f88e003","Over the last few years, holographic technology has been made readily available. This modern technology may have various applications ranging from medical, cultural, educational and communication industries. Focusing on the three latter industries, the main aim of this project is to create virtual agents to behave in a believable manner and display them within a three dimensional model of local megalithic temple ‘Hagar Qim’ in a museum context. These holographic humans are not only visually appealing with clear animations but also behave in a psychologically sound and autonomous manner, matching our expectations of what life was like in those times. Believability is a cornerstone within Artificial Intelligence and consequently, in order to achieve such a high degree of autonomy and believability, the holographic humans developed in this work are self-determined with their own reactive plan of actions to organise their daily routines. In order to produce such believable behaviour, computational motivation models based on psychological theories from natural intelligence are explored. Furthermore, visitors are able to interact with the holographic humans in order to get a clearer picture of life in prehistoric times and witness the diverse personalities and interests of the humans. Finally, the system was tested empirically by a number of people and questionnaires were filled in order to test the subjective concept of believability of the system as a whole. Highly positive feedback was generated with a 96% believability rate and an 80% agreement that this platform would be suitable in a museum context. The designed system manifested believable daily routines which visitors were able to relate to as the humans planned their activities just like any ordinary person would having time to be productive and make the most of a day whilst also adhering to biological needs such as thirst and hunger as well as sleeping when dusk falls upon the virtual environment. Therefore, artificially intelligent holographic humans were created to serve as an interactive educational platform. © Springer International Publishing Switzerland 2016.",,"Artificial intelligence; Computation theory; Feedback; Holography; Human computer interaction; Museums; Surveys; Communication industry; Degree of autonomy; Educational platforms; Holographic technology; Modern technologies; Natural intelligence; Psychological theory; Three-dimensional model; Virtual reality",2-s2.0-84978803905
"Alrajhi M., Alam Z., Khan M.A., Alobeid A.","Influence of GSD for 3d city modeling and visualization from aerial imagery",2016,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978081658&doi=10.5194%2fisprsarchives-XLI-B3-561-2016&partnerID=40&md5=378bda2ff260d6caecf7cbf823b16b96","Ministry of Municipal and Rural Affairs (MOMRA), aims to establish solid infrastructure required for 3D city modelling, for decision making to set a mark in urban development. MOMRA is responsible for the large scale mapping 1:1,000; 1:2,500; 1:10,000 and 1:20,000 scales for 10cm, 20cm and 40 GSD with Aerial Triangulation data. As 3D city models are increasingly used for the presentation exploration, and evaluation of urban and architectural designs. Visualization capabilities and animations support of upcoming 3D geo-information technologies empower architects, urban planners, and authorities to visualize and analyze urban and architectural designs in the context of the existing situation. To make use of this possibility, first of all 3D city model has to be created for which MOMRA uses the Aerial Triangulation data and aerial imagery. The main concise for 3D city modelling in the Kingdom of Saudi Arabia exists due to uneven surface and undulations. Thus real time 3D visualization and interactive exploration support planning processes by providing multiple stakeholders such as decision maker, architects, urban planners, authorities, citizens or investors with a three - dimensional model. Apart from advanced visualization, these 3D city models can be helpful for dealing with natural hazards and provide various possibilities to deal with exotic conditions by better and advanced viewing technological infrastructure. Riyadh on one side is 5700m above sea level and on the other hand Abha city is 2300m, this uneven terrain represents a drastic change of surface in the Kingdom, for which 3D city models provide valuable solutions with all possible opportunities. In this research paper: influence of different GSD (Ground Sample Distance) aerial imagery with Aerial Triangulation is used for 3D visualization in different region of the Kingdom, to check which scale is more sophisticated for obtaining better results and is cost manageable, with GSD (7.5cm, 10cm, 20cm and 40cm). The comparison test is carried out in Bentley environment to check the best possible results obtained through operating different batch processes.","3D City Modelling; DSM; GSD; Mesh Point; Oblique Imagery; Orthophoto; Stereopairs; Wire Frame","Aerial photography; Architectural design; Architecture; Batch data processing; Decision making; Planning; Remote sensing; Sea level; Surveying; Triangulation; Urban growth; Urban planning; Visualization; Mesh points; Oblique Imagery; Ortho photos; Stereopairs; Wire frames; Three dimensional computer graphics",2-s2.0-84978081658
"Bechter C., Swierczek F.","Authentic storytelling in a blended learning environment",2016,"Proceedings of the European Conference on e-Learning, ECEL",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000730382&partnerID=40&md5=d6ddae1345bdddd83f5b1e015f65d924","Engaging students in a blended learning environment can take many formats. Amongst them are collaborative projects that are based on real experiences. Authentic stories should center on a common theme, in our case cross-cultural encounters. The objective was to teach the concepts of cultural intelligence and cultural distance in an innovative way. Six classes of an Executive MBA programme had to create authentic stories and illustrate them by means of animation or other forms of digitalisation. In total 202 digital stories were analysed in our research. We looked at the technical implementation and also at the content in form of participating cultures, gender, theories and outcomes. The stories were accompanied by a questionnaire to assess the characters (actors) of the story. It was based on relevant cross-cultural and negotiation frameworks in order to guide the discussion of the results in a meaningful direction. The analysis of the outcomes, which served as starting point for online class discussion, suggest that cultural intelligence in form of willingness to adjust during a negotiation is a predictor for a successful outcome. Even more important is a humane orientation which can also be described as relationship or affiliation with attributes such as modesty and caring. Performance orientation is the strongest predictor of all. From a technical perspective, findings suggest that social networking platforms are more suitable than standard LMS for communication. Students rated the usefulness of the authentic project for their learning on average as 6.7 on a scale 1- 7. At the end of our paper we suggest 'Sequence and Timeframe' of such project. © The Authors, 2016.","Authentic storytelling; Blended learning; Cultural distance; Cultural intelligence","Authentic storytelling; Blended learning; Blended learning environments; Collaborative projects; Cultural distance; Cultural intelligence; Negotiation framework; nocv2; Technical implementation; Computer aided instruction",2-s2.0-85000730382
"Ismail I., Sunar M.S., Kolivand H.","Motion deformation style control technique for 3D humanoid character by using MoCap data",2016,"Jurnal Teknologi",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960156267&doi=10.11113%2fjt.v78.6926&partnerID=40&md5=842d84b7f5188dc007d6f2a19f8b58bb","Realistic humanoid 3D character movement is very important to apply in the computer games, movies, virtual reality and mixed reality environment. This paper presents a technique to deform motion style using Motion Capture (MoCap) data based on computer animation system. By using MoCap data, natural human action style could be deforming. However, the structure hierarchy of humanoid in MoCap Data is very complex. This method allows humanoid character to respond naturally based on user motion input. Unlike existing 3D humanoid character motion editor, our method produces realistic final result and simulates new dynamic humanoid motion style based on simple user interface control. © 2016 Penerbit UTM Press. All rights reserved","3D humanoid character; Key pose control; Motion deformation",,2-s2.0-84960156267
"Prima D.A., Hariadi M., Purnama I.K.E., Usagawa T.","Virtual camera movement with particle swarm optimization and local regression",2016,"International Review on Computers and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006725009&doi=10.15866%2firecos.v11i9.9801&partnerID=40&md5=b6f153102cdc6974debbf1d34f1ea823","Manually placing and animating virtual camera in a dynamic virtual environment to generate computer animation is a complex and time-consuming process. For this reason, this paper proposes a method to take the sequential shot by gameplay, to determine the best camera placement candidates as an unorganized point set, to reconstruct a curve by the point set using local regression technique and to generate smooth camera movement based on those curves. Finally, the paper presents the application of this algorithm and it analyzes a number of problems in different dynamic virtual environments. © 2016 Praise Worthy Prize S.r.l. - All rights reserved.","Dynamic environments; Gameplay; Virtual camera; Virtual cinematography",,2-s2.0-85006725009
"Chang X., Yi P., Zhang Q.","Skey frames extraction from human motion capture data based on hybrid particle swarm optimization algorithm",2016,"Studies in Computational Intelligence",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966479903&doi=10.1007%2f978-3-319-31277-4_29&partnerID=40&md5=4e3551f73d7b4d5dbf2021cb1ca04414","Extracting key frames from human motion capture data is a hot issue of computer animation in recent years. Though the reconstruction error of the key frames by current methods is small, the number of key frames still needs to be reduced. In order to produce results with less key frames and small reconstruction error, we propose a method employing hybrid particle swarm optimization algorithm to extract key frames. By introducing evolution strategy of Genetic Algorithm (GA) to hybrid particle swarm optimization algorithm, the method can get key frames with optimal compression ratio and small reconstruction error. Experimental results show the effectiveness of our method. © Springer International Publishing Switzerland 2016.","Compression ratio; Hybrid particle swarm optimization algorithm; Key frames; Reconstruction error",,2-s2.0-84966479903
"Neupert R.","John Lasseter",2016,"John Lasseter",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032070234&partnerID=40&md5=2b8fd2358f8827df6c76387f9b607d89","Celebrated as Pixar's ""Chief Creative Officer,"" John Lasseter is a revolutionary figure in animation history and one of today's most important filmmakers. Lasseter films from Luxo Jr. to Toy Story and Cars 2 highlighted his gift for creating emotionally engaging characters. At the same time, they helped launch computer animation as a viable commercial medium and serve as blueprints for the genre's still-expanding commercial and artistic development. Richard Neupert explores Lasseter's signature aesthetic and storytelling strategies and details how he became the architect of Pixar's studio style. Neupert contends that Lasseter's accomplishments emerged from a unique blend of technical skill and artistic vision, as well as a passion for working with collaborators. In addition, Neupert traces the director's career arc from the time Lasseter joined Pixar in 1984. As Neupert shows, Lasseter's ability to keep a foot in both animation and CGI allowed him to thrive in an unconventional corporate culture that valued creative interaction between colleagues. The ideas that emerged built an animation studio that updated and refined classical Hollywood storytelling practices--and changed commercial animation forever. © 2016 by the Board of Trustees of the University of Illinois. All rights reserved.",,,2-s2.0-85032070234
"Ye X., Zhang J., Li P.","An efficient rotational matrix extraction scheme for finite element method-based deformation",2016,"International Journal of Mechatronics and Automation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019711650&doi=10.1504%2fIJMA.2016.084213&partnerID=40&md5=2284c55064723116e1666dfa2ee48c22","With the development of computer science and mechanical engineering, advanced and stable soft tissue deformation modelling methods have been employed, such as mass-spring model, finite element method and meshless method. The co-rotational finite element method (co-rotational FEM), which was first introduced in physics-based computer animations, has shown its strengths to be a feasible approach to modelling the process of soft tissue deformation in a virtual surgery simulation system. In this study, we mainly investigated the method of extracting the rotational matrix which is used to perform stiffness warping assembly at each simulation time step. We first introduced and compared the time-consuming polar decomposition method and the efficient QR decomposition method, and then our hybrid rotational matrix extraction method is described. The final experimental results show that our efficient rotational matrix extraction method can improve the computation efficiency greatly without deformation accuracy losing. © 2016 Inderscience Enterprises Ltd.","Co-rotational FEM; Rotational matrix extraction; Soft tissue deformation; Virtual surgery",,2-s2.0-85019711650
"Miyaji I.","Change of attitude in class for creating slides to present product",2016,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956681654&doi=10.1007%2f978-3-319-28883-3_22&partnerID=40&md5=6a84732e3a227e748e81e1335b9effe3","The creation of product presentation slides using PowerPoint was implemented in order to ensure that students acquire the knowledge and information required to use computers. Students created slides presenting products in which they were interested, inserting animation and recording narration. This class combined evaluation and revision activities and implemented active learning and, along with enhancing computer skills, awareness relating to a variety of skills required for problem solving were enhanced in an attempt to cultivate independent thinking skills. In particular, the aim was not only to enhance PowerPoint skills but also to improve expressiveness, planning ability and ability to make proposals. This paper reports on the class to create product presentation slides, its contents and its learning effects. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2016.","Creation of slides; Evaluation activities; Higher education; Problem-solving ability; Product presentation; Revision activities","Artificial intelligence; Education; Online systems; Personnel training; Problem solving; Students; Creation of slides; Evaluation activity; Higher education; Problem-solving abilities; Product presentations; Revision activities; E-learning",2-s2.0-84956681654
"Kuroda T., Kuroda K.","A nystagmus and head-position recording system using a USB infrared camera and a motion sensor device",2016,"Practica Oto-Rhino-Laryngologica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965013734&partnerID=40&md5=fdda1ab95a78e993d2125df5cb8e6720","In a nystagmus test under an infrared camera, nystagmus images are not only observed on monitors but also stored in video devices, etc. When they are saved as video images, it is very important to find a way to record the information of the head positions on the video. We developed a videonystagmography system with head-position recording embedded in it: a USB infrared camera and a motion sensor device are attached to a pair of goggles made by a 3D printer and then the goggles are connected to a computer with a USB cable: the data generated by the sensor create head animation which is correlated with the nystagmus images using the software that we developed. Herein we report on the system in our clinic which is much lighter in weight and significantly more portable than the existing head-position recording system produced by medical equipment manufacturers because no power supply is required if it is used with a portable computer.","Head-position; Motion sensor; Nystagmus; USB infrared camera",,2-s2.0-84965013734
"Diwakar S., Radhamani R., Sasidharakurup H., Kumar D., Nizar N., Achuthan K., Nair B.","Assessing students and teachers experience on simulation and remote biotechnology virtual labs: A case study with a light microscopy experiment",2016,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956651833&doi=10.1007%2f978-3-319-28883-3_6&partnerID=40&md5=c8544cec486d9027099586235bf9653d","With recent trends of using Information and Communication Technologies in education, virtual labs have become more prevalent in classrooms of most schools and universities, especially in South India. The purpose of this paper was to perform a comparative analysis of virtual learning components such as animations, simulations and real-time remotely controlled experiments. As a part of this study, we conducted a series of biotechnology virtual lab workshops for University-level users within India and collected feedback related to the usage of virtual labs via direct approach. The survey amongst the students and teachers suggested simulation-based labs were more preferred in enhancing teaching and learning strategy compared to graphics-mediated animations and remotely controlled experiments. This paper also reports some of the issues faced by virtual lab users. Studies indicated that even though the web-based technologies are a new venture in education, it still poses adaptability issues. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2016.","Biotechnology; Feedback; Remote labs; Simulation; Virtual labs","Biotechnology; Distance education; Education; Educational technology; Engineering education; Feedback; Laboratories; Online systems; Students; Teaching; Comparative analysis; Controlled experiment; Information and Communication Technologies; Remote labs; Simulation; Teaching and learning strategy; Virtual lab; Web-based technologies; E-learning",2-s2.0-84956651833
"Montes J.C., López-García R., Dorado-Vicente R., Trujillo F.J.","Mock-up of an eighteenth-century oil mill via rapid-prototyping",2016,"History of Mechanism and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978704821&doi=10.1007%2f978-3-319-31184-5_7&partnerID=40&md5=a7241b7002f1c70a4f6ffa9b1e107193","Information technologies and Computer Aided Engineering (CAE) programs open new ways for conservation, documentation and study of out of date mechanisms. Resulting virtual animations and numerical simulations help to understand and recover our industrial heritage. Currently, get a mock-up from a virtual model is easier and cheaper thanks to low cost rapid prototyping techniques. These scaled models give a more vivid experience of a mechanism and its performance. This paper describes a methodology to obtain a mock-up of an XVIII century oil mill, part of the historical heritage of Fondón (Almeria, Spain). We digitalized the mill components in CAD software using field measurements, got a CNC code to print them on a Fused Deposition Modelling (FDM) machine, and printed and assembled the mill. © Springer International Publishing Switzerland 2016.","3D printing; Geometric modelling; History of machines and mechanisms",,2-s2.0-84978704821
"Duarte A., Soares J., Medeiros L., Silva J., Landau L., Borges I., Raposo G.","Characterization of carbonate rocks' porous space using X-ray microtomography",2016,"78th EAGE Conference and Exhibition 2016: Efficient Use of Technology - Unlocking Potential",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020203449&partnerID=40&md5=7097839d7df8adcd52ba18fdea6dc5c3","Digital Rock Physics (DRP) is a nondestructive technique that enables the rock physic properties quantification and characterization. The method is based on the x ray absorption from each material, depending on the material density and the chemical components. Tomography methods are commonly used by medicine, but their application is coming together with geosciences since their discovery. The cross sections coming from the gray scale, can be edited by many ways, depending on the study object. The sections integrations obtained by this method, allows a 3D projection by the material used. The image processing is made by computer systems to obtain qualitative and quantitative results quickly and efficiently. In this computer system can be generated graphics and animations which facilitate the sample viewing or only a selected absorption phase in the material. Through this stage develops a job that was applied to compute microtomography technique of X-ray mainly focused on the pores tortuosity study in carbonate rocks. In this way, assist in the investigation of potential reservoirs. The data obtained by this technique is integrated and compared with petrophysical analyzes in a laboratory.",,,2-s2.0-85020203449
"Kotluk N., Kocakaya S.","Researching and evaluating digital storytelling as a distance education tool in physics instruction: An application with pre-service physics teachers",2016,"Turkish Online Journal of Distance Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964691154&doi=10.17718%2ftojde.59900&partnerID=40&md5=6a2533a0be2dc2a1cf224c927440a640","Advances in information and communication technology in 21st century have led to changes in education trends and today new concepts such as computer, multimedia, audio, video, animation and internet have become an indispensable part of life. The storytelling is the one of approach which is allowed to using technology in educational field. The aim of this study is to define the use of digital storytelling in physics instruction as a distance education tool. In this respect, the literature related to digital storytelling was analyzed and for applying it in practice, 13 pre-service teachers from department of physic education were trained on digital storytelling for 6 weeks in spring term of 2013- 2014 academic year. Following the process of instruction, pre-service teachers created and shared digital stories in YouTube and evaluated all of them. Furthermore, opinions of the pre-service teachers were asked on digital story telling As a result of the analysing the DST videos and opinions of pre-service teacher, it is expected that using digital storytelling as distance education tool will be efficacious.","Digital storytelling; Distance education; Internet-based learning; Physics instruction",,2-s2.0-84964691154
"Stepanov A.V., Fedorov V.A., Vorobyeva J.A., Marakulina U.E., Ovchinnikov V.I.","Global design as the integral person formation strategy",2016,"International Journal of Environmental and Science Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994175703&partnerID=40&md5=9aa9875247bef4253ef71ff6942c3153","The relevance of the problem under study is based on the society's need for educating an integral person who is able to solve ecumenical project tasks. Currently this problem (as natural order from the society) is emerging in the educational system and social practices but has yet to obtain substantial scientific and theoretical justification. The purpose of the article is to initiate the theoretical-practical aspect of the educational activity towards educating a designer who is thinking and acting integrally at the early stages of professional development. The lead method for studying this problem is historical monitoring of a person’s project practice which provides the possibility to examine project processes within the context of their holistic dimension and to configure the hypothesis on the necessity of changes in the educational system. The article presents the prognostic idea, which is supported by the historical facts, that it would be necessary and effective for the educational system to depart from the practice of niche specialization in training of designers at the early stages of their professional development; it also contains the conceptual definition of and the proposal for a model of educating an universal (integral) designer within the instrumental (tool) framework of animation, computer, object and other modeling technologies which provides a practical effect for the educational system (of general, pre-vocational and vocational education). The article can be useful for innovation-thinking sponsor of educational processes, theoreticians of design and pedagogy, practitioners of design, teachers of design at higher, secondary and general educational institutions, as well as for philosophers, cultural studies scholars, sociologists, psychologists and other researchers. © 2016 Stepanov et al.","Globality in design; Humanization of education; Integral design; Universal designer",,2-s2.0-84994175703
"Velkova J.","Open cultural production and the online gift economy: The case of Blender",2016,"First Monday",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996671430&doi=10.5210%2ffm.v21i10.6944&partnerID=40&md5=c6b9d28f419ef6b4665bfdda40d5be77","The economies of the Internet are largely driven by sharing. Much of it is often veiled in a celebratory discourse that emphasizes how sharing artifacts online through gift exchanges removes hierarchies and creates broader access to public knowledge, such as in projects of free culture and open source software development. The article critically interrogates these assumptions and the gift economy of open cultural production more generally. Using a practice called open source animation film making, developed by Blender, an organisation at the core of the largest open source 3D computer graphics community, this paper shows that the discourse surrounding free culture online has largely misunderstood the complexity and ambiguities of the economy below the cultural politics of openness. With the help of classical theories of gift and value I discuss issues of debt, obligation, status, discipline, and social hierarchies created by exchanging online a variety of digital artifacts of different value, such as software, culture, and labor. This article shows that the wealth of open cultural production relies on combining multiple dimensions of gifting with fiscal and hidden forms of capital, producing a culture of secrecy in parallel to that of openness.",,,2-s2.0-84996671430
"Ocepek U., Rugelj J., Šerbec I.N., Bosnić Z.","Combining learning style models and alleviating the new user problem in learning recommender systems",2016,"Learning Styles and Strategies: Assessment, Performance and Effectiveness",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022057555&partnerID=40&md5=5548ba11043171241a072a336e034772","Adaptive computer-based multimedia learning environments support the idea that people learn better and more deeply when appropriate images (i.e., animations, video, static graphics) are included with text or narration. Adaptive learning environments mostly support only traditional concepts of learning. Development in the field of cognitive science now indicates the need for design and development of e-learning systems that are based on constructivist learning approach. Recommender systems, which suggest items of interest to a student based on his properties, preferences, and activities, can be the appropriate solution. In this paper, we present a concept of such a learning recommender system that combines knowledge from pedagogy and recommender systems, and analyze how combining of four different learning style models (cognitive styles, epistemic styles, hemispheric styles, and perceiving styles) influences the choosing preferred types of multimedia materials. We present a decision model intended for predicting an appropriate multimedia type of learning material for each individual student. The results show that students prefer well-structured learning texts with color discrimination, and that the hemispheric learning style model is the most important criterion in deciding student preferences for different multimedia learning materials. In the second part of our research, we describe an approach for improving recommendation performance in environments where the system has no prior information about learners. As a combination of findings of our research, we outline the concept of a learning system and explain its possible positive effects in practice. © 2016 Nova Science Publishers, Inc.","Adaptive learning environments; Learning styles models; New user problem; Recommender systems",,2-s2.0-85022057555
"Avci Z.Y., Eren E., Kapucu M.S.","Practical tools for content development: Pre-service teachers experiences and perceptions",2016,"International Journal of Instruction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980378786&doi=10.12973%2fiji.2016.922a&partnerID=40&md5=f249900189cf79f4eb8f387baf2d57e2","This study adopts phenomenology approach as the research design method to investigate pre-service teachers experiences and perceptions on using practical tools for content development. The participants are twenty-four pre-service teachers who were taking Computer II course during 2013-2014 spring semester at a public university in Turkey. During the course, they were introduced several practical tools, which we define as mostly internet-based technologies that do not require installation or having any computer programming skills. Pre-service teachers prepared contents specific to their fields for homework and projects. At the end of the semester individual interviews were conducted with the participants. Content analysis method was used to analyze the data. According to the results, they enjoyed creating contents using these tools. At the same time, they had some difficulties. Majority of the participants perceive presentation, animation, cartoon creation tools to be most beneficial to improve student learning. Some of the positive outcomes they foresee when these technologies are used in the classroom are: higher student engagement, active participation, reinforcement, deeper understanding, and development of imagination skills. It is believed that the findings of this study will contribute to the development of teacher preparation programs for effective use of technology especially for content development.","Content development; Experience; Perception; Practical tools; Pre-service teachers; Web 2.0",,2-s2.0-84980378786
"Tataru D., Toma-Danila D., Nastase E.","Seismic mitigation through education: The MOBEE (mobile earthquake exhibition) experience",2016,"International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994154356&doi=10.5593%2fSGEM2016%2fB53%2fS22.126&partnerID=40&md5=74e25cc7715fa3bfdb107082fab051ba","In order to remain essential cultural and educational institutions, exhibitions and museums need to adapt to the times we live in and to the pace of technology and human interests. Through this paper we present our own experience and research in developing a state-of-the art earthquake related exhibition that meets the demands of our times and efficiently addresses a large and diverse target audience. The MOBEE (MOBile Earthquake Exhibition) Project tackles a very problematic topic in regard to the present and future of Romania: the key role of education, in the perspective of a future major earthquake. The project is the only initiative of this kind in Romania, a country where the lessons of previous destructive earthquakes (of 1940 and 1977) seem to be neglected. One of the main goals of the exhibition is to provide a reliable, attractive and up-to-date source of information regarding earthquakes, leading to mitigation by education. The initiative translates modern approaches into science, arts and computer science into end-products with a direct impact in forming (awakening) and developing the interest for earth science. We provide an insight on how and why new technologies and concepts like large scale 3D printed maps and models, digital animations and app development, hands-on experiments or flexible content were put to use. We hope that by sharing our experience we can help and stimulate other similar initiatives and propagate the mobile exhibition concept, as form of reaching the nowadays audiences (beside the online environment, which we also cover). © SGEM2016.","Earthquake; Education; Museum experience; Outreach","3D printers; Earthquakes; Education; Geophysics; Direct impact; Educational institutions; End-products; Online environments; Outreach; Seismic mitigation; State of the art; Target audience; Exhibitions",2-s2.0-84994154356
"Lakshmi T.G., Narayana S., Prasad P., Murthy S., Chandrasekharan S.","Geometry-via-gestures: Design of a gesture based application to teach 3D geometry",2016,"ICCE 2016 - 24th International Conference on Computers in Education: Think Global Act Local - Workshop Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018979929&partnerID=40&md5=66e992ab5272e3de024ea3c557544c60","Geometry holds a special place in Mathematics. Learning of Geometry requires understanding and integrating a wide range of topics such as coordinates, shapes, theorems, proofs, properties and formulae, to name a few. In 3D geometry, students find difficult the manipulation of 3D objects and interpreting their structure and properties, such as volume and surface area. Research shows that students mainly focus on the formulae and the numerical operations to calculate the volume or the surface area of a 3D object, and not on visualizing the 3D objects. Various media such as images, animation, simulations and 3D geometric software have been used to help learners visualize 3D shapes. However, the affordances provided by these media do not fully support the construction and manipulation of 3D objects. Based on an embodied interaction approach, we have designed a gesture-based application for high school students to learn the properties of 3D objects. In this paper, we describe the design of the application, ""Geometry-via-Gestures"" (GvG), which enables learners to construct a right circular cylinder using gestures and derive its volume. We present the results of the first prototype pilot and the proposed redesign. Copyright 2016 Asia-Pacific Society for Computers in Education. All rights reserved.","3D geometry; 3D property; Embodied cognition; Gestures","Circular cylinders; Education; Students; 3D geometry; 3D property; Embodied cognition; Embodied interaction; Gestures; High school students; Numerical operations; Structure and properties; Geometry",2-s2.0-85018979929
"Ortwein A., Graw V., Heinemann S., Menz G., Schultz J., Selg F., Rienowg A.","Beyond the pixel - Interdisciplinary Earth observation education from the ISS in schools",2016,"Proceedings of the International Astronautical Congress, IAC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016466167&partnerID=40&md5=2429001f0f811bcb304462632603e8eb","""Man must rise above the Earth - to the top of the atmosphere and beyond - for only thus will he fully understand the world in which he lives"". This famous quote by Socrates anticipates the importance of space travels and earth observation techniques for research on coupled human-environment systems. There is an undoubtedly wide-spread use of remote sensing techniques and image processing analyses for scientific and societal purposes such as weather forecasting, ecological monitoring, or disaster management. Nevertheless, applying earth observing products in everyday school lessons is rare and narrowed only to a visual supplement. The project 'Columbus Eye - Live-Imagery from the ISS in Schools' aims at the sustainable integration of earth observation in schools. Columbus Eye is sponsored by the German Aerospace Center (DLR) Space Administration and acts as the exclusive European partner of NASA's High Definition Earth Viewing (HDEV) experiment, which features four cameras on the International Space Station (ISS) observing the earth 24/7. During the IAC 2015, we presented the implementation of a concept on how the fascination of technology and environment can be bundled in order to ignite the pupil's interest on space flight and earth observation. The corresponding learning portal (www.columbuseye.uni-bonn.de) provides a live-stream to observe our earth from the astronaut's perspective while applying professional remote sensing analysis tools. Following up on this, we are proud to present the extensions of the interactive learning materials. The e-learning section now comprises three kinds of interactivity: working sheets, classification tools, and comprehensive teaching units. The paper explains how geographic information applications build the canvas for explaining physical and mathematical curricular knowledge. Background information, quizzes, and informative animations encourage pupils to solve a given problem on their own virtue in order to foster their methodological competences. Finally, the contribution presents the shift of the didactical paradigm from computer aided e-learning to smartphone supported m-learning. Regular topographic maps are augmented by the fascinating views from above. Hence, the tangible dimensions of pens papers are virtually lifted into the fascinating environment of space. Copyright © 2016 by the International Astronautical Federation (IAF). All rights reserved.","Augmented reality; Earth observation; Education; HDEV experiment; ISS; Media literacy",,2-s2.0-85016466167
"Lee X.S., Khamidi M.F., See Z.S., Lees T.J., Chai C.","Augmented reality for ndimensional building information modelling: Contextualization, Customization and Curation",2016,"Proceedings of the 2016 International Conference on Virtual Systems and Multimedia, VSMM 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016005025&doi=10.1109%2fVSMM.2016.7863152&partnerID=40&md5=bf155d60b38075fddedfacdff70d2d62","This paper presents an experimental method and apparatus of augmented reality (AR) for nDimensional (nD) building information modeling (BIM). BIM allows nD information to be visualized simultaneously by architects, engineers and constructors to gain a synchronized understanding viewing from different perspectives. However, BIM is conventionally being operated on a desktop-based computer which makes collaboration less flexible, and it also creates an isolation gap between the model and reality. This isolation gap does not severely affect experienced and skilled professionals, as they can bridge the isolation gap with their intuition developed over the years. Nevertheless, users who are lack of such experience will feel the isolation gap between the digital realm and practicable reality, which could be the hurdle in project participation and decision making. AR allows virtual content to be mixed with real environment for user experience. In the context of our study, AR is functional to present the nD information of BIM, at the same time retaining users' connection with the reality. It is not just being utilized solely for presentation, but also to maximize the potential for communication, interaction and experience. This pilot study investigates effective technological approach of using AR as an effective collaboration technology combining with BIM through proposed key aspects of contextualization, customization and curation. Contextualization is significant to enable users to understand the AR content by making the presented information meaningful to the target audience, implemented thru the means of 2D annotations, animations and options comparison. This study compares both AR BIM with and without contextualization. Customization can generate unique virtual environment and content for different level of users tailored to their needs and preference to create intuitive interaction with AR BIM. Curation is crucial to provide users with a reliable experience, and to formulate a continually improving AR BIM thru log data and users' feedback. All in all, this paper explores the major aspects of contextualization, customization and curation, to distinguish effective approach in the currently 'free for all' AR BIM development. Finally, an implication is provided for future study in terms of balance in information sufficiency and complexity for AR BIM. © 2016 IEEE.","augmented reality; building information modelling; contextualization; curation; customization","Augmented reality; Decision making; Information theory; Virtual reality; Building Information Model - BIM; Building Information Modelling; Collaboration technology; Contextualization; Curation; customization; Experimental methods; Intuitive interaction; Architectural design",2-s2.0-85016005025
"Laurijssen D., Truijen S., Saeys W., Steckel J.","Three sources, three receivers, six degrees of freedom: An ultrasonic sensor for pose estimation & motion capture",2015,"2015 IEEE SENSORS - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963500416&doi=10.1109%2fICSENS.2015.7370689&partnerID=40&md5=f5b71d855ffb6e644edc6e1e64781993","Motion capture systems have become a common utility in a wide variety of fields and rely on various underlying principles to estimate the pose of one or multiple mobile objects. The most popular applications for pose estimation systems can be found in the entertainment sector where it is used for computer animation purposes or in sports for performance measurements. These systems present millimeter accuracy but also come with a high cost. We wish to reduce the cost of such a motion capture system while retaining the high accuracy by using an embedded ultrasonic measurement system. The proposed system comprises of one or multiple mobile nodes containing a small microphone array (at least 3 microphones) which receives multiple simultaneously emitted coded and broadband ultrasonic transmissions from at least three fixed transmitters. Using this technique, the complete pose (six degrees-of-freedom) of every mobile sensor can be estimated while retaining the low-cost aspect of the system. Motion capture systems which combine low cost with high accuracy open many new fields of application such as physiotherapy practices. © 2015 IEEE.","Motion Capture; Sensor Arrays; Ultrasonics","Animation; Costs; Electric arc welding; Mechanics; Microphones; Sensor arrays; Ultrasonic applications; Ultrasonics; Computer animation; Microphone arrays; Motion capture; Motion capture system; Performance measurements; Six degrees of freedom; Ultrasonic measurement systems; Underlying principles; Degrees of freedom (mechanics)",2-s2.0-84963500416
"Diaz L.M., Gaytan-Lugo L.S., Fleck L.","Profiling styles of use in Alice: Identifying patterns of use by observing participants in workshops with Alice",2015,"Proceedings - 2015 IEEE Blocks and Beyond Workshop, Blocks and Beyond 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964799947&doi=10.1109%2fBLOCKS.2015.7368994&partnerID=40&md5=e1106aaed027c6b94ef631648f8f8d6f","During workshops on computer animation using Alice, a free platform for three dimensional computer animation created by Carnegie Mellon University, we detected and observed a series of different patterns of use of the platform by attendants. Most participants would start following instructions as precisely as possible. Within a short time some would divert to create visually attractive scenes worrying little about movement and action, others would put two or more characters in the scene and make them talk telling a story, and a fourth group would explore by their own advanced features and functions of Alice well beyond the content of the workshop creating complex and action-rich animations. As these styles kept appearing in every event, a more systematic observation was attempted by designing a form for observers and a survey for participants. Although we have had only one opportunity to test our instruments, we believe that the study is worth continuing and the results may turn revealing not only for Alice but for other block programming environments. In this article we describe the styles observed and the instruments designed for observation. The preliminary results are also discussed. © 2015 IEEE.","Alice; Computer Animation; First Programming Environments; Styles of Use","Animation; Computer programming; Surveys; Alice; Block programming; Carnegie Mellon University; Computer animation; Programming environment; Styles of Use; Microcomputers",2-s2.0-84964799947
"Santika W.G., Sudiartha I.K.G., Putra I.G.P.M.E.","Using animated social feedback to motivate air conditioning energy saving",2015,"Proceedings 2015 International Conference on Science and Technology, TICST 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963655382&doi=10.1109%2fTICST.2015.7369333&partnerID=40&md5=644bd5c573692045549f1278764e94fd","In 2009, Midden & Ham found that social feedbacks motivated users to reduce energy consumption in washing experiments with a simulated washing machine. They also found that having negative social feedbacks reduced energy consumption better than having factual, positive social, and no feedbacks. The present study compares the effect of positive and negative social and factual feedbacks on user preferences in air conditioning (AC) temperature setting. A higher room temperature setting means a lower energy use. We predicted that having any of the feedbacks increased chosen temperatures compared to having no feedback and that having negative social feedbacks increased chosen temperatures compared to having either factual, positive social, or no feedbacks. An interface was made in order for the AC remote controller to be able to communicate with computers. Animated faces which are able to smile or frown were made representing positive and negative social feedbacks. The factual feedback is represented by a bar indicator that turns red when users choose low temperatures and green when high. 159 participants were asked to participate for the experiment and randomly assigned to either control, factual, positive, or negative feedback groups. A computer screen was put in front of respondents to display the animated feedbacks. Participants set their preferred AC temperature by means of a remote controller and the screen deliver feedbacks according to the chosen temperature. One-way ANOVA were used to analyze the data with temperatures as the dependent variable and feedbacks as independent variables. Results show that there was a significant effect of feedbacks on chosen temperatures, F(3, 153) = 20.96, p <.001, r =.54. There was a significant linear trend, F(1, 153) = 60.55, p <.001, r =.53, indicating that as the feedback changed from factual to positive and negative social, the temperature increased proportionally. Planned contrasts showed that having animated social feedbacks increased chosen temperatures compared to having no feedback, t(152) = 6.80, p <.001 (1-tailed), r =.39, and that having negative social feedbacks increased chosen temperatures compared to having positive social feedbacks, t(152) = 2.14, p .05 (1-tailed), r =.09. © 2015 IEEE.","Air conditioning; Animation; Energy conservation; Human-computer interaction; Persuasive technology; Social feedback","Air conditioning; Animation; Energy conservation; Energy utilization; Human computer interaction; Remote control; Telecontrol equipment; Washing; Air-conditioning energy savings; Dependent variables; Independent variables; Persuasive technology; Reduce energy consumption; Remote controllers; Social feedbacks; Temperature setting; Feedback",2-s2.0-84963655382
"Sayilgan M.E., Kaplanoǧlu E., Atasoy A., Kuchimov S., Özkan M.","Hand rehabilitation and prosthesis training interface [El Rehabilitasyon ve Protez Eǧitim Arayüzü]",2015,"2015 19th National Biomedical Engineering Meeting, BIYOMUT 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964089249&doi=10.1109%2fBIYOMUT.2015.7369433&partnerID=40&md5=fea864dd6bce94ad769430b79255f0c9","In this study, an interface is developed for the EMG reading glove for physical therapy patients. The purpose of the study is to make physiotherapy available anywhere with computer without the need to go to a therapy center. Physical therapist selects the exercises that fit to the user and sends the exercises to the exercise page of the program. User does the exercises using the wearable hand rehabilitation system. Program follows the user's movements, calculate success and generate a report. This program is developed on Visual Studio 2012 and is a continuous project of the »EMG Hand Rehabilitation and Support System». This process consists four phase, first is to make the exercise plan for the user, second is to demonstrate the exercises to the user, third are the readings of the user's hand movements, forth and the last phase is the animation and control. © 2015 IEEE.",,"Biomedical engineering; Patient treatment; Four-phase; Hand movement; Hand rehabilitation; Support systems; Visual studios; Physical therapy",2-s2.0-84964089249
"Hassani K., Lee W.-S.","Adaptive animation generation using web content mining",2015,"2015 IEEE International Conference on Evolving and Adaptive Intelligent Systems, EAIS 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964058484&doi=10.1109%2fEAIS.2015.7368804&partnerID=40&md5=90a6e7e1f763f8945262d515cf2462f2","Creating 3D animation is a labor-intensive and time-consuming process requiring designers to learn and utilize a complex combination of menus, dialog boxes, buttons and manipulation interfaces for a given stand-alone animation design software. On the other hand, conceptual simplicity and naturalness of visualizing imaginations from lingual descriptions motivates researchers for developing automatic animation generation systems using natural language interfaces. In this research, we introduce an interactive and adaptive animation generation system that utilizes data-driven techniques to extract the required common-sense and domain-specific knowledge from web. This system is capable of creating 3D animation based on user's lingual commands. It uses the user interactions as a relevance feedback to learn the implicit design knowledge, correct the extracted knowledge, and manipulate the dynamics of the virtual world in an active and incremental manner. Moreover, system is designed based on a multi-agent methodology which provides it with distributed processing capabilities and cross-platform characteristics. In this paper, we will focus on information retrieval agent which is responsible for extracting numeric data utilized in object attributes, spatiotemporal relations, and environment dynamics using web mining techniques. © 2015 IEEE.","computer animation; knowledge representation; natural language understanding; web mining","Animation; Computational linguistics; Feedback; Intelligent systems; Knowledge representation; Multi agent systems; Natural language processing systems; Virtual reality; Computer animation; Distributed processing; Domain-specific knowledge; Multi agent methodology; Natural language interfaces; Natural language understanding; Spatio-temporal relations; Web Mining; Data mining",2-s2.0-84964058484
"Takacs B., Csizinszky K., Mazzei D., Simon L.","A psychological framework to objectively evaluate socially capable robots for interactive tutoring systems",2015,"ICCAS 2015 - 2015 15th International Conference on Control, Automation and Systems, Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966312235&doi=10.1109%2fICCAS.2015.7364619&partnerID=40&md5=73db500b0e8b5de46cb66190f2948536","We introduce a novel evaluation methodology to establish psychometrically validated measures to objectively evaluate socially capable robots. Our methodology involves first creating a digital computer generated face model designed to replicate the facial expression space of the robot with the highest accuracy, and second, using this model to render test sequences, which are in turn analyzed with independent facial metrics software. We compared three different facial modelings techniques to approximate our robot's face and achieved 98.86% accuracy in replicating the facial appearance as measured by facial metric software. This digital face model can now be used to create arbitrary expressions for interaction purposes and for a more detailed analysis of low-amplitude micro-expressions, which are critical for proper social communication with children in a virtual tutoring context. We argue that our methodology is a first step towards objectively assessing the believability of commercially available robots. © 2015 Institute of Control, Robotics and Systems - ICROS.","FACE robot; Facial animation; Humanoid-robots; Psychological assessment; Virtual Tutors","Anthropomorphic robots; Digital computers; Distance education; Software testing; Face robot; Facial animation; Humanoid robot; Psychological assessment; Virtual tutors; Robots",2-s2.0-84966312235
"Radhamani R., Sasidharakurup H., Kumar D., Nizar N., Achuthan K., Nair B., Diwakar S.","Role of Biotechnology simulation and remotely triggered virtual labs in complementing university education",2015,"Proceedings of 2015 International Conference on Interactive Mobile Communication Technologies and Learning, IMCL 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962476283&doi=10.1109%2fIMCTL.2015.7359548&partnerID=40&md5=afe81aacb0bf723b9c6a9e6825db7a31","Blended learning has been popularized in many universities in the last decade due to the rapid advances in computer technologies and relative increase in the usage of internet connectivity. A major constraint in providing high quality laboratory resources in some universities and in economically challenged countries is high costs, training personnel, training time and maintenance-related issues. Virtual and remote labs complement the real laboratory resources with virtually defined techniques including simulations, animations, remote triggering of the actual equipment and videos that facilitate user interactions. Our goal was to analyze the effectiveness of biotechnology virtual labs in integrating learning process among school and university students of ages 12-15 years and 17-24 years respectively within India. These labs were developed as part of a National mission on Education through ICT. We also focused on the use of virtual and remote labs as a new pedagogy for distance and mobile learning courses and the context of usage outside scheduled classroom timings. The evaluation of biotechnology virtual labs was performed via surveys, including online and manual feedback reports for analyzing the learning process of various student groups. Studies amongst students of different age groups suggested that virtualization helped their active learning in a traditional classroom scenario. Feedback from student users also indicated virtual and remote labs aided, mobile learning by improving their academic performance, after using virtual and remote labs (post usage) as education platform. Feedback statistics showed 90% of students used biotechnology virtual lab techniques and that helped them to get an actual feel of the experiment. All participants scored more than 70% in the post-test, improving the class average from the pre-test scenario. 91% of teachers who participated in the workshops indicated that they could use virtual and remote labs in their daily teaching process as teaching material thereby reducing their lecture preparation time. Feedback analysis also indicated improved student performance enhancing laboratory education. © 2015 IEEE.","Biotechnology; Education; Mobile and distance learning; Remote labs; Virtual labs","Artificial intelligence; Biotechnology; E-learning; Education; Engineering education; Laboratories; Learning systems; Mobile telecommunication systems; Personnel training; Students; Teaching; Academic performance; Computer technology; Internet connectivity; Laboratory education; Remote labs; University education; Virtual and remote labs; Virtual lab; Distance education",2-s2.0-84962476283
"Diaz L.M., Gaytan-Lugo L.S., Fleck L.","From intuition to measure: Styles of use in Alice: Identifying patterns of use by observing participants in workshops with Alice",2015,"Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959924861&doi=10.1109%2fVLHCC.2015.7357242&partnerID=40&md5=bf32da31c8cd260bcac151e80bf14f4e","After several rounds of workshops on Computer Animation with Alice, a free platform for three dimensional computer animation created by Carnegie Mellon University, a pattern of styles of use was observed. Some attendants seemed to try to follow the instructions given and attempt to reproduce exactly the animation the instructor was creating. A second group concentrated on creating visually attractive scenes; a third one on inventing stories and putting models in the scene to talk to each other according to those stories. In the fourth group participants wanted to go well beyond the instructor explanations and explored features and functions of Alice by their own creating complex and action-rich animations. At some point the consistency of those observations lead us to attempt a systematic study by crafting a description of the styles and designing observation tools to detect them and measure the frequency of each one. In this showpiece we will recount the experience, describe in detail the styles observed and present the results of the systematic observation in order to receive suggestions for improvement. We hope to reflect with viewers on why the study of styles of use in Alice could be important for visual languages and computer science education. © 2015 IEEE.","Alice; Computer Animation; First Programming Environments; Styles of Use","Animation; Computational linguistics; Computer programming; Education computing; Visual languages; Alice; Carnegie Mellon University; Computer animation; Computer Science Education; Programming environment; Second group; Styles of Use; Systematic study; Microcomputers",2-s2.0-84959924861
"Surisetty S., Law C., Scaffidi C.","Behavior-based clustering of visual code",2015,"Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959925685&doi=10.1109%2fVLHCC.2015.7357225&partnerID=40&md5=27236570b04aa6f2fd36972a886da581","A perennial problem with online repositories of end-user programmers' code is the low level of reuse, including in situations where existing code might aid in learning. This paper presents a formative study of middle-schoolers learning the Scratch animation environment, which revealed that they struggled to find short pieces of code that they could reuse directly, or from which they could discover language primitives (language instructions) to implement desired behavior. In response, we present a model and supporting prototype tool for clustering behaviorally similar code together, as a basis for helping end-user programmers to locate code. We conducted an empirical study confirming that our tool's model for estimating code similarity does correspond well with programmers' perceptions of code's behavioral similarity. Future work will expand on these results by providing new search engines that help end-user programmers to find and reuse visual code from online repositories. © 2015 IEEE.","end-user programming; reuse; Scratch","Codes (symbols); Computational linguistics; Computer programming; Human computer interaction; Search engines; Behavioral similarities; Empirical studies; End user programmers; End user programming; Online repositories; Perennial problems; reuse; Scratch; Visual languages",2-s2.0-84959925685
"Furch J., Hilsmann A., Eisert P.","A framework for image-based asset generation and animation",2015,"Proceedings - International Conference on Image Processing, ICIP",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956686313&doi=10.1109%2fICIP.2015.7351141&partnerID=40&md5=1dda6602de60382bd935ef4b5b157e18","Creating digital animatable models of real-world objects and characters is important for many applications, ranging from highly expensive movie productions to low-cost real-time applications like computer games and augmented reality. However, achieving real photorealism with convincing appearance and deformation behavior requires sophisticated capturing, elaborate manual modeling and time-consuming simulation. This can only be achieved in well funded film productions, while in low-cost applications, animated objects usually lack visual quality. In this paper, we present a new framework for image-based animatable asset generation which avoids these time-consuming processes both in the modeling and the simulation stage. Real-time photo-realistic animation is enabled by the use of captured images and shifting computational complexity to an a-priori training phase. Our paper covers the complete pipeline of content creation, asset generation and representation, and a real-time animation and rendering implementation. © 2015 IEEE.","Animation; Asset Generation; Image-Based Rendering; Post-Production; Real-Time",,2-s2.0-84956686313
"Inui T., Kohana M., Okamoto S., Kamada M.","A software framework for internet of things",2015,"Proceedings - 2015 18th International Conference on Network-Based Information Systems, NBiS 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964929918&doi=10.1109%2fNBiS.2015.108&partnerID=40&md5=b001cddf06c2b91a49beea5f25d80aa6","This paper describes a software framework for building the Internet of Things widget with Raspberry Pi. This framework utilizes an interactive animation authoring tool called ""Islay,"" which generates an interactive animation written in a programming language. A generated program for Raspberry Pi runs without any operating system. It is a bootable program, which uses hardware timer interrupt by itself. This paper gives an overview of the framework, some description of Raspberry Pi, and its mechanism of timer interrupt as well as a preliminary evaluation of a program using timer interrupt. © 2015 IEEE.","Hardware interrupt; IoT; Islay; Raspberry pi; Software framework","Animation; Computer programming; Hardware; Information systems; Internet; Reconfigurable hardware; Authoring tool; Hardware timers; Interactive animations; Islay; Software frameworks; Internet of things",2-s2.0-84964929918
"Zhou E., Niibori M., Okamoto S., Kamada M., Yonekura T.","IslayTouch: An educational visual programming environment based on state-transition diagrams that runs on android devices",2015,"Proceedings - 2015 18th International Conference on Network-Based Information Systems, NBiS 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964922393&doi=10.1109%2fNBiS.2015.38&partnerID=40&md5=ca7eb3428c2c41132ec27b5a47485873","Educational programming languages are programming languages that have been designed for beginners, with the purpose of teaching them the skill of logical thinking or as an introduction to regular programming languages. Although these languages are relatively easier for beginners, difficult concepts of regular programming languages are still being introduced into some of them. As a new approach to this problem, an educational visual programming environment called Islay has been developed. Due to the adoption of the simple concept of state-transition diagram, Islay becomes even easier for beginners than some other educational programming languages. In this research, a new version of Islay is developed as an Android application, with more features being added and a new user interface that is suitable for tablet devices. © 2015 IEEE.","Android; Educational programming language; Interactive animation; Islay; State-transition diagram","Computational linguistics; Computer programming; Distributed parameter control systems; Education; Information systems; User interfaces; Android; Educational programming languages; Interactive animations; Islay; State transition diagrams; Android (operating system)",2-s2.0-84964922393
"Chang Y.-S., Hsueh Y.-H., Tung K.-C., Jhou F.-Y., Lin D.P.-C.","Characteristics of visual fatigue under the effect of 3D animation",2015,"Technology and Health Care",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951813989&doi=10.3233%2fTHC-151079&partnerID=40&md5=a80fcb33731641ca88cd40fc48095c39","Visual fatigue is commonly encountered in modern life. Clinical visual fatigue characteristics caused by 2-D and 3-D animations may be different, but have not been characterized in detail. This study tried to distinguish the differential effects on visual fatigue caused by 2-D and 3-D animations. A total of 23 volunteers were subjected to accommodation and vergence assessments, followed by a 40-min video game program designed to aggravate their asthenopic symptoms. The volunteers were then assessed for accommodation and vergence parameters again and directed to watch a 5-min 3-D video program, and then assessed again for the parameters. The results support that the 3-D animations caused similar characteristics in vision fatigue parameters in some specific aspects as compared to that caused by 2-D animations. Furthermore, 3-D animations may lead to more exhaustion in both ciliary and extra-ocular muscles, and such differential effects were more evident in the high demand of near vision work. The current results indicated that an arbitrary set of indexes may be promoted in the design of 3-D display or equipments. © 2016 - IOS Press and the authors. All rights reserved.","3-D animation; accommodation-vergence linkage; fatigue parameters; visual fatigue","accommodation; adult; binocular convergence; computer aided design; Conference Paper; exhaustion; fatigue; female; human; human experiment; male; myopia; priority journal; stereoscopic vision; three dimentional animation; video game; vision; visual acuity; visual fatigue; asthenopia; pathophysiology; physiology; three dimensional imaging; video game; vision test; Accommodation, Ocular; Adult; Asthenopia; Female; Humans; Imaging, Three-Dimensional; Male; Video Games; Vision Tests",2-s2.0-84951813989
"Keirnan A., Ahmadpour N., Pedell S., Mayasari A.","Lights, camera, action: Using animations to co-evaluate user experience scenarios",2015,"OzCHI 2015: Being Human - Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963582611&doi=10.1145%2f2838739.2838807&partnerID=40&md5=3dcddc679bdd9f9654b94264ec4a813e","Scenarios are considered a useful tool for designers and HCI communities to generate detailed problem descriptions, future predictions, concept generations, requirements analysis and detailed system design surrounding a design problem. However, little is known about animated scenarios as a tool to co-evaluate and further explore early user research insights and themes with end users. In this study, previous research findings and insights concerning emergency alarm pendants were designed and presented as animated scenarios to older participants in a workshop. Emergency alarms are wearable product technologies that allow the user to alert designated contacts in the event of falls or medical emergencies and were chosen as a case study for this paper. The findings indicate, that while the animated scenarios provide a basis for participants to describe problems associated with using the emergency alarm technology, participants also used the animated scenarios to discus and evaluate the key emotions and themes that were presented. We refer to this process as co-evaluate. It is argued that animated scenarios can be used to validate the HCI designers' understanding and interpretation of early user research insights and themes. Copyright © 2015 ACM.","Animated scenario; Design; Older adults; User research","Alarm systems; Design; Wearable technology; Animated scenario; Concept generation; Future predictions; Older adults; Problem description; Product technology; Requirements analysis; User research; Human computer interaction",2-s2.0-84963582611
"De Lucas E., Marcuello P., Parcerisa J.-M., González A.","Ultra-low power render-based collision detection for CPU/GPU systems",2015,"Proceedings of the Annual International Symposium on Microarchitecture, MICRO",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959909239&doi=10.1145%2f2830772.2830783&partnerID=40&md5=c51481da1548ed9e0f8f30d5e262195b","Smartphones have become powerful computing systems able to carry out complex tasks, such as web browsing, image processing and gaming, among others. Graphics animation applications such as 3D games represent a large percentage of downloaded applications for mobile devices and the trend is towards more complex and realistic scenes with accurate 3D physics simulations, like those in laptops and desktops. Collision detection (CD) is one of the main algorithms used in any physics kernel. However, real-time highly accurate CD is very expensive in terms of energy consumption and this parameter is of paramount importance for mobile devices since it has a direct effect on the autonomy of the system. In this work, we propose an energy-efficient, high-fidelity CD scheme that leverages some intermediate results of the rendering pipeline. It also adds a new and simple hardware block to the GPU pipeline that works in parallel with it and completes the remaining parts of the CD task with extremely low power consumption and more speed than traditional schemes. Using commercial Android applications, we show that our scheme reduces the energy consumption of the CD by 99.8% (i.e., 448x times smaller) on average. Furthermore, the execution time required for CD in our scheme is almost three orders of magnitude smaller (600x speedup) than the time required by a conventional technique executed in a CPU. These dramatic benefits are accompanied by a higher fidelity CD analysis (i.e., with finer granularity), which improves the quality and realism of the application. © 2015 ACM.","image based collision detection; mobile GPU; rendering","Animation; Computer architecture; Computer graphics; Energy efficiency; Energy utilization; Image processing; Mobile devices; Object detection; Pipelines; Three dimensional computer graphics; Android applications; Collision detection; Conventional techniques; Intermediate results; Low-power consumption; mobile GPU; rendering; Three orders of magnitude; Rendering (computer graphics)",2-s2.0-84959909239
"Sokolov D., Gentil C.","Intuitive modeling of vaporish objects",2015,"Chaos, Solitons and Fractals",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940667305&doi=10.1016%2fj.chaos.2015.08.014&partnerID=40&md5=c314481feaa43078ae2a006ca06733e7","Attempts to model gases in computer graphics started in the late 1970s. Since that time, there have been many approaches developed. In this paper we present a non-physical method allowing to create vaporish objects like clouds or smoky characters. The idea is to create a few sketches describing the rough shape of the final vaporish object. These sketches will be used as condensation sets of Iterated Function Systems, providing intuitive control over the object. The advantages of the new method are: simplicity, good control of resulting shapes and ease of eventual object animation. © 2015 Elsevier Ltd. All rights reserved.","Cloud modeling; Condensation sets; Iterated function system; Morphing","Condensation; Cloud modeling; Intuitive controls; Intuitive modeling; Iterated function system; Morphing; Object animation; Physical methods; Computer graphics",2-s2.0-84940667305
"Zhao Y., Jiang D., Sahli H.","3D emotional facial animation synthesis with factored conditional Restricted Boltzmann Machines",2015,"2015 International Conference on Affective Computing and Intelligent Interaction, ACII 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964005013&doi=10.1109%2fACII.2015.7344664&partnerID=40&md5=b9f71247e31995928538096b9200d653","This paper presents a 3D emotional facial animation synthesis approach based on the Factored Conditional Restricted Boltzmann Machines (FCRBM). Facial Action Parameters (FAPs) extracted from 2D face image sequences, are adopted to train the FCRBM model parameters. Based on the trained model, given an emotion label sequence and several initial frames of FAPs, the corresponding FAP sequence is generated via the Gibbs sampling, and then used to construct the MPEG-4 compliant 3D facial animation. Emotion recognition and subjective evaluation on the synthesized animations show that the proposed method can obtain natural facial animations representing well the dynamic process of emotions. Besides, facial animation with smooth emotion transitions can be obtained by blending the emotion labels. © 2015 IEEE.","facial expression synthesis; FAP; FCRBM","Face recognition; Human computer interaction; Intelligent computing; Motion Picture Experts Group standards; 3d facial animations; Conditional restricted boltzmann machines; Emotion recognition; Facial animation; Facial expression synthesis; FCRBM; Model parameters; Subjective evaluations; Animation",2-s2.0-84964005013
"Suranauwarat S.","Using an interactive animated tool to improve the effectiveness of learning CPU scheduling algorithms",2015,"Proceedings - Frontiers in Education Conference, FIE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960351979&doi=10.1109%2fFIE.2015.7344348&partnerID=40&md5=998e52d62eaebd0cac3209c47fabb6dd","CPU scheduling is one of the most important topics in operating systems courses. However, the main problem in learning CPU scheduling from textbooks is that textbooks usually simplify the illustration of CPU scheduling algorithms by using an unrealistic process execution model. They also do not give concrete examples when discussing complex algorithms. As a result, students are not able to gain insight into exactly how the algorithms work in real-world operating systems. To address this problem, the author developed an interactive Java-based software tool that uses graphical animation to convey the concepts of various CPU scheduling algorithms for a single CPU. While many existing animation tools were designed to be closely aligned with the content in traditional operating systems textbooks, this tool is uniquely designed and different in a number of respects. In this paper, the impact of the tool on student learning is measured, analyzed and discussed in detail. The tool has been used in two sections of the operating systems course at the author's institute, and has demonstrated effectiveness in assisting student learning of CPU scheduling algorithms. © 2015 IEEE.","Animation Tool; Computer Science Education; CPU Scheduling Algorithms; Educational Software; Operating System","Algorithms; Animation; Computer software; Education; Education computing; Engineering education; Learning algorithms; Scheduling; Scheduling algorithms; Students; Textbooks; Animation tools; Computer Science Education; CPU scheduling algorithms; Educational software; Operating System; Computer operating systems",2-s2.0-84960351979
"Calderon D.M., Man K., Kiyomitsu H., Ohtsuki K., Miyamoto Y., Sun Y.","An evaluation method for panoramic understanding of programming by comparison with visual examples",2015,"Proceedings - Frontiers in Education Conference, FIE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960381870&doi=10.1109%2fFIE.2015.7344104&partnerID=40&md5=229eff780e98a72b2e885afa5c300d1a","In recent years, professionals in different fields have become able to do programming by using simplified software tools, as a consequence of this they are becoming able to understand programming in a general or 'panoramic' way. This understanding is not evaluated by current programming abilities testing methods such as written paper tests or practical programming. This paper proposes a Programmed Visual Contents Comparison Method to assess programming ability, and additionally, a testing system based on this method. With this method, by comparing 2 displayed images and interactive animations produced by programming samples (a question) a subject must decide which one of the programs is more difficult to build with programming than the other, or, if the difficulty is similar for both of them. The validity of the method is confirmed by comparing the ability reported by programming teachers with the results of an experiment performed with a testing system. © 2015 IEEE.","Computer science education; Graphic Design; Programming Training; Software Engineering; Student Assessment","Ability testing; Design; Education; Education computing; Engineering education; Software design; Software engineering; Teaching; Comparison methods; Computer Science Education; Current programming; Graphic design; Interactive animations; Programming ability; Student assessment; Testing systems; Computer programming",2-s2.0-84960381870
"Carreno-Medrano P., Gibet S., Marteau P.-F.","End-effectors trajectories: An efficient low-dimensional characterization of affective-expressive body motions",2015,"2015 International Conference on Affective Computing and Intelligent Interaction, ACII 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964067867&doi=10.1109%2fACII.2015.7344607&partnerID=40&md5=1cce62fce8a6c332f4f95082b415a35b","Virtual characters capable of showing emotional content are considered as more believable and engaging. However, in spite of the numerous psychological studies and machine learning applications trying to decode the most salient features in the expression and perception of affect, there is still no common understanding about how affect is conveyed through body motions. Based on findings reported by the psychology research community and quantitative results obtained in the computer animation domain during the last years, we propose to represent affective bodily movement through a low-dimensional parameterization consisting of the spatio-temporal trajectories of eight main joints in the human body (hands, head, feet, elbows and pelvis). Using a combined evaluation protocol, we show that this low-dimensional parameterization and the features derived from it are a compact and sufficient representation of affective motions that can be used for automatic recognition of affect and the generation of new affective-expressive motions. © 2015 IEEE.","automatic affect recognition; body movement; inverse kinematics; low-dimensional representation; motion synthesis","Animation; Artificial intelligence; Inverse kinematics; Learning systems; Affect recognition; Automatic recognition; Body movements; Low-dimensional representation; Machine learning applications; Motion synthesis; Research communities; Spatio-temporal trajectories; Intelligent computing",2-s2.0-84964067867
"Li F., Li D., Zheng J., Zhao S.","Virtual experiments for introduction of computing: Using virtual reality technology",2015,"Proceedings - Frontiers in Education Conference, FIE",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960360590&doi=10.1109%2fFIE.2015.7344376&partnerID=40&md5=4d5e7f716bbb85770794d88d8de104ca","Introduction to Computing is a public course for the first-year non-major undergraduate students, aiming at training students for the abilities in computer science and technology with computational thinking. However, as new computer technologies emerge continuously and rapidly, it is required for this course to accommodate more and more knowledge. Therefore the teaching contents are growing enormously, which makes it very difficult to cover all of them in limited hours, and therefore sets an obstacle in understanding computing principles and building up a clear and general picture of computing, especially for non-major students. As computer science and technology are becoming more and more essential for various disciplines and majors, it is urgent for the education community to find out an effective and propagable way to solve this problem. In this regard, we employ virtual reality technology to the experiment teaching of this course, and have developed 18 virtual experiments to support the whole teaching process. For example, Turing machine is a basic model for computer science and technology. However, since it is not a real machine, it is not easy for the students to imagine the working process of Turing machine and understand the related concepts. Another example, the execution of an instruction is very important to understand the principles of computer organization. However, as the information flow is invisible, it is difficult and time-consuming for the teachers to explain how an instruction is executed inside a computer. Therefore, 3D modeling and animation techniques are used to demonstrate the invisible micro-structure of computers, and human-machine interaction and visualization techniques are used to present the internal process of information evolution, thus constructing a complete virtual experiment system of this course, including demonstration experiments, verification experiments and interaction experiments. Our virtual experiments have applied software copyrights and served more than 12,000 students from five universities of China since 2013. The evaluation demonstrates that the virtual experiments have produced excellent results in both teaching effectiveness and learning efficiency, relieved the conflicts between limited hours and vast knowledge, and helped students understand and build up the knowledge of computing. © 2015 IEEE.","Introduction to Computing; virtual experiments; virtual reality","Education; Education computing; Engineering education; Machinery; Teaching; Three dimensional computer graphics; Turing machines; Virtual reality; Computational thinkings; Computer science and technologies; Human machine interaction; Introduction to computing; Virtual experiment system; Virtual experiments; Virtual reality technology; Visualization technique; Students",2-s2.0-84960360590
"Zhao J., Wei Y., Xia S., Wang Z.","Survey of physics-based character animation",2015,"Jisuanji Yanjiu yu Fazhan/Computer Research and Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961307746&doi=10.7544%2fissn1000-1239.2015.20140634&partnerID=40&md5=bee5572fcc90da839a9afe7887a466d5","Character animation is one of the main research topics of computer graphics and virtual reality, and it plays an important role in many applications of digital entertainment, 3D game, manufacturing. Recently, along with the development of 3D animation game and special effects production in film making, physics-based character animation has attracted wide spread attention, and has been one of the hottest topics in the field of computer graphics for many years. As the growth of the requirement for physical reality, many new methods have emerged, which greatly enhance the animation and improve the performance. The most key issue is locomotion controller, which aims to calculate the joint torques to drive character move on. This paper focuses on character animation techniques. Firstly, the researches on character animation based on physical simulation are reviewed. According to the calculation methods of joint torques, these techniques are classified into 7 categories: spacetime constraint, constrained dynamics optimization control, low-dimensional planning, finite-state controller, data-driven technique, dynamic selection of motion examples, integration with statistics model. Their principles and characteristics are detailed, and recent works are highlighted. Secondly, with analyzing the related literatures, the advantages and disadvantages of the existing simulation methods are summarized. Finally, we point out various open research areas and possible future directions. © 2015, Science Press. All right reserved.","Character animation; Motion control; Motion synthesis; Physical simulation; Virtual reality","Computer games; Computer graphics; Constrained optimization; Controllers; Digital storage; Industrial research; Motion control; Three dimensional computer graphics; Virtual reality; Character animation; Data driven technique; Digital entertainment; Finite-state controllers; Locomotion controllers; Motion synthesis; Physical simulation; Spacetime constraints; Animation",2-s2.0-84961307746
"Feng Y., Ji M., Xiao J., Yang X., Zhang J.J., Zhuang Y., Li X.","Mining Spatialoral Patterns and Structural Sparsity for Human Motion Data Denoising",2015,"IEEE Transactions on Cybernetics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960460710&doi=10.1109%2fTCYB.2014.2381659&partnerID=40&md5=161e50716f58658b474da33f6f778339","Motion capture is an important technique with a wide range of applications in areas such as computer vision, computer animation, film production, and medical rehabilitation. Even with the professional motion capture systems, the acquired raw data mostly contain inevitable noises and outliers. To denoise the data, numerous methods have been developed, while this problem still remains a challenge due to the high complexity of human motion and the diversity of real-life situations. In this paper, we propose a data-driven-based robust human motion denoising approach by mining the spatialoral patterns and the structural sparsity embedded in motion data. We first replace the regularly used entire pose model with a much fine-grained partlet model as feature representation to exploit the abundant local body part posture and movement similarities. Then, a robust dictionary learning algorithm is proposed to learn multiple compact and representative motion dictionaries from the training data in parallel. Finally, we reformulate the human motion denoising problem as a robust structured sparse coding problem in which both the noise distribution information and the temporal smoothness property of human motion have been jointly taken into account. Compared with several state-of-the-art motion denoising methods on both the synthetic and real noisy motion data, our method consistently yields better performance than its counterparts. The outputs of our approach are much more stable than that of the others. In addition, it is much easier to setup the training dataset of our method than that of the other data-driven-based methods. © 2013 IEEE.","Human motion denoising; Microsoft Kinect; motion capture data; robust dictionary learning; Robust structured sparse coding; ℓ2,p-norm","Animation; Better performance; Computer animation; Denoising approach; Denoising problems; Dictionary learning algorithms; Feature representation; Motion capture system; Noise distribution; Computer vision; algorithm; automated pattern recognition; classification; data mining; human; human activities; image processing; machine learning; movement (physiology); physiology; procedures; signal processing; Algorithms; Data Mining; Human Activities; Humans; Image Processing, Computer-Assisted; Machine Learning; Movement; Pattern Recognition, Automated; Signal Processing, Computer-Assisted",2-s2.0-84960460710
"Firmin M., Van De Panne M.","Controller Design for Multi-Skilled Bipedal Characters",2015,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955187444&doi=10.1111%2fcgf.12607&partnerID=40&md5=56a5016b88e9722c6cab14f5e0aaeb27","Developing motions for simulated humanoids remains a challenging problem. While there exists a multitude of approaches, few of these are reimplemented or reused by others. The predominant focus of papers in the area remains on algorithmic novelty, due to the difficulty and lack of incentive to more fully explore what can be accomplished within the scope of existing methodologies. We develop a language, based on common features found across physics-based character animation research, that facilitates the controller authoring process. By specifying motion primitives over a number of phases, our language has been used to design over 25 controllers for motions ranging from simple static balanced poses, to highly dynamic stunts. Controller sequencing is supported in two ways. Naive integration of controllers is achieved by using highly stable pose controllers (such as a standing or squatting) as intermediate transitions. More complex controller connections are automatically learned through an optimization process. The robustness of our system is demonstrated via random walkthroughs of our integrated set of controllers. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","human simulation; motion control; physically based animation","Animation; Computational linguistics; Computer graphics; Controllers; Motion control; Authoring process; Character animation; Complex controllers; Controller designs; Human simulation; Motion primitives; Physical simulation; Physically-based animation; Process control",2-s2.0-84955187444
"Ingley S.J., Rahmani Asl M., Wu C., Cui R., Gadelhak M., Li W., Zhang J., Simpson J., Hash C., Butkowski T., Veen T., Johnson J.B., Yan W., Rosenthal G.G.","anyFish 2.0: An open-source software platform to generate and share animated fish models to study behavior",2015,"SoftwareX",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949233045&doi=10.1016%2fj.softx.2015.10.001&partnerID=40&md5=998e32acb89c2fb12d1f4b66ce25f706","Experimental approaches to studying behaviors based on visual signals are ubiquitous, yet these studies are limited by the difficulty of combining realistic models with the manipulation of signals in isolation. Computer animations are a promising way to break this trade-off. However, animations are often prohibitively expensive and difficult to program, thus limiting their utility in behavioral research. We present anyFish 2.0, a user-friendly platform for creating realistic animated 3D fish. anyFish 2.0 dramatically expands anyFish's utility by allowing users to create animations of members of several groups of fish from model systems in ecology and evolution (e.g., sticklebacks, Poeciliids, and zebrafish). The visual appearance and behaviors of the model can easily be modified. We have added several features that facilitate more rapid creation of realistic behavioral sequences. anyFish 2.0 provides a powerful tool that will be of broad use in animal behavior and evolution and serves as a model for transparency, repeatability, and collaboration. © 2015 The Authors.","Animal communication; Animation; Teleostei; Video playback",,2-s2.0-84949233045
"Engelhardt L.","Magnetic resonance: Using computer simulations and visualizations to connect quantum theory with classical concepts",2015,"American Journal of Physics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949558026&doi=10.1119%2f1.4930081&partnerID=40&md5=00d6f8a277a149cb8e682c5629a2dd28","We discuss how computers can be used to solve the ordinary differential equations that provide a quantum mechanical description of magnetic resonance. By varying the parameters in these equations and visually exploring how these parameters affect the results, students can quickly gain insights into the nature of magnetic resonance that go beyond the standard presentation found in quantum mechanics textbooks. The results were generated using an IPython notebook, which we provide as an online supplement with interactive plots and animations. © 2015 American Association of Physics Teachers.",,,2-s2.0-84949558026
"Moon W., Wu K.W., MacGinnis M., Sung J., Chu H., Youssef G., Machado A.","The efficacy of maxillary protraction protocols with the micro-implant-assisted rapid palatal expander (MARPE) and the novel N2 mini-implant—a finite element study",2015,"Progress in Orthodontics",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982867223&doi=10.1186%2fs40510-015-0083-z&partnerID=40&md5=b532209697ea30d3af48fbf49f936f60","Background: Maxillary protraction with the novel N2 mini-implant- and micro-implant-assisted rapid palatal expander (MARPE) can potentially provide significant skeletal effects without surgery, even in older patients where conventional facemask therapy has limited skeletal effects. However, the skeletal effects of altering the location and direction of force from mini-implant-assisted maxillary protraction have not been extensively analyzed. In this study, the application of the novel N2 mini-implant as an orthopedic anchorage device is explored in its ability to treat patients with class III malocclusions. Methods: A 3D cranial mesh model with associated sutures was developed from CT images and Mimics modeling software. Utilizing ANSYS simulation software, protraction forces were applied at different locations and directions to simulate conventional facemask therapy and seven maxillary protraction protocols utilizing the novel N2 mini-implant. Stress distribution and displacement were analyzed. Video animations and superimpositions were created. Results: By changing the vector of force and location of N2 mini-implant, the maxilla was displaced differentially. Varying degrees of forward, downward, and rotational movements were observed in each case. For brachyfacial patients, anterior micro-implant-supported protraction at −45° or intermaxillary class III elastics at −45° are recommended. For dolicofacial patients, either anterior micro-implants at −15° or an intermaxillary spring at +30° is recommended. For mesofacial patients with favorable vertical maxillary position, palatal micro-implants at −30° are recommended; anterior micro-implants at −30° are preferred for shallow bites. For patients with a severe mid-facial deficiency, intermaxillary class III elastics at −30° are most effective in promoting anterior growth of the maxilla. Conclusions: By varying the location of N2 mini-implants and vector of class III mechanics, clinicians can differentially alter the magnitude of forward, downward, and rotational movement of the maxilla. As a result, treatment protocol can be customized for each unique class III patient. © 2015, Moon et al.; licensee Springer.",,"adult; Article; bone remodeling; computer assisted tomography; computer program; face mask; finite element analysis; human; image reconstruction; implant; male; maxillary sinus; micro implant; orthodontics; priority journal; three dimensional imaging; zygoma; anatomic model; biological model; biomechanics; canine tooth; classification; computer simulation; devices; finite element analysis; image processing; Malocclusion, Angle Class III; maxilla; mechanical stress; miniaturization; molar tooth; orthodontic anchorage; orthodontic procedure; palatal expansion; pathology; premolar tooth; procedures; reverse-pull headgear; rotation; tooth implant; videorecording; x-ray computed tomography; tooth implant; Adult; Bicuspid; Biomechanical Phenomena; Computer Simulation; Cuspid; Dental Implants; Extraoral Traction Appliances; Finite Element Analysis; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Male; Malocclusion, Angle Class III; Maxilla; Miniaturization; Models, Anatomic; Models, Biological; Molar; Orthodontic Anchorage Procedures; Orthodontic Appliance Design; Palatal Expansion Technique; Rotation; Stress, Mechanical; Tomography, X-Ray Computed; Video Recording",2-s2.0-84982867223
"Miller C.J., Metz M.J.","Can clinical scenario videos improve dental students' perceptions of the basic sciences and ability to apply content knowledge?",2015,"Journal of Dental Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949292946&partnerID=40&md5=5dc191cb9ec11ea4f3e874e71fe21d91","Dental students often have difficulty understanding the importance of basic science classes, such as physiology, for their future careers. To help alleviate this problem, the aim of this study was to create and evaluate a series of video modules using simulated patients and custom-designed animations that showcase medical emergencies in the dental practice. First-year students in a dental physiology course formatively assessed their knowledge using embedded questions in each of the three videos; 108 to 114 of the total 120 first-year students answered the questions, for a 90-95% response rate. These responses indicated that while the students could initially recognize the cause of the medical emergency, they had difficulty in applying their knowledge of physiology to the scenario. In two of the three videos, students drastically improved their ability to answer high-level clinical questions at the conclusion of the video. Additionally, when compared to the previous year of the course, there was a significant improvement in unit exam scores on clinically related questions (6.2% increase). Surveys were administered to the first-year students who participated in the video modules and fourth-year students who had completed the course prior to implementation of any clinical material. The response rate for the first-year students was 96% (115/120) and for the fourth-year students was 57% (68/120). The first-year students indicated a more positive perception of the physiology course and its importance for success on board examinations and their dental career than the fourth-year students. The students perceived that the most positive aspects of the modules were the clear applications of physiology to real-life dental situations, the interactive nature of the videos, and the improved student comprehension of course concepts. These results suggest that online modules may be used successfully to improve students' perceptions of the basic sciences and enhance their ability to apply basic science content to clinically important scenarios.","Basic sciences; Computer-assisted instruction; Dental education; Educational technology; Medical emergencies; Online learning; Physiology","comparative study; comprehension; dental education; dental student; education; educational technology; emergency; human; learning; physiology; problem based learning; science; teaching; videorecording; Comprehension; Computer-Assisted Instruction; Education, Dental; Educational Measurement; Educational Technology; Emergencies; Humans; Learning; Patient Simulation; Physiology; Problem-Based Learning; Science; Students, Dental; Teaching Materials; Video Recording",2-s2.0-84949292946
"Griggs A.J., Davies S.M., Abbott P.M., Coleman M., Palmer A.P., Rasmussen T.L., Johnston R.","Visualizing tephra deposits and sedimentary processes in the marine environment: The potential of X-ray microtomography",2015,"Geochemistry, Geophysics, Geosystems",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955336111&doi=10.1002%2f2015GC006073&partnerID=40&md5=29409f85aab96f70e7e4ac7825773643","Localized tephra deposition in marine sequences is the product of many complex primary and secondary depositional processes. These can significantly influence the potential applicability of tephra deposits as isochronous marker horizons and current techniques, used in isolation, may be insufficient to fully unravel these processes. Here we demonstrate the innovative application of X-ray microtomography (μCT) to successfully identify tephra deposits preserved within marine sediments and use these parameters to reconstruct their internal three-dimensional structure. Three-dimensional visualizations and animations of tephra dispersal in the sediment permit a more thorough assessment of postdepositional processes revealing a number of complex microsedimentological features that are not revealed by conventional methods. These features include bioturbation burrows and horizontally discontinuous tephra packages, which have important ramifications for the stratigraphic placement of the isochron in a sedimentary sequence. Our results demonstrate the potential for utilizing rigorous two and three-dimensional microsedimentological analysis of the ichnofabric to enhance and support the use of tephra deposits as isochronous marker horizons and to identify the stratigraphic position that best reflects the primary fallout of ash. The application also provides an exceptional insight into the style and rate of sedimentation processes and permits an assessment of the stratigraphic integrity of a tephra deposit. We discuss the possibility of applying these μCT methods to the identification of cryptotephras within various paleoclimatic sequences and to enhance our understanding of marine sedimentation processes. © 2015. The Authors.","bioturbation; micromorphology; paleoceaonography; tephra; X-ray microtomography","Deposition; Deposits; Sedimentology; Stratigraphy; Submarine geology; Tomography; Bioturbation; Micromorphologies; Paleoceaonography; Tephra; X ray microtomography; Three dimensional computer graphics; bioturbation; deposition; marine environment; marine sediment; micromorphology; paleoceanography; sedimentation; tephra; tomography; visualization; X-ray spectroscopy",2-s2.0-84955336111
"Eugene Roberts W., Viecilli R.F., Chang C., Katona T.R., Paydar N.H.","Biology of biomechanics: Finite element analysis of a statically determinate system to rotate the occlusal plane for correction of a skeletal Class III open-bite malocclusion",2015,"American Journal of Orthodontics and Dentofacial Orthopedics",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951807054&doi=10.1016%2fj.ajodo.2015.10.002&partnerID=40&md5=b7396cb36cdad79b0b8b0961388bc50e","Introduction In the absence of adequate animal or in-vitro models, the biomechanics of human malocclusion must be studied indirectly. Finite element analysis (FEA) is emerging as a clinical technology to assist in diagnosis, treatment planning, and retrospective analysis. The hypothesis tested is that instantaneous FEA can retrospectively simulate long-term mandibular arch retraction and occlusal plane rotation for the correction of a skeletal Class III malocclusion. Methods Seventeen published case reports were selected of patients treated with statically determinate mechanics using posterior mandible or infrazygomatic crest bone screw anchorage to retract the mandibular arch. Two-dimensional measurements were made for incisor and molar movements, mandibular arch rotation, and retraction relative to the maxillary arch. A patient with cone-beam computed tomography imaging was selected for a retrospective FEA. Results The mean age for the sample was 23.3 ± 3.3 years; there were 7 men and 10 women. Mean incisor movements were 3.35 ± 1.55 mm of retraction and 2.18 ± 2.51 mm of extrusion. Corresponding molar movements were retractions of 4.85 ± 1.78 mm and intrusions of 0.85 ± 2.22 mm. Retraction of the mandibular arch relative to the maxillary arch was 4.88 ± 1.41 mm. Mean posterior rotation of the mandibular arch was -5.76° ± 4.77° (counterclockwise). The mean treatment time (n = 16) was 36.2 ± 15.3 months. Bone screws in the posterior mandibular region were more efficient for intruding molars and decreasing the vertical dimension of the occlusion to close an open bite. The full-cusp, skeletal Class III patient selected for FEA was treated to an American Board of Orthodontics Cast-Radiograph Evaluation score of 24 points in about 36 months by en-masse retraction and posterior rotation of the mandibular arch: the bilateral load on the mandibular segment was about 200 cN. The mandibular arch was retracted by about 5 mm, posterior rotation was about 16.5°, and molar intrusion was about 3 mm. There was a 4° decrease in the mandibular plane angle to close the skeletal open bite. Retrospective sequential iterations (FEA animation) simulated the clinical response, as documented with longitudinal cephalometrics. The level of periodontal ligament stress was relatively uniform (<5 kPa) for all teeth in the mandibular arch segment. Conclusions En-masse retraction of the mandibular arch is efficient for conservatively treating a skeletal Class III malocclusion. Posterior mandibular anchorage causes intrusion of the molars to close the vertical dimension of the occlusion and the mandibular plane angle. Instantaneous FEA as modeled here could be used to reasonably predict the clinical results of an applied load. © 2015 American Association of Orthodontists.",,"adult; biological model; biomechanics; bone screw; case report; cephalometry; computer simulation; cone beam computed tomography; devices; female; finite element analysis; follow up; human; incisor; longitudinal study; male; Malocclusion, Angle Class III; mandible; maxilla; molar tooth; Open Bite; orthodontics; pathology; procedures; retrospective study; rotation; tooth arch; tooth occlusion; young adult; Adult; Biomechanical Phenomena; Bone Screws; Cephalometry; Computer Simulation; Cone-Beam Computed Tomography; Dental Arch; Female; Finite Element Analysis; Follow-Up Studies; Humans; Incisor; Longitudinal Studies; Male; Malocclusion, Angle Class III; Mandible; Maxilla; Models, Biological; Molar; Open Bite; Orthodontic Anchorage Procedures; Orthodontic Appliance Design; Retrospective Studies; Rotation; Vertical Dimension; Young Adult",2-s2.0-84951807054
"Yu H., Garrod O., Jack R., Schyns P.","A framework for automatic and perceptually valid facial expression generation",2015,"Multimedia Tools and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942506090&doi=10.1007%2fs11042-014-2125-9&partnerID=40&md5=5a8db51a289c58a4bf791d270ba20116","Facial expressions are facial movements reflecting the internal emotional states of a character or in response to social communications. Realistic facial animation should consider at least two factors: believable visual effect and valid facial movements. However, most research tends to separate these two issues. In this paper, we present a framework for generating 3D facial expressions considering both the visual the dynamics effect. A facial expression mapping approach based on local geometry encoding is proposed, which encodes deformation in the 1-ring vector. This method is capable of mapping subtle facial movements without considering those shape and topological constraints. Facial expression mapping is achieved through three steps: correspondence establishment, deviation transfer and movement mapping. Deviation is transferred to the conformal face space through minimizing the error function. This function is formed by the source neutral and the deformed face model related by those transformation matrices in 1-ring neighborhood. The transformation matrix in 1-ring neighborhood is independent of the face shape and the mesh topology. After the facial expression mapping, dynamic parameters are then integrated with facial expressions for generating valid facial expressions. The dynamic parameters were generated based on psychophysical methods. The efficiency and effectiveness of the proposed methods have been tested using various face models with different shapes and topological representations. © 2014, Springer Science+Business Media New York.","Face dynamics; Facial animation; Facial expression mapping; FACS; Perceptually valid; Psychophysical","Animation; Encoding (symbols); Face recognition; Linear transformations; Mapping; Topology; Face dynamics; Facial animation; Facial Expressions; FACS; Perceptually valid; Psychophysical; Computer keyboards",2-s2.0-84942506090
"Andrade L.F.D.S., Sandim M., Petronetto F., Pagliosa P., Paiva A.","Particle-based fluids for viscous jet buckling",2015,"Computers and Graphics (Pergamon)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940390450&doi=10.1016%2fj.cag.2015.07.021&partnerID=40&md5=c9d61bf684416c88940dc18e62e3ae38","In this paper, we introduce a novel meshfree framework for animating free surface viscous liquids with jet buckling effects, such as coiling and folding. Our method is based on Smoothed Particle Hydrodynamics (SPH) fluids and allows more realistic and complex viscous behaviors than the previous SPH frameworks in computer animation literature. The viscous liquid is modeled by a non-Newtonian fluid flow and the variable viscosity under shear stress is achieved using a viscosity model known as Cross model. We demonstrate the efficiency and stability of our framework in a wide variety of animations, including scenarios with arbitrary geometries and high resolution of SPH particles. The interaction of the viscous liquid with complex solid obstacles is performed using boundary particles. Our framework is able to deal with different inlet velocity profiles and geometries of the injector, as well as moving inlet jet along trajectories given by cubic Hermite splines. Moreover, the simulation speed is significantly accelerated by using Computer Unified Device Architecture (CUDA) computing platform. © 2015 Elsevier Ltd.","Computer animation; CUDA; Jet buckling; SPH fluids; Viscous liquids","Animation; Buckling; Fighter aircraft; Flow of fluids; Fluids; Liquids; Non Newtonian flow; Non Newtonian liquids; Shear flow; Shear stress; Viscosity; Computer animation; Computer unified device architectures; CUDA; Inlet velocity profile; Jet buckling; Non-Newtonian fluid flow; Smoothed particle hydrodynamics; Viscous liquids; Hydrodynamics",2-s2.0-84940390450
"Cornelis J., Ihmsen M., Teschner M.","Liquid boundaries for implicit incompressible SPH",2015,"Computers and Graphics (Pergamon)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940030521&doi=10.1016%2fj.cag.2015.07.022&partnerID=40&md5=1d23dc800bf1ca0e6822b56e642a7970","We propose a novel unified particle representation for fluids and solid boundaries in Implicit Incompressible SPH (IISPH). In contrast to existing particle representations, the proposed concept does not require a separate processing of fluid and boundary particles. On one hand, this results in a simplified solver implementation with improved efficiency. On the other hand, the unified fluid and boundary representation adds flexibility to IISPH which enables versatile effects. In particular, particles can now dynamically interchange their role between fluid and boundary which we therefore refer to as liquid boundary. The paper mainly focuses on the description of the unified representation and on the application of the concept to visual effects such as solidification and liquefaction. To support the realization of these effects, the concept of unified fluid and liquid boundary particles is extended to a third particle type, so-called candidate particles that are used in a transition phase between fluid and liquid boundaries. © 2015 Elsevier Ltd.","Computer animation; Fluid animation; Physically-based simulation","Animation; Hydrodynamics; Liquids; Boundary representations; Computer animation; Fluid animation; Physically-based simulation; Solid boundaries; Transition phase; Visual effects; Fluids",2-s2.0-84940030521
"Paier W., Kettern M., Hilsmann A., Eisert P.","Video-Based Facial Re-Animation",2015,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959335391&doi=10.1145%2f2824840.2824843&partnerID=40&md5=563f511571894d2398cb6b582761f6ff","Generating photorealistic facial animations is still a challenging task in computer graphics, and synthetically generated facial animations often do not meet the visual quality of captured video sequences. Video sequences on the other hand need to be captured prior to the animation stage and do not offer the same animation exibility as computer graphics models. We present an inexpensive method for video-based facial animation, which combines the photorealism of real videos with the exibility of CGI-based animation by extracting dynamic texture sequences from existing multi-view footage. To synthesize new facial performances, these texture sequences are concatenated in a motion-graph-like way. In order to ensure realistic appearance, we combine a warpbased optimization scheme with a modified cross dissolve to prevent visual artefacts during the transition between texture sequences. Our approach makes photorealistic facial re-animation from existing video footage possible, which is especially useful in applications like video editing or the animation of digital characters. © 2015 ACM.","Facial animation; Facial texture; Geometric proxy; Tracking","Computer graphics; Surface discharges; Video recording; Video signal processing; Based animations; Digital characters; Dynamic textures; Facial animation; Facial textures; Geometric proxy; Optimization scheme; Visual qualities; Animation",2-s2.0-84959335391
"Romeo M., Auty J., Fagnou D.","Intelligent Rendering of Dailies: Automation, layering and reuse of rendered assets",2015,"ACM International Conference Proceeding Series",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959373587&doi=10.1145%2f2824840.2824858&partnerID=40&md5=fe3c6faf714d7aaec7e4ba941e00899f","In visual effects production the amount of digital assets to be created is constantly increasing [2] . These assets can be two dimensional images, three dimensional geometries or an- imated scenes with multiple characters, large scenarios and complex shading. In order to properly review the creation process for all these contents, it is necessary to rapidly gener- ate accurate previews that show the progress and enable su- pervisors to provide valuable feedback. Unfortunately, given the complex nature of these assets, it is dificult to manually generate such previews, with the quality required to provide meaningful feedback in time for daily reviews. From a technical standpoint, it is important to consider that MPC's pipeline is designed to work as a multi-layered reference tree of several assets of different types. Then, one asset is dened as a hierarchical structure of interconnected and interdependent assets [1, 3]. Because of this, it is impor- tant to ensure that, whatever version of an asset is rendered, all of its dependent assets (characters, animations, cameras, etc.) are properly sourced. In this paper we describe an automated system called ""RenderFlow""that takes advantage of our digital asset man- agement system to rapidly generate high quality renders of complex scenes by performing an automated gathering of required assets and reusing existing renders to save process- ing time. The system is integrated within our visual effects production pipeline and takes advantage of several commer- cially available products (e.g. Autodesk Maya and Pixar's RenderMan). © 2015 ACM.","Automation; Performance; Rendering; Visual effects","Automation; Pipelines; Hierarchical structures; Performance; Production pipelines; Rendering; Technical standpoint; Three dimensional geometry; Two dimensional images; Visual effects; Rendering (computer graphics)",2-s2.0-84959373587
"Bartneck C., Soucy M., Fleuret K., Sandoval E.B.","The robot engine - Making the unity 3D game engine work for HRI",2015,"Proceedings - IEEE International Workshop on Robot and Human Interactive Communication",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954040960&doi=10.1109%2fROMAN.2015.7333561&partnerID=40&md5=1efd66c2c0a4a92524689388a43fcfd1","HRI is a multi-disciplinary research field and integrating the range of expertise into a single project can be challenging. Enabling experts on human behavior to design fluent animations and behaviors for advanced robots is problematic, since the tools available for such robots are often in their prototype stage. We have built The Robot Engine (TRE) based on the Unity 3D Game Engine to control robots with Unity 3D. Unity 3D allows non-programmers to use a set of powerful animation and interaction design tools to visually program and animate robots. We review several animation techniques that are common in computer games and that could make the movements of robots more natural and convincing. We demonstrate the use of TRE with two different Arduino based robot platforms and believe that it can easily be extended for use with other robots. We further believe that this unconventional integration of technologies has the potential to fully bring the expertise of interaction designers into the process of advanced human-robot interaction projects. © 2015 IEEE.",,"Animation; Behavioral research; Computer games; Design; Machine design; Robots; 3D game engines; Animation techniques; Control robots; Human behaviors; Interaction design; Multi-disciplinary research; Robot platform; Human robot interaction",2-s2.0-84954040960
"Gutierrez R.A.R., Forero P.A.F.","Urban screen interactive in Bogotá: Proposal for interaction with Colpatria tower [Urban Screen interactiva en Bogotá: Propuesta de Interacción con la torre Colpatria]",2015,"2015 10th Colombian Computing Conference, 10CCC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963800551&doi=10.1109%2fColumbianCC.2015.7333423&partnerID=40&md5=65234d815829869a052f7706811efdf2","For several years the idea to show content on the facade of the buildings in order to bring people to the city by new experiences has been proposed. These new experiences are made using 'Urban Screen' or giant screens that display the contents to the public. One building that meets these characteristics is the Colpatria Tower, one of the most iconic buildings of the Colombian capital. The building has a set of individual lights in each of its four sides, capable of displaying different types of images, but people can not interact with them, which would be a great opportunity to attract public. This article proposes four ideas based art (music, video, animation and painting), and using unconventional devices like the Kinect and Leap Motion, in order to achieve this idea. To test each of the proposed ideas, a prototype is presentment in order to allow interaction with each built. Test users were consulted in order to prove that the idea based on animation was the most interesting among the other three. © 2015 IEEE.","HCI; Interacción; Modelo virtual; Urban Screen","Computer programming; Computer science; Human computer interaction; Colombians; Iconic buildings; Modelo virtual; Animation",2-s2.0-84963800551
"Vijitpornkul S., Marurngsith W.","Simulating crowd movement in agent-based model of large-scale flood",2015,"ICAICTA 2015 - 2015 International Conference on Advanced Informatics: Concepts, Theory and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960970143&doi=10.1109%2fICAICTA.2015.7335368&partnerID=40&md5=cb4a55fdef07bde9da4cf9430a6aa4d6","Crowd movement during natural disasters and major accidents can affect the success of evacuation procedure. Thus to develop an effective evacuation plan, a wide-range of scenarios causing different routes and patterns of crowd movement should be considered. Recent researches in agent-based simulation have achieved techniques to simulate crowd movement in emergency scenarios at city scale. However simulating crowd movement at a macroscopic level for disasters which might affect several cities, like large-scale flood, is still a challenge. This paper addresses this issue and makes three contributions. First, the development of an agent-based layered model to simulate large-scale flood using GIS is demonstrated. Second, the simulation of crowd agents' movement on available roads is presented. Third, the preliminary experiments running on private Cloud server is reported. The experiments cover case studies illustrated the movement of crowd agents around Thailand while several parts of the country were inundated. The 2D animation depict the movement of crowd; and the simulation results show the status of the agents and the amount of individuals which required shelters. To simulate one day events, the simulator took 4-9 hours execution time depending on the severity of floods and available facilities. © 2015 IEEE.","Cloud Computing; Crowd Movement; Disaster Simulation; Distributed Artificial Intelligence; Multiagent Systems","Artificial intelligence; Autonomous agents; Cloud computing; Computation theory; Computational methods; Disasters; Distributed computer systems; Information science; Multi agent systems; Agent based simulation; Crowd movements; Disaster simulation; Distributed Artificial Intelligence; Emergency scenario; Evacuation procedures; Macroscopic levels; Movement of crowds; Floods",2-s2.0-84960970143
"Annamaa A.","Introducing thonny, a python ide for learning programming",2015,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959892255&doi=10.1145%2f2828959.2828969&partnerID=40&md5=ab6260dd1cb0eb8f19d2034a54261b82","Thonny is a new Python IDE for learning and teaching programming that can make program visualization a natural part of the beginners' workow. Among its prominent features are different ways of stepping through the code, step-by-step expression evaluation, intuitive visualization of the call stack and mode for explaining the concepts of references and heap. It supports educational research by logging user actions for replaying or analyzing the programming process. It is free to use and open for extension. © 2015 Copyright held by the owner/author(s).","Computing education; Ide; Program animation; Program visualization; Programming; Python","Education; High level languages; Mathematical programming; Visualization; Computing education; Educational research; Learning and teachings; Learning programming; Program animation; Program visualization; Programming process; Python; Computer software",2-s2.0-84959892255
"Belic J., Savic A.","Detecting and comparing the onset of self-paced and cue-based finger movements from EEG signals",2015,"2015 7th Computer Science and Electronic Engineering Conference, CEEC 2015 - Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963641796&doi=10.1109%2fCEEC.2015.7332717&partnerID=40&md5=a4aed2e637b786825baceeab52932b70","We asked four subjects to perform the task of pressing a taster button with their thumbs, while their EEG recordings were obtained, in order to determine the probability of the subjects' intention to make the movement in comparison to the idle state. Humans usually spontaneously decide when to initiate movements to complete daily-life tasks, but sometimes our movements can also be externally triggered. Thus, the subjects first performed motor tasks at the instants defined by the animation shown on the screen and second, the subjects performed self-initiated movements. In this paper, we study if there is a difference in the classification results and coherence measures of EEG signals in these two paradigms. We used the Support Vector Machine (SVM) classifier on features extracted by applying Burg's algorithm to EEG signals, which arose as a solution with high accuracy. © 2015 IEEE.","Brain-Computer Interface; EEG; Neural Signal Processing; Support Vector Machines","Brain computer interface; Electroencephalography; Interfaces (computer); Signal processing; Support vector machines; Burg's algorithms; Classification results; Daily lives; EEG recording; Finger movements; High-accuracy; Motor tasks; Neural signal processing; Biomedical signal processing",2-s2.0-84963641796
"Sirkï T., Haaranen L.","Acos Server: Towards smart learning content interoperability",2015,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959879937&doi=10.1145%2f2828959.2828981&partnerID=40&md5=95edc6916fdf725617bb14543cff93ff","Modern learning environments support a variety of smart learning content, such as animations, exercises or other in- teractive learning material. These can be incorporated into different online platforms. However, there are many technical challenges in using the same smart learning content in mul- tiple learning management systems. We describe the main problems of this area and present our content server archi- tecture which emphasises interoperability of smart learning content and provides an easy way for instructors to add new learning material to their course. © 2015 Copyright held by the owner/author(s).","Interoperability; Online education; Smart learning content","Curricula; Distance education; Interoperability; Content servers; Learning contents; Learning environments; Learning management system; Learning materials; On-line education; Online platforms; Technical challenges; Computer aided instruction",2-s2.0-84959879937
"Díaz L.M., Gaytán-Lugo L.S., Fleck L.","Interaction styles in alice: Notes and observations from computer animation workshops",2015,"Proceedings of the 7th Latin American Conference on Human Computer Interaction, CLIHC 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979684038&doi=10.1145%2f2824893.2824910&partnerID=40&md5=54de07d292608f95a417ec9296de07b7","After several years conducting workshops on computer animation with Alice, a free platform for three dimensional computer animation created by Carnegie Mellon University, a pattern of styles of use was detected. It appears that participants in such workshops engage with the platform in one of four ways: 1) following instructions and copying the animation that the instructor is showing, 2) creating rich and visually attractive scenes with little or no movement, 3) inventing dialogue-based stories and placing characters in the scene to act them, and 4) scripting complex movement-rich scenes that use advanced features of Alice. In this paper we recount how we came to notice the patterns, describe the styles in detail, propose a process to validate their consistency across groups and events, and discuss why studying these styles could be relevant and revealing. © 2015 ACM.","Alice; Computer animation; Interaction styles","Animation; Microcomputers; Alice; Carnegie Mellon University; Computer animation; Interaction styles; Human computer interaction",2-s2.0-84979684038
"Kokkinara E., McDonnell R.","Animation realism affects perceived character appeal of a self-virtual face",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964343855&doi=10.1145%2f2822013.2822035&partnerID=40&md5=2f01f2c907591d5a0d36b0a57b6ec180","Appearance and animation realism of virtual characters in games, movies or other VR applications has been shown to affect audiences levels of acceptance and engagement with these characters. However, when a virtual character is representing us in VR setup, the level of engagement might also depend on the levels of perceived ownership and sense of control (agency) we feel towards this virtual character. In this study, we used advanced face-tracking technology in order to map real-time tracking data of participants' head and eye movements, as well as facial expressions on virtual faces with different appearance realism characteristics (realistic or cartoon-like) and different levels of animation realism (complete or reduced facial movements). Our results suggest that virtual faces are perceived as more appealing when higher levels of animation realism are provided through real-time tracking. Moreover, highlevels of face-ownership and agency can be induced through synchronous mapping of the face tracking on the virtual face. In this study, we provide valuable insights for future games that use face tracking as an input. © 2015 ACM.","Animation realism; Character appeal; Engagement; Face ownership; Face tracking","Eye movements; Face recognition; Interactive computer graphics; Character appeal; Engagement; Face ownership; Face Tracking; Facial Expressions; Facial movements; Real time tracking; Virtual character; Animation",2-s2.0-84964343855
"Kavafoglu Z., Kavafoglu E., Egges A.","Robust balance shift control with posture optimization",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964336636&doi=10.1145%2f2822013.2822020&partnerID=40&md5=82d0f905190f75c8b4d4d07171367d1f","In this paper we present a control framework which creates robust and natural balance shifting behaviours during standing. Given high-level features such as the position of the center of mass projection and the foot configurations, a kinematic posture satisfying these features is synthesized using online optimization. The physics-based control framework of the system calculates internal joint torques that enable tracking the optimized posture together with balance and pelvis control. Our system results in a very stable pose regardless of the position of the COM projection within the foot support polygon. This is achieved using an online knee bending and hip joint position optimization scheme. Moreover, we improve the robustness of the character under external perturbations by an arm control strategy that regulates the body's angular momentum. The capabilities of the system are demonstrated under different scenarios. The proposed framework doesn't include equations of motions or inverse dynamics. The simulations run in real-time on a standard modern PC without needing any preprocessing like offline parameter optimization. As a result, our system is suitable for commercial real-time graphics applications such as games. © 2015 ACM.","Balance control; Character animation; Physics-based animation; Standing","Equations of motion; Interactive computer graphics; Joints (anatomy); Balance control; Character animation; External perturbations; High-level features; Online optimization; Parameter optimization; Physics-based animation; Standing; Animation",2-s2.0-84964336636
"Reverdy C., Gibet S., Larboulette C.","Optimal marker set for motion capture of dynamical facial expressions",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964337213&doi=10.1145%2f2822013.2822042&partnerID=40&md5=9a31d3d2cdb280cfbdee94cb40c8380d","We seek to determine an optimal set of markers for marker-based facial motion capture and animation control. The problem is addressed in two different ways: on the one hand, different sets of empirical markers classically used in computer animation are evaluated; on the other hand, a clustering method that automatically determines optimal marker sets is proposed and compared with the empirical marker sets. To evaluate the quality of a set of markers, we use a blendshape-based synthesis technique that learns the mapping between marker positions and blendshape weights, and we calculate the reconstruction error of various animated sequences created from the considered set of markers in comparison to ground truth data. Our results show that the clustering method outperforms the heuristic approach. © 2015 ACM.","Clustering; Facial animation; Gaussian process regression; K-means","Cluster analysis; Heuristic methods; Interactive computer graphics; Optimization; Quality control; Clustering; Facial animation; Facial motion capture; Gaussian process regression; Heuristic approach; K-means; Reconstruction error; Synthesis techniques; Animation",2-s2.0-84964337213
"Carensac S., Pronost N., Bouakaz S.","Real-time gait control for partially immersed bipeds",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964327195&doi=10.1145%2f2822013.2822016&partnerID=40&md5=a98aa867bfd22c3429d4dc118b33c63b","Physics-based animation is an increasingly studied subject of computer animation because it allows natural interactions with the virtual environment. Though some existing motion controllers can handle the simulation of interactions between a character and a liquid, only few methods focus on the simulation of the locomotion of immersed bipeds. In this paper, we present a control strategy capable of simulating partially immersed gaits. The impact of the liquid on the character's motion is modeled through simple hydrodynamics. To produce natural looking animations, we design a controller allowing the combination of multiple gait styles, the conservation of balance through intelligent foot placement and precise control of the character's speed. We determine the optimal parameters for the controller by using an optimization process. This optimization is repeated for several scenarios where the character has to walk across a volume of liquid parametrized by its height. Our controller produces natural looking gaits while being capable of online adaptation to the variation of liquid height, to the modification of the liquid density and viscosity and to the variation of the required character's speed.","Motion control; Offline optimization; Physics-based animation; Real-time liquid interaction; Virtual human","Animation; Biped locomotion; Interactive computer graphics; Liquids; Motion control; Virtual reality; Control strategies; Liquid interactions; Natural interactions; Off-line optimization; Partially immersed; Physics-based animation; Real-time gait control; Virtual humans; Controllers",2-s2.0-84964327195
"Miller M., Holden D., Al-Ashqar R., Dubach C., Mitchell K., Komura T.","Carpet unrolling for character control on uneven terrain",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964407347&doi=10.1145%2f2822013.2822031&partnerID=40&md5=ad416f06e200133d9311cab766b5ba55","We propose a type of relationship descriptor based on carpet unrolling that computes the joint positions of a character based on the sum of relative vectors originating from a local coordinate system embedded on the surface of a carpet. Given a terrain that a character is to walk over, the carpet is unrolled over the surface of the terrain. The carpet adapts to the geometry of the terrain and curves according to the trajectory of the character. Because trajectories of the body parts are computed as a weighted sum of the relative vectors, the character can smoothly adapt to the elevation of the terrain and the horizontal curves of the carpet. The carpet relationship descriptors are easy to parallelize and hundreds of characters can be animated in real-time by making use of the GPUs. This makes it applicable to real-time applications such as computer games. © 2015 ACM.","Animation; Character animation; Computer games; Locomotion; Relationship descriptors; Video games","Animation; Biped locomotion; Human computer interaction; Interactive computer graphics; Landforms; Program processors; Character animation; Descriptors; Horizontal curves; Local coordinate system; Real-time application; Uneven terrain; Video game; Weighted Sum; Computer games",2-s2.0-84964407347
"Dominguez C.A., Ichimura Y., Kapadia M.","Automated interactive narrative synthesis using dramatic theory",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964372803&doi=10.1145%2f2822013.2822028&partnerID=40&md5=44c808bbc77155286aaae99d05f851ad","Current systems for automatic narrative generation lack modularity in their authoring tools as well as the ability to accommodate a human player's interaction with the characters while simultaneously preserving narrative integrity. In this paper, we propose a logical formalism of a story that incorporates an exposition, rising action, climax, falling action, and a story resolution, conforming to the widely established and studied Freytag model of a narrative. Using computational tools, our system is able to automatically synthesize stories that are grounded in narrative theory. These logical representations of stories are transformed into its equivalent Parameterized Behavior Tree (PBT) representation to facilitate an animated discourse of the narrative by leveraging existing character animations tools. Next, we automatically transform these passive narratives into interactive narratives by introducing narrative revision and nudge - two extensions that preserve narrative integrity while still allowing the player to assume control of any character at any point in the story, and the freedom to experience the story in any way he sees fit. Our results demonstrate the promise of leveraging computational intelligence for automated interactive narrative synthesis while being firmly established in classical narrative theory. © 2015 ACM.","Automated narrative synthesis; Behavior trees; Dramatic theory; Freytag's pyramid; Interactive narrative","Animation; Artificial intelligence; Automation; Computer aided software engineering; Forestry; Interactive computer graphics; Behavior trees; Character animation; Computational tools; Dramatic theory; Freytag's pyramid; Interactive narrative; Logical formalism; Logical representations; Computation theory",2-s2.0-84964372803
"Jordao K., Charalambous P., Christie M., Pettré J., Cani M.-P.","Crowd art: Density and flow based crowd motion design",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964328467&doi=10.1145%2f2822013.2822023&partnerID=40&md5=ac6b72279edba6d4f37c71ed2832b49f","Artists, animation and game designers are in demand for solutions to easily populate large virtual environments with crowds that satisfy desired visual features. This paper presents a method to intuitively populate virtual environments by specifying two key features: localized density, being the amount of agents per unit of surface, and localized flow, being the direction in which agents move through a unit of surface. The technique we propose is also timeindependant, meaning that whatever the time in the animation, the resulting crowd satisfies both features. To achieve this, our approach relies on the Crowd Patches model. After discretizing the environment into regular patches and creating a graph that links these patches, an iterative optimization process computes the local changes to apply on each patch (increasing/reducing the number of agents in each patch, updating the directions of agents in the patch) in order to satisfy overall density and flow constraints. A specific stage is then introduced after each iteration to avoid the creation of local loops by using a global pathfinding process. As a result, the method has the capacity of generating large realistic crowds in minutes that endlessly satisfy both user specified densities and flow directions, and is robust to contradictory inputs. At last, to ease the design the method is implemented in an artist-driven tool through a painting interface. © 2015 ACM.","Crowd animation; Crowd design; Crowd Patches","Design; Flow graphs; Interactive computer graphics; Iterative methods; Virtual reality; Crowd animation; Crowd Patches; Flow direction; Game designers; Iterative Optimization; Large virtual environments; Motion design; Visual feature; Animation",2-s2.0-84964328467
"Xie H., Miyata K.","Pattern-guided simulations of immersed rigid bodies",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964318629&doi=10.1145%2f2822013.2822019&partnerID=40&md5=0ba35cd182dbba0a9e8b3473726d0ff9","This paper proposes a pattern-guided framework for immersed rigid body simulations involving unsteady dynamics of a fully immersed or submerged rigid body in a still flow. Instead of the heavy computation of fluid-body coupling simulations, a novel framework considering different flow effects from the surrounding flow is constructed by parameter estimation of force coefficients. We distinguish the flow effects of the inertial, viscous and turbulent effects to the rigid body. It is difficult to clarify the force coefficients of viscous effect in real flow. In this paper we define the control parameters of viscous forces in rigid body simulator, and propose a energy optimization strategy for determining the time series of control parameters. This strategy is built upon a motion graph of motion patterns and the turbulent kinetic energy. The proposed approach achieves efficient and realistic immersed rigid body simulation results, and these results are relevant to the real-time animations of body-vorticity coupling. © 2015 ACM.","Motion patterns; Parameter subspace; Rigid body","Animation; Interactive computer graphics; Kinetic energy; Kinetics; Rigid structures; Time and motion study; Coupling simulation; Motion pattern; Parameter subspace; Real-time animations; Rigid body; Rigid-body simulations; Submerged rigid body; Turbulent kinetic energy; Bodies of revolution",2-s2.0-84964318629
"Mahmudi M., Kallmann M.","Multi-modal data-driven motion planning and synthesis",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964326583&doi=10.1145%2f2822013.2822044&partnerID=40&md5=f3c1ffef10d0e2aac6a8cbf5e5c82cf3","We present a new approach for whole-body motion synthesis that is able to generate high-quality motions for challenging mobilemanipulation scenarios. Our approach decouples the problem in specialized locomotion and manipulation skills, and proposes a multi-modal planning scheme that explores the search space of each skill together with the possible transition points between skills. In order to achieve high-quality results the locomotion skill is designed to be fully data-driven, while manipulation skills can be algorithmic or data-driven according to data availability and the complexity of the environment. Our method is able to automatically generate complex motions with precise manipulation targets among obstacles and in coordination with locomotion. © 2015 ACM.","Character animation; Motion capture; Motion planning","Animation; Coordination reactions; Interactive computer graphics; Modal analysis; Parallel processing systems; Character animation; Data availability; Motion capture; Multi-modal data; Planning scheme; Precise manipulation; Transition point; Whole-body motion; Motion planning",2-s2.0-84964326583
"Duchowski A., Jörg S., Lawson A., Bolte T., Świrski L., Krejtz K.","Eye movement synthesis with 1/f pink noise",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964397429&doi=10.1145%2f2822013.2822014&partnerID=40&md5=8c7a50dd519310a5bcf1d18229c17363","Eye movements are an essential part of non-verbal behavior. Nonplayer characters (NPCs), as they occur in many games, communicate with the player through dialogues and non-verbal behavior and can have a strong influence on the player experience or even on gameplay. In this paper we propose a procedural model to synthesize the subtleties of eye motions. More specifically, our model adds microsaccadic jitter and pupil unrest both modeled by 1/f or pink noise to the standard main sequence. In a perceptual twoalternative forced-choice (2AFC) experiment we explore the perceived naturalness of different parameters of pink noise by comparing synthesized motions to rendered motion of recorded eye movements at extreme close shot and close shot distances. Our results show that, on average, data-driven motion is perceived as most natural, followed by parameterized pink noise, with motion lacking microsaccadic jitter being consistently selected as the least natural in appearance. © 2015 ACM.","Character animation; Eye movements; Gaze synthesis; Microsaccades; Pupil unrest","Animation; Interactive computer graphics; Jitter; Speech; Character animation; Gaze synthesis; Microsaccades; Non-player character; Nonverbal behavior; Player experience; Procedural modeling; Pupil unrest; Eye movements",2-s2.0-84964397429
"Manteaux P.-L., Sun W.-L., Faure F., Cani M.-P., O'Brien J.F.","Interactive detailed cutting of thin sheets",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964355752&doi=10.1145%2f2822013.2822018&partnerID=40&md5=e956e1a0655933feae942048a0476932","In this paper we propose a method for the interactive detailed cutting of deformable thin sheets. Our method builds on the ability of frame-based simulation to solve for dynamics using very few control frames while embedding highly detailed geometry - here an adaptive mesh that accurately represents the cut boundaries. Our solution relies on a non-manifold grid to compute shape functions that faithfully adapt to the topological changes occurring while cutting. New frames are dynamically inserted to describe new regions. We provide incremental mechanisms for updating simulation data, enabling us to achieve interactive rates. We illustrate our method with examples inspired by the traditional Kirigami artform. Copyright is held by the owner/author(s).","Cutting; Interactive; Physics-based animation; Thin sheets","Cutting; Interactive computer graphics; Adaptive meshes; Interactive; Interactive rates; Physics-based animation; Shape functions; Simulation data; Thin sheet; Topological changes; Animation",2-s2.0-84964355752
"Wang Y., Neff M.","Deep signatures for indexing and retrieval in large motion databases",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964409175&doi=10.1145%2f2822013.2822024&partnerID=40&md5=5d849591e99fa795c40c9cc5fde188b2","Data-driven motion research requires effective tools to compress, index, retrieve and reconstruct captured motion data. In this paper, we present a novel method to perform these tasks using a deep learning architecture. Our deep autoencoder, a form of artificial neural network, encodes motion segments into ""deep signatures"". This signature is formed by concatenating signatures for functionally different parts of the body. The deep signature is a highly condensed representation of a motion segment, requiring only 20 bytes, yet still encoding high level motion features. It can be used to produce a very compact representation of a motion database that can be effectively used for motion indexing and retrieval, with a very small memory footprint. Database searches are reduced to low cost binary comparisons of signatures. Motion reconstruction is achieved by fixing a ""deep signature"" that is missing a section using Gibbs Sampling. We tested both manually and automatically segmented motion databases and our experiments show that extracting the deep signature is fast and scales well with large databases. Given a query motion, similar motion segments can be retrieved at interactive speed with excellent match quality. © 2015 ACM.","Character animation; Deep learning; Motion indexing; Motion retrieval","Animation; Encoding (symbols); Indexing (of information); Interactive computer graphics; Neural networks; Query processing; Search engines; Character animation; Compact representation; Condensed representations; Deep learning; Indexing and retrieval; Motion reconstruction; Motion retrieval; Small memory footprint; Database systems",2-s2.0-84964409175
"Imhof N., Milliez A., Jenal F., Bauer R., Gross M., Sumner R.W.","Fin textures for real-time painterly aesthetics",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964407182&doi=10.1145%2f2822013.2822021&partnerID=40&md5=4cf5c64b8c1591ee6331697b4f880b7c","We present a novel method for real-time stylized rendering in video games. Recent advances in painterly character authoring and rendering allow artists to create characters represented by 3D geometry as well as 3D paint strokes embedded on and around that geometry. The resulting 3D paintings are rendered in screen space using special-purpose offline rendering algorithms to achieve a unique painterly style. While providing novel styles for offline rendering, existing techniques do not support real-time applications. In this paper, we propose a method to interactively render these complex 3D paintings with a focus on character animation in video games. After observing that off-surface paint strokes can be interpreted as volumetric data in the proximity of 3D meshes, we review existing volumetric texture techniques and show that they are not adapted to paint strokes, which can be sparse and have a significant structure that should be preserved. We propose a method based on fin textures in which mesh edges are extended orthogonally off the surface and textured to replicate the results of the custom offline rendering method. Our algorithm uses a per-pixel normal calculation in order to fade in fin textures along boundary views. Our results demonstrate real-time performance using a commodity game engine while maintaining a painterly style comparable to offline methods. © 2015 ACM.","Non-photorealistic rendering; Painterly rendering; Real-time rendering; Stylization","Animation; Computer graphics; Fins (heat exchange); Human computer interaction; Interactive computer graphics; Paint; Rendering (computer graphics); Volumetric analysis; Non-Photorealistic Rendering; Painterly Rendering; Real time performance; Real-time application; Real-time rendering; Rendering algorithms; Stylization; Volumetric textures; Three dimensional computer graphics",2-s2.0-84964407182
"Parenthoen M., Murie F., Thery F.","The sea is your mirror",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964370873&doi=10.1145%2f2822013.2822038&partnerID=40&md5=83e6361debc64435faed434f41dbd80d","The Sea Is Your Mirror is an artistic interactive experience where surface cerebral electromagnetic waves from a participant wearing an EEG sensor headset are depicted in real-time as ocean waves in an animated 3D environment. The aim of this article is to describe the sea wave model used for the sea state animation and how it is connected to the brain computer interface (BCI). The sea state is animated by the groupy choppy wave model that provides nonlinear sea states with wave groups and asymmetric wave shapes. The BCI maps the temporal spectrum of the electroencephalogram onto the elevation spectrum of the sea surface. The resulting setup enables the participant to fly over a dynamic sea state: a metaphor for conscious and unconscious neurofeedback. Copyright is held by the owner/author(s).","Animation; Art and science; BCI; EEG; Natural phenomena; Sea wave; Virtual reality","Animation; Electroencephalography; Electromagnetic waves; Interactive computer graphics; Interface states; Interfaces (computer); Mirrors; Ocean currents; Surface waters; Virtual reality; Water waves; 3-D environments; Art and science; Asymmetric waves; Natural phenomena; Neurofeedback; Sea wave models; Sea waves; Wave modeling; Brain computer interface",2-s2.0-84964370873
"Bouchard D., Badler N.I.","Segmenting motion capture data using a qualitative Analysis",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964329225&doi=10.1145%2f2822013.2822039&partnerID=40&md5=73d35ff036f062501eacf34af862cd11","Many interactive 3D games utilize motion capture for both character animation and user input. These applications require short, meaningful sequences of data. Manually producing these segments of motion capture data is a laborious, time-consuming process that is impractical for real-time applications. We present a method to automatically produce semantic segmentations of general motion capture data by examining the qualitative properties that are intrinsic to all motions, using Laban Movement Analysis (LMA). LMA provides a good compromise between high-level semantic features, which are difficult to extract for general motions, and lowlevel kinematic features, which often yield unsophisticated segmentations. Our method finds motion sequences which exhibit high output similarity from a collection of neural networks trained with temporal variance. We show that segmentations produced using LMA features are more similar to manual segmentations, both at the frame and the segment level, than several other automatic segmentation methods. © 2015 ACM.","Human motion; Laban movement analysis; Motion capture; Motion segmentation","Interactive computer graphics; Semantics; Automatic segmentations; High-level semantic features; Human motions; Motion capture; Motion segmentation; Movement analysis; Qualitative properties; Real-time application; Animation",2-s2.0-84964329225
"Rumman N.A., Schaerf M., Bechmann D.","Collision detection for articulated deformable characters",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964372757&doi=10.1145%2f2822013.2822034&partnerID=40&md5=92ac22d73b0800a3213a589affa9822d","In this paper, we present an efficient method for detecting collisions and self-collisions on articulated models deformed by Position Based Skinning. Position Based Skinning is a real-time skinning method, which produces believable skin deformations, and avoids artifacts such as the well-known ""candy-wrapper"" effect and joint-bulging. The proposed method employs spatial hashing with a uniform grid to detect collisions and self collisions. All the mesh primitives are mapped to a hash table, where only primitives mapped to the same hash index indicate a possible collision and need to be tested for intersections. Being based on spatial hashing, our method requires neither expensive set-up nor complex data structures and is hence suitable for articulated characters with deformable soft tissues. We exploit the skeletal nature of the deformation to only update the hash table when required. The resulting algorithm is simple to implement and fast enough for real-time applications. We demonstrate the efficiency of our method on various animation examples. A quantitative experiment is also presented to evaluate our method. © 2015 ACM.","Articulated characters; Collision detection; Deformable bodies; Spatial hashing","Animation; Data structures; Interactive computer graphics; Object detection; Articulated characters; Articulated models; Collision detection; Complex data structures; Deformable bodies; Quantitative experiments; Real-time application; Spatial hashing; Deformation",2-s2.0-84964372757
"Duits R., Egges A., Van Der Stappen A.F.","A closed-form solution for human finger positioning",2015,"Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964324447&doi=10.1145%2f2822013.2822041&partnerID=40&md5=99b207db95e6290bcf6bac9e53a8b657","In this paper we describe a novel technique for solving the inverse kinematics problem for human fingers. We derive a closed-form solution that places the fingertips precisely in the desired location by allowing minor deviations in the rotations of the Proximal Interphalangeal and Distal Interphalangeal joints compared to the fixed ratio that is known to exist between them. The obvious advantage is that with our approach there is no need to iterate until the distance between the fingertips and the desired locations is small enough. We show that this method is reliable and exact while showing minimal differences to the finger poses generated by the original closed-form solution. In our experiments we found the positions of the intermediate joints of the finger to deviate only around 1.5 mm in the worst case from those resulting from a numerical approximation of the original closed-form solution. On average the deviation is less than 0.5 millimeter. © 2015 ACM.","Animation; Human finger; Inverse kinematics","Animation; Interactive computer graphics; Inverse kinematics; Kinematics; Closed form solutions; Distal interphalangeal joint; Human fingers; Novel techniques; Numerical approximations; Inverse problems",2-s2.0-84964324447
"Xing Y., Xu R.-Z., Tan J.-Q., Fan W., Hong L.","A class of generalized B-spline quaternion curves",2015,"Applied Mathematics and Computation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942945229&doi=10.1016%2fj.amc.2015.09.025&partnerID=40&md5=d02be7b9c1cc0cdb52b38166156c91df","Unit quaternion curves have gained considerable attention in the fields of robot control and computer animation. Kim et al. proposed a general construction method of unit quaternion curves which can transform the closed form equation for kth order B-spline basis functions in R3 into its unit quaternion analogue in SO(3) while preserving the Ck-2-continuity. Juhász and Róth generalized the classical B-spline functions by means of monotone increasing continuously differentiable core functions based on the recurrence formula of B-spline functions. In order to extend the applications of the generalized B-spline functions in computer animation, the definition and construction scheme of generalized B-spline quaternion curves in S3 are put forward in this paper. The introduced nonlinear core functions are not only theoretically interesting, but also offer a large variety of shapes. Some properties of this class of unit quaternion curves, such as continuity and local controllability are also discussed. Experimental results show the effectiveness and usefulness of our construction methods of generalized B-spline quaternion curves. © 2015 Elsevier Inc. All rights reserved.","Ck-continuity; Quaternion; S3(Unit 3-sphere), Generalized B-spline; SO(3)(3D rotation group)","Animation; Curve fitting; Splines; 3D rotation; B splines; B-spline basis function; Closed-form equations; Continuously differentiable; Generalized B spline function; Local controllability; Quaternion; Interpolation",2-s2.0-84942945229
"Milota A.","The application of word processor ui paradigms to audio and animation editing",2015,"ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959306644&doi=10.1145%2f2818346.2823292&partnerID=40&md5=914bf885a47cfc80bcef6c5160fa0a92","This demonstration showcases Quixotic, an audio editor, and Quintessence, an animation editor. Both appropriate many of the interaction techniques found in word processors, and allow users to more quickly create time-variant media. Our different approach to the interface aims to make recorded speech and simple animation into media that can be efficiently used for one-to-one asynchronous communications, quick note taking and documentation, as well as for idea refinement. © 2015 ACM.","Animation; Audio editing; Word processing","Interactive computer systems; Word processing; Animation editing; Asynchronous communication; Audio editing; Interaction techniques; Note taking; Time variant; Word processor; Animation",2-s2.0-84959306644
"Sadoughi N., Busso C.","Retrieving target gestures toward speech driven animation with meaningful behaviors",2015,"ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959298713&doi=10.1145%2f2818346.2820750&partnerID=40&md5=4dc88ecc2ddc80bf8913af8a652ce2c4","Creating believable behaviors for conversational agents (CAs) is a challenging task, given the complex relationship between speech and various nonverbal behaviors. The two main approaches are rule-based systems, which tend to produce behaviors with limited variations compared to natural interactions, and data-driven systems, which tend to ignore the underlying semantic meaning of the message (e.g., gestures without meaning). We envision a hybrid system, acting as the behavior realization layer in rule-based systems, while exploiting the rich variation in natural interactions. Constrained on a given target gesture (e.g., head nod) and speech signal, the system will generate novel realizations learned from the data, capturing the timely relationship between speech and gestures. An important task in this research is identifying multiple examples of the target gestures in the corpus. This paper proposes a data mining framework for detecting gestures of interest in a motion capture database. First, we train One-class support vector machines (SVMs) to detect candidate segments conveying the target gesture. Second, we use dynamic time alignment kernel (DTAK) to compare the similarity between the examples (i.e., target gesture) and the given segments. We evaluate the approach for five prototypical hand and head gestures showing reasonable performance. These retrieved gestures are then used to train a speech-driven framework based on dynamic Bayesian networks (DBNs) to synthesize these target behaviors. © 2015 ACM.","Conversational agents; Gesture retrieval; Speech-driven animations","Bayesian networks; Complex networks; Data mining; Gesture recognition; Hybrid systems; Interactive computer systems; Speech; Support vector machines; Believable behavior; Complex relationships; Conversational agents; Data mining frameworks; Gesture retrieval; Natural interactions; Nonverbal behavior; One-class support vector machine; Semantics",2-s2.0-84959298713
"Tannous H., Dao T.T., Istrate D., Tho M.-C.H.B.","Serious game for functional rehabilitation",2015,"2015 International Conference on Advances in Biomedical Engineering, ICABME 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962878640&doi=10.1109%2fICABME.2015.7323297&partnerID=40&md5=8ebfe75efa52474f867b90bf893c3568","Conventional musculoskeletal rehabilitation consists of a therapy consultancy, an exercise assignment, and an execution task with or without assistance of the therapist. This classical approach consumes much of the patient's time, money and effort, as well as the medical staff's. Serious games have been devised as an aided tool for clinical and home-based rehabilitation, with patient autonomy in the exercise execution but monitored by the therapist. The aim of this present study was to develop a real-time serious gaming system including a series of locomotion training exercises for musculoskeletal rehabilitation. Kinect sensor was used to capture real-time kinematics during each exercise. Six exercises with different levels of difficulties were designed and created. Several graphical user interfaces were developed for 3D animation and kinematic feedback tracking and visualization. An evaluation campaign with ten healthy subjects was established to assess the developed system. Obtained results showed that our system is robust and user-friendly for motivating the patient during his functional rehabilitation program at his clinic or at home. © 2015 IEEE.","Functional rehabilitation; Kinect sensor; musculoskeletal system; real-time monitoring; rehabilitation at home; serious game","Animation; Biomedical engineering; Graphical user interfaces; Kinematics; Musculoskeletal system; Three dimensional computer graphics; User interfaces; Classical approach; Kinect sensors; Locomotion trainings; Real time kinematic; Real time monitoring; Rehabilitation at homes; Rehabilitation programs; Serious games; Patient rehabilitation",2-s2.0-84962878640
"Janssoone T.","Temporal association rules for modelling multimodal social signals",2015,"ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959277769&doi=10.1145%2f2818346.2823305&partnerID=40&md5=c094e2fa49863211f557b8a5b20949a5","In this paper, we present the first step of a methodology dedicated to deduce automatically sequences of signals expressed by humans during an interaction. The aim is to link interpersonal stances with arrangements of social signals such as modulations of Action Units and prosody during a face-to-face exchange. The long-term goal is to infer association rules of signals. We plan to use them as an input to the animation of an Embodied Conversational Agent (ECA). In this paper, we illustrate the proposed methodology to the SEMAINE-DB corpus from which we automatically extracted Action Units (AUs), head positions, turn-taking and prosody information. We have applied the data mining algorithm that is used to find the sequences of social signals featuring different social stances. We finally discuss our primary results focusing on given AUs (smiles and eyebrows) and the perspectives of this method. © 2015 ACM.","Action Unit; Data mining; Data processing; Facial expression; Interpersonal stance; Prosody; Sequence mining; Social signal processing","Algorithms; Association rules; Data handling; Data processing; Face recognition; Gesture recognition; Interactive computer systems; Signal processing; User interfaces; Action Unit; Facial Expressions; Interpersonal stance; Prosody; Sequence mining; Social signal processing; Data mining",2-s2.0-84959277769
"De Kok I., Hough J., Hülsmann F., Botsch M., Schlangen D., Kopp S.","A multimodal system for real-time action instruction in motor skill learning",2015,"ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959300764&doi=10.1145%2f2818346.2820746&partnerID=40&md5=0271b56809ac563c98e428394a28459d","We present a multimodal coaching system that supports online motor skill learning. In this domain, closed-loop interaction between the movements of the user and the action instructions by the system is an essential requirement. To achieve this, the actions of the user need to be measured and evaluated and the system must be able to give corrective instructions on the ongoing performance. Timely delivery of these instructions, particularly during execution of the motor skill by the user, is thus of the highest importance. Based on the results of an empirical study on motor skill coaching, we analyze the requirements for an interactive coaching system and present an architecture that combines motion analysis, dialogue management, and virtual human animation in a motion tracking and 3D virtual reality hardware setup. In a preliminary study we demonstrate that the current system is capable of delivering the closed-loop interaction that is required in the motor skill learning domain. © 2015 ACM.","Coaching; Motor skill learning; Multimodal interaction; Virtual human; Virtual reality","Interactive computer systems; Motion analysis; 3D virtual reality; Coaching; Dialogue management; Empirical studies; Motor skill learning; Multi-Modal Interactions; Multimodal system; Virtual humans; Virtual reality",2-s2.0-84959300764
"Momeni A., Rispoli Z.","Dranimate: Rapid real-time gestural rigging and control of animation",2015,"UIST 2015 - Adjunct Publication of the 28th Annual ACM Symposium on User Interface Software and Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962788150&doi=10.1145%2f2815585.2817815&partnerID=40&md5=72e51d88e35ce22d0922b57747fdc6ae","Dranimate is an interactive animation system that allows users to rapidly and intuitively rig and control animations based on a still image or drawing, using hand gestures. Dranimate combines two complementary methods of shape manipulation: bone-joint-based physics simulation, and the as-rigid-as-possible deformation algorithm. Dranimate also introduces a number of designed interactions that focus the users attention on the animated content, as opposed to computer keyboard or mouse.","Animation; Gestural control; Puppetry","Animation; Complementary methods; Gestural control; Hand gesture; Interactive animations; Physics simulation; Puppetry; Shape manipulation; Still images; User interfaces",2-s2.0-84962788150
"Avramescu A.M.","Creating photo-realistic works in a 3D scene using layers styles to create an animation",2015,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960383314&doi=10.1088%2f1757-899X%2f95%2f1%2f012115&partnerID=40&md5=af9bd369839c2fee0e2e8a32b630b70e","Creating realist objects in a 3D scene is not an easy work. We have to be very careful to make the creation very detailed. If we don't know how to make these photo-realistic works, by using the techniques and a good reference photo we can create an amazing amount of detail and realism. For example, in this article there are some of these detailed methods from which we can learn the techniques necessary to make beautiful and realistic objects in a scene. More precisely, in this paper, we present how to create a 3D animated scene, mainly using the Pen Tool and Blending Options. Indeed, this work is based on teaching some simple ways of using the Layer Styles to create some great shadows, lights, textures and a realistic sense of 3 Dimension. The present work involves also showing how some interesting ways of using the illuminating and rendering options can create a realistic effect in a scene. Moreover, this article shows how to create photo realistic 3D models from a digital image. The present work proposes to present how to use Illustrator paths, texturing, basic lighting and rendering, how to apply textures and how to parent the building and objects components. We also propose to use this proposition to recreate smaller details or 3D objects from a 2D image. After a critic art stage, we are able now to present in this paper the architecture of a design method that proposes to create an animation. The aim is to create a conceptual and methodological tutorial to address this issue both scientifically and in practice. This objective also includes proposing, on strong scientific basis, a model that gives the possibility of a better understanding of the techniques necessary to create a realistic animation..",,"Animation; Content based retrieval; Teaching; Technology transfer; Three dimensional computer graphics; 2D images; 3-dimension; 3D models; 3D object; Design method; Digital image; Photo-realistic; Scientific basis; Rendering (computer graphics)",2-s2.0-84960383314
"Avramescu A.M.","Special effects used in creating 3D animated scenes-part 1",2015,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960328342&doi=10.1088%2f1757-899X%2f95%2f1%2f012116&partnerID=40&md5=7dda5c76cf1c906c0cd038ffb19c6b22","In present, with the help of computer, we can create special effects that look so real that we almost don't perceive them as being different. These special effects are somehow hard to differentiate from the real elements like those on the screen. With the increasingly accesible 3D field that has more and more areas of application, the 3D technology goes easily from architecture to product designing. Real like 3D animations are used as means of learning, for multimedia presentations of big global corporations, for special effects and even for virtual actors in movies. Technology, as part of the movie art, is considered a prerequisite but the cinematography is the first art that had to wait for the correct intersection of technological development, innovation and human vision in order to attain full achievement. Increasingly more often, the majority of industries is using 3D sequences (three dimensional). 3D represented graphics, commercials and special effects from movies are all designed in 3D. The key for attaining real visual effects is to successfully combine various distinct elements: characters, objects, images and video scenes; like all these elements represent a whole that works in perfect harmony. This article aims to exhibit a game design from these days. Considering the advanced technology and futuristic vision of designers, nowadays we have different and multifarious game models. Special effects are decisively contributing in the creation of a realistic three-dimensional scene. These effects are essential for transmitting the emotional state of the scene. Creating the special effects is a work of finesse in order to achieve high quality scenes. Special effects can be used to get the attention of the onlooker on an object from a scene. Out of the conducted study, the best-selling game of the year 2010 was Call of Duty: Modern Warfare 2. This way, the article aims for the presented scene to be similar with many locations from this type of games, more precisely, a place from the Middle East, a very popular subject among game developers..",,"Design; Motion pictures; Product design; Advanced technology; Distinct elements; Emotional state; Multimedia presentation; Technological development; Three-dimensional scenes; Virtual actors; Visual effects; Animation",2-s2.0-84960328342
"Miyai A., Yamaguchi Y.","Development and evaluation of education materials for stereoscopic 3D computer graphics animation",2015,"SIGGRAPH Asia 2015 Symposium on Education, SA 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975744386&doi=10.1145%2f2818498.2818510&partnerID=40&md5=0e2b8124e75411a47a1cbe92341d49f1","The use of stereoscopic 3D (S3D) is increasing in movies and game contents, and it has spread also into animation. However, in the Japanese animation industry, human resources with applicable knowledge and competence in S3D production skills are insufficient. In order to improve this situation, we have set out to develop new education materials that provide basic knowledge and training in production skills. The aims of these education materials are to make S3D computer graphics (CG) animation that can be used in universities, vocational schools and companies. The education materials consist of curriculum and corresponding syllabus, digital textbooks, digital workbooks, animation, production work materials, production assignments and tests (Figure 1). In this paper, we will describe the education materials we developed, the experimental classes using these materials, and the practical tests done by subjects who participated in the experimental classes. Further, we will point out the possibilities of skills measurement using practical tests and the effectiveness of the materials, in addition to the tendencies of the subjects whose performance improves.","Animation; Computer graphics; Curriculum; Education material; Stereoscopic 3D; Testing","Computer graphics; Curricula; Education; Interactive computer graphics; Stereo image processing; Testing; Three dimensional computer graphics; 3D computer graphics; Digital textbooks; Education material; Game contents; Practical tests; Production skills; Production work; Vocational schools; Animation",2-s2.0-84975744386
"Asahina W., Okada N., Iwamoto N., Masuda T., Fukusato T., Morishima S.","Automatic facial animation generation system of dancing characters considering emotion in dance and music",2015,"SIGGRAPH Asia 2015 Posters, SA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959328445&doi=10.1145%2f2820926.2820935&partnerID=40&md5=c49ee218e416df2c2295451953b50767","In recent years, a lot of 3D character dance animation movies are created by amateur users using 3DCG animation editing tools (e.g. MikuMikuDance). Whereas, most of them are created manually. Then automatic facial animation system for dancing character will be useful to create dance movies and visualize impressions effec- tively. Therefore, we address the challenging theme to estimate dancing character's emotions (we call ""dance emotion""). In previ- ous work considering music features, DiPaola et al. [2006] pro- posed music-driven emotionally expressive face system. To de- tect the mood of the input music, they used a hierarchical frame- work (Thayer model), and achieved to generate facial animation that matches music emotion. However, their model can't express subtleties of emotion between two emotions because input music divided into few moods sharply using Gaussian mixture model. In addition, they decide more detailed moods based on the psychologi- cal rules that uses score information, so they requires MIDI data. In this paper, we propose ""dance emotion model"" to visualize danc- ing character's emotion as facial expression. Our model is built by the coordinate information frame by frame on the emotional space through perceptional experiment using music and dance mo- tion database without MIDI data. Moreover, by considering the displacement on the emotional space, we can express not only a certain emotion but also subtleties of emotions. As the result, our system got a higher accuracy comparing with the previous work. We can create the facial expression result soon by inputting audio data and synchronized motion. It is shown the utility through the comparison with previous work in Figure 1.",,"Animation; Gaussian distribution; Interactive computer graphics; 3D characters; Animation editing; Emotion modeling; Facial animation; Facial Expressions; Gaussian Mixture Model; Music emotions; Synchronized motion; Behavioral research",2-s2.0-84959328445
"Mori H., Nakadi T., Toyama F., Shoji K.","Gaze animation optimization based on a Viewer's preference",2015,"SIGGRAPH Asia 2015 Posters, SA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959366749&doi=10.1145%2f2820926.2820969&partnerID=40&md5=e67f3c658863fb75fc543b5e4bf63848","The character animation is required to appear as natural as human motion. Toward that goal, there is an approach where the expression appears as natural as the human expression by adding gaze behavior to the contextual situation, and the environment to the general behavior animation [Grillion, H. et al. 2009] Comparing the character animation before and after applying this approach, we think that the generated animation is humanlike in relative terms. However, we occasionally perceive a mechanical mpression. As a possible cause of the impression, we consider that the viewer's subjective impression of the result of gaze animation is not regarded as important. In this work, we propose a method for optimizing character gaze animation based on a viewer's prefrence (Figure. 1). We translate a character's gaz motion into parameters for the gaze controller. And, we obtain the optimized parameter for the natural gaze animation that the viewer felt using the Interactive Algorithm (IGA).",,"Interactive computer graphics; Character animation; Gaze behavior; Human motions; Interactive algorithms; Optimized parameter; Subjective impressions; Animation",2-s2.0-84959366749
"Ma W.-C.A., Rhee T., Yoshiyasu Y., Von Der Pahlen J.","Making digital characters: Creation, deformation, and animation",2015,"SIGGRAPH Asia 2015 Courses, SA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984973453&doi=10.1145%2f2818143.2818172&partnerID=40&md5=a8a19edacef14128eb93e226761b659b","Digital characters have been taken an very important role for filmmaking and video games over the last decade. Now we are at the border that the difference between digital characters and real ones are vanishing. In this course we will introduce the fundamental knowledge of how to create digital characters. A state-of-the-art workow consists of three stages: creating of the facial and body puppet, applying the right deformation techniques to the puppet, and driving the puppet with keyframe animation or motion capture data through retargeting. Our goal is to present the best practice guide in terms of making digital humans for visual production. We start with an general overview of the process on how to make digital characters. It then focuses on the details about production of facial and body puppets through 3D acquisition of geometry and texture, template registration techniques that are based on generic deformation or morphable models, using deformation transfer to automatically create believable poses, and how to use motion capture data to enhance the current poses. The second part of the course will introduce various important deformation techniques such as skinning, pose space deformation, and how to do volumetric deformation based on real body medical imaging data. Finally several animation techniques will be presented to show how to make puppets perform. Level of dificulty: intermediate.",,"Deformation; Grain size and shape; Interactive computer graphics; Medical imaging; Animation techniques; Best Practice Guide; Deformation techniques; Deformation transfer; Motion capture data; Pose space deformations; Template registration; Volumetric deformation; Animation",2-s2.0-84984973453
"Hodgkinson G.","Taking animation project learning into the virtual environment",2015,"SIGGRAPH Asia 2015 Symposium on Education, SA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975749535&doi=10.1145%2f2818498.2818506&partnerID=40&md5=48f40f297900ba856dab9b74f3ba8412","This paper demonstrates how a team of honours-level students explored a new area of game interaction, supported by an academic structure that provided flexibility, opportunity and encouraged independent exploration. This project combines the cinematic aesthetic of film, the interactivity of video gaming and the immersion of virtual reality (VR) to create a compelling and unique visual experience, at a production quality level equal to an industry prototype. The academic structure similarly was required to show great flexibility and respond to the students needs with agility. Along this journey the students gained skills with advanced 3D modelling techniques, motion-capture, the 3D goggles Oculus Rift, the game engine Unreal Engine 4, as well as other supporting skills such as script writing and concept art.",,"Animation; Education; Interactive computer graphics; Three dimensional computer graphics; Virtual reality; 3D modelling; Interactivity; Motion capture; Production quality; Project learning; Supporting skills; Video gaming; Visual experiences; Students",2-s2.0-84975749535
"Zünd F., Ryffel M., Magnenat S., Marra A., Nitti M., Kapadia M., Noris G., Mitchell K., Gross M., Sumner R.W.","Augmented creativity: Bridging the real and virtual worlds to enhance creative play",2015,"SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications, SA 2015",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960933793&doi=10.1145%2f2818427.2818460&partnerID=40&md5=a332e326dadc0c22923f5c9bfe1f8532","Augmented Reality (AR) holds unique and promising potential to bridge between real-world activities and digital experiences, allowing users to engage their imagination and boost their creativity. We propose the concept of Augmented Creativity as employing AR on modern mobile devices to enhance real-world creative activities, support education, and open new interaction possibilities. We present six prototype applications that explore and develop Augmented Creativity in different ways, cultivating creativity through AR interactivity. Our coloring book app bridges coloring and computer-generated animation by allowing children to create their own character design in an AR setting. Our music apps provide a tangible way for children to explore different music styles and instruments in order to arrange their own version of popular songs. In the gaming domain, we show how to transform passive game interaction into active real-world movement that requires coordination and cooperation between players, and how AR can be applied to city-wide gaming concepts. We employ the concept of Augmented Creativity to authoring interactive narratives with an interactive storytelling framework. Finally, we examine how Augmented Creativity can provide a more compelling way to understand complex concepts, such as computer programming.","Animation; Augmented reality; Games; Storytelling; User interaction","Augmented reality; Computer programming; Interactive computer graphics; Mobile devices; Software prototyping; Virtual reality; Computer-generated animations; Creative activity; Games; Interactive narrative; Interactive storytelling; Real-world activities; Storytelling; User interaction; Animation",2-s2.0-84960933793
"Papaefthymiou M., Feng A., Shapiro A., Papagiannakis G.","A fast and robust pipeline for populating mobile AR scenes with gamified virtual Characters",2015,"SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications, SA 2015",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960870847&doi=10.1145%2f2818427.2818463&partnerID=40&md5=83487e1077490d325a71e292594ef5d4","In this work we present a complete methodology for robust authoring of AR virtual characters powered from a versatile character animation framework (Smartbody), using only mobile devices. We can author, fully augment with life-size, animated, geometrically accurately registered virtual characters into any open space in less than 1 minute with only modern smartphones or tablets and then automatically revive this augmentation for subsequent activations from the same spot, in under a few seconds. Also, we handle efficiently scene authoring rotations of the AR objects using Geometric Algebra rotors in order to extract higher quality visual results. Moreover, we have implemented a mobile version of the global illumination for real-time Precomputed Radiance Transfer algorithm for diffuse shadowed characters in real-time, using High Dynamic Range (HDR) environment maps integrated in our opensource OpenGL Geometric Application (glGA) framework. Effective character interaction plays fundamental role in attaining high level of believability and makes the AR application more attractive and immersive based on the SmartBody framework.","Animation; Augmented reality; Geometric algebra; Illumination; Mobile precomputed radiance transfer; Procedural character animation systems; Rendering","Algebra; Application programming interfaces (API); Augmented reality; Computer graphics; Geometry; Interactive computer graphics; Lighting; Mobile devices; Character animation; Geometric Algebra; Geometric applications; Global illumination; High dynamic range; Precomputed radiance transfer; Rendering; Virtual character; Animation",2-s2.0-84960870847
"Holden D., Saito J., Komura T., Joyce T.","Learning motion manifolds with convolutional autoencoders",2015,"SIGGRAPH Asia 2015 Technical Briefs, SA 2015",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960436158&doi=10.1145%2f2820903.2820918&partnerID=40&md5=03f9c724a68cf4e2d53f07250bb5b125","We present a technique for learning a manifold of human motion data using Convolutional Autoencoders. Our approach is capable of learning a manifold on the complete CMU database of human motion. This manifold can be treated as a prior probability distribution over human motion data, which has many applications in animation research, including projecting invalid or corrupt motion onto the manifold for removing error, computing similarity between motions using geodesic distance along the manifold, and interpolation of motion along the manifold for avoiding blending artefacts. © 2015 ACM.","Animation; Autoencoding; Character animation; Convolutional neural networks; Deep neural networks; Machine learning; Manifold learning; Motion data","Animation; Artificial intelligence; Blending; Convolution; Interactive computer graphics; Neural networks; Probability distributions; Autoencoding; Character animation; Convolutional neural network; Deep neural networks; Manifold learning; Motion data; Learning systems",2-s2.0-84960436158
"Craig P.","Interactive animated mobile information visualisation",2015,"SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications, SA 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960869502&doi=10.1145%2f2818427.2818458&partnerID=40&md5=6b8945ffcdb32784b909c1ee598b5c30","While the potential of mobile information visualisation is widely recognized, there is still relatively little research in this area and few practical guidelines for the design of mobile information visualisation interfaces. Indeed, it would appear that there is still a general feeling in the interface design community that mobile visualisation should be limited to simple operations and small scale data. Information visualisation research has concentrated thus far on desktop PCs and larger displays while interfaces for more compact mobile device have been neglected. This is in spite of the increasing popularity and widespread use of smart-phones and other new mobile technologies. In this paper we address this issue by developing a set of low-level interface design guidelines for mobile information visualisation development. This is done by considering a basic set of interactions and relating these to mobile device limitations. Our results suggest that the mindful application of existing information visualisation techniques can overcome many mobile device limitations and that proper implementation of interaction mechanisms and animated view transitions are key to effective mobile information visualisation. This is illustrated with case studies looking at a coordinated map and timeline interface for geo-temporal data, a distorted scatter-plot, and a space filling hierarchy view.","Animation; Information visualisation; Mobile visualisation","Animation; Display devices; Interactive computer graphics; Mobile devices; Smartphones; Visualization; Information visualisation; Interaction mechanisms; Interface designs; Mobile information; Mobile Technology; Practical guidelines; Simple operation; Timeline interfaces; Cellular telephone systems",2-s2.0-84960869502
"Leung J., Lara D.M.","Grease pencil: Integrating animated freehand drawings into 3D production environments",2015,"SIGGRAPH Asia 2015 Technical Briefs, SA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960356811&doi=10.1145%2f2820903.2820924&partnerID=40&md5=2351ea84a77e34874c21f47d8e891a54","Freehand drawing is one of the most flexible and efficient ways of expressing creative ideas. However, it can often also be tedious and technically challenging to animate complex dimensional environments or dynamic choreographies. We present a case study of how freehand drawing tools can be integrated into an end-toend 3D content creation platform to reap the benefits from both worlds. Creative opportunities and challenges in achieving this type of integration are discussed. We also present examples from short films demonstrating the potential of how these techniques can be deployed in production environments. © 2015 ACM.","2D; 3D; Animation; Drawing; Freehand; Interface; NPR; Sketch; Storyboarding; Storytelling; Stroke-based illustration","Animation; Drawing (graphics); Interfaces (materials); Motion pictures; Freehand; Sketch; Storyboarding; Storytelling; Stroke-based illustration; Interactive computer graphics",2-s2.0-84960356811
"Song M., Grogono P., Mokhov S.A., Mudur S.P.","HCI in performance arts and the case of Illimitable Space System's multimodal interaction and visualization",2015,"SA 2015 - SIGGRAPH ASIA 2015 Art Papers",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974623563&doi=10.1145%2f2835641.2835649&partnerID=40&md5=087ede2028d5b80fe9ed8eddb6169111","The primary aim of this art paper is to present a case study of the use of modern 3D graphics and sensor technologies in interactive stage performances. Specifically, we present studies of interactive performances in which we have used the Illimitable Space System, a proof-of-concept tool box that offers configurable multimodal interaction via a variety of means. The animation and interaction are all done in real-time and can be of arbitrary duration while the system is up and running. Earlier ISS versions were exhibited in the end of 2012 and 2013 during Open House and Stewart Hall Expo-Science events, as well during the 2014 2-day Chinese New Year Gala performance during the Ascension dance at Concordia University, Montreal, Canada, and in the large Like Shadows theatre production in Beijing, China. We describe how ISS was configured and used in these events, and the valuable feedback obtained, confidence gained in interactive technology usage in performances, and lessons learned from them. All of which help us in making continuous improvements in ISS. As a result this paper includes the themes of these events, methods, theory, and history. Since technology has been used in stage performances from ancient times, we start with a brief historical background of technology in performance arts. © 2015 Copyright held by the owner/author(s).",,"Interactive computer graphics; Concordia University; Continuous improvements; Historical background; Interactive performance; Interactive technology; Montreal , Canada; Multi-Modal Interactions; Sensor technologies; Interactive computer systems",2-s2.0-84974623563
"Prophet J.","(Projection) mapping the brain: A critical cartographic approach to the artist's use of fMRI to study the contemplation of death",2015,"SA 2015 - SIGGRAPH ASIA 2015 Art Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974559957&doi=10.1145%2f2835641.2835645&partnerID=40&md5=5dbd4c15398cfcc15b66d92eb5cbe639","This paper discusses the author's artwork, Neuro Memento Mori, a self-portrait comprising digital animations and live action video projection-mapped onto a 3D print. The life-sized sculpture of the head and neck, dissected to reveal the artist's brain, was produced from MRI data gathered as the artist viewed memento mori paintings and meditated on death. The production of the artwork, made with neuroscientists, explores the relationship between the so-called frontier of neuroscience, data and the map. The use of computation to produce neuroimages, 3D prints and projected video is discussed from the perspective of critical cartography. © 2015 Copyright held by the owner/author(s).",,"3D printers; Interactive computer graphics; Maps; 3d prints; Head and neck; Live actions; Video projections; Brain mapping",2-s2.0-84974559957
"Bennett G., Kruse J.","Teaching Visual Storytelling for virtual production pipelines incorporating Motion Capture and Visual Effects",2015,"SIGGRAPH Asia 2015 Symposium on Education, SA 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975759959&doi=10.1145%2f2818498.2818516&partnerID=40&md5=5c759384318a39e7bb0fc4625593cc90","Film, television and media production are subject to consistent change due to ever-evolving technological and economic environments. Accordingly, tertiary teaching of subject areas such as cinema, animation and visual effects require frequent adjustments regarding curriculum structure and pedagogy. This paper discusses a multifaceted, cross-disciplinary approach to teaching Visual Narratives as part of a Digital Design program. Specifically, pedagogical challenges in teaching Visual Storytelling through Motion Capture and Visual Effects are addressed, and a new pedagogical framework using three different modes of moving image storytelling is applied and cited as case studies. Further, ongoing changes in film production environments and their impact on curricula for tertiary education providers are detailed, and appropriate suggestions based on tangible teaching experience are made. This paper also discusses the advantages of teaching Motion Capture in the context of immersive environments.","Curriculum; Motion capture; Narrative; Visual effects; Visual storytelling","Curricula; Education; Interactive computer graphics; Cross-disciplinary approaches; Curriculum structure; Economic environment; Immersive environment; Motion capture; Narrative; Visual effects; Visual storytellings; Teaching",2-s2.0-84975759959
"Li Y., Guo A., Chin C.L.","A platform for mobile augmented reality app creation without programming",2015,"SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications, SA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960885490&doi=10.1145%2f2818427.2818452&partnerID=40&md5=268507c33b00b7f752c43247cb62925b","There are many application areas on using smartphone to access relevant information. By taking a picture from a physical object using a smartphone app, we use image recognition technology to provide a quick link between the physical object and its relevant information. However, developing smartphone apps is expensive and time consuming. We developed a platform called MIMAS AR Creator, which is a web based software platform for automatic creation of smartphone apps for multimedia access using pictures captured from the smartphone camera and its GPS location. This platform allows people without programming skill to create a smartphone app in a few minutes with existing multimedia contents, shorten more than 90% of the app development time. The digital contents can be web pages, videos, audios, images, or 3D graphics with or without animation etc. The platform can be used for mobile advertising and retail marketing, mobile learning and tour guide etc. For example, with the created app running, people can point their phone camera to a picture on newspaper, product brochure, or physical product to obtain more relevant information provided by the advertisers or vendors. They can also point the phone camera to a building or monument to retrieve relevant historical information.",,"Augmented reality; Cameras; Image recognition; Interactive computer graphics; Marketing; Multimedia systems; Smartphones; Telephone sets; Websites; World Wide Web; Automatic creations; Historical information; Image recognition technology; Mobile advertising; Mobile augmented reality; Multimedia contents; Smart-phone cameras; Web-based softwares; Signal encoding",2-s2.0-84960885490
[No author name available],"SIGGRAPH Asia 2015 Symposium on Education, SA 2015",2015,"SIGGRAPH Asia 2015 Symposium on Education, SA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975744483&partnerID=40&md5=4a497221f223c51798b7964d752abf0a","The proceedings contain 15 papers. The topics discussed include: innovation in the age of virtual reality through organizing international student competition; development and evaluation of education materials for stereoscopic 3D computer graphics animation; taking animation project learning into the virtual environment; an abstract journey; educational Escargore: visual effects education practices at media design school; teaching visual storytelling for virtual production pipelines incorporating motion capture and visual effects; courses on 3D image display for students who aim to become information media engineers and creators; square ENIX AI academy: AI workshop for blackboard architecure; learning Hawaiian hula dance by using tablet computer; future Delta 2.0 an experiential learning context for a serious game about local climate change; and square ENIX AI academy: a seminar series for the introduction of digital game AI.",,,2-s2.0-84975744483
"Liu Y., Xu F., Chai J., Tong X., Wang L., Huo Q.","Video-audio driven real-time facial animation",2015,"ACM Transactions on Graphics",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996479817&doi=10.1145%2f2816795.2818122&partnerID=40&md5=226c5613a44effaef58d31a929ebe5af","We present a real-time facial tracking and animation system based on a Kinect sensor with video and audio input. Our method requires no user-specific training and is robust to occlusions, large head rotations, and background noise. Given the color, depth and speech audio frames captured from an actor, our system first reconstructs 3D facial expressions and 3D mouth shapes from color and depth input with a multi-linear model. Concurrently a speaker-independent DNN acoustic model is applied to extract phoneme state posterior probabilities (PSPP) from the audio frames. After that, a lip motion regressor refines the 3D mouth shape based on both PSPP and expression weights of the 3D mouth shapes, as well as their confidences. Finally, the refined 3D mouth shape is combined with other parts of the 3D face to generate the final result. The whole process is fully automatic and executed in real time. The key component of our system is a data-driven regresor for modeling the correlation between speech data and mouth shapes. Based on a precaptured database of accurate 3D mouth shapes and associated speech audio from one speaker, the regressor jointly uses the input speech and visual features to refine the mouth shape of a new actor. We also present an improved DNN acoustic model. It not only preserves accuracy but also achieves real-time performance. Our method efficiently fuses visual and acoustic information for 3D facial performance capture. It generates more accurate 3D mouth motions than other approaches that are based on audio or video input only. It also supports video or audio only input for real-time facial animation. We evaluate the performance of our system with speech and facial expressions captured from different actors. Results demonstrate the efficiency and robustness of our method. © Copyright 2015 ACM.","Facial animation; Real time facial tracking; Speech animation","Animation; Audio acoustics; Speech; 3-d facial expressions; Acoustic information; Facial animation; Facial tracking; Posterior probability; Real time performance; Speaker independents; Speech animation; Three dimensional computer graphics",2-s2.0-84996479817
"Jo J., Lee B., Seo J.","WordlePlus: Expanding Wordle's use through natural interaction and animation",2015,"IEEE Computer Graphics and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961744590&doi=10.1109%2fMCG.2015.113&partnerID=40&md5=2f5d41a4646932a055aed1445866ff35","Wordle has been commonly used to summarize texts, with each word size-coded by its frequency of occurrences - the more often a word occurs in texts, the bigger it is. The interactive authoring tool WordlePlus leverages natural interaction and animation to give users more control over wordle development. WordlePlus supports direct manipulation of words with pen and touch interaction. It introduces two-word multitouch manipulation, such as concatenating and grouping two words, and provides pen interaction for adding and deleting words. In addition, WordlePlus employs animation to help users create more dynamic and engaging wordles. © 1981-2012 IEEE.",,"Computer graphics; Computer simulation; Authoring tool; Direct manipulation; Multi-touch; Natural interactions; Pen and touches; Pen interactions; Animation",2-s2.0-84961744590
"Zell E., Aliaga C., Jarabo A., Zibrek K., Gutierrez D., McDonnell R., Botsch M.","To stylize or not to stylize? The effect of shape and material stylization on the perception of computer-generated faces",2015,"ACM Transactions on Graphics",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995753013&doi=10.1145%2f2816795.2818126&partnerID=40&md5=43d011ffffe7617fe9eb87d33267a37e","Virtual characters contribute strongly to the entire visuals of 3D animated films. However, designing believable characters remains a challenging task. Artists rely on stylization to increase appeal or expressivity, exaggerating or softening specific features. In this paper we analyze two of the most influential factors that define how a character looks: shape and material. With the help of artists, we design a set of carefully crafted stimuli consisting of different stylization levels for both parameters, and analyze how different combinations affect the perceived realism, appeal, eeriness, and familiarity of the characters. Moreover, we additionally investigate how this affects the perceived intensity of different facial expressions (sadness, anger, happiness, and surprise). Our experiments reveal that shape is the dominant factor when rating realism and expression intensity, while material is the key component for appeal. Furthermore our results show that realism alone is a bad predictor for appeal, eeriness, or attractiveness. Copyright is held by the owner/author(s).","Character design; Shape and material; Stylization","Motion pictures; Character designs; Computer generated; Expression intensities; Facial Expressions; Influential factors; Perceived realisms; Stylization; Virtual character; Animation",2-s2.0-84995753013
"Abrines Jaume N., Abbiss M., Wray J., Ashworth J., Brown K.L., Cairns J.","CHILDSPLA: A collaboration between children and researchers to design and animate health states",2015,"Child: Care, Health and Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959313622&doi=10.1111%2fcch.12280&partnerID=40&md5=d71adb8244c18f890dd81a778ac6af23","Summary: Aim: The children's health state preferences learnt from animation (CHILDSPLA) project developed an interactive application presented on a touch screen device using an animated character to collect information from children about their health. Background: The underlying hypothesis was that health information could be directly collected from children as young as 4years old by the use of animated characters. This paper describes in detail how children were involved in the development of the application, and recounts both the challenges and benefits of that process. A child psychologist and an animation filmmaker worked closely with children to design a character and to animate it to represent different health states. Children were recruited from a local primary school (n=38) and a paediatric specialist hospital (n=36). Diverse interactive activities were organized to help children give feedback and guide the design process. The activities for each session were adjusted to the children's needs, based on the experience of previous sessions. Results: The character and the animations were modified according to the feedback provided by the children. Conclusions: Developing the CHILDSPLA app in collaboration with children was a worthwhile and enriching experience, despite the required iteration and extension of the design process, as it enabled us to adjust the tool to the children's needs. © 2015 John Wiley & Sons Ltd.","Animation; Children; Design; Health states; Patient and public involvement","adolescent; child; computer interface; cooperation; feedback system; female; health status indicator; human; human relation; male; mobile application; preschool child; Scotland; video game; Adolescent; Child; Child, Preschool; Cooperative Behavior; Feedback; Female; Health Status Indicators; Humans; Male; Mobile Applications; Professional-Patient Relations; Scotland; User-Computer Interface; Video Games",2-s2.0-84959313622
"Aragon-Calvo M.A., Subbarao M.","A Flight through the Universe",2015,"Computing in Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946749448&doi=10.1109%2fMCSE.2015.118&partnerID=40&md5=99555a9996f7343bf5d9249d515c016c","The authors describe the creation of a tridimensional fly-through animation across the largest map of galaxies to date. This project represented a challenge: creating a scientifically accurate representation of the galaxy distribution that was aesthetically pleasing. The animation shows almost half a million galaxies as the viewer travels through the vast intergalactic regions, giving a glimpse of the sheer size of the universe. © 1999-2011 IEEE.","3D rendering modeling; Blender; Cosmic Web galaxy surveys; Scientific computing; Sloan Digital Sky Survey","Animation; Blending; Cosmology; Natural sciences computing; Surveys; Three dimensional computer graphics; 3-D rendering; Blender; Galaxy distribution; Sheer size; Sloan Digital Sky Survey; Galaxies",2-s2.0-84946749448
"Giraudet L., Imbert J.-P., Bérenger M., Tremblay S., Causse M.","The neuroergonomic evaluation of human machine interface design in air traffic control using behavioral and EGG/ERP measures",2015,"Behavioural Brain Research",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940893019&doi=10.1016%2fj.bbr.2015.07.041&partnerID=40&md5=b97f8a2bdb809e7731319df119adee40","The Air Traffic Control (ATC) environment is complex and safety-critical. Whilst exchanging information with pilots, controllers must also be alert to visual notifications displayed on the radar screen (e.g., warning which indicates a loss of minimum separation between aircraft). Under the assumption that attentional resources are shared between vision and hearing, the visual interface design may also impact the ability to process these auditory stimuli. Using a simulated ATC task, we compared the behavioral and neural responses to two different visual notification designs-the operational alarm that involves blinking colored ""ALRT"" displayed around the label of the notified plane (""Color-Blink""), and the more salient alarm involving the same blinking text plus four moving yellow chevrons (""Box-Animation""). Participants performed a concurrent auditory task with the requirement to react to rare pitch tones. P300 from the occurrence of the tones was taken as an indicator of remaining attentional resources. Participants who were presented with the more salient visual design showed better accuracy than the group with the suboptimal operational design. On a physiological level, auditory P300 amplitude in the former group was greater than that observed in the latter group. One potential explanation is that the enhanced visual design freed up attentional resources which, in turn, improved the cerebral processing of the auditory stimuli. These results suggest that P300 amplitude can be used as a valid estimation of the efficiency of interface designs, and of cognitive load more generally. © 2015 Elsevier B.V.","Air traffic control; Attentional resources; ERP; Human machine interface evaluation; Neuroergonomics","accuracy; action potential amplitude; adult; Article; attention; auditory stimulation; behavior; BOLD signal; brain electrophysiology; brain function; cognition; computer aided design; computer interface; controlled study; electroencephalogram; event related potential; human; human experiment; nerve potential; neuroergonomic approach; neuroscience; normal human; priority journal; task performance; visual stimulation; aviation; brain; computer simulation; electroencephalography; evaluation study; evoked response; executive function; hearing; middle aged; photostimulation; physiology; procedures; vision; young adult; Acoustic Stimulation; Adult; Auditory Perception; Aviation; Brain; Computer Simulation; Electroencephalography; Evoked Potentials; Executive Function; Humans; Middle Aged; Photic Stimulation; User-Computer Interface; Visual Perception; Young Adult",2-s2.0-84940893019
"Kapsouras I., Nikolaidis N.","Person identity recognition on motion capture data using multiple actions",2015,"Machine Vision and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943352604&doi=10.1007%2fs00138-015-0704-z&partnerID=40&md5=429376e6155fe47f05128f52770cc412","In this paper, we introduce a novel method for person identity recognition (identification) on skeleton animation/motion capture data representing persons performing various actions. The joints positions or orientation angles and the forward differences of these quantities are used to represent a motion capture sequence. First K-means clustering is applied on training data to discover the most representative patterns on joints positions or orientation angles (dynemes) and their forward differences (F-dynemes). Each frame is then assigned to one of these patterns and the frequency of occurrence histograms for each movement are constructed in a bag-of-words fashion. Person identity recognition is done through a nearest neighbor classifier. The proposed method is experimentally tested on a number of datasets of motion capture data, with very good results. © 2015, Springer-Verlag Berlin Heidelberg.","Bag of words; Dynemes; Forward differences; Identity recognition; Motion capture data","Computer vision; Hardware; Machinery; Bag of words; Dynemes; Forward difference; Identity recognition; Motion capture data; Face recognition",2-s2.0-84943352604
"Arifin, Sumpeno S., Hariadi M., Haryanto H.","A text-to-audiovisual synthesizer for Indonesian by morphing Viseme",2015,"International Review on Computers and Software",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956962132&partnerID=40&md5=aec67fc6cd66d8ea04a1dcc544f67967","There are many researches held on the text-to-audiovisual, but only a few are applied on Indonesian language. The results of the present research can be applied to a very wide field, e.g. gaming industry, animation industry, human computer interaction systems, etc. The correspondence among speech, mouth movements (visual phoneme/viseme) and phoneme spoken is needed to produce a realistic text-to-audiovisual. This research aims to develop a text-toaudiovisual synthesizer for Indonesian language based on inputted Indonesian text called TTAVI (Text-To-AudioVisual synthesizer for Indonesian language). The method consists of four major parts, namely, building the models of Indonesian’s viseme, converting a text-to-speech, synchronization process, and stringing the visemes by using the morphing viseme algorithm. Morphing viseme algorithm shows that a virtual character of the phonemes pronunciation resulting from the TTAVI synthesizer is smoother. 10 Indonesian texts inputted to TTAVI synthesizer were examined by 30 users. The appraisal results of users were calculated by applying Mean Opinion Score (MOS) methods. The average of the MOS score is 4.106 with a value range from 1 to 5. This shows that TTAVI synthesizer is considered good, and morphing viseme algorithm is able to make the result of TTAVI synthesizer smoother. © 2015 Praise Worthy Prize S.r.l. - All rights reserved.","A model of indonesian’s visemes; Audiovisual; Indonesian text; Morphing viseme; Viseme",,2-s2.0-84956962132
"Fan J., Xiao S.","The study of real-time animation of forest scene in wind projection",2015,"Proceedings - VRCAI 2015: 14th ACM SIGGRAPH International Conference on Virtual Reality Continuum and its Applications in Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962374884&doi=10.1145%2f2817675.2817685&partnerID=40&md5=9aa31f6771808d0177aba8326fe5a2ac","Real-time animation of forest has become an integral part of many graphic applications like virtual reality and computer games. In this paper, we present a novel real-time method to simulate forest in wind which maintains physical reality at the same time. In this method, the wind projection is calculated based on the rules of forest meteorology which will take the position of trees in forest into consideration and compute the influence of trees to wind. Instead of physical equation, experience formula in meteorology is employed to accelerate computing process. Users can simulate different kinds of trees by changing coefficients in formulas which can be calculated based on the features of branches and leaves. Experimental results show that the proposed method is effective with highly realism and practical for interactive applications. © 2015 ACM.","Animation; Forest meteorology; Wind projection","Animation; Computer games; Interactive computer graphics; Meteorology; Virtual reality; Computing process; Graphic applications; Integral part; Interactive applications; Physical equations; Physical reality; Real time methods; Real-time animations; Forestry",2-s2.0-84962374884
"Yang X., Su W., Deng J., Pan Z.","Real traffic data-driven animation simulation",2015,"Proceedings - VRCAI 2015: 14th ACM SIGGRAPH International Conference on Virtual Reality Continuum and its Applications in Industry",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962476928&doi=10.1145%2f2817675.2817683&partnerID=40&md5=0782f4c2d6248167bc90142e3846ce1d","We present a novel traffic animation method to promote the sense of immersion of the virtual traffic flow by inserting virtual vehicles into the real trajectory data. Our intelligent agent-based approach can vividly simulate the interactions between virtual vehicles and real data controlled vehicles. The developed real-virtual interaction system includes follower-driven models and real vehicle lane-changing models, together with other models to coordinate the integrity of the traffic flow with hybrid data. Furthermore, we apply several sets of real trajectory data synchronously to our interactive system and propose a multiple real-data cooperation model to coordinate multiple real-data driven vehicles interacting with other virtual vehicles. © 2015 ACM.","Interactive simulation; Microscopic model; Traffic animation","Animation; Human computer interaction; Interactive computer graphics; Traffic control; Virtual reality; Agent-based approach; Cooperation model; Interactive simulations; Interactive system; Lane changing models; Microscopic modeling; Real trajectories; Virtual interactions; Vehicles",2-s2.0-84962476928
"Ismail I., Oshita M., Sunar M.S.","Key pose deformations in changing the 3D character motion style",2015,"Proceedings - VRCAI 2015: 14th ACM SIGGRAPH International Conference on Virtual Reality Continuum and its Applications in Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962429844&doi=10.1145%2f2817675.2817692&partnerID=40&md5=ec96e096a07d281bc0297d0821aedd66","Realistic humanoid 3D character movement plays a very crucial role in the computer games, movies, virtual reality and mixed reality environment.. However, the poses of the 3D character contains large amount of dimensional data arising from joint rotations, body positions and orientations. This paper proposes a technique to deform different motion styles by editing the specific key poses of 3D character movements via computer animation system. This unique method allows humanoid characters to respond naturally based on the inputs of user motions. Unlike an existing editor of 3D humanoid character motion, the proposed method produces realistic final result and simulates new dynamic humanoid motion style based on simple user interface control. © 2015 ACM.","3D humanoid character; Key pose control; Motion deformations","Animation; Deformation; Interactive computer graphics; Motion compensation; User interfaces; Virtual reality; 3D humanoid character; Character motion; Computer animation; Joint rotations; Key pose; Mixed-reality environment; Motion deformation; User interface control; Computer games",2-s2.0-84962429844
"Miao Y., Xiao S.","Particle-based ice freezing simulation",2015,"Proceedings - VRCAI 2015: 14th ACM SIGGRAPH International Conference on Virtual Reality Continuum and its Applications in Industry",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962439601&doi=10.1145%2f2817675.2817676&partnerID=40&md5=1d82976e8bc148876943e627a106e338","As an interesting topic in computer graphics, visual simulation of ice has been widely studied. However, there have been very few researches on flowing water freezing with phase transition. In this paper, a physical particle-based ice freezing model is presented. By solving heat conduction and air bubble diffusion based on fluid dynamics, our method allows the simulation of freezing phenomena that occur in flowing water. With the advanced heat transfer model, fluid freezing can be simulated in arbitrary cooling direction and speed. During the dynamic freezing process, distance smoothed diffusion of air bubbles are calculated to produce realistic freezing result. Dynamic volume expansion of ice is easily captured by changing particle density. Efficient and realistic solidification process is simulated with phase-based viscosity and rigid-shape matching constraints to particles. Realistic animation of ice freezing phenomenon is achieved naturally with our method. © 2015 ACM.","Ice; Natural phenomena; Solidification; Visual simulation","Air; Computer graphics; Diffusion in liquids; Freezing; Heat conduction; Heat transfer; Interactive computer graphics; Solidification; Virtual reality; Visualization; Freezing phenomena; Freezing process; Heat transfer model; Natural phenomena; Particle densities; Solidification process; Visual simulation; Volume expansion; Ice",2-s2.0-84962439601
"Lopes A.T., De Aguiar E., Oliveira-Santos T.","A Facial Expression Recognition System Using Convolutional Networks",2015,"Brazilian Symposium of Computer Graphic and Image Processing",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959358247&doi=10.1109%2fSIBGRAPI.2015.14&partnerID=40&md5=143d007bad0100d5a751136de3b0f787","Facial expression recognition has been an active research area in the past ten years, with a growing application area like avatar animation and neuromarketing. The recognition of facial expressions is not an easy problem for machine learning methods, since different people can vary in the way that they show their expressions. And even an image of the same person in one expression can vary in brightness, background and position. Therefore, facial expression recognition is still a challenging problem in computer vision. In this work, we propose a simple solution for facial expression recognition that uses a combination of standard methods, like Convolutional Network and specific image pre-processing steps. Convolutional networks, and the most machine learning methods, achieve better accuracy depending on a given feature set. Therefore, a study of some image pre-processing operations that extract only expression specific features of a face image is also presented. The experiments were carried out using a largely used public database for this problem. A study of the impact of each image pre-processing operation in the accuracy rate is presented. To the best of our knowledge, our method achieves the best result in the literature, 97.81% of accuracy, and takes less time to train than state-of-the-art methods. © 2015 IEEE.","Computer Vision; Convolutional Networks; Expression Specific Features; Facial Expression; Machine Learning","Artificial intelligence; Computer vision; Convolution; Human computer interaction; Image processing; Learning systems; Convolutional networks; Expression Specific Features; Facial expression recognition; Facial Expressions; Image preprocessing; Machine learning methods; Recognition of facial expressions; State-of-the-art methods; Face recognition",2-s2.0-84959358247
"Vershinin Y., Nnadiekwe B., Schulz S.","Simulation of Signal Transmission in Motion Simulator Using Controller Area Network (CAN-bus)",2015,"IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950285559&doi=10.1109%2fITSC.2015.432&partnerID=40&md5=7897bef3295067307bbee36bb5d329f7","The modelling of a proposed Automotive Driving Simulator (Motion Simulator) based on the Controller Area Network (CAN-bus) is described in this paper. The simulation of the CAN-bus communication was carried out using the Simulink software package and Vehicle Network Toolbox. The Driving Simulator has also been modelled as a 3D multi-body in order to visualize the dynamics of the system in 3D animation and to better understand the effects of the CAN-bus communication on the system. The 3D modelling was done using SimMechanics blocks in Simulink. When the simulation was run, it was found that at the high bus speed, the CAN-bus communication met the real time response needed from the system while at the low bus speed, the real time response was compromised. © 2015 IEEE.","Controller Area Network; Motion Simulator; Simulator Sickness; Systems Engineering; Vehicle Communication System","Automobile simulators; Control system synthesis; Controllers; Intelligent systems; Intelligent vehicle highway systems; Process control; Simulators; Systems engineering; Transportation; Automotive driving; Can bus communications; Controller area network; Motion simulator; Real time response; Signal transmission; Simulator sickness; Vehicle communications; Computer software",2-s2.0-84950285559
"Frohne U.","Expansion of the immersion zone military simulacra between strategic training and trauma",2015,"Immersion in the Visual Arts and Media",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981365841&doi=10.1163%2f9789004308237_011&partnerID=40&md5=e875300312d06324dec2eeb1de65212c","Since the mid-1990s, military strategists have used so-called Military Opera-tions in Urban Terrain (MOUT) scenarios as virtual training grounds to prepare soldiers for military operations. Here, model towns and buildings serve as a topographical infrastructure for training related to military emergencies. At the same time, computer animations of these ghost towns are utilized in the ludic practice of making contact with the enemy in the same way immersive 3-D vi-sualizations combined with role-playing are employed in the therapeutic treat-ment of those traumatized by military service. The constitutive factors of these kinds of 'military dispositifs' are the focus of Harun Farocki's film Immersion (Germany 2009, as part of the series Serious Games). He makes the unsuspect-ing viewer a witness to a simulated experiment in which a visibly shaken test subject reconstructs a life-threatening conflict, which is simultaneously played as an animated film before his eyes. The photo series personal kill (2007) by Beate Geissler and Oliver Sann also refers to the constitutive efficacy of virtual combat scenes by capturing the ubiquitous analog military model towns as dys-topian parallel worlds on the edges of our civilized living environments. Both artistic approaches address the fact that immersive combat simulations are not limited to restricted military areas or to the preparation for possible peace-keeping missions. Rather, their game format contributes to the implicit totaliza-tion of a culture of hostility. To the extent that they tend to reduce encounters with the foreign to a stereotypical friend/enemy polarity, they potentially natu-ralize the concept of a world order that appears to be only defensible by war. © 2016 by Koninklijke Brill nv, Leiden, The Netherlands. All rights reserved.",,,2-s2.0-84981365841
"Chadha S., Byalik A., Tilevich E.","Heterogeneous device hopping: Bridging the mobile cross-platform gap via a declarative query language",2015,"SPLASH Companion 2015 - Companion Proceedings of the 2015 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960325713&doi=10.1145%2f2814189.2814191&partnerID=40&md5=5ef5561f8fe7ea00977334e938c86794","A typical mobile user employs multiple devices (e.g., a smart-phone, a tablet, wearables, etc.). These devices are powered by varying mobile platforms. Enabling such cross-platform devices to seamlessly share their computational, network, and sensing resources has great potential benefit. However, sharing resources across platforms is challenging due to a number of difficulties. First, the varying communication protocols used by major mobile vendors tend to overlap minimally, making it impossible for the devices to communicate through a single protocol. Second, the host platforms' underlying architectural differences lead to drastically dissimilar application architectures and programming support. In this demo, we present Heterogeneous Device Hopping, a novel approach that systematically empowers heterogeneous mobile devices to seamlessly, reliably, and efficiently share their resources. The approach comprises 1) a declarative domain-specific language for device-to-device communication based on the RESTful architecture; 2) a powerful runtime infrastructure that supports the language's programming model. In this demo, we show how our approach can be used to implement a multi-device animation across heterogeneous nearby devices. The animation starts on one device and moves across the device boundaries, irrespective of the underlying mobile platform. © 2015 ACM.","Domain specific languages; Mobile applications; Near field resource sharing; Runtime","Animation; Application programs; Computational linguistics; Computer programming languages; Distributed computer systems; Graphical user interfaces; Mobile devices; Mobile phones; Network architecture; Problem oriented languages; Query languages; Smartphones; XML; Application architecture; Declarative query languages; Device-to-Device communications; Domain specific languages; Heterogeneous mobile devices; Mobile applications; Resource sharing; Runtimes; Computer systems programming",2-s2.0-84960325713
"Manson A., Poyade M., Rea P.","A recommended workflow methodology in the creation of an educational and training application incorporating a digital reconstruction of the cerebral ventricular system and cerebrospinal fluid circulation to aid anatomical understanding",2015,"BMC Medical Imaging",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945193776&doi=10.1186%2fs12880-015-0088-6&partnerID=40&md5=53f0ed19ef53971fb679649fbbf6fdc3","Background: The use of computer-aided learning in education can be advantageous, especially when interactive three-dimensional (3D) models are used to aid learning of complex 3D structures. The anatomy of the ventricular system of the brain is difficult to fully understand as it is seldom seen in 3D, as is the flow of cerebrospinal fluid (CSF). This article outlines a workflow for the creation of an interactive training tool for the cerebral ventricular system, an educationally challenging area of anatomy. This outline is based on the use of widely available computer software packages. Methods: Using MR images of the cerebral ventricular system and several widely available commercial and free software packages, the techniques of 3D modelling, texturing, sculpting, image editing and animations were combined to create a workflow in the creation of an interactive educational and training tool. This was focussed on cerebral ventricular system anatomy, and the flow of cerebrospinal fluid. Results: We have successfully created a robust methodology by using key software packages in the creation of an interactive education and training tool. This has resulted in an application being developed which details the anatomy of the ventricular system, and flow of cerebrospinal fluid using an anatomically accurate 3D model. In addition to this, our established workflow pattern presented here also shows how tutorials, animations and self-assessment tools can also be embedded into the training application. Conclusions: Through our creation of an established workflow in the generation of educational and training material for demonstrating cerebral ventricular anatomy and flow of cerebrospinal fluid, it has enormous potential to be adopted into student training in this field. With the digital age advancing rapidly, this has the potential to be used as an innovative tool alongside other methodologies for the training of future healthcare practitioners and scientists. This workflow could be used in the creation of other tools, which could be developed for use not only on desktop and laptop computers but also smartphones, tablets and fully immersive stereoscopic environments. It also could form the basis on which to build surgical simulations enhanced with haptic interaction. © 2015 Manson et al.","3D; Education; Neuroanatomy; Ventricular; Volumetric visualisation","anatomic model; anatomy; anatomy and histology; brain ventricle; cerebrospinal fluid; computer interface; education; human; physiology; procedures; three dimensional imaging; workflow; Anatomy; Cerebral Ventricles; Cerebrospinal Fluid; Humans; Imaging, Three-Dimensional; Models, Anatomic; User-Computer Interface; Workflow",2-s2.0-84945193776
"Mitsuhashi K., Ohyama Y., Hashimoto H.","Suggestion of creating solid method using projective method in 3D real space with microsoft kinect",2015,"IEEE International Conference on Emerging Technologies and Factory Automation, ETFA",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952916090&doi=10.1109%2fETFA.2015.7301432&partnerID=40&md5=bb357f92480393404248a367de8b6a89","3D model is normally designed by 3D-CAD software or animation software, but a 3D direct drawing method is still a developing research. In a previous study, we suggest a 3D direct drawing method for polygonal/curved surface model using Microsoft Kinect. In this study, some subjects performe the gesture expressing a solid, analyzed the gesture trajectory. And we construct the creating solid algorithm using projective methods from the results. The algorithm is the converting multiple surfaces into a solid. After that, the subjects are performed gesture expressing again and the creating model is measured. Because of the validity confirmation of our algorithm. © 2015 IEEE.","3D CAD; ARToolKit; gesture modeling; Microsoft Kinect; projective method; solid model","Factory automation; 3-d cads; Artoolkit; Microsoft kinect; Projective methods; Solid model; Computer aided design",2-s2.0-84952916090
"Potoček V., Barnett S.M.","Generalized ray optics and orbital angular momentum carrying beams",2015,"New Journal of Physics",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946771620&doi=10.1088%2f1367-2630%2f17%2f10%2f103034&partnerID=40&md5=76a2ca870ba52c2ad06e7cc36c3b0ecc","In classical optics the Wolf function is the natural analogue of the quantum Wigner function and like the latter it may be negative in some regions. We discuss the implications this negativity has on the generalized ray interpretation of free-space paraxial wave evolution. Important examples include two classes of beams carrying optical orbital angular momentum - Laguerre-Gaussian (LG) and Bessel beams. We formulate their defining eigenfunction properties as phase-space symmetries of their Wolf functions, whose analytical form is shown, and discuss their interpretation in the ray picture. By moving to a more general picture of partly coherent fields, we find that new solutions displaying the same symmetries appear. In particular, we find that mixtures of Gaussian beams (thus fully describable using classical ray optics) can mimic the basic properties of LG beams without the need for negativity, and are not restricted to quantized values of angular momentum. The quantization of both the l and p parameters and negativity of the Wolf function are both inevitable and, indeed, arise naturally when a requirement on the purity of the solution is added. This work is supplemented by a set of computer animations, graphically illustrating the interpretative aspects of the described model. © 2015 IOP Publishing Ltd and Deutsche Physikalische Gesellschaft.","optical orbital angular momentum; ray optics; Wigner function","Angular momentum; Animation; Eigenvalues and eigenfunctions; Momentum; Phase space methods; Quantum theory; Wave functions; Wigner-Ville distribution; Analytical forms; Classical optics; Coherent fields; Computer animation; Laguerre-Gaussian; Orbital angular momentum; Ray optics; Wigner functions; Gaussian beams",2-s2.0-84946771620
"Galen D.I.","Electromagnetic image guidance in gynecology: Prospective study of a new laparoscopic imaging and targeting technique for the treatment of symptomatic uterine fibroids",2015,"BioMedical Engineering Online",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945185920&doi=10.1186%2fs12938-015-0086-5&partnerID=40&md5=0c85732f2b23fd6716152c0bd540c1ac","Background: Uterine fibroids occur singly or as multiple benign tumors originating in the myometrium. Because they vary in size and location, the approach and technique for their identification and surgical management vary. Reference images, such as ultrasound images, magnetic resonance images, and sonohystograms, do not provide real-time intraoperative findings. Methods: Electromagnetic image guidance, as incorporated in the Acessa Guidance System, has been cleared by the FDA to facilitate targeting and ablation of uterine fibroids during laparoscopic surgery. This is the first feasibility study to verify the features and usefulness of the guidance system in targeting symptomatic uterine fibroids-particularly hard-to-reach intramural fibroids and those abutting the endometrium. One gynecologic surgeon, who had extensive prior experience in laparoscopic ultrasound-guided identification of fibroids, treated five women with symptomatic uterine fibroids using the Acessa Guidance System. The surgeon evaluated the system and its features in terms of responses to prescribed statements; the responses were analyzed prospectively. Results: The surgeon strongly agreed (96 %) or agreed (4 %) with statements describing the helpfulness of the transducer and handpiece's dynamic animation in targeting each fibroid, reaching the fibroid quickly, visualizing the positions of the transducer and handpiece within the pelvic cavity, and providing the surgeon with confidence when targeting the fibroid even during ""out-of-plane"" positioning of the handpiece. Conclusions: The surgeon's positive user experience was evident in the guidance system's facilitation of accurate handpiece tip placement during targeting and ablation of uterine fibroids. Continued study of electromagnetic image guidance in the laparoscopic identification and treatment of fibroids is warranted. ClinicalTrials.gov Identifier: NCT01842789. © 2015 Galen.","Ablation; Acessa; Electromagnetic image guidance; Fibroids; Myomas","Ablation; Magnetic resonance; Magnetic resonance imaging; Remote control; Surgery; Transducers; Ultrasonic applications; Acessa; Electromagnetic image; Feasibility studies; Fibroids; Laparoscopic surgery; Laparoscopic ultrasound; Myomas; Surgical management; Laparoscopy; adult; Article; clinical article; clinical trial; diagnostic imaging; electromagnetic image guidance; endometrium; endoscopic echography; feasibility study; female; human; laparoscopic imaging; pelvic cavity; pelvis; priority journal; prospective study; treatment response; tumor localization; ultrasound; ultrasound scanner; ultrasound transducer; uterus myoma; computer assisted surgery; electromagnetism; laparoscopy; leiomyoma; procedures; Adult; Electromagnetic Phenomena; Feasibility Studies; Female; Humans; Laparoscopy; Leiomyoma; Prospective Studies; Surgery, Computer-Assisted",2-s2.0-84945185920
"Liang H., Yuan J., Thalmann D., Nadia M.-T.","AR in hand: Egocentric palm pose tracking and gesture recognition for augmented reality applications",2015,"MM 2015 - Proceedings of the 2015 ACM Multimedia Conference",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962798362&doi=10.1145%2f2733373.2807972&partnerID=40&md5=89ef1bb7081f961c773cd2b6d89d2245","Wearable devices such as Microsoft Hololens and Google glass are highly popular in recent years. As traditional input hardware is dificult to use on such platforms, vision-based hand pose tracking and gesture control techniques are more suitable alternatives. This demo shows the possibility to interact with 3D contents with bare hands on wearable de-vices by two Augmented Reality applications, including vir-tual teapot manipulation and fountain animation in hand. Technically, we use a head-mounted depth camera to cap-ture the RGB-D images from egocentric view, and adopt the random forest to regress for the palm pose and classify the hand gesture simultaneously via a spatial-voting framework. The predicted pose and gesture are used to render the 3D virtual objects, which are overlaid onto the hand region in input RGB images with camera calibration parameters for seamless virtual and real scene synthesis. © 2015 ACM.","Augmented Reality; Gesture Recognition; Palm Pose Esti-mation","Augmented reality; Cameras; Decision trees; Palmprint recognition; Wearable computers; Wearable technology; Augmented reality applications; Camera calibration; Gesture control; Palm Pose Esti-mation; Pose tracking; Random forests; Virtual objects; Wearable devices; Gesture recognition",2-s2.0-84962798362
"Chen H.-R., Liao K.-C., Chang J.-J.","Design of digital game-based learning system for elementary mathematics problem solving",2015,"2015 8th International Conference on Ubi-Media Computing, UMEDIA 2015 - Conference Proceeedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959549789&doi=10.1109%2fUMEDIA.2015.7297475&partnerID=40&md5=1413b25f07ce52237cedceed7d4badcd","The goal of many elementary school courses is to develop abilities in solving math problems. Mathematics are everywhere in life; it can cultivate personal independent thinking ability, and is the most important tool in scientific research. Lively images or illustrations can effectively attract the attention of children, in turn elevating their learning interest. This study designed a digital game-based learning system for multiplication and division in basic mathematics on the basis of iconic representation animation. In order to help students in effectively understanding the meanings of word problems in mathematics and in dispelling troubles in problem-solving due to reading difficulties in mathematics. The results showed that iconic representational animated instructional materials can increase students' learning achievements, better than traditional instruction with significant benefits. © 2015 IEEE.","Game-Based Learning; iconic representational strategy; Mathematics Problem Solving","Animation; Computer games; E-learning; Learning systems; Digital game-based learning; Game-based Learning; Iconic representation; iconic representational strategy; Instructional materials; Learning achievement; Scientific researches; Traditional instruction; Problem solving",2-s2.0-84959549789
"Flotyński J., Walczak K.","Conceptual knowledge-based modeling of interactive 3D content",2015,"Visual Computer",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941024348&doi=10.1007%2fs00371-014-1011-9&partnerID=40&md5=9a60e3347dba106fc59e1d3fb845dce3","Three-dimensional content offers a powerful medium enabling rich, interactive visualization in virtual and augmented reality systems, which are increasingly used in a variety of application domains, such as education, training, tourism and cultural heritage. The creation of interactive 3D presentations is typically a complex process covering diverse aspects of the content such as geometry, structure, space, appearance, animation and behavior. Recent trends in the development of the semantic web provide new opportunities for simplifying 3D content creation, which may be performed at different levels of abstraction and may encompass the inference of hidden knowledge, which may influence the created content. However, the available approaches to 3D content creation do not enable conceptual knowledge-based modeling of 3D content. The main contribution of this paper is an approach to semantic creation of 3D content. The proposed solution leverages the semantic web techniques to enable conceptual, knowledge-driven content creation. The proposed approach has been implemented and evaluated. It has been shown that the approach can significantly simplify modeling of advanced 3D content presentations in comparison with the available approaches. © 2014, The Author(s).","3D content; 3D web; Ontology; Semantic 3D; Semantic web; Virtual and augmented reality","Augmented reality; Knowledge based systems; Ontology; Semantic Web; Social networking (online); Visualization; 3D content; 3D web; Conceptual knowledge; Cultural heritages; Interactive visualizations; Levels of abstraction; Semantic-Web techniques; Virtual and augmented reality; Three dimensional computer graphics",2-s2.0-84941024348
"Ni N.","Application and realization of the computer animation design based on improved cubic B-spline curves",2015,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988689932&doi=10.1051%2fmatecconf%2f20152503014&partnerID=40&md5=860259fa0370cc3c92b968afc2b75231","Based on the application of the cubic B-spline curves in the computer animation design, taking into account the security and confidentiality of the information, this paper improves the animation design techniques by the use of the improved cubic B-spline curves. Finally, this paper provides the relevant C language programs of the animation design. © Owned by the authors, published by EDP Sciences, 2015.","Animation design; C language; Computer; Cubic B-spline curve","C (programming language); Computers; Curve fitting; Design; Interpolation; Manufacture; Splines; Animation designs; C language; Computer animation; Cubic b-spline curves; Animation",2-s2.0-84988689932
"Baek N., Im B.","Providing preliminary profiling information for OpenGL ES 1.1 application programs",2015,"2015 5th International Conference on IT Convergence and Security, ICITCS 2015 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961696370&doi=10.1109%2fICITCS.2015.7293011&partnerID=40&md5=b28412fad1a80de5d96bc9fb21e87857","To support integrated development environment (IDE) and/or human-readable profiling messages, we need lots of profiling and debugging messages. These messages should be generated from each of the OpenGL function. Additionally, some debugging extensions are also required to provide more convenience. We first aimed to provide preliminary profiling information from the existing OpenGL ES drivers and/or implementations. Our prototype system shows the proper profiling messages from the application programs, and the OpenGL debugging extensions are fully supported. These features can be used by IDE programs to make a fully integrated OpenGL profiling and debugging environment. © 2015 IEEE.","Animation; Computer science; Debugging; Libraries; Object recognition; Prototypes","Animation; Application programming interfaces (API); Application programs; Computer debugging; Computer science; Computer software; Integrodifferential equations; Libraries; Object recognition; Web services; Fully integrated; Human-readable; Integrated development environment; Profiling informations; Prototype system; Prototypes; Program debugging",2-s2.0-84961696370
"Sifakis E., Koltun V.","Guest Editor's Introduction: Special Section on the ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA)",2015,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941047938&doi=10.1109%2fTVCG.2015.2461771&partnerID=40&md5=14f711e76322b8d2bf3a10eaccfa3c37",[No abstract available],,,2-s2.0-84941047938
"Hiruma N., Azuma M., Uchida T., Umeda S., Miyazaki T., Kato N., Inoue S.","Automatic generation system of Japanese Sign Language (JSL) with CG animation of fixed pattern weather information",2015,"ABU Technical Review",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960863739&partnerID=40&md5=45ac24da83c83778c6b9587752165763","NHK has been studying technologies for automatically generating machine translation of weather information announcements from Japanese to Japanese Sign Language (JSL) with CG animation, to increase the number of TV services for deaf people. The CG animation defines a high quality 3D human model of hands, fingers, and facial expressions, and it controls the model using motion capture data obtained from a real human signer. While the current state of the natural language machine translation technology is not yet satisfactory, we have developed a practical prototype system that generates high quality information on fixed pattern weather, utilising the language resources we built in the process of the machine translation research. In this report we first describe the outline of the research project, then, we explain the achievement of the prototype of a system for automatically generating sign language animation from formal messages in XML format issued by the Japan Meteorological Agency (JMA).",,"Animation; Computer aided language translation; Translation (languages); Automatic Generation; High quality information; Japan meteorological agencies; Japanese sign languages; Language resources; Machine translations; Motion capture data; Weather information; Computational linguistics",2-s2.0-84960863739
"Woo K.L., Rieucau G.","The importance of syntax in a dynamic visual signal: recognition of jacky dragon displays depends upon sequence",2015,"Acta Ethologica",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952982110&doi=10.1007%2fs10211-014-0209-1&partnerID=40&md5=ce9cd97ad1ef160ca0e4890c3eb8f1c7","It is well established that recognition of complex acoustic signals, such as bird song, is dependent upon the temporal ordering of signal units or syntax. Much less is known about functionally analogous visual displays. The jacky dragon (Amphibolurus muricatus) is a native Australian agamid lizard with a highly stereotyped visual display made up of three discrete motor patterns. We conducted a playback experiment using high-resolution computer animations of conspecifics to test the importance of temporal order for signal efficacy. Lizards were shown three different life-sized simulated animations of conspecific differing in their skin texture and morphology signatures ranging from highly natural to abnormal. We evaluated signal recognition and assessed the relative importance of syntax and morphology. Our results showed that signal recognition is highly sensitive to syntax and this largely determines the observers’ behavioural responses. Stimuli with abnormal texture and shape were highly effective, as long as the natural order of motor patterns was preserved. Display recognition in jacky lizards hence depends upon syntax in just the same way as temporally constrained signals in other modalities. © 2014, Springer-Verlag Berlin Heidelberg and ISPA.","Amphibolurus muricatus; Computer animation; Jacky dragon; Morphology; Syntax; Visual display",,2-s2.0-84952982110
"Iwamoto N., Shum H.P.H., Yang L., Morishima S.","Multi-layer Lattice Model for Real-Time Dynamic Character Deformation",2015,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945176435&doi=10.1111%2fcgf.12749&partnerID=40&md5=ca1c60d576717e3d8979546c4fd0c7d6","Due to the recent advancement of computer graphics hardware and software algorithms, deformable characters have become more and more popular in real-time applications such as computer games. While there are mature techniques to generate primary deformation from skeletal movement, simulating realistic and stable secondary deformation such as jiggling of fats remains challenging. On one hand, traditional volumetric approaches such as the finite element method require higher computational cost and are infeasible for limited hardware such as game consoles. On the other hand, while shape matching based simulations can produce plausible deformation in real-time, they suffer from a stiffness problem in which particles either show unrealistic deformation due to high gains, or cannot catch up with the body movement. In this paper, we propose a unified multi-layer lattice model to simulate the primary and secondary deformation of skeleton-driven characters. The core idea is to voxelize the input character mesh into multiple anatomical layers including the bone, muscle, fat and skin. Primary deformation is applied on the bone voxels with lattice-based skinning. The movement of these voxels is propagated to other voxel layers using lattice shape matching simulation, creating a natural secondary deformation. Our multi-layer lattice framework can produce simulation quality comparable to those from other volumetric approaches with a significantly smaller computational cost. It is best to be applied in real-time applications such as console games or interactive animation creation. © 2015 The Author(s) Computer Graphics Forum.",,"Algorithms; Animation; Application programs; Bone; Computer games; Computer graphics; Computer hardware; Crystal lattices; Deformation; Hardware; Computational costs; Computer graphics hardware; Interactive animations; Lattice framework; Real-time application; Real-time dynamics; Simulation quality; Volumetric approach; Finite element method",2-s2.0-84945176435
"Amini R., Lisetti C., Ruiz G.","HapFACS 3.0: FACS-based facial expression generator for 3D speaking virtual characters",2015,"IEEE Transactions on Affective Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950274718&doi=10.1109%2fTAFFC.2015.2432794&partnerID=40&md5=7528dfada32136108c1ac64615da08ce","With the growing number of researchers interested in modeling the inner workings of affective social intelligence, the need for tools to easily model its associated expressions has emerged. The goal of this article is two-fold: 1) we describe HapFACS, a free software and API that we developed to provide the affective computing community with a resource that produces static and dynamic facial expressions for three-dimensional speaking characters; and 2) we discuss results of multiple experiments that we conducted in order to scientifically validate our facial expressions and head animations in terms of the widely accepted Facial Action Coding System (FACS) standard, and its Action Units (AU). The result is that users, without any 3D-modeling nor computer graphics expertise, can animate speaking virtual characters with FACS-based realistic facial expression animations, and embed these expressive characters in their own application(s). The HapFACS software and API can also be used for generating repertoires of realistic FACS-validated facial expressions, useful for testing emotion expression generation theories. © 2015 IEEE.","3D facial animation; Facial action coding system (FACS); FACS-based facial expression generation","Computation theory; Computer graphics; Face recognition; Gesture recognition; Signal encoding; Software testing; Three dimensional computer graphics; 3d facial animations; Affective Computing; Dynamic facial expression; Emotion expression; Facial Action Coding System; Facial expression generation; Facial Expressions; Social intelligence; Computer keyboards",2-s2.0-84950274718
"Chentanez N., Müller M., Kim T.-Y.","Coupling 3D Eulerian, Heightfield and Particle Methods for Interactive Simulation of Large Scale Liquid Phenomena",2015,"IEEE Transactions on Visualization and Computer Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941104612&doi=10.1109%2fTVCG.2015.2449303&partnerID=40&md5=cdc38179b179cca868aebedcae31102c","We propose a new method to simulate large scale water phenomena by combining particle, 3D grid and height field methods. In contrast to most hybrid approaches that use particles to simulate foam and spray only, we also represent the bulk of water near the surface with both particles and a grid depending on the regions of interest and switch between those two representations during the course of the simulation. For the coupling we leverage the recent idea of tracking the water surface with a density field in grid based methods. Combining particles and a grid simulation then amounts to adding the density field of the particles and the one stored on the grid. For open scenes, we simulate the water outside of the 3D grid domain by solving the Shallow Water Equations on a height field. We propose new methods to couple these two domains such that waves travel naturally across the border. We demonstrate the effectiveness of our approach in various scenarios including a whale breaching simulation, all running in real-time or at interactive rates. © 2015 IEEE.","fluid simulation; physics based animation","Computer graphics; Software engineering; Fluid simulations; Grid based method; Interactive rates; Interactive simulations; Particle methods; Physics-based animation; Regions of interest; Shallow water equations; Equations of motion",2-s2.0-84941104612
"Gast T.F., Schroeder C., Stomakhin A., Jiang C., Teran J.M.","Optimization Integrator for Large Time Steps",2015,"IEEE Transactions on Visualization and Computer Graphics",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941042797&doi=10.1109%2fTVCG.2015.2459687&partnerID=40&md5=0ac9d54dc1bd38b291fa08259dec393f","Practical time steps in today's state-of-the-art simulators typically rely on Newton's method to solve large systems of nonlinear equations. In practice, this works well for small time steps but is unreliable at large time steps at or near the frame rate, particularly for difficult or stiff simulations. We show that recasting backward Euler as a minimization problem allows Newton's method to be stabilized by standard optimization techniques with some novel improvements of our own. The resulting solver is capable of solving even the toughest simulations at the 24, Hz frame rate and beyond. We show how simple collisions can be incorporated directly into the solver through constrained minimization without sacrificing efficiency. We also present novel penalty collision formulations for self collisions and collisions against scripted bodies designed for the unique demands of this solver. Finally, we show that these techniques improve the behavior of Material Point Method (MPM) simulations by recasting it as an optimization problem. © 2015 IEEE.","Animation; Computer Graphics; Three-Dimensional Graphics and Realism","Animation; Computer graphics; Constrained optimization; Newton-Raphson method; Nonlinear equations; Optimization; Constrained minimization; Material point methods; Minimization problems; Newton's methods; Optimization problems; Standard optimization; State of the art; Three-dimensional graphics and realism; Three dimensional computer graphics",2-s2.0-84941042797
"Li Y., Barbič J.","Stable Anisotropic Materials",2015,"IEEE Transactions on Visualization and Computer Graphics",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941030996&doi=10.1109%2fTVCG.2015.2448105&partnerID=40&md5=2d92c74145965a5d57bf4304198b1717","The Finite Element Method (FEM) is commonly used to simulate isotropic deformable objects in computer graphics. Several applications (wood, plants, muscles) require modeling the directional dependence of the material elastic properties in three orthogonal directions. We investigate linear orthotropic materials, a special class of linear anisotropic materials where the shear stresses are decoupled from normal stresses, as well as general linear (non-orthotropic) anisotropic materials. Orthotropic materials generalize transversely isotropic materials, by exhibiting different stiffness in three orthogonal directions. Orthotropic materials are, however, parameterized by nine values that are difficult to tune in practice, as poorly adjusted settings easily lead to simulation instabilities. We present a user-friendly approach to setting these parameters that is guaranteed to be stable. Our approach is intuitive as it extends the familiar intuition known from isotropic materials. Similarly to linear orthotropic materials, we also derive a stability condition for a subset of general linear anisotropic materials, and give intuitive approaches to tuning them. In order to simulate large deformations, we augment linear corotational FEM simulations with our orthotropic and general anisotropic materials. © 2015 IEEE.","Animation; Anisotropic Materials; Computer Graphics; Finite Element Method; Orthotropic Materials","Animation; Anisotropy; Computer graphics; Deformation; Optical anisotropy; Shear stress; Anisotropic material; Directional dependence; Elastic properties; Isotropic materials; Linear anisotropic materials; Orthogonal directions; Orthotropic materials; Transversely isotropic materials; Finite element method",2-s2.0-84941030996
"Luzón J.M., Letón E.","Use of animated text to improve the learning of basic mathematics",2015,"Computers and Education",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929625758&doi=10.1016%2fj.compedu.2015.04.016&partnerID=40&md5=b835596abc5494908026b0a4fe611626","A small detail can have large consequences. Current technological systems have opened up a huge world of possibilities for teachers at all levels and in every field. This research study concerns the role that can be played by technological resources to improve or promote the cognitive processes that make understanding and learning possible. More specifically it is meant to examine, within the framework of the Cognitive Theory of Multimedia Learning and of the Cognitive Load Theory, put forward by Mayer and Sweller respectively, the benefits that the introduction of slight changes in multimedia materials - in this case, the application of an animation effect to a handwritten text of a mathematical nature - can have over learning quantity and quality. The study involved 255 students in the 2nd and 3rd years of the Spanish secondary education (Educación Secundaria Obligatoria, ESO), who received a computer-based lesson in video podcast format about elementary event probability. Results suggest that suitable inclusion of an animation effect in the materials can facilitate the cognitive processes that specialise in selecting information, building representation models, and making sense, thus promoting students' learning ability. © 2015 Elsevier Ltd. All rights reserved.","Animation; Cognitive effects; Mathematics; Multimedia learning; Video podcast","Animation; Cognitive systems; E-learning; Education; Mathematical techniques; Teaching; Cognitive effects; Cognitive load theory; Cognitive theory of multimedia learning; Multi-media learning; Multimedia materials; Technological resources; Technological system; Video podcast; Education computing",2-s2.0-84929625758
"Liu L., Li X., Chen Y., Liu X., Zhang J.J., Wu E.","An Efficient Feathering System with Collision Control",2015,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945189398&doi=10.1111%2fcgf.12766&partnerID=40&md5=d6ae1376a6fe87e6eaf8ae658da72bf7","We present an efficient interactive system for dressing a naked bird with feathers. In our system, a skeleton associated with guide feathers is used to describe the distribution of the body feathers. The special skeleton can be easily built by the user, given a 3D bird model as input. To address the problem of interpenetrations among feathers, the growth priority between the feather roots is defined, with which we obtain the growth order from a greedily constructed directed acyclic graph. Each feather is then adjusted in that order by a height field based collision resolution process. The height field not only provides an efficient way to detect the collision but also enables us to finely control the degree of collision during feather adjustments. The results show that our approach is capable of resolving the collisions among thousands of feathers in a few seconds. If model animation is desired, the feathers can be adjusted on the fly at interactive framerates. Details of our implementation are provided with several examples to demonstrate the effectiveness of our system. © 2015 The Author(s) Computer Graphics Forum.",,"Birds; Musculoskeletal system; Collision control; Collision resolution; Directed acyclic graph (DAG); Growth ordering; Height fields; Interactive system; Model animations; On the flies; Directed graphs",2-s2.0-84945189398
"Diós P., Nagy S., Pál S., Pernecker T., Kocsis B., Budán F., Horváth I., Szigeti K., Bölcskei K., Máthé D., Dévay A.","Preformulation studies and optimization of sodium alginate based floating drug delivery system for eradication of Helicobacter pylori",2015,"European Journal of Pharmaceutics and Biopharmaceutics",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939179056&doi=10.1016%2fj.ejpb.2015.07.020&partnerID=40&md5=2a7e508cc1ebfba72672dd7798cb30cf","Abstract The aim of this study was to design a local, floating, mucoadhesive drug delivery system containing metronidazole for Helicobacter pylori eradication. Face-centered central composite design (with three factors, in three levels) was used for evaluation and optimization of in vitro floating and dissolution studies. Sodium alginate (X<inf>1</inf>), low substituted hydroxypropyl cellulose (L-HPC B1, X<inf>2</inf>) and sodium bicarbonate (X<inf>3</inf>) concentrations were the independent variables in the development of effervescent floating tablets. All tablets showed acceptable physicochemical properties. Statistical analysis revealed that tablets with 5.00% sodium alginate, 38.63% L-HPC B1 and 8.45% sodium bicarbonate content showed promising in vitro floating and dissolution properties for further examinations. Optimized floating tablets expressed remarkable floating force. Their in vitro dissolution studies were compared with two commercially available non-floating metronidazole products and then microbiologically detected dissolution, ex vivo detachment force, rheological mucoadhesion studies and compatibility studies were carried out. Remarkable similarity (f<inf>1</inf>, f<inf>2</inf>) between in vitro spectrophotometrically and microbiologically detected dissolutions was found. Studies revealed significant ex vivo mucoadhesion of optimized tablets, which was considerably increased by L-HPC. In vivo X-ray CT studies of optimized tablets showed 8 h gastroretention in rats represented by an animation prepared by special CT technique. © 2015 Elsevier B.V.","Ex vivo mucoadhesion; Floating force; Gastroretention; Low substituted hydroxypropyl cellulose; Sodium alginate; X-ray CT imaging","alginic acid; bicarbonate; hydroxypropylcellulose; metronidazole; alginic acid; antiinfective agent; excipient; glucuronic acid; hexuronic acid; metronidazole; tablet; animal experiment; Article; bacterial clearance; computer assisted tomography; controlled study; differential scanning calorimetry; drug absorption; drug delivery system; drug retention; drug solubility; ex vivo study; Helicobacter pylori; high performance liquid chromatography; in vitro study; in vivo study; lag time; male; mucoadhesion; nonhuman; physical chemistry; preformulation; rat; single photon emission computer tomography; SPECT scanner; statistical analysis; tablet hardness; tablet surface; tablet thickness; thermal analysis; adhesion; animal; chemistry; drug delivery system; drug design; drug effects; drug release; female; gastric mucosa; Helicobacter Infections; Helicobacter pylori; kinetics; medicinal chemistry; metabolism; microbiology; procedures; solubility; surface property; tablet; Wistar rat; Adhesiveness; Alginates; Animals; Anti-Bacterial Agents; Chemistry, Pharmaceutical; Drug Delivery Systems; Drug Design; Drug Liberation; Excipients; Female; Gastric Mucosa; Glucuronic Acid; Helicobacter Infections; Helicobacter pylori; Hexuronic Acids; Kinetics; Male; Metronidazole; Rats, Wistar; Solubility; Surface Properties; Tablets",2-s2.0-84939179056
"Ibrahim N., Wan Ahmad W.F., Shafie A.","Multimedia mobile learning application for children’s education: The development of MFolktales",2015,"Asian Social Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987922584&doi=10.5539%2fass.v11n24p203&partnerID=40&md5=57fca6e9bfefc6defef1c3e2ebd56760","Children learn from what they see and hear. One of the attractive applications is animation story and these children are exposed to various types of animation story. However, not all animation stories presented are suitable for children’s education in terms of exaggeration elements applied in animation. Furthermore, the existence of mobile application does not emphasize the touch gesture that is suitable for children’s age. Hence, there is a lack of mobile learning applications with education-oriented environment for children’s education. Therefore, there is a need for research to develop a well-designed mobile application with suitable exaggeration elements together with good story plots and socio-cultural values to educate as well entertain children. This paper discusses the design and development of Malay folktales mobile application called MFolktales based on a local Malay folktale story. MFolktales is an Android-based application and it was developed based on the validated conceptual model as well as analyzed and defined design principles and requirements. This paper presents the development process of MFolktales application. The development life cycle was adopted from ADDIE Instructional Design (ID) model, taking into consideration the animation development process of pre-production, production, and post-production. Overall, there are five phases involved in the development life cycle: analysis, design, development, implementation and evaluation. The application was tested to strengthen its functionality and usability. The result shows that MFolktales application is ready to be tested to real users and ready to be commercialized. © 2015, Canadian Center of Science and Education. All rights reserved.","Child-computer interaction; Education; Folktales; Instructional design; Mobile application",,2-s2.0-84987922584
"Lovett A., Appleton K., Warren-Kretzschmar B., Von Haaren C.","Using 3D visualization methods in landscape planning: An evaluation of options and practical issues",2015,"Landscape and Urban Planning",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944157150&doi=10.1016%2fj.landurbplan.2015.02.021&partnerID=40&md5=5a1cfb13328b49cf1cd45ea7a68bc0e1","Technical advances in landscape visualization have tended to, and still do, outstrip the understanding of how best to use them in practical planning contexts. This paper draws upon recent literature and experience gained during a number of projects to address three key questions regarding the most effective use of 3D landscape visualizations for communication purposes. In essence these are ""when?"" (to use them), ""what?"" (to include) and ""how?"" (to display them). Three main visualization options (rendered still images, animations and real-time models) are compared and particular constraints and strengths are discussed. In addition, an evaluation is made of the ability of the information presented in landscape visualizations to meet criteria of credibility, salience and legitimacy when communicating with stakeholders. Closing guidance is given on the use of visualizations in landscape planning and suggestions regarding future research needs are made. These focus on the need for applications of 3D visualization techniques to be more systematically evaluated, ideally as part of landscape planning exercises where the benefits of particular approaches for different purposes and audiences are examined across all stages of the decision-making process. © 2015 Elsevier B.V.","Evaluation; Immersion; Interactivity; Landscape visualization; Public participation; Realism","Decision making; Visualization; Evaluation; Immersion; Interactivity; Landscape visualization; Public participation; Realism; Three dimensional computer graphics",2-s2.0-84944157150
"Huang Z., Gong G., Han L.","Physically-based smoke simulation for computer graphics: a survey",2015,"Multimedia Tools and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940403991&doi=10.1007%2fs11042-014-1992-4&partnerID=40&md5=ebb6657d002c90bdd70ae1a715c6f9a5","We present an up-to-date survey on physically-based smoke simulation. Physically-based method becomes predominant in smoke simulation in computer graphics community. It prevails over traditional methods for its plausible visual effect. Significant results have been carried out over past two decades. We give a latest overview of state-of-the-art of smoke simulation and also compare various techniques according to their characteristics. We discuss several issues in terms of computational efficiency, numerical stability, numerical dissipation, and runtime performance. A number of open challenging problems are also addressed for further exploration. © 2014, Springer Science+Business Media New York.","Animation control; Physically-based methods; Real-time rendering; Smoke and gaseous phenomena","Computational efficiency; Smoke; Smoke abatement; Surveys; Animation control; Gaseous phenomenon; Numerical dissipation; Physically based; Real-time rendering; Run-time performance; Smoke simulation; State of the art; Computer graphics",2-s2.0-84940403991
"Basuhail A.A.","A Model for Implementing E-Teaching Objects for the Holy Quran and Related Sciences Using Animations",2015,"Proceedings - 2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences, NOORIC 2013",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964994065&doi=10.1109%2fNOORIC.2013.28&partnerID=40&md5=a1d875d9f7543079187feb81b8e966fa","This paper presents a suggested workable model for designing and implementing electronic teaching objects for the Holy Quran and related sciences, such as: tilawah (recitation), tafseer (interpretation), and tajweed (intonation). The developed objects can be used to perform some practices such as tahfeez (memorization) of the Holy Quran. The model represents a systematic approach for implementing Quranic contents using utilizable and accessible presentation-based developing tools that are basically employ animations and computer graphics. This approach can be followed by teachers and instructors of the Holy Quran and related sciences who are considered as matter-experts, but they are deficient in the technological expertise due to lack of specialization. The design includes educational and training contents, as well as evaluations. The model supports teachers and learners of the Holy Quran to achieve the educational goals in an attainable manner. The method of implementation discussed here can be adopted for delivering e-courses of Quranic contents to students or learners of the Holy Quran and related sciences. The designed teaching objects have the features of easiness of use and possibility of sharing among instructors and learners of the Holy Quran. Other features are rapidness of implementation and relative low cost. The objects can be integrated in an e-learning environment, or it can be distributed over an internal computer network or the Internet. The use of the teaching objects can significantly enhance the teaching of the Holy Quran and related sciences. © 2015 IEEE.","animation; computer visuals; e-learning; e-teaching; presentation-based design; Quran related sciences; Quranic content; teaching object; the Holy Quran","Animation; Computer aided instruction; Computer graphics; Distributed computer systems; E-learning; Education; Engineering education; E-learning environment; E-teaching; Educational goals; Low costs; Quran related sciences; Quranic content; the Holy Quran; Teaching",2-s2.0-84964994065
"Cho J., Choi H., Ahn S.C., Kim I.-J.","Parameterized facial modelling and animation",2015,"Context Aware Human-Robot and Human-Agent Interaction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955729179&doi=10.1007%2f978-3-319-19947-4_6&partnerID=40&md5=152aecd0d78f9e772f3bd2436a8aa259","Facial modelling is a fundamental technique in a variety of applications in computer graphics, computer vision and pattern recognition areas. As 3D technologies evolved over the years, the quality of facial modelling greatly improved. To enhance the modelling quality and controllability of the model further, parametric methods, which represent or manipulate facial attributes (e.g. identity, expression, viseme) with a set of control parameters, have been proposed in recent years. The aim of this chapter is to give a comprehensive overview of current state-of-the-art parametric methods for realistic facial modelling and animation. © Springer International Publishing Switzerland 2016. All rights reserved.",,"Animation; Computer graphics; 3D technology; Control parameters; Parameterized; Parametric method; State of the art; Pattern recognition",2-s2.0-84955729179
"Yusoff F.H., Ismail M., Yussof M.Y.M.","Random Animated Transition Using Quranic Verses",2015,"Proceedings - 2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences, NOORIC 2013",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964989569&doi=10.1109%2fNOORIC.2013.45&partnerID=40&md5=d6cbfa7089fd58f688a9f2482fe05cef","In-between animated transition can be utilized for various purposes. Among others it can be used for screen savers on PC or advertising on billboard. In the case of advertising on the billboard, a series of video clip or still images will be displayed to the prospective users. Between these clips, animated transitions will be applied so that the change from one clip to another can be smoothly displayed. Currently various transition technique can be used for achieving this effect, mathematicalbased interpolation such as linear or spline-based interpolation can be used. Similarly, nature movement pattern such as flowing water and flaming fire model are also utilized. It is widely known that Quranic verses give soothing effect to its listeners. However, not much has been studied on applying the soothing effect on visual medium. This paper looks at recreating the soothing effect on something which is visual-based. This sound-induced visualization re-creates the transition animation using Quranic verses recitation derived pattern as its model. Comparison is done with existing interpolation technique and nature based interpolation. Visual Attractive Rating experiments are conducted to measure the attractiveness level among each other. The results shows that the Quranic verses pattern can potentially produced attractive animated transition on par with general transition to be implemented for application such as advertising billboard or screen savers. © 2015 IEEE.","computer animation; image transition; Quranic Verses Visualization","Animation; Engineering education; Marketing; Visualization; Animated transitions; Computer animation; Flaming fires; Flowing waters; image transition; Interpolation techniques; Movement pattern; Transition animation; Interpolation",2-s2.0-84964989569
"Magnenat-Thalmann N., Yuan J., Thalmann D., You B.-J.","Context aware human-robot and human-agent interaction",2015,"Context Aware Human-Robot and Human-Agent Interaction",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955730401&doi=10.1007%2f978-3-319-19947-4&partnerID=40&md5=cdedb3c16631dbd4b594d1158a6f1412","This is the first book to describe how Autonomous Virtual Humans and Social Robots can interact with real people, be aware of the environment around them, and react to various situations. Researchers from around the world present the main techniques for tracking and analysing humans and their behaviour and contemplate the potential for these virtual humans and robots to replace or stand in for their human counterparts, tackling areas such as awareness and reactions to real world stimuli and using the same modalities as humans do: verbal and body gestures, facial expressions and gaze to aid seamless human-computer interaction (HCI). The research presented in this volume is split into three sections: User Understanding through Multisensory Perception: deals with the analysis and recognition of a given situation or stimuli, addressing issues of facial recognition, body gestures and sound localization. Facial and Body Modelling Animation: presents the methods used in modelling and animating faces and bodies to generate realistic motion. Modelling Human Behaviours: presents the behavioural aspects of virtual humans and social robots when interacting and reacting to real humans and each other. Context Aware Human-Robot and Human-Agent Interaction would be of great use to students, academics and industry specialists in areas like Robotics, HCI, and Computer Graphics. © Springer International Publishing Switzerland 2016. All rights reserved.",,"Behavioral research; Computer graphics; Face recognition; Human computer interaction; Robots; Virtual reality; Autonomous virtual humans; Behavioural aspects; Facial Expressions; Facial recognition; Human agent interactions; Human computer interaction (HCI); Multisensory perceptions; Sound localization; Human robot interaction",2-s2.0-84955730401
"Lee J., Magnenat-Thalmann N., Thalmann D.","Shared object manipulation",2015,"Context Aware Human-Robot and Human-Agent Interaction",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955704859&doi=10.1007%2f978-3-319-19947-4_9&partnerID=40&md5=114d379ab29daa46e22daf14b1a50a8e","In this chapter, we introduce a concept of shared object manipulation between real and virtual humans. The shared object manipulation allows both real and virtual humans to collaborate in real-time. These can be applied to 3D telepresence applications such as computer-aided design and virtual simulation and training. However, it is still far from achieving the expected results from this area because it consists of three different and complex research domains. Firstly,we need to consider a virtual object grasping method for intuitive and convenient virtual object manipulation. Secondly, human-like animation is required for virtual object manipulation by virtual humans. Thirdly, consistency management of shared object manipulation is required to avoid conflicts frommultiple simultaneous inputs. After review of state of the art, solution approaches and their limitations are introduced.We conclude with a discussion of future directions for the shared object manipulation between real and virtual humans. © Springer International Publishing Switzerland 2016. All rights reserved.",,"Computer aided design; Three dimensional computer graphics; Visual communication; Consistency management; Research domains; Shared-object manipulation; Solution approach; State of the art; Telepresence applications; Virtual objects; Virtual simulations; Virtual reality",2-s2.0-84955704859
[No author name available],"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983178068&partnerID=40&md5=c91e02e351580bf324612371871e9f6f","The proceedings contain 21 papers. The topics discussed include: Machiavellian agents: player modeling to deceive and be deceived; interacting with multiple game genres using motion onset visual evoked potentials; classification effects on motion-onset visual evoked potentials using commercially available video games; a crossword puzzle generator using genetic algorithms with wisdom of artificial crowds; a unity 3D framework for algorithm animation; applying formal picture languages to procedural content generation; the quest for the perfect perfect-maze; designing immersive affective environments with biofeedback; exploring options for efficiently evaluating the playability of computer game agents; online computer game set architecture for people with cerebral palsy: case study; and crimes in, of and by virtual worlds and computer gaming.",,,2-s2.0-84983178068
"Harshfield N., Chang D.-J., Rammohan","A Unity 3D framework for algorithm animation",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962284441&doi=10.1109%2fCGames.2015.7272955&partnerID=40&md5=1311f88714aeeb504ef39910f7cc866b","Since the first algorithm animation interactive computer system called BALSA appeared in 1984, many algorithm animation and visualization applications have been developed for educational purposes. Modern game engines (like Unity 3D and Unreal) possess a multitude of features which are vital for algorithm animation applications. Until now, these features have not been systematically exploited for educational applications. In this paper, we circumvent conventional programming languages (such as Java, C++, etc.) and their corresponding toolkits and instead describe our design of an alglorithm animation framework built around Unity 3D and demonstrate its application to the educational realm of graph algorithm animation. This project serves as a proof of concept that modern game engines such as Unity 3D can be used to create modern and effective tools for learning concepts contained in the realm of computer science and engineering. © 2015 IEEE.","animation; graph; learning; Unity 3D; visualization","Algorithms; C++ (programming language); Computer games; Education; Flow visualization; Interactive computer systems; Java programming language; Multimedia systems; Three dimensional computer graphics; Visualization; Algorithm animation; Computer science and engineerings; Educational Applications; graph; Graph algorithms; ITS applications; learning; Visualization application; Animation",2-s2.0-84962284441
"Losavio M.","Crimes in, of and by virtual worlds and computer gaming",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962285392&doi=10.1109%2fCGames.2015.7272962&partnerID=40&md5=e437435360c579f727bf36eb6c69d51c","Criminal and delictual conduct are found within virtual worlds and computer gaming just as in the physical world. These may manifest themselves in myriad ways, from the role playing conduct of players within the game space to conduct by players, game developers and operators and others that may violate criminal laws and normative prohibitions generally. We examine this spectrum of conduct and the implications for players, developers and policy makers. © 2015 IEEE.","computer game; crime; delict; virtual","Animation; Computer crime; Crime; Interactive computer graphics; Interactive computer systems; Multimedia systems; Virtual reality; Computer gaming; Criminal laws; delict; Physical world; Policy makers; Role playing; virtual; Virtual worlds; Computer games",2-s2.0-84962285392
"Wareham T., Watson S.","Exploring options for efficiently evaluating the playability of computer game agents",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962252438&doi=10.1109%2fCGames.2015.7272961&partnerID=40&md5=a935ff1386f570a8a928bba37830c0f6","Automatic generation of game content is an important challenge in computer game design. Such generation requires methods that are both efficient and guaranteed to produce playable content. While existing methods are adequate for currently available types of games, games based on more complex entities and structures may require new methods. In this paper, we use computational complexity analysis to explore algorithmic options for efficiently evaluating the playability of and generating playable groups of enhanced agents that are capable of exchanging items and facts with each other and human players. Our results show that neither of these problems can be solved both efficiently and correctly either in general or relative to a surprisingly large number of restrictions on enhanced agent structure and gameplay. We also give the first restrictions under which the playability evaluation problem is solvable both efficiently and correctly. © 2015 IEEE.","Computational complexity; Computer science; Computers; Conferences; Games; Polynomials","Animation; Computational complexity; Computer science; Computers; Interactive computer graphics; Interactive computer systems; Multimedia systems; Parallel processing systems; Polynomials; Agent structure; Automatic Generation; Complex entities; Computational complexity analysis; Conferences; Evaluation problems; Game contents; Games; Computer games",2-s2.0-84962252438
"Mendez-Zorrilla A., Garcia-Zapirain B., Eskubi-Astobiza J., Fernández-Cordero L.","Sphero as an interactive tool in computer games for people with ID",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962233635&doi=10.1109%2fCGames.2015.7272953&partnerID=40&md5=ecfef54488fb816c329f904a1590bee1","This paper presents an experiment in which people with intellectual disabilities played 3 apps with different levels and purposes on an iPad Air. As part of the game they were required to interact with Sphero and the activities they tried to perform required motor skills, attention and memory. We have selected two groups of participants according to their level of support needs. The results show the highest level of satisfaction in both groups in the game involving Sphero. In terms of effectiveness of activities for this profile of participant as interventions the results reveal that driving and care activities do show an adequate response, though with worse results related to memory. © 2015 IEEE.","intellectual disability; Smart-toy; Sphero","Animation; Interactive computer systems; Multimedia systems; Care activities; Intellectual disability; Interactive tool; Level of satisfaction; Motor skills; Smart-toy; Sphero; Computer games",2-s2.0-84962233635
"Soto B.G.-Z., Mendez-Zorrilla A., Madariaga-Ortuzar A., Lazcano-Quintana I.","Online computer game set architecture for people with cerebral palsy: Case study",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962220785&doi=10.1109%2fCGames.2015.7272973&partnerID=40&md5=19b7954743684af84806af7ef46688f9","This work in progress is focused on adapted design of a set of games for people with cerebral palsy. In the specification all the stakeholders (family, therapeutics and monitors) have participated. In the games set 4 levels of complexity have been proposed, and also the different types of interaction: touchscreen, push buttons, etc. The evaluation of the 4 prototypes will be held including not only testing the proper functionality of the games, but ensuring the accessibility and usability standards. © 2015 IEEE.","Cerebral Palsy; Game set; Push buttons","Animation; Diseases; Fasteners; Interactive computer systems; Multimedia systems; Standards; 4-level; Cerebral palsy; Game set; Push buttons; Work in progress; Computer games",2-s2.0-84962220785
"Beveridge R., Marshall D., Wilson S., Coyle D.","Classification effects on Motion-Onset Visual Evoked Potentials using commercially available video games",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962272841&doi=10.1109%2fCGames.2015.7272958&partnerID=40&md5=27473909aec21e6ce18a0d3e3443502f","Motion Onset Visually Evoked Potentials (mVEPs) are elicited by visual stimuli that offer a more elegant, less fatiguing visual presentation than other stimuli used in visual evoked potentials (VEPs) studies. mVEP for use in brain computer interface (BCI) video gaming offer users a pleasant presentation environment to play video games. Modern, commercially available video games are a popular form of entertainment offering visually compelling, dynamic and graphically complex environments. However, most popular games exhibit visually fatiguing properties such as moving, flashing imagery and complex 3D shapes which may hinder accuracies of certain BCI paradigms. Because mVEP relies on motion visual stimulus rather than flashing imagery, it may be more apposite for use within complex game environments than other VEPs such as P300 and SSVEP. In this study we investigate the potential impact of varying levels of graphical fidelity from commercially available video games within an mVEP BCI control scheme. Building on a previous study, which investigated simplistic 3D based game levels, the current study investigates increased visual complexity in commercially available games from five different generations of gaming console and from different genres. We compared the visual effects of each of the five games on mVEP detection accuracy and found some of the more primitive properties of video games such as the use of primary colours, dynamic character movement, flashing imagery and the pace of the games have an influence on detection accuracies. These findings provide information relevant to design of a mVEP BCI game which is visually appealing to a wide range of users whilst maintaining mVEP accuracies. © 2015 IEEE.","2D; 3D; Brain-Computer Interface (BCI); Console; Electroencephalography (EEG); Gaming; Geme; Graphics; Motion Onset Visually Evoked Potentials (m YEP); Visual","Animation; Bioelectric potentials; Computer games; Electroencephalography; Electrophysiology; Human computer interaction; Image coding; Interactive computer graphics; Interactive computer systems; Interfaces (computer); Motion analysis; Multimedia systems; Console; Gaming; Geme; Graphics; Visual; Visually evoked potentials; Brain computer interface",2-s2.0-84962272841
"Frutos-Pascual M., García-Zapirain B., Mehdi Q.H.","Where do they look at? Analysis of gaze interaction in children while playing a puzzle game",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962226800&doi=10.1109%2fCGames.2015.7272954&partnerID=40&md5=3388dc18ee4285abb7b9271028e10569","In recent years the usage of video-games in education, therapies and training, has risen sharply. The adaptation of serious games to users' needs may offer new enriching learning environments. Eye tracking sensors collect information about the location and duration of eye movements within a specific area on a computer monitor. This paper presents a usability analysis of users' eye movements while using the set of puzzle games. For this purpose a set of data collected from 63 children with an average age of 9.95 (SD = 1.21) and different attention skills is analyzed during their interaction with a set of puzzle games. Fixation data is extracted and analyzed as regards of where do they look first and most. These resources should be complemented with other interaction records, but they are interesting for creating optimized user interfaces. © 2015 IEEE.","Computers; Games; Gaze tracking; Monitoring; Sensors; Usability; Visualization","Animation; Computer aided instruction; Computers; Education; Eye movements; Flow visualization; Human computer interaction; Interactive computer graphics; Interactive computer systems; Monitoring; Multimedia systems; Personnel training; Sensors; Tracking (position); User interfaces; Eye-tracking sensors; Games; Gaze interaction; Gaze tracking; Learning environments; Specific areas; Usability; Usability analysis; Computer games",2-s2.0-84962226800
"Marshall D., Beveridge R., Wilson S., Coyle D.","Interacting with multiple game genres using Motion Onset Visual Evoked Potentials",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962281662&doi=10.1109%2fCGames.2015.7272957&partnerID=40&md5=2ba0d7bc571a002d0b5bcef4e2498d7b","Motion Onset Visually Evoked Potentials (mVEPs) allow users to interact with technology using non-visually fatiguing stimuli in a Brain Computer Interface (BCI). This study employs mVEP in an onscreen controller and evaluates players' ability to use mVEP for online gameplay with games from three different genres namely action, puzzle and sports. The onscreen controller consists of five mVEP stimuli that are presented as buttons to allow the participant to choose from five different actions in each game. The performance was assessed based on online BCI accuracy and game score for each game. Results indicate that the players could control the games with an average online accuracy of 71% (5 class classification chance accuracy is 20%). The results also suggest that the use of the mVEP controller with a detailed environment and stimulating feedback in the form of an action game helped to attain the highest online accuracy (75%). © 2015 IEEE.","Brain Computer Interface; Controller; Games; Genre; Motion onset visual evoked potentials","Animation; Bioelectric potentials; Computer games; Controllers; Electrophysiology; Interactive computer graphics; Interactive computer systems; Interfaces (computer); Multimedia systems; Gameplay; Games; Genre; Visual evoked potential; Visually evoked potentials; Brain computer interface",2-s2.0-84962281662
"McPheron D.","Video gaming accessibility",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962207039&doi=10.1109%2fCGames.2015.7272966&partnerID=40&md5=6df6b27140d1e206db83c68ed7412e9d","Video games are becoming less and less usable by people with disabilities every day. These disabilities include cognitive, visual, and mobility. The purpose of this paper is to discuss the necessity of making video games accessible. This will be done through looking at benefits, current work for all disabilities, and how it's looked at by the law. The topic of video gaming accessibility is especially important in today's age with the disabled population rising. It is important to not let the disabled be left out of the enjoyment of video games. © 2015 IEEE.","Computers; Lead; Presses; Visualization","Animation; Computers; Flow visualization; Human computer interaction; Interactive computer graphics; Interactive computer systems; Lead; Multimedia systems; Presses (machine tools); Transportation; People with disabilities; Video game; Video gaming; Computer games",2-s2.0-84962207039
"Watson S., Vardy A., Banzhaf W., Wareham T.","Machiavellian agents: Player modelling to deceive and be deceived",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962308268&doi=10.1109%2fCGames.2015.7272956&partnerID=40&md5=aa6795f9f602671fe41dbdfcceb86eb8","This paper explores several augmentations to the previously described Plantagenet model of computer game agents to give agents the deceptic capability to deceive the player and/or be deceived by the player. Augmented finite state machine controllers for agents in a simple role playing game are generated using an evolutionary algorithm. It is demonstrated that the proposed model is a practical option for generating populations of around 30 agents in which constraints on agent behaviour to ensure that actions are consistent with deception can be satisfied in substantial portions of the agent population. © 2015 IEEE.","Automata; Computational modeling; Computers; Evolutionary computation; Games; Sociology; Statistics","Animation; Computers; Evolutionary algorithms; Interactive computer graphics; Interactive computer systems; Logic circuits; Multimedia systems; Statistics; Automata; Computational model; Finite state; Games; Role-playing game; Sociology; Computer games",2-s2.0-84962308268
"Kosoris N., Chastine J.","A study of the correlations between Augmented Reality and its ability to influence user behavior",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962276951&doi=10.1109%2fCGames.2015.7272967&partnerID=40&md5=f29cbf903cb07ce7649f23096dc44cb7","Video game play is traditionally associated with sedentary activity, but it may be possible in the new mobile, ubiquitous game play paradigm to encourage users to engage in healthy exercise. Augmented Reality may be an ideal vehicle for this type of change, as it can add virtual game elements to a user's physical world. In this paper, we leveraged concepts drawn from mobile health monitoring as well as game design to discover whether a mobile platform with Augmented Reality game elements could have a greater effect on user health behavior than a platform with no ties to the physical world. We created a game (Imaginary Dragon) which allowed the user to care for a virtual pet by engaging in short breaks from sedentary activity. In a short term 30 person study, users indicated a strong preference for the game that contained AR elements. In a longer term study of 15 participants, it was found that the game with AR elements was used approximately ten times more than the game without AR elements. © 2015 IEEE.","game; Games with a purpose; motivation; presence and engagement; serious games","Animation; Augmented reality; Behavioral research; Human computer interaction; Interactive computer graphics; Interactive computer systems; Motivation; Multimedia systems; game; Games with a purpose; Health behaviors; Mobile health monitoring; Mobile platform; presence and engagement; Serious games; Ubiquitous games; Computer games",2-s2.0-84962276951
"Gittens C., Greaves J.","Transforming BrowserQuest into an epidemiological tool for modelling disease dissemination",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962311261&doi=10.1109%2fCGames.2015.7272972&partnerID=40&md5=1a89f7f9edec3ca43df39904320e00e1","How diseases spread and their virility in human populations is the fundamental purpose of epidemiology. Historically, human behavior has been intricately linked with the spread of infectious diseases. Models to study human behavior in the context of epidemics usually concentrate on judging the effectiveness of various institutionally enforced public health measures such as school closures, not how the individuals themselves respond to the outbreak. Using a simulated or virtual environment that incorporates human behavior holds promise as a useful modelling tool. The ""corrupted blood"" incident that occurred in the Massive Multiplayer Online Role-Playing Game (MMORPG) World of Warcraft led to the first large-scale, unplanned virtual epidemic in a game world. This event underscored the fact that MMORPGs can be used to study epidemiological events. Using BrowserQuest, we designed a disease management and dissemination system (DiMANDS) that monitors interactions and triggers infection events - using nonplayer characters (NPCs) as a human proxies - to spread a disease among a virtual population. The rate of infection in the NPC population was logged and a susceptible-infected-recovered (SIR) graph was generated. Our results showed that our SIR graph is similar to other simulation techniques, and further strengthens the possibility of using MMORPGs as an epidemiological simulation tool. © 2015 IEEE.","disease dissemination; MMORPGs; serious games; virtual worlds","Animation; Behavioral research; Diseases; Epidemiology; Interactive computer graphics; Interactive computer systems; Multimedia systems; Social networking (online); Social sciences; Virtual reality; Epidemiological simulations; Infectious disease; Massive multiplayer online role playing games; Mmorpgs; Non-player character; Serious games; Simulation technique; Virtual worlds; Computer games",2-s2.0-84962311261
"Gestwicki P., Stumbaugh K.","Observations and opportunities in cybersecurity education game design",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962305697&doi=10.1109%2fCGames.2015.7272970&partnerID=40&md5=6a844feac9a82c10183096029f9ecc8c","We identify three challenges in cybersecurity education that could be addressed through game-based learning: conveying cybersecurity fundamentals, assessment of understanding, and recruitment and retention of professionals. By combining established epistemologies for cybersecurity with documented best practices for educational game design, we are able to define four research questions about the state of cybersecurity education games. Our attention is focused on games for ages 12-18 rather than adult learners or professional development. We analyze 21 games through the lens of our four research questions, including games that are explicitly designed to teach cybersecurity concepts as well as commercial titles with cybersecurity themes; in the absence of empirical evidence of these games' efficacy, our analysis frames these games within educational game design theory. This analysis produces a three-tier taxonomy of games: those whose gameplay is not associated with cybersecurity education content (Type 1); those that integrate multiple-choice decisions only (Type 2); and those that integrate cybersecurity objectives into authentic gameplay activity (Type 3). This analysis reveals opportunities for new endeavors to incorporate multiple perspectives and to scaffold learners progression from the simple games to the more complex simulations. © 2015 IEEE.","cybersecurity education; educational games; game analysis; game design","Animation; Design; Education; Interactive computer graphics; Interactive computer systems; Multimedia systems; Scaffolds; Complex simulation; Cyber-security educations; Educational game; Game analysis; Game design; Game-based Learning; Professional development; Research questions; Computer games",2-s2.0-84962305697
"Yu Q., Crawfis R.","Gameplay-driven terrain generation in Scorched Earth",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962257106&doi=10.1109%2fCGames.2015.7272969&partnerID=40&md5=e6a35b9b0d86f28f56531067767c945a","In this paper, we propose a hybrid method to procedurally generate terrains in Scorch Earth. It features both the fast computing speed of random techniques and the wide variety of details of fractal techniques. We indirectly evaluate terrains by analyzing the gameplay data. We create an AI agent to model players' behaviors to produce gameplay data. The agent is capable to shoot and move in different scenarios. Finally we introduce metrics for gameplays to select good terrains. © 2015 IEEE.","Al agent; computer games; peiformance metrics; Procedural Content Generation; terrains","Animation; Interactive computer graphics; Interactive computer systems; Multimedia systems; Computing speed; Fractal techniques; Gameplay; Hybrid method; peiformance metrics; Procedural content generations; Terrain generations; terrains; Computer games",2-s2.0-84962257106
"Maung D., Crawfis R.","Applying formal picture languages to procedural content generation",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962310989&doi=10.1109%2fCGames.2015.7272963&partnerID=40&md5=83bd065c0f69b323b41cea439da74cb7","Procedural content generation for games often uses tile sets. Tilings generated with tile sets are equivalent to pictures generated from a fixed alphabet of characters such as those explored in the area of vision. Formal languages over pictures and their methods of definition such as 2D regular expressions, automata, and array grammars are directly applicable to generation of tilings using finite tile sets. Though grammars such as string grammars, L-systems, and graph grammars have been explored and found useful for the definition of certain content, formal methods have mostly been ignored. We introduce 2D regular expressions and array grammars as generators. We reason about the theoretical capability of these constructs and develop some practical use cases for their application in procedural content generation for games. One area lacking with a search based approach to procedural content generation is an enumeration of all possible tilings that can be generated. We show that 2D regular expressions can be used for enumeration. © 2015 IEEE.","Array Grammars; Game Design; Games; Picture Grammars; Procedural Content Generation; Regular Expressions","Animation; Computational linguistics; Computer programming languages; Formal languages; Formal methods; Interactive computer systems; Multimedia systems; Pattern matching; Array grammar; Game design; Games; Picture Grammars; Procedural content generations; Regular expressions; Computer games",2-s2.0-84962310989
"Bonomo D., Lauf A.P., Yampolskiy R.","A crossword puzzle generator using genetic algorithms with Wisdom of Artificial Crowds",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962240642&doi=10.1109%2fCGames.2015.7272960&partnerID=40&md5=3a63a3609154a11677da15948abdbf46","NP-hard problems, such as generating crossword puzzles, are candidates for solution by genetic algorithms (GAs). A combination of both a genetic algorithms and a Wisdom of Artificial Crowds (WoAC) aggregation method was developed for the purpose of creating crossword puzzles given a particular outline. The program was written using a GPL Hunspell wrapper NHunspell for word verification and suggestion. In American-style crossword puzzles, we saw performance improvements of around 20% in reaching a local optima, with a 6% improvement in the number of successful words found by a GA + WoAC algorithm over the baseline genetic algorithm. © 2015 IEEE.","Arrays; Computers; Dictionaries; Genetic algorithms; Skeleton; Sociology; Statistics","Animation; Computational complexity; Computer games; Computers; Genetic algorithms; Glossaries; Interactive computer systems; Multimedia systems; Statistics; Aggregation methods; Arrays; Genetic algorithm (GAs); Local optima; Skeleton; Sociology; Word verification; Algorithms",2-s2.0-84962240642
"Shi Y., Ferlet E., Crawfis R., Phillis P., Durano K.","3D Hospital: Design and implement quest-based game framework for transitional training",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962278174&doi=10.1109%2fCGames.2015.7272968&partnerID=40&md5=4db519a13e378437a5fe751b1fa659d2","The Ohio State University Comprehensive Cancer Center - Arthur G. James Cancer Hospital and Richard J. Solove Research Institute's (OSUCCC-James) is a transformational facility that fosters the collaboration and integration of cancer research and clinical cancer care. Unlike regular facilities, transferring between hospitals requires the staff to occupy accurate and specialized knowledge of the spatial layout for the new hospital. In order to have a smooth transition, the hospital staffs are required to orient themselves and navigate in the new facility in a timely manner. We designed a quest-based game framework to examine the scenario. This data driven framework allows the gaming content be easily updated online by demand. 3D Hospital game is developed based on that framework, which aims at training participants with spatial orientation in the OSUCCC-James. The quests are designed based on several key locations and the daily tasks for the hospital staff. We completed floor 15 in time before the transfer. To measure the effectiveness of our game for prepping the staff during the transition, we surveyed 26 participants and obtained an overall positive feedback. At last, we also examine the obstacles that we encountered as well as future direction. © 2015 IEEE.","Navigation; Serious Game","Animation; Diseases; Feedback; Hospitals; Interactive computer systems; Multimedia systems; Navigation; Cancer research; Design and implements; Ohio State University; Research institutes; Serious games; Smooth transitions; Spatial orientations; Specialized knowledge; Computer games",2-s2.0-84962278174
"Kim P.H., Crawfis R.","The quest for the perfect perfect-maze",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962333431&doi=10.1109%2fCGames.2015.7272964&partnerID=40&md5=0abe9f605534450731a31a78a6de5abb","In this paper, the quest for the perfect perfect-maze is performed over the search space of perfect mazes using an approach of search-based procedural content generation. Perfect maze construction is rather random with little to no control of the final product. We propose a search-based framework based on attributes or metrics of a constructed maze to provide a foundation for evaluation functions (fitness functions). Since the meaning of ""perfect"" is subjective and different for every designer, we allow designers to construct their own evaluation function to generate the best maze. We have also analyzed each metric's space on an exhaustive enumeration of small-sized mazes to determine allowable, and perhaps desirable, ranges for each metric. Using these metrics, an evaluation function is constructed to search for the ""best"" maze. © 2015 IEEE.","Game level design; Maze evaluation; Procedural content generation; Search-based procedural content generation","Animation; Function evaluation; Interactive computer systems; Multimedia systems; Evaluation function; Exhaustive enumeration; Fitness functions; Level design; Maze evaluation; Procedural content generations; Search spaces; Search-based; Computer games",2-s2.0-84962333431
"Redding J., Schreiver J., Shrum C., Lauf A., Yampolskiy R.","Solving NP-hard number matrix games with Wisdom of Artificial Crowds",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962225113&doi=10.1109%2fCGames.2015.7272959&partnerID=40&md5=b882b6118420c50a43b05fbf6056359b","Solving puzzles based on number-sum or ordered matrices is an NP-hard problem that requires considerable computational effort. Prime examples of these are the games Sudoku and Kakuro. Kakuro relies on number sequences that must sum to a number indicator shown on the puzzle. Sudoku requires that numbers be listed in an implicit sequence in blocks and rows. Both puzzles require exclusivity of the numbers listed in each row and logical grouping. As a result, solving these puzzles requires an iterative approach. We show that Genetic Algorithms (GA) can be augmented with postprocessing by a Wisdom of Artificial Crowds (WoAC) to constrain the solution space after a number of generations. Using the WoAC method, compared to using GA alone, we can reduce the time to a successful solution by a factor of 50% for easy and medium-difficulty puzzles. Our work has broader applications in the fields of multi-agent theory and collective decision making, as the WoAC method allows for crowd-based improvements to well-known genetic algorithm methods. © 2015 IEEE.","collective decisionmaking; genetic algorithm; puzzle solving; wisdom of artificial crowds","Animation; Computation theory; Computational complexity; Decision making; Decision theory; Genetic algorithms; Interactive computer systems; Iterative methods; Matrix algebra; Multi agent systems; Multimedia systems; Collective decision making; Computational effort; Iterative approach; Matrix game; Multi agent; puzzle solving; Solution space; wisdom of artificial crowds; Computer games",2-s2.0-84962225113
"Li Y., Elmaghraby A.S., Sokhadze E.M.","Designing immersive affective environments with biofeedback",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962269741&doi=10.1109%2fCGames.2015.7272965&partnerID=40&md5=bfb4cd0328f2b2ba7a2f720ccdccd229","Serious games have been recognized in many application areas such as heath, education and training. Designing interactive games responsive to user emotions improves their effectiveness and user acceptances. A major factor in user interaction is the emotional reaction to game scenarios, which has motivated us to analyze immersive games using biofeedback. In this article, a graph-based model is presented to design interactive games in a systematic way. This model is combined with biofeedback such as autonomic nervous system variables to evaluate user emotional reaction to different stimuli. The analysis should be used as a guiding principle for designing serious games. Oculus Rift DK2 is used in experiments to provide immersive virtual reality with affective scenarios. The experiments demonstrate the ability to induce measurable and differentiate emotions. © 2015 IEEE.","affective game; biofeedback; Oculus Rift; Serious games; virtual reality","Animation; Biofeedback; Graphic methods; Interactive computer systems; Multimedia systems; Virtual reality; affective game; Autonomic nervous system; Education and training; Emotional reactions; Graph-based modeling; Immersive virtual reality; Oculus Rift; Serious games; Computer games",2-s2.0-84962269741
"Ahmed A.M., Mehdi Q.H., Moreton R., Elmaghraby A.","Serious games providing opportunities to empower citizen engagement and participation in E-government services",2015,"Proceedings of CGAMES 2015 USA - 20th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962222317&doi=10.1109%2fCGames.2015.7272971&partnerID=40&md5=92f38bd6d28ddb1365fe2ac70ab92878","Serious games are electronic games designed not primarily for entertainment but for purposes such as education, training, health, military, politics, advertising and business. Communication between governments and citizens via electronic channels (i.e. e-government)to deliver services is difficult in developing countries due to limited IT knowledge, user experience and trust issues. Serious games can potentially improve citizen engagement in e-services by helping users expand their personal knowledge regarding services benefits, privacy and security. The main purpose of this paper is to investigate the extent to which an extended Technology Acceptance Model (TAM) and Trustworthiness Model (TM) facilitate the use of serious games in e-government services and empower citizen engagement and participation. In this research, the benefits of serious games are assayed in terms of perceived usefulness and perceived ease of use in TAM, as well as increased Internet and government trust in TM to form a conceptual model of factors that influence citizen adoption of e-government initiatives. The model provides a new way to assist governments in increasing citizens' engagement of their online services. © 2015 IEEE.","Citizen engagement; e-Government; Serious Games; TAM; Trustworthiness","Animation; Developing countries; Government data processing; Interactive computer systems; Multimedia systems; Network security; Citizen engagements; E-government services; E-governments; Extended technology acceptance models; Perceived ease of use; Privacy and security; Serious games; Trustworthiness; Computer games",2-s2.0-84962222317
"Rajasekaran S.D., Adamo-Villani N.","Senescence: An age-based character simulation framework",2015,"Proceedings of the International Conference on Information Visualisation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958545969&doi=10.1109%2fiV.2015.86&partnerID=40&md5=2a3bca701f45fcdd61e1c4837688312e","The paper presents the development and initial validation of the Senescence character framework, a simulation tool that can be used for rigging muscle deformer-based humanoid characters, with support for age. The senescence framework allows the user to rig any bipedal 3D character and manipulate skeleton and muscle parameters in order to render the age of the character realistically. The framework was developed using Python, Maya Embedded Language and PyQt. A study with 100 subjects was conducted to determine whether participants were able to perceive the age of the characters simulated with the Senescence framework. Findings show that while subjects were able to perceive age differences, they were not able to identify the age of the simulated characters with high level of accuracy. Results also show that subjects with animation expertise were able to identify the age of the characters more accurately than subjects without animation experience. © 2015 IEEE.","Character animation; Character rigging; Muscle deformer; Simulation framework","Computer graphics; Muscle; Visualization; 3D characters; Age differences; Age-based; Character animation; Character rigging; Maya embedded languages; Simulation framework; Animation",2-s2.0-84958545969
"Perrot A., Auber D.","FATuM - Fast animated transitions using multi-buffers",2015,"Proceedings of the International Conference on Information Visualisation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958545741&doi=10.1109%2fiV.2015.24&partnerID=40&md5=fbe89372c466246b9dd3d103c11cf3b2","The rise of Big Data and powerful mobile devices calls for libraries able to render a large number of visual elements and make fast animations without loss of frame rate. We introduce the FATuM library as a middleware for visualization. With a single abstraction for visual elements based on the work of Bertin and adaptation of the double buffering technique, we enable animated visualization of large datasets in native applications and in the browser using the same codebase. Our system does not differentiate animated from static rendering, thus reducing code complexity and guaranteeing smooth animation. We show that our system maintains 60fps for up to 200.000 visual elements in a native application and 30fps for 100.000 visual elements in a web browser. © 2015 IEEE.","Animation; Library; Transitions","Animation; Big data; Computer graphics; Electron transitions; Libraries; Middleware; Mobile devices; Visualization; Animated transitions; Code complexity; Double buffering; Frame rate; Large datasets; Multi Buffer; Visual elements; Rendering (computer graphics)",2-s2.0-84958545741
"Sharaf N., Abdennadher S., Fruhwirth T.","DiagrammaticCHR: A diagrammatic representation of CHR programs",2015,"Proceedings of the International Conference on Information Visualisation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958538047&doi=10.1109%2fiV.2015.31&partnerID=40&md5=68c243b106f987dcce81e701c91964f8","Recently, a new approach for embedding visualization features into Constraint Handling Rules (CHR) programs has been proposed. It allows CHR programmers to animate and visualize different algorithms implemented in CHR. Such features have become essential with CHR being a general purpose language. In this paper, a new diagrammatic representation for CHR programs is presented. The representation is also able to account for the newly embedded visual features. © 2015 IEEE.","Constraint handling rules; Program animation; Visual language","Computational linguistics; Computer graphics; Visualization; Constraint Handling Rules; Diagrammatic representations; General purpose languages; New approaches; Program animation; Visual feature; Visual languages",2-s2.0-84958538047
"Figueiras A.","Towards the understanding of interaction in information visualization",2015,"Proceedings of the International Conference on Information Visualisation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958539222&doi=10.1109%2fiV.2015.34&partnerID=40&md5=57e67aded6770fd749610cc149cddef2","Over the past few years the web has been responsible for the rise in popularity of visualizations and it seems that interactive or playable visualizations have become more popular and end up standing out more. The use of interactivity and animation has been extensively discussed in information visualization research, but there has been some controversy in relation to its benefits. Additionally, there is still little empirical evidence about its efficacy in terms of improving understanding of the data and there is few research that points out guidelines of how to incorporate it successfully and that proves that playable visualizations are indeed more enjoyable and popular among users. In order to guide future research on the actual benefits of interactivity in visualization it is important to understand what types of interactivity are currently being used in the field and to have a framework to help discuss and evaluate interaction techniques. After conducting an extensive review of popular visualizations and their interactive capabilities, we propose eleven categories of interaction techniques: filtering, selecting, abstract/elaborate, overview and explore, connect/relate, history, extraction of features, reconfigure, encode, participation/collaboration, and gamification. © 2015 IEEE.","Interaction; Taxonomy; Visualization","Computer graphics; Flow visualization; Information analysis; Information science; Information systems; Taxonomies; Gamification; Information visualization; Interaction; Interaction techniques; Interactivity; Visualization",2-s2.0-84958539222
"Ceruti A., Liverani A., Marzocca P.","A 3D User and Maintenance Manual for UAVs and Commercial Aircrafts Based on Augmented Reality",2015,"SAE Technical Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959431739&doi=10.4271%2f2015-01-2473&partnerID=40&md5=fd6deedebe4a0151d2b0aeda63d6a5d4","Traditional User/Maintenance Manuals provide useful information when dealing with simple machines. However, when dealing with complex systems of systems and highly miniaturized technologies, like UAVs, or with machines with millions of parts, a commercial aircraft is a case in point, new technologies taking advantage of Augmented Reality can rapidly and effectively support the maintenance operations. This paper presents a User/Maintenance Manual based on Augmented Reality to help the operator in the detection of parts and in the sequence to be followed to assemble/disassemble systems and subsystems. The proposed system includes a handheld device and/or an head mounted display or special goggles, to be used by on-site operators, with software management providing data fusion and overlaying traditional 2D user/maintenance manual information with an augmented reality software and appropriate interface. This device is connected by internet to a maintenance centre located in the aircraft manufacturer facilities. The on-site operator can directly access to multimedia content and historical information and can be helped or guided remotely by expert engineers residing at the manufacturer company offices. This resource may exploit Computer Aided Design and Product Data Management PDM remote facilities to prepare additional and specific 3D graphic content, supported also by a video and audio streaming from the camera and microphone of the on-site operator's handheld device. The proposed solution has revealed a number of significant advantages compared to the currently used operations: there is no need for preparing animations and graphic content for all the required maintenance sequences. The expert engineers and designers can both be involved directly in the maintenance tasks, a useful mean of feedback to evaluate the design for further projects or for project improvement. Additionally, the sensitive data is not shared outside the company since data is transmitted for visual display but it is stored on a secured location. Copyright © 2015 SAE International.",,"Audio streaming; Augmented reality; Computer aided design; Computer resource management; Data fusion; Display devices; Fighter aircraft; Hand held computers; Helmet mounted displays; Machinery; Maintenance; Manufacture; Product design; Aircraft manufacturers; Commercial aircraft; Head mounted displays; Historical information; Maintenance operations; Multimedia contents; Product Data Management; Software management; Information management",2-s2.0-84959431739
"Aeluri P.K., Bojan V., Richie S., Weeks A.","MPEG-1, MPEG-2 and windows media video codec comparisons using MSE analysis",2015,"38th SMPTE Advanced Motion Imaging Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978488306&doi=10.5594%2fM001015&partnerID=40&md5=1627a553eaafffffbf296b14bac47619","Digital video faces the intrinsic problem of huge files sizes, which puts a strain on the available bandwidth in a communication system. Correspondingly, the video files need to be compressed in some manner before transmission. The inherent properties of lossy encoding algorithms can cause artifacts in the decompressed video sequences. In this paper, the effects of encoding and decoding using three different video formats (MPEG1, MPEG2 and Windows Media Video) has been analyzed at different frame rates (15fps and 30fps), frame sizes (320×240 and 640×480) and bit rates (48k, 100k and 300k). These parameters were selected by observing that they are the most commonly used for viewing video transferred over the Internet. In order to analyze the performance of codecs over a broad range of video content, sequences of 30 seconds in length were selected from various sources including movie clippings, television footage and generic video material, depending upon the range of motion of the objects in the video. The four video sequences chosen are from sources that are described as follows: animation, still frames, 'talking head', and a slide presentation. The measurement metric used by this paper, MSE (Mean Square Error), gives the cumulative mean square error of each frame's color components, averaged for the entire video sequence. The determination of how much each codec alters the frame is the goal of this paper, which will aid in the selection of the appropriate codec for a particular application. © 2004 Society of Motion Picture and Television Engineers, Inc.",,"Bandwidth; Encoding (symbols); Mean square error; Motion Picture Experts Group standards; Multimedia systems; Video recording; Video signal processing; Available bandwidth; Color component; Digital videos; Encoding and decoding; Range of motions; Slide presentations; Video contents; Video sequences; Computer graphics",2-s2.0-84978488306
"Legault A., Lapierre J., Dionne L., Cherna T.","Professional Video under 32-Bit Windows™ Operating Systems",2015,"Proceedings 137th SMPTE Technical Conference and World Media Expo",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978419140&doi=10.5594%2fM00480&partnerID=40&md5=9765f78a5fe8c95069f7951978861b39","The PC and 32-bit Windows operating systems are quickly becoming the platform of choice for professional video, film and multimedia producers. What 486 machines and Windows 3.0 did to expand the desktop publishing market; Pentium processors, the PCI bus and Windows 95 and NT are doing for the video market. With at least 10 times the installed base of any other platform, Windows users have long benefited from the time and money savings offered by ""open platform"" interoperability. Professional media producers need the same opportunity to be able to buy the best interoperable hardware and software, from a variety of vendors, at a variety of price/performance points to meet their individual requirements. Vendors are committed to delivering video and audio editing, multimedia authoring, plug-in effects, and animation and graphics creation applications that all work together on PCs with varying performance capabilities. Users can choose all the best tools for their jobs at competitive prices. Leading the drive to make this interoperability possible is the recently formed Open Digital Media (OpenDML) consortium. In close collaboration with Microsoft, this group of hardware and software vendors has recently banded together to make the ""open platform"" dream a reality for video, audio, film and multimedia producers. Initiated by Matrox Video Products Group, the leading PC video board and system manufacturer, and D-Vision Systems, Ltd., the leading provider of PC-based non-linear editing systems, the group also involves, as members or interested observers, a quickly growing list of more than 80 vendors of professional Windows-based video/audio products. The OpenDML Group is dedicated to developing a set of standards and enhancements, using Microsoft's Video for Windows (VFW) as a foundation, that will enable manufacturers to offer broadcast-quality production tools on 32-bit Windows-based (Windows NT and Windows 95) personal computers. This paper describes a professional video software application architecture and proposes a set of enhancements to the VFW environment that are necessary for professional video, audio and film applications. © 1995 Society of Motion Picture and Television Engineers, Inc.",,"Application programs; Commerce; Computer hardware; Computer vision; Desktop publishing; Digital storage; Hardware; Interoperability; Manufacture; Microcomputers; Personal computers; Professional aspects; Reconfigurable hardware; System buses; Broadcast quality; Competitive prices; Hardware and software; Multi-Media authoring; Non-linear editing systems; Open platforms; Pentium processors; Performance capability; Windows operating system",2-s2.0-84978419140
"Charnley H.","New technology prompts expansion of the use of digital fiber optics: Networking for collaborative production efforts",2015,"139th SMPTE Technical Conference and Exhibit",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021981709&doi=10.5594%2fM00253&partnerID=40&md5=de84149118ca59d3ccec26a6b78d8868","The world of video is undergoing dramatic change. The advent of complex animation and computer graphic effects in film and television production has sparked a demand among consumers for even more sophisticated programs. Simultaneously, advances in broadcast technology will be making it possible for viewers to receive high-quality HDTV broadcasts and to have access to more channels, and thus more programs than ever before. - To meet viewer demand for increased volume and more complex programming, studios and the production facilities that serve them must begin to work together in new and innovative ways. To meet the challenge of HDTV implementation and the 500-channel future, they must revamp their infrastructures to embrace digital technology. In both instances, they need to partner with manufacturers that understand both teleproduction and telecommunications technology. It is the merger of these two markets that will enable an effective migration to a digital production and broadcast world and make possible a collaborative network of facilities for the creation of advanced programming. - This paper investigates the trends that are impacting the teleproduction world today and makes a practical case for using digital fiber optics in conjunction with currently available technologies to create advanced switched digital networks, based on a common design platform, that will connect studios and production facilities for the purpose of collaborative production. © 1997 Society of Motion Picture and Television Engineers, Inc.",,"Complex networks; High definition television; Studios; Television broadcasting; Broadcast technology; Collaborative network; Collaborative production; Digital production; Digital technologies; Production facility; Sophisticated projects; Telecommunications technologies; Digital television",2-s2.0-85021981709
"Aliaga C., O'Sullivan C., Gutierrez D., Tamstorf R.","Sackcloth or silk? the impact of appearance vs dynamics on the perception of animated cloth",2015,"Proceedings - SAP 2015: ACM SIGGRAPH Symposium on Applied Perception",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955558087&doi=10.1145%2f2804408.2804412&partnerID=40&md5=f07791264f7ff2a1ee8051f157f0dc0a","Physical simulation and rendering of cloth is widely used in 3D graphics applications to create realistic and compelling scenes. However, cloth animation can be slow to compute and difficult to specify. In this paper, we present a set of experiments in which we explore some factors that contribute to the perception of cloth, to determine how efficiency could be improved without sacrificing realism. Using real video footage of several fabrics covering a wide range of visual appearances and dynamic behaviors, and their simulated counterparts, we explore the interplay of visual appearance and dynamics in cloth animation. © 2015 ACM. Copyright is held by the owner/author(s).","Appearance modelling; Cloth rendering; Cloth simulation; Perception","Animation; Computer graphics; Interactive computer graphics; Rendering (computer graphics); Sensory perception; Visualization; 3D graphics; Cloth animation; Cloth simulation; Dynamic behaviors; Physical simulation; Video footage; Visual appearance; Three dimensional computer graphics",2-s2.0-84955558087
"Ruhland K., Zibrek K., McDonnell R.","Perception of personality through eye gaze of realistic and cartoon models",2015,"Proceedings - SAP 2015: ACM SIGGRAPH Symposium on Applied Perception",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955613153&doi=10.1145%2f2804408.2804424&partnerID=40&md5=8732c971c8be67d7e2d6aa04d1324a0e","In this paper, we conducted a perceptual experiment to determine if specific personality traits can be portrayed through eye and head movement in the absence of other facial animation cues. We created a collection of eye and head motions captured from three female actors portraying different personalities, while listening to instructional videos. In a between-groups experiment, we tested the perception of personality on a realistic model and a cartoon stylisation in order to determine if stylisation can positively influence the perceived personality or if personality is more easily identified on a realistic face. Our results verify that participants were able to differentiate between personality traits portrayed only through eye gaze, blinks and head movement. The results also show that perception of personality was robust across character realism. © 2015 ACM. Copyright is held by the owner/author(s).","Facial animation; Motion capture; Perception; Personality; Uncanny valley","Animation; Interactive computer graphics; Sensory perception; Facial animation; Head movements; Instructional videos; Motion capture; Personality; Personality traits; Realistic model; Uncanny valley; Eye movements",2-s2.0-84955613153
"Black P.","Computer Graphics Animation Methods",2015,"Video Pictures of the Future: 17th Annual SMPTE Television Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978775195&doi=10.5594%2fM00594&partnerID=40&md5=b520ee0c23996f1a50d946f7ac963b7f","The rapid proliferation of computer graphics systems, designed to aid the short-turnaround production of both static and animated short-burst graphics for video has taken place with a simultaneous burst of impossibly high expectations, confusion and general bewilderment at what these systems really do. © 1983 Society of Motion Picture and Television Engineers, Inc.",,"Computer graphics systems; Short bursts; Computer graphics",2-s2.0-84978775195
"Wu L.-P.","Research on the Group Animation Creation Method Based on the Multi-agent Strategy",2015,"Proceedings - 2015 7th International Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960158444&doi=10.1109%2fICMTMA.2015.226&partnerID=40&md5=b6851c44598e6de1f8f65ad383b56917","In recent years, the group animation has been a hot topic in computer vision. This paper proposes a novel group animation creation method based on the multi-agent strategy (MAS). In particular, multi-agent system represents a general method which utilizing multiple agents, in MAS, each agent is in a unique view, perspective and behavior, and six components are contained in MAS: 1) space, 2) objects, 3) agent, 4) relationships between the different objects, 5) operations and 6) operators. The main innovations of this paper lie in that we introduce the genetic algorithm to multi-agent system, and convert the group animation creation problem to an optimization problem. Finally, to demonstrate the effectiveness of the proposed method, we implement the biomimetic fish group animation production. © 2015 IEEE.","Animation Creation; Genetic algorithm; Motion; Multi-agent Strategy","Animation; Biomimetic processes; Biomimetics; Computer vision; Genetic algorithms; Optimization; Software agents; General method; Hot topics; Motion; Multi-agent strategy; Multiple agents; Optimization problems; Multi agent systems",2-s2.0-84960158444
[No author name available],"Video Pictures of the Future: 17th Annual SMPTE Television Conference",2015,"Video Pictures of the Future: 17th Annual SMPTE Television Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978709108&partnerID=40&md5=5d843c5a2be93c14edc9396dac0c2c23","The proceedings contain 28 papers. The topics discussed include: compatible systems for high quality television; computer graphics animation methods; menu-driven user interfaces for videographics; switching and distribution of high resolution RGB video signals; a high definition still frame television system; arithmetic control algorithms for digital video effects; extended definition television with high picture quality; the technical director's interface to digital video effects; tools for interactive picture processing systems; the HDTV camera - fighting the resolution/noise battle; 8-9 block code: a DC-free channel code for digital magnetic recording; analogue components, multiplexed components and digital components - friends or foes?; digital video recording: new results in channel coding and error protection; an introduction to analog component recording; broadcast quality video/audio recording system with VHS cassette and head scanning system; an intelligent time code peripheral for computer based video tape editing systems; and how not to be frightened by microprocessors.",,,2-s2.0-84978709108
"Eslitzbichler M.","Modelling character motions on infinite-dimensional manifolds",2015,"Visual Computer",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938746479&doi=10.1007%2fs00371-014-1001-y&partnerID=40&md5=2a457a46bc6650444b8960eecb8d8b62","In this article, we will formulate a mathematical framework that allows us to treat character animations as points on infinite-dimensional Hilbert manifolds. Constructing geodesic paths between animations on those manifolds allows us to derive a distance function to measure similarities of different motions. This approach is derived from the field of geometric shape analysis, where such formalisms have been used to facilitate object recognition tasks. Analogously to the idea of shape spaces, we construct motion spaces consisting of equivalence classes of animations under reparametrizations. Especially cyclic motions can be represented elegantly in this framework. We demonstrate the suitability of this approach in multiple applications in the field of computer animation. First, we show how visual artefacts in cyclic animations can be removed by applying a computationally efficient manifold projection method. We next highlight how geodesic paths can be used to calculate interpolations between various animations in a computationally stable way. Finally, we show how the same mathematical framework can be used to perform cluster analysis on large motion capture databases, which can be used for or as part of motion retrieval problems. © 2014, Springer-Verlag Berlin Heidelberg.","Character animation; Elastic metric; Motion capture; Motion retrieval; Parametric motion; Riemannian shape analysis","Cluster analysis; Equivalence classes; Geodesy; Object recognition; Character animation; Elastic metric; Motion capture; Motion retrieval; Parametric motion; Shape analysis; Animation",2-s2.0-84938746479
"Iglesias A., Galvez A.","Memetic Firefly Algorithm for Data Fitting with Rational Curves",2015,"2015 IEEE Congress on Evolutionary Computation, CEC 2015 - Proceedings",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960337997&doi=10.1109%2fCEC.2015.7256932&partnerID=40&md5=261cc55d96ee1b82cb4cf86ae5608137","This paper concerns the problem of obtaining a smooth fitting curve to a given set of (noisy) data points. This problem arises frequently in several industrial fields, such as computer-aided design and manufacturing (construction of car bodies, ship hulls, airplane fuselage), computer graphics and animation, medicine, and many others. The classical approach relies on polynomial functions to solve this problem. It has been noticed, however, that some shapes cannot be properly approximated through this polynomial scheme. In this paper, we address this issue by using rational functions, particularly the rational Bernstein basis functions. This poses an additional challenge: we have not only to compute the poles of the resulting rational Bézier fitting curve but also to obtain their corresponding weights and a suitable parameterization of data points. Overall, this leads to a continuous multivariate nonlinear optimization problem that cannot be solved through traditional mathematical optimization techniques. Our approach to tackle this issue is based on a memetic firefly algorithm combining a powerful metaheuristic technique (the firefly algorithm) for global optimization with a local search method. The performance of our scheme is illustrated through its application to four illustrative examples of free-form synthetic shapes. Our experimental results show that our memetic approach performs very well, and allows us to reconstruct the underlying shape of data points automatically with high accuracy. A comparative analysis on our benchmark shows that our approach outperforms some alternative methods reported in the literature for this problem. © 2015 IEEE.",,"Algorithms; Bioluminescence; Computer aided design; Computer graphics; Curve fitting; Evolutionary algorithms; Functions; Global optimization; Hulls (ship); Nonlinear programming; Problem solving; Rational functions; Comparative analysis; Computer graphics and animations; Corresponding weights; Local search method; Mathematical optimization techniques; Meta-heuristic techniques; Non-linear optimization problems; Polynomial functions; Optimization",2-s2.0-84960337997
"Geng L.","Teaching exploration and reform of program design course for digital media art students",2015,"10th International Conference on Computer Science and Education, ICCSE 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957894834&doi=10.1109%2fICCSE.2015.7250363&partnerID=40&md5=c52537d9f37e95a5f9f7dd30df36214b","As a novel cross-subject, digital media art is the combination of technology and art. The program design course is an important part of computer teaching course system. Considering the characteristics of the major and knowledge of the students, The Basic Course of Animation Programming is chosen as an introductory programming course. This paper proposes the reform of practicing on the content of course and teaching method and it also explores the measures combining teaching and ability training so as to raise the students' interest in learning and improve their programming knowledge and methods of quick understanding and application. © 2015 IEEE.","digital media art major; program design course; teaching method; The Basic Course of Animation Programming","Animation; Curricula; Digital storage; Education; Education computing; Engineering education; Students; Basic course; Computer teaching; Introductory programming course; Program design; Programming knowledge; Students' interests; Teaching methods; Teaching",2-s2.0-84957894834
"Kothiya S.V., Mistree K.B.","A review on real time object tracking in video sequences",2015,"International Conference on Electrical, Electronics, Signals, Communication and Optimization, EESCO 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957998549&doi=10.1109%2fEESCO.2015.7253705&partnerID=40&md5=925f015f061a69af8b422ecdbfe2bf6c","Object tracking is the process of locating moving objects over time using the camera in video sequences. The objective of object tracking is to associate target objects in consecutive video frames. Object tracking requires location and shape or features of objects in the video frames. So, object detection and object classification is the preceding steps of object tracking in computer vision application. To detect or locate the moving object in frame, Object detection is first stage in tracking. After that, detected object can be classified as vehicles, human, swaying tree, birds and other moving objects. It is challenging or difficult task in the image processing to track the objects into consecutive frames. Various challenges can arise due to complex object motion, irregular shape of object, occlusion of object to object and object to scene and real time processing requirements. Object tracking has a variety of uses, some of which are: surveillance and security, traffic monitoring, video communication, robot vision and animation. This paper presents the various techniques of object tracking in video sequences through different phases using image processing. © 2015 IEEE.","object classification; object detection; object tracking; video surveillance","Computer vision; Image processing; Motion analysis; Object recognition; Security systems; Signal detection; Target tracking; Tracking (position); Video recording; Video signal processing; Computer vision applications; Object classification; Object Tracking; Real-time object tracking; Realtime processing; Traffic monitoring; Video communications; Video surveillance; Object detection",2-s2.0-84957998549
"Li L., Zhang S., Wu Y.","Teaching reform and practice on software project management curriculum",2015,"10th International Conference on Computer Science and Education, ICCSE 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957881101&doi=10.1109%2fICCSE.2015.7250371&partnerID=40&md5=3fa9bfbaec570947d4e3e5b9f7b81065","Software project management is a curriculum which stress not only on many theories but also lots of practice. This paper presents some reform ideas for this curriculum. Diversification teaching methods are used in theory teaching, like compiling rhymes to summarize the theories and methods, play some animations, cases study, a series of templates, a set of tools, and so on. In practice training, we use project driven, project practice, team cooperation and team simulation to enhance students' learning enthusiasm, change their passive learning into active learning. Results show all these reforms achieve good effect and improve the teaching quality. © 2015 IEEE.","cases study; practice training; rhymes; software project management; teaching reform","Artificial intelligence; Computer software; Curricula; Education computing; Engineering education; Passive learning; rhymes; Software project management; Teaching methods; Teaching quality; Teaching reforms; Team cooperation; Theory teachings; Project management",2-s2.0-84957881101
"Fitzgerald N., Li L.","Using Presentation Software to Flip an Undergraduate Analytical Chemistry Course",2015,"Journal of Chemical Education",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938654954&doi=10.1021%2fed500667c&partnerID=40&md5=5f2c6bb63b491f275a504862936f54fe","An undergraduate analytical chemistry course has been adapted to a flipped course format. Course content was provided by video clips, text, graphics, audio, and simple animations organized as concept maps using the cloud-based presentation platform, Prezi. The advantages of using Prezi to present course content in a flipped course format are discussed. Results of an American Chemical Society analytical chemistry examination were encouraging. Results of pre- and postsurveys of student perception of their learning are summarized. © 2015 The American Chemical Society and Division of Chemical Education, Inc.","Analytical Chemistry; Collaborative/Cooperative Learning; Computer-Based Learning; Problem Solving/Decision Making; Upper-Division Undergraduate",,2-s2.0-84938654954
"Arellano D., Helzle V., Schaller U.M., Rauh R., Spicker M., Deussen O.","The SARA project: An interactive sandbox for research on autism",2015,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960094327&doi=10.1145%2f2829875.2829884&partnerID=40&md5=2f66311fce27f9bcc695f4c3117d0c31","SARA is an ongoing research project that investigates in a novel and artistic way the causes for social communication and emotion recognition deficits in children and adolescents with high-functioning autism spectrum disorders (ASD). The novelty of our work resides in the real-time generation and parameterization of emotional facial expressions of virtual characters by means of speed, intensity and abstraction, the latter achieved by non-photorealistic rendering (NPR) techniques. Although the project is currently in an ongoing phase, it shows the potential of using virtual characters and real-time techniques for interactive experiments, which otherwise would be impossible using ""linear stimuli"" (e.g. pre-rendered animations). © 2015 ACM.","Autism Spectrum Disorder; Facial Expressions; Interaction; Non-Photorealistic Rendering; Real-time Animation","Computer graphics; Diseases; Autism spectrum disorders; Facial Expressions; Interaction; Non-Photorealistic Rendering; Real-time animations; Human computer interaction",2-s2.0-84960094327
"Tsai T.-C., Chen C.-Y., Su G.-J.","U-art: Your art and ubiquitous art",2015,"UbiComp and ISWC 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the Proceedings of the 2015 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962531399&doi=10.1145%2f2800835.2807927&partnerID=40&md5=0f1ec6b350d1b3da102f41114d52c1ec","With wearable computing a new art form is evolving not only for artistic performances but now you can also interact with live digital performance content. Integrated with AR/VR (Augmented Reality/Virtual Reality) technologies, the future art performance will link with virtual characters. In this way the future artistic work may no longer be presented only on a stage, theater, or concert hall. In this paper we will present our idea on how to combine wearable sensors with art performances. Some technical problems need to be addressed. We surveyed the wearable hardware in the market and implemented the WISE (Wearable Item Service runtimE) platform. While wearing the sensors, skeleton (posture) information is delivered in real-time to WISE to render animations displayed on the screen or wearable glasses. This performance can be performed anywhere because it can be quickly deployed and supports improvisation. Even though there are hardware limitation due to non-customized hardware, we can still execute a live field performance to validate the idea and obtain feedback. We believe this will be a new art venue.","Motion capture; Wearable computing","Arts computing; Augmented reality; Computer hardware; Hardware; Reconfigurable hardware; Ubiquitous computing; Wearable computers; Wearable sensors; Artistic works; Concert hall; Field performance; Motion capture; Real time; Runtimes; Virtual character; Wearable computing; Wearable technology",2-s2.0-84962531399
"Gu H., Sanchez S., Kunze K., Inami M.","An augmented e-reader for multimodal literacy",2015,"UbiComp and ISWC 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the Proceedings of the 2015 ACM International Symposium on Wearable Computers",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962551162&doi=10.1145%2f2800835.2800897&partnerID=40&md5=d1b8c925ce103cbf92c5993938176419","We present an initial prototype to extend a reading tablet for haptic feedback -with a surface vibration transducer. This, in order to transform literature into a multimodal reading experience. In this augmented literature, the text provides its reader with verbal information, while other senses perceive context through non-verbal cues. We use our own framework to design this storytelling across senses integrating text, sound, animation and tactile sensation. The intention is to develop a multimodal storytelling that enhances the readers imagination, improving the reading experience. In this way, we believe, readers will completely immerse into the narrative and enjoy reading more.","Dual-coding; Multimodal; Reading; Valid co-occurrences","Wearable computers; Wearable technology; Co-occurrence; Dual coding; Haptic feedbacks; Multi-modal; Reading; Surface vibration; Tactile sensation; Verbal information; Ubiquitous computing",2-s2.0-84962551162
"Lösch E., Nutsi A., Koch M.","Mediating movement-based interaction through semiotically enhanced shadow representations",2015,"UbiComp and ISWC 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the Proceedings of the 2015 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962612923&doi=10.1145%2f2800835.2807956&partnerID=40&md5=d86ac59b574851bdfa8eb24a49b6ed3b","Whole-body interaction can help to motivate by-passers to interact with public displays as it enables reaction to passive users and immediate touch-less applicability. We introduce our approach of mediating movementbased interaction techniques to the user allowing spontaneous interaction within walk-up-and-use scenarios. Our concept of semiotically enhanced shadow representations combines abstract user representations with meaningful symbols, visual accentuations and animations to emphasize body parts and explain movements that are relevant for the interaction with the system. The MeetingMirror is used as an example application for implementing this approach. Copyright 2015 © ACM.","Interactive wall displays; Mediation of interaction; Walkup-and-use; Whole-body interaction","Wearable computers; Wearable technology; Mediation of interaction; Movement-based interactions; Public display; Shadow representation; Spontaneous interaction; Walk up and use; Wall displays; Whole-body interactions; Ubiquitous computing",2-s2.0-84962612923
"Sanchez S., Gu H., Kunze K., Inami M.","Multimodal literacy: Storytelling across senses",2015,"UbiComp and ISWC 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the Proceedings of the 2015 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962538791&doi=10.1145%2f2800835.2807940&partnerID=40&md5=37612d0c3921e0de9687a1f7f8a6f07a","This paper describes a novel framework for literature that presents the reader with a multimodal experience (visual, haptic and auditory). We present an initial prototype, ex- tending an iPad with a surface vibration transducer for hap- tic feedback to augment the reading of a short story. Text provides the reader with verbal information, whereas other senses perceive the context through non-verbal cues. We use our own framework to create this storytelling across senses, integrating text, sound, animation and tactile sen- sation. We believe with a multi-modal reading experience, users will enjoy reading more, will feel more immersed and remember the narrative better.","Dual-coding; Multimodal; Reading; Valid co-occurrences","Wearable computers; Wearable technology; Co-occurrence; Dual coding; Multi-modal; Reading; Surface vibration; Verbal information; Ubiquitous computing",2-s2.0-84962538791
"Somdulyawat C., Pongjitpak P., Phithakkitnukoon S., Veloso M., Bento C.","A tool for exploratory visualization of bus mobility and ridership: A case study of Lisbon, Portugal",2015,"UbiComp and ISWC 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the Proceedings of the 2015 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962585693&doi=10.1145%2f2800835.2800975&partnerID=40&md5=8730a1dfe23b261cd1e2491ff631fd83","This paper presents a visualization tool for bus mobility and ridership. Data of bus usage from Lisbon, Portugal is used as a case study. The tool runs on two modes; mobility and ridership. The mobility mode displays an animation of bus movement in the city with varying number of riders of each bus stop throughout the day. In the ridership mode, the user can observe the varying number of riders (bus usage) in different areas of the city. The tool also allows the user to interact with the tool by not only selecting different modes of display (mobility and bus ridership), but also changing 2D-3D views, visualizing specific bus lines and stations, and viewing weather conditions. The visualization gives an overview of the dynamic urban flow. This also helps describe bus usage behavior, and it can be useful for urban planning and transport engineering to manage the flow in the city. Copyright 2015 © ACM.","Bus usage; Data visualization; Urban mobility","Bus terminals; Data visualization; Ubiquitous computing; Urban transportation; Visualization; Wearable computers; Wearable technology; Bus lines; Bus stop; Exploratory visualizations; Portugal; Transport engineering; Urban flow; Urban mobility; Visualization tools; Buses",2-s2.0-84962585693
"Prapaitrakul N., Phithakkitnukoon S.","EQviz: A visualization tool for monitoring world earthquakes",2015,"UbiComp and ISWC 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the Proceedings of the 2015 ACM International Symposium on Wearable Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962489920&doi=10.1145%2f2800835.2800985&partnerID=40&md5=8bad6df9b844b4e638ee8cff337be9a0","This paper presents EQviz, a visualization tool for monitoring earthquakes with the magnitude of 6.0 or larger that take place around the world from 2000 to 2015. EQviz provides four modes of display: instant, aggregate, analysis, and selected area modes. Instant mode displays an animation of a series of earthquake instances taking place in different geographical locations globally over time. Aggregate mode displays the aggregate level of instances of the earthquakes over time. Analysis mode provides a yearly graphical information along with some basic statistics for the user's further analysis. Selected area mode extends the analysis mode by allowing the user to look through the world map and examine different geographical areas as the EQviz provides basic statistics such as the average and standard deviation values of the earthquake magnitudes along with the graphical information of the selected area. Copyright 2015 © ACM.","Data visualization; Earthquake; Interative visualization","Aggregates; Data visualization; Geophysics; Maps; Ubiquitous computing; Visualization; Wearable computers; Wearable technology; Aggregate modes; Earthquake magnitudes; Geographical area; Geographical locations; Graphical information; Interative; Standard deviation; Visualization tools; Earthquakes",2-s2.0-84962489920
"Trujillo K.M., Wiburg K., Savic M., McKee K.","Teachers learn how to effectively integrate mobile technology by teaching students using math snacks animations and games",2015,"Professional Development and Workplace Learning: Concepts, Methodologies, Tools, and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960299790&doi=10.4018%2f978-1-4666-8632-8.ch032&partnerID=40&md5=cfbc4caa4f5a0e4cf99ae91735a587c2","The time for teachers to use mobile devices is now. However, in order to ensure that yet another technological transition in the classroom is as effective as possible, there is an undeniable need for effective professional development. The models the authors propose in this chapter offer teachers experiences that require curriculum design and delivery, experience with mobile hardware and software, and opportunities to consider the pedagogical implications of integration for effective teaching and learning. The Math Snacks Summer Camp Model and the Math Snacks 3-Day Gradual Release Model offer experiences where teachers and students work together to learn challenging mathematics concepts using mobile devices, laptop computers, and hands-on activities. A description of these models, including benefits and limitations is discussed. An adaptation of each model for pre-service teachers and higher education faculty is also included. © 2016 by IGI Global. All rights reserved.",,,2-s2.0-84960299790
"Murakami R., Muranaka N.","Grading Evaluation Method in Character Drawing Study Support System",2015,"Proceedings of The International Symposium on Multiple-Valued Logic",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957949570&doi=10.1109%2fISMVL.2015.35&partnerID=40&md5=bd108f528ea96bc868387731c761f9df","we proposed already a construction of grading evaluation method (GEM) in character drawing study support system of the self-education type for beginners. However, our proposed system had an uncertainty about the grading item, and had the problems which can not be correctly evaluated about the foundation drawing ability and the progress degrees. In this research, we propose the GEM which applied multiple-valued logic. This GEM is highly reliable and it is near the human sense. © 2015 IEEE.","Animation; character; comics; drawing; illustration","Animation; Computer circuits; Drawing (graphics); Grading; Reconfigurable hardware; character; comics; Human sense; illustration; Multiple valued logic; Self-education; Support systems; Many valued logics",2-s2.0-84957949570
"Ruhland K., Peters C.E., Andrist S., Badler J.B., Badler N.I., Gleicher M., Mutlu B., McDonnell R.","A Review of Eye Gaze in Virtual Agents, Social Robotics and HCI: Behaviour Generation, User Interaction and Perception",2015,"Computer Graphics Forum",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942371792&doi=10.1111%2fcgf.12603&partnerID=40&md5=5b135c3c88e1df8ad444462c9ee38213","A person's emotions and state of mind are apparent in their face and eyes. As a Latin proverb states: 'The face is the portrait of the mind; the eyes, its informers'. This presents a significant challenge for Computer Graphics researchers who generate artificial entities that aim to replicate the movement and appearance of the human eye, which is so important in human-human interactions. This review article provides an overview of the efforts made on tackling this demanding task. As with many topics in computer graphics, a cross-disciplinary approach is required to fully understand the workings of the eye in the transmission of information to the user. We begin with a discussion of the movement of the eyeballs, eyelids and the head from a physiological perspective and how these movements can be modelled, rendered and animated in computer graphics applications. Furthermore, we present recent research from psychology and sociology that seeks to understand higher level behaviours, such as attention and eye gaze, during the expression of emotion or during conversation. We discuss how these findings are synthesized in computer graphics and can be utilized in the domains of Human-Robot Interaction and Human-Computer Interaction for allowing humans to interact with virtual agents and other artificial entities. We conclude with a summary of guidelines for animating the eye and head from the perspective of a character animator. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","facial animation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Animation","Animation; Behavioral research; Computer graphics; Eye movements; Human robot interaction; Robots; Three dimensional computer graphics; Virtual reality; Computer graphics applications; Cross-disciplinary approaches; Facial animation; Human-human interactions; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Recent researches; Social robotics; User interaction; Human computer interaction",2-s2.0-84942371792
"Norris G.","Judgement heuristics and bias in evidence interpretation: The effects of computer generated exhibits",2015,"International Journal of Law and Psychiatry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951905855&doi=10.1016%2fj.ijlp.2015.08.016&partnerID=40&md5=567ad64307fb6f075a0917824cd781cd","The increasing use of multi-media applications, trial presentation software and computer generated exhibits (CGE) has raised questions as to the potential impact of the use of presentation technology on juror decision making. A significant amount of the commentary on the manner in which CGE exerts legal influence is largely anecdotal; empirical examinations too are often devoid of established theoretical rationalisations. This paper will examine a range of established judgement heuristics (for example, the attribution error, representativeness, simulation), in order to establish their appropriate application for comprehending legal decisions. Analysis of both past cases and empirical studies will highlight the potential for heuristics and biases to be restricted or confounded by the use of CGE. The paper will conclude with some wider discussion on admissibility, access to justice, and emerging issues in the use of multi-media in court. © 2015 Elsevier Ltd.","Animations; Computer generated exhibits; Decision making; Heuristics","Article; cognition; computer generated exhibit; computer simulation; conceptual framework; decision making; examination; human; information; information retrieval; legal aspect; mathematical analysis; mathematical model; memory; multimedia; propensity score; theory; thinking; computer graphics; heuristics; jurisprudence; perception; prejudice; Computer Graphics; Decision Making; Heuristics; Humans; Judgment; Judicial Role; Prejudice; Social Perception",2-s2.0-84951905855
"Kurzhals K., Burch M., Pfeiffer T., Weiskopf D.","Eye Tracking in Computer-Based Visualization",2015,"Computing in Science and Engineering",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940034785&doi=10.1109%2fMCSE.2015.93&partnerID=40&md5=f37bc8d086c9c7da01341a1f18488635","The authors describe the creation of a tridimensional fly-through animation across the largest map of galaxies to date. This project represented a challenge: creating a scientifically accurate representation of the galaxy distribution that was aesthetically pleasing. The animation shows almost half a million galaxies as the viewer travels through the vast intergalactic regions, giving a glimpse of the sheer size of the universe. © 2015 IEEE.","3D rendering modeling; Blender; Cosmic Web galaxy surveys; scientific computing; Sloan Digital Sky Survey","Animation; Blending; Cosmology; Natural sciences computing; Surveys; Three dimensional computer graphics; 3-D rendering; Blender; Computer-based visualization; Eye-tracking; Galaxy distribution; Sheer size; Sloan Digital Sky Survey; Galaxies",2-s2.0-84940034785
"Elhayek A., Stoll C., Kim K.I., Theobalt C.","Outdoor Human Motion Capture by Simultaneous Optimization of Pose and Camera Parameters",2015,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942373134&doi=10.1111%2fcgf.12519&partnerID=40&md5=4f7ce9d925da029510542e1c9642868a","We present a method for capturing the skeletal motions of humans using a sparse set of potentially moving cameras in an uncontrolled environment. Our approach is able to track multiple people even in front of cluttered and non-static backgrounds, and unsynchronized cameras with varying image quality and frame rate. We completely rely on optical information and do not make use of additional sensor information (e.g. depth images or inertial sensors). Our algorithm simultaneously reconstructs the skeletal pose parameters of multiple performers and the motion of each camera. This is facilitated by a new energy functional that captures the alignment of the model and the camera positions with the input videos in an analytic way. The approach can be adopted in many practical applications to replace the complex and expensive motion capture studios with few consumer-grade cameras even in uncontrolled outdoor scenes. We demonstrate this based on challenging multi-view video sequences that are captured with unsynchronized and moving (e.g. mobile-phone or GoPro) cameras. © 2014 The Authors Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Animation; markerless human motion capture; moving cameras; outdoor capture","Animation; Information use; Three dimensional computer graphics; Video signal processing; Human motion capture; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Markerless human motion captures; Moving cameras; Non-static backgrounds; Outdoor capture; Sensor informations; Simultaneous optimization; Cameras",2-s2.0-84942373134
"Jacobson A.","Breathing Life into Shapes",2015,"IEEE Computer Graphics and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942742279&doi=10.1109%2fMCG.2015.110&partnerID=40&md5=2e1d806a37767582d2ebc2dc3349addf","Shape articulation transforms a lifeless geometric object into a vibrant character. Computers enrich artists' toolsets dramatically. They not only endow artists with the power to manipulate virtual 2D and 3D scenes, but they also eliminate tedium and expedite prototyping, freeing artists to focus on creative aspects. With such power comes a temptation to lean entirely on the computer. Computationally intensive animation systems sacrifice real-time feedback for physical accuracy. How can we leverage modern computational power to create the best possible shape deformations while maintaining real-time performance as a mandatory invariant? This article summarizes efforts to answer this, culminating in a deformation system with the quality of slow, nonlinear optimization, but at lightning speed. © 1981-2012 IEEE.","computer graphics; LBS; linear blend skinning; real-time animation; real-time shape deformation; shape articulation; shape editing","Animation; Computer graphics; Deformation; Mathematical transformations; Nonlinear programming; LBS; Linear blend; Real-time animations; Shape deformation; Shape editing; Real time systems",2-s2.0-84942742279
"Wu J., Westermann R., Dick C.","A Survey of Physically Based Simulation of Cuts in Deformable Bodies",2015,"Computer Graphics Forum",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942318738&doi=10.1111%2fcgf.12528&partnerID=40&md5=4cf82203aab7060bd87ca0316b88a508","Virtual cutting of deformable bodies has been an important and active research topic in physically based modelling and simulation for more than a decade. A particular challenge in virtual cutting is the robust and efficient incorporation of cuts into an accurate computational model that is used for the simulation of the deformable body. This report presents a coherent summary of the state of the art in virtual cutting of deformable bodies, focusing on the distinct geometrical and topological representations of the deformable body, as well as the specific numerical discretizations of the governing equations of motion. In particular, we discuss virtual cutting based on tetrahedral, hexahedral and polyhedral meshes, in combination with standard, polyhedral, composite and extended finite element discretizations. A separate section is devoted to meshfree methods. Furthermore, we discuss cutting-related research problems such as collision detection and haptic rendering in the context of interactive cutting scenarios. The report is complemented with an application study to assess the performance of virtual cutting simulators. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","deformable bodies; finite elements; I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling-Physically based modelling; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation; I.3.8 [Computer Graphics]: Applications; physically based modelling; surgery simulation; virtual cutting","Computational geometry; Computer graphics; Deformation; Equations of motion; Finite element method; Deformable bodies; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; I.3.8 [computer graphics]: Applications; Object modelling; Physically-based Modelling; Surgery simulations; Virtual cutting; Three dimensional computer graphics",2-s2.0-84942318738
"Abu Rumman N., Fratarcangeli M.","Position-Based Skinning for Soft Articulated Characters",2015,"Computer Graphics Forum",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942370433&doi=10.1111%2fcgf.12533&partnerID=40&md5=f6c61bc56fd25863c90cf971a81b954c","In this paper, we introduce a two-layered approach addressing the problem of creating believable mesh-based skin deformation. For each frame, the skin is first deformed with a classic linear blend skinning approach, which usually leads to unsightly artefacts such as the well-known candy-wrapper effect and volume loss. Then we enforce some geometric constraints which displace the positions of the vertices to mimic the behaviour of the skin and achieve effects like volume preservation and jiggling. We allow the artist to control the amount of jiggling and the area of the skin affected by it. The geometric constraints are solved using a position-based dynamics (PBDs) schema. We employ a graph colouring algorithm for parallelizing the computation of the constraints. Being based on PBDs guarantees efficiency and real-time performances while enduring robustness and unconditional stability. We demonstrate the visual quality and the performance of our approach with a variety of skeleton-driven soft body characters. © 2015 The Authors Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd.","animation; animation; animation w/constraints; Categories and Subject Descriptors (according to ACM CCS): Computer Graphics 1.3.7 Three-Dimensional Graphics and Realism Animation and Virtual Reality; particle systems","Computer graphics; Geometric constraint; Layered approaches; Particle systems; Real time performance; Skin deformation; Unconditional stability; Visual qualities; Volume preservation; Animation",2-s2.0-84942370433
"Mohammad A.I.S., Yannick J.T.T., Moloo R.K.","Increasing efficiency in visualizing large sets of 3D models on the web",2015,"Proceedings of 2015 IEEE International Conference on Electrical, Computer and Communication Technologies, ICECCT 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954162570&doi=10.1109%2fICECCT.2015.7226097&partnerID=40&md5=e6dfd045ebe122872361e6d4728de7fb","This paper investigates the behaviour of 3D Models on the web. The advent of WebGL as a tool for rendering 3D Models and Animation on web pages without the use of plugins opens up limitless avenues for virtual reality on the internet. In the near future, real life virtual environment consisting of thousands of complex 3D models will be a common feature across the globe, but this will depend on how effective and efficient the rendering of these models will be. In this research we identified and investigated on how algorithms can improve rendering performance in visualizing large set of 3D objects (textured and non-textured) on the web. Raycasting and Octree were identified, analyzed, implemented, tested and compared before we proposed a new algorithm by combining both Raycasting + Octree for improved performance. Three.js WebGL Framework was used to evaluate identified algorithms for loading and rendering of 3D models. We made use of different models with low, medium and high vertex count for testing and our proposed algorithm proved to be very promising against existing algorithms. © 2015 IEEE.","3D Visualisation; Efficient Algorithm; HTML5; Virtual Reality; WebGL","Algorithms; Content based retrieval; Rendering (computer graphics); Virtual reality; Websites; 3D models; 3D object; 3D Visualisation; Common features; HTML5; Raycasting; Rendering performance; WebGL; Three dimensional computer graphics",2-s2.0-84954162570
"Khantong R., Pan X., Slater M.","An experimental study on the virtual representation of children",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954561695&doi=10.1109%2fVR.2015.7223367&partnerID=40&md5=d30bfc2ea9507d1d0b4e052a76b3c5dc","Is it their movements or appearance that helps us to identify a child as a child? In this work we created four video clips with a Virtual Character walking, but with different combinations of either child or adult animation applied on either a child or adult body. An experimental study was conducted with 53 participants who viewed all four videos in random orders. The results show that participants could easily identify the consistent video clips (child animation with child body, and adult animation with adult body). With the inconsistent video clips, both animation and body shape had an effect on participants' judgments. They also reported higher level of empathy, care, and feeling of protection towards the child character as compared to the adult character. Finally, compared to appearance, animation seems to be playing a bigger role in invoking participants' emotional responses. © 2015 IEEE.","Computer Animation; User Study; Virtual Characters","Video cameras; Virtual reality; Body shapes; Computer animation; Emotional response; User study; Video clips; Virtual character; Virtual representations; Animation",2-s2.0-84954561695
"Hochreiter J., Daher S., Nagendran A., Gonzalez L., Welch G.","Touch sensing on non-parametric rear-projection surfaces: A physical-virtual head for hands-on healthcare training",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954496838&doi=10.1109%2fVR.2015.7223326&partnerID=40&md5=b931f185c4f065c4af22ada031f13d17","We demonstrate a generalizable method for unified multitouch detection and response on a human head-shaped surface with a rear-projection animated 3D face. The method helps achieve hands-on touch-sensitive training with dynamic physical-virtual patient behavior. The method, which is generalizable to other non-parametric rear-projection surfaces, requires one or more infrared (IR) cameras, one or more projectors, IR light sources, and a rear-projection surface. IR light reflected off of human fingers is captured by cameras with matched IR pass filters, allowing for the localization of multiple finger touch events. These events are tightly coupled with the rendering system to produce auditory and visual responses on the animated face displayed using the projector(s), resulting in a responsive, interactive experience. We illustrate the applicability of our physical prototype in a medical training scenario. © 2015 IEEE.","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Animations, Artificial, Augmented, and Virtual Realities; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual Reality; I.3.8 [Computer Graphics]: Applications","Cameras; Computer graphics; Light sources; Matched filters; Virtual reality; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; I.3.8 [computer graphics]: Applications; Infrared cameras; Medical training; Multimedia Information Systems - Animations; Rendering system; Tightly-coupled; Virtual patients; Three dimensional computer graphics",2-s2.0-84954496838
"Chen T.-Y., Wong S.-K.","Digital artwork creation using water and sand on a two-dimensional surface",2015,"ACM International Conference Proceeding Series",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014909501&doi=10.1145%2f2801040.2801046&partnerID=40&md5=fad51557ad2a2ee5bbf4e88ac8db5f8d","In this paper, we developed a system which enables users to draw pictures of sand and water on a two-dimensional surface in a virtual environment. By mixing water and sand for artwork creation, we can create di-erent styles of pictures. Our system has three major subsystems: water animation system, sand animation system and rendering system. In the simulation part, we compute the motion of sand and water based on the interactions for water-water, sand-water and sand-sand. In the rendering part, we attempt to balance the rendering quality and the computation cost. We render water using a ray tracing method and the sand is rendered with shadow. Thus, the rendered results of water and sand look like 2.5D. We tested our system and the experimental results showed that the users could create a variety of pictures of sand and water. © 2015 ACM.","Animation; Digital art; Height map; Particle system; Sand; Water","Animation; Arts computing; Ray tracing; Rendering (computer graphics); Virtual reality; Visual communication; Water; Animation systems; Computation costs; Digital art; Height map; Particle systems; Ray-tracing method; Rendering quality; Two-dimensional surface; Sand",2-s2.0-85014909501
"Karim I., Sumpeno S., Purnomo M.H.","Synthesis of virtual character poses using Lagrange polynomial interpolation",2015,"2015 International Seminar on Intelligent Technology and Its Applications, ISITIA 2015 - Proceeding",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954157905&doi=10.1109%2fISITIA.2015.7219991&partnerID=40&md5=b607e1b8610c14f04b0ec37b463a7056","In these times, affective virtual characters are often being involved as a major component in creative industries such as computer games and animation. Creating affective characters is not a simple job. One of technique used in creating the characters is the motion capture. Results using this technique are presented in motion capture data and can be processed further for many other functions, including creating variations of affective content. Motion capture data synthesis has been used widely to produce these variations by applying the interpolation method. In this study, Lagrange polynomial interpolation was applied to generate variations in pose. © 2015 IEEE.","affective pose; interpolation; lagrange polynomial; motion capture; synthesis","Animation; Computer games; Lagrange multipliers; Polynomials; Synthesis (chemical); affective pose; Creative industries; Interpolation method; Lagrange polynomials; Motion capture; Motion capture data; Virtual character; Interpolation",2-s2.0-84954157905
"Tucker S.-P.L., Tucker D.","Animated graphical user (AGUI) model in desktop and mobil computer devices",2015,"2015 IEEE International Conference on Consumer Electronics - Taiwan, ICCE-TW 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959512681&doi=10.1109%2fICCE-TW.2015.7216883&partnerID=40&md5=ee63dad2b77c43c56a95e8a68feed72d","Since the beginning of computers there have been many types of user interfaces. Early user interfaces were extremely limited because of the computers limited resources. As computing systems and computing power evolve, so have the user interfaces evolved. The current stage of evolution for graphical user interfaces (GUI) for most computer systems is the WIMP (Windows, Icons, Mice, Pointer). The WIMP graphical user interface design has been the standard since its conception in the 1970s. Progressing beyond the WIMP to the next level of graphical user interface has proven extremely difficult [1]. Animated Graphical User Interfaces (AGUI) are a significant improvement over windowed interfaces for some applications. The users perceived usefulness, perceived value, and perceived quality can be improved by applying an Animated Graphical User Interface to the application. Improving the users perceived usefulness, perceived value, and perceived quality can lead to a significant increase in revenue for some applications. Advertising in traditional windowed applications is not widely accepted by users making it difficult to use as a revenue source. The introduction of an Animated Graphical User Interface to an application also gives rise to the option of introducing animated advertising in the application. Animated advertising can present a new revenue source in addition to or in place of the purchase price of the application. Animated advertisements can be presented in an entertaining and passive format that users will find acceptable in applications where advertising is not normally tolerated. The Animated Graphical User Interface can also be used to bridge language barriers. Animations for the interface can be designed with a goal of language independence. The user interface and animations can be designed with intuitive animations and graphics that users can understand without using a language. Animated applications designed for language independence can be used by people all over the world without modifications for language considerations. Design innovative user Animated Graphical User Interfaces that are functional and entertaining. Use the Animated Graphical User Interface Model to increase the users perceived usefulness, perceived quality, and perceived value of the target application. Create an environment using the Animated Graphical User Interface Model that instills user tolerance for animated advertising embedded in applications. Design animations, graphics and functionalities using the Animated Graphical User Interface Model that allows language independent use of the application. © 2015 IEEE.","Advertising; Animation; Computational modeling; Computers; Graphical user interfaces; Object oriented modeling","Animation; Computational linguistics; Computers; Consumer electronics; Marketing; User interfaces; Computational model; Graphical user interfaces (GUI); Language independence; Language independents; Object oriented model; Perceived quality; Perceived usefulness; Target application; Graphical user interfaces",2-s2.0-84959512681
"Peter W.F., Loos M., van den Hoek J., Terwee C.B.","Validation of the Animated Activity Questionnaire (AAQ) for patients with hip and knee osteoarthritis: comparison to home-recorded videos",2015,"Rheumatology International",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931569964&doi=10.1007%2fs00296-015-3230-4&partnerID=40&md5=a5d18dd4e72388a9275e582d2f179947","A recently developed computerized Animated Activity Questionnaire (AAQ) uses video animations to measure limitations in basic daily activities in patients with hip or knee osteoarthritis (OA). The AAQ is less time and money consuming than performance-based tests and less burdensome for patients. Compared to patient-reported outcome measurements, the AAQ is less influenced by the perception of the patient. Previous validation studies of the AAQ showed promising results. Since the AAQ purports to measure activity limitations in real-life situations, this study aims to establish the construct validity of the AAQ by comparing the AAQ to home-recorded videos. Home-recorded videos of eleven basic activities performed by 22 OA patients were transformed into scores and subsequently correlated with the AAQ, the Hip disability and Knee injury Osteoarthritis Outcome Score (H/KOOS), and three performance-based tests (Stair Climbing Test, Timed Up and Go test, and the 30 s Chair Stand Test). The AAQ was expected to correlate highly with the home-recorded videos and the performance-based tests, and moderately with the H/KOOS. As hypothesized, the AAQ correlated highly with the home-recorded videos and performance-based tests (0.83 and, 0.73 respectively), but also unexpectedly highly with the H/KOOS (0.79). In conclusion, since the AAQ correlates highly with home-recorded videos, it seems to have potential as a measurement tool to assess limitations in activities close to the real-life situation, but this should be confirmed in a larger sample of patients. © 2015, The Author(s).","Activity limitations; Animations; Osteoarthritis; Questionnaire; Validity","aged; Animated Activity Questionnaire; Article; clinical article; construct validity; female; hip osteoarthritis; home environment; human; Knee Injury and Osteoarthritis Outcome Score; knee osteoarthritis; male; multicenter study; musculoskeletal disease assessment; outcome assessment; physical disability; physiotherapy; priority journal; validation study; videorecording; walking difficulty; computer assisted diagnosis; daily life activity; disability; hip osteoarthritis; knee osteoarthritis; middle aged; pathophysiology; questionnaire; severity of illness index; very elderly; videorecording; Activities of Daily Living; Aged; Aged, 80 and over; Diagnosis, Computer-Assisted; Disability Evaluation; Female; Humans; Male; Middle Aged; Osteoarthritis, Hip; Osteoarthritis, Knee; Severity of Illness Index; Surveys and Questionnaires; Video Recording",2-s2.0-84931569964
"Dykcik L., Kacperski D., Sekalski P.","Mirror galvanometer-based laser projector",2015,"Proceedings of the 22nd International Conference Mixed Design of Integrated Circuits and Systems, MIXDES 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953775882&doi=10.1109%2fMIXDES.2015.7208600&partnerID=40&md5=debb15b14f40b30b9086478c6ba846ac","This paper describes design and construction of a laser projector. Laser projectors are perfect for displaying graphics that need to catch our attention. In this paper we present the novel approach to animation which can later displayed by the self-made laser projector. The laser projector presented in paper is composed of galvanometer mirrors, green laser, microcontroller and a dedicated software running on it. Galvanometer mirrors are responsible for reflecting the incoming green laser beam in a precise way that will project a picture on the screen. The microcontroller synchronizes mirror movements with signals from its built-in digital-to-analogue converter. Additionally, it reads and procebes a file containing picture that will be shown. Copyright © 2015 Department of Microelectronics and Computer Science, Lodz Univeristy of Technology.","galvanometer mirrors; Laser projector; lasers; microcontroller","Controllers; Galvanometers; Integrated circuits; Laser beams; Lasers; Microcontrollers; Mirrors; Reconfigurable hardware; Design and construction; Green laser; Laser projectors; Laser mirrors",2-s2.0-84953775882
"Pan Y., White J., Sun Y., Gray J.","Gray computing: An analysis of computing with background javascript tasks",2015,"Proceedings - International Conference on Software Engineering",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951728257&doi=10.1109%2fICSE.2015.38&partnerID=40&md5=f436b483187bd78eb6d7f638594ea4f0","Websites routinely distribute small amounts of work to visitors' browsers in order to validate forms, render animations, and perform other computations. This paper examines the feasibility, cost effectiveness, and approaches for increasing the workloads offloaded to web visitors' browsers in order to turn them into a large-scale distributed data processing engine, which we term gray computing. Past research has looked primarily at either non-browser based volunteer computing or browserbased volunteer computing where the visitors keep their browsers open to a single web page for a long period of time. This paper provides a deep analysis of the architectural, cost effectiveness, user experience, performance, security, and other issues of gray computing distributed data processing engines with high heterogeneity, non-uniform page view times, and high computing pool volatility. © 2015 IEEE.",,"Cost benefit analysis; Cost effectiveness; Data handling; Engines; Software engineering; Websites; Distributed data processing; High heterogeneity; Javascript; Non-uniform; User experience; Volunteer computing; Web visitors; Distributed computer systems",2-s2.0-84951728257
[No author name available],"Proceedings - DigiPro 2015, Digital Production Symposium",2015,"Proceedings - DigiPro 2015, Digital Production Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959441194&partnerID=40&md5=56a92bc2caebdcf72d2e41a7d48556e7","The proceedings contain 10 papers. The topics discussed include: DreamWorks animation facial motion and deformation system; Dataflow: ILM's framework for procedural geometry evaluation, simulation authoring, crowds and more; motion retargeting for crowd simulation; rapid: an artist friendly particle system; improved deep image compositing using subpixel masks; empirical directional wave spectra for computer graphics; efficient and stable approach to elasticity and collisions for hair animation; a conceptual framework for understanding pipeline; ACEScg: a common color encoding for visual effects applications; rigging octopuses in 'Penguins of Madagascar'; and into the wasteland - the VFX of Mad Max: Fury Road.",,,2-s2.0-84959441194
[No author name available],"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956649977&partnerID=40&md5=4926b8f89db0ca27478ee24a0d411091","The proceedings contain 30 papers. The topics discussed include: a new sharp-crease bending element for folding and wrinkling surfaces and volumes; real-time dynamic wrinkling of coarse animated cloth; multifarious hierarchies of mechanical models for artist assigned levels-of-detail; effect of appearance on perception of deformation; fully momentum-conserving reduced deformable bodies with collision, contact, articulation, and skinning; efficient simulation of knitted cloth using persistent contacts; hands on: interactive animation of precision manipulation and contact; hierarchical planning and control for complex motor tasks; learning reduced-order feedback policies for motion skills; computational design of walking automata; simulation of fluid mixing with interface control; and learning an inverse rig mapping for character animation.",,,2-s2.0-84956649977
"Humberston B., Pai D.K.","Hands on: Interactive animation of precision manipulation and contact",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956680637&doi=10.1145%2f2786784.2786794&partnerID=40&md5=07c3e11e60552763c08da3cc42b1f996","Humans show effortless dexterity while manipulating objects using their own hands. However, specifying the motion of a virtual character's hand or of a robotic manipulator remains a difficult task that requires animation expertise or extensive periods of offline motion capture. We present Hands On: a real-time, adaptive animation interface, driven by compliant contact and force information, for animating contact and precision manipulations of virtual objects. Using our interface, an animator controls an abstract grasper trajectory while the full hand pose is automatically shaped by proactive adaptation and compliant scene interactions. Haptic force feedback enables intuitive control by mapping interaction forces from the full animated hand back to the reduced animator feedback space, invoking the same human sensorimotor processes utilized in natural precision manipulations. We provide an approach for online, adaptive shaping of the animated manipulator based on prior interactions, resulting in more functional and appealing motions. The importance of haptic feedback for authoring virtual object manipulations is verified in a user study with nonexpert participants that examines contact force trajectories while using our interface. Comparing the quality of motions produced with and without force rendering, haptic feedback is shown to be critical for efficiently communicating contact forces and dynamic events to the user.","Character animation; Contact; Hands; Physics-based animation; Sensorimotor control","Contacts (fluid mechanics); Haptic interfaces; Interactive computer graphics; Manipulators; Animation interfaces; Character animation; Hands; Interactive animations; Physics-based animation; Proactive adaptations; Robotic manipulators; Sensorimotor control; Animation",2-s2.0-84956680637
"Holden D., Saito J., Komura T.","Learning an inverse rig mapping for character animation",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956681113&doi=10.1145%2f2786784.2786788&partnerID=40&md5=364ad40aa4077fb0c2993c486fd94a87","We propose a general, real-time solution to the inversion of the rig function-the function which maps animation data from a character's rig to its skeleton. Animators design character movements in the space of an animation rig, and a lack of a general solution for mapping motions from the skeleton space to the rig space keeps the animators away from the state-of-the-art character animation methods, such as those seen in motion editing and synthesis. Our solution is to use non-linear regression on sparse example animation sequences constructed by the animators, to learn such a mapping offline. When new example motions are provided in the skeleton space, the learned mapping is used to estimate the rig space values that reproduce such a motion. In order to further improve the precision, we also learn the derivative of the mapping, such that the movements can be fine-tuned to exactly follow the given motion. We test and present our system through examples including full-body character models, facial models and deformable surfaces. With our system, animators have the freedom to attach any motion synthesis algorithms to an arbitrary rigging and animation pipeline, for immediate editing. This greatly improves the productivity of 3D animation, while retaining the flexibility and creativity of artistic input. © 2015 ACM.","Animation; Approximation; Machine learning; Rig","Artificial intelligence; Interactive computer graphics; Inverse problems; Learning systems; Mapping; Musculoskeletal system; Animation pipeline; Approximation; Character animation; Deformable surfaces; General solutions; Motion synthesis; Non-linear regression; Real time solution; Animation",2-s2.0-84956681113
"Zimmermann D., Coros S., Ye Y., Sumner R.W., Gross M.","Hierarchical planning and control for complex motor tasks",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956642216&doi=10.1145%2f2786784.2786795&partnerID=40&md5=f8f2991a586d10a9362808cc733dc9dd","We present a planning and control framework that enables physically simulated characters to perform various types of motor tasks. To create physically-valid motion plans, our method uses a hierarchical set of simplified models. Computational resources are therefore focused where they matter most: motion plans for the immediate future are generated using higher-fidelity models, while coarser models are used to create motion plans with longer time horizons. Our framework can be used for different types of motor skills, including ones where the actions of the arms and legs must be precisely coordinated. We demonstrate controllers for tasks such as getting up from a chair, crawling onto a raised platform, or using a handrail while climbing stairs. All of the motions are simulated using a black-box physics engine from high level user commands, without requiring any motion capture data. © 2015 ACM.","Control; Motion planning; Physics-based character animation","Control; Interactive computer graphics; Motion planning; Character animation; Computational resources; Hierarchical planning; Motion capture data; Physics engine; Planning and control; Time horizons; User commands; Animation",2-s2.0-84956642216
"Malgat R., Gilles B., Levin D.I.W., Nesme M., Faure F.","Multifarious hierarchies of mechanical models for artist assigned levels-of-detail",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956671565&doi=10.1145%2f2786784.2786800&partnerID=40&md5=21f0281e0fc155044124cae703cfea82","We present a new framework for artist driven level of detail in solid simulations. Simulated objects are simultaneously embedded in several, separately designed deformation models with their own independent degrees of freedom. The models are ordered to apply their deformations hierarchically, and we enforce the uniqueness of the dynamics solutions using a novel kinetic filtering operator designed to ensure that each child only adds detail motion to its parent without introducing redundancies. This new approach allows artists to easily add fine-scale details without introducing unnecessary degrees-of-freedom to the simulation or resorting to complex geometric operations like anisotropic volume meshing. We illustrate the utility of our approach with several detail enriched simulation examples. © 2015 ACM.","Deformable Solid; Multiscale Continuum Mechanics; Physically Based Animation","Continuum mechanics; Deformation; Degrees of freedom (mechanics); Filtration; Interactive computer graphics; Mechanics; Deformable solids; Deformation models; Geometric operations; Level of detail; Levels of detail; Mechanical model; Physically-based animation; Simulation example; Animation",2-s2.0-84956671565
"Gillette R., Peters C., Vining N., Edwards E., Sheffer A.","Real-time dynamic wrinkling of coarse animated cloth",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956651683&doi=10.1145%2f2786784.2786789&partnerID=40&md5=de6a59d8f23025e8ea0d351068e8905b","Dynamic folds and wrinkles are an important visual cue for creating believably dressed characters in virtual environments. Adding these fine details to real-time cloth visualization is challenging, as the low-quality cloth used for real-time applications often has no reference shape, an extremely low triangle count, and poor temporal and spatial coherence. We introduce a novel real-time method for adding dynamic, believable wrinkles to such coarse cloth animation. We trace spatially and temporally coherent wrinkle paths, overcoming the inaccuracies and noise in low-end cloth animation, by employing a two stage stretch tensor estimation process. We first employ a graph-cut segmentation technique to extract spatially and temporally reliable surface motion patterns, detecting consistent compressing, stable, and stretching patches. We then use the detected motion patterns to compute a per-triangle temporally adaptive reference shape and a stretch tensor based on it. We use this tensor to dynamically generate new wrinkle geometry on the coarse cloth mesh by taking advantage of the GPU tessellation unit. Our algorithm produces plausible fine wrinkles on real-world data sets at real-time frame rates, and is suitable for the current generation of consoles and PC graphics cards. © 2015 ACM.","Cloth animation; Computer games; Real time cloth; Wrinkle augmentation","Computer games; Computer graphics; Graphic methods; Interactive computer graphics; Tensors; Time and motion study; Virtual reality; Cloth animation; Graph-cut segmentations; Real time; Real-time application; Real-time dynamics; Real-time frame rates; Temporal and spatial; Wrinkle augmentation; Animation",2-s2.0-84956651683
"Cong M., Bao M., Jane L.E., Bhat K.S., Fedkiw R.","Fully automatic generation of anatomical face simulation models",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956607074&doi=10.1145%2f2786784.2786786&partnerID=40&md5=46280c4b6838d1d6be35df001eae98ea","We present a fast, fully automatic morphing algorithm for creating simulatable flesh and muscle models for human and humanoid faces. Current techniques for creating such models require a significant amount of time and effort, making them infeasible or impractical. In fact, the vast majority of research papers use only a floating mask with no inner lips, teeth, tongue, eyelids, eyes, head, ears, etc.-and even those that build the full visual model would typically still lack the cranium, jaw, muscles, and other internal anatomy. Our method requires only the target surface mesh as input and can create a variety of models in only a few hours with no user interaction. We start with a symmetric, high resolution, anatomically accurate template model that includes auxiliary information such as feature points and curves. Then given a target mesh, we automatically orient it to the template, detect feature points, and use these to bootstrap the detection of corresponding feature curves. These curve correspondences are used to deform the surface mesh of the template model to match the target mesh. Then, the calculated displacements of the template surface mesh are used to drive a three-dimensional morph of the full template model including all interior anatomy. The resulting target model can be simulated to generate a large range of expressions that are consistent across characters using the same muscle activations. Full automation of this entire process makes it readily available to a wide range of users.","Facial animation; Model creation; Muscles","Algorithms; Animation; Interactive computer graphics; Mesh generation; Muscle; Automatic Generation; Auxiliary information; Facial animation; Model creation; Morphing algorithms; Muscle activation; Template surfaces; User interaction; Computer graphics",2-s2.0-84956607074
"Ding K., Liu L., Van De Panne M., Yin K.","Learning reduced-order feedback policies for motion skills",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956631801&doi=10.1145%2f2786784.2786802&partnerID=40&md5=4491e2e18e44bd864b8a27d5f9809d4f","We introduce a method for learning low-dimensional linear feedback strategies for the control of physics-based animated characters around a given reference trajectory. This allows for learned low-dimensional state abstractions and action abstractions, thereby reducing the need to rely on manually designed abstractions such as the center-of-mass state or foot-placement actions. Once learned, the compact feedback structure allow simulated characters to respond to changes in the environment and changes in goals. The approach is based on policy search in the space of reduced-order linear output feedback matrices. We show that these can be used to replace or further reduce manually-designed state and action abstractions. The approach is sufficiently general to allow for the development of unconventional feedback loops, such as feedback based on ground reaction forces. Results are demonstrated for a mix of 2D and 3D systems, including tilting-platform balancing, walking, running, rolling, targeted kicks, and several types of ballhitting tasks.","Character animation; Control; Human simulation","Abstracting; Biophysics; Control; Interactive computer graphics; Animated characters; Character animation; Feedback structure; Ground reaction forces; Human simulation; Linear output feedback; Reference trajectories; State abstraction; Animation",2-s2.0-84956631801
"Schulz C., Von Tycowicz C., Seidel H.-P., Hildebrandt K.","Animating articulated characters using wiggly splines",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956634174&doi=10.1145%2f2786784.2786799&partnerID=40&md5=cde675ca237935a9e723b83d9db8a093","We propose a new framework for spacetime optimization that can generate artistic motion with a long planning horizon for complex virtual characters. The scheme can be used for generating general types of motion and neither requires motion capture data nor an initial motion that satisfies the constraints. Our modeling of the spacetime optimization combines linearized dynamics and a novel warping scheme for articulated characters. We show that the optimal motions can be described using a combination of vibration modes, wiggly splines, and our warping scheme. This enables us to restrict the optimization to low-dimensional spaces of explicitly parametrized motions. Thereby the computation of an optimal motion is reduced to a low-dimensional non-linear least squares problem, which can be solved with standard solvers. We show examples of motions created by specifying only a few constraints for positions and velocities.","Optimal control; Physically-based animation; Spacetime constraints; Wiggly splines","Interactive computer graphics; Linearized dynamics; Low-dimensional spaces; Motion capture data; Nonlinear least squares problems; Optimal controls; Physically-based animation; Spacetime constraints; Virtual character; Animation",2-s2.0-84956634174
"Brown G., Samii A., O'Brien J.F., Narain R.","Resampling adaptive cloth simulations onto fixed-topology meshes",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956687121&doi=10.1145%2f2786784.2795142&partnerID=40&md5=263c93364439307da6713a9cf66c5b6f","We describe a method for converting an adaptively remeshed simulation of cloth into an animated mesh with fixed topology. The topology of the mesh may be specified by the user or computed automatically. In the latter case, we present a method for computing the optimal output mesh, that is, a mesh with spatially varying resolution which is fine enough to resolve all the detail present in the animation. This technique allows adaptive simulations to be easily used in applications that expect fixed-topology animated meshes.",,"Animation; Interactive computer graphics; Mesh generation; Topology; Adaptive simulation; Cloth simulation; Fixed topologies; Resampling; Computer graphics",2-s2.0-84956687121
"Patkar S., Jin N., Fedkiw R.","A new sharp-crease bending element for folding and wrinkling surfaces and volumes",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956672277&doi=10.1145%2f2786784.2786792&partnerID=40&md5=8be37b42e61b16dcbb138890981ad29a","We present a novel sharp-crease bending element for the folding and wrinkling of surfaces and volumes. Based on a control curve specified by an artist or derived from internal stresses of a simulation, we create a piecewise linear curve at the resolution of the computational mesh. Then, the key idea is to cut the object along the curve using the virtual node algorithm creating new degrees of freedom, while subsequently reattaching the resulting pieces eliminating the translational degrees of freedom so that adjacent pieces may only rotate or bend about the cut. Motivated by an articulated rigid body framework, we utilize the concepts of pre-stabilization and post-stabilization in order to enforce these reattachment constraints. Our cuts can be made either razor sharp or relatively smooth via the use of bending springs. Notably, our sharp-crease bending elements can not only be used to create pleats in cloth or folds in paper but also to create similar buckling in volumetric objects. We illustrate this with examples of forehead wrinkles and nasolabial folds for facial animation. Moreover, our sharp-crease bending elements re-quire minimal extra simulation time as compared to the underlying mesh, and tend to reduce simulation times by an order of magnitude when compared to the alternative of mesh refinement.","Buckling; Creasing; Facial wrinkles; Folding","Animation; Buckling; Degrees of freedom (mechanics); Interactive computer graphics; Mechanics; Mesh generation; Piecewise linear techniques; Stabilization; Computational mesh; Creasing; Facial wrinkles; Folding; Piecewise linear; Pre-stabilization; Translational degrees of freedoms; Volumetric object; Computer graphics",2-s2.0-84956672277
"Bender J., Koschier D.","Divergence-free smoothed particle hydrodynamics",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956659641&doi=10.1145%2f2786784.2786796&partnerID=40&md5=811f56d7f40bf4ca3d687ebc37a7cdd4","In this paper we introduce an efficient and stable implicit SPH method for the physically-based simulation of incompressible fluids. In the area of computer graphics the most efficient SPH approaches focus solely on the correction of the density error to prevent volume compression. However, the continuity equation for incompressible flow also demands a divergence-free velocity field which is neglected by most methods. Although a few methods consider velocity divergence, they are either slow or have a perceivable density fluctuation. Our novel method uses an efficient combination of two pressure solvers which enforce low volume compression (below 0:01 %) and a divergence-free velocity field. This can be seen as enforcing incompressibility both on position level and velocity level. The first part is essential for realistic physical behavior while the divergence-free state increases the stability significantly and reduces the number of solver iterations. Moreover, it allows larger time steps which yields a considerable performance gain since particle neighborhoods have to be updated less frequently. Therefore, our divergence-free SPH (DFSPH) approach is significantly faster and more stable than current state-of-the-art SPH methods for incompressible fluids. We demonstrate this in simulations with millions of fast moving particles. © 2015 ACM.","Divergence-free fluids; Fluid simulation; Implicit integration; Incompressibility; Smoothed Particle Hydrodynamics","Animation; Computer graphics; Fluid dynamics; Incompressible flow; Interactive computer graphics; Velocity; Divergence free; Fluid simulations; Implicit integration; Incompressibility; Smoothed particle hydrodynamics; Hydrodynamics",2-s2.0-84956659641
"Han D., Keyser J.","Effect of appearance on perception of deformation",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956621274&doi=10.1145%2f2786784.2786797&partnerID=40&md5=dedf661661af29c0558c55cf2dd62e22","We provide an experimental validation that appearance of an object can influence the perception of its level of deformation in a 3D simulation. Our study provides helpful insights in how to improve visual plausibility of deformation, which may allow artists to adjust their designs to enhance or minimize the perceived deformation in a model. We use a physically-based deformation model to simulate simple geometric shapes undergoing deformation. We apply a number of different appearance and rendering parameters to these objects, and then use two user studies to measure whether appearance used for an object can have a statistically significant effect on the perception of its deformation. In another study, we adjust the number of objects simulated and investigate how this can influence the effect of appearance. We find that appearance can potentially influence people's sensitivity to differences of deformation as well as subjective rating of softness in our studies. Further analysis shows that, in simple scenarios, the effect of low-level cues in appearance can be dominant, even if high-level information delivered by appearance has the opposite implication. The third study shows that as the number of objects in a scenario increases, objects are perceived to be stiffer. Also, the effect of low-level cues is weaker. © 2015 ACM.","Perception; Physical simulation; Texturing","Animation; Interactive computer graphics; Sensory perception; Texturing; Deformation modeling; Experimental validations; Geometric shape; High-level information; Low-level cues; Physical simulation; Physically based; Subjective rating; Deformation",2-s2.0-84956621274
"Wang X., Ren J., Jin X., Manocha D.","BSwarm: Biologically-plausible dynamics model of insect swarms",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952311697&doi=10.1145%2f2786784.2786790&partnerID=40&md5=fc068c9ec06d0160a9cb179211b03408","We present a biologically plausible dynamics model to simulate swarms of flying insects. Our formulation, which is based on biological conclusions and experimental observations, is designed to simulate large insect swarms of varying densities. We use a hybrid formulation that combines a force-based model to capture different interactions between the insects with a data-driven noise model, and computes collision-free trajectories. We introduce a quantitative metric to evaluate the accuracy of such multi-agent systems and model the inherent noise. We highlight the performance of our dynamics model for simulating large flying swarms of midges, fruit fly, locusts and moths. In practice, our approach can generate many collective behaviors, including aggregation, migration, phase transition, and escape responses, and we highlight the benefits over prior methods. © 2015 ACM.","Crowd simulation; Insect swarm; Validation","Animation; Dynamics; Interactive computer graphics; Collective behavior; Collision-free trajectory; Crowd Simulation; Dynamics modeling; Hybrid formulations; Insect swarm; Quantitative metric; Validation; Multi agent systems",2-s2.0-84952311697
"Cirio G., Lopez-Moreno J., Otaduy M.A.","Efficient simulation of knitted cloth using persistent contacts",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956636429&doi=10.1145%2f2786784.2786801&partnerID=40&md5=aa72e6f57845bc6ed67944ec5ee57886","Knitted cloth is made of yarns that are stitched in regular patterns, and its macroscopic behavior is dictated by the contact interactions between such yarns. We propose an efficient representation of knitted cloth at the yarn level that treats yarn-yarn contacts as persistent, thereby avoiding expensive contact handling altogether. We introduce a compact representation of yarn geometry and kinematics, capturing the essential deformation modes of yarn loops and stitches with a minimum cost. Based on this representation, we design force models that reproduce the characteristic macroscopic behavior of knitted fabrics. We demonstrate the efficiency of our method on simulations with millions of degrees of freedom (hundreds of thousands of yarn loops), almost one order of magnitude faster than previous techniques. © 2015 ACM.","Knitted cloth; Physically based simulation; Yarns","Animation; Degrees of freedom (mechanics); Interactive computer graphics; Wool; Compact representation; Contact interaction; Deformation modes; Efficient simulation; Knitted fabric; Macroscopic behaviors; Physically-based simulation; Regular patterns; Yarn",2-s2.0-84956636429
"He X., Wang H., Zhang F., Wang H., Wang G., Zhou K., Wu E.","Simulation of fluid mixing with interface control",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956647294&doi=10.1145%2f2786784.2786791&partnerID=40&md5=7421a55cddb311e180f6c023a4bf6198","The simulation of fluid mixing under the Eulerian framework often suffers from numerical dissipation issues. In this paper, we present a mass-preserving convection scheme that offers direct control on the shape of the interface. The key component of this scheme is a sharpening term built upon the diffusive flux of a userspecified kernel function. To determine the thickness of the ideal interface during fluid mixing, we perform theoretical analysis on a one-dimensional diffusive model using the Fick's law of diffusion. By explicitly controlling the interface thickness using a spatio-temporally varying kernel variable, we can use our scheme to produce realistic fluid mixing effects without numerical dissipation artifacts. We can also use the scheme to control interface changes between two fluids, due to temperature, pressure, or external energy input. This convection scheme is compatible with many advection methods and it has a small computational overhead. © 2015 ACM.","Diffuse interface; Fluid control; Fluid mixing; Miscible/immiscible fluids; Phase field","Animation; Interactive computer graphics; Mixing; One dimensional; Computational overheads; Diffuse interface; Fick's law of diffusion; Fluid control; Fluid mixing; Interface thickness; Numerical dissipation; Phase fields; Diffusion in liquids",2-s2.0-84956647294
"Bharaj G., Coros S., Thomaszewski B., Tompkin J., Bickel B., Pfister H.","Computational design of walking automata",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956673963&doi=10.1145%2f2786784.2786803&partnerID=40&md5=27511dd6e930a3ce9c16563ee47b473d","Creating mechanical automata that can walk in stable and pleasing manners is a challenging task that requires both skill and expertise. We propose to use computational design to offset the technical difficulties of this process. A simple drag-and-drop interface allows casual users to create personalized walking toys from a library of pre-defined template mechanisms. Provided with this input, our method leverages physical simulation and evolutionary optimization to refine the mechanical designs such that the resulting toys are able to walk. The optimization process is guided by an intuitive set of objectives that measure the quality of the walking motions. We demonstrate our approach on a set of simulated mechanical toys with different numbers of legs and various distinct gaits. Two fabricated prototypes showcase the feasibility of our designs. © 2015 ACM.","Animation; Fabrication; Mechanical characters","Automata theory; Design; Fabrication; Interactive computer graphics; Mechanisms; Optimization; Computational design; Drag and drop; Evolutionary optimizations; Mechanical characters; Mechanical design; Physical simulation; Technical difficulties; Walking motion; Animation",2-s2.0-84956673963
"Bruneau J., Pettré J.","Energy-efficient mid-term strategies for collision avoidance in crowd simulation",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956618261&doi=10.1145%2f2786784.2786804&partnerID=40&md5=afd0bac7f3b91a37d3dd02c040555005","When navigating in crowds, humans are able to move efficiently between people. They look ahead to know which path would reduce the complexity of their interactions with others. Current navigation systems for virtual agents consider the long-term planning to find a path in the static environment and the short term reaction to avoid collision with close obstacles. Recently some mid-term considerations have been added to avoid high density areas. However, there is no mid-term planning among static and dynamic obstacles that would enable the agent to look ahead and avoid difficult paths or find easy ones as human do. In this paper we present a system for such mid-term planning. This system is added to the navigation process between the path finding and the local avoidance to improve the navigation of virtual agents. We show the capacities of such system on several case studies. Finally we use an energy criterion to compare trajectories computed with and without the mid-term planning. © 2015 ACM.","Collision avoidance; Crowd dynamics; Interaction planning; Navigation","Animation; Collision avoidance; Interactive computer graphics; Navigation; Navigation systems; Crowd dynamics; Crowd Simulation; Energy criterion; Energy efficient; Long term planning; Static and dynamic obstacles; Static environment; Virtual agent; Energy efficiency",2-s2.0-84956618261
"Lee S., Choi H., Jin T., Lee S.-H.","Trajectory-free reactive stepping of physics-based character using momentum control",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956657779&doi=10.1145%2f2786784.2795144&partnerID=40&md5=28f78b4a006fea767d85690d600ce3f2","We introduce a trajectory-free reactive stepping controller using momentum control. The controller is characterized by moving passively in the direction of external pushes without attempting to follow some prescribed trajectory, thereby achieving a natural reactive stepping behavior adaptive to various perturbations.",,"Animation; Interactive computer graphics; Trajectories; Momentum control; Physics-based; Stepping controllers; Controllers",2-s2.0-84956657779
"Daviet G., Bertails-Descoubes F., Casati R.","Fast cloth simulation with implicit contact and exact coulomb friction",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956672297&doi=10.1145%2f2786784.2795139&partnerID=40&md5=dd3451d690116a4eb2a33ac1654fc173","Cloth dynamics plays a major role in the visual appearance of moving characters. Properly accounting for frictional contact is of utmost importance to avoid cloth-body penetration and to capture folding behavior due to dry friction. We present here the first method able to account for contact with exact Coulomb friction between a cloth and the underlying character. Our key contribution is to formulate and solve the frictional contact problem merely on velocity variables, by leveraging some tools of convex analysis. Our method is both fast and robust, allowing us to simulate full-size garments with more realistic body-cloth interactions compared to former methods, while maintaining similar computational timings.",,"Animation; Interactive computer graphics; Tribology; Cloth simulation; Convex analysis; Coulomb frictions; Folding behavior; Frictional contact; Frictional contact problems; Moving character; Visual appearance; Friction",2-s2.0-84956672297
"Piddington K., Levin D.I.W., Pai D.K., Sueda S.","Eulerian-on-lagrangian cloth",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956690369&doi=10.1145%2f2786784.2795138&partnerID=40&md5=7ffa8cfd815f397c01ccb4ea2729c353","We present a new, Eulerian-on-Lagrangian approach for modeling cloth. When a cloth modeled using the traditional Lagrangian approach is moved around an object with sharp corners, such as the edge of a table, the cloth cannot always bend smoothly around the object because it can bend only at its nodes. With our method, these constraints are built into the discretization of the cloth, giving us an equation of motion that directly honors these constraints. This allows the cloth to bend and move smoothly around such constraints. We show how our method can efficiently handle challenging simulations, such as pulling a table cloth from under wine glasses without knocking them over.","Cloth; Lagrangian mechanics; Simulation","Animation; Equations of motion; Fabrics; Interactive computer graphics; Discretizations; Equation of motion; Eulerian; La-grangian approaches; Lagrangian; Lagrangian mechanics; Sharp corners; Simulation; Lagrange multipliers",2-s2.0-84956690369
"Mostaghimi P., Armstrong R.T., Gerami A., Warkaini M.E., Ramandi H.L., Pinczewski V.","Micro-CT imaging and microfluidics for understanding flow in coal seam reservoirs",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020716069&partnerID=40&md5=72a79ec469b53130190bd0fc23af0877","We investigate transport through fractured coal samples using microfluidic experiment. Firstly, micro-CT imaging at dry and wet conditions are performed to identify subresolution natural fractures in coal (cleats). Scanning Electron Microscopy (SEM) is also performed to image cleats at resolution of 100 nm. A novel image segmentation method is developed to segment the micro-CT image and measure the fracture apertures based on SEM data. We fabricate micro-models based on observed geometrical features on the segmented coal images. Microfluidic facility and high speed video microscopy are used to capture displacement of gas by brine on the fabricated model. This is a first step for understanding and analysis of high-viscosity ratio displacement in complex coal cleat systems and to optimize gas recovery from coal beds.",,"Animation; Coal; Coal deposits; Fracture; High speed cameras; Image segmentation; Interactive computer graphics; Metal recovery; Microfluidics; Scanning electron microscopy; Coal cleat systems; Dry and wet conditions; Fracture apertures; Geometrical features; High viscosities; High-speed video; Natural fracture; Segmentation methods; Computerized tomography",2-s2.0-85020716069
"Azencot O., Vantzos O., Wardetzky M., Rumpf M., Ben-Chen M.","Functional thin films on surfaces",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956631469&doi=10.1145%2f2786784.2786793&partnerID=40&md5=501d415107743dffd6ddda5d96f2b66d","The motion of a thin viscous film of fluid on a curved surface exhibits many intricate visual phenomena, which are challenging to simulate using existing techniques. A possible alternative is to use a reduced model, involving only the temporal evolution of the mass density of the film on the surface. However, in this model, the motion is governed by a fourth-order nonlinear PDE, which involves geometric quantities such as the curvature of the underlying surface, and is therefore difficult to discretize. Inspired by a recent variational formulation for this problem on smooth surfaces, we present a corresponding model for triangle meshes. We provide a discretization for the curvature and advection operators which leads to an efficient and stable numerical scheme, requires a single sparse linear solve per time step, and exactly preserves the total volume of the fluid. We validate our method by qualitatively comparing to known results from the literature, and demonstrate various intricate effects achievable by our method, such as droplet formation, evaporation, droplets interaction and viscous fingering. © 2015 ACM.","Flows on curved surfaces; Free surface flows; Thin films","Animation; Drops; Interactive computer graphics; Curved surfaces; Droplet formation; Free-surface flow; Geometric quantities; Temporal evolution; Thin viscous films; Underlying surface; Variational formulation; Thin films",2-s2.0-84956631469
"Hahn F., Mutzel F., Coros S., Thomaszewski B., Nitti M., Gross M., Sumner R.W.","Sketch abstractions for character posing",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956700956&doi=10.1145%2f2786784.2786785&partnerID=40&md5=0b173b0cdeb8cb44098e7cd5bc95ff28","We propose a sketch-based posing system for rigged 3D characters that allows artists to create custom sketch abstractions on top of a character's actual shape. A sketch abstraction is composed of rigged curves that form an iconographic 2D representation of the character from a particular viewpoint. When provided with a new input sketch, our optimization system minimizes a nonlinear iterative closest point energy to find the rigging parameters that best align the character's sketch abstraction to the input sketch. A custom regularization term addresses the underconstrained nature of the problem to select favorable poses. Although our system supports arbitrary black-box rigs, we show how to optimize computations when rigging formulas and derivatives are available. We demonstrate our system's flexibility with examples showing different artist-designed sketch abstractions for both full body posing and the customization of individual components of a modular character. Finally, we show that simple sketch abstractions can be built on the fly by projecting a drawn curve onto the character's mesh. Redrawing the curve allows the user to dynamically pose the character. Taken together, our system enables a new form of intuitive sketch-based posing in which the character designer has the freedom to prescribe the sketch abstraction that is most meaningful for the character.","Character individualization; Sketch-based posing","Abstracting; Animation; Interactive computer graphics; Character individualization; Individual components; Iterative Closest Points; Optimization system; Regularization terms; Sketch-based posing; System supports; Under-constrained; Drawing (graphics)",2-s2.0-84956700956
"Ram D., Gast T., Jiang C., Schroeder C., Stomakhin A., Teran J., Kavehpour P.","A material point method for viscoelastic fluids, foams and sponges",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956648004&doi=10.1145%2f2786784.2786798&partnerID=40&md5=22c7313476d018120309ce66b67626b8","We present a new Material Point Method (MPM) for simulating viscoelastic fluids, foams and sponges. We design our discretization from the upper convected derivative terms in the evolution of the left Cauchy-Green elastic strain tensor. We combine this with an Oldroyd-B model for plastic flow in a complex viscoelastic fluid. While the Oldroyd-B model is traditionally used for viscoelastic fluids, we show that its interpretation as a plastic flow naturally allows us to simulate a wide range of complex material behaviors. In order to do this, we provide a modification to the traditional Oldroyd-B model that guarantees volume preserving plastic flows. Our plasticity model is remarkably simple (foregoing the need for the singular value decomposition (SVD) of stresses or strains). Lastly, we show that implicit time stepping can be achieved in a manner similar to [Stomakhin et al. 2013] and that this allows for high resolution simulations at practical simulation times.","Complex fluids; Elastoplastic; MPM; Physically-based modeling","Animation; Elasticity; Interactive computer graphics; Plastic flow; Strain; Structural design; Viscoelasticity; Complex fluids; Elastic strain tensor; Elasto-plastic; High resolution simulations; Material point methods; Physically based modeling; Vis-coelastic fluids; Volume-preserving; Singular value decomposition",2-s2.0-84956648004
"Sheth R., Lu W., Yu Y., Fedkiw R.","Fully momentum-conserving reduced deformable bodies with collision, contact, articulation, and skinning",2015,"Proceedings - SCA 2015: 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956653355&doi=10.1145%2f2786784.2786787&partnerID=40&md5=2cc0ee6d156df7a69f8c369528e71d58","We propose a novel framework for simulating reduced deformable bodies that fully accounts for linear and angular momentum conservation even in the presence of collision, contact, articulation, and other desirable effects. This was motivated by the observation that the mere excitation of a single mode in a reduced degree of freedom model can adversely change the linear and angular momentum. Although unexpected changes in linear momentum can be avoided during basis construction, adverse changes in angular momentum appear unavoidable, and thus we propose a robust framework that includes the ability to compensate for them. Enabled by this ability to fully account for linear and angular momentum, we introduce an impulse-based formulation that allows us to precisely control the velocity of any node in spite of the fact that we only have access to a lower-dimensional set of degrees of freedom. This allows us to model collision, contact, and articulation in a robust and high visual fidelity manner, especially when compared to penalty-based forces that merely aim to coerce local velocities. In addition, we propose a new ""deformable bones"" framework wherein we leverage standard skinning technology for ""bones, "" ""bone"" placement, blending operations, etc. even though each of our ""deformable bones"" is a fully simulated reduced deformable model.","Collisions; Deformable bodies; Elasticity; Model reduction; Skinning; Subspace","Angular momentum; Animation; Blending; Bone; Deformation; Degrees of freedom (mechanics); Elasticity; Interactive computer graphics; Collisions; Deformable bodies; Model reduction; Skinning; Subspace; Momentum",2-s2.0-84956653355
"Flahive M.-H.W., Chuang Y.-C., Li C.-M.","The multimedia piers-harris children's self-concept scale 2: Its psychometric properties, equivalence with the paper-and-pencil version, and respondent preferences",2015,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941975829&doi=10.1371%2fjournal.pone.0135386&partnerID=40&md5=ddea1cbc2991e9e0fc8e0afcf11f5a94","A multimedia version of Piers-Harris Children's Self-Concept Scale 2 (Piers-Harris 2) was created with audio and cartoon animation to facilitate the measurement of self-concept among younger children. This study aimed to assess the psychometric qualities of the computer version of Piers-Harris 2 scores, examine its score equivalence with the paper-andpencil version, and survey the respondent preference of the two versions. Two hundred and forty eight Taiwanese students from the first to fourth grade were recruited. In regard to the psychometric properties, high internal consistency (α = .91) was found for the total score of multimedia Piers-Harris 2. High interscale correlations (.77 to .83) of the multimedia Piers-Harris 2 scores and the results of confirmatory factor analysis suggested the multimedia Piers-Harris 2 contained good structural characteristics. The scores of the multimedia Piers-Harris 2 also had significant correlations with the scores of the Elementary School Children's Self Concept Scale. The equality of convergence and criterion-related validities of Piers-Harris 2 scores for the multimedia and paper-and-pencil versions and the results of ICCs between the scores of the multimedia and paper-and-pencil Piers-Harris 2 suggested their high level of equivalence. Participants showed more positive attitudes towards the multimedia version. Copyright: © 2015 Flahive et al.",,"Article; child; child behavior; controlled study; Elementary School Children Self Concept Scale; female; human; human experiment; intermethod comparison; male; multimedia; multimedia Piers Harris Children Self Concept Scale 2; paper and pencil version of Piers Harris Children Self Concept Scale 2; psychologic test; psychological rating scale; psychometry; self report; Taiwanese; emotion; procedures; psychometry; questionnaire; reproducibility; self concept; social class; Taiwan; validation study; Child; Child Behavior; Emotions; Female; Humans; Male; Multimedia; Psychometrics; Reproducibility of Results; Self Concept; Social Class; Surveys and Questionnaires; Taiwan",2-s2.0-84941975829
"Eckert M., Gomez-Martinho I., Meneses J., Martinez Ortega J.F.","A multi functional plug-in for exergames",2015,"Proceedings of the International Symposium on Consumer Electronics, ISCE",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953278069&doi=10.1109%2fISCE.2015.7177798&partnerID=40&md5=e46d0b0011db2731fb198fcd3bb6583c","This paper describes the development of a software complement for Blender (a freely available animation software) which allows to insert motion data obtained from a motion capture camera device. The main target is to provide Blender with a tool to develop exergames, i.e. serious games for performing physical exercises, which are fully adaptive to the user's needs and capabilities, especially addressing chronical patients or handicapped. The plugin incorporates both: motion control and recording, allowing to store user movements. Transmission is realized via the OSC (Open Sound Control) protocol. The tool is still under development, here a first version is presented showing its functionalities in a demo-game. In the future, sensor data from other devices is planned to be integrated. © 2015 IEEE.","Blender; Context awareness; e-health; HCI; motion capture camera device; natural interface; Rehabilitation; serious gaming","Animation; Cameras; Consumer electronics; Human computer interaction; Patient rehabilitation; Blender; Camera devices; Context- awareness; E health; Natural interfaces; Serious gaming; Blending",2-s2.0-84953278069
"Shen C., Hahn T., Parker B., Shen S.","Animation recipes: Turning an animator's trick into an automatic animation system",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957940932&doi=10.1145%2f2775280.2792531&partnerID=40&md5=e07fcc6bd43e6c6bb1d7274aa78dad3f","With a traditional key frame animation system, animators author a tremendous number of key frames across many animation variables (avars) manually. In particular, with cycles or ambient body motion, animators have a simple but powerful trick to avoid having to do this. They hand animate the avar that is driving the motion, then duplicate and transform the motion on that avar to other detailed avars throughout the body. We have generalized this trick into a system that turns rough blocking, done with a minimum number of avars, into fully detailed animation with the click of a button.",,"Computer graphics; Interactive computer graphics; Animation systems; Automatic animations; Body motions; Key frames; Animation",2-s2.0-84957940932
"Ouni S., Gris G.","Dynamic realistic lip animation using a limited number of control points",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959374673&doi=10.1145%2f2787626.2787628&partnerID=40&md5=ef3797585aa47b1ef2649c8469e85d5b","One main concern of audiovisual speech research is the intelligibility of audiovisual speech (i.e., talking head). In fact, lip reading is crucial for challenged population as hard of hearing people. For audiovisual synthesis and animation, this suggests that one should pay careful attention to modeling the region of the face that participates actively during speech. Above all, a facial animation system needs extremely good representations of lip motion and deformation in order to achieve realism and effective communication.",,"Animation; Audition; Computer graphics; Speech intelligibility; Speech processing; Audio-visual speech; Control point; Effective communication; Facial animation; Hard of hearings; Lip animation; Lip motions; Talking heads; Interactive computer graphics",2-s2.0-84959374673
"Stelzleni R., Parker B., Hahn T., Shen S., McGarry D., Shen C.","Sketch to pose in Pixar's presto animation system",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958019700&doi=10.1145%2f2775280.2792583&partnerID=40&md5=59b58e8852b79d7e799c7eb43d7fe424","Animation rigs for key frame animation typically offer guides for direct manipulation of a model. For example, elbow rotation is conveniently specified by dragging a rotational ring guide. However, these simple guides can be cumbersome and time-consuming to use when posing structures involving multiple joints, such as a prehensile long neck or tail. In this work, we present a convenient interface to pose multiple joints at once by snapping them to a user-drawn stroke.",,"Animation; Computer graphics; Animation systems; Direct manipulation; Key frames; Multiple joints; Interactive computer graphics",2-s2.0-84958019700
"Byun D.J., Falt H., Frost B., Ali M., Daniels E., De Mund P., Kaschalk M.","Procedural animation technology behind microbots in Big Hero 6",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958012459&doi=10.1145%2f2775280.2792533&partnerID=40&md5=a0cca0ec4557e17a7f9d685cb1f43a0b","In Big Hero 6, tens of millions of tiny robots called Microbots connect together via electromagnetism to create dynamic animated structures. The Microbots rearrange by passing each other over bundles of themselves. In order to achieve a high level of precise control for elaborate art direction, we developed specific procedural animation algorithms.",,"Animation; Computer graphics; Microbots; Precise control; Procedural animation; Interactive computer graphics",2-s2.0-84958012459
"Wu L.-C., Li J.-Y., Huang Y.-H., Ouhyoung M.","First-person view animation editing utilizing video see-through augmented reality",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959353552&doi=10.1145%2f2787626.2787656&partnerID=40&md5=e7bc36ae2a94408a5580e5b11b3f8a01","In making 3D animation with traditional method, we usually edit 3D objects in 3-dimension space on the screen; therefore, we have to use input devices to edit and to observe 3D models. However, those processes can be improved. With the improvement in gesture recognition nowadays, virtual information operations are no longer confined to the mouse and keyboard. We can use the recognized gestures to apply to difficult operations in editing model motion. And for observing 3D model, we would use head tracking from external devices to improve it. It would be easy to observe the in- Teractive results without complicated operation because the system will accurately map the real world head movements.",,"Animation; Augmented reality; Computer graphics; Content based retrieval; Interactive computer graphics; 3-d modeling; Animation editing; First person; Head movements; Head tracking; Input devices; Modeling motions; Virtual information; Gesture recognition",2-s2.0-84959353552
"Cowles J., Tejima T., Yu D.","Real-time crowd visualization in point-cached pipelines",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957959778&doi=10.1145%2f2775280.2792586&partnerID=40&md5=20726d4847d562396e1183632973e884","In computer animation, a crowd of characters can create a dramatic visual impact and make an expansive set feel like it's teeming with life. To orchestrate this large scale animation, technical directors use procedural tools to author animation en masse. The character animation is created by animators for an array of background models, such as walk cycles, action transitions, and reactions. Despite being modeled and rigged specifically as a background character, deformation of crowd characters is still driven by high fidelity rigs that are too expensive to execute in real-time, even for small scale crowds. Background characters are designed to have parametric controls to create visual diversity, which require heavier mesh geometry to support such variation. The character structure must support standard shading and lighting workflows, which result in characters that include separate object primitives for skin, hair, and clothing, and frequently even more fine grained objects for eyes, teeth, fingernails, etc.",,"Computer graphics; Geometry; Interactive computer graphics; Background model; Character animation; Computer animation; Fine grained; High-fidelity; Mesh geometry; Parametric control; Visual impacts; Animation",2-s2.0-84957959778
"Kagiyama H., Kawai M., Kuwahara D., Kato T., Morishima S.","Automatic synthesis of eye and head animation according to duration and point of gaze",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959366104&doi=10.1145%2f2787626.2792607&partnerID=40&md5=9ee16c316dfee54be4a2ba5da2bf62f0","In movie and video game productions, synthesizing subtle eye and corresponding head movements of CG character is essential to make a content dramatic and impressive. However, to complete them costs a lot of time and labors because they often have to be made by manual operations of skilled artists. [Itti et al. 2006] and [Yeo et al. 2012] proposed an automatic eyes and head's motion control method by measuring a real person watching a displayed gaze point. However, in both approaches, a rotational angle and speed of eyes and head are treated together uniformly depending on the gaze point location. Specifically, dis-playing duration time of gaze target strongly influences the motion of eyes and head because the shorter the blink interval of a gaze target is, the more quickly a human response becomes to chase the target by the combination of eye rotation and head movement. In this paper, we propose a method to automatically control eyes and head by taking account of both gaze target location and its blink time duration. As a result, eye and head movement are mod-eled combined with measured data by a function whose arguments are gaze point angle and duration time. So a variety of gaze action along with head motion including Ves-tibule-ocular Reflex can be generated automatically by changing the parameters of a gaze angle and duration.",,"Animation; Computer graphics; Interactive computer graphics; Motion control; Automatic synthesis; Duration time; Head movements; Human response; Manual operations; Point of gaze; Rotational angle; Target location; Eye movements",2-s2.0-84959366104
"Bang S., Choi B., Ribera R.B.I., Kim M., Lee S.-H., Noh J.","Interactive rigging",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959361753&doi=10.1145%2f2787626.2787659&partnerID=40&md5=f047065cab0e9ce2792908d1d70138ff","Skeleton-driven animation is a widespread technique, which is frequently used in film and video game productions to animate 3D characters. The process of preparing characters for skeletal animation is referred to as character rigging. Commercial applications such as Maya or 3DS Max provide many tool that support this process, including the 'joint tool' and the 'paint skin weights tool'. Most of these tools are difficult to use for novice users. Even for professional artists, it requires many hours of intensive effort. We approach the rigging process from a semi-automatic point of view, integrating the skeleton creation process with the skinning of the mesh into an interactive rig editing system. We also maintain an important degree of control over the final result of the rig, especially in its ability to refine the skinning results. Our method begins by providing an automatically generated, fully skinned rig as a starting point for interactive editing. In this framework, the skeleton structure and the skin weights can be interactively edited with the provided manipulation tools while receiving immediate visual feedback of the current state of the rig.",,"Animation; Computer graphics; Feedback; Musculoskeletal system; Three dimensional computer graphics; Visual communication; Automatically generated; Commercial applications; Degree of control; Interactive editing; Manipulation tools; Skeletal animation; Skeleton driven animations; Skeleton structure; Interactive computer graphics",2-s2.0-84959361753
"Casas D., Alexander O., Feng A.W., Fyffe G., Ichikari R., Debevec P., Wang R., Suma E., Shapiro A.","Blendshapes from commodity RGB-D sensors",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957944664&doi=10.1145%2f2775280.2792540&partnerID=40&md5=a6145b3a3a02581e6511e8db8eed5d93","Creating and animating a realistic 3D human face is an important task in computer graphics. The capability of capturing the 3D face of a human subject and reanimate it quickly will find many applications in games, training simulations, and interactive 3D graphics. We demonstrate a system to capture photorealistic 3D faces and generate the blendshape models automatically using only a single commodity RGB-D sensor. Our method can rapidly generate a set of expressive facial poses from a single depth sensor, such as a Microsoft Kinect version 1, and requires no artistic expertise in order to process those scans. The system takes only a matter of seconds to capture and produce a 3D facial pose and only requires a few minutes of processing time to transform it into a blendshape-compatible model. Our main contributions include an end-to-end pipeline for capturing and generating face blendshape models automatically, and a registration method that solves dense correspondences between two face scans by utilizing facial landmarks detection and optical flows. We demonstrate the effectiveness of the proposed method by capturing different human subjects and puppeteering their 3D faces in an animation system with real-time facial performance retargeting.","Blendshapes; Depth sensors; Face animation; RGB-D","Animation; Computer graphics; Face recognition; Interactive computer graphics; Animation systems; Blendshapes; Dense correspondences; Depth sensors; Face animation; Microsoft kinect; Registration methods; Training simulation; Three dimensional computer graphics",2-s2.0-84957944664
"Fleischer K., Isaacs P., Parker B., Haux B., Shen S., Krishna V., Shen C., Butts A., Price J., Hahn T., Lee H., Yu D.","Silhouette sketching on ""Inside out""",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957965332&doi=10.1145%2f2775280.2792566&partnerID=40&md5=96f4d536f0bb4c62c06ed44c4a7f82f4","In hand-drawn 2D animation, artists have direct control over the image. Silhouette lines are drawn with a specific intent, e.g. an elbow might be drawn as a curve, or with a sharp angle. By contrast, in 3D animation, direct silhouette control is often lost. Animators pose a 3D model with an abstract control like ""elbow bend"" and the resulting silhouette is whatever the character rigging provides. Our goal was to create a tool to enable our animators to be able to sculpt the silhouettes quickly, in context, without requiring special expertise or assistance from riggers and modelers. During ""Inside Out"" this new sketch-based tool saw heavy use for modifying silhouettes of hero character's faces and bodies as well as for fine-tuning cloth simulation results.",,"Animation; Computer graphics; 2D animation; 3-d modeling; 3D animation; Abstract control; Cloth simulation; Direct control; Fine tuning; In contexts; Interactive computer graphics",2-s2.0-84957965332
"Yan Y., Ju T., Letscher D., Chambers E.","Burning the medial axis",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959370113&doi=10.1145%2f2787626.2792658&partnerID=40&md5=ff588d9dbaa5538e1aa0f10fae63960f","Medial axis is a classical shape descriptor that is widely used in computer graphics, computer vision, and pattern recognition. Defined elegantly as the locus of points with multiple nearest neighbors on the object boundary, the medial axis preserves both the structure and topology of the object in a compact form - A geometry that has one lower dimension than the object itself. In many applications, medial geometry at even lower dimensions are desirable. For example, the medial curve of a 3D object is useful for deformable shape matching and character animation. The medial point of an object is useful for object alignment and tracking. Although numerous heuristic approaches have been developed for computing medial curves and points of a 3D object, there has been little progress in developing a sound mathematical definition of these lower-dimensional medial geometry. To the best of our knowledge, the only definition of the medial curve of a 3D object was proposed in [Dey and Sun 2006]. However, their definition is quite different from that of the medial axis, and the defined medial curve is not guaranteed to preserve the topology of the object, which is a key property of the medial axis.",,"Animation; Computer graphics; Computer vision; Heuristic methods; Image processing; Interactive computer graphics; Pattern recognition; Topology; Character animation; Deformable shapes; Heuristic approach; Mathematical definitions; Medial axis; Nearest neighbors; Object boundaries; Shape descriptors; Geometry",2-s2.0-84959370113
"Hamed Y., Kahwaty J., Lin A., Goldberg E., Chai L.","Crowd character complexity on BIG HERO 6",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957964330&doi=10.1145%2f2775280.2792571&partnerID=40&md5=40eda92b8a2c7e9ee33636d54fd55749","On Disney's Big Hero 6, we needed to create the city of San Fransokyo with unparalleled levels of visual complexity. The cityscape has more buildings and more geometry than any prior Disney film. Inhabiting this city are hundreds of unique characters, each performing a high caliber of animation individually and as a group. These challenges prompted a major upgrade to our existing crowd pipeline and the development of several new technologies in authoring crowd characters, generating crowd animation cycles, and instancing crowds for rendering.",,"Animation; Computer graphics; Crowd animation; Visual complexity; Interactive computer graphics",2-s2.0-84957964330
"Lin A., Lee G.S., Longson J., Steele J., Goldberg E., Stefanovic R.","Achieving real-time playback with production rigs",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957954473&doi=10.1145%2f2775280.2792519&partnerID=40&md5=de482a34fac9cbcabe7a7af7c4ece414","Rig speed is of paramount importance to animation pipelines. Realtime performance provides immediate feedback to artists thereby increasing the number of possible iterations and ultimately leading to higher quality animation. This paper presents a novel method for real-time playback of production rigs inside a host application, such as Maya, without sacrificing functionality or ease of use. Realtime performance is achieved by augmenting the host with Nitro, a replacement strategy for OpenGL drawing events, RigCache, a caching system for minimizing scene graph evaluations, and Parade, a distributed system for scheduling cache updates. Only minimal rig changes are required for the three tools to collectively optimize playback. The result is a seamless experience that is natural, unobtrusive, and preserves familiar work flows.",,"Animation; Application programming interfaces (API); Computer graphics; Animation pipeline; Caching system; Distributed systems; Ease-of-use; Immediate feedbacks; Real time performance; Replacement strategy; Seamless experience; Interactive computer graphics",2-s2.0-84957954473
"Gabai I., Lai A.","Hand-Drawn looking volumetric effects in the Peanuts Movie",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957945831&doi=10.1145%2f2775280.2792536&partnerID=40&md5=2b21f8903314332cc97abac1e77f10d1","For the first time in the franchise's history, the Peanuts gang is being brought to life in a CG feature film. The biggest challenge we faced was how to successfully maintain the iconic style established over the past 60 years. Some of the FX requirements for this film included the need to maintain a 'hand drawn' look, to obey cartoon physics, and to animate on 2's (matching character animation). To achieve this we departed from our usual simulation techniques, and developed a mix of hand-animated and procedural techniques.",,"Animation; Computer graphics; Motion pictures; Character animation; Feature films; Hand-drawn; Simulation technique; Interactive computer graphics",2-s2.0-84957945831
"Knowles B., Fryazinov O.","Increasing realism of animated grass in real-time game environments",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959450606&doi=10.1145%2f2787626.2787660&partnerID=40&md5=56e9817ffe664d28b4c82188b8a4904e","With the increasing quality of real-time graphics it is vital to make sure assets move in a convincing manner otherwise the players immersion can be broken. Grass is an important area as it can move substantially and often takes up a large portion of screen space in games. Animation of grass is a subject to academic research [Fernando 2004; Perbet and Cani 2001] as well as a technology which is implemented in a number of video games. The list includes, but is not limited to, games such as Far Cry 4, Battlefield 4, Dear Esther and Unigine Valley. Comparing video games assets with reality, it can be seen that the current methods have a number of problems which decrease the realism of the resulting grass animation. These problems include: 1) the visible planar nature of grass geometry and 2) problems with the grass movement which include over-connectivity of grass blades in respect to their neighbours, no obvious wind direction and exaggerated swaying motions. In this paper we propose to increase realism of the grass by focusing on its movement. Themain contributions of this work are: 1) Distinguishing ambient and directional components of the wind and 2) The method for calculating directional wind by using a grayscale map and wind vector. The grass was implemented with vertex shaders in line with the majority of methods described in academic literature (e.g. [Fernando 2004]) and implemented in modern games.",,"Computer graphics; Human computer interaction; Interactive computer graphics; Wind effects; Academic literature; Academic research; Directional component; Grayscale maps; Real time graphics; Real-time games; Swaying motions; Wind directions; Animation",2-s2.0-84959450606
"Chiang I., Lin P.-H., Chang Y.-H., Ouhyoung M.","Synthesizing close combat using sequential Monte Carlo",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959343696&doi=10.1145%2f2787626.2787638&partnerID=40&md5=c707e17b175cc265f93d9ff5079d9b4c","Synthesizing competitive interactions between two avatars in a physics-based simulation remains challenging. Most previous works rely on reusing motion capture data. They also need an of- fline preprocessing step to either build motion graphs or perform motion analysis. On the other hand, an online motion synthesis al- gorithm [Hämaläinen et al. 2014] can produce physically plausible motions including balance recovery and dodge projectiles without prior data. They use a kd-tree sequential Monte Carlo sampler to optimize the joint angle trajectories. We extend their approach and propose a new objective function to create two-character animations in a close-range combat. The principles of attack and defense are designed according to fundamental theory of Chinese martial arts. Instead of following a series of fixed Kung Fu forms, our method gives 3D avatars the freedom to explore diverse movements and through pruning can finally evolve an optimal way for fighting.",,"Computer graphics; Interactive computer graphics; Three dimensional computer graphics; Balance recoveries; Character animation; Competitive interactions; Motion capture data; Objective functions; Physics-based Simulation; Pre-processing step; Sequential Monte Carlo; Monte Carlo methods",2-s2.0-84959343696
"Park J., Kim M., Ki S., Seo Y., Shin C.","Half frame forwarding: Frame-rate up conversion for tiled rendering GPU",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959322914&doi=10.1145%2f2787626.2787634&partnerID=40&md5=73052bf31730880127b7dd732d8d6dd9","Although the mobile industry has recently begun trending towards high quality graphics content, it is still difficult to satisfy this trend due to performance, power and thermal issue of GPU/CPU in mobile application processor. The power consumption of mobile GPU increases almost linearly with workload, depending on the graphics content. Thus, lowering the frame rate can reduce the power consumption. Some applications force the skipping of some frames during rendering in order to decrease the frame rate. Although this feature can be exploited at runtime in order to reduce the power consumption, it can make noticeable artifacts such as flickering and lagging. One common technique to help remedy these artifacts is a frame rate up conversion (FRUC) algorithm[Bowles 2012], which typically consist of two processes to determine the dynamic objects in consecutive frames: motion estimation and motion-compensated interpolation. But, those have high computational costs and, naturally, result in high power consumption. Thus, the conventional approaches are not suitable for mobile devices. In this work, we propose a novel FRUC algorithm based on a half frame forwarding approach with a low cost solution to detect dynamic objects for tile-based GPU rendering. The proposed algorithm makes intermediate frames using the tiles that cover a region with dynamic objects. Using an LG G3 Screen, our experimental result demonstrates that the proposed algorithm can reduce the system power consumption by up to 20.4%.",,"Algorithms; Animation; Computer graphics; Computer graphics equipment; Electric power utilization; Image coding; Interactive computer graphics; Mobile devices; Motion compensation; Motion estimation; Computational costs; Conventional approach; Frame rate up conversion; High power consumption; High-quality graphics; Low-cost solution; Mobile application processor; Motion compensated interpolation; Rendering (computer graphics)",2-s2.0-84959322914
"Wooley K., Jang Y., Lockwood N.","Raptor wrangling: Real-time motion capture for jurassic world",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957933080&doi=10.1145%2f2775280.2792532&partnerID=40&md5=e0d5e36c6c0e0c9262d7f3f156308b73","Inspired by the first Jurassic Park, where the velociraptors were ani-matronic suits worn by performers, Industrial Light & Magic (ILM) used real-time motion capture as the basis for the animation of the raptors and other bipedal dinosaurs in Jurassic World. Using ILM's Zeno application framework, we built a system for real-time retargeting and visualization of hero characters which was tightly integrated into our asset and shot production pipeline. During motion capture sessions, our system allowed us to visualize the actors' performances on up to four creatures at 24 frames per second, with the same geometric detail and rig complexity which artists work with offline. This gave our animation director the confidence to capture multiple takes and select performances, knowing that the motion would look identical in shot and be a solid foundation for animation to build upon.",,"Animation; Computer graphics; Application frameworks; Frames per seconds; Geometric details; Jurassic; Motion capture; Production pipelines; Real time; Real-time motion; Interactive computer graphics",2-s2.0-84957933080
"Angelidis A., Merrell J., Moyer B., Reisch A.","Developing joy for inside out",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957963955&doi=10.1145%2f2775280.2792560&partnerID=40&md5=a707bf3757b0132c1cd55443dcaedc90","The main character of Pixar Animation Studio's Inside Out is Joy, a personification of the human emotion. The art and technical departments were tasked with realizing a complete abstract into an animatable character. Moreover, since Joy was a main character, she would be used in over 750 shots in a wide range of poses, situations, and lighting setups. She needed to feel like a magical effect, but work and react as dependably as a more traditional character.",,"Computer graphics; Animation studios; Human emotion; Interactive computer graphics",2-s2.0-84957963955
"Byun D.J., Wadia Z., Kaschalk M.","Interactive script based dynamics in Big Hero 6",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958025655&doi=10.1145%2f2775280.2792534&partnerID=40&md5=a865092a10cd5e3ab971cec3bd78d461","In production environments, dynamic effects have been commonly done by rigid body simulations or particle simulations. In Big Hero 6, we set up a directable and very efficient rig for dynamic effects. We used motion equations in VEX script to calculate and control the dynamic terms of each geometry piece without using solvers. This rig was implemented in a history independent procedural animation context and it provided artists more room for art direction and fine tuning. In most cases, we could control the motion in real time. If necessary, we used parts of the geometry pieces for motion design, in order to maintain the interactivity.",,"Computer graphics; Equations of motion; Dynamic effects; History independents; Interactivity; Motion design; Particle simulations; Procedural animation; Production environments; Rigid-body simulations; Interactive computer graphics",2-s2.0-84958025655
"Heller S., Petrov M., Reed M., Song S., Tomaino N., Vanseth S.","Head, shoulders, knees and toes: Interpreting schulz in 3D",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957937941&doi=10.1145%2f2775280.2775290&partnerID=40&md5=27302de23a9c48866561d48f9f68b6b1","The original Peanuts material, defined by Charles Schulz' unique 2D language, presented a huge challenge to the development of The Peanuts Movie (2015). It required Blue Sky Studios to go beyond a mere conversion from 2D to 3D by embracing the 2D artwork and finding a unique look and fresh animation style in the spirit of the original comic strip. Three of the most recognizable and unique aspects of Schulz' work are his use of silhouette and ink line work for the drawings of the eyes, the extreme character poses implied by the comic strip, and the highly stylized indication of motion blur. To achieve a respectful 3D equivalent we found a language for the surrounding, prominent ink or expression lines by implementing sliding eyes and 'poseable' textures for animation. Additionally, we developed a unique multi-part character setup, and an approach to 3D motion blur that was inspired by the original 2D techniques of ""multiples"" and ""smears"". These techniques gave us the flexibility we needed to keep the Peanuts look while still being renderable in our photorealistic pipeline.",,"Animation; Computational linguistics; Computer graphics; 2D languages; 2D-To-3D; 3D motion; Blue sky studios; Comic strips; Line works; Motion blur; Photo-realistic; Interactive computer graphics",2-s2.0-84957937941
"Antoine F., Brucks R., Karis B., Moran G.","The boy, the kite and the 100 square mile real-time digital backlot",2015,"ACM SIGGRAPH 2015 Talks, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958025878&doi=10.1145%2f2775280.2775289&partnerID=40&md5=7118bc2f81bb3483c4987605f1ed9937","To make a short animated film in a brief period of time is in itself a challenge. To make a short animated piece using tech you haven't developed and assets you haven't created for a unmovable deadline is beyond terrifying. While we had a general plan in place as well as an approved design for our main character as well as photographs we planned to process into our world assets we had nothing else. On the 5th of January we came back to work after our Christmas break and embarked on what was one of the most challenging 57 days of our professional careers.",,"Animation; Computer graphics; Employment; Motion pictures; Christmas; Professional careers; Real time; Interactive computer graphics",2-s2.0-84958025878
"Jiao S., Tong X., Li E., Li W.","Dynamic fur on mobile using textured offset surfaces",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959420059&doi=10.1145%2f2787626.2787649&partnerID=40&md5=bf8dc37e60b885b581abfce61bf263cb","Fur simulation is crucial in many graphic applications since it can greatly enhance the realistic visual effect of virtual objects, e.g. animal avatars. However, due to its high computational cost of massive fur strands processing and motion complexity, dynamic fur is regarded as a challenging task, especially on the mobile platforms with low computing power. In order to support real-time fur rendering in mobile applications, we propose a novel method called textured offset surfaces (TOS). In particular, the furry surface is represented by a set of offset surfaces, as shown in Figure 1(a). The offset surfaces are shifted outwards from the original mesh. Each offset surface is textured with scattering density (red rectangles in Figure 1(a)) to implicitly represent the fur geometry, whose value can be changed by texture warping to simulate the fur animation. In order to achieve high quality anisotropic illumination result, as shown in Figure 1(b), Kajiya/Banks lighting model is employed in the rendering phase.",,"Computer graphics; Rendering (computer graphics); Computational costs; Computing power; Graphic applications; Mobile applications; Motion complexity; Original meshes; Scattering density; Texture warping; Interactive computer graphics",2-s2.0-84959420059
"Kresa B., Harker J.","Shogyu Mujo",2015,"ACM SIGGRAPH 2015 Emerging Technologies, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957932927&doi=10.1145%2f2782782.2785591&partnerID=40&md5=a4b4ea9cdfebabc41986beac7dc7b623","Shogyo Mujo utilizes 360° projection mapping to take artistic sculpture to the next level as temporal dimensional artwork that pulsates to music. The skull is a three-dimensional structure designed by Josh Harker, with projection and animation developed by BARTKRESA design. With over 30 perfectly mapped animations, and an extensive set of real time looks, audiences at Siggraph will get a chance to experience the constantly changing artwork, and interact with the skull through a touch interface developed in collaboration with Coolux's Pandora's Box. Shogyo Mujo is a transient 3D projection-mapped skull collaboration between design firm BARTKRESA design and artist Joshua Harker. The installation represents the 1st of the 3 marks of Dharma which states that all things are impermanent. It is visualized through a myriad of mappings that create dozens of unique experiences.","3D; Art; Design; Projection mapping; Sculpture","Computer graphics; Design; Mapping; Design firms; Real time; Sculpture; Three-dimensional structure; Touch interfaces; Interactive computer graphics",2-s2.0-84957932927
"Schmal K.A., Thomas C., Cushing J., Orr G.","Visualizing valley wind flow",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959350665&doi=10.1145%2f2787626.2792647&partnerID=40&md5=ca133b26a45226841b464045db74d11d","The field of micrometeorology is primarily concerned with smaller-scale meteorological phenomena, specifically those which occur within the lowest atmospheric layer called the Atmospheric Boundary Layer (ABL). The primary defining characteristic of the ABL is that wind dynamics within this layer are influenced by the Earth's topography, as well as time-dependent temperature changes in the Earth's surface. In forests and connected valleys, weak-wind flows transport moisture, heat, gases and potential contaminants, directly impacting adjacent ecosystems [Thomas et al. 2012]. Although weak-wind transport is a known phenomenon, it is also poorly understood. We created animations and visualizations of data collected in the ABL at H. J. Andrews. These visualizations improve upon the previous available visualizations (which were produced by the data collection equipment), by placing the data spatially, allowing for a more intuitive understanding of the data.",,"Boundary layers; Computer graphics; Interactive computer graphics; Visualization; Atmospheric layers; Data collection; Earth's surface; Intuitive understanding; Meteorological phenomena; Potential contaminants; Time-dependent temperature; Wind dynamics; Atmospheric boundary layer",2-s2.0-84959350665
"Kato T., Kato A., Okamura N., Kanai T., Suzuki R., Shirai Y.","Musasabi: 2D/3D intuitive and detailed visualization system for the forest",2015,"ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959373396&doi=10.1145%2f2787626.2792621&partnerID=40&md5=dd9108f5e23867d523f17cbffa06e40c","Trees have been a pillar of our lives not just for human but for all the species living in the earth. Despite of its blessings for our lives, the heaps of problems around forestry have not been solved. One of the major problems in this field is that most of the forest are not been sorted into an organized database. Detailed natural data have never been provided even in famous map applications, Google earth for instance, induced from its difficulty. The forest database has been demanded in many regions as it provides beneficial information for both industrial and environmental aspects. It even helps many divisions such as CG animations to simulate not only a tree itself but also the mountain or the forest as a whole depending on given natural conditions. One of the major solutions to efficiently collect data of the forest is to use the image and 3D data that are acquired from the sky as represented by the method proposed by [Vihervaara et al.2015]. While these algorithms showed the effectiveness to many regions, they only provided solutions to areas that can easily measure from the sky. In addition, these data are not understandable for unspecialized users. As a result, it has been questionable to be used in many areas with more intense natural environment and less technical knowledge such as tropical areas. Summarizing the above, the system which satisfies the usability for both the measuring process and visualization system is required. We propose a novel device and interface, which we named ""Musasabi"" to create database automatically from the acquired data from our original measuring device and visualize it onto the 2D/3D map. Our unique device enables us to acquire many different data of the forest with easy manipulation that cannot be acquired from long range sensors proposed in previous work. Our system allows users interactive and intuitive controls to the database to easily use and develop for various demands without deep knowledge of forestry, device and coding.",,"Computer graphics; Database systems; Interactive computer graphics; Timber; Visualization; Deep knowledge; Environmental aspects; Google earths; Intuitive controls; Measuring device; Natural conditions; Natural environments; Visualization system; Forestry",2-s2.0-84959373396
"Li Y., Tao X., Lu J.","Rate-distortion optimized inter-frame compression for parameter-driven animation",2015,"2015 Picture Coding Symposium, PCS 2015 - with 2015 Packet Video Workshop, PV 2015 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945924802&doi=10.1109%2fPCS.2015.7170071&partnerID=40&md5=4ea30452a8420ec5dc8cf61f24bb4303","As an important computer graphics technique, parameter-driven animation has seen increasing deployment on mobile platforms, where both communication bandwidth and device storage are subjected to stringent constraints. We propose an efficient rate-distortion optimized inter-frame compression scheme for parameter-driven animation capable of finding optimal bit-allocations for any given bit-rate. Experiments conducted on face animation based on active appearance models demonstrate that with the proposed method, the transmission and storage requirements of parameter-driven animation can be significantly reduced. © 2015 IEEE.","AAM; inter-frame compression; multiple-choice knapsack; parameter-driven animation; rate-distortion optimization","Animation; Computer graphics; Electric distortion; Image coding; AAM; Inter-frame; Multiple choice; Parameter-driven; Rate-distortion optimization; Signal distortion",2-s2.0-84945924802
"Schweiger F., Thomas G., Sheikh A., Paier W., Kettern M., Eisert P., Franco J.-S., Volino M., Huang P., Collomosse J., Hilton A., Jantet V., Smyth P.","RE@CT: A new production pipeline for interactive 3D content",2015,"2015 IEEE International Conference on Multimedia and Expo Workshops, ICMEW 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945565414&doi=10.1109%2fICMEW.2015.7169830&partnerID=40&md5=a03f5c1090a3ee2bfa05d97560b41d0d","The RE@CT project set out to revolutionise the production of realistic 3D characters for game-like applications and interactive video productions, and significantly reduce costs by developing an automated process to extract and represent animated characters from actor performance captured in a multi-camera studio. The key innovation is the development of methods for analysis and representation of 3D video to allow reuse for real-time interactive animation. This enables efficient authoring of interactive characters with video quality appearance and motion. © 2015 IEEE.","3D video processing; education; interactive content; serious gaming","Animation; Automation; Education; Video signal processing; 3-D videos; Animated characters; Automated process; Game-like applications; Interactive animations; Interactive contents; Interactive video; Serious gaming; Three dimensional computer graphics",2-s2.0-84945565414
"Volk G.F., Pototschnig C., Mueller A., Foerster G., Koegl S., Schneider-Stickler B., Rovo L., Nawka T., Guntinas-Lichius O.","Teaching laryngeal electromyography",2015,"European Archives of Oto-Rhino-Laryngology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929701976&doi=10.1007%2fs00405-015-3568-y&partnerID=40&md5=9d346f447ac13cd9407e586517b8afc4","To achieve consensus in the methodology, interpretation, validity, and clinical application of laryngeal electromyography (LEMG), a working group on neurolaryngology from the European Laryngological Society (ELS) was founded in 2010. The main task of the working group was to teach key techniques like LEMG procedures. The objective of this study was to collect information on the teaching techniques used and describe them. A multicenter registry was created to analyze the data collected from LEMGs in 14 departments. We screened how often different departments participated in teaching events. Teaching events were classified retrospectively: presentations at conferences and meetings; workshops with hands-on training on patients; workshops with hands-on training on animal models; workshops with hands-on training on anatomic specimens; and supervision by experts to perform LEMG together. Both, supervision to perform LEMG together and the total number of PCA–LEMGs (r = 0.713), as well as supervision to perform LEMG together and the PCA/total-number-of-LEMG ratio (r = 0.814) were correlated significantly (p < 0.05). Similarly, the sum of teaching events was correlated significantly with the total number of PCA–LEMGs (r = 0.605), and so did the sum of teaching events with the PCA/total-number-of-LEMG ratio (r = 0.704). Participation in hands-on training in humans was correlated significantly with the PCA/total-number-of-LEMG ratio (r = 0.640). The data presented herein suggest that multimodal teaching techniques are most effective. To promote multimodal learning an interactive webpage (http://www.lemg.org) providing videos and animations, and the possibility to discuss cases with other experts was established. © 2015, Springer-Verlag Berlin Heidelberg.","Computer-assisted learning; European Laryngological Society; Laryngeal electromyography; Neurolaryngology; Teaching","animal experiment; Article; cadaver; electromyography; human; human tissue; laryngeal electromyography; medical education; nonhuman; priority journal; professional competence; professional practice; retrospective study; standardization; workshop; consensus; education; Europe; Laryngeal Diseases; larynx; medical society; needs assessment; neurology; otorhinolaryngology; pathology; procedures; register; reproducibility; standards; teaching; Consensus; Electromyography; Europe; Humans; Laryngeal Diseases; Larynx; Needs Assessment; Neurology; Otolaryngology; Registries; Reproducibility of Results; Retrospective Studies; Societies, Medical; Teaching",2-s2.0-84929701976
"Bloch N., Weiss G., Szekely S., Harel D.","An interactive tool for animating biology, and its use in spatial and temporal modeling of a cancerous tumor and its microenvironment",2015,"PLoS ONE",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941887084&doi=10.1371%2fjournal.pone.0133484&partnerID=40&md5=194b2eb64d405b0e374b7fd8077b8d3e","The ability to visualize the ongoing events of a computational model of biology is critical, both in order to see the dynamics of the biological system in action and to enable interaction with the model from which one can observe the resulting behavior. To this end, we have built a new interactive animation tool, SimuLife, for visualizing reactive models of cellular biology. SimuLife is web-based, and is freely accessible at http://simulife.weizmann.ac.il/. We have used SimuLife to animate a model that describes the development of a cancerous tumor, based on the individual components of the system and its environment. This has helped in understanding the dynamics of the tumor and its surrounding blood vessels, and in verifying the behavior, fine-tuning the model accordingly, and learning in which way different factors affect the tumor. © 2015 Bloch et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"oxygen; vasculotropin; angiogenesis; Article; cancer research; computer memory; cytology; dynamics; endothelium cell; interactive animation tool; learning; mathematical model; medical information; simulation; spatial analysis; temporal analysis; tumor growth; tumor microenvironment; biological model; biology; computer simulation; human; Internet; neoplasm; neovascularization (pathology); pathology; procedures; reproducibility; software; vascularization; videorecording; Computational Biology; Computer Simulation; Humans; Internet; Models, Biological; Neoplasms; Neovascularization, Pathologic; Reproducibility of Results; Software; Tumor Microenvironment; Video Recording",2-s2.0-84941887084
"De La Torre F., Chu W.-S., Xiong X., Vicente F., Ding X., Cohn J.","IntraFace",2015,"2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944929632&doi=10.1109%2fFG.2015.7163082&partnerID=40&md5=ad36f46ae244a2cc08301fad39ae8fb0","Within the last 20 years, there has been an increasing interest in the computer vision community in automated facial image analysis algorithms. This has been driven by applications in animation, market research, autonomous-driving, surveillance, and facial editing among others. To date, there exist several commercial packages for specific facial image analysis tasks such as facial expression recognition, facial attribute analysis or face tracking. However, free and easy-to-use software that incorporates all these functionalities is unavailable. This paper presents IntraFace (IF), a publicly-available software package for automated facial feature tracking, head pose estimation, facial attribute recognition, and facial expression analysis from video. In addition, IFincludes a newly develop technique for unsupervised synchrony detection to discover correlated facial behavior between two or more persons, a relatively unexplored problem in facial image analysis. In tests, IF achieved state-of-the-art results for emotion expression and action unit detection in three databases, FERA, CK+ and RU-FACS; measured audience reaction to a talk given by one of the authors; and discovered synchrony for smiling in videos of parent-infant interaction. IF is free of charge for academic use at http://www.humansensing.cs.cmu.edu/intraface/. © 2015 IEEE.",,"Computer keyboards; Computer vision; Gesture recognition; Image analysis; Image recognition; Attribute recognition; Commercial packages; Emotion expression; Facial expression analysis; Facial expression recognition; Facial feature tracking; Head Pose Estimation; Synchrony detection; Face recognition",2-s2.0-84944929632
"Spallone R.","Digital reconstruction of demolished architectural masterpieces, 3D modeling, and animation: The case study of turin horse racing by mollino",2015,"Handbook of Research on Emerging Digital Tools for Architectural Surveying, Modeling, and Representation",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957107198&doi=10.4018%2f978-1-4666-8379-2.ch017&partnerID=40&md5=409711539209a2b12a250f82e1d3ec0e","This chapter reviews methods and techniques of digital reconstruction of disappeared architectural masterpieces. Through the overview of theoretical positions are explored heuristic values and communicative potentials of three-dimensional reconstruction, and prerogatives of animation in the interaction with three-dimensional data. Different critical approaches related to the architectures remained on paper are then brought to light. The examination of several case studies, also personally conducted, is extended to unbuilt architectures and minor architectures subject to demolition or transformation in order to highlight the different strategies used for the preservation of the memory of such heritage. Finally, the case study of Turin Horse-Racing Society Building by Carlo Mollino is extensively presented through the analysis of contemporary critical bibliography concerning the project, a description of archival sources and illustration of methods and techniques of the digital reconstruction. © 2015, IGI Global. All rights reserved.",,"Animation; 3-d modeling; Case-studies; Critical approach; Digital reconstruction; Three-dimensional data; Three-dimensional reconstruction; Three dimensional computer graphics",2-s2.0-84957107198
"Kretschmer H., de B. Beaver D., Kretschmer T.","Three-dimensional visualization and animation of emerging patterns by the process of self-organization in collaboration networks",2015,"Scientometrics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930818135&doi=10.1007%2fs11192-015-1579-5&partnerID=40&md5=1b743f0a284f744530c55eac1083e5d2","The “Social Gestalt” model is a new parametric model visualizing 3-D graphs, using animation to show these graphs from different points of view. A visible 3-D graph image is the emerging pattern at the macro level of a system of co-authorships by the process of self-organization. Well-ordered 3-D computer graphs are totally rotatable and their shapes are visible from all possible points of view. The objectives of this paper are the description of several methods for three-dimensional modelling and animation and the application of these methods to two co-authorship networks selected for demonstration of varying 3-D graph images. This application of the 3-D graph modelling and animation shows for both the journal “NATURE” and the journal “Psychology of Women Quarterly” that at any time and independently on the manifold visible results of rotation, the empirical values nearly exactly match the theoretical distributions (Called “Social Gestalts”) obtained by regression analysis. In addition the emergence of different shapes between the 3-D graphs of “NATURE” and “Psychology of Women Quarterly” is explained. © 2015, Akadémiai Kiadó, Budapest, Hungary.","3-D computer graphs; Animation; Co-authorship; Complementarities; Mathematical model; Self-organization; Social network analysis; Visualization",,2-s2.0-84930818135
"Doore K.","Modeling-first approach for computer science instruction",2015,"ICER 2015 - Proceedings of the 2015 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959278883&doi=10.1145%2f2787622.2787738&partnerID=40&md5=2af3fd03086fe38ac6ad4f54b07ed986","A Modeling-based pedagogical approach for curriculum design can provide useful framework for teaching computing concepts, particularly in courses that target novices. While modeling is a foundational pillar of computing, it is not typically a focus of introductory computing curricula. Our research proposes that modeling can provide a valuable conceptual framework for teaching abstract computing concepts when student learning is guided along a progression of increasingly formalized models. Our research focuses on student-constructed models to encourage collaborative discourse, which can help surface inconsistencies in student conceptual understanding. After exploring computing concepts through model-mediated activities, students can then extend their understanding through construction of creative representations of the target computing concepts. We are redesigning introductory computing curricula for students majoring in animation, game, and interaction design using this methodology. We argue that this pedagogical approach can be broadly applied, but may be particularly beneficial when designing curricula for students majoring in non-computing domains.","Curriculum design; Model; Model-based; Pedagogy","Animation; Curricula; Education; Education computing; Models; Students; Teaching; Computing curricula; Conceptual frameworks; Conceptual understanding; Curriculum designs; Model-based OPC; Pedagogical approach; Pedagogy; Science instructions; Computer games",2-s2.0-84959278883
"Sirkiä T., Sorva J.","How do students use program visualizations within an interactive ebook?",2015,"ICER 2015 - Proceedings of the 2015 ACM Conference on International Computing Education Research",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959280864&doi=10.1145%2f2787622.2787719&partnerID=40&md5=20dcdbcc34e65e6f9ad4ca3e8ef89855","We investigated students' use of program visualizations (PVs) that were tightly integrated into the electronic book of an introductory course on programming. A quantitative analysis of logs showed that most students, and beginners especially, used the PVs, even where the PV did not directly affect their grade. Students commonly spent more time studying certain steps than others, suggesting they used the PVs attentively. Nevertheless, substantial numbers of students appeared to gloss over some key animation steps, something that future improvements to pedagogy may address. Overall, the results suggest that integrating PVs into an ebook can promote student engagement and has been fairly successful in the studied context. More research is needed to understand the differences between our results and earlier ones, and to assess the generalizability of our findings. © 2015 ACM.","Beginner programmers; CS1; Ebooks; Program visualization","Computer programming; Education; Electronic publishing; Teaching; Visual servoing; Visualization; Animation steps; Beginner programmers; E-books; Electronic books; Future improvements; Introductory course; Program visualization; Student engagement; Students",2-s2.0-84959280864
"Dilorenzo P.C.","Premo: DreamWorks Animation's New Approach to Animation",2015,"IEEE Computer Graphics and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937800798&doi=10.1109%2fMCG.2015.83&partnerID=40&md5=ccbe5ff9a0a78cb0d8f74caf106b81d9","Premo offers a state-of-the-art animator experience with fully deforming characters, complex environments, and real-time lighting that is indicative of final rendered images. The technology used in Premo unlocks novel workflows that keep an animator highly efficient and engaged in the creative process. The result is a natural interface for 3D animation, in contrast to the highly technical interfaces often required by other professional animation tools. Premo was successfully deployed on the feature animated film How to Train Your Dragon 2 and is now being used by all DreamWorks animators. © 1981-2012 IEEE.","3D animation; animation; Apollo; character animation; computer graphics; DreamWorks Animation; graphics applications; LibEE; Premo","Computer graphics; Motion pictures; Three dimensional computer graphics; 3D animation; Apollo; Character animation; Graphics applications; LibEE; Premo; Animation",2-s2.0-84937800798
"Zimmer H., Rousselle F., Jakob W., Wang O., Adler D., Jarosz W., Sorkine-Hornung O., Sorkine-Hornung A.","Path-space Motion Estimation and Decomposition for Robust Animation Filtering",2015,"Computer Graphics Forum",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938053048&doi=10.1111%2fcgf.12685&partnerID=40&md5=2a68afc444654f934f291433daee565b","Renderings of animation sequences with physics-based Monte Carlo light transport simulations are exceedingly costly to generate frame-by-frame, yet much of this computation is highly redundant due to the strong coherence in space, time and among samples. A promising approach pursued in prior work entails subsampling the sequence in space, time, and number of samples, followed by image-based spatio-temporal upsampling and denoising. These methods can provide significant performance gains, though major issues remain: firstly, in a multiple scattering simulation, the final pixel color is the composite of many different light transport phenomena, and this conflicting information causes artifacts in image-based methods. Secondly, motion vectors are needed to establish correspondence between the pixels in different frames, but it is unclear how to obtain them for most kinds of light paths (e.g. an object seen through a curved glass panel). To reduce these ambiguities, we propose a general decomposition framework, where the final pixel color is separated into components corresponding to disjoint subsets of the space of light paths. Each component is accompanied by motion vectors and other auxiliary features such as reflectance and surface normals. The motion vectors of specular paths are computed using a temporal extension of manifold exploration and the remaining components use a specialized variant of optical flow. Our experiments show that this decomposition leads to significant improvements in three image-based applications: denoising, spatial upsampling, and temporal interpolation. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); I.3.7 [Computer Graphics]: Color, shading, shadowing, and texture -; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism -","Animation; Color; Computer graphics; Image compression; Image denoising; Light transmission; Monte Carlo methods; Motion estimation; Pixels; Signal sampling; Visibility; Color , shading , shadowing , and texture; Descriptors; I.3.7 [computer graphics]: three-dimensional graphics and realism; Image-based application; Image-based methods; Remaining component; Temporal extensions; Temporal interpolation; Three dimensional computer graphics",2-s2.0-84938053048
"Day C.","Days of endless time",2015,"Computing in Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934279664&doi=10.1109%2fMCSE.2015.69&partnerID=40&md5=9ca26e018e236ff5b999a6fb70b0dbb2","Columnist Charles Day observes that video installations are catching up to video games in their use of computer-generated imagery. © 2015 IEEE.","Computer animation; graphic art; scientific computing; video games",,2-s2.0-84934279664
"Oh J., Kim B., Yang K., Park S.","Real-time 3D sign language avatar animation from DTV closed captions",2015,"ABU Technical Review",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949515385&partnerID=40&md5=5517be17c0484f5de61f7afa99bb2021","Whereas closed captions are provided for almost the whole broadcast time for deaf people, in South Korea sign language broadcasting covers only 5% of the time. By translating the closed captions into sign language it is possible to provide three-dimensional (3D) sign language interpretation for more of the broadcast time. We propose a real-time avatar-based sign language broadcasting system for all kind of TV programmes. We analyzed the last three years' of weather forecast scripts, and an open-domain corpus of about 1.2 million words from KBS, so that we could find the frequency of each word and determine the priority of sign word motion capture. We used the Korean wordnet, KorLex, to build the sign language synonym dictionary and disambiguate the words with multiple meanings, for better translation performance. Optically-captured 3D sign language motions are used for the avatar to present motion-blended sign language interpretation. We implemented the real-time sign language interpretation system by extending the sign language dictionary, translation module, and motion database of our previous on-demand weather forecast sign language interpretation system.",,"Computational linguistics; Digital television; Frequency domain analysis; Television broadcasting; Three dimensional computer graphics; Weather forecasting; Broadcast time; Broadcasting systems; Deaf peoples; Interpretation systems; Motion capture; Motion database; Sign language; Threedimensional (3-d); Translation (languages)",2-s2.0-84949515385
"Chen J.Z., Lei Q., Miao Y.W., Peng Q.S.","Vectorization of line drawing image based on junction analysis",2015,"Science China Information Sciences",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933677292&doi=10.1007%2fs11432-014-5246-x&partnerID=40&md5=237d5ef45730ec07b7b925a3548d766a","Converting a scanned or shot line drawing image into a vector graph can facilitate further editand reuse, making it a hot research topic in computer animation and image processing. Besides avoiding noiseinfluence, its main challenge is to preserve the topological structures of the original line drawings, such as linejunctions, in the procedure of obtaining a smooth vector graph from a rough line drawing. In this paper, wepropose a vectorization method of line drawings based on junction analysis, which retains the original structureunlike done by existing methods. We first combine central line tracking and contour tracking, which allowsus to detect the encounter of line junctions when tracing a single path. Then, a junction analysis approachbased on intensity polar mapping is proposed to compute the number and orientations of junction branches.Finally, we make use of bending degrees of contour paths to compute the smoothness between adjacent branches,which allows us to obtain the topological structures corresponding to the respective ones in the input image.We also introduce a correction mechanism for line tracking based on a quadratic surface fitting, which avoidsaccumulating errors of traditional line tracking and improves the robustness for vectorizing rough line drawings.We demonstrate the validity of our method through comparisons with existing methods, and a large amount ofexperiments on both professional and amateurish line drawing images. © 2015, Science China Press and Springer-Verlag Berlin Heidelberg.","junction analysis; line drawing; line tracking; vector graph; vectorization","Animation; Image processing; junction analysis; Line drawings; Line tracking; Vector graphs; Vectorization; Topology",2-s2.0-84933677292
"Wood J.","Visualizing Personal Progress in Participatory Sports Cycling Events",2015,"IEEE Computer Graphics and Applications",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937788762&doi=10.1109%2fMCG.2015.71&partnerID=40&md5=ea08e0f7d6fab07ecd376db46ff6305a","This article explores the potential for creating personal visualization of participation in sports cycling as a design study. Examples show riders' personal narratives and performances relative to other participants in long-distance cycling events. Minimalist cartographic design is applied during the automatic generation of profile maps, which allows personal textual narratives to be attached to visualizations of 3D variations in terrain. Changes in relative position and time-in-hand data during mass participation events are shown as position charts, and animations of rider density over time are used to visualize the progress of larger groups of riders in an event. The designs focus on representing the aspects of participation that evoke an emotional response in an effort to engage users. © 1981-2012 IEEE.","affective computing; computer graphics; Graphics design study; personal visualization; sports data","Computer graphics; Data visualization; Design; Mapping; Sports; Visualization; Affective Computing; Automatic Generation; Cartographic design; Emotional response; Graphics design; Personal narratives; Relative positions; Sports data; Three dimensional computer graphics",2-s2.0-84937788762
"Campbell B.D., Samsel F.","Murmurations: Drawing Together Art, Visualization, and Physical Phenomena",2015,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937776569&doi=10.1109%2fMCG.2015.75&partnerID=40&md5=dd6b92d24d6f8692901129587d4d3c9f","Dennis Hylnsky, a professor at the Rhode Island School of Design and head of the Film/Animation/Video Department, is a practicing artist and early adopter of electronic media. At RISD he has studied 3D modeling and animation. One of his current projects focuses on the movement of small animals and what animal visualizations can tell us. In this issue's Art on Graphics, department editors Bruce Campbell and Francesca Samsel talk with Hylnsky about his work and how it can help to bridge the gap between art and science practice and facilitate a dialogue between the two communities. © 1981-2012 IEEE.","art-science collaborations; computer graphics; murmuration; observation science; Video sampling; visualization","Animals; Computer graphics; Flow visualization; Art and science; art-science collaborations; Current projects; Electronic media; murmuration; observation science; Physical phenomena; Rhode Island; Visualization",2-s2.0-84937776569
"Carter S., Qvarfordt P., Cooper M., Makela V.","Creating Tutorials with Web-Based Authoring and Heads-Up Capture",2015,"IEEE Pervasive Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962243106&doi=10.1109%2fMPRV.2015.59&partnerID=40&md5=742fd609368d12ab64a78b293e268307","Tutorials are one of the most fundamental means of conveying knowledge. Ideally, tutorials not only describe each step via text or audio narration but show it as well using photos or animation. In most cases, tutorial authors capture media from handheld mobile devices to import into these documents, but increasingly they use wearable devices as well. Here, the authors explore the use of head-mounted capture for authoring tutorials. They have developed a media capture tool for Google Glass that requires minimal attention to the capture device and instead allows the author to focus on creating the tutorial content. They describe a study comparing standalone (camera-on-tripod) versus wearable (Google Glass) capture, showing that tutorial authors prefer wearable capture devices, especially when recording activities involving larger objects in nontabletop environments. This article is part of a special issue on digitally enhanced reality. © 2015 IEEE.","expository documents; Google Glass; heads-up capture; Internet/Web technologies; media capture; mobile; pervasive computing; tutorial authors; tutorial creators; tutorials; wearables","Glass; Mobile devices; Ubiquitous computing; Wearable computers; expository documents; heads-up capture; Media capture; mobile; tutorial authors; tutorial creators; tutorials; wearables; Wearable technology",2-s2.0-84962243106
"Isley V., Smith P.","Dreams of mice",2015,"C and C 2015 - Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962074474&doi=10.1145%2f2757226.2757366&partnerID=40&md5=d3cb2b89278e10d9862ad20bef9d2f3e","Dreams of Mice explores a changed understanding of sleep brought about by networked technologies. A contemporary world of instant messaging and 24/7 connectivity encourages us to remain permanently available. Using computer modeling, recorded neurological data and game engine technology, boredomresearch http://www.boredomresearch.net ask if we can afford to disconnect; questioning the importance of the nonproductive third of our lives we spend asleep. Brain activity during sleep reveals that far from downtime, sleep is complex and beautiful. Developed from research exploring the interaction between environmental factors effecting sleep and human neurological disorders - Dreams of Mice considers the increased control, management and disruption of sleep behaviours. Collaborating with a neuroscientist at the University of Oxford, capturing and recording the dreams of laboratory mice, boredomresearch have revealed the intriguing beauty of slumber in a realtime artwork driven by the firing neurons of dreaming mice (see Fig.1). When we go to sleep we disconnect from our social networks and perpetual status updates, entering the last remaining sanctuary from the demands of a permanently connected and networked society. But is the space of dreams at risk from the relentless encroachment of connective technologies?","Artistic research; Computational aesthetics; Computer animation; Data; Dreams; Game engine technology; Mice; Moving image; Neuroscience; Sleep; Societal issues; Sound acoustic",,2-s2.0-84962074474
"Annamaaa A.","Thonny, a python IDE for learning programming",2015,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951962927&doi=10.1145%2f2729094.2754849&partnerID=40&md5=9085a939f32c763c8c61e25f6659b929","Thonny is a new Python IDE for learning and teaching programming that can make program visualization a natural part of the beginners' workflow. Among its prominent features are different ways of stepping through the code, step-by-step expression evaluation, intuitive visualization of the call stack and a mode for explaining the concepts of references and heap. It is free to use and open for extension.","Computing education; CS1; IDE; Program animation; Program visualization; Programming; Python","Computer software; Education computing; Engineering research; High level languages; Integrodifferential equations; Mathematical programming; Visualization; Computing education; CS1; IDE; Program animation; Program visualization; Python; Engineering education",2-s2.0-84951962927
"Xu X., Zhong L., Xie M., Qin J., Chen Y., Jin Q., Wong T.-T., Han G.","Texture-aware ASCII art synthesis with proportional fonts",2015,"Expressive 2015: Joint Symposium of Computational Aesthetics, CAe, Non-Photorealistic Animation and Rendering, NPAR, Sketch-Based Interfaces and Modeling, SBIM",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985006571&doi=10.2312%2fexp.20151191&partnerID=40&md5=2a61a8ced11de2d47ce32bbfc5af5a14","We present a fast structure-based ASCII art generation method that accepts arbitrary images (real photograph or hand-drawing) as input. Our method supports not only fixed width fonts, but also the visually more pleasant and computationally more challenging proportional fonts, which allows us to represent challenging images with a variety of structures by characters. We take human perception into account and develop a novel feature extraction scheme based on a multi-orientation phase congruency model. Different from most existing contour detection methods, our scheme does not attempt to remove textures as much as possible. Instead, it aims at faithfully capturing visually sensitive features, including both main contours and textural structures, while suppressing visually insensitive features, such as minor texture elements and noise. Together with a deformation-tolerant image similarity metric, we can generate lively and meaningful ASCII art, even when the choices of character shapes and placement are very limited. A dynamic programming based optimization is proposed to simultaneously determine the optimal proportional-font characters for matching and their optimal placement. Experimental results show that our results outperform state-of-the-art methods in term of visual quality. © The Eurographics Association 2015.",,"Animation; Character sets; Feature extraction; Rendering (computer graphics); Contour detection; Generation method; Insensitive features; Optimal placements; Phase congruency; Sensitive features; State-of-the-art methods; Visual qualities; Dynamic programming",2-s2.0-84985006571
"Berkiten S., Fan X., Rusinkiewicz S.","Semi-automatic digital epigraphy from images with normals",2015,"Expressive 2015: Joint Symposium of Computational Aesthetics, CAe, Non-Photorealistic Animation and Rendering, NPAR, Sketch-Based Interfaces and Modeling, SBIM",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984982197&doi=10.2312%2fexp.20151182&partnerID=40&md5=4af31f58629f582459234c2f13000169","We present a semi-automated system for converting photometric datasets (RGB images with normals) into geometry-aware non-photorealistic illustrations that obey the common conventions of epigraphy (black-and-white archaeological drawings of inscriptions). We focus on rock inscriptions formed by carving into or pecking out the rock surface: these are characteristically rough with shallow relief, making the problem very challenging for previous line drawing methods. Our system allows the user to easily outline the inscriptions on the rock surface, then segment out the inscriptions and create line drawings and shaded renderings in a variety of styles. We explore both constant-width and tilt-indicating lines, as well as locally shape-revealing shading. Our system produces more understandable illustrations than previous NPR techniques, successfully converting epigraphy from a manual and painstaking process into a user-guided semi-automatic process. © The Eurographics Association 2015.",,"Animation; Rendering (computer graphics); Line drawings; Photo-realistic; RGB images; Rock surfaces; Semi-automated systems; Semi-automatics; User-guided; Automation",2-s2.0-84984982197
"Cardona L., Saito S.","Hybrid-space localized stylization method for view-dependent lines extracted from 3D models",2015,"Expressive 2015: Joint Symposium of Computational Aesthetics, CAe, Non-Photorealistic Animation and Rendering, NPAR, Sketch-Based Interfaces and Modeling, SBIM",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984994053&doi=10.2312%2fexp.20151181&partnerID=40&md5=f441721a21bd2103205b91365b0f755c","We propose a localized stylization method that combines object-space and image-space techniques to locally stylize view-dependent lines extracted from 3D models. In the input phase, the user can customize a style and draw strokes by tracing over view-dependent feature lines such as occluding contours and suggestive contours. For each stroke drawn, the system stores its style properties as well as its surface location on the underlying polygonal mesh as a data structure referred as registered stroke. In the rendering phase, a new attraction field leads active contours generated from the registered strokes to match current frame feature lines and maintain the style and path coordinates of strokes in nearby viewpoints. For each registered stroke, a limited surface region referred as influence area is used to improve the line matching accuracy and discard obvious mismatches. The proposed stylization system produces uncluttered line drawings that convey additional information such as material properties or feature sharpness and is evaluated by measuring its usability and performance. © The Eurographics Association 2015.",,"Animation; Active contours; Feature lines; Image-space techniques; Line-matching; Polygonal meshes; Surface location; Surface region; View-dependent; Rendering (computer graphics)",2-s2.0-84984994053
"Lang K., Alexa M.","The markov pen: Online synthesis of free-hand drawing styles",2015,"Expressive 2015: Joint Symposium of Computational Aesthetics, CAe, Non-Photorealistic Animation and Rendering, NPAR, Sketch-Based Interfaces and Modeling, SBIM",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984985008&doi=10.2312%2fexp.20151193&partnerID=40&md5=52ab798522aa6baebaa1d6559bc93a40","Learning expressive curve styles from example is crucial for interactive or computer-based narrative illustrations. We propose a method for online synthesis of free-hand drawing styles along arbitrary base paths by means of an autoregressive Markov Model. Choice on further curve progression is made while drawing, by sampling from a series of previously learned feature distributions subject to local curvature. The algorithm requires no useradjustable parameters other than one short example style. It may be used as a custom ""random brush"" designer in any task that requires rapid placement of a large number of detail-rich shapes that are tedious to create manually. © The Eurographics Association 2015.",,"Markov processes; Auto-regressive; Feature distribution; Free-hand drawing; Local curvature; Markov model; On-line synthesis; Animation",2-s2.0-84984985008
"Ahire A.L., Evans A., Blat J.","Animation on the web: A survey",2015,"Proceedings - Web3D 2015: 20th International Conference on 3D Web Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962415125&doi=10.1145%2f2775292.2775298&partnerID=40&md5=77f6f18ce21a26f983bef74aa84d5359","The main motivation of this paper is to provide a current state and a brief overview of animation on the web. Computer animation is used in many fields and it has seen a lot of development in the recent years. With the widespread use of WebGL and the age of powerful modern hardware available on small devices, 3D rendering on the browser is now becoming commonplace. Computer Animation can be described as the rendering of objects on screen, which can change shape and properties with respect to time. There are many approaches to rendering animation on the web, but none of them yet provide a coherent approach in terms of transmission, compression and handling of the animation data on the client side (browser). And if computer animation has to become more accessible over the web, these challenges need to be addressed in the same ""minimalistic manner (requirement wise)"" as every other multimedia content has been addressed on the web. We aim to provide an overview of the current state of the art, while commenting on the shortcomings pertaining to current formats/approaches and discuss some of the upcoming standards and trends which can help with the current implementation. © 2015 ACM.","Animation; Compression; Real time animation; Streaming; Survey; Web; WebGL","Acoustic streaming; Compaction; Surveying; Surveys; Three dimensional computer graphics; Web services; 3-D rendering; Client sides; Computer animation; Multimedia contents; Real-time animations; Small devices; State of the art; WebGL; Animation",2-s2.0-84962415125
"Park J.W., Lee H.S., Chung M.J.","Generation of Realistic Robot Facial Expressions for Human Robot Interaction",2015,"Journal of Intelligent and Robotic Systems: Theory and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929521464&doi=10.1007%2fs10846-014-0066-1&partnerID=40&md5=c843693cb569a60836a2ddf90628bc02","One factor that contributes to successful long-term human-human interaction is that humans are able to appropriately express their emotions depending on situations. Unlike humans, robots often lack diversity in facial expressions and gestures and long-term human robot interaction (HRI) has consequently not been very successful thus far. In this paper, we propose a novel method to generate diverse and more realistic robot facial expressions to help long-term HRI. First, nine basic dynamics for robot facial expressions are determined based on the dynamics of human facial expressions and principles of animation in order to generate natural and diverse expression changes in a facial robot for identical emotions. In the second stage, facial actions are added to express more realistic expressions such as sniffling or wailing loudly corresponding to sadness, laughing aloud or smiling corresponding to happiness, etc. To evaluate the effectiveness of our approach, we compared the facial expressions of the developed robot with and without use of the proposed method. The results of the survey showed that the proposed method can help robots generate more realistic and diverse facial expressions. © 2014, Springer Science+Business Media Dordrecht.","Dynamics; Facial actions; Human robot interaction; Realistic facial expressions","Animation; Dynamics; Face recognition; Human computer interaction; Man machine systems; Robots; Facial action; Facial Expressions; Facial robots; Human facial expressions; Human robot Interaction (HRI); Human-human interactions; One-factor; Realistic robots; Human robot interaction",2-s2.0-84929521464
"Lee T., Park J., Kwon T.","Adaptive locomotion on slopes and stairs using pelvic rotation",2015,"Visual Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930754367&doi=10.1007%2fs00371-015-1103-1&partnerID=40&md5=bde35150d2da137d6d2e1babb0027be4","In this paper, we introduce a new online motion retargeting technique to generate natural locomotion of walking on slopes and stairs using only a single captured reference motion. An inverse-kinematics solver is developed to generate poses satisfying smooth trajectories of positional and rotational constraints for feet and hands. By considering the rotations of the pelvis and upper body, our technique is able to produce natural poses without knee-popping artifacts. © 2015, Springer-Verlag Berlin Heidelberg.","Computer animation; Inverse kinematics; Physics-based","Animation; Inverse kinematics; Kinematics; Adaptive locomotion; Computer animation; Motion retargeting; Natural locomotions; Pelvic rotation; Physics-based; Smooth trajectories; Upper bodies; Stairs",2-s2.0-84930754367
"Rodríguez-Cerro A., García-Fernández I., Martínez-Durá R.J., Pla-Castells M.","Texture advection on discontinuous flows",2015,"Visual Computer",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930763397&doi=10.1007%2fs00371-015-1118-7&partnerID=40&md5=8fd1d0e780893a58dee87cd47f674c36","Texture advection techniques, which transport textures using a velocity field, are used to visualize the dynamics of a flow on a triangle mesh. Some flow phenomena lead to velocity fields with discontinuities that cause the deformation of the texture which is not properly controlled by these techniques. We propose a method to detect and visualize discontinuities on a flow, keeping consistent texture advection at both sides of the discontinuity. The method handles the possibility that the discontinuity travels across the domain of the flow with arbitrary velocity, estimating its speed with least-squares approximation. The technique is tested with different sample scenarios and with two avalanche scenes, showing that it can run at interactive rates. © 2015, Springer-Verlag Berlin Heidelberg.","Computer animation; Discontinuity; Flow visualization; Texture advection","Advection; Animation; Flow visualization; Textures; Transpiration; Velocity; Arbitrary velocities; Computer animation; Discontinuity; Discontinuous flow; Flow Phenomena; Interactive rates; Triangle mesh; Velocity field; Least squares approximations",2-s2.0-84930763397
"Li J., Peters T.J., Marinelli K., Kovalev E., Jordan K.E.","Topological subtleties for molecular movies",2015,"Topology and its Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928169451&doi=10.1016%2fj.topol.2015.03.013&partnerID=40&md5=bc1c5898dcdbea08b3c65304c197c873","Synchronous movies permit visual analysis of shape perturbation during molecular simulations. The molecule is conceptualized as a knot and modeled as a spline curve. As the molecule writhes, the graphics approximation in each frame should display an ambient isotopic image of the perturbing spline. These graphics approximations raise subtleties for correctly rendering the embedding. A cautionary example was discovered through visualization experiments and the relevant characteristics are formally proved. © 2015 Elsevier B.V.","Computer animation; Isotopy; Knot; Molecular simulation",,2-s2.0-84928169451
"Afifi M., Hussain K.F., Ibrahim H.M., Omar N.M.","A Low-cost System for Generating Near-realistic Virtual Actors",2015,"3D Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928396413&doi=10.1007%2fs13319-015-0050-y&partnerID=40&md5=22659ce945862930254869cf9480de3f","Abstract: Generating virtual actors is one of the most challenging fields in computer graphics. The reconstruction of a realistic virtual actor has been paid attention by the academic research and the film industry to generate human-like virtual actors. Many movies were acted by human-like virtual actors, where the audience cannot distinguish between real and virtual actors. The synthesis of realistic virtual actors is considered a complex process. Many techniques are used to generate a realistic virtual actor; however they usually require expensive hardware equipment. In this paper, a low-cost system that generates near-realistic virtual actors is presented. The facial features of the real actor are blended with a virtual head that is attached to the actor’s body. Comparing with other techniques that generate virtual actors, the proposed system is considered a low-cost system that requires only one camera that records the scene without using any expensive hardware equipment. The results of our system show that the system generates good near-realistic virtual actors that can be used on many applications.Graphical Abstract: [Figure not available: see fulltext.] © 2015, 3D Research Center, Kwangwoon University and Springer-Verlag Berlin Heidelberg.","Computer animation; Digital face; Facial animation; Virtual actor","Animation; Computer graphics; Computer hardware; Computer supported cooperative work; Costs; Hardware; Academic research; Complex Processes; Computer animation; Digital face; Expensive hardware; Facial animation; Low-cost systems; Virtual actors; Virtual reality",2-s2.0-84928396413
"Rahim M.S.M., Basori A.H., Saadi S.M., Rad A.E., Rehman A.","Emotional Facial Expression and Tears Simulation: An Analysis & Comparison of Current Approaches",2015,"3D Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926339328&doi=10.1007%2fs13319-015-0046-7&partnerID=40&md5=9ed6f14cbf5095f3b4111cc041475673","The enhancement of emotional expression of virtual human in extreme situation such as, crying or sweating required physical effect that involved fluid behavior. The aim of this research is to analyze the facial action coding system and smooth particle hydrodynamic strategies to effectively provide an efficient display in computer facial animation. This research reviews and compares two major techniques for generating extreme expression in 3D facial animation, the facial action coding system is employed to describe and create facial expressions. It breaks down facial actions into minor units known as action units (AU’s). Emotion facial expressions generated are based on independent action unit’s combination. © 2015, 3D Research Center, Kwangwoon University and Springer-Verlag Berlin Heidelberg.","Composite facial features; Crying simulation; Facial analysis; Facial expression","Animation; Computer keyboards; Gesture recognition; Signal encoding; Virtual reality; 3d facial animations; Crying simulation; Emotional expressions; Facial Action Coding System; Facial analysis; Facial Expressions; Facial feature; Smooth particle hydrodynamics; Face recognition",2-s2.0-84926339328
"Hsieh H.-M., Chiang L.-K., Weng M.-H., Chen H.-N., Chen Y.-H., Lin C.-L.","Evaluation on using 3d fluid animation software to simulate hydraulic experiment results",2015,"Journal of Taiwan Agricultural Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960481802&partnerID=40&md5=57e491eb5bae2ff0681bee1f73676941","This study will apply 3D fluid simulation software, more commonly used to do a movie Fluid Effects, including Maya, RealFlow, Blender, and Glu3D for 3ds Max to do the simulation of pure water flow. The 3D fluid simulation software will be used to simulate the falling water after the weir and hydraulic jump, eddy near the cylinder pier in hydraulic laboratory, and surface disturbance near the rectangle pier in field. Finally, the comparative analysis of the hydraulic laboratory and simulation results will be done, and the order of the 3D fluid simulation software according to empirical parameters, performance and accuracy will be established in the future. In all realistic simulation perspective, film camera must work consistent with the operation of the films of hydraulic laboratory, and the simulation results provided a comparative analysis of the image. During the validation process and results, you can determine various software simulation steps, the range of parameters. Flow simulation results of various softwares have great differences, but generally water jump phenomenon has revealed, and the locations of the residence have some differences with experiment data. Generally, the RealFlow and Maya software have better performance in accuracy estimation, the Blender and Glu3D for 3ds Max software have better performance in file size and computing efficiency. Considering accuracy, the RealFlow or Maya software are still better proposed and selected to do the flow simulation with mixed sand in practicality. This results achieved in the future can provide the reference of flow simulation in actual the river, or the impact assessment for the rivers structures setting on the rivers. © 2016, Taiwan Agricultural Engineers Society. All rights reserved.","3D fluid simulation; Drop of water after the weir; Hydraulic jump; Hydraulic laboratory","Flow of water; Flow simulation; Hydraulic jump; Hydraulic laboratories; Hydraulic structures; Laboratories; Piers; Rivers; Weirs; Accuracy estimation; Comparative analysis; Computing efficiency; Empirical parameters; Fluid simulations; Realistic simulation; Software simulation; Surface disturbances; Computer software; accuracy assessment; empirical analysis; hydraulic conductivity; image analysis; simulation; software; three-dimensional modeling; water flow; weir",2-s2.0-84960481802
"Hale D.K., Antoniou C., Brackstone M., Michalaka D., Moreno A.T., Parikh K.","Optimization-based assisted calibration of traffic simulation models",2015,"Transportation Research Part C: Emerging Technologies",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936986326&doi=10.1016%2fj.trc.2015.01.018&partnerID=40&md5=e1a731539f65e643e7029c6defb3801c","Use of traffic simulation has increased in recent decades; and this high-fidelity modelling, along with moving vehicle animation, has allowed transportation decisions to be made with better confidence. During this time, traffic engineers have been encouraged to embrace the process of calibration, in which steps are taken to reconcile simulated and field-observed performance. According to international surveys, experts, and conventional wisdom, existing (non-automated) methods of calibration have been difficult or inadequate. There has been extensive research on improved calibration methods, but many of these efforts have not produced the flexibility and practicality required by real-world engineers. With this in mind, a patent-pending (US 61/859,819) architecture for software-assisted calibration was developed to maximize practicality, flexibility, and ease-of-use. This architecture is called SASCO (i.e. Sensitivity Analysis, Self-Calibration, and Optimization). The original optimization method within SASCO was based on ""directed brute force"" (DBF) searching; performing exhaustive evaluation of alternatives in a discrete, user-defined search space. Simultaneous Perturbation Stochastic Approximation (SPSA) has also gained favor as an efficient method for optimizing computationally expensive, ""black-box"" traffic simulations, and was also implemented within SASCO. This paper uses synthetic and real-world case studies to assess the qualities of DBF and SPSA, so they can be applied in the right situations. SPSA was found to be the fastest method, which is important when calibrating numerous inputs, but DBF was more reliable. Additionally DBF was better than SPSA for sensitivity analysis, and for calibrating complex inputs. Regardless of which optimization method is selected, the SASCO architecture appears to offer a new and practice-ready level of calibration efficiency. © 2015 Elsevier Ltd.","Assisted calibration; Calibration; Microscopic simulation; Simulation-based optimization; SPSA; Traffic simulation","Animation; Optimization; Sensitivity analysis; Stochastic systems; Traffic signals; International survey; Microscopic simulation; Optimization method; Simulation-based optimizations; Simultaneous perturbation stochastic approximation; SPSA; Traffic simulation model; Traffic simulations; Calibration; calibration; computer simulation; numerical model; optimization; traffic management",2-s2.0-84936986326
"Elshehaly M., Gračanin D., Gad M., Elmongui H.G., Matković K.","Interactive Fusion and Tracking for Multi-Modal Spatial Data Visualization",2015,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937935533&doi=10.1111%2fcgf.12637&partnerID=40&md5=ec505761604542966867b87ef208d0a1","Scientific data acquired through sensors which monitor natural phenomena, as well as simulation data that imitate time-identified events, have fueled the need for interactive techniques to successfully analyze and understand trends and patterns across space and time. We present a novel interactive visualization technique that fuses ground truth measurements with simulation results in real-time to support the continuous tracking and analysis of spatiotemporal patterns. We start by constructing a reference model which densely represents the expected temporal behavior, and then use GPU parallelism to advect measurements on the model and track their location at any given point in time. Our results show that users can interactively fill the spatio-temporal gaps in real world observations, and generate animations that accurately describe physical phenomena. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction techniques","Computer graphics; Visualization; Continuous tracking; I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction techniques; Interactive techniques; Interactive visualizations; Physical phenomena; Reference modeling; Spatiotemporal patterns; Temporal behavior; Data visualization",2-s2.0-84937935533
"Bach B., Henry-Riche N., Dwyer T., Madhyastha T., Fekete J.-D., Grabowski T.","Small MultiPiles: Piling Time to Explore Temporal Patterns in Dynamic Networks",2015,"Computer Graphics Forum",19,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937866346&doi=10.1111%2fcgf.12615&partnerID=40&md5=59474fd3d36a6ca5322a750215aeed8f","We introduce MultiPiles, a visualization to explore time-series of dense, weighted networks. MultiPiles is based on the physical analogy of piling adjacency matrices, each one representing a single temporal snapshot. Common interfaces for visualizing dynamic networks use techniques such as: flipping/animation; small multiples; or summary views in isolation. Our proposed 'piling' metaphor presents a hybrid of these techniques, leveraging each one's advantages, as well as offering the ability to scale to networks with hundreds of temporal snapshots. While the MultiPiles technique is applicable to many domains, our prototype was initially designed to help neuroscientists investigate changes in brain connectivity networks over several hundred snapshots. The piling metaphor and associated interaction and visual encodings allowed neuroscientists to explore their data, prior to a statistical analysis. They detected high-level temporal patterns in individual networks and this helped them to formulate and reject several hypotheses. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","H.5.2 [Information Interfaces and Presentation]: User Interfaces - Graphical user interfaces","User interfaces; Adjacency matrices; Brain connectivity; Common interfaces; H.5.2 [Information Interfaces and Presentation]: User Interfaces - Graphical User Interfaces; Individual network; Temporal pattern; Visual encodings; Weighted networks; Graphical user interfaces",2-s2.0-84937866346
"Karr J.R., Guturu H., Chen E.Y., Blair S.L., Irish J.M., Kotecha N., Covert M.W.","NetworkPainter: Dynamic intracellular pathway animation in Cytobank",2015,"BMC Bioinformatics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929577926&doi=10.1186%2fs12859-015-0602-4&partnerID=40&md5=1a1298667276bfb9708dd24f1cad9f82","Background: High-throughput technologies such as flow and mass cytometry have the potential to illuminate cellular networks. However, analyzing the data produced by these technologies is challenging. Visualization is needed to help researchers explore this data. Results: We developed a web-based software program, NetworkPainter, to enable researchers to analyze dynamic cytometry data in the context of pathway diagrams. NetworkPainter provides researchers a graphical interface to draw and ""paint"" pathway diagrams with experimental data, producing animated diagrams which display the activity of each network node at each time point. Conclusion: NetworkPainter enables researchers to more fully explore multi-parameter, dynamical cytometry data. © 2015 Karr et al.; licensee BioMed Central.","Animation; Cytometry; Network; Systems biology; Visualization","Animation; Flow visualization; Mobile security; Networks (circuits); Social networking (online); Visualization; World Wide Web; Animated diagrams; Cellular network; Cytometry; Graphical interface; High throughput technology; Intracellular pathways; Systems biology; Web-based softwares; Data visualization; biology; computer program; computer simulation; cytoplasm; data base; devices; factual database; flow cytometry; human; Internet; metabolism; mononuclear cell; procedures; signal transduction; standards; Computational Biology; Computer Simulation; Cytoplasm; Database Management Systems; Databases, Factual; Flow Cytometry; Humans; Internet; Leukocytes, Mononuclear; Signal Transduction; Software",2-s2.0-84929577926
"Choi M.-H., Wilber S.C., Hong M.","Estimating material properties of deformable objects by considering global object behavior in video streams",2015,"Multimedia Tools and Applications",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929192626&doi=10.1007%2fs11042-014-1995-1&partnerID=40&md5=093cb8bb47fcb0efdf61eed7a5cae58e","One of the crucial components in improving simulation quality in physics-based animation of deformable object is finding proper material properties that define the movement upon external excitation. Most work in the estimation of material properties for highly deformable objects involves applying localized force to a point on the object’s surface with mechanical devices and measuring the displacement of the surface at the contact point and surrounding points. While understanding this localized behavior provides a step towards accurately simulating objects with known material properties, an understanding of the global behavior of the object undergoing deformation is more important for many practical applications. This paper describes both the computer vision based techniques for tracking global position information of moving deformable objects from a video stream and the optimization routine for estimating the elasticity parameters of a mass-spring simulation. The collected data is the object’s surface node position of object over time which is used to a data-driven simulation of that object to match the behavior of a virtual object to the corresponding real one. This paper demonstrates that estimating material properties of highly elastic objects by matching the global behavior of the object in a video is possible with the proposed method and the experimental results show that the captured and simulated motions are well matched each other. © 2014, Springer Science+Business Media New York.","Computer vision; Data-driven animation; Global deformation; Material property estimation; Physically-based simulation","Animation; Computer hardware description languages; Computer vision; Video streaming; Data-driven animation; Data-driven simulation; Elasticity parameters; Global deformations; Physically-based simulation; Physics-based animation; Position information; Property estimation; Deformation",2-s2.0-84929192626
"Wheatland N., Wang Y., Song H., Neff M., Zordan V., Jörg S.","State of the Art in Hand and Finger Modeling and Animation",2015,"Computer Graphics Forum",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932140707&doi=10.1111%2fcgf.12595&partnerID=40&md5=48b41e02ddeed1b1be9c79c89830edd6","The human hand is a complex biological system able to perform numerous tasks with impressive accuracy and dexterity. Gestures furthermore play an important role in our daily interactions, and humans are particularly skilled at perceiving and interpreting detailed signals in communications. Creating believable hand motions for virtual characters is an important and challenging task. Many new methods have been proposed in the Computer Graphics community within the last years, and significant progress has been made towards creating convincing, detailed hand and finger motions. This state of the art report presents a review of the research in the area of hand and finger modeling and animation. Starting with the biological structure of the hand and its implications for how the hand moves, we discuss current methods in motion capturing hands, data-driven and physics-based algorithms to synthesize their motions, and techniques to make the appearance of the hand model surface more realistic. We then focus on areas in which detailed hand motions are crucial such as manipulation and communication. Our report concludes by describing emerging trends and applications for virtual hand animation. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Bioinformatics; Computer graphics; Biological structures; Complex biological systems; Emerging trends; Finger motion; Modeling and animation; Motion capturing; State of the art; Virtual character; Animation",2-s2.0-84932140707
"Leonardi V., Vidal V., Daniel M., Mari J.-L.","Multiple reconstruction and dynamic modeling of 3D digital objects using a morphing approach: Application to kidney animation and tumor tracking",2015,"Visual Computer",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928707755&doi=10.1007%2fs00371-014-0978-6&partnerID=40&md5=f1db9da2bff0b12821a6248b1842903c","Organ segmentation and motion simulation of organs can be useful for many clinical purposes such as organ study, diagnostic aid, therapy planning or even tumor destruction. In this paper we present a full workflow starting from a CT-Scan resulting in kidney motion simulation and tumor tracking. Our method is divided into three major steps: kidney segmentation, surface reconstruction and animation. The segmentation is based on a semi-automatic region-growing approach that is refined to improve its results. The reconstruction is performed using the Poisson surface reconstruction and gives a manifold three-dimensional (3D) model of the kidney. Finally, the animation is accomplished using an automatic mesh morphing among the models previously obtained. Thus, the results are purely geometric because they are 3D animated models. Moreover, our method requires only a basic user interaction and is fast enough to be used in a medical environment, which satisfies our constraints. Finally, this method can be easily adapted to magnetic resonance imaging acquisition because only the segmentation part would require minor modifications. © 2014, Springer-Verlag Berlin Heidelberg.","Dynamic modeling; Geometric modeling; Mesh morphing; Surface reconstruction","Animation; Computerized tomography; Diagnosis; Dynamic models; Magnetic resonance imaging; Surface reconstruction; Tumors; Geometric modeling; Kidney segmentation; Mesh morphing; Motion simulations; Organ segmentation; Therapy planning; Three dimensional (3-D) modeling; User interaction; Three dimensional computer graphics",2-s2.0-84928707755
"Bittner J., Meister D.","T-SAH: Animation Optimized Bounding Volume Hierarchies",2015,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932139525&doi=10.1111%2fcgf.12581&partnerID=40&md5=048553e7b289885f6ccc81f5a7f9a987","We propose a method for creating a bounding volume hierarchy (BVH) that is optimized for all frames of a given animated scene. The method is based on a novel extension of surface area heuristic to temporal domain (T-SAH). We perform iterative BVH optimization using T-SAH and create a single BVH accounting for scene geometry distribution at different frames of the animation. Having a single optimized BVH for the whole animation makes our method extremely easy to integrate to any application using BVHs, limiting the per-frame overhead only to refitting the bounding volumes. We evaluated the T-SAH optimized BVHs in the scope of real-time GPU ray tracing. We demonstrate, that our method can handle even highly complex inputs with large deformations and significant topology changes. The results show, that in a vast majority of tested scenes our method provides significantly better run-time performance than traditional SAH and also better performance than GPU based per-frame BVH rebuild. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Animation; Collision avoidance; Iterative methods; Optimization; Ray tracing; Better performance; Bounding volume; Bounding volume hierarchies; Bounding-volume hierarchy; Run-time performance; Surface area heuristic; Temporal domain; Topology changes; Heuristic methods",2-s2.0-84932139525
"Guo S., Southern R., Chang J., Greer D., Zhang J.J.","Adaptive motion synthesis for virtual characters: a survey",2015,"Visual Computer",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928707868&doi=10.1007%2fs00371-014-0943-4&partnerID=40&md5=ccb4ed421fdf0a919c38f986743f3dd9","Character motion synthesis is the process of artificially generating natural motion for a virtual character. In film, motion synthesis can be used to generate difficult or dangerous stunts without putting performers at risk. In computer games and virtual reality, motion synthesis enriches the player or participant experience by allowing for unscripted and emergent character behavior. In each of these applications the ability to adapt to changes to environmental conditions or to the character in a smooth and natural manner, while still conforming with user-specified constraints, determines the utility of a method to animators and industry practitioners. This focus on adaptation capability distinguishes our survey from other reviews which focus on general technology developments. Three main methodologies (example-based; simulation-based and hybrid) are summarised and evaluated using compound metrics: adaptivity, naturalness and controllability. By assessing existing techniques according to this classification we are able to determine how well a method corresponds to users’ expectations. We discuss optimization strategies commonly used in motion synthesis literature, and also contemporary perspectives from biology which give us a deeper insight into this problem. We also present observations and reflections from industry practitioners to reveal the operational constraints of character motion synthesis techniques. Our discussion and review presents a unique insight into the subject, and provide essential guidance when selecting appropriate methods to design an adaptive motion controller. © 2014, Springer-Verlag Berlin Heidelberg.","Character motion synthesis; Computer animation","Animation; Motion compensation; Surveys; Virtual reality; Character motion synthesis; Computer animation; Environmental conditions; Operational constraints; Optimization strategy; Technology development; User-specified constraints; Virtual character; Computer games",2-s2.0-84928707868
"Li W., Wolinski D., Pettré J., Lin M.C.","Biologically-Inspired Visual Simulation of Insect Swarms",2015,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932088919&doi=10.1111%2fcgf.12572&partnerID=40&md5=e6bdc59662618f70d60c5349d24acc11","Representing the majority of living animals, insects are the most ubiquitous biological organisms on Earth. Being able to simulate insect swarms could enhance visual realism of various graphical applications. However, the very complex nature of insect behaviors makes its simulation a challenging computational problem. To address this, we present a general biologically-inspired framework for visual simulation of insect swarms. Our approach is inspired by the observation that insects exhibit emergent behaviors at various scales in nature. At the low level, our framework automatically selects and configures the most suitable steering algorithm for the local collision avoidance task. At the intermediate level, it processes insect trajectories into piecewise-linear segments and constructs probability distribution functions for sampling waypoints. These waypoints are then evaluated by the Metropolis-Hastings algorithm to preserve global structures of insect swarms at the high level. With this biologically inspired, data-driven approach, we are able to simulate insect behaviors at different scales and we evaluate our simulation using both qualitative and quantitative metrics. Furthermore, as insect data could be difficult to acquire, our framework can be adopted as a computer-assisted animation tool to interpret sketch-like input as user control and generate simulations of complex insect swarming phenomena. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Algorithms; Animation; Distribution functions; Piecewise linear techniques; Probability distributions; Biologically inspired; Computational problem; Computer assisted animations; Data-driven approach; Graphical applications; Local collision avoidances; Metropolis-Hastings algorithm; Quantitative metrics; Visualization",2-s2.0-84932088919
"Yu J., Wang Z.-F.","A video, text, and speech-driven realistic 3-D virtual head for human-machine interface",2015,"IEEE Transactions on Cybernetics",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928409596&doi=10.1109%2fTCYB.2014.2341737&partnerID=40&md5=28ccee2b3301702c6301ae0fe236be99","A multiple inputs-driven realistic facial animation system based on 3-D virtual head for human-machine interface is proposed. The system can be driven independently by video, text, and speech, thus can interact with humans through diverse interfaces. The combination of parameterized model and muscular model is used to obtain a tradeoff between computational efficiency and high realism of 3-D facial animation. The online appearance model is used to track 3-D facial motion from video in the framework of particle filtering, and multiple measurements, i.e., pixel color value of input image and Gabor wavelet coefficient of illumination ratio image, are infused to reduce the influence of lighting and person dependence for the construction of online appearance model. The tri-phone model is used to reduce the computational consumption of visual co-articulation in speech synchronized viseme synthesis without sacrificing any performance. The objective and subjective experiments show that the system is suitable for human-machine interaction. © 2013 IEEE.","Facial animation; facial motion tracking; human-machine interface; virtual head","Animation; Computational efficiency; Face recognition; Human computer interaction; Man machine systems; Motion analysis; Social networking (online); Computational consumption; Facial animation; Facial motions; Human machine interaction; Human Machine Interface; Illumination ratio images; Online appearance models; Virtual heads; Virtual reality; automatic speech recognition; biological model; computer interface; computer simulation; facial expression; human; man machine interaction; natural language processing; procedures; three dimensional imaging; videorecording; Computer Simulation; Facial Expression; Humans; Imaging, Three-Dimensional; Man-Machine Systems; Models, Biological; Natural Language Processing; Speech Recognition Software; User-Computer Interface; Video Recording",2-s2.0-84928409596
"Bubník V., Havran V.","Light Chisel: 6DOF Pen Tracking",2015,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932093482&doi=10.1111%2fcgf.12563&partnerID=40&md5=66534151a58e4852246d199a189e8224","We present a novel interaction device tracked in 6 degrees of freedom by two commodity cameras. The inexpensive Light Chisel is statically illuminated with two LEDs, and uses no additional sensor (e.g. inertial or magnetic) or means of communication or synchronization. Its form factor is well suited for a screwdriver or chisel grip, allowing the Light Chisel to be rolled between the fingers. The position and orientation of the tool is tracked absolutely, making the Light Chisel suited for complex interaction, e.g. geometric modeling in augmented reality. The Light Chisel is physically small, limiting the physical and optical collisions with the real world. The orientation of the tool is tracked in a wide range of angles: pitch and yaw ±90°, roll ±180°. We evaluated our system against the OptiTrack optical tracking system. Our system achieved mean differences from OptiTrack reference of 2.07 mm in position, 1.06° in yaw and pitch, and 5.26° in roll using a pair of VGA cameras. We demonstrate usefulness of our Light Chisel in four applications: character animation, modeling by swirls, volumetric modeling, and docking of CAD models. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Animation; Augmented reality; Cameras; Computer aided design; Degrees of freedom (mechanics); Light emitting diodes; Character animation; Geometric modeling; Interaction devices; Optical collisions; Optical tracking systems; Position and orientations; Two commodities; Volumetric modeling; Tools",2-s2.0-84932093482
"Fratarcangeli M., Pellacini F.","Scalable Partitioning for Parallel Position Based Dynamics",2015,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932168595&doi=10.1111%2fcgf.12570&partnerID=40&md5=e953439bad3bce1bd76d6c6b4ab548d3","We introduce a practical partitioning technique designed for parallelizing Position Based Dynamics, and exploiting the ubiquitous multi-core processors present in current commodity GPUs. The input is a set of particles whose dynamics is influenced by spatial constraints. In the initialization phase, we build a graph in which each node corresponds to a constraint and two constraints are connected by an edge if they influence at least one common particle. We introduce a novel greedy algorithm for inserting additional constraints (phantoms) in the graph such that the resulting topology is-colourable, where is an arbitrary number. We color the graph, and the constraints with the same color are assigned to the same partition. Then, the set of constraints belonging to each partition is solved in parallel during the animation phase. We demonstrate this by using our partitioning technique; the performance hit caused by the GPU kernel calls is significantly decreased, leaving unaffected the visual quality, robustness and speed of serial position based dynamics. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Animation; Program processors; Topology; Arbitrary number; Greedy algorithms; Multi-core processor; Parallelizing; Partitioning techniques; Spatial constraints; Visual qualities; Dynamics",2-s2.0-84932168595
"Dietrich S.W., Goelman D., Borror C.M., Crook S.M.","An animated introduction to relational databases for many majors",2015,"IEEE Transactions on Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028224322&doi=10.1109%2fTE.2014.2326834&partnerID=40&md5=d69281311e082bf51880dfd20c247ad1","Database technology affects many disciplines beyond computer science and business. This paper describes two animations developed with images and color that visually and dynamically introduce fundamental relational database concepts and querying to students of many majors. The goal is for educators in diverse academic disciplines to incorporate the animations in their existing courses in order to meet their pedagogical needs. The introduction of the animations was assessed and evaluated within several contexts, including non-majors courses offered by computer scientists as well as a course on computational molecular biology. The evaluation indicated that student knowledge of fundamental database concepts improved significantly with the use of the courseware. The animations provide visual learners with an engaging method to learn the topics presented with the ability to replay the dynamic presentation. Overall, the evaluation indicates the accessibility of database topics across the disciplines as well as the specific concepts that need further elaboration. © 2014 IEEE.","Computer science education; courseware; querying; relational databases; visualization","E-learning; Education; Education computing; Flow visualization; Molecular biology; Query processing; Computational Molecular Biology; Computer Science Education; Computer scientists; Courseware; Database technology; Dynamic presentation; querying; Relational Database; Teaching",2-s2.0-85028224322
"Miandji E., Kronander J., Unger J.","Compressive Image Reconstruction in Reduced Union of Subspaces",2015,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932119888&doi=10.1111%2fcgf.12539&partnerID=40&md5=efdf6fbbc718f6daa53e1e47d1cdfb55","We present a new compressed sensing framework for reconstruction of incomplete and possibly noisy images and their higher dimensional variants, e.g. animations and light-fields. The algorithm relies on a learning-based basis representation. We train an ensemble of intrinsically two-dimensional (2D) dictionaries that operate locally on a set of 2D patches extracted from the input data. We show that one can convert the problem of 2D sparse signal recovery to an equivalent 1D form, enabling us to utilize a large family of sparse solvers. The proposed framework represents the input signals in a reduced union of subspaces model, while allowing sparsity in each subspace. Such a model leads to a much more sparse representation than widely used methods such as K-SVD. To evaluate our method, we apply it to three different scenarios where the signal dimensionality varies from 2D (images) to 3D (animations) and 4D (light-fields). We show that our method outperforms state-of-the-art algorithms in computer graphics and image processing literature. © 2015 The Author(s) Computer Graphics Forum © 2015 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Compressed sensing; Computer graphics; Image reconstruction; Signal reconstruction; Higher-dimensional; Light fields; Sparse representation; Sparse signal recoveries; Sparse solvers; State-of-the-art algorithms; Two Dimensional (2 D); Union of subspaces; Image processing",2-s2.0-84932119888
"Helmstaedter C., Jockwitz C., Witt J.-A.","Menstrual cycle corrupts reliable and valid assessment of language dominance: Consequences for presurgical evaluation of patients with epilepsy",2015,"Seizure",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955561703&doi=10.1016%2fj.seizure.2015.02.010&partnerID=40&md5=413cfc7b28d7ce3360201f7eec9f86ee","PURPOSE: Functional transcranial Doppler sonography (fTCD) is a valid and non-invasive tool for determining language dominance, e.g. in the context of presurgical evaluations. Beyond this, fTCD might be an ideal tool to study dynamics in language dominance over time. However, an essential prerequisite would be a high test-retest reliability. This was addressed in the present study.METHODS: Test-retest reliability of hemispheric hemodynamics during open speech was determined in 11 male and 11 female healthy volunteers using the Animation Description Paradigm. Expressive language dominance was assessed weekly over an interval of 4-5 weeks.RESULTS: Internal consistency of the four measurements was excellent (split-half reliability 0.85-0.95), but test-retest reliability of the lateralization index was poor to moderate (rtt=0.37-0.74). Controlling for gender, test-retest reliabilities were better in men (rtt=0.67-0.78) as compared to women (rtt=0.04-0.70). When arranging the assessments in women around day one of menstruation - all were on contraceptives - a significant shift from left hemisphere dominance toward bilaterality (t=2.2 p=0.04) was evident around menstruation with significant reversal afterwards (t=-3.4 p=0.005).CONCLUSION: A high intraindividual variability of language dominance patterns is indicated in women when assessed repeatedly by fTCD. Menstrual cycle appeared to be the source of inconsistency. The finding challenges the use of non-deactivating methods for language dominance assessment in epilepsy. Support for this is demonstrated with a female patient with epilepsy in whom language dominance assessed by repeated fMRI and fTCD varied concordantly with cycle but not so the repeated intracarotidal amobarbital test. Copyright © 2015 British Epilepsy Association. Published by Elsevier Ltd. All rights reserved.","Functional transcranial Doppler sonography; Gender; Language dominance; Menstrual cycle; Stability; Wada test","amobarbital; hypnotic sedative agent; oxygen; adult; analysis of variance; blood; brain; Doppler echography; drug effects; echography; epilepsy; female; hemispheric dominance; human; image processing; intraarterial drug administration; language; male; menstrual cycle; middle aged; nuclear magnetic resonance imaging; pathophysiology; physiology; reproducibility; sex difference; vascularization; Adult; Amobarbital; Analysis of Variance; Brain; Epilepsy; Female; Functional Laterality; Humans; Hypnotics and Sedatives; Image Processing, Computer-Assisted; Injections, Intra-Arterial; Language; Magnetic Resonance Imaging; Male; Menstrual Cycle; Middle Aged; Oxygen; Reproducibility of Results; Sex Factors; Ultrasonography, Doppler, Transcranial",2-s2.0-84955561703
"Oh W., Jeong J., Ryu K.-H.","HTML5-based 2D Dynamics Simulation for Force and Motion Education",2015,"New Physics: Sae Mulli",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951992241&doi=10.3938%2fNPSM.65.479&partnerID=40&md5=9d13caae1d2293772a3010c965f31729","This study suggests a HTML5-based algorithm for 2-dimensional dynamics simulations of two particles. In general, students and teachers in normal secondary physics classes require much training time for programming based on the popular C-language. Furthermore, the computer animation of particles with finite radii requires several sub-algorithms to change the reference system from the screen to the collision and vice versa and to perform the sophisticated calculations associated with momentum transfer. HTML5-based scripting programming will allow such simulations to be easily performed and well help students acquire deeper conceptual understandings of the dynamics of particles during the programming process.","Dynamics simulation; HTML5; Physics education",,2-s2.0-84951992241
"Kalinitchev A.","Kinetics of multicomponent ion-exchange mass transfer in ion exchangers with nonmonotonic behavior of kinetic curves: the displacement effect for diffusion concentration waves of ionic components",2015,"Protection of Metals and Physical Chemistry of Surfaces",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929079040&doi=10.1134%2fS2070205115030119&partnerID=40&md5=c33c38fe7895ac9e8d20679a501c0825","A theoretical approach to simulation of the multicomponent mass transfer of ionic components in ion exchangers is reported. A computer model is proposed for use in contemporary theoretical studies of the kinetics of the nonlinear multicomponent mass transfer of ions in the matrix of ion exchangers. Propagating diffusion concentration waves in multicomponent ion-exchange systems for the mass transfer of ions in the ion-exchange matrices of arbitrary forms—namely, planar L membrane, r grain, and ro fiber—are calculated. All the results are presented within the framework of the notion of propagating diffusion concentration waves of ionic components in the matrices of ion exchangers. The idea that is used of concentration waves for the description of the multicomponent kinetics of the diffusion mass transfer yields a clear interpretation of the computer simulation results. The kinetics of the process of the multicomponent mass transfer of components is described theoretically on the basis of computer simulation by solving the set of differential equations in partial derivatives for the mass balance of components. The propagation of concentration waves is illustrated by my simulation graphs and animations showing visually the propagation and interaction-interference of multicomponent concentration waves in the matrices of the various above-mentioned forms. Different ion-exchange systems with simulation of the anomalous behavior of the F<inf>i</inf>(T) kinetic curves (non-monotonic and with the presence of the maximum, Fmax) for one of the B+ + C+ ions entering into the R− matrix in the case of the R−A+/(B+ + C+) exchange version, with simultaneous computer simulation of the diffusion propagation of the multicomponent X<inf>i</inf> concentration waves within the nonlinear mass transfer kinetics, are examined. © 2015, Pleiades Publishing, Ltd.",,"Differential equations; Diffusion; Ion exchangers; Ions; Kinetics; Mass transfer; Diffusion concentrations; Diffusion propagation; Ion exchange systems; Multi-component mass transfer; Multicomponent ion exchange; Nonlinear mass transfer; Nonmonotonic behaviors; Theoretical approach; Ion exchange",2-s2.0-84929079040
"Yigit T., Koyun A., Yuksel A.S., Cankaya I.A., Kose U.","An example application of an artificial intelligence-supported blended learning education program in computer engineering",2015,"Curriculum Design and Classroom Management: Concepts, Methodologies, Tools, and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959139998&doi=10.4018%2f978-1-4666-8246-7.ch016&partnerID=40&md5=69e6a08e1704d8610b3407651e3bac26","Blended Learning is a learning model that is enriched with traditional learning methods and online education materials. Integration of face-to-face and online learning with blending learning can enhance the learning experience and optimize seat time. In this chapter, the authors present the teaching of an Algorithm and Programming course in Computer Engineering Education via an artificial intelligencesupported blended learning approach. Since 2011, Computer Engineering education in Suleyman Demirel University Computer Engineering Department is taught with a blended learning method. Blended learning is achieved through a Learning Management System (LMS) by using distance education technology. The LMS is comprised of course materials supported with flash animations, student records, user roles, and evaluation systems such as surveys and quizzes that meet SCORM standards. In this chapter, the related education process has been supported with an intelligent program, which is based on teaching C programming language. In this way, it has been aimed to improve educational processes within the related course and the education approach in the department. The blended learning approach has been evaluated by the authors, and the obtained results show that the introduced artificial intelligencesupported blended learning education program enables both teachers and students to experience better educational processes. © 2015, IGI Global.",,,2-s2.0-84959139998
"Flynn C., Stavness I., Lloyd J., Fels S.","A finite element model of the face including an orthotropic skin model under in vivo tension",2015,"Computer Methods in Biomechanics and Biomedical Engineering",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911989595&doi=10.1080%2f10255842.2013.820720&partnerID=40&md5=3e7a0f648d273a371b57c5bcabbcf1ba","Computer models of the human face have the potential to be used as powerful tools in surgery simulation and animation development applications. While existing models accurately represent various anatomical features of the face, the representation of the skin and soft tissues is very simplified. A computer model of the face is proposed in which the skin is represented by an orthotropic hyperelastic constitutive model. The in vivo tension inherent in skin is also represented in the model. The model was tested by simulating several facial expressions by activating appropriate orofacial and jaw muscles. Previous experiments calculated the change in orientation of the long axis of elliptical wounds on patients' faces for wide opening of the mouth and an open-mouth smile (both 30o). These results were compared with the average change of maximum principal stress direction in the skin calculated in the face model for wide opening of the mouth (18o) and an open-mouth smile (25o). The displacements of landmarks on the face for four facial expressions were compared with experimental measurements in the literature. The corner of the mouth in the model experienced the largest displacement for each facial expression (∼11–14 mm). The simulated landmark displacements were within a standard deviation of the measured displacements. Increasing the skin stiffness and skin tension generally resulted in a reduction in landmark displacements upon facial expression. © 2013, © 2013 Taylor & Francis.","anisotropy; constitutive model; expressions; face model; in vivo tension","Animation; Anisotropy; Constitutive models; Finite element method; Anatomical features; expressions; Face modeling; Hyperelastic constitutive model; In-vivo; Maximum principal stress; Standard deviation; Surgery simulations; Computer simulation; Article; biomechanics; computer model; computer simulation; cutaneous parameters; dermis; epidermis; face model; facial expression; finite element analysis; jaw muscle; muscle rigidity; orthotropic skin model; rigidity; skin tension; subcutaneous tissue; adult; automated pattern recognition; biological model; computer simulation; elasticity; face; human; image processing; male; mechanical stress; movement (physiology); physiology; skin; Adult; Biomechanical Phenomena; Computer Simulation; Elasticity; Face; Finite Element Analysis; Humans; Image Processing, Computer-Assisted; Male; Models, Biological; Movement; Pattern Recognition, Automated; Skin; Stress, Mechanical",2-s2.0-84911989595
"Piovarči M., Madaras M., Ďurikovič R.","Physically inspired stretching for skinning animation of non-rigid bodies",2015,"Proceedings - SCCG 2015: 31st Spring Conference on Computer Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963570094&doi=10.1145%2f2788539.2788545&partnerID=40&md5=c3ca99c8f5ee0a98acedc640614ff868","We propose a physically inspired stretching model for non-rigid bodies with linear skeletons. Given an input model composed of linear skeleton segments, it extract scaling matrices that can be directly used in skinning animation. The stretching model evaluates stretching of the body cause by gravitational force and stretching of the body caused by muscle contraction. Our model is based on small deformation theory, which can be directly applied on cylindrical shapes. Since the input body may differ from a cylindrical shape, it is decomposed into several cylindrical parts and stretching factors are calculated for each part individually. Next, the body is stretched along the skeleton based on the function derived from the sum of skeleton curvature. Finally, a system for the visualization of a particle-based simulation using linear blend skinning is created and enhanced with out stretching model. © 2015 ACM.","Physically inspired stretching; Simulation visualization; Skinning animation; Stretchable skinning","Animation; Computer graphics; Musculoskeletal system; Rigid structures; Visualization; Cylindrical shapes; Gravitational forces; Input modeling; Linear blend; Muscle contractions; Non-rigid bodies; Small deformations; Stretchable skinning; Gravitation",2-s2.0-84963570094
"Mindek P., Čmolík L., Viola I., Gröller E., Bruckner S.","Automatized summarization of multiplayer games",2015,"Proceedings - SCCG 2015: 31st Spring Conference on Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963616122&doi=10.1145%2f2788539.2788549&partnerID=40&md5=3c4b8523fbbb23458dae42247790f25b","We present a novel method for creating automatized gameplay dramatization of multiplayer video games. The dramatization serves as a visual form of guidance through dynamic 3D scenes with multiple foci, typical for such games. Our goal is to convey interesting aspects of the gameplay by animated sequences creating a summary of events which occurred during the game. Our technique is based on processing many cameras, which we refer to as a flock of cameras, and events captured during the gameplay, which we organize into a so-called event graph. Each camera has a lifespan with a certain time interval and its parameters such as position or look-up vector are changing over time. Additionally, during its lifespan each camera is assigned an importance function, which is dependent on the significance of the structures that are being captured by the camera. The images captured by the cameras are composed into a single continuous video using a set of operators based on cinematographic effects. The sequence of operators is selected by traversing the event graph and looking for specific patterns corresponding to the respective operators. In this way, a large number of cameras can be processed to generate an informative visual story presenting the gameplay. Our compositing approach supports insets of camera views to account for several important cameras simultaneously. Additionally, we create seamless transitions between individual selected camera views in order to preserve temporal continuity, which helps the user to follow the virtual story of the gameplay. © 2015 ACM.","Animation; Game visualization; Storytelling","Animation; Computer graphics; Human computer interaction; Interactive computer graphics; Event graphs; Importance functions; Multiplayer games; Seamless transition; Storytelling; Temporal continuity; Time interval; Visual forms; Cameras",2-s2.0-84963616122
"Mousas C., Anagnostopoulos C.-N.","Structure-aware transfer of facial blendshapes",2015,"Proceedings - SCCG 2015: 31st Spring Conference on Computer Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963632277&doi=10.1145%2f2788539.2788546&partnerID=40&md5=98d5015ac74d542febdaf5b4dff688b5","This paper presents a novel mesh deformation method for transferring reference facial blendshapes to a source face model. The presented method uses information provided by a source and a reference face model to analyze the mesh similarities and, consequently, to transfer the deformation. This is achieved by considering the distribution of vertices between the two face models in conjunction with the gradients of the meshes. Both of these components are assigned to an optimization function that is solved in two steps: (i) distribution transfer and (ii) gradient maintenance optimization. Finally, in order to analyze the efficiency of such a method, the presented method was evaluated against previous solutions in terms of deformation transfer error, and computational time. © 2015 ACM.","Blendshapes; Deformation transfer; Distribution; Facial animation; Gradient; Optimization","Deformation; Gradient methods; Mesh generation; Optimization; Blendshapes; Computational time; Deformation transfer; Distribution; Facial animation; Maintenance optimization; Mesh deformation; Optimization function; Computer graphics",2-s2.0-84963632277
[No author name available],"Proceedings - SCCG 2015: 31st Spring Conference on Computer Graphics",2015,"Proceedings - SCCG 2015: 31st Spring Conference on Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963570086&partnerID=40&md5=f4c36484b1a4aa46d3328f3adbd675d5","The proceedings contain 20 papers. The topics discussed include: automated facial landmark detection, comparison and visualization; a general framework for constrained mesh parameterization; tomographic reconstruction on the body-centered cubic lattice; surface reflectance characterization by statistical tools; physically inspired stretching for skinning animation of non-rigid bodies; structure-aware transfer of facial blendshapes; visibility-based approach to surface detection of tunnels in proteins; automatized summarization of multiplayer games; path-planning algorithm for transportation of molecules through protein tunnel bottlenecks; an improved decomposition and drawing process for optimal topological visualization of directed graphs; and finger motion estimation and synthesis for gesturing characters.",,,2-s2.0-84963570086
"Whitington J.G.","Two dimensional hidden surface removal with frame-to-frame coherence",2015,"Proceedings - SCCG 2015: 31st Spring Conference on Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963542518&doi=10.1145%2f2788539.2788560&partnerID=40&md5=69b57db19a3833c224e189284876a170","We describe a hidden surface removal algorithm for two-dimensional layered scenes built from arbitrary primitives, particularly suited to interaction and animation in rich scenes (for example, in illustration). The method makes use of a set-based raster representation to implement a front-to-back rendering model which analyses and dramatically reduces the amount of rasterization and composition required to render a scene. The method is extended to add frame-to frame coherence analysis and caching for interactive or animated scenes. A powerful system of primitive-combiners called filters is described, which preserves the efficiencies of the algorithm in highly complicated scenes. The set representation is extended to solve the problem of correlated mattes, leading to an efficient solution for high quality antialiasing. A prototype implementation has been prepared.","Antialiasing; Compositing; Frame-to-frame coherence; Hidden surface removal; Rasterization; Rendering","Algorithms; Anti-aliasing; Computer graphics; Rendering (computer graphics); Compositing; Frame-to-frame coherence; Hidden surface removal; Hidden surface removal algorithm; Powerful systems; Prototype implementations; Rendering; Set representation; Rasterization",2-s2.0-84963542518
"Achibet M., Casiez G., Lécuyer A., Marchal M.","THING: Introducing a tablet-based interaction technique for controlling 3D hand models",2015,"Conference on Human Factors in Computing Systems - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951054922&doi=10.1145%2f2702123.2702158&partnerID=40&md5=170f9bd1f871f2e1e67e38569215f6d5","The hands of virtual characters are highly complex 3D models that can be tedious and time-consuming to animate with current methods. This paper introduces THING, a novel tablet-based approach that leverages multi-touch interaction for a quick and precise control of a 3D hand's pose. The flexion/extension and abduction/adduction of the virtual fingers can be controlled for each finger individually or for several fingers in parallel through sliding motions on the tablet's surface. We designed two variants of THING: (1) MobileTHING, which maps the spatial location and orientation of the tablet to that of the virtual hand, and (2) DesktopTHING, which combines multi-touch controls of fingers with traditional mouse controls for the hand's global position and orientation. We compared the usability of THING against mouse-only controls and a data glove in two controlled experiments. Results show that DesktopTHING was significantly preferred by users while providing performance similar to data gloves. Together, these results could pave the way to the introduction of novel hybrid user interfaces based on tablets and computer mice in future animation pipelines. © Copyright 2015 ACM.","Computer animation; Multi-touch input; Virtual hand","Animation; Human computer interaction; Human engineering; Mammals; Computer animation; Controlled experiment; Hybrid User Interfaces; Interaction techniques; Multi-touch; Multi-touch interactions; Position and orientations; Virtual hand; User interfaces",2-s2.0-84951054922
"Kato J., Nakano T., Goto M.","Text Alive: Integrated design environment for kinetic typography",2015,"Conference on Human Factors in Computing Systems - Proceedings",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950973731&doi=10.1145%2f2702123.2702140&partnerID=40&md5=0013990f65ce0264ad569403a74512f8","This paper presents Text Alive, a graphical tool that allows interactive editing of kinetic typography videos in which lyrics or transcripts are animated in synchrony with the corresponding music or speech. While existing systems have allowed the designer and casual user to create animations, most of them do not take into account synchronization with audio signals. They allow predefined motions to be applied to objects and parameters to be tweaked, but it is usually impossible to extend the predefined set of motion algorithms within these systems. We therefore propose an integrated design environment featuring (1) GUIs that designers can use to create and edit animations synchronized with audio signals, (2) integrated tools that programmers can use to implement animation algorithms, and (3) a framework for bridging the interfaces for designers and programmers. A preliminary user study with designers, programmers, and casual users demonstrated its capability in authoring various kinetic typography videos. © Copyright 2015 ACM.","Animation; Creativity support tool; Integrated design environment; Kinetic typography; Live programming","Animation; Audio systems; Design; Human engineering; Kinetics; Typesetting; Animation algorithms; Creativity support tools; Existing systems; Integrated design environments; Integrated tools; Interactive editing; Kinetic typography; Motion algorithm; Human computer interaction",2-s2.0-84950973731
"Qi Y., Wang D., Zhang L., Shi Y.","TanProStory: A tangible programming system for children's storytelling",2015,"Conference on Human Factors in Computing Systems - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954225471&doi=10.1145%2f2702613.2732806&partnerID=40&md5=8972cfd213f7cbd153e0bbc736533ba6","Object-oriented programming is easily accessible by beginners, since it allows for modeling real-world entities as software objects. Storytelling is a natural way to introduce the basic concepts behind object-oriented programming. To convey object-oriented programming concepts to children, such as object, attribute and etc., we present a new tangible programming tool-TanProStory, for children in 1-3 grades. Children can tell a story by arranging programming blocks to initialize a character and construct a program controlling its action. TanProStory consists of three parts: Programming blocks, Animation Game and Sensor input module. Programming blocks in TanProStory are surface-sensitive, i.e. only the command on the top surface can be detected. We conducted a preliminary user study and analyzed the results, which can guide a better design of TanProStory.","Children; Programming languages; Storytelling; Tangible programming; Tangible user interface","Animation; Computer programming languages; Human computer interaction; Human engineering; User interfaces; Basic concepts; Children; Real-world entities; Sensor inputs; Storytelling; Tangible programming; Tangible user interfaces; Top surface; Object oriented programming",2-s2.0-84954225471
"Willett W., Jenny B., Isenberg T., Dragicevic P.","Lightweight relief shearing for enhanced terrain perception on interactive maps",2015,"Conference on Human Factors in Computing Systems - Proceedings",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951128822&doi=10.1145%2f2702123.2702172&partnerID=40&md5=09814a138af41afedb06b6f7aacc5ee3","We explore interactive relief shearing, a set of non-intrusive, direct manipulation interactions that expose depth and shape information in terrain maps using ephemeral animations. Reading and interpreting topography and relief on terrain maps is an important aspect of map use, but extracting depth information from 2D maps is notoriously difficult. Modern mapping software attempts to alleviate this limitation by presenting digital terrain using 3D views. However, 3D views introduce occlusion, complicate distance estimations, and typically require more complex interactions. In contrast, our approach reveals depth information via shearing animations on 2D maps, and can be paired with existing interactions such as pan and zoom. We examine explicit, integrated, and hybrid interactions for triggering relief shearing and present a version that uses device tilt to control depth effects. Our evaluation shows that these interactive techniques improve depth perception when compared to standard 2D and perspective views. © Copyright 2015 ACM.","Depth perception; Interaction; Plan oblique relief; Relief shearing; Terrain maps","Depth perception; Human computer interaction; Human engineering; Information use; Shearing; Direct manipulation; Distance estimation; Interaction; Interactive techniques; Plan oblique relief; Shape information; Terrain maps; Terrain perception; Landforms",2-s2.0-84951128822
"Jiang L., Nandi A.","Designing interactive query interfaces to teach database systems in the classroom",2015,"Conference on Human Factors in Computing Systems - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954239617&doi=10.1145%2f2702613.2732900&partnerID=40&md5=ce3198f71b273dc95ee07bd172946b93","Database systems have often been considered an unexciting topic for undergraduate curricula. To remedy this, we describe a novel interactive electronic textbook for teaching undergraduate database systems courses. Designed for touch-driven tablets, the textbook embeds a fully capable database. Expressions, figures and explanations in the textbook are live, interactive elements. In contrast to canned illustrations and animations, students can interact with each textbook element. The rapid feedback loop with the database allows the user to explore and understand the full scope of valid and invalid queries to the database. Wireless connectivity allows the instructor to track classroom performance in real-time, merging textbook instruction with in-class demonstrations, allowing for the scaling out of classrooms. We discuss the design of this concept, and share a preliminary evaluation of a prototype implementation used in the classroom. Copyright is held by the author/owner(s).","Databases; Education; Interaction; Touch","Curricula; Database systems; Education; Human computer interaction; Human engineering; Query processing; Teaching; Textbooks; Electronic textbooks; Interaction; Interactive elements; Interactive queries; Prototype implementations; Touch; Undergraduate curricula; Wireless connectivities; Query languages",2-s2.0-84954239617
"Kim M., Lee M.K., Dabbish L.","Shop-i: Gaze based interaction in the physical world for in-store social shopping experience",2015,"Conference on Human Factors in Computing Systems - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954228886&doi=10.1145%2f2702613.2732797&partnerID=40&md5=77ca0a024f49a00ce1375ab342680714","Gaze-based interaction has several benefits: naturalism, remote controllability, and easy accessibility. However, it has been mostly used for screen-based interaction with static information. In this paper, we propose a concept of gaze-based interaction that augments the physical world with social information. We demonstrate this interaction in a shopping scenario. In-store shopping is a setting where social information can augment the physical environment to better support a user's purchase decision. Based on the user's ocular point, we project the following information on the product and its surrounding surface: collective in-store gazes and purchase data, product comparison information, animation expressing ingredient of product, and online social comments. This paper presents the design of the system, the results and discussion of an informal user study, and future work. Copyright is held by the author/owner(s).","Context-aware computing; Eye tracking; Gaze based interaction; In-store shopping experience; Visual attentive interface","Human computer interaction; Human engineering; Remote control; Social aspects; Attentive interfaces; Context-aware computing; Eye-tracking; Gaze-based interaction; Physical environments; Purchase decision; Social information; Static information; Stereo vision",2-s2.0-84954228886
"Lasecki W.S., Kim J., Rafter N., Sen O., Bigham J.P., Bernstein M.S.","Apparition: Crowdsourced user interfaces that come to life as you sketch them",2015,"Conference on Human Factors in Computing Systems - Proceedings",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951079118&doi=10.1145%2f2702123.2702565&partnerID=40&md5=a9d68b4a7fd56bda76415ec721ddad5e","Prototyping allows designers to quickly iterate and gather feedback, but the time it takes to create even a Wizard-of-Oz prototype reduces the utility of the process. In this paper, we introduce crowdsourcing techniques and tools for prototyping interactive systems in the time it takes to describe the idea. Our Apparition system uses paid microtask crowds to make even hard-to-automate functions work immediately, allowing more fluid prototyping of interfaces that contain interactive elements and complex behaviors. As users sketch their interface and describe it aloud in natural language, crowd workers and sketch recognition algorithms translate the input into user interface elements, add animations, and provideWizardof- Oz functionality. We discuss how design teams can use our approach to reflect on prototypes or begin user studies within seconds, and how, over time, Apparition prototypes can become fully-implemented versions of the systems they simulate. Powering Apparition is the first self-coordinated, real-time crowdsourcing infrastructure. We anchor this infrastructure on a new, lightweight write-locking mechanism that workers can use to signal their intentions to each other. © Copyright 2015 ACM.","Crowdsourcing; Human computation; Rapid prototyping","Human computer interaction; Human engineering; Locks (fasteners); Rapid prototyping; Crowdsourcing; Human computation; Interactive elements; Interactive system; Interface elements; Locking mechanism; Sketch recognition; Techniques and tools; User interfaces",2-s2.0-84951079118
"Iwasa J.H.","Bringing macromolecular machinery to life using 3D animation",2015,"Current Opinion in Structural Biology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927585414&doi=10.1016%2fj.sbi.2015.03.015&partnerID=40&md5=dc5b33937a7d63d02346aadd726bfcbe","Over the past decade, there has been a rapid rise in the use of three-dimensional (3D) animation to depict molecular and cellular processes. Much of the growth in molecular animation has been in the educational arena, but increasingly, 3D animation software is finding its way into research laboratories. In this review, I will discuss a number of ways in which 3d animation software can play a valuable role in visualizing and communicating macromolecular structures and dynamics. I will also consider the challenges of using animation tools within the research sphere. © 2015 .",,"chemical structure; computer program; education; imaging; macromolecule; molecular animation; molecular dynamics; molecular model; priority journal; Review; three dimensional imaging; chemistry; computer simulation; macromolecule; metabolism; procedures; macromolecule; Computer Simulation; Imaging, Three-Dimensional; Macromolecular Substances",2-s2.0-84927585414
"Kent B.R.","3D scientific visualization with Blender®",2015,"3D Scientific Visualization with Blender®",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957369984&doi=10.1088%2f978-1-6270-5612-0&partnerID=40&md5=5743b5a1e124ca8e342193f3cf8eeda0","This is the first book written on using Blender (an open-source visualization suite widely used in the entertainment and gaming industries) for scientific visualization. It is a practical and interesting introduction to Blender for understanding key parts of 3D rendering that pertain to the sciences via step-by-step guided tutorials. Any time you see an awesome science animation in the news, you will now know how to develop exciting visualizations and animations with your own data. 3D Scientific Visualization with Blender takes you through an understanding of 3D graphics and modeling for different visualization scenarios in the physical sciences. This includes guides and tutorials for: understanding and manipulating the interface; generating 3D models; understanding lighting, animation, and camera control; and scripting data import with the Python API. The agility of Blender and its well organized Python API make it an exciting and unique visualization suite every modern scientific/engineering workbench should include. Blender provides multiple scientific visualizations including: solid models/surfaces/rigid body simulations; data cubes/transparent/translucent rendering; 3D catalogs; N-body simulations; soft body simulations; surface/terrain maps; and phenomenological models. The possibilities for generating visualizations are considerable via this ever growing software package replete with a vast community of users providing support and ideas. A companion website with tutorials, software, and files is available to supplement the book. You can also see several of the author's animations and visualizations on YouTube. © 2015 Morgan & Claypool Publishers. All rights reserved.",,"Animation; Application programming interfaces (API); Blending; Computer graphics; Data visualization; High level languages; Open source software; Rendering (computer graphics); Visualization; Websites; 3-D rendering; Camera controls; Companion website; Data import; N-body simulation; Open sources; Phenomenological models; Physical science; Three dimensional computer graphics",2-s2.0-84957369984
"Kretschmer H., Beaver D.D., Ozel B., Kretschmer T.","Who is collaborating with whom? Part I. Mathematical model and methods for empirical testing",2015,"Journal of Informetrics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925536586&doi=10.1016%2fj.joi.2015.01.004&partnerID=40&md5=63254e38d9201979a1330a439f665de1","There are two versions in the literature of counting co-author pairs. Whereas the first version leads to a two-dimensional (2-D) power function distribution; the other version shows three-dimensional (3-D) graphs, totally rotatable around and their shapes are visible in space from all possible points of view. As a result, these new 3-D computer graphs, called ""Social Gestalts"" deliver more comprehensive information about social network structures than simple 2-D power function distributions. The mathematical model of Social Gestalts and the corresponding methods for the 3-D visualization and animation of collaboration networks are presented in Part I of this paper. Fundamental findings in psychology/sociology and physics are used as a basis for the development of this model.The application of these new methods to male and to female networks is shown in Part II. After regression analysis the visualized Social Gestalts are rather identical with the corresponding empirical distributions (R2&gt;0.99). The structures of female co-authorship networks differ markedly from the structures of the male co-authorship networks. For female co-author pairs' networks, accentuation of productivity dissimilarities of the pairs is becoming visible but on the contrary, for male co-author pairs' networks, accentuation of productivity similarities of the pairs is expressed. © 2015 The Authors.","3-D computer graphs; Animation; Co-authorship; Mathematical model; Self-organization; Social network analysis","Animation; Distribution functions; Mathematical models; Productivity; Regression analysis; Social networking (online); Three dimensional computer graphics; 3-D computer graphs; Co-authorship networks; Co-authorships; Comprehensive information; Empirical distributions; Power function distribution; Self organizations; Social network structures; Computer networks",2-s2.0-84925536586
"Kretschmer H., Beaver D.D., Ozel B., Kretschmer T.","Who is collaborating with whom? Part II. Application of the methods to male and to female networks",2015,"Journal of Informetrics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925494337&doi=10.1016%2fj.joi.2015.01.009&partnerID=40&md5=e9c6776ce4cdfc606894cf33309c0fa9","The theoretical approach of the mathematical model of Social Gestalts and the corresponding methods for the 3-D visualization and animation of collaboration networks are presented in Part I. The application of these new methods to male and female networks is shown in Part II. After regression analysis the visualized Social Gestalts are rather identically with the corresponding empirical distributions (R2&gt;0.99). The structures of female co-authorship networks differ markedly from the structures of the male co-authorship networks. For female co-author pairs' networks, accentuation of productivity dissimilarities of the pairs is becoming visible but on the contrary, for male co-author pairs' networks, accentuation of productivity similarities of the pairs is expressed. © 2015 The Authors.","Co-authorship; Complementarities; Gender; Mathematical model; Self-organization; Social network analysis","Animation; Mathematical models; Productivity; Regression analysis; Social networking (online); Co-authorship networks; Co-authorships; Collaboration network; Complementarities; Empirical distributions; Gender; Self organizations; Theoretical approach; Three dimensional computer graphics",2-s2.0-84925494337
"Woo K.L., Rieucau G.","Computer-animated stimuli to investigate lizard visual communication: A case study in the jacky dragon",2015,"Animal Communication and Cognition: Principles, Evolution and Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956751730&partnerID=40&md5=dd8d14ca83d9289c3be0ba33aecb2629","Visual signals that are designed for effective communication are complex. Over the years, researchers interested in the study of animal communication have employed various artificial stimuli during behavioral experiments to precisely control what the observers get to see or experience. These diverse techniques to stage animal interactions have offered an alternative to the traditional experimental methods relying on the use of live companions or demonstrators. Current technological advances allow researchers to develop realistic computer-animated stimuli of social partners with high degree of fidelity for both morphological and dynamic behavioral characteristics. Because the computer-generated animation technique offers researchers with the ability to produce standardized visual stimuli while reducing the variable behavior of demonstrators across experimental sessions, its used is becoming increasingly popular in behavioral experiments in various taxa. In the following chapter, we provide an appraisal of the computergenerated animations efficiency to stage social interactions in lizards in general and the Jacky dragon (Amphibolurus muricatus) in particular. We present relevant experimental studies in which this innovative technique has been employed to simulate social partners in the Jacky dragon to address diverse ecological important questions. In addition, we consider the future of video and animation playback in the study of lizard's communication. © 2015 Nova Science Publishers, Inc.",,,2-s2.0-84956751730
"Castelo-Branco M.S., Amaral C.P., Simões M.A.","Neural signals evoked by stimuli of increasing social scene complexity are detectable at the single-trial level and right lateralized",2015,"PLoS ONE",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926309636&doi=10.1371%2fjournal.pone.0121970&partnerID=40&md5=23d79de7f4c5d9868c75b9365fd8cbd6","Classification of neural signals at the single-trial level and the study of their relevance in affective and cognitive neuroscience are still in their infancy. Here we investigated the neurophysiological correlates of conditions of increasing social scene complexity using 3D human models as targets of attention, which may also be important in autism research. Challenging single-trial statistical classification of EEG neural signals was attempted for detection of oddball stimuli with increasing social scene complexity. Stimuli had an oddball structure and were as follows: 1) flashed schematic eyes, 2) simple 3D faces flashed between averted and non-averted gaze (only eye position changing), 3) simple 3D faces flashed between averted and non-averted gaze (head and eye position changing), 4) animated avatar alternated its gaze direction to the left and to the right (head and eye position), 5) environment with 4 animated avatars all of which change gaze and one of which is the target of attention. We found a late (> 300 ms) neurophysiological oddball correlate for all conditions irrespective of their complexity as assessed by repeated measures ANOVA. We attempted single-trial detection of this signal with automatic classifiers and obtained a significant balanced accuracy classification of around 79%, which is noteworthy given the amount of scene complexity. Lateralization analysis showed a specific right lateralization only for more complex realistic social scenes. In sum, complex ecological animations with social content elicit neurophysiological events which can be characterized even at the single-trial level. These signals are right lateralized. These finding paves the way for neuroscientific studies in affective neuroscience based on complex social scenes, and given the detectability at the single trial level this suggests the feasibility of brain computer interfaces that can be applied to social cognition disorders such as autism. © 2015 Amaral et al.",,"accuracy; adult; Article; attention; brain function; cell function; controlled study; data analysis; evoked somatosensory response; eye dominance; eye position; female; functional assessment; gaze; human; human experiment; male; mental task; molecular dynamics; signal detection; signal transduction; social cognition; stimulus response; task performance; young adult; brain; brain mapping; electroencephalography; eye movement; hemispheric dominance; pattern recognition; perception; photostimulation; physiology; Adult; Attention; Brain; Brain Mapping; Electroencephalography; Eye Movements; Female; Functional Laterality; Humans; Male; Pattern Recognition, Visual; Photic Stimulation; Social Perception; Young Adult",2-s2.0-84926309636
"Wei L., Deng Z.","A Practical Model for Live Speech-Driven Lip-Sync",2015,"IEEE Computer Graphics and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964216465&doi=10.1109%2fMCG.2014.105&partnerID=40&md5=0c561023e6fca3342af017ca0dffac83","This article introduces a simple, efficient, yet practical phoneme-based approach to generate realistic speech animation in real time based on live speech input. Specifically, the authors first decompose lower-face movements into low-dimensional principal component spaces. Then, in each of the retained principal component spaces, they select the AnimPho with the highest priority value and the minimum smoothness energy. Finally, they apply motion blending and interpolation techniques to compute final animation frames for the currently inputted phoneme. Through many experiments and comparisons, the authors demonstrate the realism of synthesized speech animation by their approach as well as its real-time efficiency on an off-the-shelf computer. © 1981-2012 IEEE.","computer graphics; facial animation; live speech driven; speech animation; talking avatars; virtual humans","Animation; Blending; Computer graphics; Principal component analysis; Virtual reality; Facial animation; Live speech driven; Speech animation; talking avatars; Virtual humans; Speech; anatomy and histology; anatomy and histology; automated pattern recognition; biological model; computer assisted diagnosis; computer simulation; facial recognition; lip; physiology; procedures; reproducibility; sensitivity and specificity; speech; speech analysis; three dimensional imaging; anatomy and histology; anatomy and histology; Computer Simulation; Computer Simulation; Facial Recognition; Facial Recognition; Image Interpretation, Computer-Assisted; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Imaging, Three-Dimensional; Lip; Lip; methods; methods; methods; methods; methods; methods; methods; methods; Models, Biological; Models, Biological; Pattern Recognition, Automated; Pattern Recognition, Automated; physiology; physiology; physiology; physiology; physiology; physiology; Reproducibility of Results; Reproducibility of Results; Sensitivity and Specificity; Sensitivity and Specificity; Speech; Speech; Speech Production Measurement; Speech Production Measurement",2-s2.0-84964216465
"Garber L.","News",2015,"Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926034341&doi=10.1109%2fMC.2015.80&partnerID=40&md5=2145fd798b648a1fbfe1221705933d05","Topics include hackers stealing data for up to 80 million US insurance customers, mobile systems starting to use advanced technologies to improve cellular telephony, 19,000 French websites suffering cybervandalism in the wake of the country's recent terrorist attacks, researchers discovering a security flaw that could let hackers eavesdrop on cell calls, the US government requiring faster speeds for broadband services over ISPs' objections, researchers developing a poker-winning application, scientists developing a way to make supercomputers more efficient and powerful by changing the way they perform checkpointing, a new head-mounted display that projects images directly onto users' eyes, a new RAM approach could enable ultrafast smartphones, a Linux bug representing a major Internet threat, several big technology firms settling a lawsuit over accusations that they conspired to limit workers' wages, and a list of 2014's 'worst' passwords having a familiar look. © 1970-2012 IEEE.","Adobe Systems; Agence Nationale de la Sécurité des Systèmes d'Information; and HD Voice; ANSSI; Anthem Inc.; Apple; artificial intelligence; Avegant Inc.; broadband; cellular; Cepheus; Charlie Hebdo; checkpointing; counterfactual regret minimization; Devesh Tiwari; digital-light-processing; display technology; DLP; FCC; Federal Communications Commission; France; French Defense Ministry; game theory; Ghost; glibc; Glyph headset; GNU C Library; Google; Intel; Intuit; Karsten Nohl; Kickstarter; lawsuit; lazy checkpointing; Linux; Lucasfilm; Mark Burnett; Michael Devine; mobile; Morgan Slain; Nash equilibrium; Oak Ridge Leadership Computing Facility; Oak Ridge National Laboratory; OLCF; passwords; perfect information games; Pixar Animation Studios; privacy; professor Michael Bowling; Qualys; resistive random-access memory; Rice University; RRAM; Saurabh Gupta; security; settlement; Signaling System 7; silicon oxide; SplashData; SS7; supercomputers; supercomputing; terrorism; Texas hold 'em poker; Tobias Engel; University of Alberta; US District Court Judge Lucy Koh; Voice over LTE; vulnerability; Wi-Fi Calling","Animation; Artificial intelligence; Authentication; Computation theory; Computer games; Computer operating systems; Data privacy; Digital libraries; Game theory; Helmet mounted displays; Internet service providers; Linux; Mobile security; Mobile telecommunication systems; Personal computing; Secure communication; Silicon oxides; Supercomputers; Terrorism; Wireless telecommunication systems; Adobe systems; Alberta; Animation studios; ANSSI; Anthem Inc; Apple; Avegant Inc; broadband; cellular; Cepheus; Charlie Hebdo; Check pointing; Computing facilities; Devesh Tiwari; Digital light processing; Display technologies; DLP; FCC; Federal communications commission; France; French Defense Ministry; Ghost; glibc; Glyph headset; Google; Intel; Intuit; Karsten Nohl; Kickstarter; lawsuit; Lucasfilm; Mark Burnett; Michael Devine; mobile; Morgan Slain; Nash equilibria; Oak ridge National Laboratory; OLCF; passwords; Perfect informations; professor Michael Bowling; Qualys; Regret minimization; Resistive random access memory; Rice University; RRAM; Saurabh Gupta; security; settlement; Signaling systems; SplashData; SS7; supercomputing; Texas Hold'em; Tobias Engel; US District Court; vulnerability; Random access storage",2-s2.0-84926034341
"Yeh C.-K., Jayaraman P.K., Liu X., Fu C.-W., Lee T.-Y.","2.5D cartoon hair modeling and manipulation",2015,"IEEE Transactions on Visualization and Computer Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922574322&doi=10.1109%2fTVCG.2014.2360406&partnerID=40&md5=5f76d3c8f96e52bfd5cf6e8d054c8117","This paper addresses a challenging single-view modeling and animation problem with cartoon images. Our goal is to model the hairs in a given cartoon image with consistent layering and occlusion, so that we can produce various visual effects from just a single image. We propose a novel 2.5D modeling approach to deal with this problem. Given an input image, we first segment the hairs of the cartoon character into regions of hair strands. Then, we apply our novel layering metric, which is derived from the Gestalt psychology, to automatically optimize the depth ordering among the hair strands. After that, we employ our hair completion method to fill the occluded part of each hair strand, and create a 2.5D model of the cartoon hair. By using this model, we can produce various visual effects, e.g., we develop a simplified fluid simulation model to produce wind blowing animations with the 2.5D hairs. To further demonstrate the applicability and versatility of our method, we compare our results with real cartoon hair animations, and also apply our model to produce a wide variety of hair manipulation effects, including hair editing and hair braiding. © 1995-2012 IEEE.","2.5D modeling; cartoon; layering; Single-view modeling; still image animation","Animation; cartoon; Cartoon characters; Completion methods; Fluid simulations; Gestalt psychologies; layering; Single view modeling; Still images; Image segmentation; adult; algorithm; computer graphics; female; hair; human; image processing; male; physiology; procedures; young adult; Adult; Algorithms; Computer Graphics; Female; Hair; Humans; Image Processing, Computer-Assisted; Male; Young Adult",2-s2.0-84922574322
"Fan X., Wang H., Luo Z., Li Y., Hu W., Luo D.","Fiducial facial point extraction using a novel projective invariant",2015,"IEEE Transactions on Image Processing",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923164236&doi=10.1109%2fTIP.2015.2390976&partnerID=40&md5=80e64ba31a11d36cd440a2a9a86ee318","Automatic extraction of fiducial facial points is one of the key steps to face tracking, recognition, and animation. Great facial variations, especially pose or viewpoint changes, typically degrade the performance of classical methods. Recent learning or regression-based approaches highly rely on the availability of a training set that covers facial variations as wide as possible. In this paper, we introduce and extend a novel projective invariant, named the characteristic number (CN), which unifies the collinearity, cross ratio, and geometrical characteristics given by more (6) points. We derive strong shape priors from CN statistics on a moderate size (515) of frontal upright faces in order to characterize the intrinsic geometries shared by human faces. We combine these shape priors with simple appearance based constraints, e.g., texture, edge, and corner, into a quadratic optimization. Thereafter, the solution to facial point extraction can be found by the standard gradient descent. The inclusion of these shape priors renders the robustness to pose changes owing to their invariance to projective transformations. Extensive experiments on the Labeled Faces in the Wild, Labeled Face Parts in the Wild and Helen database, and cross-set faces with various changes demonstrate the effectiveness of the CN-based shape priors compared with the state of the art. © 2014 IEEE.","characteristic number; Fiducial facial point extraction; pose changes; projective invariant","Animation; Extraction; Face recognition; Quadratic programming; Automatic extraction; characteristic number; Geometrical characteristics; Point extraction; pose changes; Projective invariant; Projective transformation; Quadratic optimization; Object recognition; adult; algorithm; anatomy and histology; automated pattern recognition; child; face; factual database; female; human; image processing; male; procedures; Adult; Algorithms; Child; Databases, Factual; Face; Female; Humans; Image Processing, Computer-Assisted; Male; Pattern Recognition, Automated",2-s2.0-84923164236
"Hsu C.-C., Kang L.-W., Lin C.-W.","Temporally coherent superresolution of textured video via dynamic texture synthesis",2015,"IEEE Transactions on Image Processing",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921875963&doi=10.1109%2fTIP.2014.2387416&partnerID=40&md5=353c1b2d5ebd2dea2330a5eb98a7455a","This paper addresses the problem of hallucinating the missing high-resolution (HR) details of a low-resolution (LR) video while maintaining the temporal coherence of the reconstructed HR details using dynamic texture synthesis (DTS). Most existing multiframe-based video superresolution (SR) methods suffer from the problem of limited reconstructed visual quality due to inaccurate subpixel motion estimation between frames in an LR video. To achieve high-quality reconstruction of HR details for an LR video, we propose a texture-synthesis (TS)-based video SR method, in which a novel DTS scheme is proposed to render the reconstructed HR details in a temporally coherent way, which effectively addresses the temporal incoherence problem caused by traditional TS-based image SR methods. To further reduce the complexity of the proposed method, our method only performs the TS-based SR on a set of key frames, while the HR details of the remaining nonkey frames are simply predicted using the bidirectional overlapped block motion compensation. After all frames are upscaled, the proposed DTS-SR is applied to maintain the temporal coherence in the HR video. Experimental results demonstrate that the proposed method achieves significant subjective and objective visual quality improvement over state-of-the-art video SR methods. © 1992-2012 IEEE.","dynamic texture synthesis; motion-compensated interpolation; video hallucination; Video super-resolution; video upscaling","Animation; Motion compensation; Motion estimation; Optical resolving power; Textures; Dynamic textures; Motion compensated interpolation; video hallucination; Video super-resolution; Video upscaling; Computer graphics",2-s2.0-84921875963
"Plaisant C., Wu J., Hettinger A.Z., Powsner S., Shneiderman B.","Novel user interface design for medication reconciliation: an evaluation of Twinlist",2015,"Journal of the American Medical Informatics Association : JAMIA",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934290559&doi=10.1093%2fjamia%2focu021&partnerID=40&md5=3ef621ff27c8378688e0f7cd89a7fc86","MATERIAL AND METHODS: A 1 × 2 within-subjects experimental design was used with interface (Twinlist or Control) as an independent variable; time, number of clicks, scrolls, and errors were used as dependent variables. Participants were practicing medical providers with experience performing medication reconciliation but no experience with Twinlist. They reconciled two cases in each interface (in a counterbalanced order), then provided feedback on the design of the interface.RESULTS: Twenty medical providers participated in the study for a total of 80 trials. The trials using Twinlist were statistically significantly faster (18%), with fewer clicks (40%) and scrolls (60%). Serious errors were noted 12 and 31 times in Twinlist and Control trials, respectively.DISCUSSION: Trials using Twinlist were faster and more accurate. Subjectively, participants rated Twinlist more favorably than Control. They valued the novel layout of the drugs, but indicated that the included animation would be valuable for novices, but not necessarily for advanced users. Additional feedback from participants provides guidance for further development and clinical implementations.CONCLUSIONS: Cognitive support of medication reconciliation through interface design can significantly improve performance and safety.OBJECTIVE: The primary objective was to evaluate time, number of interface actions, and accuracy on medication reconciliation tasks using a novel user interface (Twinlist, which lays out the medications in five columns based on similarity and uses animation to introduce the grouping - www.cs.umd.edu/hcil/sharp/twinlist) compared to a Control interface (where medications are presented side by side in two columns). A secondary objective was to assess participant agreement with statements regarding clarity and utility and to elicit comparisons. © The Author 2015. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved. For Permissions, please email: journals.permissions@oup.com.","human factors; medication reconciliation; user-computer interface","attitude to computers; audiovisual aid; computer assisted drug therapy; computer interface; data base; evaluation study; human; information processing; medication therapy management; procedures; productivity; questionnaire; Attitude to Computers; Audiovisual Aids; Data Display; Databases as Topic; Drug Therapy, Computer-Assisted; Efficiency; Humans; Medication Reconciliation; Questionnaires; User-Computer Interface",2-s2.0-84934290559
"Vemuri K., Surampudi B.R.","Evidence of stimulus correlated empathy modes - Group ICA of fMRI data",2015,"Brain and Cognition",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921877507&doi=10.1016%2fj.bandc.2014.12.006&partnerID=40&md5=45a097b6bc2b69847a2ad428e136b769","The analysis of the cognitive processes in response to a narrative as presented in a movie provides an insight into momentary reaction to a single depicted action like a facial expression and an aggregate processing of the entire sequence of events. In this study we report results from fMRI data analyzed by group independent component analysis (ICA) method from a free viewing experiment using a diverse set of movie clips - an animation, a Hollywood and an Indian Hindi movie. The fMRI data were collected from 15 college students as they viewed 5-8. min clips from three movies. The movie clips were rated for depiction of emotional expressions, the emotion as per the narrative and the viewer's own empathy response. The neural correlates attributed to cognitive, motor and emotional empathy were the focus of the study. The methodology of using long duration stimuli in free viewing mode combined with ICA analysis has the potential to tease out spatially distributed but temporally coherent brain activity as demonstrated in this study. The independent components obtained from group ICA method isolated spatial maps with activations which can be safely ascribed to stimulus processing. We found that the activity in the areas attributable to cognitive and motor empathy was comparable for all the three stimuli while certain critical areas for emotional empathy were not noticed for the animation movie. These findings lead to interesting questions on possible differential emotion response in viewer(s) for computer generated actors compared to actors in live-action movies and the role of narrative and exposure to different genre of movies on racial, ethnic and cultural differences in empathy response. © 2015 Elsevier Inc.","Cartoon characters; Empathy networks; FMRI; Group ICA method; Movie","adult; Article; brain function; brain region; cognition; college student; correlation analysis; cultural anthropology; emotionality; empathy; ethnic difference; female; functional magnetic resonance imaging; human; human experiment; independent component analysis; information processing; male; methodology; narrative; normal human; race difference; stimulus response; videorecording; volunteer; young adult; brain; brain mapping; emotion; empathy; facial expression; image processing; nuclear magnetic resonance imaging; photostimulation; physiology; procedures; Adult; Brain; Brain Mapping; Emotions; Empathy; Facial Expression; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Photic Stimulation; Young Adult",2-s2.0-84921877507
"Ursyn A.","Handbook of research on maximizing cognitive learning through knowledge visualization",2015,"Handbook of Research on Maximizing Cognitive Learning through Knowledge Visualization",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946116828&doi=10.4018%2f978-1-4666-8142-2&partnerID=40&md5=b61f96cdc4d85d3db3f4148b1981691e","The representation of abstract data and ideas can be a difficult and tedious task to handle when learning new concepts; however, the advances of emerging technology have allowed for new methods of representing such conceptual data. The Handbook of Research on Maximizing Cognitive Learning through Knowledge Visualization focuses on the use of visualization technologies to assist in the process of better comprehending scientific concepts, data, and applications. Highlighting the utilization of visual power and the roles of sensory perceptions, computer graphics, animation, and digital storytelling, this book is an essential reference source for instructors, engineers, programmers, and software developers interested in the exchange of information through the visual depiction of data. © 2015 by IGI Global. All rights reserved.",,,2-s2.0-84946116828
"Gusev M.E., Alekseenko I.V.","A Study of Multicomponent Mechanical Oscillations by the Method of Digital Holographic Vibrometry",2015,"Radiophysics and Quantum Electronics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939268051&doi=10.1007%2fs11141-015-9537-x&partnerID=40&md5=5320d4d70e39c1ec33fbec49ae3bead5","We analyze the basic principles and features of the digital recording and reconstruction of holographic images and interferograms. The advantages and disadvantages of digital interferograms are presented in comparison with the classical analog interferograms. The main requirements to the parameters of software and hardware for digital holographic interferometry are indicated. Examples of practical application of the digital holographic interferometry for analyzing various vibrations under both laboratory and industrial conditions are given. A number of new high-efficiency methods for performing vibrational measurements and analyzing multicomponent free and coupled oscillations and impact vibrational excitations are described, and examples of a particular realization with presentation of the results in the form of computer dynamic animation visualization (three-dimensional representation in time) are given. Promising methods of vibrational measurements related to the programmed multiframe recording and subsequent multifunctional analysis of the recorded data array with animation of the results are proposed. © 2015, Springer Science+Business Media New York.",,"Animation; Holographic interferometry; Holography; Interferometry; Three dimensional computer graphics; Coupled oscillations; Digital holographic interferometry; Dimensional representation; Holographic images; Industrial conditions; Mechanical oscillations; Software and hardwares; Vibrational excitation; Vibration analysis",2-s2.0-84939268051
"Braga J.C., Pimentel E., Stiubiener I., Dotta S.","Experimentation and analysis of undergraduate students performance and satisfaction in a blended model of an introductory computer science and programming course",2015,"Proceedings - Frontiers in Education Conference, FIE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938117944&doi=10.1109%2fFIE.2014.7044071&partnerID=40&md5=75f6d6d12210cbc676b2cd86ad4402f7","Introduction to computer science and programming are courses that play an important role in students' performance in computer and engineering degrees. It is in this course that students learn the main basic concepts and computational structures to be applied in all kind of computer systems. Despite its importance, many teachers and many studies report difficulties observed in learning of these subjects, resulting in a high rate of failure and lack of motivation among students. There are many experiments reported in the literature that attempted to solve this problem, such as: different pedagogical approaches, the use of special hardware like tablets, and the use of learning objects; however, all these formats are applied based on traditional classroom learning formats which results in the same type of result. Even some innovative approaches that did not present a formal validation of the process ended up losing as a methodology. Considering this scenario and the importance of this discipline in students' curriculum, we propose a blended model, that uses distance learning environments allied to new technologies, aimed to contribute with students performance and knowledge acquirement. In this blended model, one programming course was developed and applied to 92 students in computer science and engineering degrees, with course material consisting of video lectures and animations that were used to show and to explain critical concepts of the discipline where students often have problems. All this material was implanted by a Learning Management System (LMS), which showed statistical reports about all activities, including collaborative and interactive activities. We also used together with the LMS a dedicated community on Facebook and, in this article we present our analysis and some conclusions obtained by observing the interactions of students on Facebook and on LMS. We did a few meetings between students and teachers and also developed a methodology for tutoring with our tutors to improve our students' participation in the activities proposed during the course. In this paper, we describe the methodology in which we developed everything. We also present the results achieved in terms of students' performance and provides comparison with other students who attended conventional courses in programming. © 2014 IEEE.","ADDIE; Computer Programming; Distance Education; Instructional Desing; INTERA","Computer aided instruction; Computer programming; Curricula; Distance education; Education; Education computing; Social networking (online); Teaching; ADDIE; Computational structure; Computer science and engineerings; Distance learning environment; Instructional Desing; INTERA; Introductory computer science; Learning management system; Students",2-s2.0-84938117944
"Restrepo A.M., Figueroa P.","Designing a blended learning curriculum in the development of video games",2015,"Proceedings - Frontiers in Education Conference, FIE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938152544&doi=10.1109%2fFIE.2014.7044292&partnerID=40&md5=ba29f2ef91eb6ea6b6717b3da33b90ca","Recent studies from the Bogota Chamber of Commerce (Cámara de Comercio de Bogotá) in the field of digital animation and video games in Colombia show an accelerated growth of this industry in the last decade, positioning it as one of the most important for years to come. However, this strategic sector has very few adequate specialized academic training in the country, as identified in the study of Animation and Video Games Education [1]. This explains why a study by Universidad de los Andes in 2012, in collaboration with the Ministry of ICT and PROEXPORT, on the domestic supply of digital content, in Colombia people dedicated to this work are mostly professionals in design and systems engineers, programs that now have no specific training for this industry. This makes harder the process of production and game development for the companies, and increases investment costs and time needed to train professionals in the workplace. So, it is necessary to give specialized education in video games. We designed a postgraduate program in Game Development that aims to the needs expressed by this contemporary productive sector. Its aim is to prepare professionals to achieve the creation of high-impact video games for different platforms and devices. The goal is training leaders that will give to the development of projects that promote interdisciplinary and teamwork who are skilled in the production and understand the design process and development of video games. In order to reach a wider audience in different regions of the country and responding to the needs of industry, this program will be offered in blended learning model, which will promote flexibility and autonomous learning. The program aims to prepare professionals from various branches to direct own projects game industry, able to coordinate and lead interdisciplinary working groups. Throughout the postgraduate program, students will develop specific skills in the area of their choice, which can be programming, graphic art or audio. © 2014 IEEE.","Blended learning; Curriculum Design; Video games","Animation; Curricula; Education; Education computing; Personnel training; Software design; Students; Academic training; Autonomous learning; Blended learning; Chamber of Commerce; Curriculum designs; Postgraduate programs; Strategic sectors; Video game; Human computer interaction",2-s2.0-84938152544
"Al-Jarrah A., Pontelli E.","AliCe-ViLlagE Alice as a Collaborative Virtual Learning Environment",2015,"Proceedings - Frontiers in Education Conference, FIE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938150502&doi=10.1109%2fFIE.2014.7044089&partnerID=40&md5=ecbd5745eb11db2a46e846de6ce16335","There is a growing literature demonstrating the importance of collaboration and teamwork in the process of learning computational thinking and the foundational aspects of computer science. While Collaborative Virtual Environments are becoming widespread in the software development professional domain and in various areas of advanced learning, their use in the introductory stages of learning computing is still very limited. On the other hand, in recent years, there has been a blooming of attractive programming environments specifically designed to expose young students (e.g., middle school age) to computational thinking. Alice is a very popular introductory programming environment, focused on programming through animations and story-telling. This paper introduces a novel extension of the Alice framework that enables interaction and collaboration among students in the development of programs. In particular, the new version of Alice described in this paper provides support for virtual pair programming. The modified version of Alice allows two students to remotely share a virtual world, and interact in its construction; the system supports roles assignments, to allow teachers to control activities and contributions of the two students in the creation of a programming project. © 2014 IEEE.",,"Computer aided instruction; Education; Software design; Teaching; Virtual reality; Collaborative virtual environment; Collaborative virtual learning environments; Computational thinkings; Foundational aspects; Introductory programming; Process of learning; Programming environment; Programming projects; Students",2-s2.0-84938150502
"Austin B.","Technology, art therapy, and psychodynamic theory: Computer animation with an adolescent in foster care",2015,"Video and Filmmaking as Psychotherapy: Research and Practice",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958597562&doi=10.4324%2f9781315769851&partnerID=40&md5=21cac1a56ba1ef7af59b03ddda465230",[No abstract available],,,2-s2.0-84958597562
"Shao X., Zhou Z., Magnenat-Thalmann N., Wu W.","Stable and fast fluid-solid coupling for incompressible SPH",2015,"Computer Graphics Forum",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923882825&doi=10.1111%2fcgf.12467&partnerID=40&md5=8c3827a70d0e64840d0582dbf745f0e6","The solid boundary handling has been a research focus in physically based fluid animation. In this paper, we propose a novel stable and fast particle method to couple predictive-corrective incompressible smoothed particle hydrodynamics and geometric lattice shape matching (LSM), which animates the visually realistic interaction of fluids and deformable solids allowing larger time steps or velocity differences. By combining the boundary particles sampled from solids with a momentum-conserving velocity-position correction scheme, our approach can alleviate the particle deficiency issues and prevent the penetration artefacts at the fluid-solid interfaces simultaneously. We further simulate the stable deformation and melting of solid objects coupled to smoothed particle hydrodynamics fluids based on a highly extended LSM model. In order to improve the time performance of each time step, we entirely implement the unified particle framework on GPUs using compute unified device architecture. The advantages of our two-way fluid-solid coupling method in computer animation are demonstrated via several virtual scenarios. The solid boundary handling has been a research focus in physically based fluid animation. In this paper, we propose a novel stable and fast particle method to couple Predictive-Corrective Incompressible SPH (PCISPH) and geometric Lattice Shape Matching (LSM), which animates the visually realistic interaction of fluids and deformable solids allowing larger time steps or velocity differences. © 2014 The Eurographics Association and John Wiley & Sons Ltd.","fluid modelling; I.3.3 [Computer Graphics]: Three-Dimensional Graphics and Realism Animation; physically based animation; point-based animation","Animation; Computer graphics; Deformation; Fluid dynamics; Parallel architectures; Program processors; Three dimensional computer graphics; Compute unified device architectures; Fluid modelling; Fluid-solid interfaces; Physically based fluid animation; Physically-based animation; Point-based animation; Smoothed particle hydrodynamics; Three-dimensional graphics and realism; Hydrodynamics",2-s2.0-84923882825
"Celikcan U., Yaz I.O., Capin T.","Example-based retargeting of human motion to arbitrary mesh models",2015,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923917962&doi=10.1111%2fcgf.12507&partnerID=40&md5=bcbbc17976593cf7e297b2c31a1ff41f","We present a novel method for retargeting human motion to arbitrary 3D mesh models with as little user interaction as possible. Traditional motion-retargeting systems try to preserve the original motion, while satisfying several motion constraints. Our method uses a few pose-to-pose examples provided by the user to extract the desired semantics behind the retargeting process while not limiting the transfer to being only literal. Thus, mesh models with different structures and/or motion semantics from humanoid skeletons become possible targets. Also considering the fact that most publicly available mesh models lack additional structure (e.g. skeleton), our method dispenses with the need for such a structure by means of a built-in surface-based deformation system. As deformation for animation purposes may require non-rigid behaviour, we augment existing rigid deformation approaches to provide volume-preserving and squash-and-stretch deformations. We demonstrate our approach on well-known mesh models along with several publicly available motion-capture sequences. We present a novel method for retargeting human motion to arbitrary 3D mesh models with as little user interaction as possible. Traditional motion-retargeting systems try to preserve the original motion, while satisfying several motion constraints. Our method uses a few pose-to-pose examples provided by the user to extract the desired semantics behind the retargeting process while not limiting the transfer to being only literal. Thus, mesh models with different structures and/or motion semantics from humanoid skeletons become possible targets. © 2014 The Eurographics Association and John Wiley & Sons Ltd.","animation systems; deformations; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Animation; motion capture; retargeting","Animation; Computer graphics; Deformation; Musculoskeletal system; Semantics; Additional structures; Animation systems; Different structure; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Motion capture; Motion retargeting; retargeting; Squash and stretches; Three dimensional computer graphics",2-s2.0-84923917962
"Huber M., Eberhardt B., Weiskopf D.","Boundary handling at cloth-fluid contact",2015,"Computer Graphics Forum",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923879029&doi=10.1111%2fcgf.12455&partnerID=40&md5=ade78a6fb36626978de3e8264620af8d","We present a robust and efficient method for the two-way coupling between particle-based fluid simulations and infinitesimally thin solids represented by triangular meshes. Our approach is based on a hybrid method that combines a repulsion force approach with a continuous intersection handling to guarantee that no penetration occurs. Moreover, boundary conditions for the tangential component of the fluid's velocity are implemented to model the different slip conditions. The proposed method is particularly useful for dynamic surfaces, like cloth and thin shells. In addition, we demonstrate how standard fluid surface reconstruction algorithms can be modified to prevent the calculated surface from intersecting close objects. For both the two-way coupling and the surface reconstruction, we take into account that the fluid can wet the cloth. We have implemented our approach for the bidirectional interaction between liquid simulations based on Smoothed Particle Hydrodynamics (SPH) and standard mesh-based cloth simulation systems. We present a robust and efficient method for the two-way coupling between particle-based fluid simulations and infinitesimally thin solids represented by triangular meshes. Our approach is based on a hybrid method that combines a repulsion force approach with a continuous intersection handling to guarantee that no penetration occurs. © 2014 The Eurographics Association and John Wiley & Sons Ltd.","cloth simulation; cloth-fluid coupling; fluid simulation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Animation; physically-based animation","Animation; Computer graphics; Hydrodynamics; Three dimensional computer graphics; Cloth simulation; Fluid couplings; Fluid simulations; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Physically-based animation; Surface reconstruction",2-s2.0-84923879029
"Xu M., Wu Y., Ye Y., Farkas I., Jiang H., Deng Z.","Collective crowd formation transform with mutual information-based runtime feedback",2015,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923860177&doi=10.1111%2fcgf.12459&partnerID=40&md5=6b63c5aad63a9977fa08e8eed721b54f","This paper introduces a new crowd formation transform approach to achieve visually pleasing group formation transition and control. Its core idea is to transform crowd formation shapes with a least effort pair assignment using the Kuhn-Munkres algorithm, discover clusters of agent subgroups using affinity propagation and Delaunay triangulation algorithms and apply subgroup-based social force model (SFM) to the agent subgroups to achieve alignment, cohesion and collision avoidance. Meanwhile, mutual information of the dynamic crowd is used to guide agents' movement at runtime. This approach combines both macroscopic (involving least effort position assignment and clustering) and microscopic (involving SFM) controls of the crowd transformation to maximally maintain subgroups' local stability and dynamic collective behaviour, while minimizing the overall effort (i.e. travelling distance) of the agents during the transformation. Through simulation experiments and comparisons, we demonstrate that this approach is efficient and effective to generate visually pleasing and smooth transformations and outperform several existing crowd simulation approaches including reciprocal velocity avoidances, optimal reciprocal collision avoidance and OpenSteer. This paper introduces a new crowd formation transform approach to achieve visually pleasing group formation transition and control. Its core idea is to transform crowd formation shapes with a least-effort pair assignment using the Kuhn-Munkres algorithm, discover clusters of agent subgroups using affinity propagation and Delaunay triangulation algorithms, and apply subgroup-based SFM (social force model) to the agent subgroups to achieve alignment, cohesion and collision avoidance. © 2014 The Eurographics Association and John Wiley & Sons Ltd.","animation; animation; behavioral animation; I.3.6 [Computer Graphics]: Methodology and Techniques Interaction Techniques; I.3.7 [Computer Graphics]: 3D Graphics and Realism Animation; motion control","Adhesion; Algorithms; Alignment; Animation; Collision avoidance; Computer graphics; Motion control; Surveying; Three dimensional computer graphics; Triangulation; 3D graphics; Affinity propagation; Behavioral animation; Collective behaviour; Delau-nay triangulations; I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction techniques; Mutual informations; Smooth transformation; Clustering algorithms",2-s2.0-84923860177
"Zhu F., Li S., Wang G.","Example-based materials in laplace-beltrami shape space",2015,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923935167&doi=10.1111%2fcgf.12457&partnerID=40&md5=f522f2f1893e6c74e957a524baf1d465","We present a novel method for flexible and efficient simulation of example-based elastic deformation. The geometry of all input shapes is projected into a common shape space spanned by the Laplace-Beltrami eigenfunctions. The eigenfunctions are coupled to be compatible across shapes. Shape representation in the common shape space is scale-invariant and topology-independent. The limitation of previous example-based approaches is circumvented that all examples must have identical topology with the simulated object. Additionally, our method allows examples that are arbitrary in size, similar but not identical in shape with the object. We interpolate the examples via a weighted-energy minimization to find the target configuration that guides the object to desired deformation. Large deformation between examples is handled by a physically plausible energy metric. This optimization is efficient as the eigenfunctions are pre-computed and the problem dimension is small. We demonstrate the benefits of our approach with animation results and performance analysis. We present a novel method for flexible and efficient simulation of example-based elastic deformation. The geometry of all input shapes is projected into a common shape space spanned by the Laplace-Beltrami eigenfunctions. The eigenfunctions are coupled to be compatible across shapes. Shape representation in the common shape space is scale-invariant and topology-independent. The limitation of previous example-based approaches is circumvented that all examples must have identical topology with the simulated object. © 2014 The Eurographics Association and John Wiley & Sons Ltd.","deformable simulation; example-based materials; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Animation; Laplace Beltrami eigen-analysis","Animation; Computer graphics; Eigenvalues and eigenfunctions; Elastic deformation; Laplace transforms; Topology; deformable simulation; Efficient simulation; Eigen analysis; Example based; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Laplace-Beltrami eigenfunctions; Target configurations; Topology-independent; Three dimensional computer graphics",2-s2.0-84923935167
"Wende K.C., Nagels A., Stratmann M., Chatterjee A., Kircher T., Straube B.","Neural basis of altered physical and social causality judgements in schizophrenia",2015,"Schizophrenia Research",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921442255&doi=10.1016%2fj.schres.2014.11.007&partnerID=40&md5=9635dd73804e3d936f7799d65781ebfe","Patients with schizophrenia (SZ) often make aberrant cause and effect inferences in non-social and social situations. Likewise, patients may perceive cause-and-effect relationships abnormally as a result of an alteration in the physiology of perception. The neural basis for dysfunctions in causality judgements in the context of both physical motion and social motion is unknown. The current study used functional magnetic resonance imaging (fMRI) to investigate a group of patients with SZ and a group of control subjects performing judgements of causality on animated collision sequences (launch-events, Michotte, 1963) and comparable ""social"" motion stimuli. In both types of animations, similar motion trajectories of the affected object were configured, using parametrical variations of space (angle deviation) and time (delay).At the behavioural level, SZ patients made more physical and less social causal judgements than control subjects, and their judgements were less influenced by motion attributes (angle/time delay). In the patients group, fMRI revealed greater BOLD-responses, during both physical and social causality judgements (group × task interaction), in the left inferior frontal gyrus (L.IFG). Across conditions (main effect), L.IFG-interconnectivity with bilateral occipital cortex was reduced in the patient group. This study provides the first insight into the neural correlates of altered causal judgements in SZ. Patients with SZ tended to over-estimate physical and under-estimate social causality. In both physical and social contexts, patients are influenced less by motion parameters (space and time) than control subjects. Imaging findings of L.IFG-disconnectivity and task-related hyper-activation in the patient group could indicate common dysfunctions in the neural activations needed to integrate external cue-information (space/time) with explicit (top-down) cause-effect judgements of object motions in physical and social settings. © 2014 Elsevier B.V.","FMRI; Inference; Launch-events; Physical causality; Schizophrenia; Social causality","adult; Article; behavior assessment; BOLD signal; brain depth stimulation; clinical article; connectome; controlled study; decision making; electroencephalogram; female; functional magnetic resonance imaging; functional neuroimaging; human; inferior frontal gyrus; inferior parietal lobule; left inferior frontal gyrus; male; negative syndrome; nerve potential; occipital cortex; physical causality; Positive and Negative Syndrome Scale; positive syndrome; response time; schizophrenia; social causality; task performance; voxel based morphometry; blood; brain; brain mapping; case control study; decision making; epidemiology; image processing; middle aged; nuclear magnetic resonance imaging; pathology; pathophysiology; physiology; psychology; schizophrenia; social behavior; vascularization; young adult; oxygen; Adult; Brain; Brain Mapping; Case-Control Studies; Causality; Female; Humans; Image Processing, Computer-Assisted; Judgment; Magnetic Resonance Imaging; Male; Middle Aged; Oxygen; Schizophrenia; Schizophrenic Psychology; Social Behavior; Young Adult",2-s2.0-84921442255
"Ostherr K.","Animating Informatics: Scientific Discovery Through Documentary Film",2015,"A Companion to Contemporary Documentary Film",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976536402&doi=10.1002%2f9781118884584.ch13&partnerID=40&md5=164f7b66c0021a2e76e6428764076c75","Scientists have employed documentary filmmaking practices in their laboratory experiments since the late nineteenth century. Their efforts to visualize unseen organisms blended the documentary capacities of cinema with the medium's ability to animate and simulate life, and these practices continue in the twenty-first century. A core premise of this study is that early science films animated cells, just as computers now animate data, and all of these practices can productively expand our understanding of documentary film. Through close analysis of two exemplary films, Development of the Fertilized Rabbit Ovum (1929) and The Inner Life of the Cell (2006), this chapter explains how the visual representation of cellular life has been a critical site of intersection for science and film since the early twentieth century. Shifting to focus on the processes by which hard data in the life sciences are now converted into animated images in computers, the chapter then analyzes how these ""informatic"" images make powerful documentary claims despite their profound mediation by software that makes pictures out of numbers. The chapter argues that the resulting ""images of objectivity"" are shaped by narrative and aesthetic strategies that have, in turn, shaped the relationships between science, documentary, and animation from the origins of cinema to the present day. © 2015 John Wiley & Sons, Inc, excepting Chapter 1 © 2014 by the Regents of the University of Minnesota and Chapter 19 © 2007 Wayne State University Press. All rights reserved..","Animation; Bill Nichols; Cinemicrography; Computer-generated imagery; Development of the Fertilized Rabbit Ovum; Informatics; Science; The Inner Life of the Cell; Warren H. Lewis; XVIVO",,2-s2.0-84976536402
"Walker J.","Projecting Sea Level Rise: Documentary Film and Other Geolocative Technologies",2015,"A Companion to Contemporary Documentary Film",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976566972&doi=10.1002%2f9781118884584.ch3&partnerID=40&md5=58db3ae61ba12c4c2be4f22676e97f0d","The documentary Someplace with a Mountain (Steve Goodall, 2010) concerns the plight of residents of a small Pacific atoll facing global warming-induced sea level rise. In a pivotal scene, the islanders gather around a laptop to watch an animated graphic depicting coastal inundation in the Shanghai region. They comprehend immediately - and trace with sweeping gestures - the broader implications of the sea change they themselves had already been experiencing in the immediate vicinity. The presence of this animation signals both the proliferation of scientific visioning technologies and their common incorporation into documentary film, although in this case the sea level rise animation is drawn from An Inconvenient Truth (Davis Guggenheim, 2006). Informed by concepts from human and critical GIS geography, Janet Walker is seeking to develop a cartographically and environmentally aware method for studying site-specific documentary as one among other media-rich technologies for mapping the planet. In this chapter, she focuses on sea level rise documentaries in relation to Google Earth and, crucially, to various interactive visioning tools that enable the user to toggle up sea heights to what they might be at some future date and view the results on maps of coastal areas. Reading back and forth among these various geolocative media, Walker exposes the aesthetic and material means through which the existence of low-lying Pacific islands and islanders is minimized in the Western geographical imagination. The critical geographer Kathryn Yusoff states that the catastrophe of climate change is upon us and that it is ""earth writing writ large."" Taking cognizance of this harrowing perception from a film and media studies perspective, Walker probes the limits and potentialities of sea level rise media as a complex mode of earth re-writing. © 2015 John Wiley & Sons, Inc, excepting Chapter 1 © 2014 by the Regents of the University of Minnesota and Chapter 19 © 2007 Wayne State University Press. All rights reserved.","An Inconvenient Truth; Computer modeling; Documentary film; Geography; Google Earth; Interactive visioning; Scientific visualization; Sea level rise; Web-based navigation",,2-s2.0-84976566972
"Smeets D.J.H., Bus A.G.","The interactive animated e-book as a word learning device for kindergartners",2015,"Applied Psycholinguistics",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930744278&doi=10.1017%2fS0142716413000556&partnerID=40&md5=639080cdf4d82134fcbdc4e1453acd4f","Electronic picture storybooks often include motion pictures, sounds, and background music instead of static pictures, and hotspots that label/define words when clicked on. The current study was designed to examine whether these additional elements aid word learning and story comprehension and whether effects accumulate making the animated e-book that also includes hotspots the most promising device. A sample group of 136 4- and 5-year-old kindergarten children were randomly assigned to one of four conditions: static e-books, animated e-books, interactive animated e-books, and a control group. In experimental conditions, four on-screen stories were each presented four times during a 4-week intervention period. Children in the control condition played nonliteracy related computer games during the same time. In all conditions, children worked independently with the computer programs. Strong treatment effects were found on target vocabulary originating from the story. Pupils gained most in vocabulary after reading interactive animated e-books, followed by (noninteractive) animated e-books and then static e-books. E-books including animations and interactivity were neither beneficial nor detrimental for story comprehension. Findings suggest that electronic storybooks are valuable additions in support of the classroom curriculum with interactive animated e-books being the best alternative. Copyright © Cambridge University Press 2014.",,,2-s2.0-84930744278
"Zhang P., Liu H., Ding Y.-H.","Crowd simulation based on constrained and controlled group formation",2015,"Visual Computer",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926632953&doi=10.1007%2fs00371-013-0900-7&partnerID=40&md5=a47d559ba61eedc72974f1d7f3a2d812","Freestyle formations appear widely in animation of groups. Most existing algorithms for generating special formations focus on the visualization performances of target formations, while social dynamics factors in the process of crowd motion are ignored. Thus, disregarding those factors will decrease the bionic features and fidelity of the crowd motion. According to this problem, a method based on bionic intelligence algorithm and self-adaptive evaluation to generate special formations is proposed in this paper. Simulation effect with good fluency and lively interaction is generated by means of user interaction, data analysis and crowd motion. In this method, 3D reconstruction is used to repaint characters, graphics or patterns in the 3D modeling system to build the basic virtual scene. Then, station points are generated through interlacing cross sampling. Based on the concentric circles model of fitness, each individual, self-adaptively, chooses a target station point which matches it aptly. Finally, the Artificial Bee Colony algorithm is used for path planing to generate the optimum route to the destination without collision. Visual simulation experiments are also made on the platforms of ACIS/HOOPS and Maya. The results show that this method can generate the optimum target formation with natural motion features and in accordance with users’ input. This method is also insensitive to the scale of crowd, exhibiting good performance when the number of individuals is large. © 2013, Springer-Verlag Berlin Heidelberg.","3D simulation; Artificial bee colony algorithm; Crowd motion; Freestyle formations","Algorithms; Evolutionary algorithms; Optimization; Visualization; Animation; 3D simulations; Artificial bee colony algorithms; Concentric circles; Crowd motion; Intelligence algorithms; Self-adaptive evaluation; Simulation effects; Visual simulation; Three dimensional computer graphics",2-s2.0-84926632953
"Vyatkin S.I.","Method of binary search for image elements of functionally defined objects using graphics processing units",2015,"Optoelectronics, Instrumentation and Data Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938065562&doi=10.3103%2fS8756699014060090&partnerID=40&md5=991440681f26d1f98fbc69fc2f15db6b","This paper deals with the real-time synthesis of high-quality images, a method of defining free forms without approximating them with polygons or patches, issues of using perturbation functions for real-time animation of the surfaces of three-dimensional objects. A method for visualizing functionally defined objects adapted for graphics processing units is proposed, and methods of transforming the describing function are implemented for geometric operations: deformation, displacement and metamorphosis, or morphing, including those for nonhomeomorphic objects. Advantages of the method of defining surfaces to the existing methods (algebraic and Bezier methods and their visualization techniques) are shown. © 2014, Allerton Press, Inc.","binary division of object space; geometric objects; geometric operations; perturbation functions","Computer graphics; Geometry; Image processing; Program processors; Geometric objects; Geometric operations; Graphics Processing Unit; Object space; Perturbation functions; Real-time animations; Three-dimensional object; Visualization technique; Algebra",2-s2.0-84938065562
"Huang H.","Research on novel 3D modelling methodology for animation design based on computer graphics theory and mathematical analysis with kinect implementation",2015,"International Journal of Multimedia and Ubiquitous Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956864446&doi=10.14257%2fijmue.2015.10.10.16&partnerID=40&md5=fd1deec402e4124a7ee9d809d4b76744","At present, the 3D object model technique is being applied in the simulation, virtual reality, 3D film industry and culture protection, and many other fields which can be widely applied. However, the existing 3D reconstruction technology is based on the complex and often expensive sensors. Therefore, we conduct research on computer graphics theory and mathematical modelling based 3D reconstruction methodology with Kinect. We firstly introduce the basic concepts and application of Kinect system which serves as the preliminary of our research. Then, we conduct mathematical modelling for our proposed system with theoretical analysis. Later, experiment and numerical simulation is conducted for verifying the robustness and effectiveness of our proposed approach. The visualized and numerical simulation result indicates that our method outperforms and holds better accuracy compared with other popular adopted algorithms. In the future, we plan to combine more optimization techniques to polish and modify our approach. © 2015 SERSC.","3D modelling and reconstruction; Animation design; Computer graphics theory; Image processing; Mathematical analysis","Animation; Computer graphics; Image processing; Image reconstruction; Numerical methods; Numerical models; Virtual reality; 3D modelling; 3D object modeling; 3D reconstruction; Animation designs; Basic concepts; Film industry; Mathematical analysis; Optimization techniques; Three dimensional computer graphics",2-s2.0-84956864446
"Guo Y., Fang N.","Interactive computer simulation and animation (csa) to improve student learning of projectile motion in an undergraduate engineering dynamics course",2015,"CSEDU 2015 - 7th International Conference on Computer Supported Education, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943528207&partnerID=40&md5=f8b15f0ebbb3e9255c48397de3122535","Computer simulation and animation (CSA) has been receiving growing attention and application in recent years in the international engineering education community. In the present study, an innovative set of CSA learning modules was developed to improve student learning of projectile motion in engineering dynamics, an important yet difficult undergraduate engineering course. The new CSA learning modules integrate visualization with mathematical modeling to help students directly connect engineering dynamics with mathematics. Quasi-experimental research involving an intervention group and a comparison group was performed to investigate the extent to which the new CSA learning modules improved student learning of projectile motion. The results show that as compared to the comparison group, students in the intervention group increased their learning gains by 30.3% to 43.6% on average, depending on the specific CSA learning modules. The difference in learning gains between the two groups is found to be statistically significant. From the present study, it is concluded that properly-designed computer simulation and animation not only provides students with a visualization tool for them to better understand engineering phenomena, but can also improve their procedural skills for finally solving problems in engineering dynamics.","Computer Simulation and Animation (CSA); Engineering Dynamics; Interactive Learning Modules; Projectile Motion; Quasi-experimental Research Design","Animation; Dynamics; E-learning; Education; Engineering education; Projectiles; Visualization; Engineering Dynamics; Experimental research; Interactive computer simulations; Interactive learning; International engineering education; Projectile motion; Undergraduate engineering; Undergraduate engineering course; Students",2-s2.0-84943528207
"Wang S.-C., Chern J.-Y.","Impact of intermittent stretching exercise animation on prolonged-sitting computer users’ attention and work performance",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945970006&doi=10.1007%2f978-3-319-21383-5_81&partnerID=40&md5=123a5f36c4037f2b3d7bcf5fb59b2c55","The prevailing use of computers and the Internet has contributed to popular symptoms of visual impairment, musculoskeletal injuries, and even emotional disorders nowadays. While certain ergonomics software packages have thus been designed to avoid or relieve the symptoms, some studies raised concern about possible decline in attention and work performance. This study aimed to explore the effects of the computer stretch/massage software on extended computer users’ attention and work performance. The Neuroscience brainwave monitor was used to evaluate the participants’ attention. Thirty college students who work more than 4 h a day in front of computer were recruited and evenly distributed to two groups. The participants in the experimental group were asked to perform the task on computer for 30 min with a stretch program on, which was set to pop-up every 10 min for about 30 s each. The control group took no breaks or interventions. The results show that the computer break software did not decrease the participants’ attention scores. Meanwhile the experimental group demonstrated higher work performance scores. It is suggested that during prolonged sitting computer work, breaks and body movements are necessary for better attention and work performance. © Springer International Publishing Switzerland 2015.","Attention score; Brainwave; Stretching exercise animation; Work performance","Animation; Computer software; Ergonomics; Students; Attention score; Brainwave; College students; Experimental groups; Musculo-skeletal injuries; Prolonged sitting; Visual impairment; Work performance; Human computer interaction",2-s2.0-84945970006
"Warburton M., Maddock S.","Physically-based forehead animation including wrinkles",2015,"Computer Animation and Virtual Worlds",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926180919&doi=10.1002%2fcav.1565&partnerID=40&md5=3f8fa102e3651fe81e145020a42cedec","Computer Animation and Virtual Worlds published by John Wiley & Sons, Ltd. A fully physically-based animation approach is presented for efficiently producing realistic-looking animations of facial movement, including expressive wrinkles. Detailed voxel-based models are simulated using a graphics processing unit-based finite element solver. Our flexible approach enables different muscle structures and material parameters to be used, for example, to animate different aged skins.Physically-based animation techniques enable more realistic and accurate animation to be created. We present a fully physically-based approach for efficiently producing realistic-looking animations of facial movement, including animation of expressive wrinkles. This involves simulation of detailed voxel-based models using a graphics processing unit-based total Lagrangian explicit dynamic finite element solver with an anatomical muscle contraction model, and advanced boundary conditions that can model the sliding of soft tissue over the skull. The flexibility of our approach enables detailed animations of gross and fine-scale soft-tissue movement to be easily produced with different muscle structures and material parameters, for example, to animate different aged skins. Although we focus on the forehead, our approach can be used to animate any multi-layered soft body. © 2014 The Authors. Computer Animation and Virtual Worlds published by John Wiley & Sons, Ltd.","facial animation; finite element method; physically-based animation; soft-tissue animation; wrinkle animation","Animation; Computer graphics; Computer graphics equipment; Muscle; Program processors; Tissue; Virtual reality; Computer animation; Explicit dynamic finite element; Facial animation; Finite element solver; Graphics Processing Unit; Muscle contractions; Physically-based animation; Soft tissue; Finite element method",2-s2.0-84926180919
"Jones B., Popovic J., McCann J., Li W., Bargteil A.","Dynamic sprites: Artistic authoring of interactive animations",2015,"Computer Animation and Virtual Worlds",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927805833&doi=10.1002%2fcav.1608&partnerID=40&md5=7abb9fc974f4963ae62fffb79f0a611b","Traditional methods for creating dynamic objects and characters from static drawings involve careful tweaking of animation curves and/or simulation parameters. Sprite sheets offer a more drawing-centric solution, but they do not encode timing information or the logic that determines how objects should transition between poses and cannot generalize outside the given drawings. We present an approach for creating dynamic sprites that leverages sprite sheets while addressing these limitations. In our system, artists create a drawing, deform it to specify a small number of example poses, and indicate which poses can be interpolated. To make the object move, we design a procedural simulation to navigate the pose manifold in response to external or user-controlled forces. Powerful artistic control is achieved by allowing the artist to specify both the pose manifold and how it is navigated, while physics is leveraged to provide timing and generality. We used our method to create sprites with a range of different dynamic properties. Copyright © 2014 John Wiley & Sons, Ltd.","computer animation; computer graphics; physics-based animation","Animation; Computer graphics; Navigation; Computer animation; Dynamic objects; Dynamic property; Interactive animations; Physics-based animation; Pose manifold; Simulation parameters; Timing information; Dynamics",2-s2.0-84927805833
"Tajvidi M., Fang N.","Application of computer simulation and animation (CSA) in teaching and learning engineering mechanics",2015,"ASEE Annual Conference and Exposition, Conference Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941994262&partnerID=40&md5=6b3f655ab29c9fd5595a509432e818eb","Use of computer simulation and animation (CSA) in higher education is growing rapidly and has become a major trend in undergraduate engineering education. This paper conducts a comprehensive and critical literature review regarding the use of CSA as a learning aid to teach engineering mechanics courses. The paper addresses two main topics: (1) pedagogical innovations in the instruction of engineering mechanics, and (2) using CSA as a learning tool in engineering mechanics education. Representative pedagogical innovations are clustered into three categories: (1) altering the engineering mechanics curriculum, (2) active learning strategies, and (3) the application of enhancement resources. Focusing on CSA as an effective enhancement tool, this literature review summarizes the main characteristics of CSA modules that impact student learning: visualization enhancement, interactive features, and straightforwardness. Major theoretical, methodological issues and practical implications as well as the strengths and weaknesses in the published studies within cognitive learning domain are reviewed. The literature review show that although all studies justify the practical effectiveness of CSA modules in improving learning styles, few of them are explicitly associated with a ""learning theory"" model. The most important advantages of CSA modules cited in the literature are: interactive feature, fostering students' visualization, and enhancing their problem-solving process. It is suggested in this paper that CSA modules cannot be considered as a stand-alone pedagogical resource since they cannot replace conventional classroom instruction. © American Society for Engineering Education, 2015",,,2-s2.0-84941994262
"Wang Y., Lang F., Wang Z., Xu B.","Automatic variable-timing animation transition based on hierarchical interpolation method",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938824691&partnerID=40&md5=082025289e5664dccf5b968cbcac6326","Character animation has been used in many fields, such as film making, virtual reality interaction and video games. Video game needs a large set of character animations for users to trigger. However, it is a complex and tedious work for animators to manufacture all the transition animations between each pair of character animations. In this paper, a novel rapid method is presented to generate transition animation automatically. Firstly, animations in the game animation set are classified. Secondly, the time length during motion interpolation is calculated automatically, which is decided by the angle velocity of character's joints. The method is called variable timing method. Lastly, by using hierarchical interpolation method, postures interpolate between different animations. The transition animation can be quickly acquired, according with human dynamics. In this way, we can get a natural movement by connecting animations together. Experimental results demonstrate that our method can be effectively and efficiently applied to generate transition animations between various character animations. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Animation transition; Character animation; Interpolation; Variable timing","Computer graphics; Human computer interaction; Interactive computer graphics; Interpolation; Virtual reality; Angle velocity; Character animation; Interpolation method; Motion interpolation; Natural movements; Transition animation; Variable timing; Virtual reality interactions; Animation",2-s2.0-84938824691
"Nosch D.S., Foppa C., Tóth M., Joos R.E.","Blink animation software to improve blinking and dry eye symptoms",2015,"Optometry and Vision Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940941450&doi=10.1097%2fOPX.0000000000000654&partnerID=40&md5=749c000d558a757f687a6ffad83454c9","Purpose To evaluate if the animation ""blink blink"" increases blink rate and improves dry eye symptoms during prolonged computer use. Methods Study part A: Blink rate was recorded at baseline and during computer work of normal subjects without symptoms of dry eye. Half of the subjects used ""blink blink,"" instructed to blink on animation appearance; the other half used a placebo version for 1 week during computer use. Thereafter, blink rate was recorded again with the use of ""blink blink."" Study part B: Blink rate was recorded during computer work with dry eye symptoms (modified Ocular Surface Disease Index > 15.0). Subjects used the test and placebo version of ""blink blink"" each for 1 week (1 week washout; crossover) and were instructed to blink twice on presentation of the animation. Blink rate and dry eye symptoms were assessed after each phase and compared with baseline. Results Study part A: Ten subjects participated (mean [±SD] age, 38.3 [±16.0] years; 5 women). A greater increase in blink rate was observed in the test group (5.62 blinks/min for the test group and 0.96 blinks/min for the control group). Study part B: Twenty-four subjects participated (mean [±SD] age, 39.3 [±19.1] years; 11 women). Dry eye symptoms improved during both phases (with test and placebo) to a statistically significant degree (each, p < 0.001). This difference was more marked with the test (-5.42 [±2.86] points) compared with the placebo version (-1.79 [±1.38] points). Blink rate increased with the program by 6.75 (±3.80) blinks/min (p < 0.001), compared with 0.50 (±2.83) blinks/min with placebo (p = 0.396). This difference between test and placebo was statistically significant (p < 0.001). Twenty of the 24 subjects could tolerate ""blink blink"" well during computer use. Conclusions Blink rate and dry eye symptoms improved with ""blink blink."" The double blink prompted by the animation allowed a decrease in number of presentations and improved acceptance of ""blink blink."". © 2015 American Academy of Optometry.","animation software; blink rate; computer vision syndrome; dry eye; OSDI","Animation; Testing; Animation softwares; Blink rates; Computer vision syndromes; Dry eye; OSDI; Computer vision; adult; blinking; computer; computer program; crossover procedure; dry eye; female; human; male; middle aged; pathophysiology; physiology; pilot study; task performance; young adult; Adult; Blinking; Computers; Cross-Over Studies; Dry Eye Syndromes; Female; Humans; Male; Middle Aged; Pilot Projects; Software; Task Performance and Analysis; Young Adult",2-s2.0-84940941450
"Cheng C., Li L.","Adaptive animation design method for virtual environments",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938829188&partnerID=40&md5=7058e6c112239034b30f536faa4fdbd5","There is a big gap between the WIMP interface animation design tools and virtual environment (VE) animation design platforms. The current animations in virtual environments lack the capability of adaptation, and adaptive animation design processes are programming based development with a great difficulty. These problems vastly limit the animation applications in virtual environments. This paper aims at putting forward an innovative animation construction strategy and methods to cope with these problems. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Adaptive animation; Animation; Behavior; Formal method; Human-computer interaction; Virtual assembly; Virtual environment","Animation; Computer graphics; Design; Formal methods; Human computer interaction; Animation designs; Behavior; Construction strategies; Virtual assembly; Virtual reality",2-s2.0-84938829188
"Way D.-L., Chang Y.-S.","A cartoon-style rendering for physical dynamic hair animation",2015,"Journal of the Chinese Institute of Engineers, Transactions of the Chinese Institute of Engineers,Series A/Chung-kuo Kung Ch'eng Hsuch K'an",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922477376&doi=10.1080%2f02533839.2014.955970&partnerID=40&md5=39ae17103a7058dd11981239da0e32ef","Hair rendering is one of the major research topics in computer graphics. A lot of papers on hair modeling have focused on photo-realistic rendering. This paper proposes a stylized cartoon hair rendering flow diagram including animated hair strand creation, stroke path generation, brush stroke line simulation, and expressive hair rendering. A reordering mechanism addresses depth and stroke line rendering for a suitable performance and temporal coherence. The proposed method creates a delicate expression similar to an artists drawing. To validate real-time performance, all stroke effects are rendered with different shaders on a graphics processing unit. The method is flexible enough to allow users to select shader effects and control the parameters of each activated shader to create esthetically pleasing results. Finally, the proposed method produces excellent experimental results. These results are compared to the results of previous studies. © 2014 The Chinese Institute of Engineers.","computer animation; hair rendering; physically based dynamics; stylized line-based rendering; toon shading","Animation; Program processors; Computer animation; Hair rendering; Physically based; stylized line-based rendering; toon shading; Rendering (computer graphics)",2-s2.0-84922477376
"Apostolakis K.C., Daras P.","Natural user interfaces for virtual character full body and facial animation in immersive virtual worlds",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944677103&doi=10.1007%2f978-3-319-22888-4_27&partnerID=40&md5=9dc039ea7e79e0370d3c49ba639e0b10","In recent years, networked virtual environments have steadily grown to become a frontier in social computing. Such virtual cyberspaces are usually accessed by multiple users through their 3D avatars. Recent scientific activity has resulted in the release of both hardware and software components that enable users at home to interact with their virtual persona through natural body and facial activity performance. Based on 3D computer graphics methods and vision-based motion tracking algorithms, these techniques aspire to reinforce the sense of autonomy and telepresence within the virtual world. In this paper we present two distinct frameworks for avatar animation through user natural motion input. We specifically target the full body avatar control case using a Kinect sensor via a simple, networked skeletal joint retargeting pipeline, as well as an intuitive user facial animation 3D reconstruction pipeline for rendering highly realistic user facial puppets. Furthermore, we present a common networked architecture to enable multiple remote clients to capture and render any number of 3D animated characters within a shared virtual environment. © 2015, Springer International Publishing Switzerland.","Face animation; Kinect-based interfaces; Markerless performance capture; Virtual character animation","Animation; Computer graphics; Interactive computer graphics; Pipelines; Rendering (computer graphics); User interfaces; Virtual reality; Visual communication; Face animation; Hardware and software components; Natural user interfaces; Networked virtual environments; Performance capture; Shared virtual environments; Virtual character; Vision based motion tracking; Three dimensional computer graphics",2-s2.0-84944677103
"He K., Mao A., Luo J., Li G.","Rapid 3D human body modeling and skinning animation based on single kinect",2015,"Journal of Fiber Bioengineering and Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942898098&doi=10.3993%2fjfbim00134&partnerID=40&md5=8d5c058ee39f7c9b9ba43cf1d50ececa","Dynamic geometries acquisition of human is one of the most popular topics in the fields of computer vision and computer graphics. This paper presents the related techniques on rapidly generation of human model sequences and makes skinning animation using single Kinect. In specified applied conditions, it has good animation effects and interaction functions. As the comparatively low request on resolution by animation, using the Kinect can greatly save human body animation production time and reduce production cost. © 2015 Binary Information Press & Textile Bioengineering and Informatics Society.","Human body; Rapid modeling; Single kinect; Skinning animation","Computer graphics; Computer vision; 3D human body; Animation effects; Dynamic geometry; Human bodies; Interaction functions; Production cost; Production time; Single kinect; Animation",2-s2.0-84942898098
"Maruya T., Tano S., Hashiyama T., Iwata M., Ichino J., Hyono Y.","Design support tool using pen device for simplification of animation design",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951795678&doi=10.1007%2f978-3-319-21380-4_9&partnerID=40&md5=550468451c7a93ccb9c9ab632bb9172b","Content using animation is widely available, and animation is often used in educational content to promote the understanding of mechanical structures and concepts. However, animations are currently created with software that requires complicated operations and programming. Such software inhibits intuitive and creative animation design. In this study, we analyze animations and determine the factors that inhibit intuitive and creative animation design. Moreover, we have developed a design support tool to make designing animations easier. © Springer International Publishing Switzerland 2015.","Animation design; Pen device","Animation; Human computer interaction; Animation designs; Design support tools; Educational contents; Mechanical structures; Pen device; Design",2-s2.0-84951795678
"Lei T., Hou J., Wang X.","Eye animation modeling based on the improved Candide-3 model",2015,"Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929611097&doi=10.3969%2fj.issn.1006-7043.201307068&partnerID=40&md5=1ba185fee53d1d7912567120f184eb12","A face reconstruction approach based on the improved Candide-3 model is presented in order to solve the problems that the details of eye movements cannot be expressed when reconstructing a three-dimensional facial model in Candide-3 model. First, the eye model was built in the Candied-3 model. It was specifically divided into two parts: the eyeball modeling and the eyelid modeling. The eyeball modeling was conducted in combination with two hemispheres. For the modeling of the eyelid, the Bezier curve was used to model the inner and outer edges of eyelid and the upper lid groove in the Candide-3 model. Next, by combining the information of facial feature points and local least squares matching principle, the 3D face model similar to the input face image was built. After that, paste facial texture by feature point constraint methods and paste texture to eyeball by the spherical and partially spherical texture mapping methods, respectively. Finally, some actions, such as closing and opening of eyelid, blinking, rotation of eyeball and other related actions were realistically completed by the piecewise linear interpolation method in the built model. ©, 2015, Editorial Board of Journal of HEU. All right reserved.","Candide-3 model; Eye animation modeling; Interpolated animation; Local least squares matching; Model improvement; Texture mapping","Animation; Eye movements; Face recognition; Interpolation; Mapping; Piecewise linear techniques; Textures; 3-D face modeling; Constraint methods; Eye animation; Face reconstruction; Facial feature points; Local least squares; Piecewise linear interpolations; Texture mapping; Three dimensional computer graphics",2-s2.0-84929611097
"Liu H., Zhang S., Lu R.","Automatic 2D animation generation",2015,"ICALIP 2014 - 2014 International Conference on Audio, Language and Image Processing, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922554915&doi=10.1109%2fICALIP.2014.7009868&partnerID=40&md5=560a2739470e55946f30099d4175d0ea","With computer technologies being widely used in animation field, the complex process of creating animations makes the animators more and more eager to a highly automatic animation technology. In consideration of the durable vitality and wide applications of the 2D animation in recent years, this paper proposes a technology for automatic generation of 2D animation. Inputting a story text based on user's demand, an animation which is coincident with the story will be ultimately generated through a series of automatic processes. The new technology has explored a new field, in which there would be many difficulties, such as 2D camera planning, path planning and layers planning. It would give a significant innovation to the production of 2D animation. © 2014 IEEE.","2D animation; automatic generation; cameras planning; knowledge base; layers planning","Cameras; Image processing; Knowledge based systems; Motion planning; 2D animation; Automatic animations; Automatic Generation; Camera planning; Complex Processes; Computer technology; Knowledge base; Animation",2-s2.0-84922554915
"Lu Y.Y., Li Z., Du R.","3D Holographic Animation of Modern Mechanical Watch Escapements",2015,"Computer-Aided Design and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923323929&doi=10.1080%2f16864360.2014.997645&partnerID=40&md5=e960325d819a09106064506766e60746","ABSTRACT: In the past 100 years, nearly all mechanical watches used a same escapement, called the Swiss lever escapement. In the past two decades, though, a couple of new escapements are invented, including the Girard-Perregaux Constant Force Escapement and the Dual Ulysse Escapement. Set aside to design and make these escapements, it is difficult to describe the movements of these complex escapements. In this paper, we use a simple pseudo 3D holography system to show the movements of these two escapements. This low-cost system can be used with a smartphone for display on site or used with a large screen TV for display in shops. It adds a new way to demonstrate the movements of complex mechanical watches and other mechanical devices. © 2015, © 2015 CAD Solutions, LLC.","3D holography; computer animation; mechanical watch escapement","Animation; Holography; Computer animation; Constant force; Large screen; Low-cost systems; Mechanical device; mechanical watch escapement; Watches",2-s2.0-84923323929
"Jiang Y., Xiao B., Yang B., Guo X.","Study of plant animation synthesis by unity3D",2015,"IFIP Advances in Information and Communication Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951757227&doi=10.1007%2f978-3-319-19620-6_39&partnerID=40&md5=689225baf6ea255d3c0bf0f6d14bf49e","Virtual plant is a novel research issue in computer applications, and realistic plant animation is widely used in many fields. The research of precise, efficient and photorealistic plant animation synthesis is one of the important issues that the current virtual plant facing with. This paper using maize achieves real time and realistic plant animation, based on the platform of Unity3D. The virtual maize model is generated by use of interactive parameterized modeling method. By setting a good interactive interface, users can dynamically adjust the parameters to realize different animation effects. Finally, concluding and analyzing this method. In addition future research and application direction is discussed in order to achieve better plant animation. © IFIP International Federation for Information Processing 2015.","Animation synthesis; Plant animation; Unity3D","Agriculture; Synthesis (chemical); Animation effects; Animation synthesis; Interactive interfaces; Parameterized model; Photo-realistic; Research and application; Research issues; Unity3d; Animation",2-s2.0-84951757227
"Gris I., Rivera D.A., Novick D.","Animation guidelines for believable embodied conversational agent gestures",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947256911&doi=10.1007%2f978-3-319-21067-4_21&partnerID=40&md5=70dec467f39b6bfd9be5ae6cdfe16a43","In animating embodied conversational agents (ECAs), run-time blending of animations can provide a large library of movements that increases the appearance of naturalness while decreasing the number of animations to be developed. This approach avoids the need to develop a costly full library of possible animations in advance of use. Our principal scientific contribution is the development of a model for gesture constraints that enables blended animations to represent naturalistic movement. Rather than creating over-detailed, fine-grained procedural animations or hundreds of motion-captured animation files, animators can include sets of their own animations for agents, blend them, and easily reuse animations, while constraining the ECA to use motions that would occur and transition naturally. © Springer International Publishing Switzerland 2015.","Animation; Embodied conversational agents; Usability","Animation; Blending; Gesture recognition; User interfaces; Virtual reality; Animation files; Embodied conversational agent; Fine grained; Procedural animation; Runtimes; Scientific contributions; Usability; Human computer interaction",2-s2.0-84947256911
"Castro-Alonso J.C., Ayres P., Paas F.","Animations showing Lego manipulative tasks: Three potential moderators of effectiveness",2015,"Computers and Education",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923345152&doi=10.1016%2fj.compedu.2014.12.022&partnerID=40&md5=bacb39c2a142eb8ec3d243bf0a25e786","Evidence suggests that transient visual information, such as animations, may be more challenging to learn than static visualizations. However, when a procedural-manipulative task is involved, our evolved embodied cognition seems to reverse this transitory challenge. Hence, for object manipulative tasks, instructional animations may be more suitable than statics. We investigated this argument further by comparing animations with statics using a Lego task shown to university students, by examining three potential moderators of effectiveness: (a) the environment of manipulation (virtual or physical), (b) the quality of visual information (focused or unfocused), and (c) the presence of hands (no hands or with hands). In Experiment 1 we found an advantage of animation over statics, and no differences among the environments. In Experiment 2, we again observed an animation advantage, a small advantage of focused static information compared to unfocused static information, and a positive effect of not showing the hands. © 2015 Elsevier Ltd. All rights reserved.","Animation-static comparison; Embodied cognition; Lego manipulative task; Transient information; Virtual and physical learning environment","Computer aided instruction; Moderators; Embodied cognition; Instructional animations; Learning environments; Lego manipulative task; Static information; Static visualizations; Transient information; University students; Animation",2-s2.0-84923345152
"Döring U., Brandt-Salloum C., Henkel V., Brix T.","Animation of historical patents",2015,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928266060&doi=10.1007%2f978-3-319-09411-3_95&partnerID=40&md5=7defe06c26fc88a792e8297da9b67429","The Geheimes Staatsarchiv Preußischer Kulturbesitz Berlin is an archive with thousands of patents from the 19th century. The documents include patent texts and figures as well as the comments of the reviewers. The paper is about first common activities of the archive and the Ilmenau University of Technology to make the documents available to a broad public. Aside of the digital reproduction and presentation of texts and images the activities focus on remodeling the technical devices and animate the models with WebGL in web browsers. In the created interactive animations different functional and constructive aspects can be explained to the viewers. The original content as well as the derived content like videos and interactive animations is finally made available in the DMG-Lib portal. The paper describes the used workflow and experiences as well as selected examples. © Springer International Publishing Switzerland 2015","CAD; Historical patents; Interactive animation; Knowledge preservation; Webgl","Animation; Computer aided design; Digital devices; Web browsers; 19th century; Digital reproductions; Historical patents; Interactive animations; Knowledge preservations; Selected examples; Webgl; Patents and inventions",2-s2.0-84928266060
"Angare L.M.G., De Martino J.M.","Manipulation of motion capture animation by characteristics",2015,"22nd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2014, Communication Papers Proceedings - in co-operation with EUROGRAPHICS Association",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957878724&partnerID=40&md5=acaec936abdc86605718bb4429604471","Three-dimensional animation is an area in vast expansion due to, continuous research in the field has enabled an increasing number of users access to powerful tools with intuitive interfaces. We present our work-in-progress methodology by which artists can manipulate existing animation segments using intuitive characteristics instead of manually changing keyframes' values and interpolations. To achieve this goal, motion capture is used to create a database in which actors perform the same movement with different characteristics; keyframes from those movements are analyzed and used to create a transformation of animation curves that describe differences of values and times in keyframes of neutral and a movement with a specific characteristic. This transformation can be used to change a large set of keyframes, embedding a desired characteristic into the segment. To test our methodology, we used as a proof of concept a character performing a walk, represented by 59 joints with 172 degrees of freedom (DOF), and a set of 12 physical and emotional characteristics. Using our methodology we embedded a neutral walk with these desired characteristics and evaluated the results with a survey comparing our modified animations with direct motion capture movements, with partial results. With this methodology, one can decrease drastically the time needed to tweak large sets of keyframes, embedding a desired characteristic in a fashion more closely related to the artistic universe of animators than the mathematical representations of angles, translations and interpolations in animation curves commonly used in commercial softwares.","Animation; Computer Graphics; Motion Capture","Computer graphics; Computer vision; Degrees of freedom (mechanics); Interpolation; Visualization; Commercial software; Intuitive interfaces; Mathematical representations; Motion capture; Partial results; Proof of concept; Three-dimensional animations; Work in progress; Animation",2-s2.0-84957878724
"Papapavlou C., Moustakas K.","Physics-based modelling and animation of saccadic eye movement",2015,"22nd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2014, Communication Papers Proceedings - in co-operation with EUROGRAPHICS Association",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957899617&partnerID=40&md5=731a567cd55f9ecd230c5dd4703bd69f","In this paper we present a new approach in producing realistic saccade eye movement animations by incorporating anatomical details of the oculomotor system into the dynamics of the eye model. Unlike abstract models of the eye motor behaviour, we make use of a biomedical framework to effectively model the eye globe along with the three extraocular muscle pairs in efficient detail, that the application of the corresponding muscle activation signals, naturally results in realistic motions. That way, we avoid the need of explicitly providing trajectory information, and therefore simplify the process of eye animation. Regarding the calculations of the muscle activation signals needed to drive the animation in a way that imitates a real human eye, we are based on existing knowledge about the way that the nervous system utilizes the extraocular muscles during saccades.","Eye Animation; Physics-Based Simulation; Saccades","Animation; Chemical activation; Computer graphics; Computer vision; Muscle; Visualization; Extraocular muscles; Eye animation; Muscle activation; Oculomotor systems; Physics-based modelling; Physics-based Simulation; Saccadic eye movements; Trajectory information; Eye movements",2-s2.0-84957899617
"Jun D., Liang Q.","Decision mechanisms for interactive character animations in virtual environment",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946541614&doi=10.1007%2f978-3-662-47791-5_36&partnerID=40&md5=44508c6e49331e474fdb83478b8183b5","Recently, interactive character animations in computer games are mainly rely on motion-captured or carefully crafted motion clips. However, it is impractical and difficult to provide motion data samples for all possible behaviors with creating realistic responses to unexpected changes in the world. In order to control characters animations more precisely and realistically in realtime, an decision mechanism that synthesizes animations with interaction between characters in virtual environment is necessary. An efficient near-optimal interactive motion controller that can intelligently adopt the input motion data to a dynamically changing virtual environment is present. The controllers using reinforcement learning to reduce the data requirement by finding the most effective set of motion data to create the desired behaviors, and can be used as basic components in global path planning, and it further reduces the computational processing burden in the real-time interactive applications. © Springer Science+Business Media New York 2015.","Motion graph; Realistic character; Reinforcement learning","Animation; Computer games; Motion planning; Virtual reality; Character animation; Computational processing; Decision mechanism; Global path planning; Interactive applications; Motion controller; Motion graph; Realistic character; Reinforcement learning",2-s2.0-84946541614
"Deglorie G., Samyn K., Lambert P., Van De Walle R., Van Hoecke S.","Procedural animation of human interaction using inverse kinematics and fuzzy logic",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938889946&partnerID=40&md5=35b9e03e2b6d18fb50626d4d85a54738","Nowadays, animation of human interaction is predominantly modelled statically. Animations are adapted manually to each set of participating characters to ensure visual fidelity. To automate this process, we propose a novel procedural animation technique where character interactions are modelled dynamically with fuzzy logic and compare our technique to conventional inverse kinematics. The 'handshake' interaction is used as an example interaction, in order to illustrate how basic animation rules are defined, while leaving room for parametrization of character specific properties. Our results show that, although inverse kinematics delivers higher precision in positioning than fuzzy logic, they are dependent on paths describing the motion of the final element in the kinematic chain. Fuzzy logic, on the other hand, is independent of such motion paths and solves towards the target location locally. The presented handshake model using fuzzy logic can serve as a basis for future models for virtual-human interaction. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Fuzzy logic; Inverse kinematics; Multi-character interaction; Procedural animation","Animation; Computer graphics; Inverse kinematics; Kinematics; Virtual reality; Human interactions; Kinematic chain; Multi-character interaction; Parametrizations; Procedural animation; Specific properties; Target location; Visual fidelity; Fuzzy logic",2-s2.0-84938889946
"Nie H.","The artistic expression analysis of animation technology based on three dimensions",2015,"Proceedings of the International Conference on Management, Information and Educational Engineering, MIEE 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957359199&partnerID=40&md5=0c8032961c6396b855299c5d9392e04a","With the development of modern computer technology, animation technology based on three dimensions becomes mature. Virtual methods based on computer software could manufacture visual effects which are realistic. This is the perfect combination of science and art which could strengthen the expressive force of animation. It also could prompt the emergence of a new form of animation. This paper will analysis the artistic expression of animation technology based on three dimensions. © 2015 Taylor & Francis Group, London.","Animation technology based on three dimensions; Artistic expression animation technology based on three dimensions",,2-s2.0-84957359199
"Lin N.-H., Tzou S.-H.","Traditional western art elements in disney animations, elite influence in mass culture through the prism of the frankfurt school",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951003829&doi=10.1007%2f978-3-319-20934-0_24&partnerID=40&md5=337f9b081c5f4628e84977d134a78ad1","Thanks to the development of the media and internet, American mass culture has been spread worldwide. Above all, Disney animation is one of the most successful in its industry. However, the success of the Disney Corporation appears not only due to the prosperity of the company but also the wide dissemination of American mass culture. While our children are watching their films they are learning the American culture and values at the same time, which will shape their ways of thinking and habits of consumption in future. This is the most important criticism of the “culture industry” from the Frankfort School. Even though Disney animations were classified as mass culture, the themes which have been used in Disney animations often contain numerous elements of western traditional culture and arts: when audiences watch these cartoons, those elements are also beginning to be implanted in their mind. In this study I intend to analyze how Disney animation uses elite culture to enhance the quality of their films, and how elite culture can be introduced to the world through an approach free of ambiguity. Most importantly, I attempt to explore how the successful experience of Disney could transfer to Taiwanese animation industry. © Springer International Publishing Switzerland 2015.","Culture industry; Disney; Elite culture; Mass culture; Taiwan animation industry; The frankfort School","Animation; Disney; Mass cultures; The frankfort School; Traditional cultures; Ways of thinking; Human computer interaction",2-s2.0-84951003829
"Luo C., Jiang C., Li R., Yu J., Wang Z.","3D virtual facial animation for general users",2015,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926364854&partnerID=40&md5=9ee95e9ddc0a2ebd4c97be163fcafe3f","To realistically animate a 3D virtual face, we propose a real-time video-driven facial animation method. Firstly, we reconstruct the user's 3D face model from a single frontal face image, and synthesize a set of facial images with different pose, illumination and expression based on this face model. The synthetic images are used to train a user-specific local texture model. Then, a video camera is used to record the facial performance of the user. Facial feature points are tracked using a constrained local model based method. Finally, facial tracking results are transformed to Blendshape coefficients based on 3D key shapes, and facial animation is generated by using Blendshape interpolation. Experiments show that our method is effective for realistic facial animation synthesis. Moreover, the method only requires a web camera and can be easily used by an ordinary user. ©, 2015, Institute of Computing Technology. All right reserved.","Blendshape model; Facial animation; Facial feature tracking; Performance-driven","Animation; Cameras; Face recognition; Video cameras; 3-D face modeling; Blendshape; Constrained local models; Facial animation; Facial feature points; Facial feature tracking; Local texture models; Performance-driven; Three dimensional computer graphics",2-s2.0-84926364854
"Bian S., You L., Zhang J.J.","Recent developments in skin deformation for character animation",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938886894&partnerID=40&md5=92df867511627ae4f57859a98b16e9d1","Achieving realistic skin deformation efficiently is a very important task for character animation. With the development of skin deformation, the efficiency and effectiveness of character modelling and animation have been obviously enhanced. In this paper, we survey the recent literature on skin deformation according to three types of approaches: purely geometric, physics-based, and data driven. Especially we focus on the work since 2009. We review the problems they primarily tackles, the methodologies they applies, and the advantages and disadvantages they have. At last, we discuss directions for future research. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Data-driven methods; Geometric techniques; Physics-based techniques; Skin deformations","Computer graphics; Deformation; Character animation; Data driven; Data-driven methods; Geometric techniques; Physics-based; Skin deformation; Animation",2-s2.0-84938886894
"Rewik N., Peuwnuan K., Woraratpanya K., Pasupa K.","Particle-flow interactive animation for painting image",2015,"Proceedings - 2015 7th International Conference on Information Technology and Electrical Engineering: Envisioning the Trend of Computer, Information and Engineering, ICITEE 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966551150&doi=10.1109%2fICITEED.2015.7408948&partnerID=40&md5=9181b05f8f79c43bd4d86daddd7183e8","In this paper, we present an interactive multimedia artwork, which awakens motionless images to interactive animations. This animation simulates the colour-flow movement from painting images. Particle movement and interaction present the rhythm of the brushstrokes. This artwork conveys lively image feelings. Human colour perception is the main idea of this work. We use image-processing techniques to extract colour distinction from painting images. After that, we render numerous particles from distinct colour areas information. Steering behaviour directs particle movement to flow smoothly on a touch-screen monitor. This artwork attracts audiences to admire painting in the new aspect that audiences play with it rather than just watching it. This works designed for arbitrary painting images, unlike previous work which ties to a particular image. © 2015 IEEE.",,"Animation; Color vision; Image processing; Interactive computer systems; Multimedia systems; Touch screens; Colour perception; Image processing technique; Interactive animations; Interactive multimedia; Particle flow; Particle movement; Touch screen monitors; Color",2-s2.0-84966551150
"Huang X.-F., Sun S.-Q., Zhang K.-J., Xu T.-N., Wu J.-F., Zhu B.","A method of shadow puppet figure modeling and animation",2015,"Frontiers of Information Technology and Electronic Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942010634&doi=10.1631%2fFITEE.1400351&partnerID=40&md5=5c1be3b0e91f32657a6be25313e64351","To promote the development of the intangible cultural heritage of the world, shadow play, many studies have focused on shadow puppet modeling and interaction. Most of the shadow puppet figures are still imaginary, spread by ancients, or carved and painted by shadow puppet artists, without consideration of real dimensions or the appearance of human bodies. This study proposes an algorithm to transform 3D human models to 2D puppet figures for shadow puppets, including automatic location of feature points, automatic segmentation of 3D models, automatic extraction of 2D contours, automatic clothes matching, and animation. Experiment proves that more realistic and attractive figures and animations of the shadow puppet can be generated in real time with this algorithm. © 2015, Journal of Zhejiang University Science Editorial Office and Springer-Verlag Berlin Heidelberg.","2D modeling; 3D human body; Data processing; Shadow play; Shadow puppet figure","Animation; Data handling; Data processing; 2-D model; 3D human body; Automatic extraction; Automatic segmentations; Intangible cultural heritages; Modeling and animation; Shadow play; Shadow puppet figure; Three dimensional computer graphics",2-s2.0-84942010634
"Ham W., Lee K.","Three dimensoinal stereo graphic animation of golf ball in putting green with no loss of orientation information",2015,"Proceedings - 2015 5th International Conference on Communication Systems and Network Technologies, CSNT 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946935506&doi=10.1109%2fCSNT.2015.234&partnerID=40&md5=368a2e2cf1d944109a3e52dacaf9f323","In this paper, we introduce the three dimensional graphic animation program for simulating the 5 DOF (degree of freedom) motion of golf ball in putting green. We revice the dynamics of rolling motion of golf ball on arbitrary surface of golf green based on the gravity and the slip mechanism suggested by our research team in previous work. We also propose a new algorithm to handle the loss of orientation information which is an essential problem happened in INS (Inertial Navigation System). We construct the real time simulation develop environment by using Open GL, MATLAB, 3ds Max, and virtual comport device driver software for implementing animation program functioning on special shutter glasses 3D LCD monitor. © 2015 IEEE.","3D; Dynamics; Golf; INS; MATLAB; OpenGL; Slip Mechanism","Air navigation; Animation; Application programming interfaces (API); Computer software; Degrees of freedom (mechanics); Dynamics; Indium; Inertial navigation systems; Liquid crystal displays; MATLAB; Navigation systems; Sporting goods; Virtual reality; Animation programs; DOF (degree of Freedom); Golf; OpenGL; Orientation information; Real time simulations; Slip mechanism; Three-dimensional graphics; Sports",2-s2.0-84946935506
"Huang P., Tejera M., Collomosse J., Hilton A.","Hybrid skeletal-surface motion graphs for character animation from 4D performance capture",2015,"ACM Transactions on Graphics",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924034998&doi=10.1145%2f2699643&partnerID=40&md5=596c7d14c14bdbf9f93529291d3d6f41","We present a novel hybrid representation for character animation from 4D Performance Capture (4DPC) data which combines skeletal controlwith surface motion graphs. 4DPC data are temporally aligned 3D mesh sequence reconstructions of the dynamic surface shape and associated appearance from multiple-view video. The hybrid representation supports the production of novel surface sequences which satisfy constraints from user-specified key-frames or a target skeletal motion. Motion graph path optimisation concatenates fragments of 4DPC data to satisfy the constraints while maintaining plausible surface motion at transitions between sequences. Space-time editing of the mesh sequence using a learned part-based Laplacian surface deformationmodel is performed to match the target skeletal motion and transition between sequences. The approach is quantitatively evaluated for three 4DPC datasets with a variety of clothing styles. Results for key-frame animation demonstrate production of novel sequences that satisfy constraints on timing and position of less than 1% of the sequence duration and path length. Evaluation of motion-capture-driven animation over a corpus of 130 sequences shows that the synthesised motion accurately matches the target skeletal motion. The combination of skeletal control with the surface motion graph extends the range and style of motion which can be produced while maintaining the natural dynamics of shape and appearance from the captured performance. © 2015 ACM.","3D video; 4D performance capture; Examplebased animation; Human motion synthesis; Motion graphs; Surface motion capture; Video-based rendering","Animation; Three dimensional computer graphics; 3-D videos; Example-based; Human motion synthesis; Motion graph; Performance capture; Surface motion captures; Video-based rendering; Musculoskeletal system",2-s2.0-84924034998
"Joselli M., Junior J.R.D.S., Clua E.W., Montenegro A., Lage M., Pagliosa P.","Neighborhood grid: A novel data structure for fluids animation with GPU computing",2015,"Journal of Parallel and Distributed Computing",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918818908&doi=10.1016%2fj.jpdc.2014.10.009&partnerID=40&md5=53e19668f9d96cce5afc4f0c36b63b7d","This paper introduces a novel and efficient data structure, called neighborhood grid, capable of supporting large number of particle based elements on GPUs (graphics processing units), and is used for optimizing fluid animation with the use of GPU computing. The presented fluid simulation approach is based on SPH (smoothed particle hydrodynamics) and uses a unique algorithm for the neighborhood gathering. The brute force approach to neighborhood gathering of n particles has complexity O(n2), since it involves proximity queries of all pairs of fluid particles in order to compute the relevant mutual interactions. Usually, the algorithm is optimized by using spatial data structures which subdivide the environment in cells and then classify the particles among the cells based on their position, which is not efficient when a large number of particles are grouped in the same cell. Instead of using such approach, this work presents a novel and efficient data structure that maintains the particles into another form of proximity data structure, called neighborhood grid. In this structure, each cell contains only one particle and does not directly represent a discrete spatial subdivision. The neighborhood grid does process an approximate spatial neighborhood of the particles, yielding promising results for real time fluid animation, with results that goes up to 9 times speedup, when compared to traditional GPU approaches, and up to 100 times when compared against CPU implementations. © 2014 Elsevier Inc. All rights reserved.","Data structure; Fluid animation; Fluid simulation; GPGPU; GPU computing; Real-time simulation","Animation; Cells; Computer graphics; Cytology; Data structures; Program processors; Fluid animation; Fluid simulations; GPGPU; GPU computing; Real time simulations; Hydrodynamics",2-s2.0-84918818908
"Li M., Liu S.","Adopting variable dependency in animation for presenting the behaviour of process",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929610554&doi=10.1007%2f978-3-319-17404-4_6&partnerID=40&md5=2edca860c2575e60821c25cd09983b0b","Scenario-based formal specification animation can dynamically present the specification without translating it into executable program. The behaviours of the system defined in the specification are organized as sequences of processes. The user can observe a specific system behaviour by watching the “execution” of the sequence of processes. To present the “execution”, each process is sequentially connected via data, which are generated based on the pre- and post-condition of the specification. However, the animation method does not provide the user with a chance of observing what happens inside a process. In this paper, we use a sequence of atomic predicate expressions to present the behaviour defined in a specific process. The atomic predicate expressions are organized based on the dependency of variables that are involved in the process.We define the variable dependency and illustrate the derivation of the dependency graph from the specification. The procedure to reorganize the atomic predicates based on the dependency graph is demonstrated with an example. © Springer International Publishing Switzerland 2015.","Animation; Formal specification; Process; Variable dependency","Animation; Atoms; Computational linguistics; Computer simulation languages; Formal languages; Modeling languages; Processing; Program translators; Specifications; Dependency graphs; Executable programs; Pre and post conditions; Scenario-based; Specification animations; Variable dependencies; Formal specification",2-s2.0-84929610554
"Altan T., Cagiltay K.","An eye-tracking analysis of spatial contiguity effect in educational animations",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947061829&doi=10.1007%2f978-3-319-20609-7_1&partnerID=40&md5=9cd2668eef70b53ea107383759dfc832","The purpose of this study is to examine spatial contiguity effect on multimedia learning with an instructional animation using eye-tracking. The research method was experimental method and the study was conducted with a user group consisting of 12 participants (6 female and 6 male). The data collection tools were a demographic survey, a prior knowledge test, a retention test and an eye-tracker. The collected data were analyzed using descriptive statistics and non-parametric statistics including Mann-Whitney U Test. According to the results there were no statistically significant difference in terms of learning outcomes, total fixation time on relevant texts and images, fixation count on relevant texts and images, and mean fixation duration on relevant images between spatial and non-spatial group according to the research results. However, mean fixation duration on relevant texts was significantly higher for spatial group than non-spatial group. According to mean ranks on all measures of eye tracking data, there may be tendency that participants in spatial group spent more time and attention on relevant text as non-spatial group spent more time and attention on narration and relevant images. © Springer International Publishing Switzerland 2015.","Educational animations; Eye-tracking; Multimedia; Spatial contiguity effect","Channel estimation; Engineering education; Surveys; Data collection tools; Descriptive statistics; Eye-tracking; Instructional animations; Multimedia; Non-parametric statistics; Spatial contiguity effect; Statistically significant difference; Human computer interaction",2-s2.0-84947061829
"Maki N., Yanaka K.","Virtual aquarium: Mixed reality consisting of 3DCG animation and underwater integral photography",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947257423&doi=10.1007%2f978-3-319-20618-9_45&partnerID=40&md5=05063f22dd9b9421bc25f8c909a6fdae","Virtual aquariums have various advantages when compared with real aquariums. First, imaginary creatures and creatures that are difficult to maintain in real aquariums can be displayed. Second, virtual aquariums have similar soothing effects as an actual aquarium. Therefore, we developed a new virtual aquarium through integral photography (IP), wherein virtual fishes are created with 3DCG animation and real water. Stereoscopic view is possible from all directions above the water tank through the IP and without the need for special glasses. A fly’s eye lens is sunk in the water resulting in larger focal length for the fly’s eye lens and an increase in the amount of popping out. Therefore, a stronger stereoscopic effect is obtained. The displayed fishes appear to be alive and swimming in the water, an effect achieved through three-dimensional computer graphics animation. This system can also be appreciated as an artwork. This system can also be applied to exhibit already-extinct ancient creatures in aquariums or museums in the future. © Springer International Publishing Switzerland 2015.","Animation; Integral photography; Three-dimensional computer graphics","Animation; Computer graphics; Fish; Photography; Stereo image processing; Three dimensional computer graphics; Virtual reality; Water tanks; Eye lens; Focal lengths; Integral photography; Mixed reality; Special glass; Stereoscopic view; Virtual fish; Human computer interaction",2-s2.0-84947257423
"Yu A.","Computer simulation modeling for human motion",2015,"Metallurgical and Mining Industry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938768017&partnerID=40&md5=cad67bf0c28831da86cdc539e1dc3a06","In the background of progressive completed sparse representation theory, sparse representation of signal has gradually aroused increasing attentions from scholars and has been widely used in various fields. At the same time, the digital media industry, represented by three-dimensional films and games, rises gradually and the computer animation technology develops greatly, which has become a hotspot between scholars. Due to the unique space structure and time structure in human motion capture data, to simply use existing sparse representation model theory is difficult for the motion capture data analysis and processing. Therefore, how to effectively use the sparse representation theory to make a better motion capture data modeling, analyze and process the human motion capture data so as to achieve better results has become a significant issue. A semi supervised learning algorithm based on sparse representation is proposed in this paper to fully excavate the potential rules in the motion, obtain the Mahalanobis distance measurement. On these grounds, the logical similarity between two motions is judged to conduct the motion modeling and simulation. Experimental results have given prominence to the algorithm advantages. © 2015. Metallurgical and Mining Industry.","Capture data; Human motion; Sparse representation","Algebra; Animation; Data handling; Digital storage; Information analysis; Learning algorithms; Supervised learning; Capture data; Computer animation; Human motion capture data; Human motions; Logical similarities; Mahalanobis distances; Motion capture data; Sparse representation; Computer games",2-s2.0-84938768017
"Jing B., Hong L.","Improved artificial bee colony algorithm and application in path planning of crowd animation",2015,"International Journal of Control and Automation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928630178&doi=10.14257%2fijca.2015.8.3.8&partnerID=40&md5=187f5d36ae21b2fe88d584305e02795b","Crowd animation is a new and continuous challenge in computer animation. In tradition, crowd animation can be realized by key frame technology, and animators should set every character's expression, action, motion, and behavior. Therefore animators' workload by hand will increase tremendously with characters growing, which lead to difficult to realize crowd animation for low efficiency and poor global controllability, especially in path planning by appointing a target position for each individuals. In order to overcome these, an improved artificial bee colony (IM-ABC) algorithm is proposed to apply on the path planning of crowd animation. The IM-ABC is fit to simulate the crowd motion in animation based on the following two merits over the others in crowd animation. One is the rule of role transformation, which can make the rapid convergence of the result and avoid getting trapped in the local optima. The other is the realization of multi-object optimization in the process of iteration, which reaches the uniformly distributed result of swarm motion and especially fits to realize the path plan. In this paper, we simply reviews classical ABC algorithm proposed by Karaboga at the beginning. Then, in order to speed the convergence and make individuals generate paths more realistic and natural, some measures are taken to modify the classical ABC (called IM-ABC) algorithm, which include initializing colony based on chaos sequence, self-adaptively selecting the follower bees, and adaptively controlling parameters, etc. After the experiments of benchmark functions, the results confirm that the IM-ABC have better performance than the classical ABC algorithm and others. Finally, the IM-ABC algorithm is used for path planning to generate the route from the initial to the destination without collision. Through simulation experiments based on four motion models it is showed that this method can succeed generating the optimum paths with efficiency, intelligence, and natural features. © 2015 SERSC.","Crowd animation; IM-ABC; Motion model; Path planning; Self-adaptive","Algorithms; Animation; Benchmarking; Evolutionary algorithms; Iterative methods; Optimization; Artificial bee colonies; Artificial bee colony algorithms; Controlling parameters; Crowd animation; IM-ABC; Motion modeling; Multi-object optimization; Self-adaptive; Motion planning",2-s2.0-84928630178
"Lackey S.J., Badillo-Urquiola K.A., Ortiz E.C., Hudson I.L.","A process for developing accurate kinesic cues in virtual environments",2015,"24th Conference on Behavior Representation in Modeling and Simulation, BRiMS 2015, co-located with the International Social Computing, Behavioral Modeling and Prediction Conference, SBP 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006240211&partnerID=40&md5=cd899d3dde8488f7ff17d8a76294882d","Computer animations exhibit the illusion of movements or actions of virtual agents and assets within a virtual environment display. Two distinct animation categories exist: two-dimensional (2D) and three-dimensional (3D). 2D animation is typically stylized and used primarily for entertainment-based efforts such as cartoons and lowfidelity games. 3D animation is applied to a wider variety of domains (e.g., entertainment games, serious games, and training simulations). A well-designed 3D computer animation enables a realistic representation of action portraying the true context of movement, particularly human gestures (Badler, Palmer, & Bindiganavale, 1999). All humans convey intent whether purposefully or not via verbal and non-verbal cues (Bavelas, 1990; Givens, 2002). Kinesic cues convey information to an observer through body language and gestures. Emerging research in training human threat detection requires virtual agents exhibiting kinesic cues to provide visual stimuli within Simulation-Based Training (SBT) applications. Thus, guidelines and specifications for system developers are required. This paper presents a process for defining, designing, and animating kinesic cues using a commercially available software application to mimic realistic human behaviors, movements, and gestures. Through this discussion, culturally agnostic kinesic cues are presented, and relevant limitations are identified. The process described and lessons learned represent a logical progression in the formalization of developing advanced visual models for training Warfighters, law enforcement agents, and first responders to detect and classify human threats. © The BRIMS Society 2015.","Behavior Cue Analysis; Computer Animation; Kinesic Cues; Simulation-Based Training","Application programs; Behavioral research; Virtual reality; 3D computer animation; Behavior Cue Analysis; Computer animation; Kinesic Cues; Simulation-based training; Software applications; Threedimensional (3-d); Two Dimensional (2 D); Animation",2-s2.0-85006240211
"Mohamed F.N., Mohd Nor N.L.","Puppet Animation Films and Gesture Aesthetics",2015,"Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938331168&doi=10.1177%2f1746847715587425&partnerID=40&md5=c9df7d13528134890d0ad69443486d1b","Gestures are meaningful acts of being. All gesture speaks of the formation of posture, and by this posture we can even comprehend the culture that is bound and produced in the action of gesture. This article examines the aesthetics of gesture found in puppet animation. Puppets are rich in their textured and sculptural forms and yet they have limited, wooden-like performance. However, it is their limitations - unlike smooth computer-generated imagery (CGI) or 2D animated drawings - which make every nuance in their performances exceptionally important and instructive in understanding the characters motivation. Three short animation films Jiří Trnkas The Hand (1965), Kihachiro¯ Kawamotos The Demon (1972) and Suzie Templetons Dog (2001) - are chosen as the case studies in this article. The authors elaborate on the way gestures are communicated through poses, shots and framings to then construct and discuss categories of gesture. © The Author(s) 2015.","animation aesthetics; gesture; Jiří Trnka; Kihachiro¯ Kawamoto; performance; puppet animation; stop-motion; Suzie Templeton",,2-s2.0-84938331168
"Huang X.","Application of 3D human motion in the sports based on computer aided analysis",2015,"Open Cybernetics and Systemics Journal",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988529634&doi=10.2174%2f1874110X01509011728&partnerID=40&md5=387d16fa2d96c377d3c479e9b8e424d7","3D human motion tracking is in recent years the field of machine vision is a very important research direction, it has a wide range of applications, such as human-computer interaction, intelligent animation, video surveillance and other. Currently about three-dimensional human motion tracking research mostly based multicast video, monocular video due to the depth information of the lack of the 3D human motion tracking is more difficult, and most of them monocular 3D video motion tracking only consider is parallel to the lens without occlusion of the movement. In view of the above problems using particle filtering method based on the Monte Carlo method, and combined with a priori knowledge of the human motion for monocular 3D human motion tracking is realized. Experiments show that under the complex background with rotating movements up tracking 100 frames or so, on the long time series of 3D human motion tracking and certain difficulty, need to add more complex motion prediction model and the human body mechanical constraints to guide track. © Xuesi Huang.","3D human animation; Human model; Human motion constraint; Inverse kinematics; Monocular video; Motion tracking","Animation; Computer aided analysis; Computer vision; Human computer interaction; Image segmentation; Inverse kinematics; Monte Carlo methods; Security systems; Target tracking; Three dimensional computer graphics; Human animation; Human Model; Human motions; Monocular video; Motion tracking; Motion analysis",2-s2.0-84988529634
"Niebe S., Erleben K.","Numerical methods for linear complementarity problems in physics-based animation",2015,"Synthesis Lectures on Computer Graphics and Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924055241&partnerID=40&md5=f8798e9eb0a315365acab116279a3fec","Linear complementarity problems (LCPs) have for many years been used in physics-based animation to model contact forces between rigid bodies in contact. More recently, LCPs have found their way into the realm of fluid dynamics. Here, LCPs are used to model boundary conditions with fluid-wall contacts. LCPs have also started to appear in deformable models and granular simulations. There is an increasing need for numerical methods to solve the resulting LCPs with all these new applications. This book provides a numerical foundation for such methods, especially suited for use in computer graphics. This book is mainly intended for a researcher/Ph.D. student/post-doc/professor who wants to study the algorithms and do more work/research in this area. Programmers might have to invest some time brushing up on math skills, for this we refer to Appendices \ref{cha:basic-calculus} and \ref{cha:first-order-optim}. The reader should be familiar with linear algebra and differential calculus. We provide pseudo code for all the numerical methods, which should be comprehensible by any computer scientist with rudimentary programming skills. The reader can find an online supplementary code repository, containing Matlab implementations of many of the core methods covered in these notes, as well as a few Python implementations [2011].","convergence rates; interior point methods; linear complementarity problems; Newton methods; performance study; splitting methods","Animation; Calculations; Computer graphics; Computer programming; Differentiation (calculus); Linear algebra; Linear programming; MATLAB; Newton-Raphson method; Convergence rates; Interior point methods; Linear complementarity problems; Performance study; Splitting method; Numerical methods",2-s2.0-84924055241
"Naraghi Z., Jamzad M.","Speech driven lips animation for the Farsi language",2015,"Proceedings of the International Symposium on Artificial Intelligence and Signal Processing, AISP 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938805124&doi=10.1109%2fAISP.2015.7123525&partnerID=40&md5=1669ebe888c753ebf15c0676979b5f60","With the growing presence of computers in everyday life, communication improvement between human and machines is inevitable. Talking faces are the faces whose movements are synchronized to speech. They have an effective role in many applications. Lip is the most important part of a talking face. The main goal of this project is implementing a natural and human-like lip movement synthesis system for the Farsi language. For this purpose, a comprehensive audio visual database called SFAVD1 was designed and used. After extracting the sufficient features and designing a parallel Hidden Markov Model, the speech driven lip movement sequence generator system for Farsi input speech was implemented. To remove discontinuities between lip frames produced by the system, a morphing algorithm was used. The proposed system is unique for Farsi, and the evaluations have shown its acceptable quality. © 2015 IEEE.","Farsi language; Hidden Markov Model; lip movement synthesis; Lips animation; Morphing algorithm; Speech","Animation; Artificial intelligence; Computational linguistics; Hidden Markov models; Markov processes; Speech; Audio-visual database; Farsi language; Human like; Lip movements; Morphing algorithms; Parallel hidden markov models; Sequence generators; Signal processing",2-s2.0-84938805124
"Kuroki Y., Ishihara M.","Manipulating animation speed of progress bars to shorten time perception",2015,"Communications in Computer and Information Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945938231&doi=10.1007%2f978-3-319-21383-5_113&partnerID=40&md5=665db86fdfaac2b85a3230cad6382db1","This manuscript introduces the basic idea of how to shorten the perceived time of progress bars’ animation. The perceived time is not always proportional to the actual elapsed time. It is affected by a variety of psychological factors, and it is manipulable and distortable under certain circumstances. This manuscript explains how the perceived time is shortened by progress bars’ animation, and shows that manipulating animation speed of progress bars has the potential to shorten the time perception. © Springer International Publishing Switzerland 2015.","GUIs; Interface design; Perceived time; Progress bars","Animation; Graphical user interfaces; Interface designs; Perceived time; Psychological factors; Time perception; Human computer interaction",2-s2.0-84945938231
"Nakada M., Terzopoulos D.","Deep learning of neuromuscular control for biomechanical human animation",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952645859&doi=10.1007%2f978-3-319-27857-5_31&partnerID=40&md5=1d88026b98d92f53be3b40378793be85","Increasingly complex physics-based models enhance the realism of character animation in computer graphics, but they pose difficult motor control challenges. This is especially the case when controlling a biomechanically simulated virtual human with an anatomically realistic structure that is actuated in a natural manner by a multitude of contractile muscles. Graphics researchers have pursued machine learning approaches to neuromuscular control, but traditional neural network learning methods suffer limitations when applied to complex biomechanical models and their associated high-dimensional training datasets. We demonstrate that “deep learning” is a useful approach to training neuromuscular controllers for biomechanical character animation. In particular, we propose a deep neural network architecture that can effectively and efficiently control (online) a dynamic musculoskeletal model of the human neck-head-face complex after having learned (offline) a high-dimensional map relating head orientation changes to neck muscle activations. To our knowledge, this is the first application of deep learning to biomechanical human animation with a muscle-driven model. © Springer International Publishing Switzerland 2015.",,"Artificial intelligence; Biomechanics; Complex networks; Computer graphics; Learning systems; Muscle; Network architecture; Virtual reality; Bio-mechanical models; High dimensional map; Machine learning approaches; Musculoskeletal model; Neck muscle activation; Neural network learning; Neuromuscular control; Physics-based models; Animation",2-s2.0-84952645859
"Chiou C.-C., Tien L.-C., Lee L.-T.","Effects on learning of multimedia animation combined with multidimensional concept maps",2015,"Computers and Education",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907906805&doi=10.1016%2fj.compedu.2014.09.002&partnerID=40&md5=994c8c1ed00dcef72768f16d9c099f72","This study investigates whether teaching materials combining multimedia animation and multidimensional concept maps (MAMCMs) improve learning achievement, retention, and satisfaction more than multidimensional concept maps (MCMs), as suggested by Huang et al. (2012) in Computers & Education. Learning retention, learning achievement, and learning satisfaction associated with two sets of course materials were compared in this quasi-experimental study. In total, 114 students from two classes at one private university in Taiwan participated in this 6-week teaching experiment. Analytical results indicate that learning achievement, learning satisfaction, and learning retention of the MAMCM group were better than those of the MCM group. Pedagogical implications and suggestions are given. © 2014 Elsevier Ltd. All rights reserved.","Computer-mediated communication; Improving classroom teaching; Multimedia/hypermedia systems; Teaching/learning strategies","Computer-mediated communication; Concept maps; Improving classroom teaching; Multimedia animation; Multimedia/hypermedia systems; Teaching/learning strategy",2-s2.0-84907906805
"Meppelink C.S., Van Weert J.C.M., Haven C.J., Smit E.G.","The effectiveness of health animations in audiences with different health literacy levels: An experimental study",2015,"Journal of Medical Internet Research",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922287277&doi=10.2196%2fjmir.3979&partnerID=40&md5=fabd355eaeec2147980432446d96740b","Background: Processing Web-based health information can be difficult, especially for people with low health literacy. Presenting health information in an audiovisual format, such as animation, is expected to improve understanding among low health literate audiences. Objective: The aim of this paper is to investigate what features of spoken health animations improve information recall and attitudes and whether there are differences between health literacy groups. Methods: We conducted an online experiment among 231 participants aged 55 years or older with either low or high health literacy. A 2 (spoken vs written text) x 2 (illustration vs animation) design was used. Participants were randomly exposed to one of the four experimental messages, all providing the same information on colorectal cancer screening. Results: The results showed that, among people with low health literacy, spoken messages about colorectal cancer screening improved recall (P=.03) and attitudes (P=.02) compared to written messages. Animations alone did not improve recall, but when combined with spoken text, they significantly improved recall in this group (P=.02). When exposed to spoken animations, people with low health literacy recalled the same amount of information as their high health literate counterparts (P=.12), whereas in all other conditions people with high health literacy recalled more information compared to low health literate individuals. For people with low health literacy, positive attitudes mediated the relationship between spoken text and the intention to have a colorectal cancer screening (b=.12; 95% CI 0.02-0.25). Conclusions: We conclude that spoken animation is the best way to communicate complex health information to people with low health literacy. This format can even bridge the information processing gap between audiences with low and high health literacy as the recall differences between the two groups are eliminated. As animations do not negatively influence high health literate audiences, it is concluded that information adapted to audiences with low health literacy suits people with high health literacy as well.","Animation; Attitudes; Audiovisual media; Cancer screening; Colorectal cancer; Health literacy; Medical illustration; Memory; Prevention; Reading","aged; audiovisual aid; Colorectal Neoplasms; comprehension; computer graphics; early diagnosis; female; health literacy; health promotion; human; male; medical illustration; middle aged; patient attitude; procedures; recall; Aged; Audiovisual Aids; Colorectal Neoplasms; Comprehension; Computer Graphics; Early Detection of Cancer; Female; Health Literacy; Health Promotion; Humans; Male; Medical Illustration; Mental Recall; Middle Aged; Patient Acceptance of Health Care",2-s2.0-84922287277
"Heinz A., Xu X., D'Costa A.","Web-animations: An interdisciplinary approach for biology and information technology students",2015,"ISEC 2015 - 5th IEEE Integrated STEM Education Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942747545&doi=10.1109%2fISECon.2015.7119941&partnerID=40&md5=722d6ddc3a1eb240a1c1e8a305153280","Interdisciplinary collaboration is becoming increasingly important not only to the scientific community but also to the corporate environment since many real world problems involve collaboration from professionals across disciplines. In this work, we engaged students using a multidisciplinary project that encompassed students from two Information Technology (IT) courses and one Biology course. Students from these courses collaborated to create animations aimed to demonstrate biology concepts. Students worked in teams throughout the semester and presented the completed animation in class. The finished animations were later used in biology classes as teaching and learning tools. The purpose of this project is to create an active learning environment that promotes interdisciplinary collaboration. By the end of the project, students learn to collaborate and communicate effectively with peers of other STEM disciplines, by creating a biology web-based animation as end-product. In this way, they learn to appreciate the value of interdisciplinary teamwork and also realize that animations can be useful teaching and learning tools. Preliminary survey data show positive student feedback regarding learning from peers, using technology and interdisciplinary teamwork. This paper shares our experience in planning and implementing the project. © 2015 IEEE.","Biology; Interdisciplinary; IT; STEM","Animation; Artificial intelligence; Biology; Computer aided instruction; Education; Teaching; Active learning environment; Interdisciplinary; Interdisciplinary collaborations; Interdisciplinary teamwork; IT; Multidisciplinary projects; STEM; Teaching and learning; Students",2-s2.0-84942747545
"Ha O., Fang N.","Developing user-controlled animations with Actionscripts 3.0 to enhance student learning of engineering dynamics",2015,"Global Journal of Engineering Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937679012&partnerID=40&md5=fd43e6853baf366294e24e60c026ea08","Computer animation (CA) is increasingly being employed in engineering education. The user-controlled animations allow users (students) to manipulate input variables and observe how the output numerical results change simultaneously and visually with animations. This article describes how ActionScript 3.0 was used to create user-controlled computer animations to improve student learning of complex concepts and spatially dependent motions in engineering dynamics, a foundational course in many engineering disciplines, such as mechanical, aerospace and civil engineering. Three representative computer animations are provided for demonstration purposes, including: a) general plane motion with a crank and slider mechanism; b) general plane motion and the principle of conservation of energy with a yoyo; and c) moment of inertia and the principle of conservation with inclined planes. These CA modules were implemented in a recent semester for students at Utah State University to learn rigid body dynamics. The results of a questionnaire survey administrated at the end of the semester are reported at the end of this article. © WIETE 2015.","ActionScript 3.0; Engineering dynamics; User-controlled animations; Visualisation",,2-s2.0-84937679012
"Transue S., Choi M.-H.","Interactive control of deformable-object animations through control metaphor pattern adherence",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938891895&partnerID=40&md5=1224b666fc28c25ad44a680fc112fd68","In this paper we present an adaptive and intuitive methodology for controlling the localized deformations of physically simulated objects using an intuitive pattern-based control interface. To maximize the interactive component presented in this approach we consolidate existing feedback mechanisms in deformable-body control techniques to provide intuitive editing metaphors for stretching, bending, twisting, and compressing simulated objects. The resulting movements created by these control metaphors are validated using imposed behavior evaluation and the effectiveness of this approach is demonstrated through interactively generated compound movements that introduce complex local deformations of objects in existing physical animations. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Animation control; Physically-based simulation","Computer graphics; Animation control; Behavior evaluations; Control interfaces; Feedback mechanisms; Interactive control; Local deformations; Localized deformations; Physically-based simulation; Deformation",2-s2.0-84938891895
"Lee L.-C., Hao K.-C.","Designing and evaluating digital game-based learning with the arcs motivation model, humor, and animation",2015,"International Journal of Technology and Human Interaction",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927521559&doi=10.4018%2fijthi.2015040105&partnerID=40&md5=8707920c2d27e4bc9c864374cfdd35bf","Multimedia teaching applications have been widely utilized in various subjects. The presentation of teaching materials with animations and games helps to stimulate the visual sense and enhance the learning motivation of learners. Successful learning, however, requires the stimulation of learning motivation that can inspire learners to achieve the desired learning objectives. This study combines the ARCS (Attention, Relevance, Confidence, Satisfaction) motivation model, and humor to design a set of multimedia applications that include teaching animations and games for sixth graders' natural science and technology course, called the Cat's Cradle Multimedia Learning System (CCMLS). The scenario stories of anthropomorphic characters introduce four units of natural science: levers, axles, pulleys and gears. Additionally, games are designed to impress learners even more. After the applications were prepared, tests for learning effectiveness, learning motivation and perceived fun associated with teaching materials were conducted with 106 students at the Qishan Elementary School in Kaohsiung. The experimental group used CCMLS, while the control group used videos of the textbook as the applications. A pre-test and post-test, ARCS Learning Motivation Questionnaire, Smileyometer and interviews were conducted with both groups. According to the statistical analysis, significance was detected in regard to learning effectiveness between the experimental group and the control group. Significance was also found in ARCS learning motivation and perceived fun of teaching materials. Moreover, there is a significant positive correlation between the perceived fun related to the teaching materials and learning motivation. The contribution of this study lies in the proposal of the digital game-based learning (DGBL) from the design perspective: to enhance students' learning motivation and use willingness regarding the teaching materials of the drama and the cartoon characters in humorous dialogues. The proper sound and light effects and examples that are close to daily life will also be taken into consideration in the design of the multimedia applications. Copyright © 2015, IGI Global.","Animation; Attention; Confidence and Satisfaction (ARCS) Theory; Digital game-based learning (DGBL); Humor; Material fun; Relevance; Virtual Figures","Animation; Computer games; Curricula; Design; Learning systems; Motivation; Natural sciences; Surveys; Teaching; Attention; Confidence and Satisfaction (ARCS) Theory; Digital game-based learning; Humor; Relevance; Virtual figure; E-learning",2-s2.0-84927521559
"Wang C., Zhang Q., Kong F., Gao Y.","Fast animation of debris flow with mixed adaptive grid refinement",2015,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926156819&doi=10.1002%2fcav.1542&partnerID=40&md5=18e3fb2b942f4f9fe0f0744934ae1669","Animating debris flow is one of the most challenging tasks in computer graphics, because of its complex dynamic mechanism and the interaction between flows and solids in so large scale region. The difficulty focuses on how to resolve the contradiction between lower computational load and higher request of animating quality. A highly effective method of modeling and animating of debris flow with adaptive grid is presented. First, the debris flow is modeled as Bingham plastic fluid with view-dependent adaptive grid that is adopted to model the flow volume, and the boundless grids can cover the large scale region of debris flow. Then the mixed grids are built for confluent flows, and the two-way coupling interaction between flows and environment is considered. After extracting the debris flow surface, adaptive surface tension combining wave particles equation is used to enhance the details and sprays are generated by particles considering the interaction between two fluid volumes. Finally, different dynamic realistic scenes with debris flow are successfully animating at interactive rates.A highly effective method of modeling and animating of debris flow with adaptive grid is presented. With the view-dependent adaptive and boundless grids, two-way coupling interaction between flows and environment is modeled. Different dynamic realistic debris flow scenes with enhanced details based on adaptive surface tension are successfully animating at interactive rates. © 2013 John Wiley & Sons, Ltd.","adaptive grid; animating; debris flow; enhanced details; interaction","Animation; Computer graphics; Surface tension; Adaptive grids; animating; Debris flows; enhanced details; interaction; Debris",2-s2.0-84926156819
"Harel D., Nitzan S.","Programming animation using behavioral programming",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950152935&doi=10.1007%2f978-3-319-21912-7_5&partnerID=40&md5=166bdf8863bfdd5f458b36bbd02ab4b7","We propose a simple, user-friendly way of creating computer programs for hybrid systems whose execution involves animation. This is done by adapting behavioral programming, a recently proposed approach to software development that is aligned with how people describe system behavior, for use in programming animation. Users can define discrete and continuous behavior, which are then run simultaneously, interacting with each other, and resulting in a smooth hybrid animation. © Springer International Publishing Switzerland 2015.",,"Animation; Hybrid systems; Software design; Behavioral programming; System behaviors; User friendly; Behavioral research",2-s2.0-84950152935
"Upadrashta R., Choubisa T., Aswath V.S., Praneeth A., Prabhu A., Raman S., Gracious T., Vijay Kumar P., Kowshik S., Iyer M.S., Prabhakar T.V.","An animation-and-chirplet based approach to intruder classification using PIR sensing",2015,"2015 IEEE 10th International Conference on Intelligent Sensors, Sensor Networks and Information Processing, ISSNIP 2015",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933565291&doi=10.1109%2fISSNIP.2015.7106914&partnerID=40&md5=9367eaf4c450efb8707312a98d55582a","The development of a Passive Infra-Red (PIR) sensing based intrusion detection system is presented here having the ability to reject vegetative clutter and distinguish between human and animal intrusions. This has potential application to reducing human-animal conflicts in the vicinity of a wildlife park. The system takes on the form of a sensor-tower platform (STP) and was developed in-house. It employs a sensor array that endows the platform with a spatial-resolution capability. Given the difficulty of collecting data involving animal motion, a simulation tool was created with the aid of Blender and OpenGL software that is capable of quickly generating streams of human and animal-intrusion data. The generated data was then examined to identify a suitable collection of features that are useful in classification. The features selected corresponded to parameters that model the received signal as the super-imposition of a fixed number of chirplets, an energy signature and a cross-correlation parameter. The resultant feature vector was then passed on to a Support Vector Machine (SVM) for classification. This approach to classification was validated by making use of real-world data collected by the STP which showed both STP design as well as classification technique employed to be quite effective. The average classification accuracy with both real and simulated data was in excess of 94%. © 2015 IEEE.","animation; chirplets; intrusion detection; passive infrared sensor; sensor array; Wireless sensor network","Animals; Animation; Application programming interfaces (API); Blending; Computer software; Image retrieval; Infrared detectors; Intrusion detection; Sensor arrays; Support vector machines; Wireless sensor networks; Chirplets; Classification accuracy; Classification technique; Cross correlations; Energy signatures; Intrusion Detection Systems; Passive infrared sensors; Spatial resolution; Classification (of information)",2-s2.0-84933565291
"Xiong L., Sun P., Tian X., Liu X., Chen F.","3D graphics rendering engine introduction and application in choreography",2015,"Electronics, Communications and Networks IV - Proceedings of the 4th International Conference on Electronics, Communications and Networks, CECNet2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960155336&partnerID=40&md5=d95ce2ed594f3bbcb3d8670df4d1af76","With the rapid development of computer hardware and software, the application of computer graphics has also got rapid development in all walks of life. Development of graphics has gone through a few decades, and now the computer has already entered a three-dimensional era. The three-dimensional graphics can be seen everywhere in real life. Scientific visualization, computer animation and virtual reality technology have become hot topics in recent years. Researches in the field of computer graphics hierarchy deepen gradually and grow fast. This article describes three common systems of graphics rendering engine, as well as discusses how to use the engine to create a three-dimensional graphics system, and introduces the binding and application of 3D graphics rendering and stage design. © 2015 Taylor & Francis Group, London.",,"Animation; Application programs; Computer graphics; Computer hardware; Engines; Rendering (computer graphics); Virtual reality; 3D graphics; Computer animation; Graphics rendering; Hardware and software; Hot topics; Three-dimensional graphics; Virtual reality technology; Three dimensional computer graphics",2-s2.0-84960155336
"Koga K., Inamura M., Kaneda K., Iwamura K.","Content control scheme to realize right succession and edit control",2015,"ICE-B 2015 - 12th International Conference on e-Business, Proceedings; Part of 12th International Joint Conference on e-Business and Telecommunications, ICETE 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969851021&partnerID=40&md5=3abe523e4cef42450c69b5e94f8f5aa3","We propose a copyright protection technology suitable for consumer generated media such as You Tube and CLIP. This technology realizes right succession of and edit control by the previous work's authors. In this technology, we use a digital signature to confirm the relation between the primary and secondary authors and to determine whether the contents may be edited. We propose to apply this technology to CLIP, which is a software used to operate a pre-set character three-dimensional (3D) model of a three-dimensional computer graphics (3DCG) for creating computer animation. In addition, we provide three security methods for the proposed technologies.","Aggregate signature; Copyright protection; Edit control; Electronic signature; Right succession","Animation; Computer graphics; Consumer protection; Electronic commerce; Electronic document identification systems; Three dimensional computer graphics; Aggregate signature; Computer animation; Copyright protections; Electronic signatures; Right succession; Security methods; Three dimensional (3-D) modeling; Three dimensional computer graphics (3DCG); Copyrights",2-s2.0-84969851021
"Hoon L.N., Abd. Rahman K.A.A., Chai W.Y.","Framework development of real-time lip sync animation on viseme based human speech",2015,"Jurnal Teknologi",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938237203&partnerID=40&md5=4196856d67f3dd4151a3ba2d14d61176","Performance of real-time lip sync animation is an approach to perform a virtual computer generated character talk, which synchronizes an accurate lip movement and sound in live. Based on the review, the creation of lip sync animation in real-time is particularly challenging in mapping the lip animation movement and sounds that are synchronized. The fluidity and accuracy in natural speech are one of the most difficult things to do convincingly in facial animation. People are very sensitive to this when you get it wrong because we are all focused on faces. Especially in real time application, the visual impact needed is immediate, commanding and convincing to the audience. A research on viseme based human speech was conducted to develop a lip synchronization platform in order to achieve an accurate lip motion with the sounds that are synchronized as well as increase the visual performance of the facial animation. Through this research, a usability automated digital speech system for lip sync animation was developed. Automatic designed with the use of simple synchronization tricks which generally improve accuracy and realistic visual impression and implementation of advanced features into lip synchronization application. This study allows simulation of lip synching in real time and offline application. Hence, it can be applied in various areas such as entertainment, education, tutoring, animation and live performances, such as theater, broadcasting, education and live presentation. © 2015 Penerbit UTM Press. All rights reserved.","Human speech recognition; Lip synchronization animation; Real time",,2-s2.0-84938237203
"Wong M., Castro-Alonso J.C., Ayres P., Paas F.","Gender effects when learning manipulative tasks from instructional animations and static presentations",2015,"Educational Technology and Society",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948162700&partnerID=40&md5=faad5c5cd819462b9cce76694d964152","Humans have an evolved embodied cognition that equips them to deal easily with the natural movements of object manipulations. Hence, learning a manipulative task is generally more effective when watching animations that show natural motions of the task, rather than equivalent static pictures. The present study was completed to explore this research domain further by investigating the impact of gender on static and animation presentations. In two experiments, university students were randomly assigned to either a static or animation condition and watched a computer-controlled presentation of a Lego shape being built. After each of two presentations, students were required to reconstruct the task followed by a transfer task. In Experiment 1 the tasks were performed using real Lego bricks (physical environment), and in Experiment 2 by computerized images of the bricks (virtual environment). Results indicated no differences between the two testing environments or an overall advantage for the animated format. However, a number of interactions between gender and presentation format were found. Follow-up analyses indicated that females benefited more than males from using animated presentations.","Animation vs. static picture; Cognitive load theory; Embodied cognition; Gender differences; Technology-based learning",,2-s2.0-84948162700
"Mukovskiy A., Land W.M., Schack T., Giese M.A.","Modeling of predictive human movement coordination patterns for applications in computer graphics",2015,"Journal of WSCG",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938281187&partnerID=40&md5=ab6db7f4be10b809fa01cef052c8d6f7","The planning of human body movements is highly predictive. Within a sequence of actions, the anticipation of a final task goal modulates the individual actions within the overall pattern of motion. An example is a sequence of steps, which is coordinated with the grasping of an object at the end of the step sequence. Opposed to this property of natural human movements, real-time animation systems in computer graphics often model complex activities by a sequential concatenation of individual pre-stored movements, where only the movement before accomplishing the goal is adapted. We present a learning-based technique that models the highly adaptive predictive movement coordination in humans, illustrated for the example of the coordination of walking and reaching. The proposed system for the real-time synthesis of human movements models complex activities by a sequential concatenation of movements, which are approximated by the superposition of kinematic primitives that have been learned from trajectory data by anechoic demixing, using a step-wise regression approach. The kinematic primitives are then approximated by stable solutions of nonlinear dynamical systems (dynamic primitives) that can be embedded in control architectures. We present a control architecture that generates highly adaptive predictive full-body movements for reaching while walking with highly human-like appearance. We demonstrate that the generated behavior is highly robust, even in presence of strong perturbations that require the insertion of additional steps online in order to accomplish the desired task. © 2015, Vaclav Skala Union Agency. All rights reserved.","Action sequences; Computer animation; Motor coordination; Movement primitives; Prediction",,2-s2.0-84938281187
"Tyler D.W., Dank J.A.","Cramér-Rao lower bound calculations for image registration using simulated phenomenology",2015,"Journal of the Optical Society of America A: Optics and Image Science, and Vision",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943277715&doi=10.1364%2fJOSAA.32.001425&partnerID=40&md5=e44252f37d327dcff28425e06bd9f332","The Cramér-Rao lower bound (CRLB) is a valuable tool to quantify fundamental limits to estimation problems associated with imaging systems, and has been used previously to study image registration performance bounds. Most existing work, however, assumes constant-variance noise; for many applications, noise is signal-dependent. Further, linear filters applied after detection can potentially yield reduced registration error, but prior work has not treated the CRLB behavior caused by filter-imposed noise correlation. We have developed computational methods to efficiently generalize existing image registration CRLB calculations to account for the effect of both signal-dependent noise and linear filtering on the estimation of rigid-translation (""shift"") parameters. Because effective use of the CRLB requires radiometrically realistic simulated imagery, we have also developed methods to exploit computer animation software and available optical properties databases to conveniently build and modify synthetic objects for radiometric image simulations using DIRSIG. In this paper, we present the generalized expressions for the rigid shift Fisher information matrix and discuss the properties of the associated CRLB. We discuss the methods used to synthesize object ""sets"" for use in DIRSIG, and then demonstrate the use of simulated imagery in the CRLB code to choose an error-minimizing filter and optimal integration time for an image-based tracker in the presence of random platform jitter. © 2015 Optical Society of America.",,"Animation; Fisher information matrix; Image registration; Optical properties; Optimal systems; Computer animation; Estimation problem; Optimal integration time; Radiometric images; Registration error; Registration performance; Signal dependent noise; Simulated imageries; Image processing; algorithm; automated pattern recognition; computer assisted diagnosis; image enhancement; image subtraction; machine learning; procedures; reproducibility; sensitivity and specificity; three dimensional imaging; Algorithms; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique",2-s2.0-84943277715
"Takano W., Ishikawa J., Nakamura Y.","Using a human action database to recognize actions in monocular image sequences: Recovering human whole body configurations",2015,"Advanced Robotics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930571707&doi=10.1080%2f01691864.2014.996604&partnerID=40&md5=3fc95b07816422d343f1221abe8819ca","Understanding human behaviors and generating human-like motions are key technologies for human-robot interaction, motion synthesis in computer animation, sports training, and rehabilitation. Motion capture systems have been developed to accomplish this, and marker-based motion capture systems, in particular, have been used in measuring human actions and performing action recognition. However, marker-based motion capture systems have several drawbacks; in particular, the capture system is expensive, intrusive, and complex to use. Markerless motion capture systems have the potential to overcome these drawbacks. Recently, databases containing a large number of configurations of human whole body actions are available, and they are expected to be reused as new approaches to recognizing actions and recovering action configurations from motion depicted in videos comprising monocular images. This paper describes a design of an action database that consists of action configurations, pose descriptors from silhouette images, a stochastic model encoding each sequence of the pose descriptors, and relations between the data and the stochastic models. The proposed action database is applied to recognizing a video containing a performer doing a specific action and to recovering all the joint angles from the video. We tested the action database on recognition and configuration recovery, and the results show that the database is suitable for this purpose. © 2015 The Author(s).","action database; action recognition; recovery of action configurations","Animation; Computer vision; Database systems; Gesture recognition; Human computer interaction; Human robot interaction; Image coding; Image recognition; Motion estimation; Recovery; Robots; Stochastic models; Stochastic systems; Action recognition; Computer animation; Human-like motion; Markerless motion capture; Monocular image sequence; Motion capture system; Motion synthesis; Silhouette images; Behavioral research",2-s2.0-84930571707
"Ai M., Tong H., Shen L., Wang R., Zhang F., Zhang Z., Hu Q., Zhu Y., Zhang H.","4D visualization of painted sculpture and murals",2015,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974589156&doi=10.5194%2fisprsarchives-XL-5-W7-1-2015&partnerID=40&md5=511babe65ecf3bdac40e52c3a459a72e","Most cultural heritage applications address visualization with using various media or platforms: desktop-based multimedia presentations, museum kiosks, or videos produced with computer animation. However, these techniques can not directly reveal or show the course that the colorful surface of painted sculpture and murals becomes faint along with the change of the climate and time. Most current techniques just preserve the current appearance and disseminate the current situation of the painted sculpture and murals. The course how these forms of cultural heritage change along the time has not been visualized. In this paper we developed an approach to modelling of painted sculpture and murals that has undergone changes over the years. Different hypotheses has also be given if there is uncertainty. A painted sculpture of Mogao Grottoes is used to demonstate this approach.","3D Reconstruction; 4D Visualization; Chemical Analysis; Image Segmentation; Painted Sculpture and Murals","Animation; Chemical analysis; Climate change; Image reconstruction; Image segmentation; Visualization; 3D reconstruction; 4D visualization; Computer animation; Cultural heritage application; Cultural heritages; Current situation; Multimedia presentation; Painted Sculpture and Murals; Three dimensional computer graphics",2-s2.0-84974589156
"Majhi M., Chakrabarti D.","A paradigm-shift towards user-centred empirical methodology in interactive multimedia communication",2015,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943253610&doi=10.1007%2f978-81-322-2229-3_57&partnerID=40&md5=42f1b790b98098fa0aa4899830f2108f","With multiple mediums of interaction available, it has become essential for a designer to be able to choose the medium that can be most effective for the chosen user. The popular mediums identified for the interactive study are special effects, Cel-animation, Puppetry, Video and Stop-motion animation. Case studies were made available to a group of 40 users, so as to be able to get an exposure of the available mediums of interactive multimedia communication. The findings from the study gave a surprising revelation of the preference of the users in choosing the medium for the empiricism with more than half the users preferring the stop-motion medium to be used to communicate. The study focuses on the user-centered empirical methodology to reveal the vein of the interactivity which was the user having a flexibility of using the expertise of using observation, being able to create which is an inventive process, an appreciation of the invention to interact by studying the inventive user-centered empirical methodology to make the design effective for its aesthetics, semiotics and semantics in design. © Springer India 2015.","Cel-animation; Photography; Puppetry; SFX; Stop-motion animation; Videography","Animation; Design; Interactive computer systems; Photography; Semantics; Video recording; Cel animation; Puppetry; SFX; Stop-motion animations; Videography; Multimedia systems",2-s2.0-84943253610
"Khan K.A., Akhter G.","Computer-based experiments for learning seismic signal processing concepts",2015,"Computer Applications in Engineering Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945488078&doi=10.1002%2fcae.21669&partnerID=40&md5=8c9684515a6b78c2fe67d397ca876751","A good understanding of digital signal processing concepts is essential for students of geophysical engineering, electrical engineering, and image processing. This paper presents a computer-based training software, which uses signal processing libraries to perform a number of interesting seismic experiments. Each experiment is focused towards a specific concept and presents a parameters input interface. The results are instantly generated in the form of a graphical display. This facilitates the student to play with parameters and observe their effects on the output. Some selected experiments have been discussed along with their parameters input interfaces and sample outputs. Such experiments provide a better understand and visualization of various seismic concepts. Studies on student groups indicate that these experiments motivate students and expedite self-learning, thus reducing the teaching load. © 2015 Wiley Periodicals, Inc.","animations; computer-based training; digital signal processing; educational experiments; seismic","Animation; Digital signal processing; E-learning; Image processing; Seismology; Students; Computer - based trainings; Digital signals; Educational experiment; Geophysical engineering; Graphical displays; Input interface; Seismic; Seismic signal processing; Signal processing",2-s2.0-84945488078
"Chen K., Johan H.","Animating 3D vegetation in real-time using a 2D approach",2015,"Proceedings of the 19th Symposium on Interactive 3D Graphics and Games, i3D 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927136319&partnerID=40&md5=a8865242e0af11caac576605d96b8d05","In this paper, we propose a 2D approach for real-time animation of vegetation in 3D scenes, especially suitable for simulating wind effects on 3D vegetation fields with densely leaved foliage. We represent a vegetation field as view-dependent 2D billboard layers, perform a 2D harmonic motion simulation for modeling the dynamics of vegetation at the first layer (closest to the viewer), and utilize this dynamics to guide the animation of the rest of the layers while addressing the motion effects in depth and occlusion effects. As a result, our method can produce natural looking motions of vegetation swaying in wind comparable with existing commercial software, however the effort to setting up the underlying animation model and the computational cost can be significantly reduced. Copyright © ACM.","2D billboards; 3D vegetation; Harmonic motion; Real-time animation","Animation; Interactive computer graphics; Vegetation; Wind effects; 2D billboards; Animation modeling; Commercial software; Computational costs; Harmonic motion; Occlusion effect; Real-time animations; View-dependent; Three dimensional computer graphics",2-s2.0-84927136319
"Xiao J., Tang Z., Feng Y., Xiao Z.","Sketch-based human motion retrieval via selected 2D geometric posture descriptor",2015,"Signal Processing",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922633386&doi=10.1016%2fj.sigpro.2015.01.004&partnerID=40&md5=3aefcdcdc3895acf34d5bb726cedf651","Sketch-based human motion retrieval is a hot topic in computer animation in recent years. In this paper, we present a novel sketch-based human motion retrieval method via selected 2-dimensional (2D) Geometric Posture Descriptor (2GPD). Specially, we firstly propose a rich 2D pose feature call 2D Geometric Posture Descriptor (2GPD), which is effective in encoding the 2D posture similarity by exploiting the geometric relationships among different human body parts. Since the original 2GPD is of high dimension and redundant, a semi-supervised feature selection algorithm derived from Laplacian Score is then adopted to select the most discriminative feature component of 2GPD as feature representation, and we call it as selected 2GPD. Finally, a posture-by-posture motion retrieval algorithm is used to retrieve a motion sequence by sketching several key postures. Experimental results on CMU human motion database demonstrate the effectiveness of our proposed approach. © 2015 The Authors. Published by Elsevier B.V.","Computer animation; Feature selection; Motion retrieval; Sketch-based","Animation; Geometry; Computer animation; Discriminative features; Feature representation; Feature selection algorithm; Geometric relationships; Human motion retrieval; Motion retrieval; Sketch-based; Feature extraction",2-s2.0-84922633386
"Vynnycky M., Kanev K.","Mathematical Analysis of the Multisolution Phenomenon in the P3P Problem",2015,"Journal of Mathematical Imaging and Vision",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923702515&doi=10.1007%2fs10851-014-0525-0&partnerID=40&md5=b0d90818925b2d8c50a648fac9039cb0","The perspective 3-point problem, also known as pose estimation, has its origins in camera calibration and is of importance in many fields: for example, computer animation, automation, image analysis and robotics. One line of activity involves formulating it mathematically in terms of finding the solution to a quartic equation. However, in general, the equation does not have a unique solution, and in some situations there are no solutions at all. Here, we present a new approach to the solution of the problem; this involves closer scrutiny of the coefficients of the polynomial, in order to understand how many solutions there will be for a given set of problem parameters. We find that, if the control points are equally spaced, there are four positive solutions to the problem at 25 % of all available spatial locations for the control-point combinations, and two positive solutions at the remaining 75 %. © 2014, Springer Science+Business Media New York.","Multiple solutions; P3P; Quartic polynomial","Animation; Image coding; Robotics; Camera calibration; Computer animation; Mathematical analysis; Multiple solutions; P3P; Perspective 3-Point problems; Problem parameters; Quartic polynomial; Polynomials",2-s2.0-84923702515
"Elias P., Sedmidubsky J., Zezula P.","Motion images: An effective representation of motion capture data for similarity search",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951855309&doi=10.1007%2f978-3-319-25087-8_24&partnerID=40&md5=7a3f94dc1043a89b7abe444c31f08967","The rapid development of motion capturing technologies has caused a massive usage of human motion data in a variety of fields, such as computer animation, gaming industry, medicine, sports and security. These technologies produce large volumes of complex spatio-temporal data which need to be effectively compared on the basis of similarity. In contrast to a traditional way of extracting numerical features, we propose a new idea to transform complex motion data into RGB images and compare them by content-based image retrieval methods. We see these images not only as human-understandable visualization of motion characteristics (e.g., speed, duration and movement repetitions), but also as descriptive features for their ability to preserve key aspects of performed motions. To demonstrate the usability of this idea, we evaluate a preliminary experiment that classifies 1, 034 motions into 14 categories with the 87.4% precision. © Springer International Publishing Switzerland 2015.",,"Animation; Content based retrieval; Image retrieval; Numerical methods; Sports medicine; Computer animation; Content based image retrieval; Human motion data; Motion capture data; Motion characteristics; Numerical features; Similarity search; Spatio-temporal data; Motion analysis",2-s2.0-84951855309
"Kulkarni A.N., Gandhe S.T., Dhulekar P.A., Phade G.M.","Fractal image compression using genetic algorithm with ranking select mechanism",2015,"Proceedings - 2015 International Conference on Communication, Information and Computing Technology, ICCICT 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925600185&doi=10.1109%2fICCICT.2015.7045731&partnerID=40&md5=90548aefa9689f58e553bf214de5e036","The demand for images in video sequences and computer animation has increased drastically over the years. This gives attention on an important issue of compression, resulting into reduction in cost of data storage and transmission. For still image compression JPEG is used world -wide. But alternative methods are also being explored; Fractal image compression is one of them. It is based on the self-similarity property to find out the best match within the image itself. This property is used to generate a fractal code. In this paper, the new approach for fractal image compression using genetic algorithm with ranking select mechanism is proposed. This proposed algorithm is applied on fractal as well as non-fractal images and the experimental result shows that the encoding time for both types of images is greatly reduced while maintaining their quality intact. © 2015 IEEE.","Fractal; Genetic Algorithm; MSE; PSNR; Ranking select mechanism","Algorithms; Animation; Digital storage; Fractals; Genetic algorithms; Image coding; Image compression; Computer animation; Fractal image compression; MSE; New approaches; PSNR; Self similarity properties; Still image compression; Video sequences; Image matching",2-s2.0-84925600185
"Blanchfield P., Valle P.L., Nguyen T., Bradley M., Liu D.","Aspects of development of computer games for therapeutic purposes",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951738042&doi=10.1007%2f978-3-319-23766-4_59&partnerID=40&md5=ec4e18190107bdce5f3f2a422c6366bc","Computer games have from early in their development, experienced negative attitudes from many quarters. Many of these attitudes arise from quite superficial views of computer games, though some work has also been done by those who have observed harm being done to understand the reasons for this and the context in which it occurs. Others have tried to use computer games in the treatment of a range of illnesses. While a wide range of work has been done there have been a number of obstacles to delivering therapeutic interventions. One major problem is the difficulty of developing the highly sophisticated games that are. This paper looks at how recent availability of tools which can support the creation of such games have made it potentially easier to produce them. Examples are given of how these are being used in supporting work that has been shown to be of value in treatment. © Springer International Publishing Switzerland 2015.","Animation Tools; Asset Development; Therapeutic games","Animation; Animation tools; Asset Development; Therapeutic games; Therapeutic intervention; Computer games",2-s2.0-84951738042
"Liu H., Wang Y.","Narrow passage watcher for safe motion planning by using motion trend analysis of C-obstacles",2015,"Open Automation and Control Systems Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928543451&partnerID=40&md5=6c0147e6bf22a0a989bf4b1f5a1eda3a","Finding safe paths for robots in changing environments is a significant issue for motion planning. However, it could be fairly difficult when there are narrow passages in the configuration space. Solutions to this problem can be applicable to not only mobile robots but also other domains such as computer animation and computational biology. This paper presents a novel method called Narrow Passage Watcher (NPW) to cope with narrow passage issues in changing environments. It approximately predicts the variation trend of narrow passages and analyzes their security and thus guides safe path planning. Meanwhile, a supporting hybrid boost strategy is presented to increase the sampling density inside narrow passages with different variation trend. Compared with existing work, the predictive mechanism provided by NPW gives the planner foresight so that it can find safer paths in changing environments with a higher success rate. Experiments conducted with a dual-manipulator system with 12 DOFs show that NPW can reduce the number of replanning times and total planning time remarkably as well as improving the success rate of path planning. © Liu and Wang; Licensee Bentham Open.","Manipulator planning; Narrow passage; Robot and mechanism; Safe motion planning","Animation; Bioinformatics; Manipulators; Motion planning; Robots; Changing environment; Computational biology; Computer animation; Configuration space; Dual-manipulator system; Narrow passage; Predictive mechanisms; Sampling densities; Robot programming",2-s2.0-84928543451
"Kim Y.","Learning statics through in-class demonstration, assignment and evaluation",2015,"International Journal of Mechanical Engineering Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936999753&doi=10.1177%2f0306419015574643&partnerID=40&md5=188ccf206780bde38c099bcdde2d0698","Statics is the well-established first course in mechanics for first-year engineering students all over the world. For this reason, good learning modules (making use of computer animation, group-based projects, practical labs, internet, etc.) have been developed for teaching statics especially at education-oriented universities. It seems, however, that rarely found are 'in-class' demonstrations or 'hands-on' teaching methods for statics which turn out to be crucial for encouraging first-year students to become quickly engaged in mechanics. There is indeed a lot of evidence that students fully appreciate physical concepts right in the classroom via these hands-on teaching methods. In this paper, one such hands-on teaching method, so-called 'in-class demonstration, assignment and evaluation' (DAE, for short), is presented. DAE involves six exercises that can be immediately adopted in the classroom to clearly convey to students the major concepts arising in statics, such as equilibrium, centre of gravity, stability and friction. It is found that DAE can get approximately 94% of the students in class to engage in learning and reduce the percentage of low-motivation students by 7-11%. © The Author(s) 2015.","assignment; demonstration; evaluation; Statics","Animation; Demonstrations; Education; Students; assignment; Centre of gravity; Computer animation; evaluation; First year students; First-year engineering; Statics; Teaching methods; Teaching",2-s2.0-84936999753
"Li D., Yang R., Hu Y., Gong D., Zhu L.","Tracking trajectory of 3D trees moving based on video data driven",2015,"Proceedings - 2014 7th International Symposium on Computational Intelligence and Design, ISCID 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931029825&doi=10.1109%2fISCID.2014.72&partnerID=40&md5=e767b2da7fd25457a26d588813fbf78c","Tracking trajectory of three-dimensional trees is a difficult problem in computer animation and virtual reality. It requires not only high sense of reality for the morphology of trees and tree moving, but also adequate real-time. In this paper, we present a simulation method based on video data driven. Firstly, split out the main branches and leaves of trees from video images by using hybrid method of edge detection and K-means clustering based on color. And then, construct wind-speed sequence of trees in the video by using feature matching algorithm through analyzing the model of trees trunks and set of cloud point of leaves. Finally, by classifying and tracking video sequences with statistical models, we can get trajectory of trees swaying. Experimental results show that only a small part of the motion tracking in the algorithm is calculated in real-time way, the rest are calculated in pretreatment. So this model greatly improves the real-time effect of computing the trajectory of trees moving while keep a good sense of reality at the same time. © 2014 IEEE.","data driven; image segmentation; statistical model; trajectory of 3D trees","Algorithms; Animation; Artificial intelligence; Edge detection; Image matching; Image segmentation; Motion analysis; Trajectories; Video recording; Virtual reality; Wind; 3D tree; Computer animation; Data driven; Feature matching algorithms; K-means clustering; Statistical modeling; Tracking trajectory; Wind speed sequences; Trees (mathematics)",2-s2.0-84931029825
"Rushmeier H., Lockerman Y., Cartwright L., Pitera D.","Experiments with a low-cost system for computer graphics material model acquisition",2015,"Proceedings of SPIE - The International Society for Optical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928501072&doi=10.1117%2f12.2082895&partnerID=40&md5=627f4cd2f395e84ef56ce731d0147f18","We consider the design of an inexpensive system for acquiring material models for computer graphics rendering applications in animation, games and conceptual design. To be useful in these applications a system must be able to model a rich range of appearances in a computationally tractable form. The range of appearance of interest in computer graphics includes materials that have spatially varying properties, directionality, small-scale geometric structure, and subsurface scattering. To be computationally tractable, material models for graphics must be compact, editable, and efficient to numerically evaluate for ray tracing importance sampling. To construct appropriate models for a range of interesting materials, we take the approach of separating out directly and indirectly scattered light using high spatial frequency patterns introduced by Nayar et al. in 2006. To acquire the data at low cost, we use a set of Raspberry Pi computers and cameras clamped to miniature projectors. We explore techniques to separate out surface and subsurface indirect lighting. This separation would allow the fitting of simple, and so tractable, analytical models to features of the appearance model. The goal of the system is to provide models for physically accurate renderings that are visually equivalent to viewing the original physical materials. © 2015 SPIE-IS&T.","LaTeX; Manuscript format; SPIE proceedings; Template","Animation; Computer games; Conceptual design; Importance sampling; Latexes; Ray tracing; Rendering (computer graphics); Separation; Appearance modeling; Computer graphics rendering; Geometric structure; High spatial frequency; Manuscript format; SPIE proceedings; Subsurface scattering; Template; Computer graphics",2-s2.0-84928501072
"Hayashi Y., Fukamachi K.-I., Komatsugawa H.","Collaborative learning in computer programming courses that adopted the flipped classroom",2015,"Proceedings - 2015 International Conference on Learning and Teaching in Computing and Engineering, LaTiCE 2015",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942798161&doi=10.1109%2fLaTiCE.2015.43&partnerID=40&md5=2ce429371d7fa035d0c84eee79a0ff8c","Flipped classroom is a pedagogical model in which the typical lecture and homework elements of a course are reversed. Teachers provide online materials to students for preparation of the lecture and students dedicate to practice in the course. We have put into practice the flipped classroom in our computer programming courses teaching C and Java languages since 2013 as a way of utilizing our e-learning system and contents. As a problem in computer programming education, although teachers explain grammar, students cannot create software well by themselves and. Some students give up the learning. Our goal is to promote each student's learning motivation and understanding for computer programming by the training that the flipped classroom and collaborative learning are applied to. Main feature of this approach is to spend most of the time of a programming class with collaboration among students in order to make practical software. We assign the students homework using Flash animations and video data explaining the lecture as learning-materials to learn vocabularies and grammar of the programming languages every week. Web-based tests consisting of easy questions to confirm the results of doing homework every week are done at the beginning of the actual classes, and it is useful to clarify difficult parts of understanding that the students don't notice. Additionally, we confirmed the effectiveness of this approach by comparing examination scores between 2012 and 2014. Compared with the score of 2012, the average scores of the Web-based test and the written test on mid-exam became high, and the minimum scores of both of the tests also became high. The standard deviation of both of the tests became low. Moreover, the each student was able to make the code of a console game through this collaborative learning. © 2015 IEEE.","Active Learning; Collaborative Learning; Computer Programming; e-Learning; Flipped-classroom","Animation; Artificial intelligence; C (programming language); Computational linguistics; Computer programming; Computer programming languages; Computer systems programming; E-learning; Education; Education computing; Engineering education; Java programming language; Students; Testing; Websites; Active Learning; Collaborative learning; Computer programming course; Flipped-classroom; Learning materials; Learning motivation; Programming education; Standard deviation; Teaching",2-s2.0-84942798161
"Le Muzic M., Waldner M., Parulek J., Viola I.","Illustrative Timelapse: A technique for illustrative visualization of particle-based simulations",2015,"IEEE Pacific Visualization Symposium",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942249205&doi=10.1109%2fPACIFICVIS.2015.7156384&partnerID=40&md5=f6426fcaa5a0168a9e1282ddd802f9e7","Animated movies are a popular way to communicate complex phenomena in cell biology to the broad audience. Animation artists apply sophisticated illustration techniques to communicate a story, while trying to maintain a realistic representation of a complex dynamic environment. Since such hand-crafted animations are time-consuming and cost-intensive to create, our goal is to formalize illustration techniques used by artists to facilitate the automatic creation of visualizations generated from mesoscale particle-based molecular simulations. Our technique Illustrative Timelapse supports visual exploration of complex biochemical processes in dynamic environments by (1) seamless temporal zooming to observe phenomena in different temporal resolutions, (2) visual abstraction of molecular trajectories to ensure that observers are able to visually follow the main actors, (3) increased visual focus on events of interest, and (4) lens effects to preserve a realistic representation of the environment in the context. Results from a first user study indicate that visual abstraction of trajectories improves the ability to follow a story and is also appreciated by users. Lens effects increased the perceived amount of molecular motion in the environment while trading off traceability of individual molecules. © 2015 IEEE.","I.3.7 [COMPUTER GRAPHICS]: Three-Dimensional Graphics and Realism - Animation; I.6.3 [SIMULATION AND MODELING]: Applications -","Abstracting; Animation; Computer graphics; Cytology; Lenses; Visualization; Biochemical process; Dynamic environments; I.3.7 [computer graphics]: three-dimensional graphics and realism - animations; Illustrative visualization; Molecular simulations; Molecular trajectories; Particle-based simulation; Simulation and modeling; Three dimensional computer graphics",2-s2.0-84942249205
"Anjyo K., Ochiai H.","Mathematical basics of motion and deformation in computer graphics",2015,"Synthesis Lectures on Computer Graphics and Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932637968&doi=10.2200%2fS00599ED1V01Y201409CGR017&partnerID=40&md5=0aaa3c22b752f70a90c08ab786336284","This synthesis lecture presents an intuitive introduction to the mathematics of motion and deformation in computer graphics. Starting with familiar concepts in graphics, such as Euler angles, quaternions, and affine transformations, we illustrate that a mathematical theory behind these concepts enables us to develop the techniques for efficient/effective creation of computer animation. This book, therefore, serves as a good guidepost to mathematics (differential geometry and Lie theory) for students of geometric modeling and animation in computer graphics. Experienced developers and researchers will also benefit from this book, since it gives a comprehensive overview of mathematical approaches that are particularly useful in character modeling, deformation, and animation. Copyright © 2014 by Morgan & Claypool. All rights reserved.","deformation; Lie algebra; Lie group; motion; quaternion","Algebra; Animation; Deformation; Geometry; Lie groups; Mathematical transformations; Affine transformations; Differential geometry; Lie Algebra; Mathematical approach; Mathematical theory; motion; Motion and deformations; quaternion; Computer graphics",2-s2.0-84932637968
"Liu Y., Yang X., Cao Y., Wang Z., Chen B., Zhang J., Zhang H.","Dehydration of core/shell fruits",2015,"Computers and Graphics (Pergamon)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920084557&doi=10.1016%2fj.cag.2014.11.003&partnerID=40&md5=03af39119b26a544da298fc0b3b60be5","Dehydrated core/shell fruits, such as jujubes, raisins and plums, show very complex buckles and wrinkles on their exocarp. It is a challenging task to model such complicated patterns and their evolution in a virtual environment even for professional animators. This paper presents a unified physically-based approach to simulate the morphological transformation for the core/shell fruits in the dehydration process. A finite element method (FEM), which is based on the multiplicative decomposition of the deformation gradient into an elastic part and a dehydrated part, is adopted to model the morphological evolution. In the method, the dehydration pattern can be conveniently controlled through physically prescribed parameters according to the geometry and material of the real fruits. The effects of the parameters on the final dehydrated surface patterns are investigated and summarized in detail. Experiments on jujubes, wolfberries, raisins and plums are given, which demonstrate the efficacy of the method. © 2014 The Authors. Published by Elsevier Ltd.","Buckling and wrinkling; Computer animation; Core/shell fruits; Dehydration; Morphological transformation","Animation; Dehydration; Fruits; Virtual reality; Computer animation; Core/shell; Deformation gradients; Dehydration process; Morphological evolution; Morphological transformations; Multiplicative decomposition; Physically based; Finite element method",2-s2.0-84920084557
"Wang S., Zhang X., Xiao Q., Liang X.","Method and applications of 3D deformation based on tetrahedron coordinate system",2015,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926292962&partnerID=40&md5=fca28605616cff3277978d9e5949a47f","In order to control the deformation of model directly and accurately, a method based on self-defined tetrahedron coordinate system is proposed for 3D deformation. Firstly, the definition of the tetrahedron coordinate system is given, and some theorems are discussed, which can be applied in 3D deformation and 3D morphing and make topological transformation easy. Secondly, the details of two 3D deformation algorithms are presented: embedded deformation and precise deformation based on features. The experimental results obtained show that the proposed method is effective for 3D deformation and 3D morphing. ©, 2015, Institute of Computing Technology. All right reserved.","3D deformation; 3D morphing; Computer animation; Geometric transformation; Tetrahedron coordinate system","Animation; Computational mechanics; Geometry; Mathematical transformations; 3-D deformation; 3D morphing; Co-ordinate system; Computer animation; Geometric transformations; Deformation",2-s2.0-84926292962
"Huang Z., Han L., Gong G.","A local adaptive Catmull-Rom to reduce numerical dissipation of semi-Lagrangian advection",2015,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927804634&doi=10.1002%2fcav.1559&partnerID=40&md5=2c40b7cddbe2bd05afe7e3a456fce0de","We propose an adaptive Catmull-Rom interpolation to improve accuracy of semi-Lagrangian advection for smoke simulation. Original Catmull-Rom improves numerical accuracy but overshoot violates global stability. Monotonic Catmull-Rom is unconditionally stable, whereas it sweeps out detail features due to overly suppression operations. Our method modifies original Catmull-Rom to obtain second-order accuracy and unconditional stability. It flattens locations where interpolations might break through global bounds but maintains local overshoots to conserve diversity of fluid flow. The scheme is easy to collaborate with existing fluid simulators to improve small features. Copyright © 2013 John Wiley & Sons, Ltd.","computer animation; fluid simulation; interpolation; numerical dissipation; semi-Lagrangian advection","Advection; Animation; Interpolation; Lagrange multipliers; Computer animation; Fluid simulations; Numerical accuracy; Numerical dissipation; Second-order accuracy; Semi-Lagrangian advections; Unconditional stability; Unconditionally stable; Flow of fluids",2-s2.0-84927804634
"Förger K., Takala T.","A motion style toolbox",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943623705&doi=10.1007%2f978-3-319-21996-7_36&partnerID=40&md5=7194cc8851c4a5eca856e55036f3fdc9","We present a Matlab toolbox for synthesis and visualization of human motion style. The aim is to support development of expressive virtual characters by providing implementations of several style related motion synthesis methods thus allowing side-by-side comparisons. The implemented methods are based on recorded (captured or synthetic) motions, and include linear motion interpolation and extrapolation, style transfer, rotation swapping per body part and per quaternion channel, frequency band scaling and swapping, and Principal/Independent Component Analysis (PCA/ICA) based synthesis and component swapping. © Springer International Publishing Switzerland 2015.","Computer animation; Human motion; Motion style; Motion synthesis; Toolbox","Animation; Frequency bands; Principal component analysis; Synthesis (chemical); Computer animation; Human motions; Motion styles; Motion synthesis; Toolbox; Intelligent virtual agents",2-s2.0-84943623705
"Alkawaz M.H., Mohamad D., Basori A.H., Saba T.","Blend Shape Interpolation and FACS for Realistic Avatar",2015,"3D Research",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921978049&doi=10.1007%2fs13319-015-0038-7&partnerID=40&md5=c5e87620dec49f175ca34863f18bc55e","Abstract: The quest of developing realistic facial animation is ever-growing. The emergence of sophisticated algorithms, new graphical user interfaces, laser scans and advanced 3D tools imparted further impetus towards the rapid advancement of complex virtual human facial model. Face-to-face communication being the most natural way of human interaction, the facial animation systems became more attractive in the information technology era for sundry applications. The production of computer-animated movies using synthetic actors are still challenging issues. Proposed facial expression carries the signature of happiness, sadness, angry or cheerful, etc. The mood of a particular person in the midst of a large group can immediately be identified via very subtle changes in facial expressions. Facial expressions being very complex as well as important nonverbal communication channel are tricky to synthesize realistically using computer graphics. Computer synthesis of practical facial expressions must deal with the geometric representation of the human face and the control of the facial animation. We developed a new approach by integrating blend shape interpolation (BSI) and facial action coding system (FACS) to create a realistic and expressive computer facial animation design. The BSI is used to generate the natural face while the FACS is employed to reflect the exact facial muscle movements for four basic natural emotional expressions such as angry, happy, sad and fear with high fidelity. The results in perceiving the realistic facial expression for virtual human emotions based on facial skin color and texture may contribute towards the development of virtual reality and game environment of computer aided graphics animation systems.Graphical Abstract: Realistic facial expressions of avatar. © 2015, 3D Research Center, Kwangwoon University and Springer-Verlag Berlin Heidelberg.","3D modelling; Blend shape; Facial action coding; Facial animation; Facial expression; Texturing","Algorithms; Animation; Bayesian networks; Color computer graphics; Computer games; Computer graphics; Face recognition; Gesture recognition; Graphical user interfaces; Interpolation; Texturing; Three dimensional computer graphics; User interfaces; Virtual reality; 3D modelling; Face-to-face communications; Facial action coding; Facial Action Coding System; Facial animation; Facial Expressions; Geometric representation; Non-verbal communications; Computer keyboards",2-s2.0-84921978049
"Summan R., Pierce S.G., Macleod C.N., Dobie G., Gears T., Lester W., Pritchett P., Smyth P.","Spatial calibration of large volume photogrammetry based metrology systems",2015,"Measurement: Journal of the International Measurement Confederation",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924993963&doi=10.1016%2fj.measurement.2015.02.054&partnerID=40&md5=8a5ef4db25924dbc5000ff6bb947f4dd","Photogrammetry systems are used extensively as volumetric measurement tools in a diverse range of applications including gait analysis, robotics and computer generated animation. For precision applications the spatial inaccuracies of these systems are of interest. In this paper, an experimental characterisation of a six camera Vicon T160 photogrammetry system using a high accuracy laser tracker is presented. The study was motivated by empirical observations of the accuracy of the photogrammetry system varying as a function of location within a measurement volume of approximately 100 m3. Error quantification was implemented through simultaneously tracking a target scanned through a sub-volume (27 m3) using both systems. The position of the target was measured at each point of a grid in four planes at different heights. In addition, the effect of the use of passive and active calibration artefacts upon system accuracy was investigated. A convex surface was obtained when considering error as a function of position for a fixed height setting confirming the empirical observations when using either calibration artefact. Average errors of 1.48 mm and 3.95 mm were obtained for the active and passive calibration artefacts respectively. However, it was found that through estimating and applying an unknown scale factor relating measurements, the overall accuracy could be improved with average errors reducing to 0.51 mm and 0.59 mm for the active and passive datasets respectively. The precision in the measurements was found to be less than 10 μm for each axis. © 2015 Elsevier Ltd.All rights reserved.","Accuracy study; Calibration; Laser tracker; Photogrammetry","Animation; Errors; Photogrammetry; Target tracking; Accuracy study; Active calibrations; Computer-generated animations; Error quantification; Laser tracker; Precision applications; Spatial calibration; Volumetric measurement; Calibration",2-s2.0-84924993963
"Ruby A.J., Aisha B.W., Subash C.P.","Rendering-as-a-Service: Taxonomy and comparison",2015,"Procedia Computer Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937400174&doi=10.1016%2fj.procs.2015.04.048&partnerID=40&md5=154d53ec778d37c35ba4370286484fdb","The movies like the ""Avathar"" are a good example of the stunning visual effects that the animation could bring into a movie. The 3D wireframe models are converted to 3D photorealistic images using a process called the rendering. This rendering process is offered as a service in the cloud, where the animation files to be rendered are split into frames and rendered in the cloud resources and are popularly known as Rendering-as-a-Service (RaaS). As this is gaining high popularity among the animators community, this work intends to enable the animators to: (a) Gain basic knowledge about Rendering-as-a-Service (RaaS). (b) Understand the variety in the RaaS service models through the taxonomy (c) Explore, compare and classify the RaaS services quickly using the tree-structured taxonomy of services. In this paper, the various characteristics of the RaaS services are organized in the form of a tree to enable quick classification and comparison of the RaaS services. To enhance the understandability, three popular RaaS services have been classified and verified according to the proposed tree-structured taxonomy. © 2015 The Authors. Published by Elsevier B.V.","3D animation; Cloud computing; Rendering; Rendering-as-a-service","Animation; Big data; Cloud computing; Forestry; Taxonomies; Three dimensional computer graphics; 3D animation; Animation files; Photorealistic images; Rendering; Rendering process; Rendering-as-a-service; Tree-structured; Understandability; Rendering (computer graphics); Computation; Images; Models; Three Dimensional Design",2-s2.0-84937400174
"Rathinavelu A., Saranya K.","Computer-aided animated gesture-driven facial model with speech synthesis",2015,"International Journal on Disability and Human Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922530159&doi=10.1515%2fijdhd-2013-0029&partnerID=40&md5=4af028016eb8cffb1c6d3da6415bf235","The aim of this study was to develop a gesture-driven facial model with speech synthesis capability. A two-dimensional facial Model was developed and animated based on the Facial Action Coding System. Such emotions as ""happy"", ""sad"", ""anger"", and ""fear"" were simulated and visualized through the combination of eight action units. A speech synthesizer for the Tamil language was built using a syllable-based concatenation approach. The results indicated that the synthetic speech had an average accuracy rate ranging from 85% to 90% as natural as the human speech. Moreover, 75%-85% of the words were articulated well and identified by the children correctly. The ultimate goal of the system is to assist children with vocal and hearing disabilities in their language learning process. © 2015 by De Gruyter.","Audio visual speech synthesis (AV-TTS); concatenative speech synthesis; facial action coding system (FACS); gesture driven facial animation (GDFA); hearing impairment (HI)","anger; Article; association; computer aided animated gesture; computer aided design; facial expression; fear; gesture; hearing; human; intelligence; perception; speech; speech therapy; teleconference; verbal communication; visual information; voice",2-s2.0-84922530159
"Alkawaz M.H., Mohamad D., Basori A.H., Mohamed F.","A crucial investigation of facial skin colour research trend and direction",2015,"International Journal of Multimedia and Ubiquitous Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922996980&doi=10.14257%2fijmue.2015.10.1.29&partnerID=40&md5=c77e2f9985c799f4d23d853b9cf9dd04","The research on facial animation is growing and became more sensible in terms of three dimensional data. The emergence of laser scans and advanced 3D tools imparted further towards the rapid development of complex facial model. This paper has given an overview on facial animation techniques such as blend shape interpolation, facial action coding system and parameterization. The major challenges, excitement, applications, recent progress and the future of various diversified facial animation methods are high-lighted as well. The emotional theory, involving the cognition as one of the elements of emotion and emphasizing on somatic factors describing emotional expressions and its perception as the other elements are presented. The essential factors responsible for emo-tional colors manifestations to an individual are the key issues. The notable theories and models of Goethe, Claudia Cortes, Naz Kaya, Color Wheel Pro, Shirley Willet and Yau Xueon facial colors expressions are critically commented and a facile comparison is car-ried out. Furthermore, a detailed discussions on facial colors appearance are provided using image based skin color analysis and synthesis, reflectance based model, bidirec-tional texture function, physiology measurement based and emotional appearance mod-els. The paper completed with the remarkable features official expression comprised of facial action coding system and MPEG-4 facial animation that enable considerable im-provement on facial animation technology. Our in-depth appraisal on facial animation may contribute as taxonomy towards the development of human facial skin colors on 3D avatar including facial action coding system, emotion theory, color theory, animation via blending and image based color analysis useful for various applications. © 2015 SERSC.","Animation; Avatars; Computer graphics; Hemoglobin and melanin; Virtual reality","Animation; Behavioral research; Codes (symbols); Color; Computer graphics; Computer keyboards; Face recognition; Gesture recognition; Image coding; Motion Picture Experts Group standards; Signal encoding; Skin; Three dimensional computer graphics; Virtual reality; Avatars; Emotional expressions; Facial Action Coding System; Facial animation; Measurement-based; Shape interpolation; Skin color analysis; Three-dimensional data; Color computer graphics",2-s2.0-84922996980
"Teplá M., Klímová H.","Using Adobe Flash Animations of electron transport chain to teach and learn biochemistry",2015,"Biochemistry and Molecular Biology Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948715534&doi=10.1002%2fbmb.20867&partnerID=40&md5=80288a7104e1a95339d54c9c86097c31","Teaching the subject of the electron transport chain is one of the most challenging aspects of the chemistry curriculum at the high school level. This article presents an educational program called ""Electron Transport Chain"" which consists of 14 visual animations including a biochemistry quiz. The program was created in the Adobe Flash CS3 Professional animation program and is designed for high school chemistry students. Our goal is to develop educational materials that facilitate the comprehension of this complex subject through dynamic animations which show the course of the electron transport chain and simultaneously explain its nature. We record the process of the electron transport chain, including connections with oxidative phosphorylation, in such a way as to minimize the occurrence of discrepancies in interpretation. The educational program was evaluated in high schools through the administration of a questionnaire, which contained 12 opened-ended items and which required participants to evaluate the graphics of the animations, chemical content, student preferences, and its suitability for high school biochemistry teaching. © 2015 by the International Union of Biochemistry and Molecular Biology, 43(4):294-299, 2015.","Computers in research and teaching; High school; Using multimedia in the classroom; Using simulation and internet resources for teaching","audiovisual aid; biochemistry; comprehension; curriculum; education; electron transport; human; learning; procedures; student; teaching; Audiovisual Aids; Biochemistry; Comprehension; Computer-Assisted Instruction; Curriculum; Electron Transport; Humans; Learning; Students; Teaching",2-s2.0-84948715534
"Edgcomb A.D., Yuen J.S., Vahid F.","Does student crowdsourcing of practice questions and animations lead to good quality materials?",2015,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941992526&partnerID=40&md5=a1a562a1700dc11434b4e45180d19a0a","Web-native textbooks use practice questions and animations to improve student performance to help learn and visualize concepts. Creating practice questions and animations is time intensive. This paper investigates whether having students create and/or rate practice questions and animations - student crowdsourcing - can lead to good quality items. For animations, we conducted experiments involving 587 participants from a basic computing technology course. Students were asked to create animations of a topic, and a professor and fellow students rated those animations. Some students showed the ability to create quality animations: 2 of 19 completed animations were rated a ""5"" on a 1 to 5 scale (5 is best) by a professor / professional animation author. Furthermore, some students showed the ability to effectively rate student-created animations; the top 10% of student ratings was strongly correlated with the professor ratings with R-value = 0.88 (p-value < 0.001). For questions, we conducted experiments involving 25 participants from an introductory embedded programming course. Students were asked to create and rate practice questions for various embedded programming topics. Some students could effectively rate questions: the average of the top 20% of student ratings was strongly correlated with the professor rating with R-value = 0.82 (p-value = 0.02). However, students did not show the ability to create good question; no student's question was professor-rated above a 4. The common problem seen was an inability to write correct and precise English. © American Society for Engineering Education, 2015.","Authoring; Computer science; Crowdsourcing; Digital learning; Digitally-enhanced education; Interactive content; Online learning; Programming; Rating; Student-made content; Web-native content",,2-s2.0-84941992526
"Pandey N., Anwer E., Salam A., Pandey S., Gupta S.","3-D medical animation could be helpful tool for integration of medical curriculum",2015,"Medical Teacher",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919683242&doi=10.3109%2f0142159X.2014.940884&partnerID=40&md5=eb71c6b16d1ae071bf9acd17fb3b43ae",[No abstract available],,"computer interface; curriculum; human; medical education; procedures; teaching; Computer-Assisted Instruction; Curriculum; Education, Medical, Undergraduate; Humans; User-Computer Interface",2-s2.0-84919683242
"Pedra A., Mayer R.E., Albertin A.L.","Role of Interactivity in Learning from Engineering Animations",2015,"Applied Cognitive Psychology",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947489493&doi=10.1002%2facp.3137&partnerID=40&md5=6c82e41efca17acf48d042ac324bffcc","Summary: This study examines the pedagogic value of incorporating sophisticated interactivity features into lessons on hand-held devices. Engineering students (Experiment 1) and non-engineering college students (Experiment 2) spent 5min studying an animation showing a six-step maintenance procedure for a mechanical device called a Power Take-Off presented on an iPad. In both experiments, students who received high interactivity (i.e., rotation through dragging movements and zoom through pinching movements) reported higher interest but did not show better learning as compared to the low interactivity group (i.e., pause and continue buttons on the touch screen) or no interactivity group. Across two experiments, the interactivity hypothesis was supported in terms of increased interest but not supported in terms of improved learning. Thus, there was not support for the idea that increasing situational interest through high levels of interactivity primes deeper learning processes that produce better learning outcomes. Copyright © 2015 John Wiley & Sons, Ltd.",,"adult; Article; college student; computer graphics; educational technology; engineering; female; human; human computer interaction; human experiment; interactivity; learning; male; microcomputer; motivation; multimedia; normal human; priority journal",2-s2.0-84947489493
"Jantzen S.G., Jenkinson J., McGill G.","Transparency in film: Increasing credibility of scientific animation using citation",2015,"Nature Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926431151&doi=10.1038%2fnmeth.3334&partnerID=40&md5=5137b4fa8676aab07e09bad45b869dd1",[No abstract available],,"computer aided design; computer simulation; imaging; information; molecular dynamics; molecular model; Note; priority journal; audiovisual equipment; chemical structure; education; science; standards; trends; Models, Molecular; Motion Pictures as Topic; Science",2-s2.0-84926431151
"Li R., Yu J., Wang Z.","Collision Handling in 3D Articulatory Animation for Chinese Speech Articulation",2015,"IFAC-PapersOnLine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988473724&doi=10.1016%2fj.ifacol.2015.12.269&partnerID=40&md5=75c4526f805d29d59f239c858c19d1ac","The aim of this paper is to efficiently handle collisions that happened in the oral cavity. We proposed a collision handling method which includes two stages: collision detection stage for detecting collisions happened among the tongue vs: teeth and the tongue vs: palate; and collision response stage which is used to avoid a physically impossible situation. Here, the physically impossible situation indicates that the virtual tongue would penetrate the rest articulators in the oral cavity during its movements. The movements of the virtual tongue are driven by the data recorded by three electromagnetic articulography (EMA) sensors attached to a female Chinese speaker's tongue when the desired Chinese speech articulations are being articulated. Here, two Chinese speech articulations are used in our experiment to test our method: /ba/ and /t'a/. © 2015","biological systems; computer-aided simulation; detection algorithms; educational aids; Multimedia; physiological models","Bioinformatics; Biological systems; Collision detection; Collision handling; Collision response; Computer aided simulations; Detection algorithm; educational aids; Electromagnetic articulography; Multimedia; Physiological models",2-s2.0-84988473724
"Boukhalfi T., Desrosiers C., Paquette E.","A machine learning approach to automate facial expressions from physical activity",2015,"23rd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2015 - Full Papers Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962434640&partnerID=40&md5=f15f140a24f0a8f86e1e414159d3b04f","We propose a novel approach based on machine learning to simulate facial expressions related to physical activity. Because of the various factors they involve, such as psychological and biomechanical, facial expressions are complex to model. While facial performance capture provides the best results, it is costly and difficult to use for real-time interaction during intense physical activity. A number of methods exist to automate facial animation related to speech or emotion, but there are no methods to automate facial expressions related to physical activity. This leads to unrealistic 3D characters, especially when performing intense physical activity. This research highlights the link between physical activity and facial expression, and to propose a data-driven approach providing realistic facial expressions, while leaving creative control. First, biological, mechanical, and facial expression data are captured. This information is then used to train regression trees and support vector machine (SVM) models, which predict facial expressions of virtual characters from their 3D motion. The proposed approach can be used with real-time, pre-recorded or key-framed animations, making it suitable for video games and movies as well.","Biomechanics; Facial animation; Machine learning; Physical activity","Animation; Artificial intelligence; Biomechanics; Computer graphics; Learning systems; Support vector machines; Three dimensional computer graphics; Visualization; Data-driven approach; Facial animation; Facial expression data; Facial Expressions; Machine learning approaches; Performance capture; Physical activity; Real time interactions; Computer vision",2-s2.0-84962434640
"Nikolas I., Papapavlou C., Lalos A., Moustakas K.","Interactive visualization and analysis of eye biomechanics",2015,"Proceedings of the International Conferences on Interfaces and Human Computer Interaction 2015, IHCI 2015, Game and Entertainment Technologies 2015, GET 2015 and Computer Graphics, Visualization, Computer Vision and Image Processing 2015, CGVCVIP 2015 - Part of the Multi Conference on Computer Science and Information Systems 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969263264&partnerID=40&md5=f0c8d79a71afad471127aeb7a3e8968c","Modeling realistic eye movements is an active area of research and can provide useful information related to brain and neurological diseases. To facilitate the early diagnosis and management of those diseases, both computational models of eye movements and visualization tools that will allow users to interact with those models are required. Accurate models are useful for simulating realistic movements, while visualization tools allow the extraction of meaningful information from the dynamic simulation. Several works in the literature focus on the eye movement simulation completely ignoring the information visualization part. In the context of this work a novel visualization tool is proposed, that illustrates the interaction between the biomedical eye movements and the extra-ocular muscles activation levels. This tool can be used as a test bed to understand and study how different neurological commands have a direct impact on the biomedical eye motion trajectory.","Eye animation; Information visualization; Interaction; Physics-based simulation; Saccades","Animation; Computer games; Computer graphics; Computer vision; Diagnosis; Human computer interaction; Image processing; Information analysis; Information science; Information systems; Neurology; Visualization; Eye animation; Information visualization; Interaction; Interactive visualizations; Motion trajectories; Neurological disease; Novel visualizations; Physics-based Simulation; Eye movements",2-s2.0-84969263264
"Xian C., Li G., Xiong Y.","Efficient and effective cage generation by region decomposition",2015,"Computer Animation and Virtual Worlds",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927804400&doi=10.1002%2fcav.1571&partnerID=40&md5=cd8b37e9d2460a0d8e5805eaec7b0907","Cage-based deformation has become a popular method for shape deformation in computer graphics and animation. To edit a shape first requires a cage to be built to envelop the target model which is a tedious work by manual approaches. In this paper, we develop an automatic method to generate the cage for a model using voxelization based decomposition. We first voxelize the input model, and then use the seed filling algorithm to group the inner voxels. By dilating the inner voxel groups, we decompose the model into broad regions and narrow regions. Then we construct partial cages using different strategies and unite them to get a cage. Experiment results demonstrate that our method is effective, efficient as well as robust to model transformation. Copyright © 2014 John Wiley & Sons, Ltd.","cage generation; mesh deformation; region decomposition; voxelization","Animation; Computer graphics; Automatic method; Cage generations; Computer graphics and animations; Mesh deformation; Model transformation; Region decomposition; Shape deformation; Voxelization; Deformation",2-s2.0-84927804400
"Vo A., Ly N.Q.","Facial expression recognition using pyramid local phase quantization descriptor",2015,"Advances in Intelligent Systems and Computing",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910642301&doi=10.1007%2f978-3-319-11680-8_9&partnerID=40&md5=4116a382345eaa505ebb0af6f62e7e2c","Facial expression recognition is a challenging and interesting problem. It has many potential and important applications in data-driven animation, human computer interaction (HCI), social robots, deceit detection and behavior monitoring. In this paper, we present the novel descriptors Pyramid local phase quantization (PLPQ). The effective of our proposed descriptor is evaluated by facial expressions recognition very efficiently and with high accuracy. On the other hand, the proposed framework extracts texture features in a pyramidal fashion only from the perceptual salient region of the face thereby our proposed framework achieved reduction in computation time of feature extraction and improved accuracy. There with the proposed framework achieved accuracy of 96.7% on extended Cohn-Kanade (CK+) posed facial expression database for six basic emotions and exceed the state-of–theart methods for expression recognition using texture features. © Springer International Publishing Switzerland 2015.","Facial Expression Recognition; Local Phase Quantization; Salient Facial Region; Support Vector Machine","Animation; Feature extraction; Gesture recognition; Human computer interaction; Human robot interaction; Support vector machines; Systems engineering; Textures; Behavior monitoring; Data-driven animation; Expression recognition; Facial expression recognition; Facial expressions recognition; Facial regions; Human computer interaction (HCI); Local phase quantizations; Face recognition",2-s2.0-84910642301
"Ninomiya K., Kapadia M., Shoulson A., Garcia F., Badler N.","Planning approaches to constraint-aware navigation in dynamic environments",2015,"Computer Animation and Virtual Worlds",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927740865&doi=10.1002%2fcav.1622&partnerID=40&md5=4b605425754d2da41f1f69ee6d10337e","Path planning is a fundamental problem in many areas, ranging from robotics and artificial intelligence to computer graphics and animation. Although there is extensive literature for computing optimal, collision-free paths, there is relatively little work that explores the satisfaction of spatial constraints between objects and agents at the global navigation layer. This paper presents a planning framework that satisfies multiple spatial constraints imposed on the path. The type of constraints specified can include staying behind a building, walking along walls, or avoiding the line of sight of patrolling agents. We introduce two hybrid environment representations that balance computational efficiency and search space density to provide a minimal, yet sufficient, discretization of the search graph for constraint-aware navigation. An extended anytime dynamic planner is used to compute constraint-aware paths, while efficiently repairing solutions to account for varying dynamic constraints or an updating world model. We demonstrate the benefits of our method on challenging navigation problems in complex environments for dynamic agents using combinations of hard and soft, attracting and repelling constraints, defined by both static obstacles and moving obstacles. Copyright © 2014 John Wiley & Sons, Ltd.","anytime dynamic planning; navigation; path planning; potential fields; spatial constraints","Animation; Artificial intelligence; Collision avoidance; Computational efficiency; Computer graphics; Motion planning; Navigation; Repair; Robots; Collision-free paths; Complex environments; Computer graphics and animations; Dynamic environments; Dynamic planning; Environment representations; Potential field; Spatial constraints; Robot programming",2-s2.0-84927740865
"Bozkurt E., Khaki H., Kececi S., Türker B.B., Yemez Y., Erzin E.","JESTKOD database: Dyadic interaction analysis [JESTKOD Veritabani: Ikili Iletişim Analizi]",2015,"2015 23rd Signal Processing and Communications Applications Conference, SIU 2015 - Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939193639&doi=10.1109%2fSIU.2015.7130097&partnerID=40&md5=6914b646b39b393539852b288a004da6","In the nature of human-to-human communication, gesture and speech co-exist in time with a tight synchrony. We tend to use gestures to complement or to emphasize speech. In this study we present the JESTKOD database, which will be a valuable asset to examine gesture and speech in defining more natural human-computer interaction systems. This JESTKOD database consists of speech and motion capture data recordings of dyadic interactions under friendly and unfriendly interaction scenarios. In this paper we present our multimodal data collection process as well as the early experimental studies on friendly/unfriendly classification of dyadic interactions using body gesture and speech data. © 2015 IEEE.","affective state tracking; Gesticulation; human-computer interaction; speech; virtual character animation","Animation; Database systems; Signal processing; Speech; Speech communication; Virtual reality; Affective state; Dyadic interaction; Gesticulation; Human communications; Motion capture data; Multi-modal data; Natural human computer interactions; Virtual character; Human computer interaction",2-s2.0-84939193639
"Zheng Z., Zhang H.","Highly parallel crowd simulation using speed field",2015,"ICALIP 2014 - 2014 International Conference on Audio, Language and Image Processing, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922564148&doi=10.1109%2fICALIP.2014.7009762&partnerID=40&md5=5547f871942bcc4896422dbef8f56e6f","We present a novel approach for simulating large-scale crowds. Speed field together with potential field are used for global navigation. Also a hardware instancing method with two streams is proposed for rendering crowd animation. In practice, when computation and rendering are mainly performed on GPU, the proposed approach can demonstrate smooth flow under variety conditions, and thousands of agents can be exhibited at interactive rates. © 2014 IEEE.","GPU acceleration; hardware instancing; soft collision; speed field","Animation; Computer hardware description languages; Hardware; Image processing; Crowd animation; Crowd Simulation; Global navigation; GPU accelerations; Highly parallels; Interactive rates; Potential field; soft collision; Rendering (computer graphics)",2-s2.0-84922564148
"Peng X.B., Berseth G., Van De Panne M.","Dynamic terrain traversal skills using reinforcement learning",2015,"ACM Transactions on Graphics",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947230189&doi=10.1145%2f2766910&partnerID=40&md5=9564e66b823aae5874afa5beee4b1358","The locomotion skills developed for physics-based characters most often target flat terrain. However, much of their potential lies with the creation of dynamic, momentum-based motions across more complex terrains. In this paper, we learn controllers that allow simulated characters to traverse terrains with gaps, steps, and walls using highly dynamic gaits. This is achieved using reinforcement learning, with careful attention given to the action representation, non-parametric approximation of both the value function and the policy; epsilon-greedy exploration; and the learning of a good state distance metric. The methods enable a 21-link planar dog and a 7-link planar biped to navigate challenging sequences of terrain using bounding and running gaits. We evaluate the impact of the key features of our skill learning pipeline on the resulting performance. Copyright 2015 ACM.","Computer animation; Physics simulation",,2-s2.0-84947230189
"Kätsyri J., Förger K., Mäkäräinen M., Takala T.","A review of empirical evidence on different uncanny valley hypotheses: Support for perceptual mismatch as one road to the valley of eeriness",2015,"Frontiers in Psychology",30,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926671218&doi=10.3389%2ffpsyg.2015.00390&partnerID=40&md5=94ee18ea91de391de1e38537540fd00e","The uncanny valley hypothesis, proposed already in the 1970s, suggests that almost but not fully humanlike artificial characters will trigger a profound sense of unease. This hypothesis has become widely acknowledged both in the popular media and scientific research. Surprisingly, empirical evidence for the hypothesis has remained inconsistent. In the present article, we reinterpret the original uncanny valley hypothesis and review empirical evidence for different theoretically motivated uncanny valley hypotheses. The uncanny valley could be understood as the naïve claim that any kind of human-likeness manipulation will lead to experienced negative affinity at close-to-realistic levels. More recent hypotheses have suggested that the uncanny valley would be caused by artificial-human categorization difficulty or by a perceptual mismatch between artificial and human features. Original formulation also suggested that movement would modulate the uncanny valley. The reviewed empirical literature failed to provide consistent support for the naïve uncanny valley hypothesis or the modulatory effects of movement. Results on the categorization difficulty hypothesis were still too scarce to allow drawing firm conclusions. In contrast, good support was found for the perceptual mismatch hypothesis. Taken together, the present review findings suggest that the uncanny valley exists only under specific conditions. More research is still needed to pinpoint the exact conditions under which the uncanny valley phenomenon manifests itself. © 2015 Kätsyri, Förger, Mäkäräinen and Takala.","Anthropomorphism; Categorical perception; Computer animation; Human-likeness; Perceptual mismatch; Uncanny valley",,2-s2.0-84926671218
"Mukhina K., Bezgodov A.","The Method for Real-time Cloud Rendering",2015,"Procedia Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962706980&doi=10.1016%2fj.procs.2015.11.079&partnerID=40&md5=8a3581e88458115a5abc213e3d6a5c82","Modeling of realistic clouds always was one of the most important problems in creating any virtual scenes outside. It has always been an extremely valuable feature for great variety of applications: from flight simulators or meteorological software to computer games especially with an open world. In this work the algorithm of rendering flat clouds in real-time is presented. The hemispherical grid was designed to fill natural placement of clouds. Tools for high-quality visualization of stratocumulus clouds were created. The model of light scattering through clouds is described. This approach allows rendering realistic clouds evolving through time at high frame rates. © 2015 The Authors.","cloud animation; cloud modeling; cloud rendering; light scattering; real-time rendering","Animation; Application programs; Computer games; Flight simulators; Light scattering; Cloud modeling; Cloud rendering; High frame rate; High quality; Open world; Real-time rendering; Stratocumulus clouds; Virtual scenes; Rendering (computer graphics)",2-s2.0-84962706980
"Brom C., Děchtěrenko F.","Mathematical self-efficacy as a determinant of successful learning of mental models from computerized materials",2015,"Proceedings of the European Conference on Games-based Learning",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961069677&partnerID=40&md5=077cb16002fe3c8d5ec3da74679a38a7","Computerized animations, simulations and games are useful tools for supporting acquisition of mental models. Various personal characteristics, such as prior knowledge and spatial abilities, can influence, in various ways, effectivity of learning from these materials. In comparative studies with between-subject design that investigate learning effects of these materials, it is important to control for these variables because they should be taken as covariates in case the two (or more) research groups are not sampled equally (which happens even in the case of random assignment of participants to the research groups). In addition, it would be useful to have interventions that measure these variables with as few items as possible; to avoid unbearably long questionnaires. In this initial exploratory study we investigate if mathematical selfefficacy, measured by a single question, and self-assessed ability of acquiring mental models (SAAMM), also measured by a single question, predicts learning outcomes; as concerns mental models acquisition. Re-analyzing data from our four recent studies on one of the well-known principles of multimedia learning, personalization principle (N = 75, 85, 76, 41; college students with diverse background), we show that mathematical self-efficacy and SAAMM are moderately correlated (r = .32 - .40) and indeed related to learning outcomes, measured by transfer tests (r = .22 - .57 and .28 - .48, respectively). However, the reasons behind these relationships seem to be complex and diverse, and at least partly dependent on treatments' characteristics. For a complex simulation using graphs and resembling an educational computer game, this relationship can be, to a large extent, explained by mutual relationships between graphing skills, frequency of game-playing, mathematical self-efficacy, SAAMM, and learning outcomes. For a short animation on an electrophysical topic, it can be explained by mutual links between prior electrophysical knowledge, mathematical self-efficacy, SAAMM, and learning outcomes. Only for a short animation on a math/physics-unrelated topic, we could not explain the relationship between mathematical selfefficacy, SAAMM, and learning outcomes by a third variable (however, the graphing test was not administered in this case). In general, this study indicates that our two questions for assessing mathematical self-efficacy and SAAMM are promising instruments for measuring variables that should be controlled for in studies on learning effects of computerized materials with between-subject design, but more research is needed to pin down details.","Animations; Learning outcomes; Mathematical self-efficacy; Mental models; Serious games; Simulations","Animation; Cognitive systems; Computer games; Students; Surveys; Learning outcome; Mental model; Self efficacy; Serious games; Simulations; Game theory",2-s2.0-84961069677
"Kabra S., Dua H., Kapoor A.","Development of e-learning based module for teaching practicals in electronics to science and engineering students in India",2015,"Proceedings of IEEE International Conference on Teaching, Assessment and Learning for Engineering: Learning for the Future Now, TALE 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928243631&doi=10.1109%2fTALE.2014.7062613&partnerID=40&md5=71c01076e419b7ed2d28a9986333de04","The paper contains the description of entire process of development of e-learning module including animations, videos and power point presentations of various devices used in electronics practical laboratories by science and engineering students in India. In this work, we have focused on using multimedia technology as an innovative teaching and learning strategy in a problem-based learning environment. The work presented in this paper shows the use of e-learning based approach to make learning of electronics practical more effective and interesting. © 2014 IEEE.","animations; e-learning; electronics; multimedia","Animation; Computer aided instruction; Electronic equipment; Engineering education; Multimedia systems; E-learning modules; Innovative teaching; multimedia; Multimedia technologies; Power Point presentations; Problem based learning; Science and engineering; E-learning",2-s2.0-84928243631
"Humienny Z., Berta M.","Using animations to support the understanding of geometrical tolerancing concepts",2015,"Technisches Messen",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942424103&doi=10.1515%2fteme-2015-0048&partnerID=40&md5=4cd56d52dfc9237d26e7b27d76900516","A new concept of teaching and training the ISO GPS system fundamental and advanced principles with use of computer simulations, as well as animations at a very large extend is shown. The innovative application Geometrical Tolerancing structure, main components and key capabilities are demonstrated and discussed through a few screen shoots. It is indicated that application is suitable for open distance learning. The short analysis of the educational theories and other approaches that were considered to form background of the application are also given. © 2015 Walter de Gruyter Berlin/Boston 2015.","E-Learning; Geometrische Tolerierung; GPS (Geometrische Produktspezifikation); ISO 1101; Toleranzangaben","E-learning; Educational theory; Geometrische Tolerierung; Gps systems; ISO 1101; Open distance learning; Tolerancing; Toleranzangaben; Distance education",2-s2.0-84942424103
"Boujut H., Ourir M., Zaharia T.","A fully automatic framework for building 3D animated avatars",2015,"IEEE International Conference on Consumer Electronics - Berlin, ICCE-Berlin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937931357&doi=10.1109%2fICCE-Berlin.2014.7034312&partnerID=40&md5=eb95d6dfdc2a20a035e28d415cf13e15","The face animation process still requires an important amount of manual human interaction involving highly qualified artists with strong knowledge in facial anatomy. In this paper, we introduce a framework for automatic construction of 3D animated avatars. The proposed approach allows for animating an inanimate facial 3D mesh. The adopted representation is based on the MPEG-4 standard. First, the Supervised Descent Method (SDM) is employed for detecting automatically the MPEG-4 feature points starting from 2D images consisting of projections of 3D avatars. The originality of the approach consists of the training procedure proposed. Thus, we specifically train a SDM detector for each part of the face, i.e. mouth, eyes, nose, chin, cheeks, etc. Skinning operations are performed by jointly using the MPEG-4 FAPs and the feature point based deformation method. The combination of these three methods allows for building animated avatar with a large variety of shapes, i.e. from realistic human faces to cartoons. © 2014 IEEE.","3D avatar animation; MPEG-4 FAPs; SIFT; Supervised Descent Method","Animation; Consumer electronics; Feature extraction; Motion Picture Experts Group standards; 3D avatar animation; Automatic construction; Descent method; Human interactions; MPEG-4 FAPs; MPEG-4 standard; SIFT; Training procedures; Three dimensional computer graphics",2-s2.0-84937931357
"Raman R., Haridas M., Nedungadi P.","Blending concept maps with online labs for STEM learning",2015,"Advances in Intelligent Systems and Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921341717&doi=10.1007%2f978-3-319-11218-3_14&partnerID=40&md5=c04540735eca8ceb29f36e7fe5494155","In this paper we describe the architecture of an e-learning environment that blends concept maps with Online Labs (OLabs) to enhance student performance in biology. In the Indian context, a secondary school student’s conceptual understanding of hard topics in biology is at risk because of a lack of qualified teachers and necessary equipments in labs to conduct experiments. Concept map provides a visual framework which allows students to get an overview of a concept, its various sub concepts and their relationships and linkages. OLabs with its animations, videos and simulations is an interactive, immersive approach for practicing science experiments. The blended e-learning environment was tested by systematically developing a concept map for the concept “Photosynthesis” and by successfully integrating it into the OLabs environment. Our blended approach to concept understanding has interesting implications for the teacher who is engaged in training programs. © Springer International Publishing Switzerland 2015.","Animations; Biology; Concept map; OLabs; Online labs; Photosynthesis; Simulations; Virtual labs","Animation; Biology; Blending; Computer aided instruction; E-learning; Education; Personnel training; Photosynthesis; Social networking (online); Students; Teaching; Concept maps; OLabs; Online labs; Simulations; Virtual lab; Laboratories",2-s2.0-84921341717
"Raghuraman S., Bahirat K., Prabhakaran B.","Evaluating the efficacy of RGB-D cameras for surveillance",2015,"Proceedings - IEEE International Conference on Multimedia and Expo",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946045367&doi=10.1109%2fICME.2015.7177415&partnerID=40&md5=4362da4dbc9fa7b59af3000bca37b599","RGB-D cameras have enabled real-time 3D video processing for numerous computer vision applications, especially for surveillance type applications. In this paper, we first present a real-time anti-forensic 3D object stream manipulation framework to capture and manipulate live RBG-D data streams to create realistic images/videos showing individuals performing activities they did not actually do. The framework uses computer vision and graphics methods to render photorealistic animations of live mesh models captured using the camera. Next, we conducted a visual inspection of the manipulated RGB-D streams (just like security personnel would do) by users who are computer vision and graphics scientists. The study shows that it was significantly difficult to distinguish between the real or reconstructed rendering of such 3D video sequences, thus clearly showing the potential security risk involved. Finally, we investigate the efficacy of forensic approaches for detecting such manipulations. © 2015 IEEE.","3D animation; anti-forensic; image rendering; RGB-D forgery; security","Cameras; Computer graphics; Computer hardware description languages; Computer vision; Rendering (computer graphics); Security systems; Video signal processing; 3D animation; Anti-Forensics; Image rendering; RGB-D forgery; security; Three dimensional computer graphics",2-s2.0-84946045367
"Lowe R.","Perceptual learning in the comprehension of animations and animated diagrams",2015,"The Cambridge Handbook of Applied Perception Research",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954306124&doi=10.1017%2fCBO9780511973017.042&partnerID=40&md5=81d648f3bbfe8f044c504f399b915e8b","Introduction Animations are increasingly used to present complex information in technical and educational settings. One reason for the rising popularity of these representations has been advancing technology that has greatly facilitated the authoring, presentation, and dissemination of animated displays. Another reason is the widespread assumption that animations are an intrinsically effective way of presenting information, especially subject matter in which dynamics play an important role. However, findings from recent research have cast doubt on the assumed universal effectiveness of animations. Much of this research has been conducted in the field of education, where there is a growing reliance on the use of animations in multimedia learning materials (Höffler and Leutner, 2007). Too often, the effectiveness of animations as tools for explanation has fallen well short of educators’ expectations. It is becoming clear that some of the shortcomings of explanatory animations originate in the perceptual challenges they can pose to learner processing. This chapter examines evidence for the importance of perception in the processing of animations with a particular focus on the methodologies used to produce that evidence. Animations in Real-World Contexts Dynamic graphic displays have become a routine way of presenting information in a wide variety of workplaces. Rather than dealing with information only in its original numerical form, it is now common practice to convert it into graphic displays to provide new affordances that can foster understanding of how information changes over time. The sophisticated visualisation opportunities offered by today’s powerful graphics-oriented computers allow real-time monitoring of such changes as well as retrospective analysis of historical data for predictive purposes. One example of using dynamic graphic displays for “online” monitoring involves the displays used in industrial process control. In this application, animated diagrams are presented on computer screens to depict the events in an industrial plant as they are actually occurring. This allows plant operators to adjust the component production processes so that cost effectiveness can be maximised and safety hazards minimised. Another example is in meteorology, where weather centre staff rely on multiple visualisations of real-time data from various types of sensors to develop their warnings about potentially catastrophic weather events. © Cambridge University Press 2015.",,,2-s2.0-84954306124
"Starostenko O., Cortés X., Sánchez J.A., Alarcon-Aquino V.","Unobtrusive emotion sensing and interpretation in smart environment",2015,"Journal of Ambient Intelligence and Smart Environments",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921630780&doi=10.3233%2fAIS-140298&partnerID=40&md5=5394260c76af489b37c0aceb44ae289b","Currently, a particular focus of human centered technology is in expanding traditional contextual sensing and smart processing capabilities of ubiquitous systems exploiting user's affective and emotional states to develop more natural communication between computing artefacts and users. This paper presents a smart environment of Web services that has been developed to integrate and manage different existing and new emotion sensing applications, which working together provide tracking and recognition of human affective state in real time. In addition, two emotion interpreters based on the proposed 6-FACS and Distance models have been developed. Both models operate with encoded facial deformations described either in terms of Ekman's Action Units or Facial Animation Parameters of MPEG-4 standards. Fuzzy inference system based on reasoning model implemented in a knowledge base has been used for quantitative measurement and recognition of three-level intensity of basic and non-prototypical facial expressions. Designed frameworks integrated to smart environment have been tested in order to evaluate capability of the proposed models to extract and classify facial expressions providing precision of interpretation of basic emotions in range of 65-96% and non-prototypical emotions in range of 55-65%. The conducted tests confirm that such basic as non-prototypical expressions may be composed by other basic emotions establishing in this way the concordance between existing psychological models of emotions and Ekman's model traditionally used by affective computing applications. © 2015 - IOS Press and the authors. All rights reserved.","Affective computing applications; Facial expression recognition; Sensing basic and non-prototypical emotions","Animation; Fuzzy inference; Gesture recognition; Human computer interaction; Knowledge based systems; Motion Picture Experts Group standards; Ubiquitous computing; Web services; Affective Computing; Facial animation parameters; Facial expression recognition; Fuzzy inference systems; Natural communication; Processing capability; Quantitative measurement; Sensing basic and non-prototypical emotions; Face recognition",2-s2.0-84921630780
"Sun C.-C., Lo Y.-H., Wang G.-C.","The impact of applying interactive multimedia materials to English teaching practices on children’s learning of English—the case of K.C. English",2015,"Innovation in Design, Communication and Engineering - Proceedings of the 3rd International Conference on Innovation, Communication and Engineering, ICICE 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949757132&partnerID=40&md5=9d647fa2be20dedffb9271072b164bd7","In recent years, as multimedia interactive technologies are widely applied in education, the teacher’s role is also transformed from being an “initiator” to being a “mentor”. Using multimedia animation and games as learning media enhances the children’s learning interest and efficiency. It is not only restricted to a traditional fixed curriculum schedule but time can also be allocated in order to strengthen learning because practice can be repeatedly carried on parts that are not understood. These are the advantages of using interactive multimedia materials. This study investigates the effects of teaching English to children using interactive multimedia materials. Through the collection and analysis of relevant literature, the differences between traditional teaching and digital teaching were explored. Also investigated were the feasibility of implementing the application of interactive multimedia materials in teaching English to children, the impact on students of introducing game concept into such instructional materials, and the design principles of these materials. Through interview and observation, the methods and status of an after school learning center that uses its self-developed interactive multimedia materials in teaching was actually understood. This study found out that application of interactive multimedia materials can improve children’s concentration during English lessons, increase interaction with teachers, develop the students’ ability to express themselves, and enhance the students’ learning motivation and effect. © 2015 Taylor & Francis Group, London.","E-learning; Interactive games; Interactive multimedia materials; Multimedia","Animation; Curricula; E-learning; Education computing; Interactive computer systems; Multimedia systems; Students; Teaching; Design Principles; Instructional materials; Interactive games; Interactive multimedia; Interactive technology; Learning motivation; Multimedia; Multimedia animation; Education",2-s2.0-84949757132
"Adams R.J., Lichter M.D., Krepkovich E.T., Ellington A., White M., Diamond P.T.","Assessing Upper Extremity Motor Function in Practice of Virtual Activities of Daily Living",2015,"IEEE Transactions on Neural Systems and Rehabilitation Engineering",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924874257&doi=10.1109%2fTNSRE.2014.2360149&partnerID=40&md5=a653c034e8d674a52ca0a78aca2ce2a5","A study was conducted to investigate the criterion validity of measures of upper extremity (UE) motor function derived during practice of virtual activities of daily living (ADLs). Fourteen hemiparetic stroke patients employed a Virtual Occupational Therapy Assistant (VOTA), consisting of a high-fidelity virtual world and a Kinect™ sensor, in four sessions of approximately one hour in duration. An unscented Kalman Filter-based human motion tracking algorithm estimated UE joint kinematics in real-time during performance of virtual ADL activities, enabling both animation of the user's avatar and automated generation of metrics related to speed and smoothness of motion. These metrics, aggregated over discrete sub-task elements during performance of virtual ADLs, were compared to scores from an established assessment of UE motor performance, the Wolf Motor Function Test (WMFT). Spearman's rank correlation analysis indicates a moderate correlation between VOTA-derived metrics and the time-based WMFT assessments, supporting the criterion validity of VOTA measures as a means of tracking patient progress during an UE rehabilitation program that includes practice of virtual ADLs. © 2001-2011 IEEE.","Human computer interaction; human motion tracking; human motor performance; occupational therapy; patient rehabilitation; virtual reality","Animation; Human computer interaction; Interactive computer graphics; Medical computing; Occupational therapy; Patient rehabilitation; Patient treatment; Target tracking; Activities of Daily Living; Activities of daily living (ADLs); Human motion tracking; Human motor; Rehabilitation programs; Spearman's rank correlation analysis; Unscented Kalman Filter; Wolf motor function tests; Virtual reality; aged; ambulatory monitoring; arm; computer assisted diagnosis; computer interface; daily life activity; evaluation study; female; human; male; middle aged; movement (physiology); neurologic examination; paresis; pathophysiology; procedures; reproducibility; sensitivity and specificity; very elderly; Activities of Daily Living; Aged; Aged, 80 and over; Arm; Diagnosis, Computer-Assisted; Diagnostic Techniques, Neurological; Female; Humans; Male; Middle Aged; Monitoring, Ambulatory; Movement; Paresis; Reproducibility of Results; Sensitivity and Specificity; User-Computer Interface",2-s2.0-84924874257
"Wolfson T.S., Atesok K.I., Turhan C., Mabrey J.D., Egol K.A., Jazrawi L.M.","Animation and surgical simulation in orthopedic education",2015,"Sports Injuries: Prevention, Diagnosis, Treatment and Rehabilitation, Second Edition",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957035959&doi=10.1007%2f10.1007%2f978-3-642-36569-0_246&partnerID=40&md5=2fab0e5e88b291271747b9f1991e662f","The mastery of rapidly evolving orthopedic surgical techniques requires a long period of rigorous training. Recently implemented work-hour restrictions, mounting cost pressures, and patient safety concerns challenge trainees to acquire more complex surgical skills in a shorter amount of time. To meet these demands, educators have turned to alternative methods for surgical skills training outside of the operating room. These methods include hands-on training in specially designed surgical skills labs with cadavers, synthetic bones, anatomic models, or simulators. Computerized surgical simulators harness the power of advanced computer-generated imaging to render realistic medical animations for virtual reality training in a safe, controlled setting. There is a growing body of evidence supporting the educational advantages of surgical simulation in orthopedic skills training. However, questions remain regarding the validity and reliability of surgical simulation training in orthopedic surgery and if the skills acquired in the lab are transferrable to the operating room. Despite this, positive effects on the overall education of orthopedic residents, and on maintaining the proficiency of practicing orthopedic surgeons, are anticipated. © Springer-Verlag Berlin Heidelberg 2012, 2015, All Rights Reserved.",,,2-s2.0-84957035959
"Becker-Asano C., Riesterer N., Hué J., Nebel B.","Embodiment, emotion, and chess: A system description",2015,"AISB Convention 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938702179&partnerID=40&md5=f4f8f9f55b67532f3aeea34d287add36","We present a hybrid agent that combines robotic parts with 3D computer graphics to make playing chess against the computer more enjoyable. We built this multimodal autonomous robotic chess opponent under the assumption that the more life-like and physically present an agent is the more personal and potentially more effective the interaction will be. To maximize the life-likeness of the agent, a photo-realistic animation of a virtual agent's face is used to let the agent provide verbal and emotional feedback. For the latter an emotion simulation software module has been integrated to drive the agent's emotional facial expressions in parallel to its verbal utterances.",,"Computer graphics; Computer software; Robotics; Software agents; Three dimensional computer graphics; 3D computer graphics; Autonomous robotics; Emotion simulation; Emotional feedback; Facial Expressions; Hybrid agents; Photo-realistic animation; System description; Autonomous agents",2-s2.0-84938702179
"Nistor N., Trəuşan-Matu Ş., Dascəlu M., Duttweiler H., Chiru C., Baltes B., Smeaton G.","Finding student-centered open learning environments on the internet: Automated dialogue assessment in academic virtual communities of practice",2015,"Computers in Human Behavior",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027938230&doi=10.1016%2fj.chb.2014.07.029&partnerID=40&md5=febaa4ca801cba9658bcba8e71af58e1","Starting from the socio-constructivist concepts of (virtual) community of practice (vCoP) and internet-based argumentative open-ended learning environments, this study proposes and validates two tools for automated dialogue assessment, ReaderBench and Important Moments, developed on the ground of the polyphonic social knowledge building model. The analyzed corpus was the dialogue produced by an academic vCoP with N = 179 community members in 23 months, and consisting of 3685 interventions in 292 text-based discussion threads. The analysis results uncovered significant differences in the discussion threads produced by central and peripheral participants, such that central participants produced more interventions with higher collaborative dialogue quality, and the discussion threads they initiated were longer and involved a larger number of participants. Moreover, based on the automated analysis result, the vCoP participants could be classified in two clusters corresponding to the well-known core-periphery structure of CoPs. These findings are consistent with those revealed by other methods, and suggest that the employed tools are appropriate for identifying virtual communities that are appropriate as open-ended learning environments. Further research and development is needed to deepen quantitative vCoP models and test communication strategies recommended to students in vCoP-based argumentative open-ended learning environments. © 2014 Elsevier Ltd. All rights reserved.","Dialogue analysis; Inter-animation; Natural language processing; Open-ended learning environments; Polyphony; Virtual communities of practice","Animation; Automation; Internet; Knowledge acquisition; Natural language processing systems; Quality control; Virtual reality; Dialogue analysis; Learning environments; NAtural language processing; Polyphony; Virtual communities of practices; Computer aided instruction",2-s2.0-85027938230
"Zboinska M.A.","Hybrid CAD/E platform supporting exploratory architectural design",2015,"CAD Computer Aided Design",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907932197&doi=10.1016%2fj.cad.2014.08.029&partnerID=40&md5=69fc44db53fcaaa77ad1a39dc68c133d","Although computers prove useful in aiding human creativity, there is still shortage of adequate software for early-stage explorations in the design disciplines. One of such under-supported disciplines is architectural design. In response to this lack of proper software, architects adopted tools from other industries with a large level of success. However, despite the fact that several types of such tools have now been employed in conceptual architectural design, their application indicates that they are seldom used altogether. This paper presents a hybrid software platform, bringing these various CAD and CAE tools into one design toolkit. Each platform tool introduces a different possibility of designing, and supports computation-based activities, human intuitive ones, or a mixture of both. The platform user can freely switch between various working styles: algorithmic on the one hand, and fuzzy on the other. Moreover, the designer can perform tasks impossible to execute in traditional design, such as quick generation, exploration and evaluation of large design spaces, containing geometrically-complex solutions. The testing of the hybrid platform in a design experiment indicates its ability to support meaningful early-stage explorations and to yield a highly creative design. One of the aims of investigating a CAD/E platform based on the existing software is to lay the foundations for the development of a future CAD/E system for early-stage architectural design - a tool which is currently missing in the architectural practice. By revealing the potentials of the ready-made software, and by pointing out the technical challenges associated with its integration, we wish to suggest a possible direction for future studies, so that solutions developed by academia have higher chances of being noticed and more widely implemented in praxis. © 2014 Elsevier Ltd. All rights reserved.","Animation; CAD-CAE integration; Computer-aided conceptual design; Free-form modeling; Parametric modeling; Performance analysis and simulation","Ability testing; Animation; Architectural design; Computer aided analysis; Computer simulation; Computer software; Conceptual design; CAD-CAE integrations; Computer-aided; Free form modeling; Parametric modeling; Performance analysis and simulation; Computer aided design",2-s2.0-84907932197
"El Sayeh Khalil J., Saenen I., Lambert P., Van De Walle R.","Extreme asset simplification and the preservation of visual appearance",2015,"Proceedings of the International Conferences on Interfaces and Human Computer Interaction 2015, IHCI 2015, Game and Entertainment Technologies 2015, GET 2015 and Computer Graphics, Visualization, Computer Vision and Image Processing 2015, CGVCVIP 2015 - Part of the Multi Conference on Computer Science and Information Systems 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969211480&partnerID=40&md5=61388182903012c41f77f4bcfe3d7cce","Reusing animation film assets for real-time rendering requires extreme simplification. As well-known simplification approaches do not suffice, studios are still forced to manually simplify their assets. To automate this, we employ a pipeline for efficient geometry-based simplification and make use of normal mapping to ensure visual similarity. Our obtained results are promising: geometric complexity is vastly reduced while maintaining a recognizable model, unlike results with classical simplification approaches as employed by commercial applications. We have compared the approaches in two settings, aiming at a similar number of triangles and aiming at a similar storage size, both of which prove that our extreme asset simplification is a valid alternative for classical topological simplification approaches.","Appearance preservation; Asset simplification; Real-time rendering","Animation; Computer games; Computer graphics; Computer vision; Image processing; Information systems; Rendering (computer graphics); Visualization; Asset simplification; Commercial applications; Geometric complexity; Real-time rendering; Similar numbers; Topological simplification; Visual appearance; Visual similarity; Human computer interaction",2-s2.0-84969211480
"Fan Z., Liy H., Hilleslandz K., Shengx B.","Simulation and rendering for millions of grass blades",2015,"Proceedings of the 19th Symposium on Interactive 3D Graphics and Games, i3D 2015",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943261389&partnerID=40&md5=e579f79c1f9abc5e63522f7dc833d152","We provide detailed simulated response for individual blades of grass in fields of millions of blades. The field is divided into tiles whose blade data are instanced from a small patch of blades on the GPU to limit memory and bandwidth requirements. We only instantiate simulation state and compute simulation for tiles interacting with objects. The simulation does not stop immediately when objects leave the tile but with a smooth transition to the original GPU-instanced state. Grass motion is solved with collision, length, bending and twisting constraints. Global animation from wind is still handled through conventional, procedural methods in the vertex shader. Our method is also compatible with a rendering level-of-detail (LOD) system. With 128 objects moving in a field with over a million blades of grass, the frame rate is less than 20 ms, with only a few milliseconds of that time for simulation. Copyright © ACM 978.","GPU; Grass; Instancing; Simulation","Animation; Computer graphics; Computer graphics equipment; Interactive computer graphics; Three dimensional computer graphics; Bandwidth requirement; GPU; Grass; Instancing; Level of detail; Simulated response; Simulation; Smooth transitions; Rendering (computer graphics)",2-s2.0-84943261389
"Kakimzhanov Y., Kozhaev Z., Bektemirova S.","Technique of creation interactive visualization of 3d maps within the University Campus",2015,"International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946558500&partnerID=40&md5=8ef6fa0584c66697c634d630e3e3de2b","Using three-dimensional modeling in GIS include the materials in the form of vector maps, satellite images, photographs, three-dimensional models, diagrams, plans, diagrams, graphs, tables, databases, multimedia and text documents. A distinctive feature of system is based on web-technologies that can run on any computer from anywhere in the world via a standard web-browser (Internet Explorer, Mozilla Firefox, Google Chrome, etc.) and does not require installation on your computer, making the solution versatile, working on virtually at all operating systems and platforms (Glander et al.; 2012) and as noticed Jiann-Yeou Rau it also gives us 3-D virtual reality of environment through the internet. All information systems stored in a single database that allows many employees to work in real time with a single and up to date information. GIS based on 3-D modeling by fragmented computer animation used in Kazakhstan. Web application used on the territory of Al-Farabi Kazakh National University exists a universal 3-D virtual model that allows us not only to show the 3-dimensional visualization engineering constructions and also shows what is inside building to provide a complete and accurate visual information about the infrastructure of complicated technical object, nature monuments, etc. Modeling innovative and integrated 3-D model of the University territory by applying the geographic information systems (GIS). In addition to the above guidelines the experience of constructing and using the basic 3- D model of urban space, it is appropriate to use to enhance the accuracy and relevance of the model point of laser reflections from studies of airborne laser scanning. In this regard, the study of GIS using 3-D simulation gives the opportunity to work with spatial data that can give us more opportunity to multiple-scale strategy including block modeling, texture modeling and photo-realistic detailed modeling of research area. © SGEM2015.","3-D model; Computer modeling; Geographic information systems; GIS technology; Three-dimensional map; Virtual model","Aluminum; Animation; Computer operating systems; Engineering research; Geographic information systems; Information systems; Internet; Real time systems; Virtual reality; Visualization; Web browsers; World Wide Web; 3-d modeling; Computer modeling; GIS technology; Three-dimensional maps; Virtual modeling; Three dimensional computer graphics",2-s2.0-84946558500
"Ellis B.","What bronies see when they brohoof: Queering animation on the dark and evil Internet",2015,"Journal of American Folklore",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940942196&partnerID=40&md5=869ae3d8452befd3d711853b55fe23ee","After the cartoon series My Little Pony: Friendship Is Magic began airing in 2010, a network of adult fans, predominantly young males, formed an Internet-based vernacular culture in homage. Calling themselves ""bronies,"" this virtual community circulated ""photoshops,"" computer-generated visual humor, and discussed them online using an emic folk speech called ""bronyspeak"" This article examines several photoshops in the context of the discussions in which they emerged. Bronies, like earlier fan groups, poach elements from the original show, ""queer them"" in consciously transgressive ways, and use them to challenge prevailing attitudes toward gender and sexual orientation in graceful, yet disturbing ways. Copyright © 2015 by the Board of Trustees of the University of Illinois.","Folk art; Folk speech; Gender identity; Internet; Queer theory",,2-s2.0-84940942196
"Sigitov A., Scherfgen D., Hinkenjann A., Staadt O.","Adopting a Game Engine for Large, High-Resolution Displays",2015,"Procedia Computer Science",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964057123&doi=10.1016%2fj.procs.2015.12.246&partnerID=40&md5=ae16c037334a18b218a9a7d01ce51707","The steadily decreasing prices of display technologies and computer graphics hardware contribute to the increasing popularity of multiple-display environments, like large, high-resolution displays. It is therefore necessary that educational organizations give the new generation of computer scientists an opportunity to become familiar with this kind of technology. However, there is a lack of tools that allow for getting started easily. Existing frameworks and libraries that provide support for multi-display rendering are often complex in understanding, configuration and extension. This is critical especially in educational context where the time that students have for their projects is limited and quite short. These tools are also rather known and used in research communities only, thus providing less benefit for future non-scientists. In this work we present an extension for the Unity game engine. The extension allows - with a small overhead - for implementation of applications that are apt to run on both single-display and multi-display systems. It takes care of the most common issues in the context of distributed and multi-display rendering like frame, camera and animation synchronization, thus reducing and simplifying the first steps into the topic. In conjunction with Unity, which significantly simplifies the creation of different kinds of virtual environments, the extension affords students to build mock-up virtual reality applications for large, high-resolution displays, and to implement and evaluate new interaction techniques and metaphors and visualization concepts. Unity itself, in our experience, is very popular among computer graphics students and therefore familiar to most of them. It is also often employed in projects of both research institutions and commercial organizations; so learning it will provide students with qualification in high demand. © 2015 The Authors.","large-high-resolution displays; rapid prototyping tool; tools for education; Unity","Animation; Augmented reality; Computer graphics; Computer hardware; Display devices; Education; Rendering (computer graphics); Societies and institutions; Virtual reality; Computer graphics hardware; Display technologies; Educational organizations; High resolution display; Interaction techniques; Rapid prototyping tool; Research institutions; Unity; Students",2-s2.0-84964057123
"Iglesias A., Gálvez A.","Memetic electromagnetism algorithm for finite approximation with rational bézier curves",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947732314&doi=10.1007%2f978-3-319-20466-6_3&partnerID=40&md5=fd85cf884b028a4df815a6d56f358eb6","The problem of obtaining a discrete curve approximation to data points appears recurrently in several real-world fields, such as CAD/CAM (construction of car bodies, ship hulls, airplane fuselage), computer graphics and animation, medicine, and many others. Although polynomial blending functions are usually applied to solve this problem, some shapes cannot yet be adequately approximated by using this scheme. In this paper we address this issue by applying rational blending functions, particularly the rational Bernstein polynomials. Our methodology is based on a memetic approach combining a powerful metaheuristic method for global optimization (called the electromagnetism algorithm) with a local search method. The performance of our scheme is illustrated through its application to four examples of 2D and 3D synthetic shapes with very satisfactory results in all cases. © Springer International Publishing Switzerland 2015.",,"Algorithms; Approximation algorithms; Artificial intelligence; Blending; Computer aided design; Computer graphics; Global optimization; Hulls (ship); Optimization; Bernstein polynomial; Blending function; Computer graphics and animations; Electromagnetism algorithms; ITS applications; Local search method; Memetic approach; Meta-heuristic methods; Rational functions",2-s2.0-84947732314
"Iglesias A., Gálvez A., Collantes M.","Global-support rational curve method for data approximation with bat algorithm",2015,"IFIP Advances in Information and Communication Technology",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946091319&doi=10.1007%2f978-3-319-23868-5_14&partnerID=40&md5=b9f8e95d05bdb38c9c2b36de0bc5f793","The problem of obtaining an approximating curve from a given set of data points appears recurrently in several applied and industrial domains, such as CAD/CAM, computer graphics and animation, medicine, and many others. Although polynomial blending functions are usually applied to tackle this issue, some shapes cannot yet be adequately approximated by using the polynomial scheme. In this paper we address this limitation by applying rational global-support blending functions, particularly rational Bézier curves. Our method is based on a natureinspired meta-heuristic called bat algorithm, which has been recently introduced to solve difficult optimization problems. To check the performance of our approach, it has been applied to some illustrative examples of 2D and 3D curves. Our results show that the method performs very well, being able to yield a satisfactory approximating curve with a high degree of accuracy. © IFIP International Federation for Information Processing 2015.","Bat algorithm; Bézier curve; Data approximation; Metaheuristic technique; Rational curve","Algorithms; Approximation algorithms; Artificial intelligence; Blending; Computer aided design; Computer graphics; Heuristic methods; Optimization; Bat algorithms; Blending function; Computer graphics and animations; Data approximation; High degree of accuracy; Meta-heuristic techniques; Optimization problems; Rational curves; Rational functions",2-s2.0-84946091319
"Popkonstantinovic B., Jeli Z., Miladinovic L.J.","3D modeling and motion analysis of the Maltese cross (Geneva) mechanisms",2015,"2015 IFToMM World Congress Proceedings, IFToMM 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018976014&doi=10.6567%2fIFToMM.14TH.WC.OS5.009&partnerID=40&md5=976e3f46da476a8a86857e5963d4c66c","The paper presents a several 3D computer model of the Maltese cross (Geneva) mechanism. In purposes of examination Maltese cross mechanisms project contain three type of 3D computer model of the Maltese cross mechanism. The main goal of this project is improving present and acquiring new abilities and skills of solving a mechanical systems computer modeling problems. In addition, the project aims to present the importance of the strong co-relation between classical mechanical engineering and up to date modern methods of optimization and modeling using computer graphics which play a key role in the project. Finally, this project incorporates the motion, i.e. kinematical and dynamical analysis which is documented and presented by several movies.","3D computer model; Animation; Maltese cross mechanism; Simulation","Animation; Computer graphics; 3-D computer modeling; 3-d modeling; Computer modeling; Dynamical analysis; Maltese cross; Mechanical systems; Simulation; Motion analysis",2-s2.0-85018976014
"Yuan X.","An approach to integrating emotion in dialogue management",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947564310&doi=10.1007%2f978-3-319-20469-7_32&partnerID=40&md5=a2df9b5f3d19efc9d7510ac1f6325b8b","Presented in this paper is a method for the construction of emotion-enabled embodied (conversational) agents. By using a modified POMDP model, this method allows dialogue management not only to include emotion as part of the observation of user’s actions, but also to take system’s response time into consideration when updating belief states. Consequently, a novel algorithm is created to direct conversation in different contextual control modes, whose dynamic changes further provide hints for emotion animation with facial expressions and voice tunes. Experiment results demonstrate that the integration of emotion in dialogue management makes embodied agents more appealing and yields much better performance in human/computer interaction. © Springer International Publishing Switzerland 2015.","Dialogue management; Embodied agents; Emotion animation; Emotion recognition; POMDP model","Algorithms; Animation; Artificial intelligence; Control modes; Dialogue management; Dynamic changes; Embodied agent; Emotion recognition; Facial Expressions; Novel algorithm; Updating beliefs; Speech recognition",2-s2.0-84947564310
"Yang L., Xu T., Li X.","An interactive construction method of 3D objects from Chinese ink paintings",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941659211&doi=10.1007%2f978-3-662-48247-6_16&partnerID=40&md5=be19365f35edc0a89605c580b36737ea","We propose an interactive construction method of 3D objects from Chinese ink paintings for the challenge problem of generating the Chinese ink animation. Marching Cube method is the popular method of 3D modeling; however, it has the limitation on constructing the objects with complex shapes by lines in Chinese ink paintings. Based on our method, we develop a software system for constructing 3D objects interactively by the manual input of brush strokes from the Chinese ink paintings. And then the system can generate 3D objects with 2D surface mesh and 3D skinned mesh automatically. Finally, the system renders them with the original ink effect textures of input image. Our experiments show that the approach is suitable for converting 2D painting image into 3D objects. This work would be helpful for the problem of generating 3D animation of Chinese ink painting. © Springer-Verlag Berlin Heidelberg 2015.","3D modeling; Animation; Chinese ink painting; Geometry processing; Non-photorealistic rendering (NPR)","Animation; Computer graphics; Mesh generation; Painting; Rendering (computer graphics); 3-d modeling; Challenge problems; Complex shapes; Construction method; Geometry processing; Ink paintings; Non-Photorealistic Rendering; Software systems; Three dimensional computer graphics",2-s2.0-84941659211
"Deng C., Wang S., Ma L.","Conclusions and perspectives",2015,"Visual Signal Quality Assessment: Quality of Experience (QoE)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944599314&doi=10.1007%2f978-3-319-10368-6_10&partnerID=40&md5=48e3b660c32f5b6a48ebf7d5c12b1eea","The main contribution of this book is offering an overview of current status, challenges, and new trends of visual quality assessment, from subjective assessment models to objective metrics, covering full-reference (FR), reduced-reference (RR), and no-reference (NR), multiply distorted images, contrast-changed images, mobile media, high dynamic range (HDR) images and videos, medical images, stereoscopic/3D videos, retargeted images and videos, computer graphics and animation quality assessment. Figure 10.1 diagrams the content presented in this book. © Springer International Publishing Switzerland 2015.",,"Computer graphics; Contrast media; Stereo image processing; Computer graphics and animations; Distorted images; High dynamic range images; Objective metrics; Quality assessment; Reduced reference; Subjective assessments; Visual quality assessment; Medical imaging",2-s2.0-84944599314
"Haschka T., Dauchez M., Henon E.","Visualization of molecular properties at the qantum mechanical level using blender",2015,"2015 IEEE 1st International Workshop on Virtual and Augmented Reality for Molecular Science, VARMS@IEEEVR 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941106619&doi=10.1109%2fVARMS.2015.7151719&partnerID=40&md5=913b5f0803ad7756bf43055a5b6b0274","Molecular visualization is an active and ever expanding subject of research. Most of the visualization methods are however applied on large biological molecules. The representation of smaller molecules on a quantum mechanical level is to date both cumbersome and rare. We present herein a workflow that allows arbitrary volumetric datasets obtained from quantum mechanical calculations to be visualized. Using the open source Blender software and in house developed scripts we show how a researcher might create high resolution publication ready images from quantum mechanical data, such as electron density, electrostatic potential or spin density. This approach currently beats standard molecular visualization tools such as VMD and PyMOL as it allows to visualize higher resolution volumetric datasets and hence, more complex molecules and molecular properties. Further we boast superior image qualitity due to the availability of high quality volumetric absorbtion, scattering and emission shaders in Blender. Finally we show how a today's state of the art cloud platforms provide the computational power required to create high quality visual representions. © 2015 IEEE.","I.3.7 [computer graphics]: three-dimensional graphics and realism-animation I.3.m [computer graphics]: three-dimensional graphics and realism-miscellaneous I.6.8 [simulation and modeling]: types of simulation-visual","Augmented reality; Computer graphics; Molecules; Open source software; Open systems; Quantum theory; Visualization; Electrostatic potentials; Molecular properties; Molecular visualization; Molecular visualization tools; Quantum mechanical levels; Quantum-mechanical calculation; Three-dimensional graphics and realism; Visualization method; Three dimensional computer graphics",2-s2.0-84941106619
"Laja Uggah L., Manaf A.A.","Overcoming the uncanny valley theory in digital characters based on human attitudes",2015,"Pertanika Journal of Social Science and Humanities",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943236113&partnerID=40&md5=5def4e75ef1479fedabf60daebc2b537","The uncanny valley theory is an idea pioneered by Masahiro Mori in 1970 in relation to the psychological effects of lifelike robotics (Mori, 1970). The uncanny valley is a phenomenon that occurs in animation and robotic, wherein things that look extremely similar to the human face, but with slight differences from the natural appearance or the natural movements and expressions of humans, that are found to be disturbing, uncanny, and revolting (Mewes &Heloir, 2009). This study aimed to accomplish three goals: 1) analysing the participants' attitudes towards digital characters based on a series of validated semantic differential questionnaires; 2) developing a conceptual model focusing on overcoming the uncanny valley theory in computer generated digital characters based on empirical findings; and 3) validating the theoretical model by providing specific guidelines for overcoming the uncanny valley theory by avoiding negative human attitude responses. Based on results from 229 participants, this study examined the key factors of digital characters from games and movies which caused uncanny responses from the participants based on their attitudes. The structural model indicates that digital characters' facial expressions have the strongest influence on the participants' perceived humanness, followed by the stimulus's physical movements. Meanwhile, the digital characters' animated hair has the next strongest influence on the participants' familiarity, followed by its facial expression.","3D Animation Perceived Humaness; Psychology; Stylized Animation; Uncanny Valley Indices",,2-s2.0-84943236113
"Sui X.L., Chen J.T., Zhang X.W., Hua C.","Read and display of UG models in OpenGL",2015,"Electronic Engineering and Information Science - Proceedings of the 2015 International Conference on Electronic Engineering and Information Science, ICEEIS 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949963515&partnerID=40&md5=704625043f8f41ace25dfec2ead98924","Aiming at complex three-dimensional objects’ animation demonstration problems in the virtual NC milling simulation system, UG model’s simulation completed in OpenGL is proposed. Visual C ++ 6.0 is chosen as a development tool, the UG is used as a modeling tool, then UG software’s PRT format data files are converted into the STL format data files. 3ds Max is used as a model transformation tool to convert STL files to 3DS files. Ultimately, 3DS models are reappearing in OpenGL by programming and realized the UG files’ read and display in OpenGL. The complex problems of UG models’ difficulty to realize animation demonstrate and OpenGL software’s difficulty to accomplish multiplex modeling of the three-dimensional objects are solved. It is of great significance of improving the simulation speed, real-time simulation as well as the dynamic display process of simulation in the virtual NC simulation system. © 2015 Taylor & Francis Group, London.","3ds Max; Display; OpenGL; Read; UG","Animation; Application programming interfaces (API); C++ (programming language); Computer programming; Display devices; Information science; 3ds max; Development tools; Model transformation; OpenGL; Read; Real time simulations; Three-dimensional object; UG; Computer software",2-s2.0-84949963515
"Fraiwan M., Barqawi L., Haddad G., Tawalbeh D., Al-Zamil M.","A gaming approach to behavioural rehabilitation: Concept exploration",2015,"International Journal of Computer Applications in Technology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929623436&doi=10.1504%2fIJCAT.2015.069337&partnerID=40&md5=370ecb95175e243c064d88056c879c1a","The awareness of behavioural disabilities like autism has increased dramatically in the past few years, revealing staggering numbers of affected individuals, mainly children. The pervasiveness of mobile and gaming technologies presents an excellent opportunity to educate children with behavioural difficulties. In this paper, gaming technology was used to present real-life scenarios to children, helping them to behave under those circumstances. Various scenes unconsciously train the children to act in the right manner, which aids their logic, behaviour, and self-confidence. The synergy of advanced fun 2D gaming and animation, attractive graphics, and professional therapy guidance provides an effective and strong learning experience. Copyright © 2015 Inderscience Enterprises Ltd.","ABI; Acquired brain injury; ADD; ADHD; Android; Attention deficit disorder; Attention deficit hyper activity disorder; Autism; Behavioural disability; Computer games","Brain; Computer games; Diseases; Interactive computer graphics; ABI; Acquired brain injuries; ADD; ADHD; Android; Attention deficit; Attention deficit disorder; Autism; Behavioural disability; Animation",2-s2.0-84929623436
"Sharma S., Jerripothula S.","An indoor augmented reality mobile application for simulation of building evacuation",2015,"Proceedings of SPIE - The International Society for Optical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928494365&doi=10.1117%2f12.2086390&partnerID=40&md5=c41f96531acf6a596a8a136376517ed2","Augmented Reality enables people to remain connected with the physical environment they are in, and invites them to look at the world from new and alternative perspectives. There has been an increasing interest in emergency evacuation applications for mobile devices. Nearly all the smart phones these days are Wi-Fi and GPS enabled. In this paper, we propose a novel emergency evacuation system that will help people to safely evacuate a building in case of an emergency situation. It will further enhance knowledge and understanding of where the exits are in the building and safety evacuation procedures. We have applied mobile augmented reality (mobile AR) to create an application with Unity 3D gaming engine. We show how the mobile AR application is able to display a 3D model of the building and animation of people evacuation using markers and web camera. The system gives a visual representation of a building in 3D space, allowing people to see where exits are in the building through the use of a smart phone or tablets. Pilot studies were conducted with the system showing its partial success and demonstrated the effectiveness of the application in emergency evacuation. Our computer vision methods give good results when the markers are closer to the camera, but accuracy decreases when the markers are far away from the camera. © 2015 SPIE-IS&T.","Augmented Reality; Evacuation; Mobile AR; Simulation and modeling","Animation; Augmented reality; Buildings; Cameras; Computer vision; Mobile devices; Smartphones; Telephone sets; Virtual reality; Evacuation; Evacuation procedures; Mobile Ar; Mobile augmented reality; Physical environments; Simulation and modeling; Simulation of buildings; Visual representations; Three dimensional computer graphics",2-s2.0-84928494365
"Ouyang Y., Zhang J., Leininger T.D., Frey B.R.","A STELLA model to estimate water and nitrogen dynamics in a short-rotation woody crop plantation",2015,"Journal of Environmental Quality",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920945960&doi=10.2134%2fjeq2014.01.0015&partnerID=40&md5=c9fec4b720c648dffa1a23873959f376","Although short-rotation woody crop biomass production technology has demonstrated a promising potential to supply feedstocks for bioenergy production, the water and nutrient processes in the woody crop planation ecosystem are poorly understood. In this study, a computer model was developed to estimate the dynamics of water and nitrogen (N) species (e.g., NH4-N, NO3-N, particulate organic N, and soluble organic N [SON]) in a woody crop plantation using STELLA (Structural Thinking and Experiential Learning Laboratory with Animation) software. A scenario was performed to estimate diurnal and monthly water and N variations of a 1-ha mature cottonwood plantation over a 1-yr simulation period. A typical monthly variation pattern was found for soil water evaporation, leaf water transpiration, and root water uptake, with an increase from winter to summer and a decrease from summer to the following winter. Simulations further revealed that the rate of soil water evaporation was one order of magnitude lower than that of leaf water transpiration. In most cases, the relative monthly water loss rates could be expressed as evapotranspiration &gt; root uptake &gt; percolation &gt; runoff. Leaching of NO3-N and SON depended not only on soil N content but also on rainfall rate and duration. Leaching of NO3-N from the cottonwood plantation was about two times higher than that of SON. The relative monthly rate of N leaching was NO3-N &gt; SON &gt; NH4-N. This study suggests that the STELLA model developed is a useful tool for estimating water and N dynamics from a woody crop plantation. © American Society of Agronomy, Crop Science Society of America, and Soil Science Society of America.",,"Animation; Biomass; Crops; Dynamics; Evaporation; Forestry; Leaching; Nitrogen; Rotation; Soil moisture; Soils; Solvents; Transpiration; Bioenergy productions; Biomass productions; Computer modeling; Experiential learning; Nitrogen dynamics; Short-rotation woody crops; Soil water evaporation; Variation pattern; Evapotranspiration; rain; runoff; soil water; surface water; water; air temperature; Article; circadian rhythm; computer model; crop; denitrification; evapotranspiration; fertilizer application; leaching; loblolly pine; mineralization; nitrification; nitrogen dynamics; plant stoma; plantation; sandy loam; seasonal variation; soil depth; soil temperature; soil water content; summer; sweating; water cycle; water loss; water transport; winter; Populus",2-s2.0-84920945960
"Sulaiman H.A.B., Othman M.A., Aziz M.Z.A.A., Bade A.","Review on narrow phase collision detection system in virtual environment",2015,"ARPN Journal of Engineering and Applied Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923010787&partnerID=40&md5=34e10a78f49ab809f3b2d404148523a4","Collision detection is one of the most important tools that has been used widely in animation and simulation especially in computer games and medical simulation purpose. One of the critical issues in collision detection system is to actually prepared what kind of technique that is suitable for virtual environment to adapt collision detection system installed. Hence, this research paper described a detailed review on collision detection algorithm mainly in narrow phase collision detection phase. © 2006-2015 Asian Research Publishing Network (ARPN).","Animation; Collision detection; Computer games; Simulation; Virtual environment",,2-s2.0-84923010787
"Karhu S., Alander J.T., Nurmi O.","Some tools for aiding teaching the basics of digital electronics and signal processing",2015,"CSEDU 2015 - 7th International Conference on Computer Supported Education, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943419373&partnerID=40&md5=2425e0692c80f8f5c16ce9f3f3535fdf","In this paper we describe some computing tools designed for aiding teaching of the basics of digital electronics and its applications mainly in signal processing for university studies of engineering. In this study we have developed two types of teaching tools: firstly, several small JavaScript-based simulation tools for visualizing the basic functions of digital circuits and their hardware design language models, and secondly, an FPGA-based FIR filter system for showing how to perform simple digital signal processing tasks with FPGAs.","Animation; Digital electronics; Digital signal processing (DSP); Engineering studies; Field programmable gate array (FPGA); Finite impulse response filter (FIR); Hardware design languages (HDL); VHDL","Animation; Computational linguistics; Computer hardware; Computer hardware description languages; Computer simulation languages; Digital circuits; Digital signal processing; E-learning; Field programmable gate arrays (FPGA); FIR filters; Hardware; Impulse response; Basic functions; Computing tools; Digital electronics; Digital signal processing (DSP); Filter system; Hardware design language; ITS applications; Teaching tools; Signal processing",2-s2.0-84943419373
"Hutter M., Knuth M., Kuijper A.","Mesh partitioning for parallel garment simulation",2015,"22nd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2014, Communication Papers Proceedings - in co-operation with EUROGRAPHICS Association",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957864321&partnerID=40&md5=da3f1df1ccb187c04db1c04e03dfcca8","We present a method for partitioning meshes that allows a simple and efficient parallel implementation of different simulation methods. It is based on a generalization of the concept of independent sets from graph theory to sets of simulation elements. The general description makes it versatile and flexibly applicable in existing simulation systems. Every simulation method that formerly worked by sequentially processing a set of simulation elements can now be parallelized by partitioning the underlying set, without affecting the behavior of the simulated model.","Animation; Computer Graphics; Parallel Programming; Simulation","Animation; Computer graphics; Computer programming; Graph theory; Parallel programming; Visualization; General description; Independent set; Mesh partitioning; Parallel implementations; Simulated model; Simulation; Simulation elements; Simulation systems; Computer vision",2-s2.0-84957864321
"Turner C., Yan J., Richards D., O'Brien P., Odubiyi J., Brown Q.","Lucid: A visualization and broadcast system for cyber defense competitions",2015,"ACM Inroads",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930422980&doi=10.1145%2f2746408&partnerID=40&md5=9ab72454617ed714d349572501f52d90","In this article, we discuss LUCID, a visualization and broadcast system targeted to improving a spectator's ability to understand and make sense of cyber defense competitions. The system aims to engage the spectator by presenting information pertinent to understanding the real-time events of the competition as they unfold. It accomplishes this through a combination of techniques, including real-time network security visualization, live video and audio monitoring, animation, computer graphics, user profiling, and commentary. We examine, specifically, how the LUCID system enables the audience to make sense of ongoing activities in a cyber defense competition. © 2015 ACM.",,"Animation; Computer graphics; Visualization; Broadcast systems; Cyber defense; Live video; Presenting informations; Real time; Real time network; User profiling; Network security",2-s2.0-84930422980
"Pokorný P., Macht P.","The tomas bata regional hospital grounds - the design and implementation of a 3D visualization",2015,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942750027&doi=10.1007%2f978-3-319-18473-9_21&partnerID=40&md5=82f269d6867cc953e9f0aa3c06cebb2e","This paper briefly describes a visualization method of the Tomas Bata Regional Hospital grounds in Zlín. This hospital was founded in 1927 and has grown rapidly to the present day. We also collected all available historical materials of the Tomas Bata Regional Hospital and its surrounding area. We mainly focused on building plans, cadastral maps and historical photos. All the information we collected was chronologically sorted and on this basis, we created a 3D visualization of the urban development of these hospital grounds. To begin with, we created the grounds terrain model based on the Daftlogic database [14]. All buildings and accessories were separately modeled (we used the standard polygonal representation) and textured by the UV mapping technique. After that, we created the more complex 3D scenes from the individual models in these years: 1927, 1930, 1935, 1940, 1950, 1960, 1980, 1990, 2000, 2005 and 2013. The visualization output is performed by rendered images and animations in these years. We used the Blender software suite for this visualization. © Springer International Publishing Switzerland 2015.","3D Visualization; Animation; Computer Graphics; Modeling; Texturing","Animation; Computer graphics; Hospitals; Intelligent systems; Models; Software engineering; Texturing; Urban growth; Visualization; 3D Visualization; Design and implementations; Individual models; Polygonal representation; Rendered images; Terrain Modeling; Urban development; Visualization method; Three dimensional computer graphics",2-s2.0-84942750027
"Cai X., Cheng C., Marwah A., Salem M.H., Ear M.","Research on behavior simulation of virtual hand in virtual manufacturing environment",2015,"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926387756&partnerID=40&md5=5971d2da8327ee22bbf1aaeb35c96031","An autonomous virtual hand behavior construction method for virtual manufacturing environments is presented to improve the current mainstream virtual hand animation method which totally depends on capturing a user's hand movement. The goal of this research is to provide an intelligent efficient virtual hand for virtual manufacturing scenario. The perception ability of virtual hand is established by adding ring sensors to its structural model. An adaptive behavior mechanism of virtual hand is constructed to alleviate user's cognitive load and manipulative loads which is composed by three-stage perception algorithms the authors invented. Furthermore, a gesture set and a gesture state transition model are given to realize a continuous grasping behavior of virtual hand on the surfaces of complex parts. The focus of this work is to investigate how to construct and realize a kind of continuous virtual hand manipulation behavior mechanism and algorithms on the surfaces of complex parts. The experiment results show that the designed virtual hand in this paper has a good geometric realism and behavior realism. The method given in this paper has characteristics of usability, reliability and real-time. ©, 2015, Institute of Computing Technology. All right reserved.","Behavior simulation; Human-computer interaction; Perception algorithm; Virtual environment; Virtual hand; Virtual manufacturing","Agile manufacturing systems; Animation; Behavioral research; Human computer interaction; Industrial research; Manufacture; Adaptive behavior; Behavior simulation; Cognitive loads; Construction method; State transition models; Structural modeling; Virtual hand; Virtual manufacturing; Virtual reality",2-s2.0-84926387756
"Lei Z., Taghaddos H., Han S.H., Bouferguène A., Al-Hussein M., Hermann U.","From autoCAD to 3ds max: An automated approach for animating heavy lifting studies",2015,"Canadian Journal of Civil Engineering",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925343224&doi=10.1139%2fcjce-2014-0313&partnerID=40&md5=237445ff6f7effed1be4329efef7c1af","Modular construction is a dominant manufacturing method for industrial construction in Alberta, Canada. Modularization requires large-capacity mobile cranes to lift heavy modules, such as piperack modules. The current practice utilizes AutoCAD to generate heavy lift studies for modular onsite installations. Heavy lift studies consist of 2D and 3D simulations of the lifting scenarios, along with the corresponding calculations (e.g., lifting capacity checking, ground bearing pressure checking). These static simulations provide snapshots of mobile cranes at pick and set configurations, but they do not represent the movements between the two configurations. For better communication among site engineers and crews, current static heavy lift studies need to be improved by animating the entire lifting process. 3ds Max is an animation tool that can visualize the lifting process, but the tedious and manual process of preparing the animation restricts efficiency and productivity. This research thus introduces a newly developed animation system that automates the transfer of heavy lift studies from AutoCAD into Autodesk 3ds Max animation. Also in this research, the kinetics of mobile cranes are studied and generic crane movements are defined. Using MAXScript, a script is written to link the crane and project database for automatic generating of animations. This research aims to provide the construction industry with a generic method for automating the animation process for heavy lifts based on AutoCAD and 3ds Max systems. © 2015(Publisher name). All rights reserved.","3ds Max; Animation; Automation; Heavy lift; Mobile crane","Animation; Automation; Computer aided design; Construction industry; Modular construction; 3ds max; Automated approach; Heavy lifts; Industrial construction; Manufacturing methods; Mobile cranes; Onsite installation; Static simulations; Cranes; construction industry; database; manufacturing; three-dimensional modeling; two-dimensional modeling; visualization; Alberta; Canada; Gruidae",2-s2.0-84925343224
"Lin E.C.-H.","A research on 3D motion database management and query system based on Kinect",2015,"Lecture Notes in Electrical Engineering",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922323227&doi=10.1007%2f978-94-017-9558-6_4&partnerID=40&md5=ca36ffe8315c25fcbcd3832210459bdd","Due to the development of computer technology and the mature development of 3D motion capture technology, the applications of 3D motion databases become more and more important. How to analysis the huge data stored in the database and efficiently retrieved the matched data is an important research issue. 3D animation design is one of the important applications of 3D motion databases. Based on our teaching experience, the bottleneck of the students’ learning of 3D animation is the motion animation of the 3D characters. Therefore, the 3D motion database can be used to assist the design of the motion for 3D characters. However, it is still a difficult problem because of the high complexity of the matching mechanism and the difficult of user interface design. Kinect, which is developed by Microsoft, is used as a remote controller of Xbox 360 games. Because of the capability of capturing user motions, Kinect is used in this project as the user interface. The captured data can be used as the user query and the further comparison will be performed to find the matched motion data. © Springer Science+Business Media Dordrecht 2015.","3D motion database; Index structure; Kinect; Query processing","Animation; Database systems; Design; Query processing; Remote control; 3D motion; Computer technology; Index structure; Kinect; Matching mechanisms; Remote controllers; Teaching experience; User interface designs; User interfaces",2-s2.0-84922323227
"Sidhu M.S.","The effects of using learning-aided cues in an augmented reality environment for a multi-body mechanism",2015,"International Journal of Computer Applications in Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951149784&doi=10.1504%2fIJCAT.2015.073587&partnerID=40&md5=615b4cc04e23fee0658fa13c17d4e45e","Visual cues have been used in educational multimedia and virtual reality. Augmented reality (AR) is a new potential area of research for education, covering issues such as tracking and calibration, and realistic rendering of virtual objects. The ability to augment the real world with virtual information has opened the possibility of using AR technology in areas such as education and training. In the domain of computer-aided learning (CAL), researchers have long been looking into enhancing the effectiveness of the teaching and learning process by providing cues that could assist learners to better comprehend the materials presented. Although a number of works were done looking into the effectiveness of learning-aided cues, none has addressed this issue for AR-based learning solutions. This paper discusses the effects of using learningaided cues in an AR environment for a multi-body mechanism. The results indicated positive acceptance by students as a new technology in their learning. Copyright © 2015 Inderscience Enterprises Ltd.","Animation; Augmented reality; Cues; Education; Engineering; Multimedia","Animation; Augmented reality; Computer aided instruction; Education; Engineering; Learning systems; Virtual reality; Computer aided learning; Cues; Education and training; Multibody mechanisms; Multimedia; Realistic rendering; Teaching and learning; Virtual information; Engineering education",2-s2.0-84951149784
"Yan S., Zheng X., Shi X., Zheng F.","Study of intelligent multimedia display system for classic chinese poetry",2015,"Beijing Daxue Xuebao (Ziran Kexue Ban)/Acta Scientiarum Naturalium Universitatis Pekinensis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926642200&doi=10.13209%2fj.0479-8023.2015.045&partnerID=40&md5=3138c3e1b4aa77054201f95178e36d24","Focusing on classical Chinese poetry, the authors firstly achieve the combination of NLP, computing poetics and computer animation to solve the automatic animation generation of classical poetries. The authors firstly automatically determine the poetry style, subject matter and the time using SVM-based and collaborative learning classifier. After the achievement of automatic animation generation by using Flash Actionscript 3.0 script, using co-occurrence relationship supplies animation elements and gives poetry scene classification method. The results show that the proposed methodology initially solves the automatic generation of classical poetry animation, and provides a theoretical basis and experimental foundation for subsequent research. ©2015 Peking University.","Ancient poetry; Animation generation; Co-occurrence analysis; SVM classification",,2-s2.0-84926642200
"Evangeline D., Anitha S.","2D Polygon clipping using shear transformation: An extension of Shear based 2D line Clipping",2015,"Proceedings of 2014 IEEE International Conference on Advanced Communication, Control and Computing Technologies, ICACCCT 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923287641&doi=10.1109%2fICACCCT.2014.7019326&partnerID=40&md5=27f7bc548a37cd7e8cdfbd5fcb9954af","Computer Graphics, an emerging field is widely used in CAD, entertainment, animation, education and training, graphical user interface, etc., Polygon clipping which is one among the indispensable operations in Geographic Information Systems and Very Large Scale Integration that selects particular regions of a 2D object interior to a window of rectangle or any arbitrary shape. Already, various polygon clipping algorithms are available along with their complexity analyses. In our paper, we propose an algorithm which uses Shear Transformation for Polygon Clipping. Experimental results prove that our algorithm outperforms conventional clipping algorithms by its suitability to clip all types of polygons with reduced running time and memory usage in addition to handling degenerate cases. © 2014 IEEE.","Computer Graphics; Degeneracy; Polygon Clipping; Shear","Algorithms; Animation; Computer graphics; Geographic information systems; Graphical user interfaces; Shearing; User interfaces; Arbitrary shape; Clipping algorithms; Complexity analysis; Degeneracy; Degenerate case; Education and training; Polygon Clipping; Shear transformation; Geometry",2-s2.0-84923287641
"Ismail A., Sharaf N., Abdennadher S.","CHR in action",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952779856&doi=10.1007%2f978-3-319-27436-2_22&partnerID=40&md5=9a86a8e0b71d140c6214f0c82c9f1015","Constraint Handling Rules (CHR) has expanded its application range over the past few years to include different algorithms rather than only constraint solvers. Animation of algorithms has been used over the past few decades to aid the understanding of programming languages and how they are processed. In this work, we present a generic form of animating CHR programs using source-to-source transformation. The transformation converts CHR programs into their equivalent CHR programs enhanced with animation features, in an automated manner. © Springer International Publishing Switzerland 2015.","Animation; Constraint handling rules; Source-to-source transformation; XPCE","Animation; Logic programming; Reconfigurable hardware; Constraint Handling Rules; Constraint solvers; Generic forms; ITS applications; Source-to-source transformations; XPCE; Computer circuits",2-s2.0-84952779856
"Mollahosseini A., Graitzer G., Borts E., Conyers S., Voyles R.M., Cole R., Mahoor M.H.","ExpressionBot: An emotive lifelike robotic face for face-to-face communication",2015,"IEEE-RAS International Conference on Humanoid Robots",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945184597&doi=10.1109%2fHUMANOIDS.2014.7041505&partnerID=40&md5=18569b08dcd079c33abde5564496a271","This article proposes an emotive lifelike robotic face, called ExpressionBot, that is designed to support verbal and non-verbal communication between the robot and humans, with the goal of closely modeling the dynamics of natural face-to-face communication. The proposed robotic head consists of two major components: 1) a hardware component that contains a small projector, a fish-eye lens, a custom-designed mask and a neck system with 3 degrees of freedom; 2) a facial animation system, projected onto the robotic mask, that is capable of presenting facial expressions, realistic eye movement, and accurate visual speech. We present three studies that compare Human-Robot Interaction with Human-Computer Interaction with a screen-based model of the avatar. The studies indicate that the robotic face is well accepted by users, with some advantages in recognition of facial expression and mutual eye gaze contact. © 2014 IEEE.",,"Anthropomorphic robots; Degrees of freedom (mechanics); Eye movements; Face recognition; Human computer interaction; Human robot interaction; Lenses; Robots; 3 degrees of freedom; Face-to-face communications; Facial animation; Facial Expressions; Hardware components; Non-verbal communications; Recognition of facial expressions; Visual speech; Robotics",2-s2.0-84945184597
"Ervasti M., Häikiö J., Isomursu M., Isomursu P., Liuska T.","Digital signage effectiveness in retail stores",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945977126&doi=10.1007%2f978-3-319-22668-2_35&partnerID=40&md5=629aedbd7245cc33dafaa454fb0a70d0","This paper presents results from a study on the effectiveness of digital signage in the retail environment. The goal of the study was to examine design parameters relevant to digital signage content design which could be used to create guidelines and templates for designing effective digital signage content. In this study, we focused on how video and animation affect the effectiveness of digital signage. When comparing still content with content enhanced with video or animation, no significant difference in effectiveness could be observed. This observation contradicts with earlier studies. Our study supports the views that the digital displays are currently most useful and effective to the younger generation, and that male customers consider digital displays in a store more useful than females do. © IFIP International Federation for Information Processing 2015.","Digital content design; Digital signage; Media management; Retail store; User experience; User interfaces; User study","Animation; Costs; Human computer interaction; Sales; User interfaces; Digital contents; Digital signage; Media management; User experience; User study; Retail stores",2-s2.0-84945977126
"Zhang J., Kan M., Shan S., Zhao X., Chen X.","Topic-aware deep auto-encoders (TDA) for face alignment",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983474445&doi=10.1007%2f978-3-319-16811-1_46&partnerID=40&md5=aa3cd861a441f5ddb365c9cb6db01944","Facial landmark localization plays an important role for many computer vision tasks, e.g., face recognition, face parsing, facial expression analysis, face animation, etc. However, it remains a challenging problem due to the diverse variations, such as head poses, facial expressions, occlusions and so on. In this work, we propose a topic-aware face alignment method to divide the difficult task of estimating the target shape into several much easier subtasks according to the topics. Specifically, topics are determined automatically by clustering according to the target shapes or shape deviations which are more compatible with the task of alignment. Then, within each topic, a deep auto-encoder network is employed to regress from the shape-indexed feature to the target shape. Deep model specific to each topic can capture more subtle variations in shape and appearance, and thus leading to better alignment results. This process is conducted in a cascade structure to further improve the performance. Experiments on three challenging databases demonstrate that our method significantly outperforms the state-of-the-art methods and performs in real-time. © Springer International Publishing Switzerland 2015.",,"Computer vision; Electron emission; Formal languages; Learning systems; Cascade structures; Face alignment; Face animation; Facial expression analysis; Facial Expressions; Facial landmark; Shape deviations; State-of-the-art methods; Face recognition",2-s2.0-84983474445
"Lee Y.","AR coloring jigsaw puzzles with texture extraction and auto-UV mapping algorithm",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947229246&doi=10.1007%2f978-3-319-20804-6_17&partnerID=40&md5=d0a1cf5be50d253ee9af5e27aca1dd79","There have been many applications with AR technology such as advertisement, education, etc. Books with AR technology are the most interesting application area. In this paper, we propose an AR coloring jigsaw puzzles which provides users with puzzle pieces for coloring and AR/VR worlds for colored 3D animations. The proposed puzzle is composed of a jigsaw puzzle with unpainted pieces and a smart phone application. The jigsaw puzzle with unpainted pieces is designed large pieces of puzzle and several uncolored pieces. The smart phone application has an AR scene for extracting color from puzzle and a VR world for user interaction with colored animals. © Springer International Publishing Switzerland 2015.","Augmented reality; Coloring book; Virtual reality; Vuforia SDK","Algorithms; Augmented reality; Conformal mapping; Smartphones; Telephone sets; User interfaces; Virtual reality; 3D animation; Application area; Jigsaw puzzles; Smart-phone applications; Texture extraction; U-v-mapping; User interaction; Vuforia SDK; Human computer interaction",2-s2.0-84947229246
"Min K.","Feature-guided convolution for salient rendering of 3D meshes",2015,"International Journal of Engineering Systems Modelling and Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918593728&doi=10.1504%2fIJESMS.2015.066122&partnerID=40&md5=0c8be87fa3120f193b006225c392a7f3","We present a novel algorithm that depicts the salient shape of a 3D mesh by mimicking pencil drawing style. In estimating the saliency of a mesh, we consider both view-independent and view-dependent saliency. The view-independent saliency is estimated from the strength of silhouette and the view-dependent one is computed by approximating the curvature of a mesh. We extend the pencil drawing algorithm for a mesh and develop a convolution-based scheme that renders the saliency of a mesh in a pencil drawing style. Furthermore, we develop a scheme that controls the coherence of the depiction through an animation of a mesh. Copyright © 2015 Inderscience Enterprises Ltd.","3D mesh; Convolution.; Curvature; Non-photorealistic rendering; NPR; Pencil drawing; Saliency; Silhouette","Algorithms; Animation; Convolution; 3D meshes; Curvature; Non-Photorealistic Rendering; NPR; Pencil drawing; Saliency; Silhouette; Three dimensional computer graphics",2-s2.0-84918593728
"Chen C.-H., Lee I.-J., Lin L.-Y.","Augmented reality-based self-facial modeling to promote the emotional expression and social skills of adolescents with autism spectrum disorders",2015,"Research in Developmental Disabilities",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909981707&doi=10.1016%2fj.ridd.2014.10.015&partnerID=40&md5=66c1dabf8ea0cfe6d483f25c15157d34","Autism spectrum disorders (ASD) are characterized by a reduced ability to understand the emotions of other people; this ability involves recognizing facial expressions. This study assessed the possibility of enabling three adolescents with ASD to become aware of facial expressions observed in situations in a school setting simulated using augmented reality (AR) technology. The AR system provided three-dimensional (3-D) animations of six basic facial expressions overlaid on participant faces to facilitate practicing emotional judgments and social skills. Based on the multiple baseline design across subjects, the data indicated that AR intervention can improve the appropriate recognition and response to facial emotional expressions seen in the situational task. © 2014 Elsevier Ltd.","3-D facial animation; Augmented reality (AR); Emotions; Self-facial modeling; Three-dimensional (3-D) facial expressions","adolescent; Article; augmented reality system; autism; awareness; case report; child; computer simulation; emotion; facial expression; female; human; male; recognition; social adaptation; task performance",2-s2.0-84909981707
"Shi H., Bai X., Duan J.","3D fabric dynamic simulation based on Mapreduce",2015,"International Journal of Clothing Science and Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946058297&doi=10.1108%2fIJCST-02-2014-0023&partnerID=40&md5=49214d8fb1777d9f1038463bebd1f968","Purpose – In cloth animation field, the collision detection of fabric under external force is very complex, and difficult to satisfy the needs of reality feeling and real time. The purpose of this paper is to improve reality feeling and real-time requirement. Design/methodology/approach – This paper puts forward a mass-spring model with building bounding-box in the center of particle, and designs the collision detection algorithm based on Mapreduce. At the same time, a method is proposed to detect collision based on geometric unit. Findings – The method can quickly detect the intersection of particle and triangle, and then deal with collision response according to the physical characteristics of fabric. Experiment shows that the algorithm improves real-time and authenticity. Research limitations/implications – Experiments show that 3D fabric simulation can be more efficiency through parallel calculation model − Mapreduce. Practical implications – This method can improve the reality feeling, and reduce calculation quantity. Social implications – This collision-detection can be used into more fields such as 3D games, aero simulation training and garments automation. Originality/value – This model and method have originality, and can be used to 3D animation, digital entertainment, and garment industry. © 2015, Emerald Group Publishing Limited.","3D fabric; Collision detection; Dynamic simulation; Mapreduce","Computer simulation; Image segmentation; Object detection; 3-D fabrics; Collision detection; Collision detection algorithm; Design/methodology/approach; Digital entertainment; Map-reduce; Physical characteristics; Real time requirement; Animation",2-s2.0-84946058297
"Knyaz V.A.","Scalable photogrammetric motion capture system ""mosca"": Development and application",2015,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936817518&doi=10.5194%2fisprsarchives-XL-5-W6-43-2015&partnerID=40&md5=85d92a7ae34873d3c86696b585a81198","Wide variety of applications (from industrial to entertainment) has a need for reliable and accurate 3D information about motion of an object and its parts. Very often the process of movement is rather fast as in cases of vehicle movement, sport biomechanics, animation of cartoon characters. Motion capture systems based on different physical principles are used for these purposes. The great potential for obtaining high accuracy and high degree of automation has vision-based system due to progress in image processing and analysis. Scalable inexpensive motion capture system is developed as a convenient and flexible tool for solving various tasks requiring 3D motion analysis. It is based on photogrammetric techniques of 3D measurements and provides high speed image acquisition, high accuracy of 3D measurements and highly automated processing of captured data. Depending on the application the system can be easily modified for different working areas from 100 mm to 10 m. The developed motion capture system uses from 2 to 4 technical vision cameras for video sequences of object motion acquisition. All cameras work in synchronization mode at frame rate up to 100 frames per second under the control of personal computer providing the possibility for accurate calculation of 3D coordinates of interest points. The system was used for a set of different applications fields and demonstrated high accuracy and high level of automation.","Accuracy; Calibration; Motion capture; Photogrammetry; Tracking","Animation; Automation; Biometrics; Calibration; Cameras; Data handling; Image acquisition; Image processing; Personal computers; Photogrammetry; Security systems; Surface discharges; Accuracy; Accurate calculations; Automated processing; Development and applications; Image processing and analysis; Motion capture; Motion capture system; Photogrammetric technique; Motion analysis",2-s2.0-84936817518
"Kazmi I.K., You L., Yang X., Jin X., Zhang J.J.","Efficient sketch-based creation of detailed character models through data-driven mesh deformations",2015,"Computer Animation and Virtual Worlds",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929277966&doi=10.1002%2fcav.1656&partnerID=40&md5=8b5c7a1c61b484b072c5ca6399604327","Creation of detailed character models is a very challenging task in animation production. Sketch-based character model creation from a 3D template provides a promising solution. However, how to quickly find correct correspondences between user's drawn sketches and the 3D template model, how to efficiently deform the 3D template model to exactly match user's drawn sketches, and realize real-time interactive modeling is still an open topic. In this paper, we propose a new approach and develop a user interface to effectively tackle this problem. Our proposed approach includes using user's drawn sketches to retrieve a most similar 3D template model from our dataset and marrying human's perception and interactions with computer's highly efficient computing to extract occluding and silhouette contours of the 3D template model and find correct correspondences quickly. We then combine skeleton-based deformation and mesh editing to deform the 3D template model to fit user's drawn sketches and create new and detailed 3D character models. The results presented in this paper demonstrate the effectiveness and advantages of our proposed approach and usefulness of our developed user interface. Copyright © 2015 John Wiley & Sons, Ltd.","3D template models; detailed character creation; Laplacian mesh editing; mean value coordinates; skeleton-based deformation; sketch-based modeling","Animation; Deformation; Human computer interaction; Musculoskeletal system; User interfaces; 3D template-models; Detailed character creation; Mean value coordinates; Mesh editing; Sketch-based modeling; Drawing (graphics)",2-s2.0-84929277966
"Zboinska M.A.","Enriching creativity in digital architectural design: A hybrid digital design toolset as a catalyst for design emergence in early-stage explorations of complex forms",2015,"CAADRIA 2015 - 20th International Conference on Computer-Aided Architectural Design Research in Asia: Emerging Experiences in the Past, Present and Future of Digital Architecture",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936129389&partnerID=40&md5=4faa86f6920de048b98f869d227b342d","Although conceptual design is one of the most important stages of creation, impacting the quality and cost of the final product, current research indicates that designers still lack adequate tools supporting early-stage design. This research challenges that notion, by proposing a hybrid digital design platform for conceptual architectural design. The platform contains four miscellaneous techniques: Animation, free-form modelling, associative parametric modelling and performance- driven modelling. In a digital design experiment we demonstrate that the collective application of these techniques to early-stage design explorations intensifies the architect's visual and cognitive reasoning processes, and hence supports the emergence of promising design artefacts which bear the traces of all the techniques applied in the course of their conception. Additionally, the study also points at some other promising virtues of the hybrid toolset, including: provision of diversified form-finding opportunities on various levels of design abstraction; the potential to direct designers onto unplanned creation paths; the ability to increase the versatility and functionality of the solutions; and the capacity to sustain design activities of various character, ranging from highly intuitive ones to very rational ones. © 2015 All rights reserved and published by The Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.","Animation; Associative parametric modelling; Conceptual design methods and tools; Free-form modelling; Performance-driven design","Animation; Computer architecture; Conceptual design; Curricula; Design; Product design; Cognitive reasoning; Design abstractions; Digital designs; Early stage designs; Freeform modelling; Parametric modelling; Performance-driven; Research challenges; Architectural design",2-s2.0-84936129389
"Ramasubramanian M., Rangaswamy M.A.D., Reddy G.N.V.R.","A survey study on detecting and tracking objective methods",2015,"Proceedings - NCET NRES EM 2014: 2nd IEEE National Conference on Emerging Trends in New and Renewable Energy Sources and Energy Management",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929325325&doi=10.1109%2fNCETNRESEM.2014.7088759&partnerID=40&md5=8a45b7a7e35140e5382fd8c623463fce","The purpose of prosecution is segmentation feature a region of interest in a video scene and retention proposal, positioning and locking. Object detection and classification of objects are preceded steps for tracking an object in the image sequence. Object detection is done to check for objects in the video and find out exactly what the object. Then the detected object can be classified into different categories, such as people, vehicles, birds, clouds floating, swaying trees and other moving objects. Object Tracking is performed using spatial and temporal changes of items during a video monitoring, including presence, position, size, shape, etc. The object is used in several applications such as video surveillance, robot vision, monitoring traffic Video and Animation painting. This paper presents a brief overview of object detection, object classification and object tracking different algorithms available in the literature, including the analysis and comparative study of the various techniques used at various stages of prosecution. © 2014 IEEE.","Background Modeling; Object Classification; Object Detection; Object Tracking; Video Surveillance","Animation; Computer vision; Image processing; Image segmentation; Law enforcement; Locks (fasteners); Object recognition; Renewable energy resources; Security systems; Tracking (position); Background model; Comparative studies; Object classification; Object Tracking; Objective methods; Region of interest; Spatial and temporal changes; Video surveillance; Object detection",2-s2.0-84929325325
"Effland A., Rumpf M., Simon S., Stahn K., Wirth B.","Bézier curves in the space of images",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931042844&doi=10.1007%2f978-3-319-18461-6_30&partnerID=40&md5=c064db27236be358e302a0da001876c8","Bézier curves are a widespread tool for the design of curves in Euclidian space. This paper generalizes the notion of Bézier curves to the infinite-dimensional space of images. To this end the space of images is equipped with a Riemannian metric which measures the cost of image transport and intensity variation in the sense of the metamorphosis model [MY01]. Bézier curves are then computed via the Riemannian version of de Casteljau’s algorithm, which is based on a hierarchical scheme of convex combination along geodesic curves. Geodesics are approximated using a variational discretization of the Riemannian path energy. This leads to a generalized de Casteljau method to compute suitable discrete Bézier curves in image space. Selected test cases demonstrate qualitative properties of the approach. Furthermore, a Bézier approach for the modulation of face interpolation and shape animation via image sketches is presented. © Springer International Publishing Switzerland 2015.","De Casteljau algorithm; Metamorphosis; Shape manifolds","Animation; Geometry; Convex combinations; De Casteljau algorithms; Infinite dimensional; Intensity variations; Metamorphosis; Qualitative properties; Shape manifold; Variational discretization; Computer vision",2-s2.0-84931042844
"Baroin G., Seress H.","The Spinnen-Tonnetz: New musical dimensions in the 2D network for tonal music analysis using polarization and tonal regions in a dynamic environment",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948992541&doi=10.1007%2f978-3-319-20603-5_32&partnerID=40&md5=9c50351c4ecf118212c966de71ff5499","The Polarized Tonnetz developed by Hugues Seress [4] is an innovative two-dimensional representation system for visualizing statically and dynamically some triadic or post-triadic organization, harmonic and tonal paths, as well as tonal regions and musical relations. As for the traditional Tonnetz, the Polarized one relates to transformational design and parsimonious voice leading. Its originality resides however in the introduction of three differentiated criteria concerning the transformation (chromatic distance, modal orientation, polarity) and a fourth parameter: the upward or downward direction of the voice leading. We then enhanced the Polarized Tonnetz with the Planet-4D colorization and animation system developed by Gilles Baroin [1], and finally add a new dynamic graphical layer that illustrates the tonal regions. This paper describes the construction and features of the Spinnen-Tonnetz as well as some musical analysis performed. All videos concerning the construction of the Spinnen-Tonnetz and the musical sample studied are available online at www.MatheMusic.net. © Springer International Publishing Switzerland 2015.","Analysis; Animation; CGI; Mathemusical; Neo-Riemannian; Planet-4D; Polarized tonnetz; Tonal regions; Tonnetz; Transformation","Artificial intelligence; Computers; Analysis; CGI; Mathemusical; Neo-Riemannian; Tonal regions; Tonnetz; Transformation; Animation",2-s2.0-84948992541
"Alom M., Awwal N., Scoular C.","Technology integration in multiplayer game design",2015,"Proceedings of the European Conference on Games-based Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955130106&partnerID=40&md5=f3ccca0a7352c15042af36a479a53732","Online multiplayer educational games can be designed to promote collaboration and assess abilities of students through their responses or actions within the game environment. This paper describes the design and integration process for such games, prototypes of which have been developed as part of the ATC21S™ research study by the University of Melbourne. HTML5 has been used in preference to other available technologies in creating the games to provide a consistent experience for students across all browsers, platforms, and devices. The multiplayer component of the games was supported with the use of the Web Socket application which enabled the communication protocol between the client and server to be established. Canvas is used to create all animations and game objects. The paper will describe justification for the use of additional technologies to facilitate the game flow and a positive user experience.","Canvas; Collaborative; Game design; HTML5; Web socket","Distributed computer systems; HTML; Internet protocols; Canvas; Collaborative; Game design; HTML5; Web socket; Animation",2-s2.0-84955130106
"Neto J., Ribeiro C., Pereira J., Neto M.J.","Virtual agents and multi-modality of interaction in multimedia applications for cultural heritage: A case study",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938903814&partnerID=40&md5=73c09f0969737285cad09cc7829b73cd","Cultural Heritage encompasses a set of traditions and commodities inherited from our ancestors, and it is vital to convey and preserve them for the next generation. Cultural Multimedia applications and Serious Games form an important pedagogical and didactic medium, mainly for a young demography, which can learn while playing. In this paper is presented an innovative platform, named EI2VA (Engine for Immersive Interaction with Virtual Agents), in which a virtual character, endowed with facial, corporal and behavioural animation can be integrated in multimedia applications. These multimedia applications, derived from the Fala Comigo project, which set the example for a possible use of this technology, preserving the historical and cultural contents indispensable for the users, based on a multi-modality of evident interaction. The resulting multimedia applications were used in a case study conduct with three different user groups (experts and nonexperts) in different settings including classroom, museum and scientific conference. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Cultural heritage; Embodied conversational agents; Immersive and interactive experience; Multi-modal; Multidisciplinary approach; Multimedia applications","Animation; Computer graphics; Teaching; Cultural heritages; Embodied conversational agent; Immersive; Multi-disciplinary approach; Multi-modal; Multimedia applications; Historic preservation",2-s2.0-84938903814
"Pulijala Y., Ma M., Ayoub A.","Design and development of Sur-Face: an interactive mobile app for educating patients regarding corrective surgery of facial deformities",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945966876&doi=10.1007%2f978-3-319-19126-3_3&partnerID=40&md5=7b3958fd262ff955ceb5bcff64fcdc4a","Corrective surgery of face, also known as orthognathic surgery, is a complex procedure performed to correct the underlying facial deformities. In case of elective surgeries like these, patients need to make voluntary decisions whether or not undergo the surgery. Hence, it is very important for them to understand the intricacy of the techniques and potential side effects of the surgery before they sign the consent form. Conventional methods of patient education using leaflet-based instructions were found to be ineffective in providing them the required information. Sur-Face, named after surgery of face is a healthcare app exploring a new dimension in patient education with the help of interactive 3D visualizations and serious gaming elements on a mobile platform. It demonstrates the surgical process and it’s after effects using high quality 3D animations. The aim of this study is to evaluate the efficacy of Sur-Face by comparing two methods of delivery of instructions: a mobile app with interactive 3D animations and an audio file containing only verbal instructions. To evaluate these methods, participant’s ability to understand and retain the instructions was analyzed using a questionnaire. The null hypothesis was that there would be no difference between the two methods of instructions. On analysis, participants of the ‘app’ group performed significantly better (p<0.0034) than the ‘voice’ group suggesting the role of interactive visualizations in improved understanding, intuitive knowledge transfer and communication. This paper describes the principles of design, development and potential advances of Sur-Face. Further it also explores the application of serious games in patient education and informed consent process. © Springer International Publishing Switzerland 2015.","3D modeling; Facial deformities; mHealth; Mobile apps; Orthognathic surgery; Visualization","Animation; Education; Flow visualization; Knowledge management; Three dimensional computer graphics; Visualization; 3-d modeling; Facial deformities; mHealth; Mobile apps; Orthognathic surgeries; Surgery",2-s2.0-84945966876
"Hu W., Cheung G., Ortega A., Au O.C.","Multiresolution graph fourier transform for compression of piecewise smooth images",2015,"IEEE Transactions on Image Processing",40,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920157216&doi=10.1109%2fTIP.2014.2378055&partnerID=40&md5=d54972310096fc3340d4a5b30cfd0daf","Piecewise smooth (PWS) images (e.g., depth maps or animation images) contain unique signal characteristics such as sharp object boundaries and slowly varying interior surfaces. Leveraging on recent advances in graph signal processing, in this paper, we propose to compress the PWS images using suitable graph Fourier transforms (GFTs) to minimize the total signal representation cost of each pixel block, considering both the sparsity of the signal's transform coefficients and the compactness of transform description. Unlike fixed transforms, such as the discrete cosine transform, we can adapt GFT to a particular class of pixel blocks. In particular, we select one among a defined search space of GFTs to minimize total representation cost via our proposed algorithms, leveraging on graph optimization techniques, such as spectral clustering and minimum graph cuts. Furthermore, for practical implementation of GFT, we introduce two techniques to reduce computation complexity. First, at the encoder, we low-pass filter and downsample a high-resolution (HR) pixel block to obtain a low-resolution (LR) one, so that a LR-GFT can be employed. At the decoder, upsampling and interpolation are performed adaptively along HR boundaries coded using arithmetic edge coding, so that sharp object boundaries can be well preserved. Second, instead of computing GFT from a graph in real-time via eigen-decomposition, the most popular LR-GFTs are pre-computed and stored in a table for lookup during encoding and decoding. Using depth maps and computer-graphics images as examples of the PWS images, experimental results show that our proposed multiresolution-GFT scheme outperforms H.264 intra by 6.8 dB on average in peak signal-to-noise ratio at the same bit rate. © 2014 IEEE.","Graph Fourier Transform; Image Compression; Piecewise Smooth Images","Animation; Clustering algorithms; Computer graphics; Cosine transforms; Decoding; Discrete cosine transforms; Graphic methods; Image coding; Image compression; Image quality; Image segmentation; Low pass filters; Pixels; Signal processing; Signal to noise ratio; Table lookup; Computation complexity; Encoding and decoding; Graph Fourier transforms; Peak signal to noise ratio; Piecewise smooth; Signal characteristic; Signal representations; Transform coefficients; Fourier transforms",2-s2.0-84920157216
"Spinillo C.G., Perozza R.","An interactive guide to design animated visual instructions in Brazil",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947285746&doi=10.1007%2f978-3-319-20898-5_36&partnerID=40&md5=2f5b3e26c0f4c81bbfd401c7aab5b839","Animated visual instructions have been increasingly produced to support the industry of assembling products. Despite the growing demand for this type of instruction, in Brazil, little has been investigated on how animated instructions should be graphically presented to promote communication effectiveness. This paper discusses a research-based interactive guide to aid the design process of animated instructions in Brazil from user-centered design approach. First, to develop the guide, the graphic presentation of information of a sample of 23 animated instructions was assessed. Then, an experimental study on understanding and preference of narrative times (slow, spontaneous and accelerated) was investigated with 25 participants for an animation representative of the sample analyzed: the 3D puzzle assembly. Based on the results of the studies, guidelines were proposed to the interactive digital guide which usability was validated with 05 experts through checklist with heuristics, and with 10 potential users through post-interaction interviews. The results were generally positive about the content and graphic interface, but pointed to the need of improvements in navigation and menu hierarchy. Accordingly, adjustments were then made in the interactive guide in its final version. © Springer International Publishing Switzerland 2015.","Animation; Assembling; Interactive guide; Visual instruction","Animation; Design; User centered design; Assembling; Communication effectiveness; Graphic interfaces; Graphic presentation; Interactive guide; Potential users; User-centered design approaches; Visual instruction; Human computer interaction",2-s2.0-84947285746
"Arslan E., Yuksel M., Gunes M.H.","Training network administrators in a game-like environment",2015,"Journal of Network and Computer Applications",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926160375&doi=10.1016%2fj.jnca.2015.03.005&partnerID=40&md5=7a8ecc234ee32c221eeb5b8b4a538282","Abstract Management and automated configuration of large-scale networks is one of the crucial issues for Internet Service Providers (ISPs). Since incorrect configurations may lead to loss of an enormous amount of customer traffic, highly experienced network administrators are typically the ones who are trusted for the management and configuration of a running ISP network. In this paper, we present an online management and experimentation system with a ""game"" interface to train network administrators and explore what-if scenarios without having to risk the large-scale network operation. The interactive environment treats the trainee network administrators as players of a game and tests them with various failures or dynamics for real-time management and configuration of large-scale networks. To prototype the concept of ""network management as a game"", we modified NS-2 to establish an interactive simulation engine and connected the modified engine to a graphical user interface for traffic animation and interactivity with the player. We also conducted two user experiments using different learning methods and observed sizable improvement in the capabilities of trainees on the problem of interior gateway protocol link weight setting. © 2015 Elsevier Ltd. All rights reserved.","Network management; Network operations; NS-2","Animation; Engines; Graphical user interfaces; Intelligent systems; Internet; Internet service providers; Network management; Personnel training; Risk perception; User interfaces; Automated configuration; Experimentation systems; Interactive Environments; Interactive simulations; Interior gateway protocol; Network administrator; Network operations; NS-2; Gateways (computer networks)",2-s2.0-84926160375
"Duan F., Huang D., Tian Y., Lu K., Wu Z., Zhou M.","3D face reconstruction from skull by regression modeling in shape parameter spaces",2015,"Neurocomputing",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919479161&doi=10.1016%2fj.neucom.2014.04.089&partnerID=40&md5=5ca5558ce2e3a8cb365ced144f3b67d3","Craniofacial reconstruction is to estimate a person[U+05F3]s face model from the skull. It can be applied in many fields such as forensic medicine, face animation. In this article, a regression modeling based method for craniofacial reconstruction is proposed, in which a statistical shape model is built for skulls and faces, respectively, and the relationship between them is extracted in the shape parameter spaces through partial least squares regression (PLSR). Craniofacial reconstruction is realized by using the relationship and the face statistical shape model. To better represent craniofacial shape variations and boost the reconstruction, both the skull and face are divided into five corresponding feature regions, and a mapping from each skull region to the corresponding face region is established. For an unknown skull, the five face regions are obtained through the five mappings, and the face is recovered by stitching the five face regions. The attributes such as age and body mass index (BMI) can be added into the mappings to achieve the face reconstruction with different attributes. Compared with other statistical learning based methods in literature, the proposed method more directly and reasonably reflects the relationship that the face shape is determined by the skull and influenced by some attributes. In addition, the proposed method does not need to locate landmarks, whose quantity and accuracy can highly affect the reconstruction. Experimental results validate the proposed method. © 2014 Elsevier B.V.","Craniofacial reconstruction; PLSR; Statistical shape model","Animation; Face recognition; Health; Mapping; Regression analysis; 3D face reconstruction; Craniofacial reconstruction; Face reconstruction; Forensic medicine; Partial least squares regressions (PLSR); PLSR; Statistical learning; Statistical shape model; Least squares approximations; accuracy; analytical parameters; anatomic landmark; Article; body mass; computer model; face; image processing; image reconstruction; mathematical parameters; partial least squares regression; simulation; skin surface; skull; statistical shape model; three dimensional imaging; uniform coordinate system; validation study",2-s2.0-84919479161
"Escudeiro P., Escudeiro N., Reis R., Rodrigues P., Lopes J., Norberto M., Baltasar A.B., Barbosa M., Bidarra J.","Real time bidirectional translator of Portuguese sign language",2015,"WEBIST 2015 - 11th International Conference on Web Information Systems and Technologies, Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945414092&partnerID=40&md5=c1d920cad8311aae39277f6068260366","The communication with deaf by means of written text is not as efficient as it might seem. In fact, there is a very deep gap between sign language and spoken/written language. The deployment of tools to assist the daily communication between deaf people and the rest may be a significant contribution to the social inclusion of the deaf community. The work described in this paper addresses the development of a bidirectional translator between Portuguese Sign Language and Portuguese text and a serious game to promote the learning of the Portuguese Sign Language. The translator from sign language to text employs two devices, namely the Microsoft Kinect and 5DT Sensor Gloves in order to gather data about the motion and shape of the hands. The hands configurations are classified using Support Vector Machines. The classification of the movement and orientation of the hands is achieved through the use of Dynamic Time Warping algorithm. The translator exhibits a precision higher than 90%. In the other direction, the translation of Portuguese text to Portuguese Sign Language is supported by a 3D avatar which interprets the entered text and performs the corresponding animations. As a complement, we also present a serious game directed to assist in the difficult task of learning the Portuguese Sign Language.","Avatar; Deaf; Dynamic Time Warping; Education; Kinect; Machine learning; Opencv; Portuguese Sign Language; Sensor Gloves; Serious games; Support Vector Machines; Translator","Animation; Artificial intelligence; Computational linguistics; Education; Information systems; Learning systems; Support vector machines; Three dimensional computer graphics; Wearable sensors; World Wide Web; Avatar; Deaf; Dynamic time warping; Kinect; Opencv; Sensor gloves; Serious games; Sign language; Translator; Translation (languages)",2-s2.0-84945414092
"Dzeka-Lozano N., Higuera-Burgos N., Vega-Medina L., Uribe-Quevedo A., Perez-Gutierrez B., Tibamoso G.","Development of an application for performing the subclavian central venous access on neonates",2015,"Conference Proceedings - 2014 IEEE Games, Media, Entertainment Conference, IEEE GEM 2014",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939222879&doi=10.1109%2fGEM.2014.7048107&partnerID=40&md5=c2746677439b9cecf477150f458c49a2","The Central Venous Access (CVA) is an invasive technique practiced in adults, children and neonates for supplying necessary nutritional solutions or medication. The procedure is mastered through practice and its incorrect or poor execution may lead to health risks such as infections, pneumothorax and even death. To develop the required skills for performing this procedure, teachers and students rely on common and traditional tools such as books, videos and multimedia content, complementing when available with hands-on practices on CVA simulators, however, the skills are fully developed through practice by performing the procedure on patients when sufficient knowledge has been proved and certified. This project addresses the limitations of traditional means of study for CVA by presenting an application for learning and practicing the subclavian procedure in neonates by presenting three modules: informative, evaluation and exploration, for assessing the student progress, while providing feedback in the form of scores and badges. The application uses virtual 3D models, animation and hypertext for providing context while allowing the exploration of the scenario. The goal of this application is to serve as a complimentary studying tool for the development of knowledge and skills related to the CVA technique with virtual reality. © 2014 IEEE.",,"Animation; Consumer electronics; Health risks; Hypertext systems; Students; Teaching; Virtual reality; Hands-on practice; Invasive techniques; Multimedia contents; Student progress; Studying tools; Virtual 3D model; Three dimensional computer graphics",2-s2.0-84939222879
"Okada N., Iwamoto N., Fukusato T., Morishima S.","Dance motion segmentation method based on choreographic primitives",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938829175&partnerID=40&md5=9d8df5aa78288e174077726b8b97f6a1","Data-driven animation using a large human motion database enables the programing of various natural human motions. While the development of a motion capture system allows the acquisition of realistic human motion, segmenting the captured motion into a series of primitive motions for the construction of a motion database is necessary. Although most segmentation methods have focused on periodic motion, e.g., walking and jogging, segmenting non-periodic and asymmetrical motions such as dance performance, remains a challenging problem. In this paper, we present a specialized segmentation approach for human dance motion. Our approach consists of three steps based on the assumption that human dance motion is composed of consecutive choreographic primitives. First, we perform an investigation based on dancer perception to determine segmentation components. After professional dancers have selected segmentation sequences, we use their selected sequences to define rules for the segmentation of choreographic primitives. Finally, the accuracy of our approach is verified by a user-study, and we thereby show that our approach is superior to existing segmentation methods. Through three steps, we demonstrate automatic dance motion synthesis based on the choreographic primitives obtained. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Choreographic primitives; Dance motion; Motion capture; Motion segmentation","Motion analysis; Choreographic primitives; Dance motion; Data-driven animation; Human motion database; Motion capture; Motion capture system; Motion segmentation; Realistic human motion; Computer graphics",2-s2.0-84938829175
"Serrano-Laguna Á., Rotaru D.-C., Calvo-Morata A., Torrente J., Fernández-Manjón B.","Creating interactive content in android devices: The mokap hackaton",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931082005&doi=10.1007%2f978-3-319-18425-8_31&partnerID=40&md5=ca8265624f798a0aac34ed1993f6e645","We propose the organization of a Mokap hackathon. In this activity participants will have the opportunity to develop interactive content using the Mokap Android app, either individually or in groups. Mokap is a new authoring tool for creating interactive content, developed by the e-UCM research group. It allows composing scenes by combining text, hand drawings, pictures and elements imported from an online repository. Mokap also supports basic animation and interaction. Users can take advantage of this functionality to create presentations, training materials, simulations, postcards and even simple games. We will start the activity with an introduction to Mokap, followed by a quick demo. Then we will help participants design their own mokaps and implement them. At the end of the activity participants will be given the possibility to share their mokaps with the rest of the audience. Participants will vote online to choose the best mokap developed during the session, which will be awarded a symbolic prize. © Springer International Publishing Switzerland 2015.","Authoring; Educational games; Interactive content; Mobile learning; Mokap; Serious games","Animation; Human computer interaction; Social networking (online); Authoring; Educational game; Interactive contents; Mobile Learning; Mokap; Serious games; Android (operating system)",2-s2.0-84931082005
"Li Z.-X., Wang Y.-D., Li L.","3D simulation of disaster process in mine ventilation system during fire period",2015,"Meitan Xuebao/Journal of the China Coal Society",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923802289&doi=10.13225%2fj.cnki.jccs.2014.0001&partnerID=40&md5=6625a4b00545bf56e534973f64a3dd4e","The mathematical model of disaster process in mine ventilation system during mine fire period was built based on source-containing ventilation network and previous fire studies, and the software TF1M(3D) was developed based on MATLAB. Combined with the typical mine ascensional airflow fire example, the airflow movement during fire period, the distribution of fume concentration and temperature, the ventilation system variations were simulated in a whole mine scale. Simulation results show that the air quantity in main airway increases with fire when ascensional airflow fire occurred in mine, while the airflow in the side branch of fire source decreases, stagnate and reverse; driven by fire burning power (fire ventilation pressure), overflowing quantity and reverse air quantity have consistent symmetry; and in complex ventilation network, reverse airflow in side branch orderly occurs. A series of changes of ventilation system during fire period are all produced by the interaction of ventilation power and fire ventilation pressure, which also lead to the dynamic drift of mine system total wind drag. This paper provides the relationship between fire severity and wind drag drift value. The software TF1M(3D) offers a good platform for analyzing mine fire because of its large amount of information, good animation and intuitive phenomenon. ©, 2015, China Coal Society. All right reserved.","3D visualization; Ascensional airflow fire; System disorder; Unsteady migration","Animation; Complex networks; Disasters; Drag; MATLAB; Mine fires; Mine ventilation; Three dimensional computer graphics; Ventilation; 3D Visualization; Complex ventilation; Fume concentrations; Mine ventilation systems; System disorder; Unsteady migration; Ventilation network; Ventilation systems; Fires",2-s2.0-84923802289
"Górski F., Buń P., Wichniarek R., Zawadzki P., Hamrol A.","Immersive City Bus Configuration System for Marketing and Sales Education",2015,"Procedia Computer Science",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963997690&doi=10.1016%2fj.procs.2015.12.230&partnerID=40&md5=619cb885adfd5099da93bf3ddd796aa8","The paper presents a Virtual Reality system developed as a result of cooperation of the University and an industrial company - a major city bus manufacturer. Main objective of work presented in the paper was to obtain a tool suitable for daily work with the clients on configuration of visual features of customized city buses. A city bus can have more than 100 visible features (options), which can be changed to obtain virtually infinite configuration possibilities. Visual representation of many of these features was largely unavailable before the presented work was commenced, resulting in certain problems in process of communication between salesmen and clients. The developed Virtual Reality system allows for visual representation of the bus functions during the configuration process, so it solves many problems in the client-company communication. It is also a knowledge base of all visual options which can be changed in scope of the configuration process - knowledge from many departments of the company was used to develop it, including knowledge unknown to representatives of sales and marketing. As a result, the immersive configurator can be effectively used to train salesmen and marketing representatives in terms of technical knowledge about customization capabilities of the offered product. The paper presents shortly the overview and functions of the whole system. The system is a large, multi-modal solution built of many software and hardware components and is also integrated with other, existing systems. It allows to display high-quality images of a configured bus in real-time in stereoscopic 3D on a large screen, as well as using professional Head-Mounted Display or low-cost systems (e.g. Oculus Rift) for a virtual walk inside the configured bus, with full integration between all the visualization instances. Interaction with the system is divided into several groups of functions - configuration, navigation, animation and extra functions. Different devices are used for interaction: joystick, gyroscopic mouse and gesture recognition systems like Kinect can be used for navigation and animation, while most of the configuration and extra functions are launched using a graphical user interface, operated using a touch screen or a tablet. Efficiency of the system in the visual configuration process was confirmed by representatives of the company. Capabilities of the system for education was tested using a sample of non-technical users from the sales and marketing department, using the system and then leaving their impressions in a survey study. It confirmed high effectiveness of the system in terms of presenting variability of the product features in a clear visual way. Immersive aspect of the system was also valued very high - usage of the stereoscopic 3D and Head-Mounted Device allowed to present the bus in a more realistic way than it was possible earlier. In the near future, the system will be fully developed and implemented to use in the sales process. © 2015 The Authors.","immersion; mass customization; variant product configuration; Virtual Reality","Animation; Augmented reality; Commerce; Education; Gesture recognition; Graphical user interfaces; Helmet mounted displays; Knowledge based systems; Marketing; Real time systems; Sales; Stereo image processing; Three dimensional computer graphics; Touch screens; User interfaces; Virtual reality; Configuration process; Gesture recognition system; immersion; Mass customization; Product configuration; Software and hardwares; Virtual reality system; Visual representations; Buses",2-s2.0-84963997690
"Patwardhan M., Murthy S.","When does higher degree of interaction lead to higher learning in visualizations? Exploring the role of 'Interactivity Enriching Features'",2015,"Computers and Education",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919782508&doi=10.1016%2fj.compedu.2014.11.018&partnerID=40&md5=6c732e0e77ceafadbbbcbec44921fb3b","Interactive visualizations are being used extensively for effective teaching and learning. Higher degree of interaction in visualizations improves comprehension and leads to deeper learning. However, some research studies have reported ambiguous, inconclusive results in terms of learning benefits of interactive visualizations. The conditional results in such studies suggest some additional features to be instrumental in assisting learners in deriving benefits of interactivity in visualizations. We refer to these features as 'Interactivity Enriching Features'. This study examines how degree of interaction of the user with the visualization affects learning outcome. The study proposes how interactivity in visualizations can be enriched by offering apt affordances and evaluates what additional features could make learning from interactive visualizations more effective at the same degree of interaction. The study has been carried out in the context of a course on Signals and Systems in Electrical Engineering on second year engineering students (N = 134). The subjects were assigned to one of the four conditions: a Non- Interactive Visualization, an Animation, a Simulation, and an Interactivity Enriched Visualization. The dependent variable was test-score for 'Understand conceptual knowledge', 'Understand procedural knowledge' and 'Apply procedural knowledge' categories. The research findings indicate that, i) different degrees of interaction are required for learning different types of knowledge and ii) interactive visualization could not deliver its learning benefits unless it was augmented by 'Interactivity Enriching Features' in the form of appropriate affordance for variable manipulation, especially for higher learning outcomes. This research study contributes towards the design of educationally effective interactive visualizations. © 2014 Elsevier Ltd. All rights reserved.","Affordance; Engineering education; Interactive learning environments; Multimedia learning; Simulations","Animation; Computer aided instruction; Concentration (process); Engineering education; Teaching; Affordances; Conceptual knowledge; Degree of interaction; Interactive learning environment; Interactive visualizations; Multi-media learning; Procedural knowledge; Simulations; Visualization",2-s2.0-84919782508
"Kate L.S., Waghmare M.M., Priyadarshi A.","An approach for automated video indexing and video search in large lecture video archives",2015,"2015 International Conference on Pervasive Computing: Advance Communication Technology and Application for Society, ICPC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929241099&doi=10.1109%2fPERVASIVE.2015.7087169&partnerID=40&md5=f824a66f313f9710f8dea83f320d5f1d","E-Learning is the use of educational technology, communication and information technologies and electronic media in education. E learning contains various types of media including images, video, audio, streaming videos, animation, web based learning, video based learning, audio based learning, E books etc. Distance learning can be done without school or collages, anyone can learn from their home or office. E- Learning industry is economically remarkable and it was work out in 2000 to be above 50$ billion corresponding to traditionalist estimates. Lecture Audio, video data on internet is growing rapidly. Hence there is immediate need for method by which we can retrieve audio, videos on internet. In this paper we have presented a technology for video search in lecture video archive. Initially, we can introduce segmentation of videos and key frame detection for offering rules for navigation of video contents. By applying ASR (Automatic Speech Recognition) on lecture audio and OCR (Optical Character Recognition) on video content we can extract metadata. OCR can be used in Data entry for business document, Automatic Number plate Recognition, Extracting business card information into a contact list and so on.ICR (Intelligent character recognition) focuses on handwritten documents as well as cursive character one at a time usually it involves in Machine Learning. Speech recognition system can classify into continuous or discrete system which can be speaker independent, speaker dependent or adaptive. Discrete system focuses on a separate acoustic model for each single word, sentence, phrase etc. are said to be isolated word speech recognition (ISR). CSR (Continuous Speech Recognition) System focuses on user who speaks sentences continually. © 2015 IEEE.","acoustic model; Machine Learning; metadata; segmentation; streaming videos","Adaptive optics; Animation; Artificial intelligence; Automatic vehicle identification; Character recognition; Computer aided instruction; Continuous speech recognition; Distance education; E-learning; Educational technology; Engineering education; Image segmentation; Indexing (of information); Internet; Learning systems; Media streaming; Metadata; Optical character recognition; Social networking (online); Speech processing; Ubiquitous computing; Video recording; Acoustic model; Automatic number plate recognition; Automatic speech recognition; Handwritten document; Intelligent character recognition; Isolated word speech recognition; Speech recognition systems; Streaming videos; Speech recognition",2-s2.0-84929241099
"Subhashini P.V.S., Raju N.V.S., Venkata Rao G.","Studies on robotic deburring of machined components using a SCARA robot",2015,"Proceedings of 2015 International Conference on Robotics, Automation, Control and Embedded Systems, RACE 2015",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934774950&doi=10.1109%2fRACE.2015.7097238&partnerID=40&md5=ec4f1ba1568a7bb175f42e61d20282c9","In this paper, the complex aspect of deburring of machined components while using a Selective Compliance Assembly Robot Arm (SCARA) robot is analyzed. There are two practices followed in robotic deburring, viz., the work piece is held by the robot's gripper while the deburring tool is external to the robot and the second mode, the deburring tool is held by the gripper with the work piece is held in a fixture external to the robot. The second mode is the focus of the present paper. In deburring operations, the forces exerted are very small in the case of small and medium sized components machined earlier by fine cuts with a small depth of cut, and therefore the deburring forces are neglected in the present analysis. A SCARA robot fabricated in-house has been utilized for the video graphic analysis. The recorded video is analyzed using any of the many video players to trace the path taken by the robot's quill. This data is utilized as inputs for the mathematical analysis and animation studies. Kinematic equations of a SCARA robot are derived using Denavit- Hartenberg notation. Mathematical equations for kinematic parameters and torques are derived. Kinematic parameters include joint angles, joint velocities, and joint accelerations. Mathematical analysis has been carried out using MATLAB software. The same SCARA robot is modelled and simulated for the path taken during deburring using CAD software and the analysis is carried for kinematic parameters .Comparisons are made for results obtained by the above mentioned three methods and graphs are drawn for joint angles, joint velocities, joint accelerations. Important conclusions are drawn for the robotic deburring operations using SCARA robots. © 2015 Hindustan University.","Deburring; kinematics; modeling and analysis; SCARA robot; video graphic analysis","Animation; Computer aided design; Deburring; Embedded systems; Grippers; Kinematics; Machine tools; MATLAB; Robotic arms; Robots; Graphic analysis; Kinematic parameters; Mathematical analysis; Mathematical equations; Model and analysis; SCARA robot; Selective compliance assembly robot arm robots; Small depth of cuts; Robotics",2-s2.0-84934774950
"Ichim A.E., Bouazizy S., Paulyz M.","Dynamic 3D avatar creation from hand-held video input",2015,"ACM Transactions on Graphics",27,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947229810&doi=10.1145%2f2766974&partnerID=40&md5=71fb1b98b5e1b56efbb9247643e4eddb","We present a complete pipeline for creating fully rigged, personalized 3D facial avatars from hand-held video. Our system faithfully recovers facial expression dynamics of the user by adapting a blendshape template to an image sequence of recorded expressions using an optimization that integrates feature tracking, optical flow, and shape from shading. Fine-scale details such as wrinkles are captured separately in normal maps and ambient occlusion maps. From this user- and expression-specific data, we learn a regressor for on-the-fly detail synthesis during animation to enhance the perceptual realism of the avatars. Our system demonstrates that the use of appropriate reconstruction priors yields compelling face rigs even with a minimalistic acquisition system and limited user assistance. This facilitates a range of new applications in computer animation and consumer-level online communication based on personalized avatars. We present realtime application demos to validate our method. Copyright is held by the owner/author(s).","3D avatar creation; Blendshapes; Face animation; Rigging",,2-s2.0-84947229810
"Samoui S., El Bouabidi I., Obaidat M.S., Zarai F., Hsiao K.F., Kamoun L.","Improved IPSec tunnel establishment for 3GPP-WLAN interworking",2015,"International Journal of Communication Systems",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925135193&doi=10.1002%2fdac.2769&partnerID=40&md5=42b89781c2a9d93fc2ca4d4b5265ad21","Interworking between wireless local area network (WLAN) and the 3rd Generation Partnership Project (3GPP) such as Long Term Evolution (LTE) is facing more and more problems linked to security threats. Securing this interworking is a major challenge because of the vastly different architectures used within each network. Therefore, security is one of the major technical concerns in wireless networks that include measures such as authentication and encryption. Among the major challenges in the interworking security is the securing of the network layer. The goal of this article is twofold. First, we propose a new scheme to secure 3GPP LTE-WLAN interworking by the establishment of an improved IP Security tunnel between them. The proposed solution combines the Internet Key Exchange (IKEv2) with the Host Identity Protocol (HIP) to set up a security association based on two parameters, which are location and identity. Our novel scheme, which is called HIP-IKEv2, guarantees better security properties than each protocol used alone. Second, we benefit from Mobile Internet Key Exchange protocol (MOBIKE) in case of mobility events (handover). And we extend HIP-IKEv2 to HIP-MOBIKEv2 protocol in order to reduce the authentication signaling traffic. The proposed solution reinforces authentication, eliminates man-in-the-middle attack, reduces denial-of-service attack, assures the integrity of messages, and secures against reply attack. Finally, our proposed solution has been modeled and verified using the Automated Validation of Internet Security Protocols and Applications and the Security Protocol Animator, which has proved its security when an intruder is present. Copyright © 2014 John Wiley & Sons, Ltd.","3GPP LTE; AVISPA; Interworking; Security; WLAN","Animation; Authentication; Computer crime; Denial-of-service attack; Internet; Internet protocols; Local area networks; Long Term Evolution (LTE); Mobile security; Mobile telecommunication systems; Network layers; Telecommunication networks; Wireless local area networks (WLAN); Wireless telecommunication systems; 3gpp lte; AVISPA; Interworking; Security; WLAN; Network security",2-s2.0-84925135193
"Mokhtar S.A., Anuar S.M.S.","Learning application for Malaysian sign language: Content design, user interface and usability",2015,"ACM IMCOM 2015 - Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926163040&doi=10.1145%2f2701126.2701142&partnerID=40&md5=8f299a0f1d2d8917c85113108bf2394a","In spite of the assistance and encouragement from the government, there is still an apparent lack of learning applications for the deaf, especially based on local content. The paper describes an application for the learning of Malaysian Sign Language. The focus of the paper is on the content design, user interface and usability of the application. The paper highlights how the application was designed to incorporate local needs and culture of Malaysia. The medium of communication for the application is in Bahasa Melayu and English. It uses an animated character to illustrate the different signs. It also integrates audio and text narration for better content delivery.","Animation; Hearing-impaired; Learning application; Multimedia; Sign language; Usability; User-interface","Animation; Audition; Computational linguistics; Computer aided instruction; Information management; Animated characters; Content delivery; Content design; Hearing impaired; Local contents; Multimedia; Sign language; Usability; User interfaces",2-s2.0-84926163040
"Moreland J., Zaraliakos J.E., Campbell W., Nakayama S., Zhang J., Arteaga N., Zhou C.Q.","Interactive incident visualization for steel industry safety training",2015,"AISTech - Iron and Steel Technology Conference Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940403844&partnerID=40&md5=e9b96c800c8532a9bae8684a6ad985e1","Hazard Control can be accomplished through various means, including eliminating the hazard from the environment, engineering control, warning devices, training, and PPE. Safety training has been shown to be most effective when it is engaging for trainees. This project explores the application of interactive 3D software to enhance safety training. 3d models are used to re-create a work environment and introduce hazards. The Unity 3D game engine is used to create an interactive experience, allowing trainees to control an avatar in the environment, recognize safety hazards, and learn about the actions that can be taken to prevent incidents from occurring. The resulting interactive 3D Environment can be used on PC, but can also leverage lowcost consumer virtual reality devices such as head mounted displays to provide an immersive training environment. The software was created through collaboration between Purdue University Calumet and Nucor Steel-Indiana. Development and initial results will be discussed. © 2015 by AIST.","3D; Animation; Hazard; Safety; Simulation; Training; Visualization","Accident prevention; Animation; Application programs; Display devices; Flow visualization; Hazards; Helmet mounted displays; Personnel training; Safety engineering; Steelmaking; Virtual reality; Visualization; 3-D environments; Engineering controls; Head mounted displays; Nucor Steel-Indiana; Purdue University Calumet; Simulation; Virtual reality devices; Work environments; Three dimensional computer graphics",2-s2.0-84940403844
"Pillias C., Cubaud P.","Bilingual reading experiences: What they could be and how to design for them",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945548840&doi=10.1007%2f978-3-319-22701-6_39&partnerID=40&md5=2f9fbded424d4f43c09f311a6000e22d","We introduce the idea of bilingual reading, where a document comes in two languages and the reader can choose at will on which language to focus during the reading. Between the complete ignorance of a language (where translation is the only option) and bilingualism (where translation is useless), there exists a variety of contexts of partial bilingualism where bilingual reading interfaces would prove highly useful. We first study through interviews and reviews how the bilingual reading experience is understood today. We provide an analysis framework and highlight design challenges for the design of bilingual reading appliances. We then describe a taxonomy of the different approaches available to address these challenges, analyze them in the light of our framework and show how they can be derived to sketch future bilingual reading interfaces. © IFIP International Federation for Information Processing 2015.","Bilingual reading; E-book; E-reader; Mechanisms of reading; Nexus of attention; Parallel text; Text animation; Text morphing","Computational linguistics; Translation (languages); Bilingual reading; E-books; E-reader; Morphing; Nexus of attention; Parallel text; Text animation; Human computer interaction",2-s2.0-84945548840
"Combemale B., DeAntoni J., Barais O., Blouin A., Bousse E., Brun C., Degueule T., Vojtisek D.","A solution to the TTC'15 model execution case using the GEMOC studio",2015,"CEUR Workshop Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962515889&partnerID=40&md5=82ab301e5bd6c6bd5b3ffdefa7bb0931","We present in this paper a complete solution to the Model Execution case of the Transformation Tool Contest 2015 using the GEMOC Studio. The solution proposes an implementation of the most complete version (variant 3) of the UML Activity Diagram language. The implementation uses different technologies integrated into the GEMOC Studio for implementing the various concerns of the language: Kermeta is used to modularly implement the operational semantics and to weave it into the provided metamodel, Melange is used to build the overall language runtime seamlessly integrated to EMF, Sirius Animator is used to develop a graphical animator, the GEMOC execution engine is used to execute the conforming models according to the operational semantics and to build a rich and efficient execution trace that can be manipulated through a powerful timeline, which provides common facilities like, for instance trace visualization, and step-by-step execution (incl. breakpoint, step forward and step backward). Finally, MoCCML is used to provide an alternative to the implementation with an explicit and formal concurrency model for activity diagrams supported by a solver and analysis tools. We evaluate our implementation with regard to the evaluation criteria provided in the case description and give evidence of the correctness, understandability, conciseness and performance of our solution. © 2015 G. Szárnyas et al.",,"Animation; Computational linguistics; Computer programming languages; Semantics; Studios; Systems analysis; Complete solutions; Concurrency modeling; Evaluation criteria; Operational semantics; Trace visualization; Transformation tools; UML activity diagrams; Understandability; Application programs",2-s2.0-84962515889
"Allen L.K., Bhattacharyya S., Wilson T.D.","Development of an interactive anatomical three-dimensional eye model",2015,"Anatomical Sciences Education",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928250470&doi=10.1002%2fase.1487&partnerID=40&md5=a9f17d60e6895c0c4d71b8f66192e567","The discrete anatomy of the eye's intricate oculomotor system is conceptually difficult for novice students to grasp. This is problematic given that this group of muscles represents one of the most common sites of clinical intervention in the treatment of ocular motility disorders and other eye disorders. This project was designed to develop a digital, interactive, three-dimensional (3D) model of the muscles and cranial nerves of the oculomotor system. Development of the 3D model utilized data from the Visible Human Project (VHP) dataset that was refined using multiple forms of 3D software. The model was then paired with a virtual user interface in order to create a novel 3D learning tool for the human oculomotor system. Development of the virtual eye model was done while attempting to adhere to the principles of cognitive load theory (CLT) and the reduction of extraneous load in particular. The detailed approach, digital tools employed, and the CLT guidelines are described herein. Anat Sci Educ 8: 275-282. © 2014 American Association of Anatomists.","Animation; Cognitive load; Computer-assisted learning; Eye virtual model; Gross anatomy education; Medical education; Oculomotor system; Ophthalmology; Three-dimensional modeling; Undergraduate education","anatomic model; anatomy; anatomy and histology; cognition; education; eye; human; medical education; multimedia; procedures; simulation training; three dimensional imaging; trends; Anatomy; Cognition; Education, Medical, Undergraduate; Eye; Humans; Imaging, Three-Dimensional; Models, Anatomic; Multimedia; Simulation Training",2-s2.0-84928250470
"Madera F.A., Ayala E., Moo-Mena F.","Self-collision detection using sphere chains",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938880276&partnerID=40&md5=eb253bfe7113dd0111bc9a954638cf72","An algorithm to detect self-collisions in a human object is presented. We proposed to approximate the human object by spheres, which are placed inside the object mesh to fill the correspondent volume. We introduce the concept of sphere chain, a set of joined spheres which contains some regions of the human mesh. The object is approximated by several chains in the preprocessing stage to be prepared for the running stage to perform the collision detection. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Approximation with spheres; Collision detection; Human animation","Algorithms; Chains; Mesh generation; Object detection; Spheres; Collision detection; Human animation; Self-collision detection; Computer graphics",2-s2.0-84938880276
"Lokesh R., Chittawadigi R.G., Saha S.K.","MechAnalyzer: 3D simulation software to teach kinematics of machines",2015,"2nd International and 17th National Conference on Machines and Mechanisms, iNaCoMM 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015236923&partnerID=40&md5=169cb0e7597bf78efebb593186c15d91","Theory of Machine course includes kinematics and dynamics of mechanisms and machines. Though it is an important part of Mechanical Engineering curriculum, it is often difficult for teachers to teach and students to learn the concepts related to mechanisms, by just following text-books. With physical prototypes or virtual mechanisms in a software environment, the course can be taught in a lucid and effective way. While several commericial and free software exist that can be used to compliment the teaching and learning, a significant amount of time is required to learn the software first, and then use it. In this paper, MechAnalyzer (Version 3) software is presented which has a very simple to use interface and an easy learning curve. An user can select from any of the available mechanism and change the input parameters. A 3D model of the selected mechanism with linkages and joints are generated and shown to the user in a 3D environment, whose motion can be animated and seen. The main advantage of MechAnalyzer is that it has been developed as a framework with modules making it easier for developers to add new mechanisms. The authors would like to include as many mechanisms as possible to make it a digital library of mechanism and perform analyses on them. © 2015, Indian Institute of Technology, IIT. All rights reserved.","Animation; Education; Kinematic analysis; Mechanisms simulation","Animation; Computer software; Curricula; Digital libraries; Education; Education computing; Kinematics; Mechanisms; 3-D environments; Kinematic Analysis; Kinematics and dynamics; Learning curves; Mechanical engineering curriculum; Software environments; Teaching and learning; Virtual mechanism; Teaching",2-s2.0-85015236923
"Goldberg D.B.","Computer-animated model of accommodation and presbyopia",2015,"Journal of Cataract and Refractive Surgery",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923102633&doi=10.1016%2fj.jcrs.2014.07.028&partnerID=40&md5=9c3d330d48775428a36f4d71c79850c6","Purpose To understand, demonstrate, and further research the mechanisms of accommodation and presbyopia. Setting Private practice, Little Silver, New Jersey, USA. Design Experimental study. Methods The CAMA 2.0 computer-animated model of accommodation and presbyopia was produced in collaboration with an experienced medical animator using Autodesk Maya animation software and Adobe After Effects. Results The computer-animated model demonstrates the configuration and synchronous movements of all accommodative elements. A new classification of the zonular apparatus based on structure and function is proposed. There are 3 divisions of zonular fibers; that is, anterior, crossing, and posterior. The crossing zonular fibers form a scaffolding to support the lens; the anterior and posterior zonular fibers work reciprocally to achieve focused vision. The model demonstrates the important support function of Weiger ligament. Dynamic movement of the ora serrata demonstrates that the forces of ciliary muscle contraction store energy for disaccommodation in the elastic choroid. The flow of aqueous and vitreous provides strong evidence for our understanding of the hydrodynamic interactions during the accommodative cycle. The interaction may result from the elastic stretch in the choroid transmitted to the vitreous rather than from vitreous pressue. The model supports the concept that presbyopia results from loss of elasticity and increasing ocular rigidity in both the lenticular and extralenticular structures. Conclusion The computer-animated model demonstrates the structures of accommodation moving in synchrony and might enhance understanding of the mechanisms of accommodation and presbyopia. Financial Disclosure Dr. Goldberg is a consultant to Acevision, Inc., and Bausch & Lomb. © 2015 ASCRS and ESCRS.",,"accommodation; anterior eye chamber; Article; Bruch membrane; choroid; ciliary body; ciliary muscle; computer model; elastic fiber; elasticity; experimental study; hydrodynamics; lens; lens capsule; ligament; presbyopia; priority journal; sclera; thickness; trabecular meshwork; vision; vitreous body; Weiger ligament; zonular fiber; accommodation; computer simulation; human; middle aged; pathophysiology; physiology; presbyopia; Accommodation, Ocular; Ciliary Body; Computer Simulation; Elasticity; Humans; Lens, Crystalline; Ligaments; Middle Aged; Presbyopia",2-s2.0-84923102633
"Heinze F., Wolf F., Weisner K., Rossmann J., Deuse J., Kuhlenkoetter B.","Motion capturing for the simulation of manual industrial processes",2015,"13th International Industrial Simulation Conference 2015, ISC 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963606429&partnerID=40&md5=abd3b90e2e94dd61aa4a4bf97588debd","The appearance of service robots and lightweight robots pave the way for a direct collaboration of robots and humans in industrial production facilities. Thus, the areas of industrial robotics and service robotics begin to merge to the new area of industrial service robotics. The evaluation of manual processes regarding their potential for automation remains a highly complex task. The objective of the project MANUSERV is to develop a planning and decision support system for selecting industrial service robots in order to fully or partially automate manual processes. A simulation system compares the initial manual process and the proposed (semi-) automatic process. Before an analysis of manual processes is possible, they have to be included into the simulation of the whole production process. This paper focuses on the process of integrating human motion sequences from an industrial production process into a 3D simulation environment. The human motion is captured and digitalized with the aid of a motion capture system. The gained data is converted into a standard computer animation file format, and subsequently mapped to an existing digital model of the human body. Thus, the described workflow allows the analysis of the manual process based on the generated computer model.","Manual processes; MANUSERV; Motion capturing; Service robotics; Virtual human","Animation; Artificial intelligence; Decision support systems; Mobile robots; Robot learning; Robotics; Robots; Virtual reality; Manual process; MANUSERV; Motion capturing; Service robotics; Virtual humans; Robot programming",2-s2.0-84963606429
"Zhang Z., Li G., Lu H., Ouyang Y., Yin M., Xian C.","Fast as-isometric-as-possible shape interpolation",2015,"Computers and Graphics (Pergamon)",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908454349&doi=10.1016%2fj.cag.2014.09.005&partnerID=40&md5=d8fb188744b3588124d7ab222e8e6872","Shape interpolation, as a bridge communicating static geometries and dynamic shape sequences, is a fundamental operation in digital geometry processing and computer animation. We propose a fast as-isometric-as-possible (AIAP) 3D mesh interpolation approach which casts the shape interpolation problem to finding an AIAP motion trajectory from the start shape to the end shape. This leads to a nonlinear optimization problem with all intermediate shapes as unknowns. The block-coordinate descent method is then employed to iteratively solve the optimization. In each iteration, we need to solve two linear equations whose dimensionality can further be reduced based on a decoupling strategy. Connection maps between orthogonal frames of adjacent edges are further introduced for producing an initial shape sequence in order to address the large-scale deformation problem. A propagation-optimization strategy is then presented to quickly reconstruct the orthogonal frames of all edges from connection maps as well as the orthogonal frame of a specified edge. Refinement of edge quality is available in our method due to the AIAP iterative procedure. In the end, a shape manipulation framework is established for shape sequence transfer and shape sequence editing. © 2014 Elsevier Ltd.","As-isometric-as-possible; Shape interpolation; Shape sequence editing; Shape sequence transfer","Animation; Geometry; Iterative methods; Nonlinear programming; Optimization; Coordinate descent methods; Digital geometry processing; Fundamental operations; Large-scale deformation; Non-linear optimization problems; Shape interpolation; Shape sequence editing; Shape sequence transfer; Interpolation",2-s2.0-84908454349
"Joy Prabhakaran P., Poonacha P.G.","A new decimation and interpolation algorithm and an efficient lossless compression technique for images",2015,"2015 21st National Conference on Communications, NCC 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929120121&doi=10.1109%2fNCC.2015.7084824&partnerID=40&md5=e7d8fc3d261ae6b50cddf03cbc92705a","Efficient lossless compression using decimation and interpolation algorithms with low complexity and high quality is an important goal for multi-media distribution over the internet. This is because content is consumed at different sizes and over networks with different bandwidths. It is also because informational content, large screen advertisements, professional video and high quality computer animation have different quality requirements. In this paper we propose and study a novel decimation and interpolation scheme. Our method compares well in terms of PSNR with well-known Bi-cubic interpolation as well as other computationally more expensive methods available in the literature. We have compared the efficiency of our method with Bi-cubic in terms of computational complexity. In the second part of the paper we have used our decimation and interpolation scheme for developing a new lossless compression technique for images. This falls broadly under the spatial hierarchy schemes. Literature consists of many attempts to use decimation and interpolation for lossy compression of images. We have compared the efficiency of our method with Bi-cubic interpolation based approach. On an average our method has better compression efficiency than methods like lossless JPEG. Our experimental results show that ZIP, PNG and TIFF are 27%, 57% and 42% poorer in terms of compression efficiency respectively. However, this comes at the cost of increased computational complexity. © 2015 IEEE.","compression; decimation; interpolation; PSNR; resolution","Algorithms; Animation; Compaction; Complex networks; Computational complexity; Efficiency; Interpolation; Optical resolving power; Bicubic interpolation; Compression efficiency; decimation; Interpolation algorithms; Interpolation schemes; Lossless compression; Lossless compression techniques; PSNR; Image compression",2-s2.0-84929120121
"Xu H., Li Y., Chen Y., Barbič J.","Interactive material design using model reduction",2015,"ACM Transactions on Graphics",26,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924039729&doi=10.1145%2f2699648&partnerID=40&md5=df5e5db47257c7d58ea34be2872598aa","We demonstrate an interactive method to create heterogeneous continuous deformable materials on complex three-dimensionalmeshes. The user specifies displacements and internal elastic forces at a chosen set ofmesh vertices. Our system then rapidly solves an optimization problem to compute a corresponding heterogeneous spatial distribution of material properties using the Finite Element Method (FEM) analysis. We apply our method to linear and nonlinear isotropic deformable materials. We demonstrate that solving the problem interactively in the full-dimensional space of individual tetrahedron material values is not practical. Instead, we propose a new model reduction method that projects the material space to a low-dimensional space of material modes. Our model reduction accelerates optimization by two orders of magnitude andmakes the convergence much more robust,making it possible to interactively design material distributions on complex meshes. We apply our method to precise control of contact forces and control of pressure over large contact areas between rigid and deformable objects for ergonomics. Our tetrahedron-based dithering method can efficiently convert continuous material distributions into discrete ones and we demonstrate its precision via FEM simulation. We physically display our distributions using haptics, as well as demonstrate how haptics can aid in the material design. The produced heterogeneous material distributions can also be used in computer animation applications. © 2015 ACM.","Design; Fem; Interactive; Material design; Materials; Model reduction","Animation; Computational mechanics; Deformation; Design; Ergonomics; Geometry; Materials; Optimization; Finite element method analysis; Heterogeneous materials; Interactive; Low-dimensional spaces; Material designs; Model reduction; Model reduction method; Optimization problems; Finite element method",2-s2.0-84924039729
"Dupac M.","Spatial impact of a beam attached to a sliding structure",2015,"Proceedings of the ECCOMAS Thematic Conference on Multibody Dynamics 2015, Multibody Dynamics 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979500773&partnerID=40&md5=992e91d86d70f339adbfac8f9c3c71f8","Dynamic simulation of impact in multibody system is of great interest for scientists and engineers in many different areas - robotics, biomechanics, computer animations and/or virtual reality are just a few examples. Simple or multiple impacts/collisions - contact event(s) that occurs at a common point of contact - in multibody dynamics presents many challenges. Due to the complexity of the impact dynamics, the development of various methods for predicting the behavior multibody systems (as for example kinematic chains) after collision is considered desirable. Analytical solutions of the post impact velocities (in terms of pre-impact velocities) may be obtained through the use of the classical rigid body collision theory formulated in terms of Newton's fundamental principles (law of motion) and Coulomb's friction model. In addition, the knowledge of some material constants such as coefficient of restitution and coefficient of friction are required. In this paper, the dynamics of a spatial impact of a rigid beam attached to a sliding structure-two-link chain-with an external surface is considered. The normal impulsive forces - considered in differential formulation of the equations of impact - are determined by combining the elastic-plastic indentation theory with the classical Hertzian contact theory. To reflect dissipation in the contact/impact area and energy loss during impact the force-deformation model includes damping. Velocity and kinetic energy are investigated for different incident impact angles of the beam in an impact process which consider friction at the contact point. The two-link chain - beam and sliding mass-impact is studied numerically. Further acquired experimental data should be compared with the numerical results for validation and generalisation.","Dynamics; Energy; Impact; Kinematic chain; Multibody systems","Animation; Chains; Elastoplasticity; Energy dissipation; Friction; Kinematics; Kinetic energy; Kinetics; Robotics; Tribology; Virtual reality; Coefficient of frictions; Coefficient of restitution; Differential formulations; Energy; Impact; Kinematic chain; Multi Body Systems; Scientists and engineers; Dynamics",2-s2.0-84979500773
"Selnihhin D., Andersen E.S.","Computer-aided design of DNA origami structures",2015,"Methods in Molecular Biology",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84917690646&doi=10.1007%2f978-1-4939-1878-2_2&partnerID=40&md5=64187d935f6c91646add1d1fffad7502","The DNA origami method enables the creation of complex nanoscale objects that can be used to organize molecular components and to function as reconfigurable mechanical devices. Of relevance to synthetic biology, DNA origami structures can be delivered to cells where they can perform complicated sense-andact tasks, and can be used as scaffolds to organize enzymes for enhanced synthesis. The design of DNA origami structures is a complicated matter and is most efficiently done using dedicated software packages. This chapter describes a procedure for designing DNA origami structures using a combination of state-ofthe- art software tools. First, we introduce the basic method for calculating crossover positions between DNA helices and the standard crossover patterns for flat, square, and honeycomb DNA origami lattices. Second, we provide a step-by-step tutorial for the design of a simple DNA origami biosensor device, from schematic idea to blueprint creation and to 3D modeling and animation, and explain how careful modeling can facilitate later experimentation in the laboratory. © Springer Science+Business Media New York 2015.","Biosensor; CAD; DNA; Nanotechnology; Origami; Software","Article; biosensor; computer aided design; computer program; crossing over; DNA helix; DNA structure; enzyme synthesis; molecular model; synthetic biology",2-s2.0-84917690646
"Jones L.L., Kelly R.M.","Visualization: The Key to Understanding Chemistry Concepts",2015,"ACS Symposium Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949545960&doi=10.1021%2fbk-2015-1208.ch008&partnerID=40&md5=6d9f3b59ba2fd875d8706cbaab9eeb4c","Chemistry is a science that operates at many levels, but perhaps the most fascinating is the level that explores the complexities of chemistry at the invisible molecular level. Over the years chemists have devised ever more useful and complex representations of molecular-level structures and interactions. The introduction of computers in the latter half of the 20th century led to the development of powerful visualization and modeling tools that have enhanced chemistry research capabilities. These techniques allowed more accurate and informative images of the molecular level to be generated for use in education, and animations were developed to communicate how atoms and molecules might interact and move. Assessment of conceptual understanding was also updated to reflect the use of visualizations in the learning of chemistry. Because scientific visualizations and animations can be complex and difficult to understand, multidisciplinary teams are now studying how the use of visualization techniques in the teaching and learning of chemistry can be optimized. These collaborations are revealing how students perceive and interpret various kinds of molecular animations and are showing how best to develop and use static graphics and dynamic visualizations for the learning of chemistry. © 2015 American Chemical Society.",,"Chemistry concepts; Chemistry research; Conceptual understanding; Dynamic visualization; Molecular animation; Multi-disciplinary teams; Teaching and learning; Visualization technique; Visualization",2-s2.0-84949545960
"Frude N., Jandrić P.","The intimate machine – 30 years on",2015,"E-Learning and Digital Media",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945965987&doi=10.1177%2f2042753015571830&partnerID=40&md5=6187ae3139a10f647201effc6b3b6324","This conversation focuses on a book published in 1983 that examined ‘animism’, the tendency to regard non-living entities as living and sentient. The Intimate Machine suggested that animism will be fully exploited by artificial intelligence (AI) and robotics, generating artefacts that will engage the user in ‘social’ interactions so that eventually people will form close and beneficial social relationships with artificial ‘companion systems’. The author of the book, clinical psychologist Neil Frude, is asked to reflect on his book and, although he admits that his techno-optimism in the 1980s was exaggerated, it is clear that he still holds to his major thesis. He considers ‘virtual pets’, such as Tamagotchi, Furby and Sony’s Aibo, and considers why they did not evolve into more sophisticated social artefacts. Frude identifies three vital elements needed for a successful artificial companion – animism, artistry and AI – and acknowledges that the last of these has been the weak link. However, even simple AI programs can make an impressive impact when skilfully implemented. He emphasizes the relevance of characterization, pointing to examples in recent computer- generated animations. In the context of interactive technology, the addition of character and artificial personality will generate companion machines that are highly engaging and exceptionally appealing. Insights into the likely nature and roles of artificial companions, and how people will relate to them, are available in the science fiction corpus, and this literature has also examined relevant ethical and social issues. Finally, he considers some of the possible clinical applications of such systems in both physical health and mental health and he also reflects on some of the potential dangers of the kind of artefact that he is envisioning. © The Author(s) 2015.","Animation; Animism; Artificial intelligence; Companion machines; Human–computer interaction; Intimate machine; Neil Frude; Robotics",,2-s2.0-84945965987
"Izadi E., Bezuijen A.","Simulation of granular soil behaviour using the Bullet physics library",2015,"Geomechanics from Micro to Macro - Proceedings of the TC105 ISSMGE International Symposium on Geomechanics from Micro to Macro,  IS-Cambridge 2014",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907379878&partnerID=40&md5=8f33fc1b448d36b260bb7ac452796ebe","A physics engine is computer software which provides a simulation of certain physical systems, such as rigid body dynamics, soft body dynamics and fluid dynamics. Physics engines were firstly developed for using in animation and gaming industry; nevertheless, due to fast calculation speed they are attracting more and more attention from researchers of the engineering fields. Since physics engines are capable of performing fast calculations on multibody rigid dynamic systems, soil particles can be modeled as distinct rigid bodies. However, up to date, it is not clear to what extent they perform accurately in modeling soil behaviour from a geotechnical viewpoint. To investigate this, examples of pluviation and vibration-induced densification were simulated using the physics engine called Bullet physics library. In order to create soil samples, first, randomly shaped polyhedrons, representing gravels, were generated using the Voronoi tessellation approach. Then, particles were pluviated through a funnel into a cylinder. Once the soil particles settled in a static state, the cylinder was subjected to horizontal sinusoidal vibration for a period of 20 seconds. The same procedure for sample preparation was performed in the laboratory. The results of pluviation and vibration tests were recorded and compared to those of simulations. A good agreement has been found between the results of simulations and laboratory tests. The findings in this study reinforce the idea that physics engines can be employed as a geotechnical engineering simulation tool. © 2015 Taylor & Francis Group.",,"Animation; Engines; Geomechanics; Geotechnical engineering; Rigid structures; Engineering fields; Fast calculations; Laboratory test; Physical systems; Rigidbody dynamics; Sample preparation; Sinusoidal vibration; Voronoi tessellations; Soils",2-s2.0-84907379878
"Vallet A., Sakamoto H.","A multi-label convolutional neural network for automatic image annotation",2015,"Journal of Information Processing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947245532&doi=10.2197%2fipsjjip.23.767&partnerID=40&md5=f6d018df81c1dcaed3ff84bd87a64f55","Over the past few years, convolutional neural networks (CNN) have set the state of the art in a wide variety of supervised computer vision problems. Most research effort has focused on single-label classification, due to the availability of the large scale ImageNet dataset. Via pre-training on this dataset, CNNs have also shown the ability to outperform traditional methods for multi-label classification. Such methods, however, typically require evaluating many expensive forward passes to produce a multi-label distribution. Furthermore, due to the lack of a large scale multi-label dataset, little effort has been invested into training CNNs from scratch with multi-label data. In this paper, we address both issues by introducing a multi-label cost function adequate for deep CNNs, and a prediction method requiring only a single forward pass to produce multi-label predictions. We show the performance of our method on a newly introduced large scale multi-label dataset of animation images. Here, our method reaches 75.1% precision and 66.5% accuracy, making it suitable for automated annotation in practice. Additionally, we apply our method to the Pascal VOC 2007 dataset of natural images, and show that our prediction method outperforms a comparable model for a fraction of the computational cost. © 2015 Information Processing Society of Japan.","Animation images; Convolutional neural networks; Multi-label classification",,2-s2.0-84947245532
"Crespo R., García R., Quiroz S.","Virtual Reality Application for Simulation and Off-line Programming of the Mitsubishi Movemaster RV-M1 Robot Integrated with the Oculus Rift to Improve Students Training",2015,"Procedia Computer Science",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964068311&doi=10.1016%2fj.procs.2015.12.226&partnerID=40&md5=379b1e6c4f60904cc8ae95de2d128585","The overall purpose of this project is to test the impact and potential benefits of Virtual Reality technology by improving the current training methods for the operation of the Mitsubishi Movemaster RV-M1 Robot. The final application aims to achieve this goal by increasing the user's interactivity with the robot's features inside a virtual environment developed using the game engine Unity and the Oculus Rift headset for the virtual visualization. By using this application, on site operation time is decreased mainly by allowing off-line programming of the equipment. It also allows universities without or with limited industrial machinery to provide their students a way to learn and practice on industrial automation and robotics simulation topics without inconvenience. The application is designed to decrease the student's learning curve by displaying a complete virtual environment where the tridimensional model of the robotic arm can be visualized and programmed according to the real model's parameters and specifications. Joint type moving sequences are compiled into a file which afterwards can be transferred to the robot for real testing and execution. The system integrates a set of joysticks that allows the user to program each of the robot's joints as well as display several features of it in the virtual environment such as animations, images and text information that simplify the instructions shown in a printed manual. In order to find an optimized, collision-free movement sequence between two points an A∗shortest path algorithm is implemented using some of the built-in tools and plugins available in Unity and its Asset store. As a result of this last feature, the application can create a comparison between the user's input sequence and a computer generated sequence based on the A∗algorithm. © 2015 The Authors.","A; algorithm; Oculus Rift; Off-Line Programming; Robotics; Unity; Virtual Reality","Algorithms; Animation; Arsenic; Augmented reality; Education; Education computing; Machinery; Robotics; Robots; Students; Virtual reality; Collision free movement; Industrial automation; Industrial machinery; Oculus Rift; Off line programming; Shortest path algorithms; Unity; Virtual reality technology; Robot programming",2-s2.0-84964068311
"Mather R.","A mixed-methods exploration of an environment for learning computer programming",2015,"Research in Learning Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962243494&doi=10.3402%2frlt.v23.27179&partnerID=40&md5=0d3e7f802bb2a53cd43d7b6da776a3ca","A mixed-methods approach is evaluated for exploring collaborative behaviour, acceptance and progress surrounding an interactive technology for learning computer programming. A review of literature reveals a compelling case for using mixed-methods approaches when evaluating technology-enhanced-learning environments. Here, ethnographic approaches used for the requirements engineering of computing systems are combined with questionnaire-based feedback and skill tests. These are applied to the 'Ceebot' animated 3D learning environment. Video analysis with workplace observation allowed detailed inspection of problem solving and tacit behaviours. Questionnaires and knowledge tests provided broad sample coverage with insights into subject understanding and overall response to the learning environment. Although relatively low scores in programming tests seemingly contradicted the perception that Ceebot had enhanced understanding of programming, this perception was nevertheless found to be correlated with greater test performance. Video analysis corroborated findings that the learning environment and Ceebot animations were engaging and encouraged constructive collaborative behaviours. Ethnographic observations clearly captured Ceebot's value in providing visual cues for problem-solving discussions and for progress through sharing discoveries. Notably, performance in tests was most highly correlated with greater programming practice (p≤0.01). It was apparent that although students had appropriated technology for collaborative working and benefitted from visual and tacit cues provided by Ceebot, they had not necessarily deeply learned the lessons intended. The key value of the 'mixed-methods' approach was that ethnographic observations captured the authenticity of learning behaviours, and thereby strengthened confidence in the interpretation of questionnaire and test findings. © 2015 R. Mather.","Computer programming; Evaluation; Mixed methods; Video analysis",,2-s2.0-84962243494
"Schatz K., Rüppel U.","The potential of ontology-based serious game design for the AEC domain",2015,"Ontology in the AEC Industry: A Decade of Research and Development in Architecture, Engineering, and Construction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018810845&doi=10.1061%2f9780784413906.ch06&partnerID=40&md5=be6717c2a6fe3f8961bfee9bb8b78caf","The term “Serious Gaming” or “Gaming with a purpose” describes the combination of game concepts and methods with other information technologies in “serious” fields of applications. In the context of the Architecture, Engineering and Construction (AEC) domain Serious Games have the potential to achieve additional value beyond pure entertainment. During the game design process the thematic background (in the presented case the AEC background) of a Serious Game is of particular importance. This requires domain-specific knowledge, usually represented by domain-experts (civil engineers and architects) as part of the game development team. A challenging task of the design process is the creation of game objects to model the game world. In the presented case these game objects are based on common AEC objects (like wall, floor, window, door etc.) with some additional information about their role in the game scenario like interactive behavior or different states during the game timeline. To enhance the AEC objects information about the implicit meaning of each object is required. This includes a timeconsuming reasoning and decision-making process based on the experts experience in the application domain. However, it is assumed that this currently limits the application of Serious Gaming in the AEC domain. To solve this problem the presented research approach tries to retrieve most of the required knowledge automatically form a knowledge base (KB). This KB consists of digital content, which is already created during the Building Information Modeling (BIM) process. The challenge here is to displace the interpretation of information from the expert into a computer system. This requires a formalization of knowledge that could be derived from existing data and captured by an ontology, including a set of concepts and relationships between those concepts within the application domain. The present chapter introduces an ontology-based approach to support Serious Game design by enabling automatic creation of game design documents and game content using BIM data as a KB. For creating the KB for the presented use case, single AEC objects were enriched with additional information (e.g. events for interaction, animations, artwork, textures) about their role in the game with semantic technologies. This approach has the potential, that Serious Gaming becomes a common engineering method for daily practice, because data that are already incurred in the BIM process can be integrated and reused with minor effort. © 2015 by the American Society of Civil Engineers.",,"Animation; Architectural design; Decision making; Design; Knowledge based systems; Ontology; Semantics; Software design; Architecture , engineering and constructions; Automatic creations; Building Information Model - BIM; Decision making process; Domain-specific knowledge; Game design document; Interactive behavior; Semantic technologies; Serious games",2-s2.0-85018810845
"Legde K., Castillo S., Cunningham D.W.","Multimodal affect: Perceptually evaluating an affective talking head",2015,"ACM Transactions on Applied Perception",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941557357&doi=10.1145%2f2811265&partnerID=40&md5=6fbc4ab2555afaa36e9203af3a52f086","Many tasks such as driving or rapidly sorting items can be best achieved by direct actions. Other tasks such as giving directions, being guided through a museum, or organizing a meeting are more easily solved verbally. Since computers are increasingly being used in all aspects of daily life, it would be of great advantage if we could communicate verbally with them. Although advanced interactions with computers are possible, a vast majority of interactions are still based on the WIMP (Window, Icon, Menu, Point) metaphor [Hevner and Chatterjee 2010] and are, therefore, via simple text and gesture commands. The field of affective interfaces is working toward making computers more accessible by giving them (rudimentary) natural-language abilities, including using synthesized speech, facial expressions, and virtual body motions. Once the computer is granted a virtual body, however, it must be given the ability to use it to nonverbally convey socio-emotional information (such as emotions, intentions, mental state, and expectations) or it will likely be misunderstood. Here, we present a simple affective talking head along with the results of an experiment on the multimodal expression of emotion. The results show that although people can sometimes recognize the intended emotion from the semantic content of the text even when the face does not convey affect, they are considerably better at it when the face also shows emotion. Moreover, when both face and text convey emotion, people can detect different levels of emotional intensity. © 2015 ACM.","Affective interfaces; Emotion; Facial animation; Speech","Character recognition; Semantics; Speech; Affective interfaces; Emotion; Emotional information; Facial animation; Facial Expressions; Multimodal expressions; Natural languages; Synthesized speech; Face recognition",2-s2.0-84941557357
"Magdin M., Turčáni M.","A few observations and remarks on time effectiveness of interactive electronic testing",2015,"Informatics in Education",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929353518&doi=10.15388%2finfedu.2015.06&partnerID=40&md5=f7d9bfc7f17b6d68ae879181e05974a6","In the paper, we point out several observations and remarks on time effectiveness of electronic testing, in particular of its new form (interactive tests). A test is often used as an effective didactic tool for evaluating the extent of gained cognitive capabilities. According to authors Rudman (1989) and Wang (2003) it is provable that the relationship towards e-testing depends on the degree of previous experiences with this form of examination. Conducted experiments (not only by these authors) show that students using the traditional testing form (putting answers down on a paper) are happy to have the opportunity to use a computer for testing. The reason is the fact that they are usually used to a complete explanation of the educational content, frontal examination during the lesson and also in the course of the school year and more limited possibilities to use the Internet for educational purposes. Most of them do not even know about the possibilities of e-learning and electronic evaluation. On the other hand, the group of students who are being tested using the traditional form and at the same time using computers usually prefer the traditional form, while using multimedia tools is more or less normal to them. © 2015 Vilnius University.","Electronic testing; Interactive animations; Interactive tests; Interactivity; Time effective",,2-s2.0-84929353518
"Hougaard A.K.","Architectural drawing - an animate field",2015,"Open House International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938232921&partnerID=40&md5=42433cfe0e27569a1d772c85564426ce","Architectural drawing is changing because architects today draw with computers. Due to this change digital diagrams employed by computational architectural practices are often emphasized as powerful structures of control and organisation in the design process. But there are also diagrams, which do not follow computational logic worth paying attention to. In the following I will investigate one such other kind of diagram, a sketch diagram, which has a play-like capacity where rules can be invented and changed as you go. In that way, sketch diagrams are related to steered indeterminacy and authorial ways of directing behaviour of artefacts and living things without controlling this behaviour completely. I analyse a musical composition by John Cage as an example of a sketch diagram, and then hypothesize that orthogonal, architectural drawing can work in similar ways. Thereby I hope to point out important affordance of architectural drawing as a ¬hybrid between the openness of hand-sketching and the rule-basedness of diagramming, an affordance which might be useful in the migrational zone of current architectural drawing where traditional hand drawing techniques and computer drawing techniques are being combined with each other.","Animation; Architectural drawing; Diagram; Freedom and control",,2-s2.0-84938232921
"Yang X., Cai Y., Tseng C.","Visualizing Bacterial Gene Regulation with an Interactive Computer Program: The Trp Operon",2015,"Proceedings - 15th International Conference on Computational Science and Its Applications, ICCSA 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945933584&doi=10.1109%2fICCSA.2015.12&partnerID=40&md5=dd6e48c15c91c18e16cb34981be593b9","The paper describes an interactive computer program for visualizing bacterial gene regulation: the trp operon. The computer program was implemented based on our recently developed Gene Act framework. The advantages of this computer framework are 1) accelerating the development process and 2) simplifying the program development for researchers who wish to pack and distribute their work with interactive programs. The Gene Act frame work has been successfully used as a tutorial tool for learning the lac operon, the classical example of gene regulation in bacteria. The trp operon described here is as second example for such an application. Unlike the lac operon, which controls the breakdown of the sugar lactose, the trp operon is responsible for the synthesis of the amino acid tryptophan. As it is often challenging for beginners to understand the control mechanisms of the trp operon, especially the attenuation system, we hope that this interactive computer program may facilitate and improve learning by illustrating the process with rich text, images, animations, and interactive steps. © 2015 IEEE.","framework; interactive program; trp operon",,2-s2.0-84945933584
[No author name available],"International Conference on Human-Computer Interaction, HCI 2015",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951795538&partnerID=40&md5=fbb5da2754ff95fa791005050607852a","The proceedings contain 142 papers. The special focus in this conference is on Design and Evaluation Methods, Techniques and Tools, Cognitive and Psychological Issues in HCI. The topics include: Coding schemes for observational studies of usability in collaborative tangible user interfaces; toward a new design philosophy; method to design adaptable and adaptive user interfaces; designing for affectibility; a comparative analysis of usability evaluation methods on their versatility in the face of diversified user input methods; understanding IoT through the human activity; a pedagogical approach to usability in serious games; design support tool using pen device for simplification of animation design; user experience and other people; universal usability in mass media via discourse analysis; international and regional standards for usability and user experience; a framework proposal of UX evaluation of the contents consistency on multi screens; assessing usability of a post-mission reporting technology; validated usability heuristics; questionnaire survey on attention of young adults; spatial effect of target display on visual search; influence of color combination pattern considered usability to mental workload; emotion elicitation using film clips; examining the gender gap in information assurance; the effects of life-likeness on persuasion and attention-drawing in a mobile digital signage; the influence of different lighting source positions on the visual comfort of refrigerator illumination and brain mechanism research on visual information cognition of digital human computer interface.",,,2-s2.0-84951795538
[No author name available],"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938827756&partnerID=40&md5=c8c88a9ab9b55d2f7c4c8c2f8390f381","The proceedings contain 60 papers. The topics discussed include: gesture interaction with virtual humans and social robots; from single object to contextual authentication - a new challenge in multimedia forensics and beyond; improved representation of dependencies in feature-based parametric CAD models using acyclic digraphs; inverse light design for high-occlusion environments; towards a fully automatic markerless motion analysis system for the estimation of body joint kinematics with application to sport analysis; integrated modeling of road environments for driving simulation; PGP2X: principal geometric primitives parameters extraction; CEFM - a heuristic mesh segmentation method based on convexity estimation and fast marching; recent developments in skin deformation for character animation; a homotopy surface cutting using paths crossing in geodesic distance; second degree of freedom of elastic objects - adjustable Poisson's ratio for mass spring models; and point cloud structural parts extraction based on segmentation energy minimization.",,,2-s2.0-84938827756
"Voronin S.V., Yushin V.D., Bunova G.Z.","Computer-aided study of materials' microstructure influence on cracks' propagation pattern in brittle anisotropic bodies",2015,"Modern Applied Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920194081&doi=10.5539%2fmas.v9n3p51&partnerID=40&md5=e4f179884781289d459669cb1741b488","The purpose of the presented study is a solution of a boundary-value problem, a visualization and a study of crack propagation pattern of a plane specimen of an anisotropic brittle material by computer modeling method. As main software for the research, MSC Nastran finite-element analysis package is used. As a result of the presented study, a methodology for a creation of finite-element models of various structural constituents and specimens with consideration of material's microstructure is developed. Developed methodology is tested during the creation of finite-element model of the specimen assigned for a fracture with stress concentrators of varying forms and with a consideration of hypothetical structure, consisting of three types of crystallite with different mechanical properties. The methodology is proposed for an evaluation of kinetics and visualization of the crack growth in models of isotropic and anisotropic brittle materials. As the result of step-by-step visualization of the crack growth, animation files in AVI-format are created, which allow us to analyze the process of the material fracture. A theoretical equation is proposed for determination of the crack growth trajectory, which defines a relationship between a work needed for the crack growth and stresses in the specimen and its geometric parameters. An influence of the material on the trajectory of the crack growth is determined. Results of the presented study can serve as a tool for development of new materials with a high crack resistance due to their optimal microstructure. Developed methodologies allow you to determine desired location, size, shape of grains and their mechanical properties in microstructure of created material, without fabrication of many expensive full-size specimens. © By the author(s).","Brittle anisotropic body; Crack propagation; Finite-element analysis; Microstructure",,2-s2.0-84920194081
[No author name available],"7th International Conference on Cross-Cultural Design, CCD 2015 held as part of Human-Computer Interaction, HCI 2015",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951057693&partnerID=40&md5=4e81353b143d99f2e29eb4c9ecacd698","The proceedings contain 42 papers. The special focus in this conference is on Cultural Aspects of Social Media, Mobile Services, Culture for Transport and Travel. The topics include: Culturally appropriate design of mobile learning applications in the malaysian context; social media design requirements for the collectivist international students; the impact of natural utilization of traditional chinese cultural elements on the user experience in mobile interaction design; service design towards sustainable lifestyle in the context of mobile internet; from technology to design; from customer satisfaction to customer experience; e-commerce purchase intention in emerging markets; cultural capital at work in facebook users’ selection of different languages; applying soundscape to creating an interactive and cultural centered experience; design of vehicle-to-vehicle communication system for chinese and german drivers; investigation of a driver-to-driver communication method through rear window display for chinese; driving safety considered user interface of a smartphone; exploring smart-car space in urban india; explore a new place like locals; analysis of emotional design and cultural product narrative communication model; monster design and classifier cognition; design of literature management tool; traditional western art elements in disney animations, elite influence in mass culture through the prism of the frankfurt school and the application of chinese poem yu mei ren in design.",,,2-s2.0-84951057693
"Mahdavi-Amiri A., Whittingham P., Samavati F.","Cover-it: An interactive system for covering 3D prints",2015,"Proceedings - Graphics Interface",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018971107&partnerID=40&md5=5f7a0ff991bdc0052ed31db138120cc6","The ubiquity of 3D printers has made it possible to print various types of objects, from toys to mechanical objects. However, most available 3D printers are single or double colors. Even printers that can produce objects with multiple colors do not offer the ability to cover the object with a desired material, such as a piece of cloth or fur. In this paper, we propose a system that produces simple 2D patches that can be used as a reference for cutting material to cover the 3D printed object. The system allows for user interactions to correct and modify the patches, and provides guidelines on how to wrap the printed object via small curves illustrating the patch boundaries etched on the printed object as well as an animation showing how the 2D patches should be folded together. To avoid wasting materials, a heuristics method is also employed to pack 2D patches in the layout. To compensate the effect of inflation resulted from covering objects with thick materials, an offsetting tool is provided in Cover-it. In addition, since many low scale details of an object is not visible after covering, a mesh can be simplified in Cover-it to reduce the number of 2D patches. Copyright held by authors.","I.3.5 [computer graphics]: Computational geometry and object modeling—modeling packages; I.3.8 [Computer graphics]: Applications","Color computer graphics; Computational geometry; Computer graphics; Heuristic methods; Printers (computer); Printing machinery; Printing presses; 3d prints; Computational Geometry and Object Modeling; Cutting materials; I.3.8 [computer graphics]: Applications; Interactive system; Thick materials; User interaction; 3D printers",2-s2.0-85018971107
"Gonçalves D.A., Todt E., Garcia L.S.","3D avatar for automatic synthesis of signs for the sign languages",2015,"23rd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2015 - Short Papers Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969785111&partnerID=40&md5=7680df3cf4fdd67cdcab01940c56fc86","This paper discusses a synthesis system that generates, from a XML input representing gesture descriptors, a vector of configuration parameters that are executed by a 3D Avatar for use in the animation of Sign Languages. The development of virtual agents able to reproduce gestures of sign languages is very important to the deaf community, since in general they also have difficulties to read conventional texts. In this research project, a consistent combination of 3D editor Blender, CMarkup parser and graphics engine Irrlicht was used to develop a novel approach to sign synthesis, based on a recent XML model that describes hand gestures using shape, location, movement and orientation descriptors. The described experiments validate the proposed implementation model, which constitutes a promising alternative in the area of synthesis of signals for computational applications of Sign Languages.","Accessibility and usability; Deaf community; Gesture synthesis; Graphics engine; HCI","Blending; Computational linguistics; Computer graphics; Computer vision; Engines; Human computer interaction; Visualization; XML; Accessibility and usability; Automatic synthesis; Computational applications; Configuration parameters; Deaf community; Gesture descriptors; Graphics engine; Implementation models; Three dimensional computer graphics",2-s2.0-84969785111
"Takeuchi A., Hasegawa D., Sakuta H.","Web-based avatar represented lecture viewer toward interactive e-Lecture performed by 3D avatar",2015,"IEEE Global Engineering Education Conference, EDUCON",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946071062&doi=10.1109%2fEDUCON.2015.7095984&partnerID=40&md5=0f2e9f52b0aa36c3ed4104b0b2a42b32","To introduce interactivity in e-learning, HTML5 and JavaScript have been widely used for years. And recent advancements of WebGL, JavaScript API for computer graphic programming that works on any modern browsers, enable us to draw animations of a fully human-like embodied computer graphics character on web-browsers. With these technologies, web-based e-learning could be more interactive. We propose interactive e-Lecture, where lecturers' three dimensional motions and audio are captured by a motion capture system, then a 3D avatar interactively performs the lecture. The advantage of the use of computer graphics character to perform lectures instead of videos is that e-learning designers can introduce interaction into the e-learning. For example, by controlling the avatar's head and eye movements according to the results of face-recognition, the eye-gaze behavior could be realized. We recorded 3D motions of a lecture performed by a volunteer with a motion capture system, and created a small lecture data. We also developed a web-based viewer that can process the 3D motion data and draw a lecture performed by a 3D avatar on a web-browser. © 2015 IEEE.","e-learning; gesture segmentation; html5; javascript; motion capture","Application programming interfaces (API); Computer graphics; Computer programming; E-learning; Eye movements; Face recognition; High level languages; Three dimensional computer graphics; Web browsers; Websites; World Wide Web; Gesture segmentation; Graphic programming; html5; Javascript; Motion capture; Motion capture system; Three-dimensional motion; Web based e learning; Engineering education",2-s2.0-84946071062
"da Silva R.R., Bissaco M.A.S., Goroso D.G.","MioLab, a rat cardiac contractile force simulator: Applications to teaching cardiac cell physiology and biophysics",2015,"Computer Methods and Programs in Biomedicine",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947550167&doi=10.1016%2fj.cmpb.2015.09.012&partnerID=40&md5=dd008487a8b93bdd0bb7eb7dfe91cf25","Introduction: Understanding the basic concepts of physiology and biophysics of cardiac cells can be improved by virtual experiments that illustrate the complex excitation-contraction coupling process in cardiac cells. The aim of this study is to propose a rat cardiac myocyte simulator, with which calcium dynamics in excitation-contraction coupling of an isolated cell can be observed. This model has been used in the course ""Mathematical Modeling and Simulation of Biological Systems"". In this paper we present the didactic utility of the simulator MioLab®. Methods: The simulator enables virtual experiments that can help studying inhibitors and activators in the sarcoplasmic reticulum sodium-calcium exchanger, thus corroborating a better understanding of the effects of medications, which are used to treat arrhythmias, on these compartments. The graphical interfaces were developed not only to facilitate the use of the simulator, but also to promote a constructive learning on the subject, since there are animations and videos for each stage of the simulation. The effectiveness of the simulator was tested by a group of graduate students. Results: Some examples of simulations were presented in order to describe the overall structure of the simulator. Part of these virtual experiments became an activity for Biomedical Engineering graduate students, who evaluated the simulator based on its didactic quality. As a result, students answered a questionnaire on the usability and functionality of the simulator as a teaching tool. All students performed the proposed activities and classified the simulator as an optimal or good learning tool. In their written questions, students indicated as negative characteristics some problems with visualizing graphs; as positive characteristics, they indicated the simulator's didactic function, especially tutorials and videos on the topic of this study. Conclusions: The results show that the simulator complements the study of the physiology and biophysics of the cardiac cell. © 2015 Elsevier Ireland Ltd.","Cardiac myocyte; Computer models; Simulator; Teaching; Virtual experiments","Bioinformatics; Biological systems; Biomedical engineering; Biophysics; Calcium; Cells; Cytology; Education; Heart; Physiology; Rats; Students; Teaching; Virtual reality; Cardiac myocytes; Computer models; Engineering graduate students; Excitation - contraction couplings; Excitation contraction coupling process; Mathematical modeling and simulation; Sodium-calcium exchangers; Virtual experiments; Simulators; animal; biophysics; cardiac muscle cell; computer interface; computer simulation; heart contraction; physiology; rat; teaching; Animals; Biophysics; Computer Simulation; Myocardial Contraction; Myocytes, Cardiac; Rats; Teaching; User-Computer Interface",2-s2.0-84947550167
"Goguadze G.","Integrating teacher and student workspaces in a technology-enhanced mathematics lecture",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944705634&doi=10.1007%2f978-3-319-24258-3_62&partnerID=40&md5=5949b9c6caf6272786850a04f8fde171","Recent introduction of modern computer technology into schools and universities presented new challenges to mathematics teachers. On one hand, powerful computer tools have emerged that allow for rich animation and visualization. On the other hand, the teachers are not ready to give up using the blackboard, which is still their main workspace. This work presents a tool for teachers, that allows for more freedom than the fixed lecture slides and helps illustrating rules for transforming mathematical expressions and solving equations. Using this tool, the teacher can automatically generate solutions for mathematical problems on the fly and interactively present these to the students step by step. The solution is then blended out and the students are offered to solve similar problems on their computers interactively using the system. This tool is a part of a larger toolkit used within several innovative Blended Learning Bridging Courses in Mathematics at Leuphana University in L¨uneburg, held in a computer-equipped classroom. © Springer International Publishing Switzerland 2015.","Intelligent tutoring systems; Interactive exercises; Technology enhanced teaching; Worked solutions","Computer aided instruction; Education; Engineering education; Students; Blended learning; Bridging course; Computer technology; Intelligent tutoring system; Interactive exercise; Mathematical expressions; Mathematical problems; Mathematics teacher; Teaching",2-s2.0-84944705634
"Wang Y., Sun L., Xu Y., Xiao Q., Chang P., Wu Y.","Comparision and analysis of top 10 exercise android Apps in mainland China",2015,"Studies in Health Technology and Informatics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952054732&doi=10.3233%2f978-1-61499-564-7-1024&partnerID=40&md5=0d5a37eaed4cebc4a97b15f93fd8a746","Medical guidelines highly recommend physical activity and aerobic exercise in the prevention of primary and secondary cardiovascular disease. The use of exercise-promoting application software may improve clinical outcomes for cardiovascular disease (CVD) patients. The study aimed to compare and analyze the functions of the top 10 exercise Android Apps which had more than 1,000,000 downloads from the main four Android App stores in mainland China. The results showed that most of these popular apps had pedometer, exercise plan preset, user data presentation, user encouragement and community sharing functions while a few of them had exercise video clips or animation support and wearable devices. Given these data, the conclusion is that these popular apps fulfill some of the functions recommended by medical guidelines, however, lack of some functions such as pre-exercise risk assessment, the exercise intensity recording, specific instructions by professionals, and monitoring functions for CVD patients. © 2015 IMIA and IOS Press.","Android; App; CVD; Exercise; Health","ambulatory monitoring; biomedical technology assessment; China; classification; comparative study; computer assisted therapy; computer language; evaluation study; kinesiotherapy; mobile application; procedures; self care; statistics and numerical data; telemedicine; utilization; China; Exercise Therapy; Mobile Applications; Monitoring, Ambulatory; Programming Languages; Self Care; Technology Assessment, Biomedical; Telemedicine; Therapy, Computer-Assisted",2-s2.0-84952054732
"Michiels N., Put J., Bekaert P.","Interactive relighting of virtual objects under environment lighting",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938890395&partnerID=40&md5=b5c5ba140453dce1fd3cdd8f37bf66d4","Current relighting applications often constrain one or several factors of the rendering equation to keep the rendering speed real-time. For example, visibility is often precalculated and animations are not allowed, changes in lighting are limited to simple rotation or the lighting is not very detailed. Other techniques compromise on quality and often coarsely tabulate BRDF functions. In order to solve these problems, some techniques have started to use spherical radial basis functions. However, solving the triple product integral does not guarantee interactivity. In order to dynamically change lighting conditions or alter scene geometry and materials, these three factors need to be converted to the SRBF representation in a fast manner. This paper presents a method to perform the SRBF data construction and rendering in real-time. To support dynamic high-frequency lighting, a multiscale residual transformation algorithm is applied. Area lights are detected through a peak detection algorithm. By using voxel cone tracing and a subsampling scheme, animated geometry casts soft shadows dynamically. We demonstrate the effectiveness of our method with a real-time application. Users can shine with multiple light sources onto a camera and the animated virtual scene is relit accordingly. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","GPU; Real-time; Rendering; Spherical gaussians; Triple product","Light sources; Lighting; Radial basis function networks; Rendering (computer graphics); Three dimensional computer graphics; Gaussians; GPU; Real time; Rendering; Triple product; Computer graphics",2-s2.0-84938890395
"Vukolov A., Egorova O.","New perspectives of real and virtual mechanisms models in theory of mechanisms and machines",2015,"2015 IFToMM World Congress Proceedings, IFToMM 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018954979&doi=10.6567%2fIFToMM.14TH.WC.OS7.006&partnerID=40&md5=a7c3e9d7c190502734b0fcd5e395b4fb","Scaled models of mechanisms are widely used in theory of machines and mechanisms. Through history of discipline from XIXth century several collections of mechanisms and ""Cabinets of models"" were created in Germany, Russia, Italy etc. Development of new technologies including photography, computer graphics and 3D modeling made it possible to save artifact models and improve usage of their images. They turn model to a kind of smart object with capabilities of integration with modern IT infrastructure. This paper presents new perspectives of virtual mechanisms models of several kinds (photographs, animations, 3D-models) in historical context of engineering education and famous ""Russian method"" of training.","3D modeling; Bmstu; Engineering education; History of MMS; Mechanisms collection; Mechanisms models; Virtual models","Computer graphics; Engineering education; Photography; 3-d modeling; Bmstu; IT infrastructures; Scaled models; Smart objects; Theory of mechanisms; Virtual mechanism; Virtual models; Three dimensional computer graphics",2-s2.0-85018954979
"Pacheco D., Le Groux S., Verschure P.F.M.J.","Two dimensional shapes for emotional interfaces: Assessing the influence of angles, curvature, symmetry and movement",2015,"ACHI 2015 - 8th International Conference on Advances in Computer-Human Interactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966486998&partnerID=40&md5=2a49cd07b7958578716b0123d86d9590","Recent investigations aiming to identify which are the most influential parameters of graphical representations on human emotion have presented mixed results. In this study, we manipulated four emotionally relevant geometric and kinematic characteristics of non symbolic bidimensional shapes and animations, and evaluated their specific influence in the affective state of human observers. The controlled modification of basic geometric and cinematic features of such shapes (i.e., angles, curvature, symmetry and motion) led to the generation of a variety of forms and animations that elicited significantly different self-reported affective states in the axes of valence and arousal. Curved shapes evoked more positive and less arousing emotional states than edgy shapes, while figures translating slowly were perceived as less arousing and more positive than those translating fast. In addition, we found significant interactions between angles and curvature factors both in the valence and the arousal scales. Our results constitute a direct proof of the efficacy of abstract, non-symbolic shapes and animations to evoke emotion in a parameterized way, and can be generalized for the development of real-time, emotionally aware user interfaces. Copyright © IARIA, 2015.","Affective Computing; Emotional Design; Emotional interfaces; Expressive Interfaces; Graphical User Interfaces","Behavioral research; Human computer interaction; Interactive computer systems; User interfaces; Affective Computing; Controlled modification; Emotional design; Emotional state; Expressive interfaces; Graphical representations; Human observers; Kinematic characteristics; Graphical user interfaces",2-s2.0-84966486998
"Edgcomb A.D., Vahid F., Lysecky R., Knoesen A., Amirtharajah R., Dorf M.L.","Student performance improvement using interactive textbooks: A three-university cross-semester analysis",2015,"ASEE Annual Conference and Exposition, Conference Proceedings",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941993369&partnerID=40&md5=365ac689d9a7b02b29d8978af47fca1f","We conducted studies to determine whether introducing an interactive textbook into introductory STEM (science, technology, engineering, math) courses can improve student grades. An interactive textbook has substantially less text than a traditional textbook, instead having numerous embedded question sets designed for learning and not quizzing, numerous animations of key concepts, and some built-in tools. The studies included four introductory computer-programming courses at three research universities: C++ at Univ. of Michigan, C/C++ at Univ. of Arizona, and MATLAB at Univ. of California at Davis. For each, two course offerings were compared, the first using a static textbook or static web resources, and the second using an interactive textbook. Most other course features remained the same between offerings, including the teacher and the semester offering (e.g., Spring semester), or were very similar; differences are noted. We analyzed final course grades and performance on specific course items using nonparametric analysis with conservative Bonferroni adjustment for multiple tests. Across all courses involving 1,945 students, course grades improved by 0.28 points on a 0-4 point scale (p-value < 0.001), or 1/4 letter grade, from static to interactive textbook. More importantly, students in the lower quartile of the course improved by 0.38 points (p-value < 0.001), or 1/3 letter grade. Exam scores improved by 13.6% (p-value < 0.001) and project scores by 7.4% (p-value < 0.001) from static to interactive textbooks. 98% of the students subscribed to the interactive textbook and completed at least some activities on the interactive textbook. The average student completed 87% of the assigned activities in the interactive textbook. © American Society for Engineering Education, 2015.","Computer engineering; Computer science; Digital learning; Digitally-enhanced education; Interactive content; Online textbooks; Programming; Static content; Web-native content",,2-s2.0-84941993369
"Trouvain G., Gagnol V., Duc E., Sancho J.F.","Mass-spring parameters definition in 2D for simulation",2015,"22nd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2014, Communication Papers Proceedings - in co-operation with EUROGRAPHICS Association",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957895017&partnerID=40&md5=bf9678a924c2eeca50d5a660efe25024","In computer graphics and in industrial context, Mass-Spring model is used to obtain fast and visual results in physical simulations. A disadvantage of the method is to obtain accurate result on account of the difficulty to define parameters of a Mass-Spring Model. Different works and results are carried out to define Mass-Spring parameters in other domains such as in cloth animation or in soft tissue modeling. However the Mass-Spring model is not used in some context where a real-time computation can be useful as in tire manufacturing industry for example. In this paper, a method is presented to define the geometric configuration of a Mass-Spring system and the tuning of the mass, stiffness and damper parameters according to physical material behaviours. Different load cases are studied and used to conduct a sensitivity study on the network spring parameters. Then, results are compared to Finite Element Model of same cases in order to evaluate the precision of the proposed approach.","Mass-Spring System; Mechanical behavior; Physically-based simulation; Spring stiffness","Computer graphics; Computer vision; Stiffness; Visualization; Geometric configurations; Manufacturing industries; Mass spring systems; Mechanical behavior; Physically-based simulation; Real-time computations; Soft tissue modeling; Spring stiffness; Finite element method",2-s2.0-84957895017
"Gorobtsov A., Getmanskiy V., Andreev A., Trung D.D.","Simulation and visualization software for vehicle dynamics analysis using multibody system approach",2015,"Communications in Computer and Information Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951861887&doi=10.1007%2f978-3-319-23766-4_30&partnerID=40&md5=fca37539a39905c22c16498d524015b8","The vehicle dynamics analysis requires modern coupled simulation techniques which are implemented in modern simulation software. Custom simulation method of full vehicle multibody model and coupled model of separate parts are considered in the paper. The method is implemented in developed simulation software which is capable of use CAD geometries of vehicle parts. Several useful visualization features are developed in postprocessor based on visualization toolkit library. Visualization approaches using semi-transparent CAD geometry attached to the bodies in simplified model are used to obtain descriptive animation of vehicle movement. Partial visualization of grids for coupled CADbased models is implemented using the Cartesian thresholds for inner structure analysis of the physical processes simulated for some parts of vehicle. Simulation examples and visualization results including vehicle motion and large scale grids based on parts geometry are presented. © Springer International Publishing Switzerland 2015.","CAD geometry; Discrete elements; Dynamic stress analysis; Multibody simulation; Postprocessor; Vehicle model","Computer software; Geometry; Stress analysis; Vehicles; Visualization; CAD geometry; Discrete elements; Dynamic stress analysis; Multibody simulations; Post-processor; Vehicle model; Computer aided design",2-s2.0-84951861887
"Jiang C., Wang Z., Yu J.","An Expressive Eye Model: Using Eye Movement to Show Ocular Emotional Expression",2015,"IFAC-PapersOnLine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988592894&doi=10.1016%2fj.ifacol.2015.12.338&partnerID=40&md5=404d8017eb61f0643dc508a23d773afd","Emotionally expressive eye movement is important for facial animation. However, relation between eye movement and emotions has not been well studied. This paper integrates various sources of information to create an expressive eye model capable of expressing different emotions through vivid eye movements. First, based on statistical data and experimental studies, we endow eye model with detailed motion parameters and functions, with which detailed eye movement under neutral emotion state can be displayed. Second, an eye tracking experiment is performed to find the impact of emotional change on eye movements, and then the analysis result of tracking data are used to model eye movements under different emotion conditions. Experiment demonstrates that our eye model can reflect emotional changes of virtual character through different eye movement patterns. © 2015","agents; computer graphics; computer simulation; human perception; Human-machine interface","Agents; Color image processing; Computer graphics; Computer simulation; Emotional expressions; Eye movement patterns; Human Machine Interface; Human perception; Motion parameters; Sources of informations; Statistical datas; Virtual character; Eye movements",2-s2.0-84988592894
"Bajaj H., Jindal R.","Thinking beyond WhatsApp",2015,"2015 International Conference on Computing for Sustainable Global Development, INDIACom 2015",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958077170&partnerID=40&md5=0afd133b2e73c7d51d23b1875ef0af0e","Communication in the present scenario has changed its form from audio to textual means, among most of the people specially the younger generation. All credit goes to the various convenient and easy to use apps available to be freely downloaded. Today the market is brimming with 'WhatsApp', 'WeChat', 'Viber', 'LINE', 'Snapchat', Chat ON and many more such apps which we are referring as ""WhatsApp family"" apps. With the help of some of the most popular messaging apps already in market, this clearly states some possibilities of the future messaging apps stating the picture of the present needs. In this paper, we are presenting a new all in one app having feature upto the expectations of next generation like virtual social platform, organizational attributes, communication among different apps, communication in all languages, animation and should be capable to solve some major issues of the country like health. © 2015 IEEE.","Communication; Health; Messaging apps; Virtualization; WhatsApp","Communication; Computer programming; Computer science; Health; Virtualizations; WhatsApp; Younger generations; Commerce",2-s2.0-84958077170
"Peter W.F., Loos M., De Vet H.C.W., Boers M., Harlaar J., Roorda L.D., Poolman R.W., Scholtes V.A.B., Boogaard J., Buitelaar H., Steultjens M., Roos E.M., Guillemin F., Rat A.C., Benedetti M.G., Escobar A., Østeras N., Terwee C.B.","Development and preliminary testing of a computerized animated activity questionnaire in patients with hip and knee osteoarthritis",2015,"Arthritis Care and Research",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920000745&doi=10.1002%2facr.22386&partnerID=40&md5=c8bc68a6a0a2c9c344366442e9dc0eaa","Methods: Item selection was based on the pilot AAQ, prespecified conditions, the International Classification of Functioning, Disability, and Health core set for OA, existing measurement instruments, and focus groups of patients. Test-retest reliability was assessed in 30 of 110 patients. In 110 patients, correlations were calculated between the AAQ and the self-reported Hip Disability/Knee Injury and Osteoarthritis Outcome Score activities of daily living subscale (H/KOOS). In 45 of 110 patients, correlations with performance-based tests (stair climbing test, timed up and go test, and 30-second chair stand test) were calculated.Results: In total, 17 basic daily activities were chosen for the AAQ. Video animations were made showing a person performing each activity with 3-5 different levels of difficulty. Patients were asked to select the level that best matched their own performance. Reliability was high (intraclass correlation coefficient 0.97 [95% confidence interval 0.93-0.98]); the AAQ correlated highly with performance-based tests (0.62), but higher with the H/KOOS (0.76) than expected.Conclusion: A computerized AAQ for assessing activity limitations was developed. Content validity was considered good. Preliminary validation results showed high reliability, but construct validity needs further study with a larger sample size. Continuing research will focus on construct validity and crosscultural validity.Objective: To develop an Animated Activity Questionnaire (AAQ) based on video animations for assessing activity limitations in patients with hip/knee osteoarthritis (OA) that combines the advantages of self-reported questionnaires and performance-based tests without many of their limitations and to preliminarily assess its reliability and validity. We hypothesized that the AAQ would correlate highly with performance-based tests and moderately with self-reported questionnaires. © 2015, American College of Rheumatology.",,"adult; aged; Animated Activity Questionnaire; Article; assessment of humans; construct validity; controlled study; daily life activity; female; hip osteoarthritis; human; International Classification of Functioning, Disability and Health; Knee Injury and Osteoarthritis Outcome Score; knee osteoarthritis; major clinical study; male; self concept; test retest reliability; computer interface; daily life activity; middle aged; Osteoarthritis, Hip; Osteoarthritis, Knee; pain measurement; photostimulation; pilot study; procedures; questionnaire; reproducibility; self report; standards; very elderly; videorecording; Activities of Daily Living; Aged; Aged, 80 and over; Female; Humans; Male; Middle Aged; Osteoarthritis, Hip; Osteoarthritis, Knee; Pain Measurement; Photic Stimulation; Pilot Projects; Questionnaires; Reproducibility of Results; Self Report; User-Computer Interface; Video Recording",2-s2.0-84920000745
"Huang Z., Feng Z., He N., Yang X.","3D gesture-based interaction interface oriented to mental model expression",2015,"Journal of Information and Computational Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941948998&doi=10.12733%2fjics20106447&partnerID=40&md5=f5e241aefb4ab588d675a8e26c8d8f0f","The process of the three-dimensional interaction has different motion style for different users. To reflect the users' different motion style, this paper presents a gesture style expression algorithm based on monocular vision from the three aspects of speed, trajectory and perspective. Firstly, we establish the gesture behavior model under the fundamental experimental platform using camera, data glove and position tracker. Secondly, we put emphasis on building the speed, trajectory and perspective models according to the behavior model. Finally, we get the styles of gesture based on motion models and complete the interactive task. The main contribution of this paper is that we establish mathematical relation between the real hand and gesture animation for users from the perspective of gesture behavioral model. Our experimental results demonstrate that the proposed approach fully reflects the different styles for users. The overall average tracking accuracy error is 12% compared with data glove in different speed. At the same time, the system based on our algorithm can reduce the cognitive load for users and provide an enhanced user experience. ©, 2015, Journal of Information and Computational Science. All right reserved.","3D Interface; Human-computer Interaction; Model; Motion Style; Perspective; Speed Model; Trajectory Model","Models; Trajectories; User interfaces; 3D interface; Motion styles; Perspective; Speed models; Trajectory modeling; Human computer interaction",2-s2.0-84941948998
"Burns B., Samanta B.","Mechanical design and control calibration for an interactive animatronic system",2015,"ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982899200&doi=10.1115%2fIMECE201552477&partnerID=40&md5=b7b333a7fd2ecef6a9a8a4e8250312bd","Animatronic figures provide key show effects in the entertainment and theme park industry by simulating life-like animations and sounds. There is a need for interactive, autonomous animatronic systems to create engaging and compelling experiences for the guests. The animatronic figures must identify the guests and recognize their status in dynamic interactions for enhanced acceptance and effectiveness as socially interactive agents, in the general framework of humanrobot interactions. The design and implementation of an interactive, autonomous animatronic system in form of a tabletop dragon and the comparisons of guest responses in its passive and interactive modes are presented in this work. The purpose of this research is to create a platform that may be used to validate autonomous, interactive behaviors in animatronics, utilizing both quantitative and qualitative analysis methods of guest response. The dragon capabilities include a four degreesof- freedom head, moving wings, tail, jaw, blinking eyes and sound effects. Human identification, using a depth camera (Carmine from PrimeSense), an open-source middleware (NITE from OpenNI), Java-based Processing and an Arduino microcontroller, has been implemented into the system in order to track a guest or guests, within the field of view of the camera. The details of design and fabrication of the dragon model, algorithm development for interactive autonomous behavior using a vision system, the experimental setup and implementation results under different conditions are presented. Copyright © 2015 by ASME.",,"Cameras; Computer vision; Middleware; Open source software; Open systems; Algorithm development; Autonomous behaviors; Design and implementations; Dynamic interaction; Human identification; Interactive behavior; Open source middlewares; Quantitative and qualitative analysis; Computer graphics",2-s2.0-84982899200
"Fels D.I., Smith D.H., Baffa Da Silva R., Aybar D., Whitfield M.","IIS you is my digital baby: An Intimate Interface System for persons with disabilities",2015,"Proceedings - Graphics Interface",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032179845&partnerID=40&md5=0846b6102d30087497cb12bd3974aa47","Virtual worlds, avatars and cybersex are becoming more commonplace and acceptable. Virtual environments such as Second Life™ allow for the construction and exploration of virtual selves or agents that are bounded only by imagination and fantasy of their participants. However, they are also informed by the attitudes, limits and agendas of the real life participants that invade these worlds. For people with disabilities, virtual environments may allow the crossing of boundaries of taboo subjects such as disability and sex, and intimate technologies. The Intimate Interface System (IIS) was designed to support and encourage intimacy and cybersex discovery for people with disabilities in an inclusive manner. It is composed of a virtual world component replete with customizable avatars, animations and sound combine with physical devices including a vibrating chair and a pressure pad. Results were derived from an initial focus group with four persons with motoric disabilities. Notions of positive and negative aspects of cybersex, such as the ability to do things in virtual life that cannot be done in real life, and spending time in virtual relationships is for people who are socially inept were found reflecting the literature. However, there were also unique viewpoints such as the desire for more realism that were brought to bear on the discussion. Reaction to IIS was generally positive, however, participants wanted more features such as temperature control and enhanced realism. Copyright held by authors.","Accessibility; Avatar; Cybersex; Inclusive design; Intimacy; Social interaction; Virtual world","Interactive computer systems; Virtual reality; Accessibility; Avatar; Cybersex; Inclusive design; Intimacy; Social interactions; Virtual worlds; Interactive computer graphics",2-s2.0-85032179845
"Vieira Júnior E.E., Wen C.L.","Training of beauty salon professionals in disease prevention using interactive tele-education",2015,"Telemedicine journal and e-health : the official journal of the American Telemedicine Association",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017330243&doi=10.1089%2ftmj.2014.0044&partnerID=40&md5=d665c0a63b979b59b408f578bd70d8a1","BACKGROUND: Infectious diseases can be acquired in places where invasive procedures are often performed without the proper care of hand washing and material sterilization. There are approximately 500,000 beauty and esthetics centers in Brazil, which are visited by thousands of people every day. Many diseases, including sexually transmitted infections, are still highly prevalent in Brazil, such as warts caused by human papillomavirus, hepatitis B and C, and human immunodeficiency virus infection, and can be transmitted in beauty salons.MATERIALS AND METHODS: We have developed a tele-education course divided into four main themes: sexually transmitted infections, indoor health in beauty salon workplaces, hand washing, and material sterilization. The course was made available through a Web site, which included a face-to-face meeting, Web synchronous meetings (chats and Web conferences), and asynchronous resources (reading material, discussion lists, situations simulator, educational videos, and three-dimensional virtual human video animation on sexually transmitted infections and hand washing), mediated by professors and coordinators.RESULTS: Fifty-two beauty professionals and 33 other professionals were enrolled from different regions. Of the 61 who completed the course and received a certificate at the course's end, 100% considered good to excellent the course's applicability to everyday life and would recommend it to a fellow professional.CONCLUSIONS: The results demonstrate the feasibility of an interactive, tele-education model using low-cost tools as an educational resource to teach beauty professionals. In the future, this may become a branch of nationwide telehealth action.","distance learning; education; teledermatology; telehealth; telemedicine","Brazil; computer interface; education; esthetics; female; hand disinfection; health education; human; indoor air pollution; instrument sterilization; male; occupational exposure; organization and management; prevention and control; procedures; Sexually Transmitted Diseases; Air Pollution, Indoor; Beauty; Brazil; Education, Distance; Female; Hand Disinfection; Health Education; Humans; Male; Occupational Exposure; Sexually Transmitted Diseases; Sterilization; User-Computer Interface",2-s2.0-85017330243
"Li Q., Wu W., Sun Z., Wang L., Huang J.","Economy-oriented deadline scheduling policy for render system using IaaS cloud",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952058735&doi=10.1007%2f978-3-319-27137-8_6&partnerID=40&md5=abe0c7a28bee270b800fe9f773efd56e","Along with the increase of demand for high definition animation film, when the render system with local computing resources cannot supply enough resources to satisfy the user requirement for time, acquiring additional resources is necessary. The Infrastructure as a service (IaaS) Cloud offers user with computing infrastructures on-demand to be used based on the paradigm of pay-per-use, which provides extra resources with fee to extending the capacity of render system with local cluster. Consequently, the scheduling policy under the hybrid render system should consider the constraints of deadline and budget and billing policy. In this paper, an economy-oriented deadline scheduling policy is proposed, which not only guarantees the deadline for user by the way of employing resources for rendering, but also offers an economic way to hire resources from IaaS Cloud provider reasonably. The experiment with single workload and multi workloads shows that the proposed policy can finish the user’s rendering job before deadline as well as obtain approving cost efficient. © Springer International Publishing Switzerland 2015.","Budget; Cluster rendering; Deadline; IaaS cloud; Scheduling","Budget control; Cluster computing; Computer architecture; Distributed computer systems; Parallel architectures; Scheduling; Budget; Cluster rendering; Computing infrastructures; Computing resource; Deadline; Deadline scheduling; Iaas clouds; Scheduling policies; Infrastructure as a service (IaaS)",2-s2.0-84952058735
"Matzke H., Schirner M., Vollbrecht D., Rothmeier S., Llarena A., Rojas R., Triebkorn P., Domide L., Mersmann J., Solodkin A., Jirsa V.K., McIntosh A.R., Ritter P.","TVB-EduPack—an interactive learning and scripting platform for the virtual brain",2015,"Frontiers in Neuroinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948756257&doi=10.3389%2ffninf.2015.00027&partnerID=40&md5=f168e3bfcd1aaa69ccbe36444f8bebdb","The Virtual Brain (TVB; thevirtualbrain.org) is a neuroinformatics platform for full brain network simulation based on individual anatomical connectivity data. The framework addresses clinical and neuroscientific questions by simulating multi-scale neural dynamics that range from local population activity to large-scale brain function and related macroscopic signals like electroencephalography and functional magnetic resonance imaging. TVB is equipped with a graphical and a command-line interface to create models that capture the characteristic biological variability to predict the brain activity of individual subjects. To enable researchers from various backgrounds a quick start into TVB and brain network modeling in general, we developed an educational module: TVB-EduPack. EduPack offers two educational functionalities that seamlessly integrate into TVB’s graphical user interface (GUI): (i) interactive tutorials introduce GUI elements, guide through the basic mechanics of software usage and develop complex use-case scenarios; animations, videos and textual descriptions transport essential principles of computational neuroscience and brain modeling; (ii) an automatic script generator records model parameters and produces input files for TVB’s Python programming interface; thereby, simulation configurations can be exported as scripts that allow flexible customization of the modeling process and self-defined batch- and post-processing applications while benefitting from the full power of the Python language and its toolboxes. This article covers the implementation of TVB-EduPack and its integration into TVB architecture. Like TVB, EduPack is an open source community project that lives from the participation and contribution of its users. TVB-EduPack can be obtained as part of TVB from thevirtualbrain.org. © 2015 Matzke, Schirner, Vollbrecht, Rothmeier, Llarena, Rojas, Triebkorn, Domide, Mersmann, Solodkin, Jirsa, McIntosh and Ritter.","Brain modeling; Computational neuroscience; Connectome; Educational platform; The Virtual Brain","computer interface; computer program; human; human experiment; language; learning; mechanics; model; neuroscience; scientist; videorecording",2-s2.0-84948756257
"Yoon J.-S., Kwon H.-J., Kim B.-H., Lee J.-Y.","Development of a service platform for sensitization of manufacturing-related activities to use 3D CAD data",2015,"Procedia CIRP",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939493085&doi=10.1016%2fj.procir.2015.02.108&partnerID=40&md5=b96c00ee38d260220eef6b7af6dba888","Most of manufacturing enterprises design their products through the 3D CAD system. Generated 3D CAD data are mainly used in design and manufacturing stage for product engineering. Since the 3D CAD data includes not only shape models but also part structures and specifications, it is possible to reuse the data in various kinds of manufacturing-related activities after design and manufacturing. For example, 3D CAD data could be used to produce a catalog for marketing and promotion of products by replacing product images, a manual provided to the customers by implementing the animation for the operation of the product and educational materials for training of service staffs by guiding maintenance instructions interactively. These activities for customer support are necessary and significant from the perspective of product lifecycle although they may be not directly related to productivity and quality of products. However, a lot of manufacturing enterprises, especially SMEs (small and medium-sized Enterprises) have difficulty in to carry out these activities due to problems of cost and labor. In this context, this study proposes a new service model to support the manufacturing-related activities to be able to use 3D CAD data. The service model could operate through a software system as follows: A service provider (e.g. IT service vendor) makes core functions to process and manipulate 3D model a form of service platform and develops applications based on the service platform according to the supporting activities so that more applications could be added and expanded effectively. A service consumer (e.g. manufacturing enterprise) requests a service with required data such as 3D CAD data and service contents data to the provider and receives deliverables corresponding to the service. To implement the service model, this study specifies stakeholders, workflow and data of the service model, and develops the service platform. And this study illustrates an industrial case of the service model by developing a 3D digital catalog application and demonstrating a home appliance example. © 2015 The Authors. Published by Elsevier B.V This is an open access article under the CC BY-NC-ND license.","3D CAD data; 3D digital catalog and manua; Manufacturing service; Service platform","Application programs; Domestic appliances; Industrial economics; Life cycle; Manufacture; Product design; Three dimensional computer graphics; 3-d cad datum; 3D digital catalog and manua; Educational materials; Manufacturing enterprise; Manufacturing service; Manufacturing stages; Service platforms; Small and medium sized enterprise; Computer aided design",2-s2.0-84939493085
"Li J., Li B., Xu J., Xiong R.","An adaptive hierarchical QP setting for screen content coding",2015,"2015 Visual Communications and Image Processing, VCIP 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978985685&doi=10.1109%2fVCIP.2015.7457812&partnerID=40&md5=605f0e2d12b9987163549f00ccab606a","Screen content refers to computer generated content like text, graphics, and animations. In such video, many regions may remain static for a long period after a sudden change. Traditional hierarchical Quantization Parameter (QP) setting may not be able to handle these regions efficiently because the encoder probably needs to refine the quality of these static regions multiple times. It will cost more bits while the quality of the static regions may reach the expected degree which the flat QP setting is able to achieve. This paper proposes using different QP settings for different regions in a picture. Region classification algorithms are developed to determine whether a flat or hierarchical QP setting is used. Experimental results demonstrate that the proposed scheme can achieve an average bitrate reduction of 3.1%, and up to 8.1% bitrate reduction for IBBB coding. The proposed method improves coding efficiency without increasing encoding complexity. © 2015 IEEE.","flat QP; hierarchical QP; High Efficiency Video Coding (HEVC); quality refinement; Screen Content Coding (SCC)","Codes (symbols); Efficiency; Image coding; Visual communication; Bit-rate reduction; Computer generated; Encoding complexity; flat QP; hierarchical QP; High-efficiency video coding; Quantization parameters; Region classifications; Image processing",2-s2.0-84978985685
"Nguyen T.-H.D., Carstensdottir E., Ngo N., Seif El-Nasr M., Gray M., Isaacowitz D., Desteno D.","Modeling warmth and competence in virtual characters",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943632897&doi=10.1007%2f978-3-319-21996-7_18&partnerID=40&md5=55d19c032fc4455997363841d3ae0d02","Developing believable virtual characters has been a subject of research in many fields including graphics, animations, artificial intelligence, and human-computer interaction. One challenge towards commoditizing the use of virtual humans is the ability to algorithmically construct characters of different stereotypes. In this paper, we present our efforts in designing virtual characters that can exhibit non-verbal behaviors to reflect varying degrees of warmth and competence, two personality traits shown to underlie social judgments and form stereotypical perception. To embark on developing a computational behavior model that portrays these traits, we adopt an iterative design methodology tuning the design using theory from theatre, animation and psychology, expert reviews, user testing and feedback. Using this process we were able to construct a set of virtual characters that portray variations of warmth and competence through combination of gestures, use of space, and gaze behaviors. In this paper we discuss the design methodology, the resultant system, and initial experiment results showing the promise of the model. © Springer International Publishing Switzerland 2015.","Believable virtual characters; Non-verbal behaviour; Personality traits","Artificial intelligence; Computation theory; Human computer interaction; Iterative methods; Speech; Virtual reality; Behavior model; Design Methodology; Iterative design methodology; Non-verbal behaviours; Nonverbal behavior; Personality traits; Virtual character; Virtual humans; Intelligent virtual agents",2-s2.0-84943632897
"Akl A., Yaacoub C., Donias M., Da Costa J.-P., Germain C.","Two-stage color texture synthesis using the structure tensor field",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938902213&partnerID=40&md5=b6e142a1462bfabe1d1bd4eb631cdb59","Since reproducing the realism of the physical word is a major goal for computer graphics, color texture synthesis is important for rendering synthetic images and animations. Most of the existing synthesis techniques provide impressive results in many cases, but fail in difficult situations with large patterns, or with long range directional variations. Based on a previously developed two-stage structure/texture synthesis algorithm where the structure tensor is used to represent the structure layer, an extension to color texture synthesis is proposed. Two different methods are used for the computation of the color structure tensor field. An acceleration method for the proposed algorithm is also presented. Results show that the proposed approach successfully synthesizes the output texture in many situations where traditional algorithms fail to reproduce the exemplar's patterns and dynamics. These promising results pave the way towards 3D color textures synthesis showing multi-scale patterns. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Color structure tensor; Color texture; Multi-scale; Non parametric synthesis; Texture synthesis","Algorithms; Color; Computation theory; Computer graphics; Tensors; Color textures; Multi-scale; Non-parametric; Structure tensors; Texture synthesis; Image processing",2-s2.0-84938902213
"Watanobe Y., Mirenkov N., Watanabe M.","Educational features of *AIDA programs",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942606153&doi=10.1007%2f978-3-319-17530-0_12&partnerID=40&md5=4e5dc0459ad696c49f73cba3ac2ca90d","Programming in pictures is an approach whereby pictures and animation are used as super-characters for representing features of computational algorithms and data structures, as well as for explaining models and application methods involved. *AIDA is a language supporting programming in pictures. In this chapter, some features of *AIDA programs are discussed and how these features can be applied for educational goals oriented to users with little programming experience. Special attention is paid to new examples in which algorithmic dynamics is explained by animations and template programs supporting the implementation of this dynamics. © Springer International Publishing Switzerland 2015.","AIDA; Algorithmic cyber-scene; Educational materials","Computers; AIDA; Algorithmic cyber-scene; Application method; Computational algorithm; Educational goals; Educational materials; Programming experience; Programming in pictures; Algorithms",2-s2.0-84942606153
"Sugiyama T., Motono Y., Nagao K.","Placeness of subcultures in the Nipponbashi district, Osaka, Japan",2015,"Geographical Review of Japan",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928940419&partnerID=40&md5=c97a758e0e2b9bc85b5064af97f1f877","The purpose of this study is to examine locational shifts of specialized stores and discuss the placeness of a shopping district, the Nipponbashi district in Osaka, Japan. This district has developed as an electronic retail district since the Second World War and has recently attracted various shops of subculture, similar to the well-known case of the Akihabara district in Tokyo. Senmontengai (retail districts for specialized goods) are a distinctive feature of large cities in Japan. The Nipponbashi district is a fairly small area with a dense concentration of specialized stores. When the locational changes in retail activities were examined in detail, stores can be classified into three groups: consumer electronics; personal computers; and hobby items including animation-related products. In the electronic retail district, stores were originally concentrated in the north-central area. Booms in retail activities were associated with geographical shifts. Relatively large stores of personal computers were located in the south of the area. Otaku-related subculture stores moved to the northwest area. This area is called ""Ota Road"" (the road of Otaku). The dense clustering in Nipponbashi has an important influence not only on the scale of commercial activities but also on generating and attracting new subcultures. Nipponbashi is a unique place that is a setting for social interactions and encourages openness toward different values. To explore its placeness, we present the importance of land/store owners' tolerance in the Nipponbashi district.","Nipponbashi district; Openness; Placeness; Shopping district; Subculture; Tolerance","commercial activity; computer; cultural relations; electronic equipment; retailing; shopping activity; Honshu; Japan; Kinki; Osaka [Kinki]",2-s2.0-84928940419
"Lorenz M., Riedel T., Pürzel F., Wittstock V., Hoffmann A., Spranger M., Hoffmann A., Spranger M.","An automated way for conversion from CAD to virtual reality [Automatische Konvertierung vom CAD in die Virtuelle Realität]",2015,"Konstruktion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028018440&partnerID=40&md5=f2ae84562c233847281390051875ee80","At the moment the usage of Virtual Reality in SMEs is mainly prevented due to the complex conversion process of CAD models for Virtual Reality systems. This article outlines a concept that will allow an automated conversion of CAD data into Virtual Reality, including animations as well as kinematics, and will simplify the VR-interaction in the future.",,"Data handling; Virtual reality; CAD data; CAD models; Conversion process; Virtual reality system; Computer aided design",2-s2.0-85028018440
"Egan P.F., Schunn C., Cagan J., LeDuc P.R.","Development of graphical user interfaces to improve human design proficiency for complex multi-level biosystems",2015,"Proceedings of the ASME Design Engineering Technical Conference",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979082802&doi=10.1115%2fDETC2015-47460&partnerID=40&md5=d9ccae961bccd3a7974b99386c1ba2a1","Complex systems are challenging to design, particularly because of multi-level organizations that lead to non-obvious relationships among design components. One aspect of that challenge is how to effectively present complex information to the user for systems with multiple levels of organization. Two contrasting design graphical user interfaces (GUIs) were developed to aid multi-level biosystem design: a GUI with feedback via performance charts that emphasized learning of parametric relationships, and a GUI with feedback via agent-based animations that emphasized learning of inter-level causalities. The effectiveness of these interfaces is compared through assessing the design proficiency of human users for optimization design tasks. Results from user interactions with the interfaces demonstrated that users with both interfaces improved on pre-/post-learning design tasks, and users that demonstrated an understanding of inter-level causal relationships had greater improvement. However, only users with the animations interface tended to learn inter-level causal relationships. All users were then presented contrasting animations of systems with opposing emergent system behaviors, resulting in many more participants demonstrating an understanding of inter-level causal behaviors. These findings reveal the usefulness of interactive software tools for supporting engineers in overcoming challenges of complex systems design. Particularly, that successful design of complex systems requires unique reasoning skills that are informed by knowing how system components relate across levels, and specialized interfaces with animations provide information necessary for the learning these relationships. © Copyright 2015 by ASME.",,"Computer aided software engineering; Design; User interfaces; Causal relationships; Complex information; Graphical user interface (GUIs); Interactive software tool; Multi-level organizations; Optimization design; Parametric relationships; System components; Graphical user interfaces",2-s2.0-84979082802
"Johar K., Low C.Y., Hanapiah F.A., Jaffar A., Idris F., Abu Kasim M.A.","Towards the development of a electro encephalography based neuroprosthetic terminal device",2015,"Jurnal Teknologi",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941946202&doi=10.11113%2fjt.v76.5490&partnerID=40&md5=c96df5be4dc185abf91c9059be1ffc83","Brain-Computer Interface (BCI) using Electroencephalography (EEG) enables noninvasive direct control between human brain and machine and opens up new possibilities in providing healthcare solutions for people with severe motor impairment. This paper reviews the recent trends in neuroprostheses and presents a conceptual design for the development of a cost-effective neuroprosthetic hand deploying EEG signals. Towards the development of a brain-computer interface for neuroprostheses, EEG signals are recorded from healthy subjects using the Emotiv Suite Software. The recognition phase and signal analysis are performed using the EEGLab Software. Signal processing is required until clear rhythmic waves are obtained as a command to control a prosthetic hand. A Graphical User Interface (GUI) will be developed using Matlab Software and aided with 3D Animation as a medium of interaction for basic training for the patient before using the prosthetic hand. © 2015 Penerbit UTM Press. All rights reserved.","Brain computer interface; Electroencephalography; Neuroprostheses",,2-s2.0-84941946202
"Drossel W.-G., Wittstock V., Kollatsch C., Schumann M.","Method for the visualization of measurement results of experimental property analyses of machine tools [Methode zur Visualisierung von Messergebnissen experimenteller Eigenschaftsanalysen von Werkzeugmaschinen]",2015,"Konstruktion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027968072&partnerID=40&md5=d799463918a7e8d11fb31261de2f19eb","If measurement results of the experimental property analysis of machine tools are visualized in charts only, it is difficult to understand the overall context. A vivid impression about the change of the properties can be achieved, when the visualization of the measurement results is combined with an overlaid 3D model of the machine tool and an animation. For this purpose, an application was developed, that creates this kind of 3D visualization automatically based on the measurement data.",,"Data visualization; Three dimensional computer graphics; Visualization; 3-d modeling; 3D Visualization; Measurement data; Property analysis; Machine tools",2-s2.0-85027968072
"Zhang F., Guo J., Wan J., Qin J.","Efficient culling criteria for continues collision detection using a fast statistic analysis method",2015,"Open Mechanical Engineering Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943810499&partnerID=40&md5=321d4a03fd352d2f7c2cb3c695237535","Continuous Collision Detection (CCD) between deforming triangle mesh elements in 3D is significant in many computer and graphics applications, such as virtual surgery, simulation and animation. Although CCD is more accurate than discrete methods, its application is limited mainly due to its time-consuming nature. To accelerate computation, we present an efficient CCD method to perform both inter-object and intra-object collision queries of triangle mesh models. Given a model set of different poses as training data, our method uses Statistic Analysis (SA) to make regression on a deformation subspace and also on collision detection conditions in a pre-processing stage, under a uniform framework. A data-driven training process selects a set of “key points” and produces a credible subspace representation, from which a plug-in type of collision culling certificate can be then obtained by regression process. At runtime, our certificate can be easily added to the classic BVH traversal procedure, as a sufficient condition of collision free cases, providing efficient culling in overlapping test and reducing hierarchy updates frequency. In the end, we describe performance and quality of our method using different experiments. © 2015, Bentham Science Publishers B.V. All Rights Reserved.","CCD; Deformation body; Regression; Statistic analysis","Charge coupled devices; Collision avoidance; Deformation; Mesh generation; Object detection; Regression analysis; Collision detection; Continuous collision detection; Deformation bodies; Graphics applications; Regression; Statistic analysis; Subspace representation; Uniform framework; Three dimensional computer graphics",2-s2.0-84943810499
"Chen K.-L., Liu S.-Y., Chen P.-H.","Assessing multidimensional energy literacy of secondary students using contextualized assessment",2015,"International Journal of Environmental and Science Education",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929166055&doi=10.12973%2fijese.2015.241a&partnerID=40&md5=e9c507523044494d8aa8c96b69120502","Energy literacy is multidimensional, comprising broad content knowledge as well as affect and behavior. Our previous study has defined four core dimensions for the assessment framework, including energy concepts, reasoning on energy issues, low-carbon lifestyle, and civic responsibility for a sustainable society. The present study compiled a series of contextualized question items into a computer-based test (CBT) platform to examine students’ energy literacy. Each test unit included a scenario, presented via multimedia materials (e.g., text, image, short video, and animation), that pertained to real-life situations. Various types of questions were employed (e.g., multiple true-false, multiple choice, and short-answer) that required students to construct responses and make judgments. A total of 1,711 secondary school students participated in this survey. The results indicate that the energy literacy level of Taiwanese secondary students is discouragingly low and inter-correlations between the dimensions of energy literacy reveal that energy knowledge and behavior are more closely correlated than affect and behavior. In addition, the scores on the attitudinal items were slightly higher for junior than senior students and the students in the southern region scored higher on energy literacy than those in other regions. These findings provide evidence for the future development of energy-related educational curricula and materials that can improve students’ energy literacy and engagement in energy-related decisions. © 2015 by iSER, International Society of Educational Research.","Assessment; Computer-based test; Energy education; Energy literacy",,2-s2.0-84929166055
"Tapia C., San Segundo P., Artieda J.","A PDDL-based simulation system",2015,"Proceedings of the European Conference on Data Mining 2015, ECDM 2015 and International Conferences on Intelligent Systems and Agents 2015, ISA 2015 and Theory and Practice in Modern Computing 2015, TPMC 2015 - Part of the Multi Conference on Computer Science and Information Systems 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970028890&partnerID=40&md5=d5eda142c954840e324c9e6af7861797","This paper presents a planning simulation system that allows automated planning practitioners to experiment with planning domains, defined using the PDDL language. The proposed system has a modular architecture including a SAT planner (PDDL parser, SAT encoder and SAT solver), a plan simulator and a 3D view user interface. Most of these modules can be changed with other with similar purpose. This system allows users to test and validate PDDL domains and solutions, using an attractive user interface that includes the simulation of the execution of the plan on a 3D view as an animation.","Artificial intelligence; Automated planning; PDDL; SAT; Simulation","Artificial intelligence; Computation theory; Computer simulation languages; Intelligent systems; User interfaces; Automated planning; Modular architectures; PDDL; Planning domains; SAT solvers; Simulation; Simulation systems; Data mining",2-s2.0-84970028890
"Wang D.S., Jani A.B., Sesay M., Tai C.G., Lee D.K., Echt K.V., Goodman M.G., Kilbridge K.E., Master V.A.","Video-based educational tool improves patient comprehension of common prostate health terminology",2015,"Cancer",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923310230&doi=10.1002%2fcncr.29101&partnerID=40&md5=f569052d868aedc2941be8534b1ac041","BACKGROUND: Health care providers often counsel prostate cancer patients about treatment options with medical terminology. However, studies have demonstrated a severe lack of comprehension of these terms, particularly in underserved populations. It was hypothesized that a video-based educational tool would significantly improve the understanding of key terms related to prostate health in a predominantly lower literacy population. METHODS: A software application was developed by various experts, including urologists and human-computer interaction specialists, to serve as a video-based educational tool emphasizing narrated animations to promote understanding of terms related to urinary, bowel, and sexual function. This application was viewed by patients recruited from 2 low-income safety net clinics, where a previously developed survey was administered to assess pre- and postintervention levels of comprehension. RESULTS: Fifty-six patients with a mean literacy level of 7th to 8th grade completed the study. Patients achieved statistically significant improvements in comprehension for the majority of the terms after the video intervention, with notable improvements including the terms incontinence (from 14% to 50%), bowels (from 14% to 46%), and impotence (from 58% to 84%). Patients demonstrated significant gains in their understanding of the function of the prostate (from 11% to 30%) and in their ability to locate the prostate on anatomic drawings (from 50% to 82%). CONCLUSIONS: This video-based educational tool is an effective method for overcoming the severe lack of comprehension of prostate health terminology among patients. The improvements achieved have the potential to enhance patient participation in shared and informed decision making and to support combined visual-audio multimedia as a promising tool for prostate cancer education. © 2014 American Cancer Society.","Health literacy; Multimedia; Patient education; Prostate cancer; Shared decision making","adult; Article; clinical effectiveness; comprehension; computer program; functional anatomy; health education; health literacy; human; impotence; incontinence; intestine function; major clinical study; male; medical terminology; middle aged; outcome of education; patient education; priority journal; prostate cancer; videorecording; attitude to health; multimedia; nomenclature; physiology; poverty; procedures; prostate; questionnaire; Comprehension; Health Education; Health Knowledge, Attitudes, Practice; Health Literacy; Humans; Male; Middle Aged; Multimedia; Poverty; Prostate; Questionnaires; Terminology as Topic",2-s2.0-84923310230
"Andreev V., Karbanov V., Kharin K., Kuvshinov S., Poduraev Y., Pryanichnikov V.","Training situation center based on three-dimensional virtual studio for distributed mobile robotics laboratory",2015,"Annals of DAAAM and Proceedings of the International DAAAM Symposium",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987618914&doi=10.2507%2f26th.daaam.proceedings.064&partnerID=40&md5=b0fa04bba3199feab1fa143eb70d5780","We consider the problems of creating a training situation center for training management skills of mobile robotic systems control based on the concept of territorially distributed laboratory. This task can be efficiently performed by means of three-dimensional rendering system and software and hardware support for information analysis and management activities. The base concept of approach is the real-Time virtual studio that provides computer simulation of threedimensional scenes and motion of actual mobile robots, real-Time operation with multiple cameras and have powerful and fast 3D and stereoscopic real-Time rendering. We have developed 3D scenes corresponding to places of the intended use of robotic devices and additionally several polygonal 3D models of external artifacts, textures for them and finally recorded animation layers with appropriate controllers of the virtual studio. Mobile robots moved against a background of the chromakey green screen in different places of distributed laboratory are incorporated into the virtual network laboratory on the basis of VPN-Tunnels through the Internet by special software.","3D Virtual Studio; Local Area Network; Mobile Robots; Real-Time Simulation; Territorially Distributed Laboratory; Training Situation Center","Information management; Laboratories; Local area networks; Mobile robots; Robotics; Robots; Stereo image processing; Studios; Management activities; Mobile robotic systems; Real time simulations; Real-time operation; Situation centers; Software and hardwares; Three-dimensional scenes; Virtual Studio; Three dimensional computer graphics",2-s2.0-84987618914
"Mercy Gnana Gandhi S.","Technology and multimedia in the language classrooms: A special focus on Indian engineering students",2015,"International Journal of Applied Engineering Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928910525&partnerID=40&md5=d5d3606e5cf5b455e7c91b880aa249c0","Due to the unexpected leaping of technology beyond the boundaries, multimedia technology has taken the rightful place in English language teaching, especially in the non-native speaking countries and situations. It also aims at building the non-native speakers of English, as language teachers, making them aware of the technical strategies to use multimedia in an effective way. The sudden reformation and exploration of technology lead to changes in the language style of student community, particularly among the engineering students and their English language usage. Innovations such as multimedia and internet bring audio, visual, and animation effects in the English language classroom and thus improve classroom activities and the way of communication has been brought well-advanced. This paper aims at analyzing the use of technology to English language teaching in India by highlighting the role of language teachers and students of engineering colleges and universities. It discusses different techniques which can lend a hand to language teachers and students to improve their learning skills by using computer assisted language learning programs, presentation software, electronic dictionaries and listening to CD players. The author has compared the conventional method and the modern method of using software through multimedia. Finally, the papers were valued and the scores have been displayed through bar diagrams. We may call this CG – the Control Group. These diagrams were compared with the graphs of the modern method of EG – the Experimental Group. The graphs themselves demonstrate the validity of the methods. © Research India Publications.","Computers; Engineering colleges; Language teaching; Method; Multimedia; Technology",,2-s2.0-84928910525
"Melenbrink N., King N.","Fulldome interfacing: A real-time immersive environment as a tool for design",2015,"CAADRIA 2015 - 20th International Conference on Computer-Aided Architectural Design Research in Asia: Emerging Experiences in the Past, Present and Future of Digital Architecture",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936088471&partnerID=40&md5=34097e60847ca4e76fe5560ea0fd13f8","The ability to communicate design intent to potential users, clients, and communities is fundamental to the process of architectural design. Conventionally, this need is addressed through phased submissions of drawings, renderings, animations, and physical models- All with the intention of representing space and its constituent elements. Recent technological advancements however-including tools like those produced by OculusTM-have begun to present new opportunities for spatial representation through the use of simulated 3D environments that are both convenient for the design team and readily accepted by clients and end users.i While immersive technologies do present novel representational opportunities, current workflows position the potential at the conclusion of the design process, not as part of it. The project presented here moves beyond mere representation and positions simulated 3D environments within the design process itself. To this end, an integrated real-time computational workflow that enables the use of simulated spatial experience as an iterative design tool was developed in order to create the illusion of being in a space while it is being designed and allowing experientially informed decision making. The Fulldome Interface creates a collaborative immersive environment that utilizes a novel computational design workflow (linking the parametric GrasshopperTM for RhinocerosTM design environment to the Unity3DTM gaming engine) that responds in real-time through dome-based stereoscopic projection that can be experienced by multiple occupants simultaneously. © 2015 All rights reserved and published by The Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.","Fulldome; Immersive; Interface; Parametric design; Real-time","Computer architecture; Decision making; Design; Interfaces (materials); Stereo image processing; Fulldome; Immersive; Immersive environment; Immersive technologies; Parametric design; Real time; Spatial representations; Technological advancement; Architectural design",2-s2.0-84936088471
"Olsson M., Mozelius P.","Visualization of concepts and algorithms in programming education - A design theoretic multimodal perspective",2015,"Proceedings of the International Conference on e-Learning, ICEL",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940657052&partnerID=40&md5=75675c8b5717af6358c1c347f298e137","Programming is an important core subject in most Computer science programmes at university level but many students have difficulties to learn the necessary combination of knowledge and skills. Code concepts and algorithms are abstract and dynamic entities, where teachers face problems with the transfer of theoretical concepts as well as with the explanation of more practical programming techniques. Software visualization with the multimodal combination of graphical, audial and textual representations aims to facilitate learning and understanding of programming. Software visualization can further be divided into program visualization and algorithm visualization. This study presents a design theoretic multimodal approach where software visualization is introduced and evaluated as an extra communication channel between teachers and students in programming courses. Two visualization prototypes have been designed and developed for evaluation in lectures for an experimental group. Data has been gathered by handing out questionnaires to students in the experimental group and to students in a control group. Both groups had attended the same lecture setup, with identical learning content but only the experimental group had access to the multimodal program visualization and algorithm visualization prototypes. 85% in the experimental group and 62% in the control group stated that they did understand where the focus of the code executing was all through the prototype for algorithm visualization. For the other prototype, visualizing object-oriented concepts, 60% in the experimental group and 54% in the control group stated that they understood where the focus of the code executing was all through the multimodal animation. Findings indicate that programming lecturing using multimodal explanations as additional learning tools is a promising path to enhance programming education in the 21st century. Guided by multimodal design theory, we can better understand how appropriate activities for novice student's learning of programming concepts should be implemented. A problem with the evaluated prototypes that was identified is focus overload during execution of object-oriented animations. One possible solution to address this issue might be to divide the object visualization into two parts, where one is dealing with concepts and the other is illustrating dynamics.","Algorithm visualization; Multimodality; Program visualization; Programming education; Software visualization","Algorithms; Codes (symbols); Computer programming; Curricula; E-learning; Education; Object oriented programming; Programming theory; Surveys; Teaching; Visualization; Algorithm visualization; Multi-modality; Program visualization; Programming education; Software visualization; Students",2-s2.0-84940657052
"Rodrigues A., Machado P., Martins P., Cardoso A.","Sound visualization through a swarm of fireflies",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945958732&doi=10.1007%2f978-3-319-23485-4_67&partnerID=40&md5=246209bb2cd1cb8a27a76d69dccf52dc","An environment to visually express sound is proposed. It is based on a multi-agent system of swarms and inspired by the visual nature of fireflies. Sound beats are represented by light sources, which attract the virtual fireflies. When fireflies are close to light they gain energy and, as such, their bioluminescence is emphasized. Although real world fireflies do not behave as a swarm, our virtual ones follow a typical swarm behavior. This departure from biological plausibility is justified by aesthetic reasons: the desire to promote fluid visualizations and the need to convey the perturbations caused by sound events. The analysis of the experimental results highlights how the system reacts to a variety of sounds, or sequence of events, producing a visual outcome with distinct animations and artifacts for different musical pieces and genres. © Springer International Publishing Switzerland 2015.","Computer art; Multi-agent systems; Sound visualization; Swarm intelligence","Artificial intelligence; Bioluminescence; Intelligent agents; Light sources; Visualization; Computer art; Musical pieces; Real-world; Sequence of events; Sound events; Sound visualization; Swarm behavior; Swarm Intelligence; Multi agent systems",2-s2.0-84945958732
"Lahami M., Krichen M., Barhoumi H., Jmaiel M.","Selective test generation approach for testing dynamic behavioral adaptations",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952784381&doi=10.1007%2f978-3-319-25945-1_14&partnerID=40&md5=265addcd61f84aaa03ac15f3f93c38ec","This paper presents a model-based black-box testing app- roach for dynamically adaptive systems. Behavioral models of such systems are formally specified using timed automata. With the aim of obtaining the new test suite and avoiding its regeneration in a cost effective manner, we propose a selective test generation approach. The latter comprises essentially three modules: (1) a model differencing module that detects similarities and differences between the initial and the evolved behavioral models, (2) an old test classification module that identifies reusable and retestable tests from the old test suite, and finally (3) a test generation module that generates new tests covering new behaviors and adapts old tests that failed during animation. To show its efficiency, the proposed technique is illustrated through the Toast application and compared to the classical Regenerate All and Retest All approaches. © IFIP International Federation for Information Processing 2015.",,"Behavioral research; Black-box testing; Computer software reusability; Cost effectiveness; Testing; Behavioral adaptation; Behavioral model; Cost effective; Dynamically adaptive systems; Its efficiencies; Model-based OPC; Test generations; Timed Automata; Software testing",2-s2.0-84952784381
"Soga A., Yoshida I.","Interactive control of dance groups using kinect",2015,"GRAPP 2015 - 10th International Conference on Computer Graphics Theory and Applications; VISIGRAPP, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938898797&partnerID=40&md5=408ffe95eeff2a052a94c1c21e44c5de","This paper describes a system that can control the CG animation of dance groups in a virtual world by recognizing gestures using Kinect in real time. The system can change the formation of CG dancers by rightarm gestures and their motions by left-arm gestures. Moreover, a virtual camera is controlled by the gestures of both arms. The rotational data of the joints are used to recognize each arm gesture to control the dance groups, and the translational data of the joints are used to control the virtual camera. Since the system recognizes both arm gestures at the same time, users can control two or more objects by a combination of gestures. Copyright © 2015 SCITEPRESS - Science and Technology Publications. All rights reserved.","Dance groups; Gesture recognition; Kinect; Motion data","Cameras; Computer graphics; Virtual reality; Arm gestures; Dance groups; Interactive control; Kinect; Motion data; Rotational data; Virtual camera; Virtual worlds; Gesture recognition",2-s2.0-84938898797
"Transue S., Choi M.-H.","Deformable object behavior reconstruction derived through simultaneous geometric and material property estimation",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952802040&doi=10.1007%2f978-3-319-27863-6_44&partnerID=40&md5=350b5a039eac022cc3cc6b6751b2eade","We present a methodology of accurately reconstructing the deformation and surface characteristics of a scanned 3D model recorded in real-time within a Finite Element Model (FEM) simulation. Based on a sequence of generated surface deformations defining a reference animation, we illustrate the ability to accurately replicate the deformation behavior of an object composed of an unknown homogeneous elastic material. We then formulate the procedural generation of the internal geometric structure and material parameterization required to achieve the recorded deformation behavior as a non-linear optimization problem. In this formulation the geometric distribution (quality) and density of tetrahedral components are simultaneously optimized with the elastic material parameters (Young’s Modulus and Possion’s ratio) of a procedurally generated FEM model to provide the optimal deformation behavior with respect to the recorded surface. © Springer International Publishing Switzerland 2015.",,"Deformation; Elasticity; Finite element method; Geometry; Nonlinear programming; Optimization; Probability distributions; Deformation behavior; Geometric and material properties; Geometric distribution; Geometric structure; Material parameterization; Non-linear optimization problems; Optimal deformation; Surface characteristics; Three dimensional computer graphics",2-s2.0-84952802040
"Jie M., Riley P.","Integrated optimized design of mobile phone interface based on human factors engineering",2015,"Journal of Mechanical Engineering Research and Developments",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979520418&partnerID=40&md5=1caed033adadd0a244bafae10ade92e0","Human factors engineering is a new rapidly developing interdisciplinary, which involves many subjects. Nowadays, with the continuous development of science and technology, mobile phone as a new medium has penetrated into people's daily life and work. As a platform of information exchange between human and machine, the mobile phone interface is now a new type of special and independent system which has beyond the scope of traditional interface design. The success of the web interface design is not just depends on its beautiful layout, harmonious color, and gorgeous animation effect, but also on its ease of use and people's acceptability. Practicability and artistic form of emotion is an eternal state of design. From a certain level, the continuous development and improvement of design is the continuous improvement of people's cognition, emotion and thought. Therefore, mobile phone interface is constructed by emotional design method, and human-machine interaction interface is perfected by applying human factors engineering knowledge.","Artistic form of emotion; Human factors engineering; Human-machine interaction; Mobile phone interface; Practicability","Cellular telephones; Design; Human computer interaction; Human engineering; Man machine systems; Mobile phones; Telephone sets; Artistic form of emotion; Continuous development; Continuous improvements; Human machine interaction; Information exchanges; Mobile phone interfaces; Practicability; Web interface design; Cellular telephone systems",2-s2.0-84979520418
"Rostianingsih S., Chang M., Liliana","Multimedia design for learning media of majapahit",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930441610&doi=10.1007%2f978-3-662-46742-8_33&partnerID=40&md5=910ef5d73f345732372485a663f0b269","Majapahit was one of the last major empires of the region and is considered to be one of the greatest and most powerful empires in the history of Indonesia and Southeast Asia. However, learning history is became unpopular to young generation. Interactive media can help society to learn history enjoyable. This interactive multimedia will allow the reader to interact with combination of text, image, sound, and animations of Majapahit. There are three aspects of disccusion which are economics, politics, also arts and cultures. Each aspects will provide information related with Majapahit. From the results of questionnaire can be conclude that interactive multimedia form is more interesting than history’s books which full of text. The audience is satisfy with the utility and interaction form. Their knowledge also improve after they use the application. © Springer-Verlag Berlin Heidelberg 2015.","Interactive; Majapahit; Multimedia","Big data; Intelligent systems; Interactive computer systems; Multimedia systems; Soft computing; Indonesia; Interactive; Interactive media; Interactive multimedia; Learning media; Majapahit; Multimedia; Southeast Asia; Intelligent computing",2-s2.0-84930441610
"Sebastian J., Tai C.-Y., Lindholm K., Hsu Y.-L.","Development of caricature robots for interaction with older adults",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949814996&doi=10.1007%2f978-3-319-20913-5_30&partnerID=40&md5=db5167e9863c551fda009e95059f52c1","This paper proposes a concept of combining the techniques of classic animation and robotic design to create a simple robot capable of interacting with older adults, denominated “caricature robots”. A caricature robot can be described as “a non-humanoid robot that can show simplified humanoid motions in exaggerated ways”. To achieve that illusion, three key elements should be met in a caricature robot: functionality, simplicity in motion and personality. While interaction for every older adult can be different, users are allowed to personalize their caricature robot by creating their own set of motions and personas that suits their personal taste. This is made possible through the “Body Cerebellar and Brain” control structure and the MotionClips software developed in this research. MusicMouth is used to exemplify caricature robots. Through the advantage of customization and personalization, caricature robots present a range of scenarios. © Springer International Publishing Switzerland 2015.","Caricature robots; Interaction; Robotic motion design","Anthropomorphic robots; Human computer interaction; Robotics; Robots; Control structure; Humanoid robot; Interaction; Key elements; Motion design; Older adults; Personalizations; Robotic design; Machine design",2-s2.0-84949814996
"Cheng T.-S., Lu Y.-C., Yang C.-S.","Teaching effectively with the multi-screen multimedia integrated system",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961375677&doi=10.1007%2f978-3-662-46315-4_21&partnerID=40&md5=5cff4423d48c1031b2872071c51b612d","Multimedia resources, such as images, sounds, videos and animations, aid for learning effectiveness when teachers utilize these elements to demonstrate concepts or conveying information. However, teachers often confronted with the limitations of showing more contents from multiple multimedia resources while preparing the teaching material. This research revealed that the multi-screen display could assist teachers to overcome the limitations and reduce the students’ cognitive load. Moreover, a “multi-screen multimedia integrated system” was proposed to provide teachers a platform for designing and displaying the multimedia teaching materials in multi-screen. The system was developed with intuitive design interface and functional displaying objects. With practical experiments, the system was proved to increase the efficiency both in teaching and learning. © Springer-Verlag Berlin Heidelberg 2015.","Cognitive load; Integrated teaching system; Multi-screen; Multimedia","Computer aided instruction; Education; Integrated control; Knowledge management; Multimedia systems; Social networking (online); Teaching; Ubiquitous computing; Websites; Cognitive loads; Integrated teaching; Learning effectiveness; Multi screens; Multi-screen displays; Multimedia; Multimedia teachings; Teaching and learning; E-learning",2-s2.0-84961375677
"Guo H.J., Fan W., Wang S., Huang N.","The research of aircraft assembly simulation based on motion capture and application in production worksite",2015,"Advances in Energy Science and Equipment Engineering - Proceedings of International Conference on Energy Equipment Science and Engineering, ICEESE 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973532120&partnerID=40&md5=c0f7c533e95305aafa9683d2c9633484","The aircraft assembly simulation is a hot direction in the field of aircraft manufacturing. Due to the closed space and complex layout in the engine room, man-machine engineering simulation is applied to the aircraft assembly. Motion capture is a potential way to complete the man-machine engineering simulation. In this paper, we present the man-machine engineering simulation solution based on motion capture, respectively verified in Delmia and the software independently developed for assembly simulation. The simulation results, such as simulation animation and simplified 3D models, are displayed on the mobile terminals in the production worksite. Finally the aircraft component assembly simulation is presented as an example, to prove the feasibility of the proposed solution. © 2015 Taylor & Francis Group, London.",,"Aircraft; Assembly; Equipment; Aircraft assemblies; Aircraft components; Aircraft manufacturing; Assembly simulation; Closed spaces; Engineering simulation; Mobile terminal; Motion capture; Computer software",2-s2.0-84973532120
"Cai D., He X., Yu Z., Wang L., Xie G., Ai Q.","3D power-map for smart grids - An integration of high-dimensional analysis and visualization",2015,"IET Conference Publications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962668683&partnerID=40&md5=40d06839c1f197473a2b1f194e3a6c5b","Data with features of volume, velocity, variety, and veracity are challenging traditional tools to extract useful analysis for decision-making. By integrating high-dimensional analysis with visualization, this paper develops a 3D power-map animation as an effective solution to the challenge. An architecture design, with detailed data processing procedure, is proposed to realize the integration. Two of the most important components in the architecture are presented: the Single-Ring Law for random matrices as solid mathematic foundation, and the proposed statistic MSR as high-dimensional data for visualization. The whole procedure is easy in logic, fast in speed, objective and even robust against bad data. Moreover, it is an unsupervised machine learning mechanism directly oriented to the raw data rather than logics or models based on simplifications and assumptions. A case study validates the effectiveness and performance of the developed 3D power-map in analysis extraction.","3D power-map; Big data; High-dimensional analysis; Smart grid; Visualization","Artificial intelligence; Big data; Clustering algorithms; Data handling; Data mining; Data visualization; Decision making; Electric power transmission networks; Flow visualization; Learning systems; Three dimensional computer graphics; Visualization; Architecture designs; Effective solution; High dimensional data; High-dimensional; Mathematic foundation; Processing procedures; Smart grid; Unsupervised machine learning; Smart power grids",2-s2.0-84962668683
"Choroś K.","Automatic categorization of shots in news videos based on the temporal relations",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983770713&doi=10.1007%2f978-3-319-24306-1_2&partnerID=40&md5=76131c0c0d48192e7437e7842d5e1fad","The development of new methods and technologies of video indexing and retrieval is stimulated by the growing amount of digital video data stored in Internet video collections, TV shows archives, video-on-demand systems, personal video archives offered by Web services, etc. The videos very frequently offered in the Web by broadcast channels are news videos and sports news videos. Content-based indexing of videos is based on the automatic detection of a video structure. A video shot is the main structural video unit. Shots can be of different categories such as intro or final animation, chart or table shots, anchor, reporter, statement, or interview shots, and finally the most informative report shots. The temporal aggregation results in grouping of shots into scenes of a given category. The paper examines the usefulness of the temporal aggregation method to select report shots and non-report shots in a news video. © Springer International Publishing Switzerland 2015.","Content-based video indexing; Digital video segmentation; News shots categories; News videos; Temporal aggregation; Video structures","Indexing (of information); Multimedia systems; Search engines; Video on demand; Video signal processing; Web services; Content based video indexing; Digital videos; News shots categories; News video; Temporal aggregation; Video structures; Computer graphics",2-s2.0-84983770713
"Saenz M., Strunk J., Maset K., Malone E., Seo J.H.","See the flex: Investigating various display settings for different study conditions",2015,"Communications in Computer and Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945899564&doi=10.1007%2f978-3-319-21383-5_50&partnerID=40&md5=5c6674809f3cfa5c9db7344673768736","We present FlexAR, a kinetic tangible augmented reality (TAR) [5] application for anatomy education in varied learning situations. Learning anatomy is fundamental to every health profession as well as related domains such as performance, physical therapy, art, and animation. For example, dancers need to learn anatomy to care for their bodies and learn to move efficiently. Anatomy has traditionally been taught in two dimensions, particularly for those in non-medical fields such as artists and physical education practitioners. Medical students often gain hands-on experience through cadaver dissections [8]. However, with dissection becoming less practical, researchers have begun evaluating techniques for teaching anatomy through technology. Our goal is to develop TAR interfaces to enhance the effectiveness of learning gross anatomy in group and individual study settings. We believe that once expanded FlexAR could be effective as a standalone or supplementary tool for both group and individual learning. © Springer International Publishing Switzerland 2015.","Augmented reality; Education; Human anatomy; Tangible user interface","Augmented reality; Dissection; Education; Tar; User interfaces; Anatomy educations; Health professions; Human anatomy; Individual learning; Learning situation; Medical students; Physical education; Tangible user interfaces; Human computer interaction",2-s2.0-84945899564
"Nedungadi P., Malini P., Raman R.","Inquiry based learning pedagogy for chemistry practical experiments using OLabs",2015,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921499979&doi=10.1007%2f978-3-319-11218-3_56&partnerID=40&md5=20d002d5d8dc58ccf4891e707fb7fb39","Our paper proposes a new pedagogical approach for learning chemistry practical experiments based on three modes of inquiry-based learning namely; structured, guided and open. Online Labs (OLabs) is a web-based learning environment for science practical experiments that include simulations, animations, tutorials and assessments. Inquiry-based learning is a pedagogy that supports student-centered learning and encourages them to think scientifically. It develops evidence based reasoning and creative problem solving skills that result in knowledge creation and higher recall. We discuss the methodology and tools that OLabs provides to enable educators to design three types of inquiry-based learning for Chemistry experiments. The integration of inquiry-based learning into OLabs is aligned with the Indian Central Board of Secondary Education (CBSE) goal of nurturing higher order inquiry skills for student centered and active learning. Inquiry-based OLabs pedagogy also empowers the teachers to provide differentiated instruction to the students while enhancing student interest and motivation. © Springer International Publishing Switzerland 2015.","Chemical Sciences; Chemistry; Guided inquiry; IBL; Inquiry-based learning; Olabs; Online Labs; Open inquiry; Simulations; Structured inquiry; Virtual Labs","Artificial intelligence; Chemistry; E-learning; Education; Problem solving; Social networking (online); Students; Teaching; Chemical science; Guided inquiry; IBL; Inquiry-based learning; Olabs; Online labs; Open inquiry; Simulations; Structured inquiry; Virtual lab; Computer aided instruction",2-s2.0-84921499979
"Pathak A.K., Mishra N., Vaz A.","Modeling and simulation of a three-joint prosthetic finger actuated by remaining functional natural fingers: A bond graph approach",2015,"2nd International and 17th National Conference on Machines and Mechanisms, iNaCoMM 2015",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015220328&partnerID=40&md5=9b966f970791f84ec2f3d4d550c79f86","This paper addresses issues pertaining to hand prostheses with functional finger joints actuated by remaining natural fingers. These offer improved options for rehabilitation of hand impairments with partial disabilities. A prosthetic finger mechanism with three joints, offering greater dexterity and based on the like-unlike configuration presented earlier is used to realize the implementation of the abstract concept of Opposition Space. A methodology for modeling and simulating the dynamics of a three-joint prosthetic finger actuated by remaining natural finger joints based on the string-tube mechanism using multibond graph is presented here. The numerical simulation of the Bond graph model is performed using MATLAB and SCILAB. 3D animation of the simulated results performed in the open source VRML environment has been used to obtain a better understanding through visualization. © 2015, Indian Institute of Technology, IIT. All rights reserved.","Equations (to be formatted in 9pt Times New Roman); Figures; Margins; Tables","Graph theory; MATLAB; Prosthetics; Three dimensional computer graphics; Equations (to be formatted in 9pt Times New Roman); Figures; Margins; Model and simulation; Modeling and simulating; Prosthetic fingers; Simulated results; Tables; Joint prostheses",2-s2.0-85015220328
"Nappi M.","Lillian F. schwartz redux: In movement, color and 3D chromostereoscopy",2015,"Leonardo",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921852799&doi=10.1162%2fLEON_a_00894&partnerID=40&md5=daa7ddcb7f504dcb124005ad2783c686","This article examines three computer animations created by the pioneering filmmaker Lillian F. Schwartz circa 1970 that are currently viewable in 3D chromostereoscopy, specifically with ChromaDepth® 3D glasses. Reimaging these works 40 years after their creation permits a renewed formalist experience and a thematic analysis that reveals the primacy of Schwartz’s concern with depth and visual perception as part of her poetic sensibility. Excerpted interviews between the author and Lillian Schwartz are provided as an online appendix to this paper. © 2015 ISAST.",,,2-s2.0-84921852799
"Liu P., Zhu C.-F.","Virtual machining",2015,"HandBook of Manufacturing Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948758452&doi=10.1007%2f978-1-4471-4670-4_16&partnerID=40&md5=df712fc09744d65675764370eb33767a","Virtual machining simulates NC code to discover errors, without a time consuming trial run or online debugging on real machine tool. Since machining is a material removal process that will deform the workpiece geometry with cutting, the traditional rigid geometrical model could not be used to describe the in-process status of workpiece, which changes shape continually. The evolution of deformable workpiece model from the 2D sections to 3D representations revolutionized not only the machining industry, but also pioneered the digital manufacturing age with virtual manufacturing. This chapter traces back the history of CNC simulation, analysis of the different CNC machining models, tested with application examples, and lists different CNC verification industry applications for the last 30 years. Working towards a vision of pervasive modelling and simulation, a unified voxel-based in-process geometry model for multiple-machining and 3D printing simulations is discussed with industrial applications of composite material plating simulation. The virtual machine tool, which includes material removal animation and machine kinetic movement, can be controlled with a virtual CNC control panel and equipped with virtual jigs and inspection tools, such as dial indicator and wiggler, for immersive training of a young machinist. Towards a competitive sustainable manufacturing future, pervasive applications of virtual machining are not only technologically possible, but also make business sense, in this high material and energy cost world. © Springer-Verlag London 2015. All rights reserved.",,"3D printers; Agile manufacturing systems; Geometry; Jigs; Machine tools; Manufacture; Program debugging; Three dimensional computer graphics; Digital manufacturing; Geometrical modeling; Industry applications; Material removal process; Modelling and simulations; Pervasive applications; Sustainable manufacturing; Virtual manufacturing; Virtual machine",2-s2.0-84948758452
"Mangnus L., Meijer D.T., Stufkens S.A., Mellema J.J., Steller E.P., Kerkhoffs G.M.M.J., Doornberg J.N.","Posterior malleolar fracture patterns",2015,"Journal of Orthopaedic Trauma",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940207482&doi=10.1097%2fBOT.0000000000000330&partnerID=40&md5=77c7e9447a42a3fb4c72cf310363587a","Objective: To characterize posterior malleolar fracture morphology using Cole fracture mapping and to study reliability of quantification of 3-dimensional computed tomography (CT)-modeling for posterior malleolar fractures with respect to quantification of fragment size (in cubic millimeter) and true articular involvement (in square millimeter). Methods: CT scans of a consecutive series of 45 patients with an ankle fracture involving the posterior malleolus were reconstructed to calculate (1) fracture maps, (2) fragment volume, (3) articular surface of the posterior malleolar fragment, (4) articular surface of intact tibia, and (5) articular surface of the medial malleolus by 3 independent observers. Three-dimensional animation of this technique is shown on www.traumaplatform.org. Results: Fracture mapping revealed (1) a continuous spectrum of posterolateral oriented fracture lines and (2) fragments with posterolateral to posteromedial oriented fracture lines extending into the medial malleolus. Reliability of measurements of the volume and articular surface of posterior malleolar fracture fragments was defined as almost perfect according to the categorical system of Landis (interclass coefficient, range, 0.978-1.000). Conclusions: Mapping of posterior malleolar fractures revealed a continuous spectrum of Haraguchi III to I fractures and identified Haraguchi type II as a separate pattern. Quantification of 3-dimensional CT-modeling is reliable to assess fracture characteristics of posterior malleolar fracture fragments. Morphology might be more important than posterior malleolar fracture size alone for clinical decision making. © 2015 Wolters Kluwer Health, Inc.","ankle; posterior malleolar fracture; Q3DCT","Article; bone mass; clinical article; clinical decision making; clinical evaluation; computer assisted tomography; human; image analysis; interrater reliability; malleolus fracture; measurement accuracy; musculoskeletal system parameters; posterior malleolar fracture; priority journal; radiological parameters; three dimensional imaging; tibia; adult; ankle fracture; computer assisted tomography; female; injuries; male; middle aged; procedures; radiography; reproducibility; sensitivity and specificity; tarsal bone; three dimensional imaging; Adult; Ankle Fractures; Female; Humans; Imaging, Three-Dimensional; Male; Middle Aged; Reproducibility of Results; Sensitivity and Specificity; Tarsal Bones; Tibia; Tomography, X-Ray Computed",2-s2.0-84940207482
"Raman R.","Flipped labs as a smart ICT innovation: Modeling its diffusion among interinfluencing potential adopters",2015,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921341675&doi=10.1007%2f978-3-319-11218-3_55&partnerID=40&md5=4033412badc3e13b9acbf5ccaa364abb","Smart ICT innovation like flipped classroom pedagogy is freeing up face-to-face in-class teaching system for additional problem based learning activities in the class. But the focus of flipped classrooms is more on the theory side with related lab work in science subjects further getting marginalized. In this paper we are proposing Flipped Labs - a method of pedagogy premeditated as a comprehensive online lab learning environment outside the class room by means of tutorials, theory, procedure, animations and videos. Flipped labs have the potential to transform the traditional methods of lab teaching by providing more lab time to students. An ICT educational innovation like flipped labs will not occur in isolation in an environment where two interrelated potential adopters namely teachers and students influence each other and both have to adopt for the innovation to be successful. In this paper we provide the theoretical framework for the diffusion and the adoption patterns for flipped labs using theory of perceived attributes and take into account the important intergroup influence between teachers and students. The results of this analysis indicated that Relative Advantage, Compatibility, Ease of Use, Teacher Influence and Student Influence were found to be positively related to acceptance of flipped labs. © Springer International Publishing Switzerland 2015.","Chemistry; Flipped classroom; ICT; Innovation; Online Labs; Simulations","Chemistry; Computer aided instruction; Education; Innovation; Laboratories; Social networking (online); Students; Educational innovations; Flipped classroom; ICT; Learning environments; Online labs; Problem based learning; Simulations; Theoretical framework; Teaching",2-s2.0-84921341675
"Donlon J.P., Poulard D., Lessley D., Riley P., Subit D.","Understanding how pre-impact posture can affect injury outcome in side impact sled tests using a new tool for visualization of cadaver kinematics",2015,"Journal of Biomechanics",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921340785&doi=10.1016%2fj.jbiomech.2014.12.042&partnerID=40&md5=77055170415888e5d6b214e424c95b40","The effect of posture and subject-specific factors on injury outcome is an active field of research in injury biomechanics, in particular in automotive safety research where post-mortem human subjects (PMHS) are used as surrogates. Current PMHS tests routinely include acquisition of the subjects[U+05F3] geometry and kinematics. However, combining these two datasets to better understand the injury mechanism is still a challenge. This study investigated the connection between pre-impact posture and resulting injuries in six previously published side impact sled tests (three with a rigid wall and three with an airbag) by creating three-dimensional kinematic animations (3DKA) of the tests. The 3DKA allow qualitative assessment of parameters related to posture and their possible effect on injury outcome. The orientation of the struck scapula and the lateral leaning of the torso were identified as potentially significant parameters. The ranges of variation in these parameters were quantified and compared to the number of rib fractures for each subject: the data suggested a correlation, but there was insufficient data for a probabilistic analysis. The 3DKA were published with this study and are freely available. © 2015 Elsevier Ltd.","Kinematics; Posture; Side impact; Visualization","Flow visualization; Safety testing; Visualization; Injury biomechanics; Injury mechanisms; Posture; Probabilistic analysis; Qualitative assessments; Ranges of variations; Side impact; Three-dimensional kinematics; Kinematics; airbag; Article; body posture; cadaver; computer model; controlled study; kinematics; qualitative analysis; quantitative analysis; rib fracture; three dimensional imaging; traffic accident; traffic safety; adult; biomechanics; body posture; human; incidence; injuries; male; procedures; scapula; Shoulder Fractures; three dimensional imaging; Accidents, Traffic; Adult; Biomechanical Phenomena; Cadaver; Humans; Imaging, Three-Dimensional; Incidence; Male; Posture; Scapula; Shoulder Fractures",2-s2.0-84921340785
"Ahmadi M., Abbasi M., Bahaadinbeigy K.","Design and implementation of a software for teaching health related topics to deaf students: The first experience in Iran",2015,"Acta Informatica Medica",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928956073&doi=10.5455%2faim.2015.23.76-80&partnerID=40&md5=4269d966bbdf2030e34abc113ccd12b9","Introduction: Deaf are not able to communicate with other community members due to hearing impaired. Providing health care for deaf is more complex because of their communication problems. Multimedia tools can provide multiple tangible concepts (movie, subtitles, and sign language) for the deaf and hard of hearing. In this study, identify the priority health needs of deaf students in primary schools and health education software has been created. Method: Priority health needs and software requirements were identified through interviews with teachers in primary schools in Tehran. After training videos recorded, videos edited and the required software has been created in stages. Results: As a result, health care needs, including: health, dental, ear, nails, and hair care aids, washing hands and face, the corners of the bathroom. Expected Features of the software was including the use of sign language, lip reading, pictures, animations and simple and short subtitles. Discussion: Based on the results of interviews and interest of educators and students to using of educational software for deaf health problems, we can use this software to help Teachers and student's families to education and promotion the health of deaf students for learn effectively. © 2015 Maryam Ahmadi, Masoomeh Abbasi, Kambiz Bahaadinbeigy.","Deaf students; Iran; Software for teaching health related topics","adolescent; Article; audiovisual equipment; bath; clinical feature; computer program; deaf education; dental health; ear; educational technology; face; hair; hand washing; health care need; health care planning; health education; health promotion; health status; hearing impairment; human; in service training; information technology; interview; Iran; lip reading; major clinical study; mouth hygiene; nail; personal experience; personal hygiene; primary school; sign language; teacher; videorecording",2-s2.0-84928956073
"Nogueira de Góes F.S., Monti Fonseca L.M., Aukarde de Camargo R.A., Nakata Hara C.Y., Deponti Gobbi J., Stabile A.M.","Developing a digital learning environment in nursing professional education [Elaboração de um ambiente digital de aprendizagem na educação profissionalizante em enfermagem1] [Elaboración de un entorno digital de aprendizaje en la educación profesional de enfermería]",2015,"Ciencia y Enfermeria",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931096490&doi=10.4067%2fS0717-95532015000100008&partnerID=40&md5=5da3643dfe9b25fa8447e59dabb80d23","The development of digital learning environments can contribute to nursing education more participative, providing the teacher and students collaborative materials, content and simulations that can be used according to their needs and learning rhythm. Objective: To describe the process of developing a learning environment as a resource to assist the teacher in training professional education students mid-level nursing. Method: For the development of the learning environment was used model that features four sequential phases of software development: scope definition, planning, production and implementation, which facilitates the construction didactically. Results: The definition of the scope was performed based on the results of a previous study that identified the learning needs of students of vocational education average level in Ribeirão Preto/SP. So we chose to address Vital Signs relating them to some aspects of human anatomy and physiology. The multimedia system features built for WEB full interactivity level simulation with built through scenarios and character in two-dimensional animation (2D). It was organized in theoretical module and a simulation module. Conclusion: It is expected that the digital environment produced learning can add knowledge to the student of vocational education average level in nursing as well as being used by the teacher as a teaching resource, facilitating the understanding of abstract content. © 2015, Universidad de Concepcion. All Rights Reserved.","Computer-assisted instruction; Education; Nursing; Nursing education; Professional",,2-s2.0-84931096490
"Karadogan E., Williams R.L., Karadogan F.","Evaluation of Haptic modules for training in undergraduate mechanics",2015,"Proceedings of the ASME Design Engineering Technical Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979031693&doi=10.1115%2fDETC2015-46060&partnerID=40&md5=efd522fa7c0f6df0007ceae96dd889fe","This article reports the evaluation results of the software modules we are developing to augment teaching and learning in standard required undergraduate engineering mechanics courses. Using these modules, students can change parameters, predict answers, compare outcomes, interact with animations, and ""feel"" the results using a force feedback joystick. The overall system aims to increase teaching and learning effectiveness by rendering the concepts compelling, fun, and engaging. Three software modules in Dynamics were evaluated by a sample of the target population, 40 undergraduate engineering students who were enrolled in a sophomore-level Dynamics course during the evaluation. Students showed significant preference in that the modules would increase their interest in Dynamics subject and their engagement in the Dynamics course that they were enrolled at the time of the evaluation. Evaluation results also showed significant difference in preference in that the modules would improve students' both conceptual understanding of the Dynamics subjects and problem-solving skills. Tactile learners believed that the modules would improve their conceptual understanding of Dynamics subjects more than the visual learners. 97.5% of the students were willing to use the software again in the future. 92.5% of the students believed that the incorporation of this software to the instruction of Dynamics would be beneficial to their learning. Copyright © 2015 by ASME.","Dynamics; Engineering mechanics courses; Force feedback; Haptics; Undergraduate engineering; User evaluation; Virtual reality","Computer software; Design; Dynamics; Education; Mechanics; Personnel training; Problem solving; Students; Teaching; Virtual reality; Engineering mechanics; Force feedback; Haptics; Undergraduate engineering; User evaluations; Curricula",2-s2.0-84979031693
"Vermeulen J., Luyten K., Coninx K., Marquardt N., Bird J.","Proxemic flow: Dynamic peripheral floor visualizations for revealing and mediating large surface interactions",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945532893&doi=10.1007%2f978-3-319-22723-8_22&partnerID=40&md5=c0d788920f793660eb37678a15f1a00c","Interactive large surfaces have recently become commonplace for interactions in public settings. The fact that people can engage with them and the spectrum of possible interactions, however, often remain invisible and can be confusing or ambiguous to passersby. In this paper, we explore the design of dynamic peripheral floor visualizations for revealing and mediating large surface interactions. Extending earlier work on interactive illuminated floors, we introduce a novel approach for leveraging floor displays in a secondary, assisting role to aid users in interacting with the primary display. We illustrate a series of visualizations with the illuminated floor of the Proxemic Flow system. In particular, we contribute a design space for peripheral floor visualizations that (a) provides peripheral information about tracking fidelity with personal halos, (b) makes interaction zones and borders explicit for easy opt-in and opt-out, and (c) gives cues inviting for spatial movement or possible next interaction steps through wave, trail, and footstep animations. We demonstrate our proposed techniques in the context of a large surface application and discuss important design considerations for assistive floor visualizations. © IFIP International Federation for Information Processing 2015.","Discoverability; Feedback; Implicit interaction; Intelligibility; Proxemic interactions; Spatial feedback","Feedback; Floors; Speech intelligibility; Visualization; Assistive; Design considerations; Design spaces; Discoverability; Flow systems; Implicit interaction; Interaction zone; Large surfaces; Human computer interaction",2-s2.0-84945532893
"Hartiine C.S., Walters M.A., Wright M.C.","Three-Dimensional structural model building, induced seismicity analysis, drilling analysis, and reservoir management at the geysers geothermal field, Northern California",2015,"Transactions - Geothermal Resources Council",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963995188&partnerID=40&md5=f433dc0f641908dbd228728ef9044bc7","Calpine has adopted the use of Paradigm Geophysical SKUA GOCAD software originally developed for the oil and gas industry in its 3D visualization and model building of The Geysers geothermal reservoir. Structural model building constraints include lithology logs, temperature logs, pressure logs, tracer analysis patterns, heat flow patterns, reservoir history matching, surface geologic maps and seismicity hypocenters available from the Northern California Earthquake Data Center (NCEDC) and Lawrence Berkeley National Laboratory (LBNL). Recent upgrades to the Paradigm Geophysical SKUA GOCAD 3D seismicity analysis and time animation software have allowed an improved understanding of the spatiotemporal relationships between water injection, induced seismicity, and fracture orientations at The Geysers. This in turn provides a refined understanding of fluid flow paths, fluid boundaries, reservoir heterogeneity and compartmentalization at The Geysers. We can now demonstrate The Geysers reservoir is subdivided by intersecting zones of faulting and fracturing the majority of which are oriented NNW-SSE and ENE-WSW. The 3D structural model development is part of a program to more closely link geoscience, drilling and reservoir engineering, and is anticipated to contribute to reservoir management and induced seismicity mitigation efforts at The Geysers. © Copyright (2015) by Geothermal Resources Council All rights reserved.","3D model building; 3D visualization; Induced seismicity; Reservoir management; The geysers","Earthquakes; Flow of fluids; Gas industry; Geophysics; Geothermal fields; Geysers; Lithology; Model buildings; Oil well flooding; Petroleum reservoirs; Reservoir management; Seismology; Structural analysis; Structural geology; Thermal logging; Three dimensional computer graphics; Visualization; Water injection; Well drilling; 3-d modeling; 3D Visualization; Geysers geothermal fields; Geysers geothermal reservoirs; Lawrence Berkeley National Laboratory; Reservoir heterogeneity; Reservoir history matching; Spatio-temporal relationships; Induced Seismicity",2-s2.0-84963995188
"Shefrin A.E., Khazei A., Hung G.R., Odendal L.T., Cheng A.","The TACTIC: Development and validation of the tool for assessing chest tube insertion competency",2015,"Canadian Journal of Emergency Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937850563&doi=10.2310%2f8000.2014.141406&partnerID=40&md5=aa0c73dd7163900817c58f4ece77debb","Objectives: Pediatric emergency medicine (PEM) physicians receive little opportunity to practice and perform chest tube insertion. We sought to develop and validate a scoring tool to assess chest tube insertion competency and identify areas where training is required for PEM physicians. Methods: We developed a 40-point, 20-item (scored 0,1, or 2) assessment tool entitled the Tool for Assessing Chest Tube Insertion Competency (TACTIC) and studied how PEM physicians and fellows scored when inserting a chest tube into a pork rib model. Participants were scored at baseline and compared to themselves after receiving targeted training using Web-based animations and presentations followed by expert instruction and practice on chest tube insertion task trainers. All insertions were video recorded and reviewed by two blinded reviewers. Eight common videos were reviewed to assess interrater reliability. Results: The TACTIC demonstrated good interrater reliability with an r2 = 0.86. Our cohort demonstrated a significant improvement in TACTIC scores by taking part in targeted training (precourse TACTIC = 65%, 95% CI 54-76 v. postcourse TACTIC = 84%, 95% CI 80-88), highlighting the construct validity of the TACTIC. Individual participants increased their TACTIC scores by an average of 17%. Conclusions: The TACTIC demonstrates good interrater reliability, content validity, and construct validity in assessing a PEM practitioner’s skill inserting chest tubes in a simulated setting. © Canadian Association of Emergency Physicians.","Chest tubes; Procedural competency; Simulation; Task trainers","animal tissue; Article; chest tube; clinical assessment tool; computer simulation; construct validity; content validity; emergency medicine; human; human experiment; interrater reliability; motor performance; nonhuman; normal human; pediatrics; process model; professional competence; validation study; videorecording; animal; child; clinical competence; education; medical education; physician; pig; procedures; reproducibility; standards; Animals; Chest Tubes; Child; Clinical Competence; Education, Medical; Humans; Internship and Residency; Pediatrics; Physicians; Reproducibility of Results; Swine; Video Recording",2-s2.0-84937850563
"Alhama I., Cánovas M., Alhama F.","Simulation of fluid flow and heat transport coupled processes using fahet software",2015,"Journal of Porous Media",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938067314&doi=10.1615%2fJPorMedia.v18.i5.60&partnerID=40&md5=efbec0678b10f877430b9b3cad0dbfa8","FAHET is a software developed to simulate 2D, transient nonlineal conjugate processes of fluid flow and heat transport in porous media. Such problems, which are governed by flow and heat conservation equations and Darcy's law as momentum equation, are formulated using the stream function variable in order to better demonstrate the patterns of flow particle paths. FAHET, developed at the Technical University of Cartagena (UPCT) and based on the network simulation method, carries out the numerical calculus with a standard code of circuit simulation, e.g., Pspice, and uses programming subroutines in MATLAB for both creating the network model and postprocessing the results for better graphical representation, including animations. Finally, the source code C# is used to design the input data interface in a user friendly windows environment. The reliability, power, efficiency and low cost of FAHET make the program a suitable tool for educational and research applications in several fields, particularly in groundwater flow with heat transport processes. Two illustrative applications, the geothermal Yusa problem and the Bénard flow between horizontal plates heated from below, are solved to demonstrate the capability of the software. © 2015 by Begell House, Inc.","Fluid flow; Geothermal; Heat transport; Network method; Porous media","Application programs; Calculations; Computer software; Fluid dynamics; Geothermal energy; Groundwater; Groundwater flow; Heat transfer; MATLAB; Numerical methods; Porous materials; SPICE; Subroutines; Transport properties; Geothermal; Graphical representations; Heat transport; Network methods; Network simulation method; Research applications; Technical universities; Windows environment; Flow of fluids",2-s2.0-84938067314
"Šag G., Lulić Z., Mahalec I.","Reverse engineering",2015,"Concurrent Engineering in the 21st Century: Foundations, Developments and Challenges",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944587719&doi=10.1007%2f978-3-319-13776-6_12&partnerID=40&md5=cbfd4623e64a805dd9e7ed7df90fa1f1","One of the most time-consuming aspects of creating 3D virtual models is the generation of geometric models of objects, in particular if the virtual model is derived (digitized) from a physical version of the object. A variety of commercially available technologies can be used to digitize objects at the molecular scale but also multi-storey buildings or even planets and stars. The process of 3D digitizing basically consists of a sensing phase followed by a rebuild phase. The sensing phase collects or captures raw data and generates initial geometry data, usually as a 2D boundary object, or a 3D point cloud. Sensing technologies are based on tracking, imaging, and range finding or their combination. The rebuild phase is internal processing of data into conventional 3D CAD and animation geometry data, such as NURBS and polygon sets. Finally, in most cases, the digitized objects must be refined by using the CAD software to gain CAD models of optimal quality which are needed in the downstream processes. Leading CAD software packages include special modules for such tasks. Many commercial vendors offer sensors, software and/or complete integrated systems. Reverse engineering focuses not only on the reconstruction of the shape and fit, but also on the reconstruction of physical properties of materials and manufacturing processes. Reverse engineering methods are applied in many different areas, ranging from mechanical engineering, architecture, cultural heritage preservation, terrain capture, astronomy, entertainment industry to medicine and dentistry. © Springer International Publishing Switzerland 2015.","Feature reconstruction; Innovative design; Intellectual property protection; Reverse engineering; Scanning methods; Shape reconstruction","Data handling; Geometry; Historic preservation; Reverse engineering; Feature reconstruction; Innovative design; Intellectual property protection; Scanning methods; Shape reconstruction; Computer aided design",2-s2.0-84944587719
"Yavner S.D., Pusic M.V., Kalet A.L., Song H.S., Hopkins M.A., Nick M.W., Ellaway R.H.","Twelve tips for improving the effectiveness of web-based multimedia instruction for clinical learners",2015,"Medical Teacher",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922747359&doi=10.3109%2f0142159X.2014.933202&partnerID=40&md5=2b844872dd592a7983e2e12963524304","Using educational technology does not necessarily make medical education more effective. There are many different kinds of technology available to the contemporary medical teacher and what constitutes effective use may depend on the technology, the learning situation and many other factors. Web-based multimedia instruction (WBMI) provides learners with self-directed independent learning opportunities based on didactic material enhanced with multimedia features such as video and animations. WBMI may be used to replace other didactic events (e.g. lectures) or it may be provided in addition to other learning opportunities. Clinical educators looking to use WBMI need to make sure that it will meet both their learners' needs and the program's needs, and it has to align to the contexts in which it is used. The following 12 tips have been developed to help guide faculty through some of the key features of the effective use of WBMI in clinical teaching programs. These tips are based on more than a decade developing, using and appraising WBMI in support of surgical clerkship education across the USA and beyond and they are intended both to inform individual uses of WBMI in clinical training and to guide the strategic use of WBMI in clinical clerkship curricula. © 2015 Informa UK Ltd. All rights reserved: reproduction in whole or part not permitted",,"curriculum; education; educational model; feedback system; human; Internet; learning; medical education; multimedia; procedures; standards; teaching; Computer-Assisted Instruction; Curriculum; Education, Medical; Educational Measurement; Feedback; Humans; Internet; Learning; Models, Educational; Multimedia",2-s2.0-84922747359
"Reeves T., Gomm P.","Community and contribution: Factors motivating students to participate in an extra-curricular online activity and implications for learning",2015,"E-Learning and Digital Media",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945971684&doi=10.1177%2f2042753015571828&partnerID=40&md5=ec740f828b7f18bc163fab7d996d0c5b","The human desire to join and participate in communities can be seen as an attempt to satisfy some of our universal human needs. The theory of communities of practice has been widely used to explain how and why humans participate in multiple communities, and a key requirement of a community of practice (CoP) is that members engage in ‘joint activities and discussions’. In the current age where social media tools have facilitated the exponential growth of online communities, the term CoP is often used to describe a group of people engaging in online discussion. In the context of online learning, the use of CoP theory can often lead to online discussion being interpreted as a joint activity. This paper argues that the concept of a joint activity as something other than online discussion has been neglected, and that while online discussion may account for the presence of an online community, evidence of joint activities beyond the simple discussion of ideas is required for the community to constitute a true CoP. Using activity theory, the authors investigated the factors motivating students on the Digital Design and Animation course at West Midlands University to participate in a non-formal learning activity involving the co-creation of a digital artefact. The authors believe that a greater understanding of the concept of joint activity, and of the link between co-creating an artefact and members’ shared emotional connection, has the potential to refocus our understanding and application of the theory of CoP in the networked era. © The Author(s) 2015.","Activity theory; Community of practice; Computer-supported collaborative learning; Online collaboration; Online learning community; Sense of community",,2-s2.0-84945971684
"Escudeiro P., Escudeiro N., Reis R., Lopes J., Norberto M., Baltasar A.B., Barbosa M., Bidarra J.","Virtual Sign - A Real Time Bidirectional Translator of Portuguese Sign Language",2015,"Procedia Computer Science",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962793739&doi=10.1016%2fj.procs.2015.09.269&partnerID=40&md5=4ca2e06239251501926a0732d5077f2a","Promoting equity, equal opportunities to all and social inclusion of people with disabilities is a concern of modern societies at large and a key topic in the agenda of European Higher Education. Despite all the progress, we cannot ignore the fact that the conditions provided by the society for the deaf are still far from being perfect. The communication with deaf by means of written text is not as efficient as it might seem at first. In fact, there is a very deep gap between sign language and spoken/written language. The vocabulary, the sentence construction and the grammatical rules are quite different among these two worlds. These facts bring significant difficulties in reading and understanding the meaning of text for deaf people and, on the other hand, make it quite difficult for people with no hearing disabilities to understand sign language. The deployment of tools to assist the daily communication, in schools, in public services, in museums and other, between deaf people and the rest may be a significant contribution to the social inclusion of the deaf community. The work described in this paper addresses the development of a bidirectional translator between Portuguese Sign Language and Portuguese text. The translator from sign language to text resorts to two devices, namely the Microsoft Kinect and 5DT Sensor Gloves in order to gather data about the motion and shape of the hands. The hands configurations are classified using Support Vector Machines. The classification of the movement and orientation of the hands are achieved through the use of Dynamic Time Warping algorithm. The translator exhibits a precision higher than 90%. In the other direction, the translation of Portuguese text to Portuguese Sign Language is supported by a 3D avatar which interprets the entered text and performs the corresponding animations. © 2015 Published by Elsevier B.V.","Avatar; Deaf; Dynamic Time Warping; Education; Kinect; Machine Learning; OpenCv; Portuguese Sign Language; Sensor Gloves; Support Vector Machines; Translator","Artificial intelligence; Audition; Computational linguistics; Education; Learning systems; Software design; Support vector machines; Three dimensional computer graphics; Transportation; Wearable sensors; Avatar; Deaf; Dynamic time warping; Kinect; OpenCv; Sensor gloves; Sign language; Translator; Translation (languages)",2-s2.0-84962793739
"Liaw S.Y., Wong L.F., Chan S.W.-C., Ho J.T.Y., Mordiffi S.Z., Ang S.B.L., Goh P.S., Ang E.N.K.","Designing and evaluating an interactive multimedia web-based simulation for developing nurses' competencies in acute nursing care: Randomized controlled trial",2015,"Journal of Medical Internet Research",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922287125&doi=10.2196%2fjmir.3853&partnerID=40&md5=e9d54618b0c68692238a5bb9e393ddfe","Background: Web-based learning is becoming an increasingly important instructional tool in nursing education. Multimedia advancements offer the potential for creating authentic nursing activities for developing nursing competency in clinical practice. Objective: This study aims to describe the design, development, and evaluation of an interactive multimedia Web-based simulation for developing nurses' competencies in acute nursing care. Methods: Authentic nursing activities were developed in a Web-based simulation using a variety of instructional strategies including animation video, multimedia instructional material, virtual patients, and online quizzes. A randomized controlled study was conducted on 67 registered nurses who were recruited from the general ward units of an acute care tertiary hospital. Following a baseline evaluation of all participants' clinical performance in a simulated clinical setting, the experimental group received 3 hours of Web-based simulation and completed a survey to evaluate their perceptions of the program. All participants were re-tested for their clinical performances using a validated tool. Results: The clinical performance posttest scores of the experimental group improved significantly (P<.001) from the pretest scores after the Web-based simulation. In addition, compared to the control group, the experimental group had significantly higher clinical performance posttest scores (P<.001) after controlling the pretest scores. The participants from the experimental group were satisfied with their learning experience and gave positive ratings for the quality of the Web-based simulation. Themes emerging from the comments about the most valuable aspects of the Web-based simulation include relevance to practice, instructional strategies, and fostering problem solving. Conclusions: Engaging in authentic nursing activities using interactive multimedia Web-based simulation can enhance nurses' competencies in acute care. Web-based simulations provide a promising educational tool in institutions where large groups of nurses need to be trained in acute nursing care and accessibility to repetitive training is essential for achieving long-term retention of clinical competency.","Acute nursing care; Authentic learning; Clinical competency; Deterioration; Instructional strategies; Multimedia; Simulation; Web-based simulation","adult; clinical competence; computer simulation; controlled study; education; female; human; Internet; male; multimedia; nurse; nursing education; procedures; randomized controlled trial; Adult; Clinical Competence; Computer Simulation; Education, Distance; Education, Nursing; Female; Humans; Internet; Male; Multimedia; Nurses",2-s2.0-84922287125
"Brey J.A., Geer I.W., Mills E.W., Nugnes K.A., Asokan A.","Energizing students' earth science literacy",2015,"2014 Oceans - St. John's, OCEANS 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921725212&doi=10.1109%2fOCEANS.2014.7003014&partnerID=40&md5=acfc992a89a17679357ba86917c86997","The future state of the world's oceans greatly depends on the leaders of tomorrow. That's why increasing current students' ocean and overall Earth science literacy is so important and a primary goal of the American Meteorological Society (AMS). To this end, the AMS has created a suite of introductory, undergraduate-level courses that have already engaged approximately a hundred thousand students in the Earth sciences. AMS Ocean Studies, AMS Weather Studies, and AMS Climate Studies have been developed by the AMS with support from NSF, NOAA, and NASA and are designed to be adaptable to traditional, hybrid, or online instructional settings. Course components include a comprehensive textbook (ebook only for AMS Climate Studies; printed or ebook options for AMS Ocean and Weather Studies), eInvestigations Manual, course website, faculty website, and a faculty resource CD. Instructors can use these materials in any combination that best suits their needs. The 3rd edition Ocean Studies textbook features topics such as ocean acidification, harmful algal blooms, the use of ocean currents as an alternative energy source, along with a detailed look at the essential role the ocean plays in Earth's climate system. The textbook also reviews the latest technology for monitoring ocean properties including floats and gliders and cabled ocean observatories. The newest version of the climate studies textbook, Our Changing Climate, is currently under revision and was released for the fall 2014 semester. A greater focus on climate change issues as well as new chapters detailing human and ecosystem vulnerabilities to climate change, energy and geopolitical issues, and climate change denial are a few highlights in the new text. Additionally, new findings from the IPCC AR5 report and the USGCRP National Climate Assessment will be included along with mitigation and adaptation solutions to climate change issues. Updated yearly, the eInvestigations Manuals contain 30 laboratory activities and innovatively connects with a third online component, Current Ocean/Weather/Climate Studies, via the RealTime Ocean/Weather/Climate Portals. These online investigations reference data from NOAA, NOS, reports from the IPCC, USGCRP and contain real-world data from other lead scientific organizations. The RealTime Ocean/Weather/Climate Portals is an all-inclusive webpage that provides links to numerous external sources that further engage students. Instructor support materials are available with each course and include a faculty CD that contains a faculty manual with learning objectives and suggestions for course implementation, as well as investigations manual answer forms compatible with any course management system, test bank questions and answers, textbook images, and PowerPoint® presentations for each chapter. The investigations manual answer forms are files compatible with Respondus®, test-generating software for which many institutions are licensed (answer forms are also provided in Respondus® format). The faculty member has the option of delivering questions through their course management system to allow automatic scoring and immediate results for their students. This feature allows for full integration to a college's e-learning environment. AMS Ocean Studies also offers a unique way to study marine science through the use of Google Earth-based animations and other similar data visualization tools, such as NOAA View that allows students to view satellite, model, and other data and export high-resolution images. These tools bring oceanography to life! The AMS believes that students are truly motivated to learn when they can relate to the topic. That is why use of current, real-world data is vital to all three of the courses. A few examples include the 2011 Japan earthquake/tsunami event, the 2012 record-low Arctic sea ice, and Superstorm Sandy. In all of these instances, online activities were created as these events were occurring; students learned the science as it was happening! AMS Ocean Studies, AMS Weather Studies, and AMS Climate Studies can be taught by experienced science faculty or those new to teaching the subject matter. Mentoring by AMS-trained course instructors is available to all new instructors. These courses aim to interest all students in the geosciences and increase scientific literacy through the use of real-world data. © 2014 IEEE.","climate; course; diversity; ocean; online; water","Computer aided instruction; Data visualization; E-learning; Earth (planet); Earth sciences; Education; Electronic publishing; NASA; Ocean currents; Oceanography; Online systems; Sea ice; Social networking (online); Software testing; Students; Teaching; Textbooks; Water; Websites; climate; course; diversity; ocean; online; Climate change",2-s2.0-84921725212
"Wang L., Blackwell A.A.","Effects of dual coded multimedia instruction employing image morphing on learning a logographic language",2015,"Journal of Educational Multimedia and Hypermedia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945253612&partnerID=40&md5=c1b3ccef1fd101eab062f3f84b9911ae","Native speakers of alphabetic languages, which use letters governed by grapheme-phoneme correspondence rules, often find it particularly challenging to learn a logographic language whose writing system employs symbols with no direct sound-to-spelling connection but links to the visual and semantic information. The visuospatial properties of logographic languages, such as Chinese, have inspired the development of promising instructional methods informed by the Dual Coding Theory (Paivio, 1971) which postulates that coding a stimulus in two different ways, verbally and visually, increases retention compared to a single-coded stimulus. Extending this line of research, this study investigated the effects of dual-coded instruction, including an additional image morphing component, on learning Chinese vocabulary. One hundred twenty adult participants without prior knowledge of logographic languages were randomly assigned to one of four treatment groups: a text-only method group, an animation-only method group, an animation-plus-text method group, and an animation-plus-narration method group. All participants learned the same 24 Chinese characters, of which 12 were concrete characters and 12 were abstract characters. Controlling for participants' spatial ability, e.g., mentally rotating pictures of three-dimensional objects, statistical analyses revealed that the dual coded methods worked better than the single coded methods, and participants performed better on concrete characters than on abstract characters. In addition, under the single coded method, the animation-only method resulted in more substantial gains in Chinese vocabulary learning than the text-only method, while under the dual coded method, the animation-plus-narration method was superior to the animation-plus-text method. These results suggest that dual coded instructional methods involving image morphing based computer animations with multi-sensory input have a significant positive influence on logographic language vocabulary learning.",,,2-s2.0-84945253612
"Berta M., Humienny Z.","Software tools and tricks used to develop application that explains geometrical tolerancing concepts",2015,"XXI IMEKO World Congress ""Measurement in Research and Industry""",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951066647&partnerID=40&md5=4b29fac39a4c26a37d6739330b16545c","The paper demonstrates a new concept of teaching and training geometrical tolerancing fundamental and advanced principles with usage of computer simulations, as well as animations at a very large extend. The general concept, along with some programming solutions employed to develop an application Geometrical Tolerancing are presented. The application contains definitions, illustrations, plain animations, cartoon sequences and exercises for selftuition that explain the ISO GPS tolerance system.","E-learning; Geometrical tolerancing; ISO 1101; Tolerance indication","E-learning; Geometry; Industrial research; ISO 1101; Programming solutions; Tolerance systems; Tolerancing; Application programs",2-s2.0-84951066647
"Sakamoto M., Uchida Y., Nagatomo M., Zhang T., Susaki H., Ito T., Yoshinaga T., Ikeda S., Yokomichi M., Furutani H.","Remarks on four-dimensional probabilistic finite automata",2015,"International Journal of Software Engineering and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928981659&doi=10.14257%2fijseia.2015.9.4.09&partnerID=40&md5=7678e886adcaabcc65814f701677b6e0","This paper deals with the study of four-dimensional automata. Recently, due to the advances in many application areas such as dynamic image processing, computer animation, augmented reality (AR), and so on, it is useful for analyzing computation of four-dimensional information processing (three-dimensional pattern processing with time axis) to explicate the properties of four-dimensional automata. From this point of view, we have investigated many properties of four-dimensional automata and computational complexity. On the other hand, the class of sets accepted by probabilistic machines have been studied extensively. As far as we know, however, there is no results concerned with four-dimensional probabilistic machines. In this paper, we introduce four-dimensional probabilistic finite automata, and investigate some accepting powers of them. © 2015 SERSC.","Alternation; Chunk; Finite automaton; Four-dimension; Probability",,2-s2.0-84928981659
"Sakamoto M., Uchida Y., Nagatomo M., Zhang T., Susaki H., Ito T., Yoshinaga T., Ikeda S., Yokomichi M., Furutani H.","Remarks on four-dimensional probabilistic finite automata",2015,"International Journal of Software Engineering and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938700933&doi=10.14257%2fijseia.2015.9.6.10&partnerID=40&md5=8fb9846259f178f49d2399f522c90722","This paper deals with the study of four-dimensional automata. Recently, due to the advances in many application areas such as dynamic image processing, computer animation, augmented reality (AR), and so on, it is useful for analyzing computation of four-dimensional information processing (three-dimensional pattern processing with time axis) to explicate the properties of four-dimensional automata. From this point of view, we have investigated many properties of four-dimensional automata and computational complexity. On the other hand, the class of sets accepted by probabilistic machines have been studied extensively. As far as we know, however, there is no results concerned with four-dimensional probabilistic machines. In this paper, we introduce four-dimensional probabilistic finite automata, and investigate some accepting powers of them. © 2015 SERSC.","Alternation; Chunk; Finite automaton; Four-dimension; Probability",,2-s2.0-84938700933
"Kay S.","Adventures in cartography with free and open source tools",2015,"Bulletin of the Society of Cartographers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936756434&partnerID=40&md5=75aee395897a6a888297c6bf67bafbc4","The increasing availability of open data, coupled with free and open source software (FOSS), has enabled those from outside of traditional cartography to venture into the field. FOSS tools can be combined and extended in creative ways to enable many forms of cartography, for example 3D-printed models, animations and photo-realistic Computer Generated Imagery (CGI). The possibilities are opening up for cartographers, both professional and amateur, to explore areas of interest.",,"cartography; software; three-dimensional modeling",2-s2.0-84936756434
"Roohani A., Jafarpour A., Zarei S.","Effects of visualisation and advance organisers in reading multimedia-based texts",2015,"3L: Language, Linguistics, Literature",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937432991&partnerID=40&md5=3105a6752b65d1923a719a04a984c50e","Recent advancements in multimedia systems to integrate text, audio, graphics, and video have created a new interest in using instructional strategies in a multimedia-based learning environment. In this light, this study explores the effect of two types of visualisations (static and animated) and advance organisers (descriptive and question) on EFL learners' reading comprehension in a multimedia context. To this end, a software program with four computer-based modules was designed to show texts with four instructional formats - texts with static visual embedded descriptive advance organisers, texts with static visual embedded question advance organisers, texts with animation embedded descriptive advance organisers, and texts with animation embedded question advance organisers. Eighty intermediate Iranian EFL learners, who were selected from three language institutes through a placement test, were randomly assigned to one of four computer-based instructional formats: the first group read texts with static visual embedded descriptive advance organisers, the second group had texts with static visual embedded question advance organisers, the third group read texts with animation embedded descriptive advance organisers, and the fourth group had texts with animation embedded question advance organisers. Once the EFL learners interacted with their respective instructional materials, they then took a reading comprehension test. The results revealed that the question type of advance organiser was more effective than the descriptive one; the animation type of visualisation was more effective than the static one and embedding animations with question advance organisers improved reading comprehension significantly. The findings imply the integration of advance organisers with computer-generated visuals in multimedia reading programs cue attention of L2 students to salient features conveyed in the reading texts and visuals.","Advance organisers; Instructional strategies; Multimedia; Reading comprehension; Visualisation",,2-s2.0-84937432991
"Collard C.","Mediation in motion: Performing permanent presence",2015,"Studies in Theatre and Performance",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954237006&doi=10.1080%2f14682761.2015.1030242&partnerID=40&md5=39272d22c0f91ab482020f334fab8843","This essay opens by arguing that the notion of scenography, which effectively encapsulates the entire technical dimension of a theatre production, could be placed on equal footing with the dramatic text as both object of analysis and stepping stone for further conceptualization. Especially so when adapting a historiographical posture, as the conjunction of scenography and historiography entails the entanglement of human beings with technological devices while foregrounding history’s own essentially mediated character. In more concrete terms, addressing the process of writing history arguably yields insight into the various signifying systems and methods that bring it into being. Tackling signification from the angle of theatre scenography, consequently, reveals the act of ‘meaning making’ in its broadest sense as an immanent, collective entanglement of material enunciations that operate on, shape, and transform the world in real time. As such, the proposed perspective provides a platform to reflect upon the principle of a ‘permanent present’ by dramatizing a process metaphysics via the prism of Jet Lag (1998), a cross-media performance by The Builders Association with Diller + Scofidio combining live action, live and recorded video, computer animation, music, and dramatic text with two historical characters. © 2015 Taylor & Francis.",,,2-s2.0-84954237006
"Qian Y., Yang X.","Compressed-sensing based up-sampling method for fluid simulation",2015,"Xitong Fangzhen Xuebao / Journal of System Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945580706&partnerID=40&md5=f10dd0065cad8565aca586eaa3f5d28f","In computer fluid animation, the grid-based Euler method is a well-matured and effective way of simulating fluids, but a key bottleneck of Euler method is that it is limited to the traditional Nyquist-Shannon sampling theorem in sampling step. So it cannot effectively reduce the massive data and computing of the large-scale flow fields. In order to solve this problem, compressed sensing theory was used to probe a way to break through the limitation of the sampling theorem in fluid simulation. The sparsity and compressibility of fluid data were explored, then applicable sampling function, compressive basis and reconstruction algorithm for fluid data are selected. A compressed-sensing based up-sampling method and framework for fluid simulation was constructed based on researches and experiments. Several scenes of smoke animation were presented, the results show that compressed-sensing based up-sampling method can recover the details of the flow field to a certain extent, and prove the compressed sensing theory can apply to fluid simulation. ©, 2015, Chinese Association for System Simulation. All right reserved.","Compressed sensing; Fluid simulation; Reconstruction algorithm; Sparse representation; Up-sampling",,2-s2.0-84945580706
"Ismail I., Sunar M.S.","Editing virtual human motion techniques with dynamic motion simulator and controller",2015,"Jurnal Teknologi",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938241792&partnerID=40&md5=890a0f8e9ed7754797ca4e1579cf4d8a","Modifying realistic virtual human movement has become a challenging task to the researcher for computer games and animation development. To achieve realistic virtual human, the character movement must have same motion like real human. Virtual human movement can be created by blending different sources such as motion capture, dynamic and kinematics simulation. Editing dynamic movement requires a great skill from animator and takes a long time to setup. This paper presents a new technique for editing virtual human motion state using dynamic motion control in the real time animation. The system approach based on active dynamic control by normalizes the trajectory of vector space position. This technique explores the perfect balance in dynamic motion controls for virtual human motion initial and final states. For that purpose, an enhancement of proportional-derivative controller will be used. This paper focuses on three main parts; virtual human hierarchy, motion editing techniques and motion dynamic control. © 2015 Penerbit UTM Press. All rights reserved.","Dynamic motion; Motion techniques; Simulator and controller; Virtual human",,2-s2.0-84938241792
"Zabusky N.J.","Fluids in motion inspiration and realization for artists and STEMists",2015,"Leonardo",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925605811&doi=10.1162%2fLEON_a_00831&partnerID=40&md5=c25bb3e5f45df1816d141fe92029d1e4","The author examines contemporary work in fluids in motion and demonstrates strong connections between visual art and science resulting from innovative technology. In one burgeoning domain— falling liquid drops impacting solid surfaces and liquid pools—it is valuable to compare how artists and scientists describe their goals and their use of high-speed photography to capture and measure events. The author also examines the use of devices to create still images, animations and objects: computers/software for simulation, visualization and 3D printing; installations at focal locations. Finally, he examines the utilization of digital technology by artists, educators, museums and galleries for innovative and interactive displays. © 2015 ISAST.",,,2-s2.0-84925605811
"Knight P.","The Kennedy assassination and postmodern paranoia",2015,"The Cambridge Companion to John F. Kennedy",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953725435&doi=10.1017%2fCCO9781107256699.014&partnerID=40&md5=4939ef8865cbacda565bb1572b1d4120","The Kennedy assassination has haunted the American cultural imagination for the last half century. In Flying in to Love, for example, the novelist D. M. Thomas interweaves the known facts of the event with outlines of an alternative history in which Kennedy isn't assassinated, the latter expressing a collective wish fulfillment fantasy on the part of a nation in thrall to JFK's seductive image. The novel begins with a declaration from a Dallas psychologist that “ten thousand dreams a night … are dreamt about Kennedy's assassination.” And, in fact, the event has been the focus of thousands of books, magazine and newspaper articles, novels, films, paintings, and computer animations, its story told in genres including journalism, memoir, history, biography, government reports, sociological inquiries, popular conspiracy exposés, literary and pulp fiction, museums and monuments, Hollywood film, and avant-garde art. These retellings evince a sharp divide between those who believe that Oswald acted alone (as the Warren Commission insisted), and those who are convinced that there was some kind of cover-up or conspiracy. The assassination is now routinely viewed as the mother of all conspiracy theories, the defining event responsible for a widespread and ongoing sense of suspicion that the official version of things is a lie. According to an annual opinion poll, three-quarters of Americans trusted their government in the early 1960s; by the early 1990s, three quarters of Americans distrusted their government. With respect to the assassination, the overwhelming majority of Americans now believe that it was not the work of a lone gunman but was part of a large conspiracy. In the immediate aftermath of the shooting, however, it was not obvious that a popular culture of paranoia would be the inevitable reaction to the event. Given the recent experience of the Cuban Missile Crisis in 1962, as well as decades of FBI director J. Edgar Hoover's anticommunist scaremongering, the majority of Americans suspected some form of communist conspiracy. © Cambridge University Press 2015.",,,2-s2.0-84953725435
"Dongyi W., Yan Z., Xiaojuan R.","An improved decision-making model for multimedia teaching and college students' physical health: An empirical analysis of wushu education",2015,"International Journal of Security and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950313529&doi=10.14257%2fijsia.2015.9.11.34&partnerID=40&md5=84774b516cf2231a670b3714b29221fc","Multimedia teaching is a new kind of teaching mode, it makes multimedia computer as the core, and includes sound, images, text and animation. In multimedia teaching, teaching is always the main body, and multimedia is to cooperate with the teaching. In this paper, we make empirical analysis of performance evaluation of the multimedia teaching, the study subjects is martial arts courses in colleges. The result shows that after experiment, the students' psychological quality and body movement quality have very significant increase, Body function and body form has improved. At the same time, college students give a better evaluation of the multimedia class, so multimedia teaching is worth promoting. © 2015 SERSC.","College students; Influence factors; Information technology; Martial arts; Multimedia teaching","Decision making; Education; Education computing; Information technology; Students; Body movements; College students; Decision making models; Empirical analysis; Influence factors; Martial art; Multimedia teachings; Physical health; Teaching",2-s2.0-84950313529
"Girges C., Spencer J., O'Brien J.","Categorizing identity from facial motion",2015,"Quarterly Journal of Experimental Psychology",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937519314&doi=10.1080%2f17470218.2014.993664&partnerID=40&md5=e3dfaaee6b2ce8b12082c42eda9dde8a","Advances in marker-less motion capture technology now allow the accurate replication of facial motion and deformation in computer-generated imagery (CGI). A forced-choice discrimination paradigm using such CGI facial animations showed that human observers can categorize identity solely from facial motion cues. Animations were generated from motion captures acquired during natural speech, thus eliciting both rigid (head rotations and translations) and nonrigid (expressional changes) motion. To limit interferences from individual differences in facial form, all animations shared the same appearance. Observers were required to discriminate between different videos of facial motion and between the facial motions of different people. Performance was compared to the control condition of orientation-inverted facial motion. The results show that observers are able to make accurate discriminations of identity in the absence of all cues except facial motion. A clear inversion effect in both tasks provided consistency with previous studies, supporting the configural view of human face perception. The accuracy of this motion capture technology thus allowed stimuli to be generated that closely resembled real moving faces. Future studies may wish to implement such methodology when studying human face perception. © 2015 The Experimental Psychology Society.","Biological motion; Facial motion; Identity; Perception; Vision","adult; analysis of variance; association; concept formation; face; facial expression; female; human; male; middle aged; motion; movement perception; nonlinear system; pattern recognition; perceptive discrimination; photostimulation; physiology; young adult; Adult; Analysis of Variance; Concept Formation; Cues; Discrimination (Psychology); Face; Facial Expression; Female; Humans; Male; Middle Aged; Motion; Motion Perception; Nonlinear Dynamics; Pattern Recognition, Visual; Photic Stimulation; Young Adult",2-s2.0-84937519314
"Capanna A.","BiOrganic design: A new method for architecture and the city",2015,"Architecture and Mathematics from Antiquity to the Future: Volume II: The 1500s to the Future",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944611152&doi=10.1007%2f978-3-319-00143-2_39&partnerID=40&md5=4343cd5b756006b5b0e5aba94200a4e3","In recent times many architects have proclaimed a new design philosophy based on complex-systems science, in opposition to conventional analytical methodology, or reductionism, and non-linear processes including computer aided design. Some claim that with the support of computers, entire new forms of design have become possible, while others believe that computers have even modified the creative processes and the design theory. In this sense, architects are involved in scientific investigations of artificial life, genetic algorithms and neural network programs. Artificial Intelligence, which supports the development of digital systems, both those produced for self-generated architectures as well as those for drawing topological transformation in Euclidean space, is evolving quickly. The use of digital systems for animation, on which programs such as ALIAS and MAYA are based, have had a liberating and cathartic effect enabling architects to draw and control unusual shapes with high levels of complexity. © Springer International Publishing Switzerland 2015.",,,2-s2.0-84944611152
"Xu H., Sin F., Zhu Y., Barbič J.","Nonlinear material design using principal stretches",2015,"ACM Transactions on Graphics",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947232530&doi=10.1145%2f2766917&partnerID=40&md5=1ba9ea6ada8707615fbac9560ee737f9","The Finite Element Method is widely used for solid deformable object simulation in film, computer games, virtual reality and medicine. Previous applications of nonlinear solid elasticity employed materials from a few standard families such as linear corotational, nonlinear St.Venant-Kirchhoff, Neo-Hookean, Ogden or Mooney-Rivlin materials. However, the spaces of all nonlinear isotropic and anisotropic materials are infinite-dimensional and much broader than these standard materials. In this paper, we demonstrate how to intuitively explore the space of isotropic and anisotropic nonlinear materials, for design of animations in computer graphics and related fields. In order to do so, we first formulate the internal elastic forces and tangent stiffness matrices in the space of the principal stretches of the material. We then demonstrate how to design new isotropic materials by editing a single stress-strain curve, using a spline interface. Similarly, anisotropic (orthotropic) materials can be designed by editing three curves, one for each material direction. We demonstrate that modifying these curves using our proposed interface has an intuitive, visual, effect on the simulation. Our materials accelerate simulation design and enable visual effects that are difficult or impossible to achieve with standard nonlinear materials. Copyright 2015 ACM.","Anisotropic; Design; FEM; Isotropic; Material",,2-s2.0-84947232530
"Sora M.-C., Erman G., Pirtea L., Boia M., Matusz P., Sas I.","Three dimensional reconstruction and modeling of complex pelvic anatomical structures by using plastinated cross sections",2015,"Materiale Plastice",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941274805&partnerID=40&md5=1cd729cdb2a9beee2e20cabb1b7ec680","Computerized reconstruction of anatomical structures is becoming very useful for developing anatomical teaching modules and animations. The first computer-aided 3D reconstruction was achieved in 1965 by Glaser and Van der Loos. With the improvements in computer hardware and software tools, computerized modeling of anatomical structures has become very useful for visualizing complex 3D forms. Three-dimensional visualization of various microanatomic structures using special preparation and staining methods is important. Although databases exist consisting of serial sections derived from frozen cadaver material, plastination represents an alternate method for developing anatomical data useful for computerized reconstruction. Plastination is used as an excellent tool for studying different anatomical and clinical questions. The sheet plastination technique is unique because it offers the possibility to produce transparent slices series, which can easily be processed morphometrically. A female pelvis was obtained, plastinated, sectioned and subject to 3D computerized reconstruction using WinSURF modeling system (SURFdriver Software). Qualitative observations revealed that the morphological features of the model were consistent with those displayed by typical cadaveric specimens. Morphometric analysis indicated that the model did not significantly differ from a sample of cadaveric specimens. This data supports the use of plastinates for generating tissues sections useful for 3D computerized modeling.","3D reconstruction; Anatomy; Female pelvis; Plastination; Urinary bladder; Uterus",,2-s2.0-84941274805
"Pulay M.A.","Eye-Tracking and EMG supported 3D Virtual Reality-An integrated tool for perceptual and motor development of children with severe physical disabilities: A research concept",2015,"Studies in Health Technology and Informatics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952024782&doi=10.3233%2f978-1-61499-566-1-840&partnerID=40&md5=7462e7843804a02742076d4d093a64fe","Letting children with severe physical disabilities (like Tetraparesis spastica) to get relevant motional experiences of appropriate quality and quantity is now the greatest challenge for us in the field of neurorehabilitation. These motional experiences may establish many cognitive processes, but may also cause additional secondary cognitive dysfunctions such as disorders in body image, figure invariance, visual perception, auditory differentiation, concentration, analytic and synthetic ways of thinking, visual memory etc. Virtual Reality is a technology that provides a sense of presence in a real environment with the help of 3D pictures and animations formed in a computer environment and enable the person to interact with the objects in that environment. One of our biggest challenges is to find a well suited input device (hardware) to let the children with severe physical disabilities to interact with the computer. Based on our own experiences and a thorough literature review we have come to the conclusion that an effective combination of eye-Tracking and EMG devices should work well. © 2015 The authors and IOS Press. All rights reserved.","Assistive Technology; Children with Cerebral Palsy; Cognitive processes; EMG; Eye-Tracking; neurorehabilitation; Perception; Virtual Reality",,2-s2.0-84952024782
"Aparna M., Soni P.","Optimized cordic designs and application of BI-CORDIC in JPEG compression",2015,"ARPN Journal of Engineering and Applied Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943415594&partnerID=40&md5=88d0bbedda3edd52df3dbcf59073649e","Growth of VLSI technology has inspired many designers to port algorithms into architectures. Coordinate Rotation Digital Computer (CORDIC) was one such algorithm which gained widespread attention, and many methods have come up for the implementation of CORDIC. Rotation of vectors through fixed and known angles has wide range of applications in digital signal processing, robotics, games, graphics, and animation. But, not much work has been done in the area of hardware optimization of CORDIC architecture. A few architectures which can be used for optimization of CORDIC for fixed angles of rotation are studied here. These designs were simulated and synthesized for Xilinx Field programmable gate array platforms and shown that device utilization can be improved using optimized designs. The most efficient design was identified and the same was selected for application in JPEG compression. © 2006-2015 Asian Research Publishing Network (ARPN).","CORDIC; DCT; FPGA; JPEG compression; Rotation",,2-s2.0-84943415594
"Tedore C., Johnsen S.","Visual mutual assessment of size in male Lyssomanes viridis jumping spider contests",2015,"Behavioral Ecology",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938510183&doi=10.1093%2fbeheco%2faru222&partnerID=40&md5=b4e1e56a09f1afdaa08368c3b95aeb8a","Numerous animals are known to assess the resource holding potential of their opponents using conventional signals and other correlates of resource holding potential. Although body and weapon size generally correlate with resource holding potential and are often presumed to be visually evaluated in animal contests, no one has demonstrated visual assessment of opponent size while controlling for all potential correlates of size. To this end, we presented male Lyssomanes viridis jumping spiders with computer-animated opponents 1) of 3 different overall sizes and 2) with different weapon and nonweapon appendages elongated by the amount that would normally accompany a 20% increase in body size. Male L. viridis have strikingly colored, exaggerated chelicerae and forelegs, which are used as weapons in contests, and the forelegs are waved during visual agonistic displays. We scored 4 levels of escalation in males' responses to animations. Using generalized linear mixed modeling, we assessed the relative predictive power of the following variables on escalation intensity: 1) focal male size, 2) animated opponent size, and 3) the difference in size between the focal male and his animated opponent. When we presented males with animations scaled to different sizes, we found that size difference was the best predictor of escalation intensity, followed by opponent size. The effect of opponent size disappeared when size difference was included in the same model. Focal male size did not significantly predict escalation intensity. This suggests that males employ a mutual assessment strategy. Surprisingly, males did not respond differently to animations with versus without elongated weaponry. © 2014 The Author 2014.","assessment strategy; male-male competition; resource holding potential; Salticidae; size assessment; vision; weaponry","assessment method; biological weapon; body size; competition (ecology); correlation; ecological modeling; male; morphology; signal; spider; vision; Animalia; Lyssomanes viridis; Salticidae",2-s2.0-84938510183
"Crandall P.G., Engler R.K., III, Beck D.E., Killian S.A., O'Bryan C.A., Jarvis N., Clausen E.","Development of an augmented reality game to teach abstract concepts in food chemistry",2015,"Journal of Food Science Education",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920887643&doi=10.1111%2f1541-4329.12048&partnerID=40&md5=e09294cdd2438720f6da9abaff16991d","One of the most pressing issues for many land grant institutions is the ever increasing cost to build and operate wet chemistry laboratories. A partial solution is to develop computer-based teaching modules that take advantage of animation, web-based or off-campus learning experiences directed at engaging students' creative experiences. We used the learning objectives of one of the most difficult topics in food chemistry, enzyme kinetics, to test this concept. Students are apprehensive of this subject and often criticize the staid instructional methods typically used in teaching this material. As a result, students do not acquire a useful background in this important subject. To rectify these issues, we developed an interactive augmented reality application to teach the basic concepts of enzyme kinetics in the context of an interactive search that took students to several locations on campus where they were able to gather raw materials and view videos that taught the basics of enzyme kinetics as applied to the production of high fructose corn syrup (HFCS). The students needed this background to prepare for a mock interview with an HFCS manufacturer. Students and instructors alike found the game to be preferable to sitting in a classroom listening to, or giving, a PowerPoint presentation. We feel that this use of gaming technology to teach difficult, abstract concepts may be a breakthrough in food science education and help alleviate the drain on administrative budgets from multiple wet labs. © 2015 Institute of Food Technologists®.",,,2-s2.0-84920887643
"Lin H.-C.K., Su S.-H., Wang S.-T., Tsai S.-C.","Influence of cognitive style and cooperative learning on application of augmented reality to natural science learning",2015,"International Journal of Technology and Human Interaction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944675456&doi=10.4018%2fIJTHI.2015100103&partnerID=40&md5=711d13d0a7879876e9daddc5e22b5b93","With the constant progress of information technology, as long as computer software is connected with video equipment, augmented reality can be implemented. In teaching, augmented reality can provide specific images of learning objects and interact with them to enhance students' learning interest and effectiveness. The main purpose of this study is to integrate unmarked augmented reality technology with natural science courses to develop a system that is suitable for learning. This system uses image objects and 3D animation to stimulate sensory learning and strengthen users' learning effectiveness and memory. Moreover, this study also intends to investigate the system usability perception, learning motivation, and self-perceived learning effectiveness of users with different cognitive styles as they operate this system to engage in cooperative learning. Furthermore, this study used triangulation method to assess usability. In the end, this study analyzed and investigated the qualitative and quantitative data of the research questions. Copyright © 2015 IGI Global.","Augmented reality; Cognitive style; Cooperative learning; Learning effectiveness; Natural science learning","Natural sciences; Teaching; Augmented reality technology; Cognitive styles; Cooperative learning; Learning effectiveness; Learning motivation; Perceived learning; Science learning; Triangulation method; Augmented reality",2-s2.0-84944675456
"Bellamine I., Tairi H.","Motion detection using color structure-texture image decomposition",2015,"2015 Intelligent Systems and Computer Vision, ISCV 2015",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934324790&doi=10.1109%2fISACV.2015.7105545&partnerID=40&md5=bb8fe1d1d04b6d7c1f95d1e120cda445","Analyzing and interpreting video is a growing topic in computer vision and its applications. This paper mainly contributes to the Color Space-Time Interest Points (CSTIP) extraction and detection. We propose a new method for detection of moving objects. Two main steps compose the proposed method. First, we suggest applying the algorithm of the detection of Color Space-Time Interest Points (CSTIP) on both components of the Color Structure - Texture Image Decomposition which is based on a Partial Differential Equation (PDE): A color geometric structure component and a color texture component. A descriptor is associated to each of these points. In a second stage, we address the problem of grouping the points (CSTIP) into clusters. Experiments and comparison to other motion detection methods on challenging sequences show the performance of the proposed method and its utility for video analysis. Experimental results are obtained from very different types of videos, namely sport videos and animation movies. © 2015 IEEE.","clustering; Color Space-Time Interest Points (CSTIP); Color Structure-Texture Image Decomposition; Motion Detection",,2-s2.0-84934324790
"Gadomska A.","Using lego blocks for technology-mediated task-based english language learning",2015,"Teaching English with Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930150450&partnerID=40&md5=a0a898dbfb18b35ce2599fd7b6f36b06","Lego blocks have been played with by generations of children worldwide since the 1950s. It is undeniable that they boost creativity, eye-hand coordination, focus, planning, problem solving and many other skills. Lego bricks have been also used by educators across the curricula as they are extremely motivating and engaging and, in effect, make learning effective. The toy has developed with time, as a result of technology impact as well as users' needs and expectations. This paper describes the transformation of the use of Lego based activity in the academic writing class in the Institute of English Studies at the University of Social Sciences and Humanities in Warsaw, Poland spanning a period of the last seven years. Originally, the author's idea was just to illustrate in theory the principle of cohesion and coherence on the example of Lego composition instruction, a concept described by Joseph Williams; however, it evolved into a highly successful technology mediated task-based activity. The activity has been conducted since 2008 and in the author's newest 2014/15 version, it involves online writing, digital photography, computer editing programs, animation, e-learning tools and blogging; it boosts, apart from the above mentioned skills, writing, reading, teamwork and IT skills. Its teaching/ learning success results also from its multimodality, learner empowerment and authenticity. Moreover, the case illustrates teacher development due to both external and internal class factors, including the impact of learners' competence and skills on the transformation of the activity itself and the resulting teacher training. Finally, the paper focuses on the role of the fast changing ICT technology in the development and adjustment of the English language learning task, the task based on the innovative use of Lego blocks in teaching academic skills to the students of the English studies program.","LEGO blocks; TBLL; Technology-mediated learning",,2-s2.0-84930150450
"Chang M., Lachance D., Lin F., Al-Shamali F., Chen N.-S.","Enhancing orbital physics learning performance through a hands-on Kinect game",2015,"Egitim ve Bilim",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940050464&doi=10.15390%2fEB.2015.3145&partnerID=40&md5=ad644be73a58c6596d4d3b45be1a75b9","Practicing is very important in the process of learning physics. Experiencing physics laws and observing the phenomenon in the experiments and labs help students learn. However, some contexts like the law of orbits in physics cannot be practiced directly and students can only learn it from animation or drawings. We have designed a Kinect game for students to experience orbital physics and conducted a pilot in a summer camp of Athabasca University's science outreach program to verify the hypotheses include whether the students' attitudes toward computer/video games will affect their perceptions toward the developed Kinect game or not, and whether their performance in the game will be influenced by the lack of prior knowledge of the law of orbits or not. The quantitative analysis results showed that there was a positive correlation between students' gaming performances and what they knew about the relevant physics knowledge. Also, it shows that the students' attitudes toward computer/video games do not affect their perceptions toward the developed Kinect game in terms of its usability.","Elementary School; High School; Kinect; Motion-Sensing; Physics",,2-s2.0-84940050464
"Potočnik D.","Teaching history and the modern media [Pouk zgodovine in sodobni mediji]",2015,"Didactica Slovenica - Pedagoska Obzorja",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951167820&partnerID=40&md5=e29e392ed2908a83bb22eb8b9d2f0e65","The historical sources that are suitable for teaching history can be found through modern media (audio and video sources, information-communication technology: the internet, e-materials). History teachers can choose from a wide array of technologies and learning tools for a more authentic presentation of history. They can use pictures from different audiovisual sources, elements from historical films on television, cultural-historical and archaeological documentaries, etc. Audio and visual sources thus include documentaries, fictional documentaries and historical films. The information-communication technology and e-materials enable teaching about historical processes through the use ofmodern forms of learning materials: electronic history maps, interactive games, 3-D presentations, animations, films, quizzes, etc. With the help of computer technology pupils gain access to the interactive materials, and what's more, they can create these materials themselves with the help of different programs, thus producing timelines, posters, websites, brochures about the local history, and visual presentations. The internet and e-materials can be used by teachers as a basic source of information or as an addition to the established ways of transmitting knowledge.","Audio and visual sources; E-materials; Historical sources; Informationcommunication technology; The modem teaching of history",,2-s2.0-84951167820
"Anantha Natarajan V., Jothilakshmi S.","Tracking of facial feature points around lip based on low-level spatial feature using KLT tracker algorithm",2015,"International Journal of Applied Engineering Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942043074&partnerID=40&md5=06d4397706b63dc2bc590aea903b385f","In most of the computer vision applications like face recognition, facial expression analysis and face animation Facial feature point detection is an important step. Therefore, locating these facial features such as lip contour, eyes, eyebrows, and nose in a face image accurately is an important step these above mentioned applications. In this work an automatic method for lip contour tracking in image sequences using Fuzzy C-means cluster based color segmentation and kaande, lucas, tomasi feature tracker algorithm is proposed and implemented. These extracted feature points around the Lip contour can be used to reconstruct a three dimensional human face. Initially, using the face detection algorithm based on the skin color as a clue the human face are detected from the initial frame of given input image sequence. Once the face is detected the lip region is localized using the Haar Classifier. Then feature points around the lip contour are detected using the L*a*b color space and Fuzzy C-means clustering algorithm in the localized lip region. Then finally these extracted feature points are tracked in all the remaining video frames using the Kanade, Lucas, Tomasi (KLT) feature tracker algorithm. For analyzing the performance of the proposed method the error in detecting these lip contour feature points is calculated by finding the Euclidean distance between the extracted feature points and the manually marked feature points. The final results show that the proposed algorithm is performing better than the other methods proposed by researchers in various literatures. © Research India Publications.","Euclidean distance; Fuzzy C -means clustering; Haar classifier; KLT feature tracker; L*a*b color space",,2-s2.0-84942043074
[No author name available],"2nd International Conference on Learning and Collaboration Technologies, LCT 2015",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947072993&partnerID=40&md5=651130a0447db0e12b7d236489c9a0ba","The proceedings contain 74 papers. The special focus in this conference is on Technology-Enhanced Learning, Adaptive, Personalised Learning and Assessment. The topics include: An eye-tracking analysis of spatial contiguity effect in educational animations; using augmented reality technology in assisting english learning for primary school students; gesture-based nursing educational training support system; dual-coding strategy for the chinese characters learners; assessments of user centered design framework for M-learning application development; design and evaluation of a learning assistant system with optical head-mounted display OHMD; prediction of learner native language by writing error pattern; an exploration of mobile collaborative writing interface design; a tablet-based lego mindstorms programming environment for children; voice-based computer mediated communication for individual practice to increase speaking proficiency; a robotic platform controlled by smartphone; the use of augmented reality interfaces for on-site crisis preparedness; design solutions for interactive multi-video multimedia learning objects; automatic pronunciation error detection and feedback generation for CALL applications; feedback in computer-based concept mapping tools; model for detecting student difficulties in solving formative assessments; enhancing the learner’s performance analysis using SMEUS semantic e-learning system and business intelligence technologies; creation of meaningful-learning and continuous evaluation education system; a computational model to determine desirability of events based on personality for performance motivational orientation learners; recommendation engine for an online drill system; usability of educational technology APIs and ontological design to support cognitive plasticity for creative immersive experience in computer aided learning.",,,2-s2.0-84947072993
"Lansiquot R.D., Cabo C.","Strategies to Integrate Writing in Problem-Solving Courses: Promoting Learning Transfer in an Interdisciplinary Context",2015,"ASEE Annual Conference and Exposition, Conference Proceedings",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941992550&partnerID=40&md5=1f63949c29a99bc0c172c62facf96ed7","Reflective writings, the contextualization of learning experiences, and the application of learning to real life all facilitate the transfer of interdisciplinary learning. Such strategies include making explicit to students the need for such a transfer, advising them to follow the appropriate course sequence, emphasizing material they need to transfer to other courses, practicing transfer by inviting guest lecturers, developing metacognitive skills, and reinforcing concepts by using them in different contexts. As the transfer of learning does not occur automatically, curricular and course design should intentionally emphasize the connection between courses. Problem Solving with Computer Programming (PS) is a required course for first-year computer systems majors, offering an ideal opportunity to establish a transfer structure. To make students aware of the connections between PS and English Composition (EG1), another required course, and to facilitate the transfer of skills, we developed a learning community (LC) linking these courses. This innovative approach to teaching computing and writing to first-year computer systems majors at a college of technology uses programming narratives as its theme. Students write and implement narratives using computer programming to develop a narrative-driven video game prototype. They use Alice, a three-dimensional animation software (www.alice.org).9,10 The LC emphasizes the importance of connecting courses in the major and those in general education. The LC builds on our previous research, which found that introducing narrative elements into problem-solving courses improves overall student performance and computer programming-related problem-solving skills in particular. This study presents best practices and lessons learned from our LC, and we present three novel strategies to integrate writing in PS courses for majors and non-majors. First, since implementation of LCs is not always feasible, to infuse narrative elements into problem-solving we developed a narrative module to help students develop narrative and writing skills that can be incorporated in all sections of the PS course. Second, we developed a series of student-assessed case studies that can be integrated in all sections of the PS course for computer systems majors. Cases studies provide a narrative context in which students learn basic constructs of computer programming such as sequencing, selection and repetition structures. Third, we created a general education interdisciplinary course, Programming Narratives: Computer Animated Storytelling, open to noncomputer majors, which emphasize creative writing and computational thinking. In this interdisciplinary course, students learn the structure of narrative, concepts of problem solving, and the logic of computer programming languages as they develop a narrative-driven video game prototype. This process helps students achieve the college-wide learning goal of making meaningful and multiple connections among the liberal arts as well as between the liberal arts and the areas of study leading to a major or profession. © American Society for Engineering Education, 2015.",,,2-s2.0-84941992550
"Jovanovic V.M., Goris T.V., Djuric A.M., Katsioloudis P.J., Luetke N.J., Moustafa M.R., Matrood B.","Integration of mechatronics design approach into teaching of modeling practices",2015,"ASEE Annual Conference and Exposition, Conference Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941995466&partnerID=40&md5=c56ad105d43ca3dc8a306abd3da8d283","Engineering design has transformed significantly due to advances in embedded system design and computer technologies. Almost every mechanical design today has some electrical and electronic components. Many products manufactured today contain both electrical and mechanical components and systems. Mechatronics is a design process that is multi-disciplinary in nature and integrates principles of many engineering disciplines including, but not limited to, mechanical engineering and mechanical engineering technology, electrical engineering and electrical engineering technology, and controls engineering. Mechatronic systems can be found in many different places today. These range from computer hard drives and robotic assembly systems, to washing machines, coffee makers, printers, and medical devices, as well as to various advanced manufacturing machines and devices that are numerically controlled, such as additive manufacturing machines, rapid prototyping machines and multi-axis CNC machines. The main purpose for integrating a mechatronics themed activity into a computer-modeling course is to engage students in project-based learning through hands-on activities related to modeling a mechatronic device. Students learn the basics of electromechanical systems, the integration of machine elements (gear reducer) and the basics of actuators (electrical motor), all of which are fundamental to understanding mechatronic systems through activities related to the mechatronic design principles. Hence, engineering design for mechanical engineers and mechanical engineering technologists have to involve embedded multi-disciplinary knowledge with the understanding of both mechanical and electrical systems. This paper will focus on presenting the use of modeling as a vehicle to teaching more complex engineering concepts, such as gears, linkage analysis, animation and the solid modelling course content. © American Society for Engineering Education, 2015.",,,2-s2.0-84941995466
"Andrea R., Darryl M., Morgan B.","E-learning professional development resources for families where a parent has a mental illnes",2015,"Parental Psychiatric Disorder: Distressed Parents and their Families, Third Edition",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954202414&doi=10.1017%2fCBO9781107707559.028&partnerID=40&md5=8ac3c6e3ad0dfa982078e2cdf727f814","The various e-learning resources for professional development in the area of parental mental illness will be presented and critically reviewed in this chapter. We define professional development (sometimes referred to as in-service training, continuing education, or retraining; Lyon et al., 2011), as the process by which professionals acquire new skills for the workplace. The advantages, primarily around the flexibility that e-learning resources offer, along with some of the problems associated with their uptake and use, will be presented. A newly developed, four-tiered, professional development framework for those working with parents and children where a parent has a mental illness will conclude this chapter. What is e-learning?, E-learning can take various forms, from reading papers or listening to podcasts online, to multimedia modules or courses using text, sound, animation, video, links to other websites, and a variety of interactive elements including a final assessment (Hare, 2009). Various terms have been used to refer to e-learning, including computer-delivered, computer-assis ted, online learning, virtual learning environment, web course tools, and learning management systems (Hare, 2009). While often sourced from a personal computer, other electronic equipment such as MP3 players and mobile phones can also be used. E-learning is increasingly considered to be an efficient way to deliver professional development programs, with some 80% of 642 companies reporting that e-learning is the most popular form of learning technology (Jeske and Stamov-Roßnagel, 2012). Moreover, the internet is becoming the first place that both clients and professionals turn to for information about mental health (Powell and Clarke, 2006). E-learning in its various guises is increasingly used in medical and allied health education (Cook et al., 2009) and is considered by many to be comparable and in some ways superior to face-to-face training. For example, in a study on community education in mental health first aid, Jorm and colleagues (2010) randomly assigned participants to (1) an e-learning CD, (2) a mental health first aid manual, or (3) a wait-list control group. Both the e-learning and the printed manual groups demonstrated increased knowledge and confidence and reduced stigma, compared to the wait-list group. However, those exposed to the e-learning CD held less stigmatizing attitudes to mental illness than those who had been through the printed manual. © Cambridge University Press (1996, 2004) 2015.",,,2-s2.0-84954202414
"Kuroda T., Kuroda K.","The head positions and nystagmus recording system using a motion sensor device",2015,"Equilibrium Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927917831&partnerID=40&md5=6e618e5a21c835c2b0f5de4d83a062d4","Instead of examination under Fresnel lenses, infrared videonystagmography is now commonly used in cases of nystagmus. Nystagmus images are stored on a video recorder or a computer, and the information of the head positions is also saved using voice in the video. The method using voice is a simple way to record positions of the head, because it needs no additional hardware. However, judgment of the head position is difficult during playback if it is started from the middle of the recorded nystagmus images, which forces the examining clinician to continue to talk about the position of the head during the entire examination. We developed a motion sensor device and related software to record information about the position of the head which we have been using in our clinic since 2010. Recently the price and size of integrated circuitry, such as sensors, have fallen dramatically, concomitantly with improved performance. Even as amateurs, we can assemble a motion sensor device with a small number of parts and cheaply. Herein we explain how to make the motion sensor device and related software, which generate data on head animation from the sensor, correlate these data with the nystagmus images before saving them, and enable us to utilize the recorded images in various ways.","Head position; Motion sensor; Nystagmus; Video","Article; Fresnel lens; head position; human; motion sensor device; nystagmus; ophthalmological diagnostic device; videorecording",2-s2.0-84927917831
"Davies C., Fabrikant S.I., Hegarty M.","Toward empirically verified cartographic displays",2015,"The Cambridge Handbook of Applied Perception Research",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954286571&doi=10.1017%2fCBO9780511973017.043&partnerID=40&md5=fd5e13d8e5da85fa11f607dad6955da4","Introduction Maps, like many other kinds of purposefully constructed graphic displays, are so familiar in everyday life that it is easy to overlook the complex decisions made by the cartographers who design them. Although cartography has a long history as both art and science, there has been very little empirical work on the scientific evaluation of map designs. This chapter summarizes current knowledge and research on perceptual and attentional aspects of cartographic design, and empirical methods that can be used to evaluate the design of both static maps and more flexible, and dynamic, computer-based geographic visualizations. We focus on the use of “salience maps” to characterize the map stimuli, and the use of eye fixations to measure visual attention. We also summarize some alternative empirical methods. All of these methods can be used to evaluate not only the more common static map displays such as road maps and topographic maps, but also the more realistic-looking geographic visualizations used in remote sensing and photogrammetry (the extraction of measurements, physical topography, and other information from aerial photographs or satellite imagery). Furthermore, the evaluation methods can also be used with more abstract cartographic products, such as statistical maps and multivariate spatiotemporal displays, including map animations and three-dimensional-globe viewers. As such, our discussion pertains not only to conventional cartographic designers but also to other visual design disciplines. © Cambridge University Press 2015.",,,2-s2.0-84954286571
"Håkansson A., Stenberg M., Öhrling J.D.","Visualising workplace design",2015,"Proceedings of the 17th International Conference on Engineering and Product Design Education: Great Expectations: Design Teaching, Research and Enterprise, E and PDE 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958149198&partnerID=40&md5=813b530bcba5ea832674d3cf7741f20e","Design is a learning process and the use of prototyping activities for the sake of learning increases the design thinking, i.e. the dialogue and feedback on ideas. Hence, representations ranging from sketches to different kind of models and animations are recommended to be used as prototypes to mediate user needs and to support communication within the team. Low-fidelity prototyping enables rapid visualisation of ideas, reframes failures into learning, generates perceptual progress and supports creativity. In product design, different visualisation techniques are used to generate and communicate ideas since thinking visually is seen as necessary for innovation. This paper describes the work of developing a course where you combine the task of workplace design with traditional industrial design visualisation methods like sketching, model making and 3D computer aids. By using the knowledge and experience from product design and incorporate it into workplace design, a process where all parties contribute in new ways could be achieved. In the course the students start by performing an individual investigation of the present research front for production visualisation by summarizing and analysing a number of scientific articles. A work place design project was then performed where exploratory, explanatory and persuasive visualizing techniques were implemented. Through a creative and constructive collaboration across disciplinary boundaries, Industrial Production Environment and Industrial Design, we have created and implemented a course in an area that has been lacking in our Master Program. © 2015, The Design Society. All rights reserved.","Communication; Layout; Participation; Visualization; Workplace design","Communication; Curricula; Design; Education computing; Engineering education; Flow visualization; Teaching; Visualization; Disciplinary boundaries; Industrial production; Knowledge and experience; Layout; Low-fidelity prototyping; Participation; Scientific articles; Workplace design; Product design",2-s2.0-84958149198
"Pendit U.C., Zaibon S.B., Abubakar J.A.","Digital interpretive media usage in cultural heritage sites at yogyakarta",2015,"Jurnal Teknologi",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938262225&partnerID=40&md5=ee8be7276c66a028444174d72b05b8e6","Cultural heritage is the asset of tourism industry to attract tourist for visiting a country. Cultural heritage needs to be conserved in order to prolong the life from being deterioration. However, conservation needs huge financial cost and this reason becomes the major obstacles for cultural heritage to be maintained its existence in a country. Nowadays, digital cultural heritage conservation is alternatively utilized as it reduces the cost of conservation in the form of digital interpretive media such as video, animation, 3D simulation, virtual reality, and augmented reality. Therefore, this study attempted to seek about the availability of digital interpretive media at cultural heritage sites through a survey. This paper presents the findings of availability level of digital media in the heritage sites in Yogyakarta, Indonesia. The findings show that the availability of digital media in Yogyakarta cultural heritage sites are mostly in traditional media types such as signs, brochures, maps, leaflets, and books. In attracting tourist, it is suggested that the cultural heritage sites should be provided with more advance interpretive media, namely computer simulations; personal stereo guided tours, virtual reality, and recently augmented reality as a way to conserve cultural heritage information and values. © 2015 Penerbit UTM Press. All rights reserved","Digital conservation; Interpretive media; Virtual heritage",,2-s2.0-84938262225
"Çengel M.","Concept teaching to mentally retarded students through mobile devices",2015,"Turkish Online Journal of Educational Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957565125&partnerID=40&md5=27ec86c2ca151ed64b6cde3ca3591b75","In the process of design, refinement and selection of the software required for mentally retarded students’ education, the characteristics of students should be taken into consideration. Mobile application software can be used as a supplementary material in the education of students who need special education. Many studies reveal that computer assisted programs increase the motivation and concentration time of mentally retarded students and they enjoy studying with mobile devices (Tablets, Smartphones). Apart from ordinary students, mentally retarded students should also be provided with opportunities of technology in their education after developing technology gets into every aspect of the life and is also used in education. In this study, concept teaching based on animation and simulation is intended by making use of technology in the education of mentally retarded students. This process makes a valuable contribution to students in terms of concept learning at schools and rehabilitation centers which facilitate for learning by technology assisted visual programs. This study was conducted with 40 students at four schools of mentally retarded and rehabilitation centers inning Sakarya. The evaluation of the data obtained from the application, students who have been learning the concepts of mobile learning tools revealed that they are more successful than those who had learned classical learning methods. According to these results, it can be said that mobile devices make a contribution to concept learning of mentally retarded students. © The Turkish Online Journal of Educational Technology.","Concept teaching and technology; Mentally retarded students",,2-s2.0-84957565125
"Abuhashish F.A.M., Kolivand H., Sunar M.S., Mohamad D.","Framework of controlling 3d virtual human emotional walking using BCI",2015,"Jurnal Teknologi",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938279642&partnerID=40&md5=9137bc42c5e8b62f55c8198f61b9e29e","A Brain-Computer Interface (BCI) is the device that can read and acquire the brain activities. A human body is controlled by Brain-Signals, which considered as a main controller. Furthermore, the human emotions and thoughts will be translated by brain through brain signals and expressed as human mood. This controlling process mainly performed through brain signals, the brain signals is a key component in electroencephalogram (EEG). Based on signal processing the features representing human mood (behavior) could be extracted with emotion as a major feature. This paper proposes a new framework in order to recognize the human inner emotions that have been conducted on the basis of EEG signals using a BCI device controller. This framework go through five steps starting by classifying the brain signal after reading it in order to obtain the emotion, then map the emotion, synchronize the animation of the 3D virtual human, test and evaluate the work. Based on our best knowledge there is no framework for controlling the 3D virtual human. As a result for implementing our framework will enhance the game field of enhancing and controlling the 3D virtual humans’ emotion walking in order to enhance and bring more realistic as well. Commercial games and Augmented Reality systems are possible beneficiaries of this technique. © 2015 Penerbit UTM Press. All rights reserved.","BCI; Component; EEG; Emotion recognition; Framework",,2-s2.0-84938279642
"Shih R.","A hands-on project approach to teaching solid modeling",2015,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941992628&partnerID=40&md5=96e1c6e05c14dbaa2da63caccbb91988","This paper describes an integrated laboratory-oriented course MET/MFG407 in computer-aided Design at Oregon Institute of Technology. Teaching this subject in an 11-week of academic quarter is a challenging task requiring a combination of instructional delivery methods. Besides the in class lectures on the different aspects of using the CAD software; each student is also given a toy robot kit to be modeled. The course content is designed around three learning objectives: be able to create parametric models, be able to generate the associated 2D multiview drawings of the solid models, be able to create assemblies and animations of the solid models, and perform kinematic analysis of the given design. The author will share his observations and experience with educators in the field. Computer-aided-engineering tools, such as CAD, FEA and CAM, are becoming to be the essential tools to the engineering practices in industry. This paper describes the development of an applied Solid Modeling course that is being offered by the Mechanical and Manufacturing Engineering Technology (MMET) department at Oregon Institute of Technology. Solid Modeling is an important part of Computer Aided Design (CAD) technology, which can be used to aid the creation of better Designs. At Oregon Institute of Technology, the first Solid Modeling course was first developed and taught back in 1987; and with the developments of the other leading edge technologies, we now see very exciting changes in how an engineer perform his/her daily tasks in industry. In 1996, the MMET department began to incorporate the parametric modeling software in the MET and MFG programs. In the Spring term of 2011, an elective course (MET/MFG 407 Advanced Solid Modeling) was developed and offered. Students are required to have finished the required MET 375 Solid Modeling class to enroll in this course. A different Parametric Modeling software is used in this second solid modeling course. The course has been offered every year since 2011. The main emphases of the course are placed on both teaching the students to use a commercially available parametric package and have the students performing the modeling and analysis tasks of a toy robot kit. The course objectives have been established as follows:. To learn the basic concepts and procedures associated with using a commercially available Parametric Modeling package. To understand and use the tools available in 3D Parametric Modeling technology. To generate 2D working drawings of the 3D models. To learn and perform 2D and 3D kinematic analysis using modern computer software. Apply the techniques and skills taught to related problems in follow-on courses. This paper describes the changes and results of the Advanced Solid Modeling course offered by the Mechanical and Manufacturing Engineering Technology Department at Oregon Institute of Technology. © American Society for Engineering Education, 2015.",,,2-s2.0-84941992628
"Vranić V., Porubän J., Bystrický M., Frťala T., Polášek I., Nosáľ M., Lang J.","Challenges in preserving intent comprehensibility in software",2015,"Acta Polytechnica Hungarica",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948740449&partnerID=40&md5=809ffbfe131c528126ad5c66479bc846","Software is not only difficult to create, but it is also difficult to understand. Even the authors themselves in a relatively short time become unable to readily interpret their own code and to explain what intent they have followed by it. Software is being created with the goal to satisfy the needs of a customer or directly of the end users. Out of these needs comes the intent, which is relatively well understandable to all stakeholders. By using other specialized modeling techniques (typically the UML language) or in the code itself, use cases and other high-level specification and analytical artifacts in common software development almost completely dissolve. Along with dedicated initiatives to improve preserving intent comprehensibility in software, such as literate programming, intentional programming, aspect-oriented programming, or the DCI (Data, Context and Interaction) approach, this issue is a subject of contemporary research in the re-revealed area of engaging end users in software development, which has its roots in Alan Kay's vision of a personal computer programmable by end users. From the perspective of the reality of complex software system development, the existing approaches are solving the problem of losing intent comprehensibility only partially by a simplified and limited perception of the intent and do this only at the code level. This paper explores the challenges in preserving the intent comprehensibility in software. The thorough treatment of this problem requires a number of techniques and approaches to be engaged, including preserving use cases in the code, dynamic code structuring, executable intent representation using domain specific languages, advanced UML modularization, 3D rendering of UML, and representation and animation of organizational patterns. © 2015, Budapest Tech Polytechnical Institution. All Rights Reserved.","3D rendering of UML; Domain specific languages; Intent; Organizational patterns; Use cases",,2-s2.0-84948740449
"Markusic C.A., Songade R.","Simplified Side Impact FE Model - SSM",2015,"SAE Technical Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938331859&doi=10.4271%2f2015-01-1486&partnerID=40&md5=a3edb8db7e8130e1c83ad6cabc88fbf4","Simplified Side Impact Finite Element Model (SSM) merged the complex side crash model parameters used in LS-DYNA4; the same sophisticated software employed by finite element (FE)2 analysts, and the user-friendly custom graphical user interface (GUI)1 to allow users having little to no simulation software knowledge the ability to conduct a full vehicle representative crash simulation. Prior to SSM development a literature search was carried to try and identify similar CAE tools for side impact. We did not find any tool that would cater specifically to side impact. During the testing phase, SSM demonstrated that one model analysis run can be completed in fewer than thirty (30) minutes, a radical efficiency increase because previous procedures require several days of effort from a highly skilled FE2 analyst to set up, execute, and analyze. The GUI1 can be used to easily view an animation of the simulation or plot graphs of the dummy response, compare results from multiple simulations, and generate reports. We also established that SSM provides a valuable analysis tool that can be used by a crash engineer to evaluate and fine tune the vehicle's side crash restraint system using body performance specification during the planning stages of development. The GUI1 allows users to easily modify the performance characteristics of the side impact system that are critical to side crash performance, including, but not limited to, intrusion rate, door liner stiffness, side airbag stiffness, and side airbag time to fire. Prior to the development of SSM the crash safety engineers choices for specification analysis were limited to sled testing or vehicle crash testing, both time consuming and resource intensive activities, or full vehicle simulation which is also time consuming and not so well suited to easy manipulation of structural and restraint system parameters. The use of SSM allows earlier integration of restraint computer-aided engineering (CAE) analysis into the development process for a quick and accurate specification optimization. Copyright © 2015 SAE International.",,,2-s2.0-84938331859
"Williamson C.","Hidden in plain sight: An archaeology of magic and the cinema",2015,"Hidden in Plain Sight: An Archaeology of Magic and the Cinema",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018612983&partnerID=40&md5=5061d83d4a12db1ae987b2466d4631dc","What does it mean to describe cinematic effects as “movie magic,"" to compare filmmakers to magicians, or to say that the cinema is all a “trick”? The heyday of stage illusionism was over a century ago, so why do such performances still serve as a key reference point for understanding filmmaking, especially now that so much of the cinema rests on the use of computers? To answer these questions, Colin Williamson situates film within a long tradition of magical practices that combine art and science, involve deception and discovery, and evoke two forms of wonder-both awe at the illusion displayed and curiosity about how it was performed. He thus considers how, even as they mystify audiences, cinematic illusions also inspire them to learn more about the technologies and techniques behind moving images. Tracing the overlaps between the worlds of magic and filmmaking, Hidden in Plain Sight examines how professional illusionists and their tricks have been represented onscreen, while also considering stage magicians who have stepped behind the camera, from Georges Méliès to Ricky Jay. Williamson offers an insightful, wide-ranging investigation of how the cinema has functioned as a “device of wonder” for more than a century, while also exploring how several key filmmakers, from Orson Welles to Christopher Nolan and Martin Scorsese, employ the rhetoric of magic. Examining pre-cinematic visual culture, animation, nonfiction film, and the digital trickery of today’s CGI spectacles, Hidden in Plain Sight provides an eye-opening look at the powerful ways that magic has shaped our modes of perception and our experiences of the cinema. © 2015 by Colin Williamson. All rights reserved.",,,2-s2.0-85018612983
"Brunner G.W., Piper S.S., Jensen M.R., Chacon B.","Combined 1D and 2D hydraulic modeling within HEC-RAS",2015,"World Environmental and Water Resources Congress 2015: Floods, Droughts, and Ecosystems - Proceedings of the 2015 World Environmental and Water Resources Congress",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935115762&doi=10.1061%2f9780784479162.141&partnerID=40&md5=7e424e363c9e417a608f0be6e88bb209","HEC has added the ability to perform two-dimensional (2D) hydrodynamic flow routing within the unsteady flow analysis portion of HEC-RAS. This new capability within HEC-RAS has the following attributes: 1. The ability to perform combined 1D and 2D modeling within the same unsteady flow model will allow users to work on larger river systems, utilizing 1D modeling where appropriate and 2D modeling in areas that require a higher level of hydrodynamic fidelity. 2. The program solves either the full 2D Saint Venant equations or the 2D Diffusion Wave equations. This is user selectable, giving modelers more flexibility. 3. The 2D flow solver uses an Implicit Finite Volume algorithm. The implicit solution algorithm allows for larger computational time steps than explicit methods. The finite volume approach provides a measure of improved stability and robustness over traditional finite difference and finite element techniques. 4. The 1D and 2D solution algorithms are tightly coupled on a time step by time step basis (optionally, iteration by iteration within a time step). 5. The software was designed to use structured or unstructured computational meshes. 6. Each cell, and cell face, of the computational mesh is pre-processed in order to develop detailed hydraulic property tables based on the underlying terrain used in the modeling process. Additionally, each face of a computational cell is pre-processed into detailed hydraulic property tables (elevation versus, wetted perimeter, area, roughness, etc.). This allows the user to use larger computational cells, without losing the detail of the underlying terrain. 7. Mapping of the inundated area, as well as animations of the flooding can be accomplished right inside of RAS using RAS Mapper. 8. The 2D Flow Area computational solution has been programmed to take advantage of multi-processors on a computer (referred to as parallelization). This paper will discuss the details of the new 2D modeling capabilities that have been added to HEC-RAS. Additionally, the new capabilities of combining 1D and 2D modeling elements within the same unsteady flow model will be demonstrated with the application of real world data sets. © 2015 ASCE.",,"Algorithms; Cells; Cytology; Drought; Ecology; Ecosystems; Finite element method; Floods; Fluid dynamics; Hydrodynamics; Iterative methods; Unsteady flow; Virtual reality; Wave equations; Computational solutions; Diffusion wave equation; Finite element techniques; Finite volume approach; Stability and robustness; Two Dimensional (2 D); Unsteady flow analysis; Unsteady flow modeling; Water resources",2-s2.0-84935115762
"Wang Z., Ye T., Lu M., Yuan X., Qu H., Yuan J., Wu Q.","Visual exploration of sparse traffic trajectory data",2014,"IEEE Transactions on Visualization and Computer Graphics",37,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910040705&doi=10.1109%2fTVCG.2014.2346746&partnerID=40&md5=0df316d5c8a2462e8acebaf84e40c6d1","In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system. © 1995-2012 IEEE.","Dynamic Graph Visualization; Sparse Traffic Trajectory; Traffic Congestion; Traffic Visualization","Dynamic graph; Trajectory data; Visual exploration; Traffic congestion; city; computer graphics; computer simulation; human; information science; motion; motor vehicle; procedures; Cities; Computer Graphics; Computer Simulation; Humans; Informatics; Motion; Motor Vehicles",2-s2.0-84910040705
"Hsu W.H.","Creating open source lecture materials: A guide to trends, technologies, and approaches in the information sciences",2014,"STEM Education: Concepts, Methodologies, Tools, and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957975930&doi=10.4018%2f978-1-4666-7363-2.ch004&partnerID=40&md5=4f4c13532a1a93466929a0e33c1d369b","This chapter surveys recent and continuing trends in software tools for preparation of open courseware, in particular audiovisual lecture materials, documentaries and tutorials, and derivative materials. It begins by presenting a catalog of tools ranging from open source wikis and custom content management systems to desktop video production. Next, it reviews techniques for preparation of lecture materials consisting of five specific learning technologies: animation of concepts and problem solutions; explanation of code; video walkthroughs of system documentation; software demonstrations; and creation of materials for instructor preparation and technology transfer. Accompanying the description of each technology and the review of its state of practice is a discussion of the goals and assessment criteria for deployed courseware that uses those tools and techniques. Holistic uses of these technologies are then analyzed via case studies in three domains: artificial intelligence, computer graphics, and enterprise information systems. An exploration of technology transfer to college and university-level instructors in the information sciences then follows. Finally, effective practices for encouraging adoption and dissemination of lecture materials are then surveyed, starting with comprehensive, well-established open courseware projects that adapt pre-existing content and continuing through recent large-scale online courses aimed at audiences of tens to hundreds of thousands. © 2015, IGI Global. All rights reserved.",,,2-s2.0-84957975930
"Levy K., Lerner A., Shashar N.","Mate choice and body pattern variations in the Crown Butterfly fish Chaetodon paucifasciatus (Chaetodontidae)",2014,"Biology Open",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979211514&doi=10.1242%2fbio.20149175&partnerID=40&md5=84f32461f413b08b4e9b84b044c8d478","Mate choice is an important ecological behavior in fish, and is often based on visual cues of body patterns. The Crown Butterfly fish Chaetodon paucifasciatus (Chaetodontidae) is a monogamist, territorial species; it swims in close proximity to its partner throughout most of its life. This species is characterized by a pattern of 6-8 vertical black stripes on a white background, on both sides of its body. Our aim was to define spatial features (variations) in body patterns by evaluating the level of dissimilarity between both sides of each individual fish, and the level of dissimilarity between patterns of different individuals. In addition, we tested whether the fish are attracted to or reject specific features of the body patterns. Features were defined and counted using photographs of body patterns. Attraction to or rejection of specific features were tested behaviorally using a dual-choice experiment of video animations of individuals swimming over a coral-reef background. We found that the patterns of each fish and sides of the body were no less dissimilar, compared intraspecificly to other fish, and that each side pattern was unique and distinguishable. Variations in the patterns occurred mostly in the last three posterior stripes. Individuals were mainly attracted to conspecifics with multiple crossing patterns (two or more consecutive crossings), and rejected patterns with holes. Our results suggest that in this species the unique body pattern of each fish is used for conspecific identification of mates and intruders. © 2014. Published by The Company of Biologists Ltd.","Animal recognition; Computer animation; Sexual selection; Symmetry; Vision",,2-s2.0-84979211514
"Musti U., Ouni S., Zhou Z., Pietikäinen M.","3D visual speech animation from image sequences",2014,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955261126&doi=10.1145%2f2683483.2683530&partnerID=40&md5=e9cc98ca18f0b20475d0bc4b15551f52","In this paper we describe an early version of our system which synthesizes 3D visual speech including tongue and teeth from frontal facial image sequences. This system is developed for 3D Visual Speech Animation (VSA) using images generated by an existing state-of-the-art image-based VSA system. In fact, the prime motivation for this system is to have a 3D VSA system from limited amount of training data when compared to that required for developing a conventional corpus based 3D VSA system. It consists of two modules. The first module iteratively estimates the 3D shape of the external facial surface for each image in the input sequence. The second module complements the external face with 3D tongue and teeth to complete the perceptually crucial visual speech information. This has the added advantages of 3D visual speech, which are renderability of the face in different poses and illumination conditions and, enhanced visual information of tongue and teeth. The first module for 3D shape estimation is based on the detection of facial landmarks in images. It uses a prior 3D Morphable Model (3D-MM) trained using 3D facial data. For the time being it is developed for a person-specific domain, i.e., the 3D-MM and the 2D facial landmark detector are trained using the data of a single person and tested with the same person-specific data. The estimated 3D shape sequences are provided as input to the second module along with the phonetic segmentation. For any particular 3D shape, tongue and teeth information is generated by rotating the lower jaw based on few skin points on the jaw and animating a rigid 3D tongue through keyframe interpolation. Copyright 2014 ACM.","3D facial shape estimation from images; 3D morphable models; 3D visual speech; Active appearance models; Facial landmark detection; Tongue animation; Visual speech animation","Animation; Computer vision; Face recognition; Speech; 3D Morphable model; Active appearance models; Facial landmark detection; Facial shape; Visual speech; Image processing",2-s2.0-84955261126
"Wood A.","Software, Animation and the Moving Image: What's in the Box?",2014,"Software, Animation and the Moving Image: What's in the Box?",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973131533&doi=10.1057%2f9781137448859&partnerID=40&md5=0d60b036281345aeea46d318d790da42","Software, Animation and the Moving Image brings a unique perspective to the study of computer-generated animation by placing interviews undertaken with animators alongside an analysis of the user interface of animation software. Wood develops a novel framework for considering computer-generated images found in visual effects and animations. © Aylish Wood 2015. All rights reserved.",,"Animation; User interfaces; Animation softwares; Computer-generated animations; Computer-generated images; Moving image; Visual effects; Computer software",2-s2.0-84973131533
"Somov S., Somova T.","Methods for nonlinear analysis, simulation and animation of land-survey spacecraft guidance",2014,"AIP Conference Proceedings",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959923818&doi=10.1063%2f1.4904678&partnerID=40&md5=0f3000654dfdbef89f5e77539119728a","Obtained in the space photos a ground resolution depends on a spacecraft spatial angular motion during optoelectronic survey the paper studies case of optimal equalization of an image longitudinal velocity in the focal plane of telescope and tackles the problem of defining initial azimuth of the scanning survey under the condition of minimizing quadratic functional of image cross velocity values on edges of the CCD linear array. Results of a simulated survey of random surface object are presented, and the change of initial azimuth value for various survey angles within the swath is examined the paper presents also a brief description of developed software for designing the space telescope characteristics, simulation and animation of the land-survey spacecraft spatial motion and gives recommendations for its applications. © 2014 AIP Publishing LLC.","animation; observation; optimization; simulation; spacecraft","Animation; Application programs; Computer software; Nonlinear analysis; Optimization; Spacecraft; Angular motions; Ground resolution; ITS applications; Longitudinal velocity; observation; Quadratic functionals; Random surfaces; simulation; Surveys",2-s2.0-84959923818
"Duman S., Onarlioglu K., Ulusoy A.O., Robertson W., Kirda E.","TrueClick: Automatically distinguishing trick banners from genuine download links",2014,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954518099&doi=10.1145%2f2664243.2664279&partnerID=40&md5=3998e84e742a95d34c4929520067a943","The ubiquity of Internet advertising has made it a popular target for attackers. One well-known instance of these attacks is the widespread use of trick banners that use social engineering techniques to lure victims into clicking on deceptive fake links, potentially leading to a malicious domain or malware. A recent and pervasive trend by attackers is to imitate the ""download"" or ""play"" buttons in popular file sharing sites (e.g., one-click hosters, video-streaming sites, bittorrent sites) in an attempt to trick users into clicking on these fake banners instead of the genuine link. In this paper, we explore the problem of automatically assisting Internet users in detecting malicious trick banners and helping them identify the correct link. We present a set of features to characterize trick banners based on their visual properties such as image size, color, placement on the enclosing webpage, whether they contain animation effects, and whether they consistently appear with the same visual properties on consecutive loads of the same webpage. We have implemented a tool called TrueClick, which uses image processing and machine learning techniques to build a classifier based on these features to automatically detect the trick banners on a webpage. Our approach automatically classifies trick banners, and requires no manual effort to compile blacklists as current approaches do. Our experiments show that TrueClick results in a 3.55 factor improvement in correct link selection in the absence of other ad blocking software, and that it can detect trick banners missed by a popular ad detection tool, Adblock Plus.",,"Artificial intelligence; Distributed computer systems; Image processing; Internet; Learning systems; Online systems; Security of data; Security systems; Video streaming; Websites; World Wide Web; Animation effects; Detection tools; File Sharing; Internet advertising; Internet users; Machine learning techniques; Social engineering; Visual properties; Malware",2-s2.0-84954518099
"Greuter S., Nash A.","Game asset repetition",2014,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955576779&doi=10.1145%2f2677758.2677782&partnerID=40&md5=78f04167f1b3c5eb370a56221c91eb49","The frequent repetition of visual assets, such as the frequent appearance of a particular game object in a game world or the repetition of a character's animation cycle, often becomes apparent to players when they encounter such repetition within a short period of time. A certain amount of visual repetition has always been accepted by players, however as technology improves and game worlds tend towards more detail, the repetition of assets in games becomes more obvious. Particularly graphically advanced games require an increasing number of assets to hide the repetition and to create believable game worlds. This paper examines various levels of asset repetition in electronic games and addresses problems that can arise. The paper describes some contemporary approaches used by artists in the industry to hide repetition, and touches on current technologies that might be applied in game development to address this problem. © 2014 ACM.","Asset Repetition; Game Assets; Procedural Generation","Animation; Interactive computer graphics; Asset Repetition; Electronic games; Game Assets; Game development; On currents; Procedural Generation; Short periods; Software design",2-s2.0-84955576779
"Walther-Franks B., Malaka R.","An interaction approach to computer animation",2014,"Entertainment Computing",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912573456&doi=10.1016%2fj.entcom.2014.08.007&partnerID=40&md5=b8335da6f9007d10ee1602f623cbc8ea","Design of and research on animation interfaces rarely uses methods and theory of human-computer-interaction (HCI). Graphical motion design interfaces are based on dated interaction paradigms, and novel procedures for capturing, processing and mapping motion are preoccupied with aspects of modeling and computation. Yet research in HCI has come far in understanding human cognition and motor skills and how to apply this understanding to interaction design. We propose an HCI perspective on computer animation that relates the state-of-the-art in motion design interfaces to the concepts and terminology of this field. The main contribution is a design space of animation interfaces. This conceptual framework aids relating strengths and weaknesses of established animation methods and techniques. We demonstrate how this interaction-centric approach can be put into practice in the development of a multi-touch animation system. © 2014 Elsevier B.V.","Design space; Human-computer interaction; Motion design interfaces; Performance animation","Animation; Computation theory; Design; Interface states; Animation interfaces; Conceptual frameworks; Design spaces; Interaction design; Interaction paradigm; Modeling and computation; Motion design; Performance animations; Human computer interaction",2-s2.0-84912573456
"Berghel H.","Judson Rosebush on computer graphics and animation",2014,"Computer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919915926&doi=10.1109%2fMC.2014.357&partnerID=40&md5=bf1de892e10d8bde2d5c523913d7c7a9","Once animation went digital, we (almost) never looked back. Here I speak with one of the pioneers of animation and multimedia, Judson Rosebush. © 2014 IEEE.",,"Animation; Computer graphics and animations; Computer graphics",2-s2.0-84919915926
"Kenwright B.","Planar character animation using genetic algorithms and GPU parallel computing",2014,"Entertainment Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912573412&doi=10.1016%2fj.entcom.2014.09.003&partnerID=40&md5=5225cdd07ef682754cf630b70251314d","The emergence of evolving search techniques (e.g., genetic algorithms) has paved the way for innovative character animation solutions. For example, generating human movements without key-frame data. Instead character animations can be created using biologically inspired algorithms in conjunction with physics-based systems. While the development of highly parallel processors, such as the graphical processing unit (GPU), has opened the door to performance accelerated techniques allowing us to solve complex physical simulations in reasonable time frames. The combined acceleration techniques in conjunction with sophisticated planning and control methodologies enable us to synthesize ever more realistic characters that go beyond pre-recorded ragdolls towards more self-driven problem solving avatars. While traditional data-driven applications of physics within interactive environments have largely been confined to producing puppets and rocks, we explore a constrained autonomous procedural approach. The core difficulty is that simulating an animated character is easy, while controlling one is more complex. Since the control problem is not confined to human type models, e.g., creatures with multiple legs, such as dogs and spiders, ideally there would be a way of producing motions for arbitrary physically simulated agents. This paper focuses on evolutionary genetic algorithms, compared to the traditional data-driven approach. We demonstrate generic evolutionary techniques that emulate physically-plausible and life-like animations for a wide range of articulated creatures in dynamic environments. We help address the computational bottleneck of the genetic algorithms by applying the method to a massively parallel computational environments, such as, the graphical processing unit (GPU). © 2014 Elsevier B.V.","Animation; Computer games; Control; Genetic; Graphical processing unit (GPU); Interactive","Computer games; Computer graphics equipment; Computer simulation; Control; Genetic algorithms; Parallel architectures; Problem solving; Biologically inspired algorithms; Computational bottlenecks; Computational environments; Data-driven applications; Genetic; Graphical processing units; Interactive; Interactive Environments; Animation",2-s2.0-84912573412
"Noguera J.M., Rueda A.J., Espada M.A., Martín M.","Optimized generation of stereoscopic CGI films by 3D image warping",2014,"Computer Graphics Forum",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913588771&doi=10.1111%2fcgf.12422&partnerID=40&md5=f9c252fb80c3c9bf4f022d5fd6edd080","The generation of a stereoscopic animation film requires doubling the rendering times and hence the cost. In this paper, we address this problem and propose an automatic system for generating a stereo pair from a given image and its depth map. Although several solutions exist in the literature, the high standards of image quality required in the context of a professional animation studio forced us to develop specially crafted algorithms that avoid artefacts caused by occlusions, anti-aliasing filters, etc. This paper describes all the algorithms involved in our system and provides their GPU implementation. The proposed system has been tested with real-life working scenarios. Our experiments show that the second view of the stereoscopic pair can be computed with as little as 15% of the effort of the original image while guaranteeing a similar quality. © 2014 The Authors Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Image-based rendering; Novel applications of the GPU; Rendering","Animation; Anti-aliasing; Image reconstruction; Rendering (computer graphics); Three dimensional computer graphics; Animation studios; Antialiasing filters; Automatic systems; GPU implementation; Image-Based Rendering; Novel applications; Rendering; Stereoscopic pair; Stereo image processing",2-s2.0-84913588771
"Campen M., Kobbelt L.","Quad layout embedding via aligned parameterization",2014,"Computer Graphics Forum",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913593441&doi=10.1111%2fcgf.12401&partnerID=40&md5=e4b9bf5343a34e6edcb34e6ded4b9ac1","Quad layouting, i.e. the partitioning of a surface into a coarse network of quadrilateral patches, is a fundamental step in application scenarios ranging from animation and simulation to reverse engineering and meshing. This process involves determining the layout's combinatorial structure as well as its geometric embedding in the surface. We present a novel quad layout algorithm that focuses on the embedding optimization, thereby complementing recent methods focusing on the structure optimization aspect. It takes as input a description of the target layout structure and computes a complete embedding in form of a parameterization globally optimized for isometry and, in particular, principal direction alignment. Besides being suited for fully automatic workflows, our method can also incorporate user constraints and support the tedious but common procedure of manual layouting. © 2014 The Authors Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Geometric modeling; Mesh generation; Surface parameterization","Animation; Computer simulation; Mesh generation; Parameterization; Reverse engineering; Structural optimization; Animation and simulations; Application scenario; Combinatorial structures; Geometric modeling; Principal directions; Quadrilateral patches; Structure optimization; Surface parameterization; Computational geometry",2-s2.0-84913593441
"Kohout J., Kukačka M.","Real-time modelling of fibrous muscle",2014,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913587947&doi=10.1111%2fcgf.12354&partnerID=40&md5=f9d650c99de791ccf45272470001a4bd","Relatively recently it has become apparent that providing human kind with a better healthcare requires personalized, predictive and integrative medicine, for which the building of virtual physiological human (VPH) framework accessible via virtual patient avatar is necessary. Real-time modelling and visual exploration of such a complex avatar is a challenging task. In this paper, we propose a real-time method for automatic modelling of an arbitrarily large number of muscle fibres in the volume of a muscle represented by its surface mesh. The method is based on an iterative morphing of predefined fibres template into the muscle volume exploiting harmonic scalar field computed on the surface of muscle. Experiments with muscles of thighs and pelvis show that the method produces realistic shapes of fibres. Our sequential VTK-based C++ implementation is capable of producing 64 fine fibres within a muscle of 10K triangles in less than 170 ms on commodity hardware making the method suitable for VPH purposes as well as for interactive educational medical software. © 2014 The Authors Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Animation biological modeling; Geometric modeling; Human simulation","Animation; Bioinformatics; C++ (programming language); Computer software; Fibers; Iterative methods; Virtual reality; Biological modeling; Commodity hardware; Geometric modeling; Human simulation; Medical software; Virtual patients; Virtual physiological human; Visual exploration; Muscle",2-s2.0-84913587947
"Charalambous P., Chrysanthou Y.","The PAG crowd: A graph based approach for efficient data-driven crowd simulation",2014,"Computer Graphics Forum",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913591812&doi=10.1111%2fcgf.12403&partnerID=40&md5=7ae37e34241c541f78bc6da8e9c1d721","We present a data-driven method for the real-time synthesis of believable steering behaviours for virtual crowds. The proposed method interlinks the input examples into a structure we call the perception-action graph (PAG) which can be used at run-time to efficiently synthesize believable virtual crowds. A virtual character's state is encoded using a temporal representation, the Temporal Perception Pattern (TPP). The graph nodes store groups of similar TPPs whereas edges connecting the nodes store actions (trajectories) that were partially responsible for the transformation between the TPPs. The proposed method is being tested on various scenarios using different input data and compared against a nearest neighbours approach which is commonly employed in other data-driven crowd simulation systems. The results show up to an order of magnitude speed-up with similar or better simulation quality. © 2014 The Authors Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","2D techniques; Behavioral animation; Human simulation","Animation; 2D techniques; Behavioral animation; Data-driven methods; Human simulation; Real-time synthesis; Simulation quality; Temporal perception; Temporal representations; Behavioral research",2-s2.0-84913591812
"Lawonn K., Gasteiger R., Preim B.","Adaptive surface visualization of vessels with animated blood flow",2014,"Computer Graphics Forum",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913537554&doi=10.1111%2fcgf.12355&partnerID=40&md5=b146a9ab754fe2321d1b8c686388461d","The investigation of hemodynamic information for the assessment of cardiovascular diseases (CVDs) gained importance in recent years. Improved flow measuring modalities and computational fluid dynamics (CFD) simulations yield in reliable blood flow information. For a visual exploration of the flow information, domain experts are used to investigate the flow information combined with its enclosed vessel anatomy. Since the flow is spatially embedded in the surrounding vessel surface, occlusion problems have to be resolved. A visual reduction of the vessel surface that still provides important anatomical features is required. We accomplish this by applying an adaptive surface visualization inspired by the suggestive contour measure. Furthermore, an illustration is employed to highlight the animated pathlines and to emphasize nearby surface regions. Our approach combines several visualization techniques to improve the perception of surface shape and depth. Thereby, we ensure appropriate visibility of the embedded flow information, which can be depicted with established or advanced flow visualization techniques. We apply our approach to cerebral aneurysms and aortas with simulated and measured blood flow. An informal user feedback with nine domain experts, we confirm the advantages of our approach compared with existing methods, e.g. semi-transparent surface rendering. Additionally, we assessed the applicability and usefulness of the pathline animation with highlighting nearby surface regions. © 2014 The Authors Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Flow visualization; Perceptually based rendering; Rendering; Scientific visualization; Visualization; Visualization","Animation; Blood; Blood vessels; Computational fluid dynamics; Data visualization; Hemodynamics; Rendering (computer graphics); Anatomical features; Cardio-vascular disease; Cerebral Aneurysms; Computational fluid dynamics simulations; Perceptually based rendering; Rendering; Visual exploration; Visualization technique; Flow visualization",2-s2.0-84913537554
"Hamid D.H.T.A.H., Alias N., Omar A.H.H., Islam M.R., Saipol H.F.S., Palil S.Q.M., Ghani A.C.A., Ramli N.","Web-based service for collaborative authoring learning using grid portal",2014,"Open Source Technology: Concepts, Methodologies, Tools, and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956734055&doi=10.4018%2f978-1-4666-7230-7.ch094&partnerID=40&md5=c83521b9273111fecd8d892602874bc0","The OER is a comparatively innovative phenomenon which perhaps seen as a part of a bigger movement towards openness in advanced education including more familiar and recognized trends, for example Open Access (OA) and Open Source Software (OSS). This study introduces a web based service for collaborative authoring learning to create, share and explore dynamic contents since many problems occurred while using the current e-learning software such as Moodle and LAMS. This paper proposed the alternative e-learning software technology based on grid portal, grid computing platform and it was implemented in two courses. The conventional web based education may not suitable for collaborative tools and online collaborative authoring environment because of slow operation in searching, uploading, visualizing output, and file sharing. The new web based service offers an efficient authoring infrastructure dealing with online collaborative tools and collaborative authoring environment based on grid portal technology to solve the unequal distribution of task and compensation problem as well as investigates how to improve access and usefulness for the users of such OER. UCLA Grid Portal open source software with parallel computing system has been implemented in order to design the efficient authoring infrastructure and to implement an online graphics, animation, audio and video technology courses. The idea is to show how the environment can offer web assisted education that goes beyond providing digital learning materials. The OER, especially in the collaborative authoring activity environment in parallel computing are designed to provide students with new environment where they can share skills, knowledge, and understanding within the group members as well as to enhance students' teamwork skills in parallel and distributed processing for high performance computing. Based on the strong foundations, hopefully the users are ready to apply their knowledge, creativity and leadership to fulfill the need of their future career development. As a conclusion, the collaborative authoring learning becomes more effective in terms of performance evaluations analysis. © 2015, IGI Global. All rights reserved.",,"Computer software; Curricula; Distributed computer systems; Education; Electronic document exchange; Employment; Grid computing; Open source software; Open systems; Portals; Software engineering; Students; Web services; Websites; Collaborative authoring; Compensation problems; Digital learning materials; Grid computing platform; High performance computing; Parallel and distributed processing; Parallel computing system; Web based education; Collaborative tools; E-learning",2-s2.0-84956734055
"Hsu W.H.","Creating open source lecture materials: A guide to trends, technologies, and approaches in the information sciences",2014,"Open Source Technology: Concepts, Methodologies, Tools, and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956740073&doi=10.4018%2f978-1-4666-7230-7.ch020&partnerID=40&md5=34f5fcf8dc13eb0d539550a1f7dd3114","This chapter surveys recent and continuing trends in software tools for preparation of open courseware, in particular audiovisual lecture materials, documentaries and tutorials, and derivative materials. It begins by presenting a catalog of tools ranging from open source wikis and custom content management systems to desktop video production. Next, it reviews techniques for preparation of lecture materials consisting of five specific learning technologies: animation of concepts and problem solutions; explanation of code; video walkthroughs of system documentation; software demonstrations; and creation of materials for instructor preparation and technology transfer. Accompanying the description of each technology and the review of its state of practice is a discussion of the goals and assessment criteria for deployed courseware that uses those tools and techniques. Holistic uses of these technologies are then analyzed via case studies in three domains: artificial intelligence, computer graphics, and enterprise information systems. An exploration of technology transfer to college and university-level instructors in the information sciences then follows. Finally, effective practices for encouraging adoption and dissemination of lecture materials are then surveyed, starting with comprehensive, well-established open courseware projects that adapt pre-existing content and continuing through recent large-scale online courses aimed at audiences of tens to hundreds of thousands. © 2015, IGI Global. All rights reserved.",,"Computer graphics; Curricula; E-learning; Education; Information systems; Open source software; Open systems; Surveys; Teaching; Technology transfer; Assessment criteria; Content management system; Effective practices; Enterprise information system; Problem solutions; Specific learning; State of practice; Tools and techniques; Engineering education",2-s2.0-84956740073
"Caldwell C.","Bringing stories to life... Developing the narrative for games, animation, and VFX: SIGGRAPH Asia 2014 course notes",2014,"SIGGRAPH Asia 2014 Courses, SA 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983649240&doi=10.1145%2f2659467.2659476&partnerID=40&md5=965670cb0a3d92cb494176f3c2047281","This course has been designed for programmers, game designers, technical directors, modelers, and animators whose work is essential in making ""the story"" come to life. This information can be particularly useful when communicating with game designers, directors, writers, and producers. This course answers the question ""how are stories developed?"" (and you don't even have to take a course in screenwriting). Engaging with numerous clips to show how this has been used in games, animation, and VFX.",,"Curricula; Interactive computer graphics; Software design; Game designers; Animation",2-s2.0-84983649240
"Salvaneschi G., Amann S., Proksch S., Mezini M.","An empirical study on program comprehension with reactive programming",2014,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986917965&doi=10.1145%2f2635868.2635895&partnerID=40&md5=1fd215fd1cedc64532601efc5e592077","Starting from the first investigations with strictly functional languages, reactive programming has been proposed as THE programming paradigm for reactive applications. The advantages of designs based on this style over designs based on the Observer design pattern have been studied for a long time. Over the years, researchers have enriched reactive languages with more powerful abstractions, embedded these abstractions into mainstream languages - including object-oriented languages - and applied reactive programming to several domains, like GUIs, animations, Web applications, robotics, and sensor networks. However, an important assumption behind this line of research - that, beside other advantages, reactive programming makes a wide class of otherwise cumbersome applications more comprehensible - has never been evaluated. In this paper, we present the design and the results of the first empirical study that evaluates the effect of reactive programming on comprehensibility compared to the traditional object-oriented style with the Observer design pattern. Results confirm the conjecture that comprehensibility is enhanced by reactive programming. In the experiment, the reactive programming group significantly outperforms the other group. Copyright 2014 ACM.","Controlled experiment; Empirical study; Reactive programming","Abstracting; Computer systems programming; Design; Functional programming; Robot programming; Sensor networks; Software engineering; Controlled experiment; Empirical studies; Functional languages; Observer design patterns; Program comprehension; Programming paradigms; Reactive languages; Reactive programming; Object oriented programming",2-s2.0-84986917965
"Sadoughi N., Liu Y., Busso C.","Speech-driven animation constrained by appropriate discourse functions",2014,"ICMI 2014 - Proceedings of the 2014 International Conference on Multimodal Interaction",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947243490&doi=10.1145%2f2663204.2663252&partnerID=40&md5=8394a7aef1d6257662c55c34e17be723","Conversational agents provide powerful opportunities to interact and engage with the users. The challenge is how to create naturalistic behaviors that replicate the complex gestures observed during human interactions. Previous studies have used rule-based frameworks or data-driven models to generate appropriate gestures, which are properly synchronized with the underlying discourse functions. Among these methods, speech-driven approaches are especially appealing given the rich information conveyed on speech. It captures emotional cues and prosodic patterns that are important to synthesize behaviors (i.e., modeling the variability and complexity of the timings of the behaviors). The main limitation of these models is that they fail to capture the underlying semantic and discourse functions of the message (e.g., nodding). This study proposes a speech-driven framework that explicitly model discourse functions, bridging the gap between speech-driven and rule-based models. The approach is based on dynamic Bayesian Network (DBN), where an additional node is introduced to constrain the models by specific discourse functions. We implement the approach by synthesizing head and eyebrow motion. We conduct perceptual evaluations to compare the animations generated using the constrained and unconstrained models. Copyright 2014 ACM.","Conversational agent; Discourse function; Dynamic Bayesian network; Eyebrow movement; Head motion","Bayesian networks; Complex networks; Interactive computer systems; Semantics; Conversational agents; Data-driven model; Dynamic Bayesian networks; Eyebrow movement; Head motion; Human interactions; Perceptual evaluation; Rule-based models; Speech",2-s2.0-84947243490
"Pejsa T.","Authoring communicative behaviors for situated, embodied characters",2014,"ICMI 2014 - Proceedings of the 2014 International Conference on Multimodal Interaction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947222395&doi=10.1145%2f2663204.2667576&partnerID=40&md5=d8a7b9124030444593afa48494451177","Embodied conversational agents hold great potential as multimodal interfaces due to their ability to communicate naturally using speech and nonverbal cues. The goal of my research is to enable animators and designers to endow ECAs with interactive behaviors that are controllable, communicatively effective, as well as natural and aesthetically appealing; I focus in particular on spatially situated, communicative nonverbal behaviors such as gaze and deictic gestures. This goal requires addressing challenges in the space of animation authoring and editing, parametric control, behavior coordination and planning, and retargeting to different embodiment designs. My research will aim to provide animators and designers with techniques and tools needed to author natural, expressive, and controllable gaze and gesture movements that leverage empirical or learned models of human behavior, to apply such behaviors to characters with different designs and communicative styles, and to develop techniques and models for planning of coordinated behaviors that economically and correctly convey the range of diverse cues required for multimodal, user-machine interaction. Copyright 2014 ACM.","Animation; Behavior coordination; Behavior planning; Embodied conversational agents; Gaze; Gestures; Multimodal interfaces; Nonverbal communication; Situated interaction","Animation; Design; Human computer interaction; Interactive computer systems; User interfaces; Behavior coordination; Behavior planning; Embodied conversational agent; Gaze; Gestures; Multi-modal interfaces; Non-verbal communications; Situated interactions; Behavioral research",2-s2.0-84947222395
"Zhu Z., Branzoi V., Wolverton M., Murray G., Vitovitch N., Yarnall L., Acharya G., Samarasekera S., Kumar R.","AR-mentor: Augmented reality based mentoring system",2014,"ISMAR 2014 - IEEE International Symposium on Mixed and Augmented Reality - Science and Technology 2014, Proceedings",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945136387&doi=10.1109%2fISMAR.2014.6948404&partnerID=40&md5=4c6420b1287b27d198467e972c2ffc30","AR-Mentor is a wearable real time Augmented Reality (AR) mentoring system that is configured to assist in maintenance and repair tasks of complex machinery, such as vehicles, appliances, and industrial machinery. The system combines a wearable Optical-See-Through (OST) display device with high precision 6-Degree-Of-Freedom (DOF) pose tracking and a virtual personal assistant (VPA) with natural language, verbal conversational interaction, providing guidance to the user in the form of visual, audio and locational cues. The system is designed to be heads-up and hands-free allowing the user to freely move about the maintenance or training environment and receive globally aligned and context aware visual and audio instructions (animations, symbolic icons, text, multimedia content, speech). The user can interact with the system, ask questions and get clarifications and specific guidance for the task at hand. A pilot application with AR-Mentor was successfully built to instruct a novice to perform an advanced 33-step maintenance task on a training vehicle. The initial live training tests demonstrate that AR-Mentor is able to help and serve as an assistant to an instructor, freeing him/her to cover more students and to focus on higher-order teaching. © 2014 IEEE.","Mentoring System; Optical See Through Glasses; Virtual Personal Assistant; Wearable Technology","Augmented reality; Display devices; Machinery; Maintenance; Repair; Visual languages; Wearable computers; Conversational interaction; Industrial machinery; Mentoring System; Multimedia contents; Natural languages; Optical see-through; Personal assistants; Pilot applications; Wearable technology",2-s2.0-84945136387
"Kijsipongse E., Assawamekin N.","Improving the communication performance of distributed animation rendering using BitTorrent file system",2014,"Journal of Systems and Software",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908154450&doi=10.1016%2fj.jss.2014.07.050&partnerID=40&md5=8581c01ef51ef3af1defb3f839cfc9bd","Rendering is a crucial process in the production of computer generated animation movies. It executes a computer program to transform 3D models into series of still images, which will eventually be sequenced into a movie. Due to the size and complexity of 3D models, rendering process becomes a tedious, time-consuming and unproductive task on a single machine. Accordingly, animation rendering is commonly carried out in a distributed computing environment where numerous computers execute in parallel to speedup the rendering process. In accordance with distribution of computing, data dissemination to all computers also needs certain mechanisms which allow large 3D models to be efficiently moved to those distributed computers to ensure the reduction of time and cost in animation production. This paper presents and evaluates BitTorrent file system (BTFS) for improving the communication performance of distributed animation rendering. The BTFS provides an efficient, secure and transparent distributed file system which decouples the applications from complicated communication mechanism. By having data disseminated in a peer-to-peer manner and using local cache, rendering time can be reduced. Its performance comparison with a production-grade 3D animation favorably shows that the BTFS outperforms traditional distributed file systems by more than 3 times in our test configuration. © 2014 Elsevier Inc. All rights reserved.","Animation rendering; Distributed file system; Peer-to-peer","Animation; Distributed computer systems; File organization; Peer to peer networks; Three dimensional computer graphics; Communication mechanisms; Communication performance; Computer-generated animations; Distributed computing environment; Distributed file systems; Peer to peer; Performance comparison; Test configurations; Rendering (computer graphics)",2-s2.0-84908154450
"Jenny H., Liem J., Lucash M.S., Scheller R.M.","4-D statistical surface method for visual change detection in forest ecosystem simulation time series",2014,"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921026102&doi=10.1109%2fJSTARS.2014.2324972&partnerID=40&md5=0b9c59565dc4cf3570703b368953a406","Rising uncertainties associated with climate change compel forest management planning to include forest ecosystem simulations. The output of such models is often of high spatio-temporal complexity and difficult to interpret for the user. This contribution describes a novel visualization method called four-dimensional (4-D) statistical surfaces, which aims at improving the visual detection of change in time series. The method visualizes attribute values as surfaces, which are interpolated and animated over time; the interactive attribute surfaces are combined with color-coding and contour lines to support absolute and relative height judgment as well as faster perception and better location of change. A design study and prototypical implementation of the visualization method is described in this contribution. Time-series simulation results of LANDIS-II, a commonly used modeling tool in forest ecology, as well as a temporal vegetation index dataset (NDVI) are visualized using 4-D statistical surfaces. Usability challenges are addressed based on explorative interviews with a small group of users. The method is not limited to ecological model output; it can be used to create three-dimensional (3-D) temporal animations of arbitrary time-series datasets where parameters are supplied in regular raster format. © 2008-2012 IEEE.","Forestry; simulation software; time-series animation; visualization","Animation; Climate change; Computer software; Ecology; Flow visualization; Forestry; Time series; Visualization; Forest management planning; Novel visualizations; Prototypical implementation; Simulation software; Spatio-temporal complexity; Threedimensional (3-d); Time-series simulation; Visualization method; Ecosystems; data set; detection method; forest ecosystem; NDVI; simulation; software; three-dimensional modeling; time series; visualization; Computer Programs; Ecosystems; Forests; Seasonal Variation; Time Series Analysis",2-s2.0-84921026102
"Wu T., Hung A., Mithraratne K.","Generating facial expressions using an anatomically accurate biomechanical model",2014,"IEEE Transactions on Visualization and Computer Graphics",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907562407&doi=10.1109%2fTVCG.2014.2339835&partnerID=40&md5=ac16f70e876db9777a59100aa4717717","This paper presents a computational framework for modelling the biomechanics of human facial expressions. A detailed high-order (Cubic-Hermite) finite element model of the human head was constructed using anatomical data segmented from magnetic resonance images. The model includes a superficial soft-tissue continuum consisting of skin, the subcutaneous layer and the superficial Musculo-Aponeurotic system. Embedded within this continuum mesh, are 20 pairs of facial muscles which drive facial expressions. These muscles were treated as transversely-isotropic and their anatomical geometries and fibre orientations were accurately depicted. In order to capture the relative composition of muscles and fat, material heterogeneity was also introduced into the model. Complex contact interactions between the lips, eyelids, and between superficial soft tissue continuum and deep rigid skeletal bones were also computed. In addition, this paper investigates the impact of incorporating material heterogeneity and contact interactions, which are often neglected in similar studies. Four facial expressions were simulated using the developed model and the results were compared with surface data obtained from a 3D structured-light scanner. Predicted expressions showed good agreement with the experimental data. © 1995-2012 IEEE.","anatomical facial geometry; Facial animation; finite deformation elasticity; muscle-driven model","Bio-mechanical models; Facial animation; Facial Expressions; Facial geometry; Finite deformation elasticity; anatomy and histology; biological model; computer simulation; face; facial expression; functions of the skin and its appendages; human; physiology; procedures; reproducibility; sensitivity and specificity; skeletal muscle; skin; three dimensional imaging; Computer Simulation; Face; Facial Expression; Humans; Imaging, Three-Dimensional; Models, Biological; Muscle, Skeletal; Reproducibility of Results; Sensitivity and Specificity; Skin; Skin Physiological Phenomena",2-s2.0-84907562407
"Qin H., Hong X., Xiao B., Zhang S., Wang G.","Blue noise sampling method based on mixture distance",2014,"Journal of Electronic Imaging",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920668038&doi=10.1117%2f1.JEI.23.6.063015&partnerID=40&md5=e2705b3d7a7b06bac9b0bcff6941fba3","Blue noise sampling is a core component for a large number of computer graphic applications such as imaging, modeling, animation, and rendering. However, most existing methods are concentrated on preserving spatial domain properties like density and anisotropy, while ignoring feature preserving. In order to solve the problem, we present a new distance metric called mixture distance for blue noise sampling, which is a combination of geodesic and feature distances. Based on mixture distance, the blue noise property and features can be preserved by controlling the ratio of the geodesic distance to the feature distance. With the intention of meeting different requirements from various applications, an adaptive adjustment for parameters is also proposed to achieve a balance between the preservation of features and spatial properties. Finally, implementation on a graphic processing unit is introduced to improve the efficiency of computation. The efficacy of the method is demonstrated by the results of image stippling, surface sampling, and remeshing. © 2014 SPIE and IS&T.","Blue noise; Dart throwing; Lloyd relaxation; Mixture distance; Remeshing; Sampling","Animation; Geodesy; Sampling; Adaptive adjustment; Blue noise; Dart throwing; Feature preserving; Graphic applications; Graphic processing units; Lloyd relaxation; Remeshing; Mixtures",2-s2.0-84920668038
"Cui J., Ma Z., Popescu V.","Animated depth images for interactive remote visualization of time-varying data sets",2014,"IEEE Transactions on Visualization and Computer Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907507453&doi=10.1109%2fTVCG.2013.259&partnerID=40&md5=ebe347cfa686603cd774b4f5ea81ef51","Remote visualization has become both a necessity, as data set sizes have grown faster than computer network performance, and an opportunity, as laptop, tablet, and smartphone mobile computing platforms have become ubiquitous. However, the conventional remote visualization (CRV) approach of sending a new image from the server to the client for every view parameter change suffers from reduced interactivity. One problem is high latency, as the network has to be traversed twice, once to communicate the view parameters to the server and once to transmit the new image to the client. A second problem is reduced image quality due to aggressive compression or low resolution. We address these problems by constructing and transmitting enhanced images that are sufficient for quality output frame reconstruction at the client for a range of view parameter values. The client reconstructs thousands of frames locally, without any additional data from the server, which avoids latency and aggressive compression. We introduce animated depth images, which not only store a color and depth sample at every pixel, but also store the trajectory of the samples for a given time interval. Sample trajectories are stored compactly by partitioning the image into semi-rigid sample clusters and by storing one sequence of rigid body transformations per cluster. Animated depth images leverage sample trajectory coherence to achieve a good compression of animation data, with a small and user-controllable approximation error. We demonstrate animated depth images in the context of finite element analysis and SPH data sets. © 1995-2012 IEEE.","animation data compression; bounded error; Remote visualization; rigid-body decomposition; time-varying data sets","Bounded errors; Depth image; Remote visualization; Rigid body; Time-varying data sets",2-s2.0-84907507453
"Taylor R.M., Harter J.","Random per-element luminance modulation for improved visual tracking",2014,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909642650&doi=10.1109%2fMCG.2014.116&partnerID=40&md5=92dddc210d05085a69847e0a33cb1e52","Using random per-element luminance modulation can increase the visual salience of details in a range of visualizations (2D, 3D, and ND scalar, vector, and tensor fields). Although random luminance has been used in specific designs, its wide applicability isn't reflected in visualizations, perhaps because it hasn't yet been presented as a cross-cutting technique. Adding random-luminance contrast can benefit both static and animated visualizations. The article presents perceptual reasons for this technique's effectiveness. This article has two accompanying videos, at http://youtu.be/TTaSFMvBgvg and http://youtu.be/Rx1oPMTpPA4, showing animations of cones moving through a weather simulation, with and without random luminance modulation. © 2014 IEEE.","computer graphics; graphics; line-integral convolution; luminance modulation; parallel coordinates; random; streamlines; vector visualization","graphics; Line integral convolution; Parallel coordinates; random; streamlines; Vector visualization; Computer graphics; human; illumination; physiology; vision; Humans; Lighting; Vision, Ocular",2-s2.0-84909642650
"Waldon S.M., Thompson P.M., Hahn P.J., Taylor R.M.","SketchBio: A scientist's 3D interface for molecular modeling and animation",2014,"BMC Bioinformatics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920768296&doi=10.1186%2f1471-2105-15-334&partnerID=40&md5=28650b99d266a776df586d8f7d5edeb0","Background: Because of the difficulties involved in learning and using 3D modeling and rendering software, many scientists hire programmers or animators to create models and animations. This both slows the discovery process and provides opportunities for miscommunication. Working with multiple collaborators, a tool was developed (based on a set of design goals) to enable them to directly construct models and animations. Results: SketchBio is presented, a tool that incorporates state-of-the-art bimanual interaction and drop shadows to enable rapid construction of molecular structures and animations. It includes three novel features: crystal-by-example, pose-mode physics, and spring-based layout that accelerate operations common in the formation of molecular models. Design decisions and their consequences are presented, including cases where iterative design was required to produce effective approaches. Conclusions: The design decisions, novel features, and inclusion of state-of-the-art techniques enabled SketchBio to meet all of its design goals. These features and decisions can be incorporated into existing and new tools to improve their effectiveness. © 2014 Waldon et al.","Animation; Collision detection; Molecular modelling","Animation; Iterative methods; Molecular modeling; Three dimensional computer graphics; Bi-manual interaction; Collision detection; Construct models; Design decisions; Effective approaches; Modeling and animation; Rapid construction; State-of-the-art techniques; Design; chemical structure; computer program; computer simulation; conformation; human; Computer Simulation; Humans; Models, Molecular; Molecular Conformation; Software",2-s2.0-84920768296
"Garaizar P., Vadillo M.A., López-De-Ipiña D.","Presentation accuracy of the web revisited: Animation methods in the HTML5 era",2014,"PLoS ONE",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907828120&doi=10.1371%2fjournal.pone.0109812&partnerID=40&md5=d8a4378781c772e59d75247b81d6ef93","Using the Web to run behavioural and social experiments quickly and efficiently has become increasingly popular in recent years, but there is some controversy about the suitability of using the Web for these objectives. Several studies have analysed the accuracy and precision of different web technologies in order to determine their limitations. This paper updates the extant evidence about presentation accuracy and precision of the Web and extends the study of the accuracy and precision in the presentation of multimedia stimuli to HTML5-based solutions, which were previously untested. The accuracy and precision in the presentation of visual content in classic web technologies is acceptable for use in online experiments, although some results suggest that these technologies should be used with caution in certain circumstances. Declarative animations based on CSS are the best alternative when animation intervals are above 50 milliseconds. The performance of procedural web technologies based on the HTML5 standard is similar to that of previous web technologies. These technologies are being progressively adopted by the scientific community and have promising futures, which makes their use advisable to utilizing more obsolete technologies. © 2014 Garaizar et al.",,"accuracy; animation; application service provider; Article; computer analysis; computer graphics; computer language; computer program; computer system; data analysis software; information processing; web browser; human; Internet; multimedia; Humans; Internet; Multimedia; Software",2-s2.0-84907828120
"Kim T., Summer R.","Guest editors' Introduction: Special section on the ACM SIGGRAPH/eurographics symposium on Computer Animation (SCA)",2014,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906860154&doi=10.1109%2fTVCG.2014.2321713&partnerID=40&md5=f1e669e22197a7039a94fedf045c8b0f",[No abstract available],,,2-s2.0-84906860154
"Seiler M., Spillmann J., Harders M.","Data-driven simulation of detailed surface deformations for surgery training simulators",2014,"IEEE Transactions on Visualization and Computer Graphics",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906857714&doi=10.1109%2fTVCG.2014.2317192&partnerID=40&md5=a7d221bf974580b799b98bb61a46baa0","Data-driven methods have received increasing attention in recent years in order to meet real-time requirements in computationally intensive tasks. In our current work we examine the application of such approaches in soft-tissue simulation. The core idea is to split deformations into a coarse approximation and a differential part that contains the details. We employ the data-driven stamping approach to enrich a fast simulation surface with details that have been extracted from a set of example deformations obtained in offline computations. In this paper we detail our technique, and suggest further extensions over our previous work. First, we propose an improved method for correlating the current coarse approximation to the examples in the database. The new correlation metric combines Euclidean distances with cosine similarity. It allows for better example discrimination, resulting in a well-conditioned linear system. This also enables us to use a non-negative least squares solver that leads to a better regression and guarantees positive stamp blending weights. Second, we suggest a frequency-space stamp compression scheme that saves memory and, in most instances, is faster, since many operations can be done in the compressed space. Third, cutting is included by employing a physically-inspired influence map that allows for proper handling of material discontinuities that were not present in the original examples. We thoroughly evaluate our method and demonstrate its practical application in a surgical simulator prototype. © 1995-2012 IEEE.","animation; Computer graphics; data-driven; simulation; surgery training","Animation; Blending; Computer graphics; Linear systems; Surgery; Surgical equipment; data-driven; Data-driven simulation; Material discontinuity; Off-line computation; Real time requirement; simulation; Soft-tissue simulations; Surgery training; Deformation; arthroscopy; biological model; computer assisted diagnosis; computer interface; computer simulation; education; human; image enhancement; knee meniscus; pathology; pathophysiology; physiology; procedures; reproducibility; sensitivity and specificity; surgery; teaching; three dimensional imaging; Young modulus; Arthroscopy; Computer Simulation; Computer-Assisted Instruction; Elastic Modulus; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Menisci, Tibial; Models, Biological; Reproducibility of Results; Sensitivity and Specificity; User-Computer Interface",2-s2.0-84906857714
"Agrawal S., Shen S., Panne M.V.D.","Diverse motions and character shapes for simulated skills",2014,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906887051&doi=10.1109%2fTVCG.2014.2314658&partnerID=40&md5=157ac087432a68135daa944ac9b40df5","We present an optimization framework that produces a diverse range of motions for physics-based characters for tasks such as jumps, flips, and walks. This stands in contrast to the more common use of optimization to produce a single optimal motion. The solutions can be optimized to achieve motion diversity or diversity in the proportions of the simulated characters. As input, the method takes a character model, a parameterized controller for a successful motion instance, a set of constraints that should be preserved, and a pairwise distance metric. An offline optimization then produces a highly diverse set of motion styles or, alternatively, motions that are adapted to a diverse range of character shapes. We demonstrate results for a variety of 2D and 3D physics-based motions, showing that the approach can generate compelling new variations of simulated skills. © 1995-2012 IEEE.","diversity optimization; motion control; Physics-based character animation","Computer graphics; Motion control; Character animation; Character modeling; Motion styles; Off-line optimization; Optimal motion; Optimization framework; Pairwise distances; Parameterized; Software engineering",2-s2.0-84906887051
"Zordan V., Brown D., Macchietto A., Yin K.","Control of rotational dynamics for ground and aerial behavior",2014,"IEEE Transactions on Visualization and Computer Graphics",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906847367&doi=10.1109%2fTVCG.2014.2330610&partnerID=40&md5=cb57b6fa62d8da980d0f69f80103715b","This paper proposes a physics-based framework to control rolling, flipping and other behaviors with significant rotational components. The proposed technique is a general approach for guiding coordinated action that can be layered over existing control architectures through the purposeful regulation of specific whole-body features. Namely, we apply control for rotation through the specification and execution of specific desired 'rotation indices' for whole-body orientation, angular velocity and angular momentum control and highlight the use of the angular excursion as a means for whole-body rotation control. We account for the stylistic components of behaviors through reference posture control. The novelty of the described work includes control over behaviors with considerable rotational components, both on the ground and in the air as well as a number of characteristics useful for general control, such as flight planning with inertia modeling, compliant posture tracking, and contact control planning. © 1995-2012 IEEE.","character animation; human behavior; motion capture; Physics-based control; torque control","Computer graphics; Torque control; Character animation; Control architecture; Coordinated actions; Human behaviors; Motion capture; Physics-based; Rotational component; Rotational dynamics; Software engineering",2-s2.0-84906847367
"Guo S., Chang J., Yang X., Wang W., Zhang J.","Locomotion Skills for Insects with Sample-based Controller",2014,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939428078&doi=10.1111%2fcgf.12471&partnerID=40&md5=d1b5da1dd2eac6df62f0e2ea5a8e508e","Natural-looking insect animation is very difficult to simulate. The fast movement and small scale of insects often challenge the standard motion capture techniques. As for the manual key-framing or physics-driven methods, significant amounts of time and efforts are necessary due to the delicate structure of the insect, which prevents practical applications. In this paper, we address this challenge by presenting a two-level control framework to efficiently automate the modeling and authoring of insects' locomotion. On the top level, we design a Triangle Placement Engine to automatically determine the location and orientation of insects' foot contacts, given the user-defined trajectory and settings, including speed, load, path and terrain etc. On the low-level, we relate the Central Pattern Generator to the triangle profiles with the assistance of a Controller Look-Up Table to fast simulate the physically-based movement of insects. With our approach, animators can directly author insects' behavior among a wide range of locomotion repertoire, including walking along a specified path or on an uneven terrain, dynamically adjusting to external perturbations and collectively transporting prey back to the nest. © 2014 The Author(s) Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Table lookup; Central pattern generator; External perturbations; Fast movement; Look up table; Motion capture; Physically based; Two-level control; Uneven terrain; Animation",2-s2.0-84939428078
"Sizarov A., de Bakker B.S., Klein K., Ohlerth S.","Building foundations for transcatheter intervascular anastomoses: 3D anatomy of the great vessels in large experimental animals",2014,"Interactive cardiovascular and thoracic surgery",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943425618&doi=10.1093%2ficvts%2fivu210&partnerID=40&md5=90d21e7d3f1069ccdddd8b450ca9f4a1","OBJECTIVES: To provide comprehensive illustrations of anatomy of the relevant vessels in large experimental animals in an interactive format as preparation for developing an effective and safe transcatheter technique of aortopulmonary and bidirectional cavopulmonary intervascular anastomoses.METHODS: Computed tomographic angiographic studies in two calves and two sheep were used to prepare 3D reconstructions of the aorta, pulmonary arteries, and caval and pulmonary veins. Based on these reconstructions, computer simulations of the creation of stent-enhanced aortopulmonary and bidirectional cavopulmonary anastomoses were made.RESULTS: We observed the following major anatomical features: (i) caudal course of the main pulmonary artery and its branches with the proximal right pulmonary artery located immediately caudal to the aortic arch, and with the central left pulmonary artery lying at a substantial distance from the descending aorta; and (ii) the distal right pulmonary artery is located dorsal to the right atrium and inferior caval vein at a substantial distance from the superior caval vein. Animations showed creation of transcatheter analogues of Waterston's and Potts' aortopulmonary shunts through placement of a covered spool-shaped stent, and the transcatheter creation of bidirectional Glenn's cavopulmonary anastomosis, by placement of a long covered trumpet-shaped stent.CONCLUSIONS: There are considerable differences in vascular anatomy between large experimental animals and humans. Given the need to elaborate new transcatheter techniques for intervascular anastomoses in suitable animal models before application to human, it is crucial to take these anatomical differences into account during testing and optimization of the proposed procedures. © The Author 2014. Published by Oxford University Press on behalf of the European Association for Cardio-Thoracic Surgery. All rights reserved.","Aortopulmonary shunt; Cavopulmonary anastomosis; Experimental animals; Stent; Vascular anatomy","age; animal; animal model; aortography; audiovisual equipment; biological model; bovine; computer assisted diagnosis; computer assisted tomography; computer simulation; devices; Fontan procedure; heart catheterization; inferior cava vein; newborn; phlebography; predictive value; procedures; prosthesis; pulmonary artery; pulmonary vein; radiography; sheep; species difference; stent; superior cava vein; three dimensional imaging; Age Factors; Animals; Animals, Newborn; Aortography; Cardiac Catheterization; Cattle; Computer Simulation; Fontan Procedure; Imaging, Three-Dimensional; Models, Anatomic; Models, Animal; Models, Cardiovascular; Phlebography; Predictive Value of Tests; Prosthesis Design; Pulmonary Artery; Pulmonary Veins; Radiographic Image Interpretation, Computer-Assisted; Sheep; Species Specificity; Stents; Tomography, X-Ray Computed; Vena Cava, Inferior; Vena Cava, Superior",2-s2.0-84943425618
"Eom H., Choi B., Noh J.","Data-Driven Reconstruction of Human Locomotion Using a Single Smartphone",2014,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939446525&doi=10.1111%2fcgf.12469&partnerID=40&md5=8fe0883fab98be2057b52dc0e3adeeca","Generating a visually appealing human motion sequence using low-dimensional control signals is a major line of study in the motion research area in computer graphics. We propose a novel approach that allows us to reconstruct full body human locomotion using a single inertial sensing device, a smartphone. Smartphones are among the most widely used devices and incorporate inertial sensors such as an accelerometer and a gyroscope. To find a mapping between a full body pose and smartphone sensor data, we perform low dimensional embedding of full body motion capture data, based on a Gaussian Process Latent Variable Model. Our system ensures temporal coherence between the reconstructed poses by using a state decomposition model for automatic phase segmentation. Finally, application of the proposed nonlinear regression algorithm finds a proper mapping between the latent space and the sensor data. Our framework effectively reconstructs plausible 3D locomotion sequences. We compare the generated animation to ground truth data obtained using a commercial motion capture system. © 2014 The Author(s) Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Computer graphics; Mapping; Principal component analysis; Signal encoding; Decomposition model; Gaussian Processes; Human locomotions; Latent variable modeling; Low dimensional embedding; Motion capture system; Non-linear regression; Temporal coherence; Smartphones",2-s2.0-84939446525
"Tejedor L.C., Méndez J.A.J., Palomera P.R.","Development of audiovisual material for teaching in medicine",2014,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014863240&doi=10.1145%2f2669711.2669877&partnerID=40&md5=ec236d3453ad99fc94674fadf0c741db","In this study we present the development of a self-created audiovisual material through the use of commercial software like Autodesk Maya (special effects and animation program in three dimensions); Adobe Flash Player (allows multimedia file reproduction); Adobe Photoshop (image editing tool used primarily for photograph manipulation and treatment); Sony Vegas Movie Studio (used for final editing of the teaching video); Audacity (used for sound material debugging, reduction and cleaning of noise as well as unnecessary parts). As an example, we describe the consequences produced by a blood vessel endothelial dysfunction in a video. Our objective with this material is the assimilation of clinical knowledge quickly and effectively, encouraging active learning. The satisfaction survey revealed an excellent acceptance by students who highlighted the quality content and length of the audiovisual teaching material presented. There is no doubt that the use of audiovisual material in university teaching, in addition to theoretical and practical classes, entails a new teaching style that promotes the teaching and learning process.","Audiovisual material; Medical training; Software; Video classes","Blood vessels; Computer software; Ecology; Ecosystems; Multimedia systems; Program debugging; Audio-visual material; Commercial software; Endothelial dysfunction; Image editing tools; Medical training; Teaching and learning; University teaching; Video classes; Medical education",2-s2.0-85014863240
"Liktor G., Pan M., Dachsbacher C.","Fractional Reyes-Style Adaptive Tessellation for Continuous Level of Detail",2014,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939435315&doi=10.1111%2fcgf.12487&partnerID=40&md5=ccbdd89efc76b3e385863999e9dd0cbe","In this paper we present a fractional parametric splitting scheme for Reyes-style adaptive tessellation. Our parallel algorithm generates crack-free tessellation from a parametric surface, which is also free of sudden temporal changes under animation. Continuous level of detail is not addressed by existing Reyes-style methods, since these aim to produce subpixel-sized micropolygons, where topology changes are no longer noticeable. Using our method, rendering pipelines that use larger triangles, thus sensitive to geometric popping, may also benefit from the quality of the split-dice tessellation stages of Reyes. We demonstrate results on a real-time GPU implementation, going beyond the limited quality and resolution of the hardware tessellation unit. In contrast to previous split-dice methods, our split stage is compatible with the fractional hardware tessellation scheme that has been designed for continuous level of detail. © 2014 The Author(s) Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Algorithms; Adaptive tessellations; Continuous level of detail; GPU implementation; Parametric surfaces; Rendering pipelines; Sub pixels; Temporal change; Topology changes; Hardware",2-s2.0-84939435315
"Estrada M.A.R.","Economic waves: The effect of the U.S. economy on the world economy",2014,"Contemporary Economics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907697430&doi=10.5709%2fce.1897-9254.143&partnerID=40&md5=ac5942937e311a3aa16381bfd2918a17","This paper models the inter-connections between the U.S. economy and five major economic regions in the world, namely, Japan, China, ASEAN, Latin America, and the European Union, using an inter-linkage coordinate space. This space is represented graphically, with the U.S. economy placed in the center and the connected economic regions plotted along rays (axes) that are drawn from the center, each of which can have as many windows as are required at the predetermined perimeter levels. Using this model, this paper evaluates whether and how an economic recession or financial crisis in the U.S. economy can simultaneously affect the five aforementioned economic regions. Finally, this paper proposes the use of computer graphical animation to provide a visual representation of the concomitant effect of these economic waves in the same graphical space. © 2007 University of Finance and Management in Warsaw & Vizja Press&IT.","Econographicology; Economic teaching; Euclidean geometry",,2-s2.0-84907697430
"Zarka D., Cevallos C., Petieau M., Hoellinger T., Dan B., Cheron G.","Neural rhythmic symphony of human walking observation: Upside-down and uncoordinated condition on cortical theta, Alpha, Beta and gamma oscillations",2014,"Frontiers in Systems Neuroscience",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907297520&doi=10.3389%2ffnsys.2014.00169&partnerID=40&md5=8ee98543cbb23ce7467a65389b4a8da6","Biological motion observation has been recognized to produce dynamic change in sensorimotor activation according to the observed kinematics. Physical plausibility of the spatial-kinematic relationship of human movement may play a major role in the top-down processing of human motion recognition. Here, we investigated the time course of scalp activation during observation of human gait in order to extract and use it on future integrated brain-computer interface using virtual reality (VR). We analyzed event related potentials (ERP), the event related spectral perturbation (ERSP) and the inter-trial coherence (ITC) from high-density EEG recording during video display onset (-200-600 ms) and the steady state visual evoked potentials (SSVEP) inside the video of human walking 3D-animation in three conditions: Normal; Upside-down (inverted images); and Uncoordinated (pseudo-randomly mixed images). We found that early visual evoked response P120 was decreased in Upside-down condition. The N170 and P300b amplitudes were decreased in Uncoordinated condition. In Upside-down and Uncoordinated conditions, we found decreased alpha power and theta phase-locking. As regards gamma oscillation, power was increased during the Upside-down animation and decreased during the Uncoordinated animation. An SSVEP-like response oscillating at about 10 Hz was also described showing that the oscillating pattern is enhanced 300 ms after the heel strike event only in the Normal but not in the Upside-down condition. Our results are consistent with most of previous point-light display studies, further supporting possible use of virtual reality for neurofeedback applications. © 2014 Zarka, Cevallos, Petieau, Hoellinger, Dan and Cheron.","ERP; ERSP; ITC; Observation; SSVEP; Virtual reality; Walking","adult; alpha rhythm; Article; beta rhythm; brain computer interface; electroencephalography; event related potential; evoked visual response; female; gait; gamma oscillation; human; human experiment; kinematics; male; movement perception; neurofeedback; normal human; oscillation; theta rhythm; virtual reality; visual stimulation; walking",2-s2.0-84907297520
"Zamuda A., Brest J.","Vectorized procedural models for animated trees reconstruction using differential evolution",2014,"Information Sciences",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901793000&doi=10.1016%2fj.ins.2014.04.037&partnerID=40&md5=26c51d307cc23ed316aae685620c4eec","This paper presents a vectorized matrix parameters encoding aspect for an evolutionary computer vision approach to procedural tree modeling. A serialized fixed-size floating-point encoded tree parameter set consists of a set of auxiliary local and other global parameters. The main goal of paper is to lower problem dimensionality needed for encoding local parameters. For evolution simulation, differential evolution algorithm is used. The optimizer evolves a parameterized procedural model by fitting a set of its rendered images to a set of automatically preprocessed reference photo images. The reconstructed tree morphology is then used for reconstructed tree animation, to generate similar geometrical tree models based on similar morphology. Examples of reconstructed model animation are shown, such as simulation of its growth, sway in the wind, or adding leaves. © 2014 Elsevier Inc. All rights reserved.","3D procedural model; Differential evolution; Evolutionary computer vision; Morphology reconstruction; Tree modeling","Animation; Encoding (symbols); Evolutionary algorithms; Forestry; Morphology; Optimization; Differential Evolution; Differential evolution algorithms; Global parameters; Morphology reconstruction; Problem dimensionality; Procedural modeling; Procedural models; Tree modeling; Computer simulation; Algorithms; Forestry; Optimization; Simulation",2-s2.0-84901793000
"Luo C., Yu J., Jiang C., Li R., Wang Z.","Real-time control of 3D facial animation",2014,"Proceedings - IEEE International Conference on Multimedia and Expo",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937458636&doi=10.1109%2fICME.2014.6890231&partnerID=40&md5=9898a72152ddeb53488f4bc71bdc620a","Facial animation is useful in human-machine interaction, computer games and teleconferences. We propose a realtime performance-driven facial animation system for ordinary users. The system enables a user to animate an avatar by performing desired facial motions in front of a video camera. First, a constrained local model based approach is used to track facial features of a performer in the video. To increase the tracking accuracy, we propose an efficient method to build a user-specific local texture model. Next, a 3D blendshape face model is fitted to the tracked feature points. To improve the expressiveness of synthesized animations, facial expression recognition results and pre-recorded animation priors are incorporated into the fitting procedure. Finally, facial animations are created using blendshape interpolation. Experiments show that the synthetic facial motions are realistic and quite similar to the facial actions of the performer. By using an ordinary camera, our system provides the user complete control over the generated facial animations. © 2014 IEEE.","blendshape model; face tracking; Facial animation; facial performance","Cameras; Computer games; Face recognition; Human computer interaction; Interactive computer graphics; Real time control; Video cameras; Blendshape; Constrained local models; Face Tracking; Facial animation; Facial expression recognition; facial performance; Human machine interaction; Real time performance; Animation",2-s2.0-84937458636
"MadehKhaksar F., Luo Z., Pronost N., Egges A.","Modeling and simulating virtual anatomical humans",2014,"3D Multiscale Physiological Human",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929551843&doi=10.1007%2f978-1-4471-6275-9_6&partnerID=40&md5=140de32888afc6c512b2f642ffd029d4","Research in human modeling and simulation has been one of the primary areas of research in computer graphics since the early 1970s. It involves creating human life on a computer, digital avatars that move, talk, and behave like humans. The complexity of simulating the human body and its behavior is directly proportional to the complexity of the human body itself, and is compounded by the vast number of movements it is capable of. Research in this area encompasses multi-disciplinary efforts which include: biomechanics; computer animation; posture and motion prediction; anatomical modeling and physiological simulation. In this chapter we present a structured view of over two decades of research on anatomical modeling and simulation of virtual humans. We pay special attention to the modeling of the skeletal structure and the muscles as well as the simulation of their interactions. © 2014 Springer-Verlag London. All rights are reserved.","Anatomical modeling; Biomechanics; Computer animation; Virtual human simulation and actuation","Animation; Biomechanics; Computer graphics; Motion estimation; Anatomical modeling; Computer animation; Human modeling and simulation; Modeling and simulating; Motion prediction; Physiological simulation; Skeletal structures; Virtual humans; Virtual reality",2-s2.0-84929551843
"Schleife A., Draeger E.W., Anisimov V.M., Correa A.A., Kanai Y.","Quantum dynamics simulation of electrons in materials on high-performance computers",2014,"Computing in Science and Engineering",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908090547&doi=10.1109%2fMCSE.2014.55&partnerID=40&md5=36e90522758a4bac74197e503279e8fc","Advancement in high-performance computing allows us to calculate properties of increasingly complex materials with unprecedented accuracy. At the same time, to take full advantage of modern leadership-class supercomputers, the calculations need to scale well on hundreds of thousands of processing cores. We demonstrate such high scalability of our recently developed implementation of Ehrenfest non-adiabatic electron-ion dynamics up to 1 million floating-point processing units on two different leadership-class computing architectures. As a representative example of material properties that derive from quantum dynamics of electrons, we demonstrate the accurate calculation of electronic stopping power, which characterizes the rate of energy transfer from a high-energy particle to electrons in materials. We discuss the specific case of crystalline gold with a hydrogen atom as the high-energy particle, and we illustrate detailed scientific insights that can be obtained from the quantum dynamics simulation at the electronic structure level. Please note that two animation videos of the time evolution for Figure 3 are available as Web extras at http://youtu.be/WxiMZ2DVBbM and http://youtu.be/bAcaxF9ARzM. © 2014 IEEE.","computational materials science; high-performance computing; HPC; quantum electron dynamics; scientific computing","Computational materials science; High-performance computers; High-performance computing; HPC; Quantum dynamics simulation; Quantum electron dynamics; Natural sciences computing",2-s2.0-84908090547
"Sanderson M.J.","Ceiba: Scalable visualization of phylogenies and 2D/3D image collections",2014,"Bioinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907021027&doi=10.1093%2fbioinformatics%2fbtu315&partnerID=40&md5=872c373f419e0d07ece5f3bfdc3e7005","Summary: Phylogenetic trees with hundreds of thousands of leaves are now being inferred from sequence data, posing significant challenges for visualization and exploratory analysis. Image data supplying valuable context for species in trees (and cues for exploring them) are becoming increasingly available in biodiversity databases and elsewhere but have rarely been built into tree visualization software in a scalable way. Ceiba lets the user explore large trees and inspect image collection arrays (sets of 'homologous' images) comprising mixtures of 2D and 3D image objects. Ceiba exploits recent improvements in graphics hardware, OpenGL toolkits and many standard high-performance computer graphics strategies, such as texture compression, level of detail control, culling, animations and image caching. Its tree layouts can be tuned by user-provided phylogenetic definitions of subtrees. The code has been extensively tested on phylogenies of up to 55 000 leaves and images. © The Author 2014. Published by Oxford University Press. All rights reserved.",,"Ceiba; computer graphics; computer interface; computer program; image processing; phylogeny; three dimensional imaging; Computer Graphics; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Phylogeny; Software; User-Computer Interface",2-s2.0-84907021027
"Saltarelli A.J., Roseth C.J., Saltarelli W.A.","Human cadavers Vs. multimedia simulation: A study of student learning in anatomy",2014,"Anatomical sciences education",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027923113&doi=10.1002%2fase.1429&partnerID=40&md5=5d176bff49cd33cb465c522efd10361b","Multimedia and simulation programs are increasingly being used for anatomy instruction, yet it remains unclear how learning with these technologies compares with learning with actual human cadavers. Using a multilevel, quasi-experimental-control design, this study compared the effects of ""Anatomy and Physiology Revealed"" (APR) multimedia learning system with a traditional undergraduate human cadaver laboratory. APR is a model-based multimedia simulation tool that uses high-resolution pictures to construct a prosected cadaver. APR also provides animations showing the function of specific anatomical structures. Results showed that the human cadaver laboratory offered a significant advantage over the multimedia simulation program on cadaver-based measures of identification and explanatory knowledge. These findings reinforce concerns that incorporating multimedia simulation into anatomy instruction requires careful alignment between learning tasks and performance measures. Findings also imply that additional pedagogical strategies are needed to support transfer from simulated to real-world application of anatomical knowledge. © 2014 American Association of Anatomists.","CAI; computer-aided instruction; computers in anatomical education; digital anatomy; gross anatomy education; interactive computer graphics; multimedia; teaching of anatomy","anatomy; biological model; cadaver; comparative study; computer simulation; education; evaluation study; female; human; learning; male; medical education; multimedia; teaching; young adult; Anatomy; Cadaver; Computer Simulation; Computer-Assisted Instruction; Education, Premedical; Educational Measurement; Female; Humans; Learning; Male; Models, Biological; Multimedia; Young Adult",2-s2.0-85027923113
"Im C., Park M.","Development and evaluation of a computerized multimedia approach to educate older adults about safe medication",2014,"Asian Nursing Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027918358&doi=10.1016%2fj.anr.2014.06.001&partnerID=40&md5=9606f6be1c170c09a53371f75c181422","Purpose Interactive multimedia education using computer technology is increasing in the area of health education. The purpose of this study was to examine the effects of interactive multimedia education on community dwelling older adults' self-efficacy and knowledge for medication and level of satisfaction with the education program.Methods A nonequivalent control group pretest and post-test design was used in this study. The multimedia education was designed to enhance safe medication of older adults. Education consisted of seven modules which contained the medication name, usage, side effects, interactions, and storage requirements. Computerized interactive learning activities consisted of multimedia animations and games. A total of 60 older adults from two local senior centers were recruited and assigned to the experimental and control group. Twenty-six participants in experimental group used the interactive multimedia education on laptop computers.Results Participants receiving interactive multimedia education had significantly higher self-efficacy (F = 20.03, p <.001) and knowledge (F = 36.26, p <.001) scores than the control group did at post intervention. The experimental group indicated a high degree of satisfaction with the interactive multimedia education.Conclusion The study results suggest that the interactive multimedia education is an effective teaching method that empowers older adults to facilitate individual learning using computer technology. © 2014, Korean Society of Nursing Science. Published by Elsevier. All rights reserved.","aged; computers; education; medication","aged; Article; computer; controlled study; drug effect; drug interaction; drug safety; drug storage; drug use; education program; female; health education; human; knowledge; learning; major clinical study; male; medical information; multimedia; nonequivalent control group; pretest posttest design; satisfaction; self concept; senior center; side effect; very elderly",2-s2.0-85027918358
"Wong S.-K., Cheng Y.-C.","Continuous self-collision detection for deformable surfaces interacting with solid models",2014,"Computer Graphics Forum",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908510233&doi=10.1111%2fcgf.12284&partnerID=40&md5=e563f93cff60b0d6071e04e08e614855","In this paper, we propose a new continuous self-collision detection (CSCD) method for a deformable surface that interacts with a simple solid model. The method is developed based on the radial-view-based culling method. Our method is suitable for the deformable surface that has large contact region with the solid model. The deformable surface may consist of small round-shaped holes. At the pre-processing stage, the holes of the deformable surface are filled with ghost triangles so as to make the mesh of the deformable surface watertight. An observer primitive (i.e. a point or a line segment) is computed so that it lies inside the solid model. At the runtime stage, the orientations of triangles with respect to the observer primitive are evaluated. The collision status of the deformable surface is then determined. We evaluated our method for several animations including virtual garments. Experimental results show that our method improves the process of CSCD. In this paper, we propose a new Q4 continuous self-collision detection (CSCD) method for a deformable surface that interacts with a simple solid model. The method is developed based on the radial-view-based culling method. Our method is suitable for the deformable surface that has large contact region with the solid model. The deformable surface may consist of small round-shaped holes. At the pre-processing stage, the holes of the deformable surface are filled with ghost triangles so as to make the mesh of the deformable surface watertight. An observer primitive (i.e. a point or a line segment) is computed so that it lies inside the solid model. © 2014 The Authors Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd.","continuous self-collision detection; deformable surfaces; radial-view-based culling","Mesh generation; Object detection; Contact regions; Deformable surfaces; Line segment; Pre-processing; Self-collision detection; Shaped holes; View-based; Virtual garments; Deformation",2-s2.0-84908510233
"Moore E.B., Chamberlain J.M., Parson R., Perkins K.K.","PhET interactive simulations: Transformative tools for teaching chemistry",2014,"Journal of Chemical Education",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906057041&doi=10.1021%2fed4005084&partnerID=40&md5=0ff3d0b775b78bb328a51eb2ee006444","Developing fluency across symbolic-, macroscopic-, and particulate-level representations is central to learning chemistry. Within the chemistry education community, animations and simulations that support multi-representational fluency are considered critical. With advances in the accessibility and sophistication of technology, interactive computer simulations are emerging as uniquely powerful tools to support chemistry learning. In this article, we present examples and resources to support successful implementation of PhET interactive simulations. The PhET Interactive Simulations project at the University of Colorado Boulder has developed over 30 interactive simulations for teaching and learning chemistry. PhET simulations provide dynamic access to multiple representations, make the invisible visible, scaffold inquiry, and allow for safe and quick access to multiple trials, while being engaging and fun for students and teachers. The simulations are readily accessible online, and are designed to be flexible tools to support a wide-range of implementation styles and teaching environments. Here, we introduce the PhET project, including the project's goals and design principles. We then highlight two simulations for chemistry, Molecule Polarity and Beer's Law Lab. Finally, we share examples (with resources) of the variety of ways PhET simulations can be used to teach chemistry-in lecture, laboratory, and homework. © 2014 The American Chemical Society and Division of Chemical Education, Inc.","Computer-Based Learning; Elementary/Middle School Science; First-Year Undergraduate/General; High School/Introductory Chemistry; Inquiry-Based/Discovery Learning; Internet/Web-Based Learning; Second-Year Undergraduate",,2-s2.0-84906057041
"Kelly R.M.","Using variation theory with metacognitive monitoring to develop insights into how students learn from molecular visualizations",2014,"Journal of Chemical Education",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906069313&doi=10.1021%2fed500182g&partnerID=40&md5=3492a45824707a22b95232fdcaff1b4b","Molecular visualizations have been widely endorsed by many chemical educators as an efficient way to convey the dynamic and atomic-level details of chemistry events. Research indicates that students who use molecular visualizations are able to incorporate most of the intended features of the animations into their explanations. However, studies also suggest that learning from visualizations is imperfect. In this study a new theoretical framework, variation theory, was used to examine learning and understanding based on students' reported experience of variation while viewing visualizations. Student metacognition was examined to gain insight into how students recognized variation between their mental models and the visualization models. Results from this study provide visual evidence of a transitional state of understanding in which students' previous conceptions merge with new conceptions learned from the visualizations. However, limitations in students' ability to monitor their understanding made unpacking what students understood challenging, as students tend to communicate only what they believe to be the most essential details. © 2014 The American Chemical Society and Division of Chemical Education, Inc.","Chemical Education Research; Computer-Based Learning; High School/Introductory Chemistry; Misconceptions/Discrepant Events; Qualitative Analysis",,2-s2.0-84906069313
"Akpınar E.","The use of interactive computer animations based on POE as a presentation tool in primary science teaching",2014,"Journal of Science Education and Technology",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890374435&doi=10.1007%2fs10956-013-9482-4&partnerID=40&md5=5e8c5f1feeeee04a0d4b423cf59c9258","This study investigates the effects of using interactive computer animations based on predict–observe–explain (POE) as a presentation tool on primary school students’ understanding of the static electricity concepts. A quasi-experimental pre-test/post-test control group design was utilized in this study. The experiment group consisted of 30 students, and the control group of 27 students. The control group received normal instruction in which the teacher provided instruction by means of lecture, discussion and homework. Whereas in the experiment group, dynamic and interactive animations based on POE were used as a presentation tool. Data collection tools used in the study were static electricity concept test and open-ended questions. The static electricity concept test was used as pre-test before the implementation, as post-test at the end of the implementation and as delay test approximately 6 weeks after the implementation. Open-ended questions were used at the end of the implementation and approximately 6 weeks after the implementation. Results indicated that the interactive animations used as presentation tools were more effective on the students’ understanding of static electricity concepts compared to normal instruction. © 2013, Springer Science+Business Media New York.","Interactive animation; Predict–observe–explain; Science teaching; Static electricity",,2-s2.0-84890374435
"Cooper M.L., Shaffer C.A., Edwards S.H., Ponce S.P.","Open source software and the algorithm visualization community",2014,"Science of Computer Programming",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899094159&doi=10.1016%2fj.scico.2013.12.008&partnerID=40&md5=03a67530b4953cf74d895212b932faf9","Algorithm visualizations are widely viewed as having the potential for major impact on computer science education, but their quality is highly variable. We report on the software development practices used by creators of algorithm visualizations, based on data that can be inferred from a catalog of over 600 algorithm visualizations. Since nearly all are free for use and many provide source code, they might be construed as being open source software. Yet many AV developers do not appear to have used open source best practices. We discuss how such development practices might be employed by the algorithm visualization community, and how they might lead to improved algorithm visualizations in the future. We conclude with a discussion of OpenDSA, an open-source project that builds on earlier progress in the field of algorithm visualization and hopes to use open-source procedures to gain users and contributors. © 2014 Elsevier B.V.","Algorithm animation; Open source licensing; Open source tools; Project hosting; Version control","Animation; Computer software; Software design; Algorithm animation; Open source tools; Open sources; Project hosting; Version control; Computer aided instruction",2-s2.0-84899094159
"Blinowski G., Kamiński M., Wawer D.","Trans3D: A free tool for dynamical visualization of EEG activity transmission in the brain",2014,"Computers in Biology and Medicine",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902958937&doi=10.1016%2fj.compbiomed.2014.05.006&partnerID=40&md5=f09b3abbc4bac83a85e2d5fc98ea9641","The problem of functional connectivity in the brain is in the focus of attention nowadays, since it is crucial for understanding information processing in the brain. A large repertoire of measures of connectivity have been devised, some of them being capable of estimating time-varying directed connectivity. Hence, there is a need for a dedicated software tool for visualizing the propagation of electrical activity in the brain. To this aim, the Trans3D application was developed. It is an open access tool based on widely available libraries and supporting both Windows XP/Vista/7™, Linux and Mac environments. Trans3D can create animations of activity propagation between electrodes/sensors, which can be placed by the user on the scalp/cortex of a 3D model of the head. Various interactive graphic functions for manipulating and visualizing components of the 3D model and input data are available. An application of the Trans3D tool has helped to elucidate the dynamics of the phenomena of information processing in motor and cognitive tasks, which otherwise would have been very difficult to observe. Trans3D is available at: http://www.eeg.pl/. © 2014 Elsevier Ltd.","3D visualization; Directed transfer function; Effective connectivity; Transmission between brain structures; Visualization software","Computer operating systems; Data processing; Linux; Three dimensional computer graphics; Visualization; 3D Visualization; Brain structure; Directed transfer functions; Effective connectivities; Visualization software; Brain; article; attention; color; computer program; electrode; electroencephalogram; human; imagination; information processing device; movement (physiology); neurotransmission; primary motor cortex; priority journal; scalp; sensor; supplementary motor area; working memory; brain cortex; brain mapping; electroencephalography; physiology; procedures; three dimensional imaging; Brain Mapping; Cerebral Cortex; Electroencephalography; Humans; Imaging, Three-Dimensional; Software",2-s2.0-84902958937
"Pu X., Liu T., Wu Q., Zhang R., Xu P., Li K., Xia Y., Yao D.","Study on neurofeedback system based on electroencephalogram signals",2014,"Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929511505&partnerID=40&md5=13f69e88f9c10c119023f812b7600eee","Neurofeedback, as an alternative treatment method of behavioral medicine, is a technique which translates the electroencephalogram (EEG) signals to styles as sounds or animation to help people understand their own physical status and learn to enhance or suppress certain EEG signals to regulate their own brain functions after several repeated trainings. This paper develops a neurofeedback system on the foundation of brain-computer interface technique. The EEG features are extracted through real-time signal process and then translated to feedback information. Two feedback screens are designed for relaxation training and attention training individually. The veracity and feasibility of the neurofeedback system are validated through system simulation and preliminary experiment.",,"brain computer interface; electroencephalography; female; human; neurofeedback; Brain-Computer Interfaces; Electroencephalography; Female; Humans; Neurofeedback",2-s2.0-84929511505
"Yilmazyildiz S., Verhelst W., Sahli H.","Gibberish speech as a tool for the study of affective expressiveness for robotic agents",2014,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945439878&doi=10.1007%2fs11042-014-2165-1&partnerID=40&md5=d3b7e5b1104892dd38d35946432beace","Recent technological advancements bring virtual agents, avatars, and social robotic characters into our daily lives. These characters must acquire the ability to express (simulated) emotions vocally and gesturally. In the vocal channel, Natural Language Interaction technologies today have some limitations when used in real-world natural environments and the models of expressivity of text to speech synthesis engines are not yet mature enough. To address these limitations, an alternative form of vocal communication - gibberish speech - is introduced in this paper. Gibberish speech consists of vocalizations of meaningless strings of speech sounds, and thus has no semantic meaning. It is occasionally used by performing artists or for cartoon animations and games to express intended emotions (e.g. Teletubbies and The Sims). In this paper, our approach for constructing expressive gibberish speech is described and the experimental evaluations with its intended robotic agents are reported. It is shown that the generated gibberish speech can contribute to a significant extent to studies concerning emotion expression for robotic agents and can be further utilized in affective human-robot interaction studies. © 2014, Springer Science+Business Media New York.","Expressive gibberish speech; Expressive speech; Human robot interaction; Speech without semantic information; Vocal emotion expression; Voice modification","Animation; Human computer interaction; Man machine systems; Robotics; Robots; Semantics; Speech; Speech communication; Speech synthesis; Cartoon animation; Emotion expression; Experimental evaluation; Expressive speech; Natural environments; Natural language interaction; Semantic information; Technological advancement; Human robot interaction",2-s2.0-84945439878
"Yigit T., Koyun A., Yuksel A.S., Cankaya I.A., Kose U.","An example application of an artificial intelligence-supported blended learning education program in computer engineering",2014,"Artificial Intelligence Applications in Distance Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949599416&doi=10.4018%2f978-1-4666-6276-6.ch012&partnerID=40&md5=06f05bb8f5c238c8e929475d8db3eba2","Blended Learning is a learning model that is enriched with traditional learning methods and online education materials. Integration of face-to-face and online learning with blending learning can enhance the learning experience and optimize seat time. In this chapter, the authors present the teaching of an Algorithm and Programming course in Computer Engineering Education via an artificial intelligencesupported blended learning approach. Since 2011, Computer Engineering education in Suleyman Demirel University Computer Engineering Department is taught with a blended learning method. Blended learning is achieved through a Learning Management System (LMS) by using distance education technology. The LMS is comprised of course materials supported with flash animations, student records, user roles, and evaluation systems such as surveys and quizzes that meet SCORM standards. In this chapter, the related education process has been supported with an intelligent program, which is based on teaching C programming language. In this way, it has been aimed to improve educational processes within the related course and the education approach in the department. The blended learning approach has been evaluated by the authors, and the obtained results show that the introduced artificial intelligencesupported blended learning education program enables both teachers and students to experience better educational processes. © 2015 by IGI Global. All rights reserved.",,"Application programs; Blending; C (programming language); Computer programming; Distance education; E-learning; Education computing; Engineering education; Learning systems; Students; Teaching; Computer engineering; Computer engineering education; Education technology; Educational process; Intelligent programs; Learning experiences; Learning management system; Traditional learning; Education",2-s2.0-84949599416
"Ding C., Xie L., Zhu P.","Head motion synthesis from speech using deep neural networks",2014,"Multimedia Tools and Applications",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945435061&doi=10.1007%2fs11042-014-2156-2&partnerID=40&md5=38e7353812c821c31779c5e6fbd916d8","This paper presents a deep neural network (DNN) approach for head motion synthesis, which can automatically predict head movement of a speaker from his/her speech. Specifically, we realize speech-to-head-motion mapping by learning a DNN from audio-visual broadcast news data. We first show that a generatively pre-trained neural network significantly outperforms a conventional randomly initialized network. We then demonstrate that filter bank (FBank) features outperform mel frequency cepstral coefficients (MFCC) and linear prediction coefficients (LPC) in head motion prediction. Finally, we discover that extra training data from other speakers used in the pre-training stage can improve the head motion prediction performance of a target speaker. Our promising results in speech-to-head-motion prediction can be used in talking avatar animation. © 2014, Springer Science+Business Media New York.","Computer animation; Deep neural network; Head motion synthesis; Talking avatar","Animation; Filter banks; Speech recognition; Synthesis (chemical); Broadcast news; Computer animation; Deep neural networks; Head motion synthesis; Linear prediction coefficients; Mel-frequency cepstral coefficients; Talking avatar; Trained neural networks; Forecasting",2-s2.0-84945435061
[No author name available],"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984868918&partnerID=40&md5=493a8554af2bfa60fba7781148259322","The proceedings contain 20 papers. The topics discussed include: coupling 3D Eulerian, heightfield and particle methods for interactive simulation of large scale liquid phenomena; ocean waves animation using boundary integral equations and explicit mesh tracking; position-based elastic rods; optimization integrator for large time steps; stable orthotropic materials; a peridynamic perspective on spring-mass fracture; adaptive tetrahedral meshes for brittle fracture simulation; an adaptive virtual node algorithm with robust mesh cutting; efficient denting and bending of rigid bodies; DenseSense: interactive crowd simulation using density-dependent filters; and holonomic collision avoidance for virtual crowds.",,,2-s2.0-84984868918
"Keeler T., Bridson R.","Ocean waves animation using boundary integral equations and explicit mesh tracking",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984911031&partnerID=40&md5=c04964ff75454fd65832ad6cb352b602","We tackle deep water simulation in a scalable way, solving 3D irrotational flow using only variables stored in a mesh of the surface of the water, in time proportional to the rendered mesh. The heart of our method is a novel boundary integral equation formulation that is amenable to explicit mesh tracking with unstructured triangle meshes. Our method complements FFT style waves as it is able to handle solid boundaries. It is less memory intensive than volumetric methods and inherently handles the near-infinite depth of the deep ocean. We demonstrate acceleration techniques using the FMM and GPU computing. The natural Lagrangian motion of our model gives inherent adaptivity to our simulation without the need for direct mesh operations. © The Eurographics Association 2014.",,"Animation; Computer graphics; Integral equations; Interactive computer graphics; Mesh generation; Water waves; Acceleration technique; Adaptivity; GPU computing; Irrotational flow; Lagrangian motion; Solid boundaries; Triangle mesh; Volumetric methods; Boundary integral equations",2-s2.0-84984911031
"Gao M., Mitchell N., Sifakis E.","Steklov-Poincaré skinning",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984876773&partnerID=40&md5=3a43b59830c497912abc639d71f169eb","We introduce a novel and efficient simulation technique for generating physics-based skinning animations of skeleton-driven characters with full support for collision handling. Although physics-based approaches may use a volumetric (e.g. tetrahedral) flesh model, operations such as rendering, collision processing and user manipulation directly involve only the surface of this mesh. Motivated by this fact we define an elastic model of the skin surface which, while directly using only the surface degrees of freedom, exhibits a mechanical response that captures the full volumetric flesh behavior. We achieve this unusual result by combining three fundamental contributions: First, we present a material model which offers a plausible approximation to corotational elasticity at significantly reduced cost, by computing local rotations via procedural skinning rather than deriving them from the mesh deformation; the result is a force model which is affine on vertex positions, with coefficients dependent on the skeletal pose (but not on the deformation). Second, we use this force model to derive a direct mapping between surface vertex positions and resulting equilibrium forces on the same boundary vertices, which is a discrete version of the Steklov-Poincaré operator of the volumetric elastic model. This mapping is conveniently shown to also be affine (with pose-dependent coefficients), but with a dense stiffness matrix which renders direct numerical solution impractical. However, as a third and final step we show how a modified Newton iteration and a skinning-inspired preconditioner can solve the boundary problem with a competitive runtime cost. We assess the efficacy of our solution in simulations of high resolution human flesh models, with full external and self-collision processing. © The Eurographics Association 2014.",,"Animation; Deformation; Degrees of freedom (mechanics); Interactive computer graphics; Iterative methods; Mapping; Mesh generation; Stiffness matrix; Boundary problems; Boundary vertices; Collision handling; Efficient simulation; Equilibrium forces; Material modeling; Mechanical response; Numerical solution; Computer graphics",2-s2.0-84984876773
"Li Y., Barbič J.","Stable orthotropic materials",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984876995&partnerID=40&md5=923c610926338de786669ddf291552b2","Isotropic Finite Element Method (FEM) deformable object simulations are widely used in computer graphics. Several applications (wood, plants, muscles) require modeling the directional dependence of the material elastic properties in three orthogonal directions. We investigate orthotropic materials, a special class of anisotropic materials where the shear stresses are decoupled from normal stresses. Orthotropic materials generalize transversely isotropic materials, by exhibiting different stiffnesses in three orthogonal directions. Orthotropic materials are, however, parameterized by nine values that are difficult to tune in practice, as poorly adjusted settings easily lead to simulation instabilities. We present a user-friendly approach to setting these parameters that is guaranteed to be stable. Our approach is intuitive as it extends the familiar intuition known from isotropic materials. We demonstrate our technique by augmenting linear corotational FEM implementations with orthotropic materials. © The Eurographics Association 2014.",,"Animation; Computer graphics; Interactive computer graphics; Shear stress; Anisotropic material; Deformable object; Directional dependence; Elastic properties; Isotropic materials; Orthogonal directions; Orthotropic materials; Transversely isotropic materials; Finite element method",2-s2.0-84984876995
"Koschier D., Lipponer S., Bender J.","Adaptive tetrahedral meshes for brittle fracture simulation",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984863729&partnerID=40&md5=faf0c3ce2be9afb2e9e04f6e6ea94c10","We present a method for the adaptive simulation of brittle fracture of solid objects based on a novel reversible tetrahedral mesh refinement scheme. The refinement scheme preserves the quality of the input mesh to a large extent, it is solely based on topological operations, and does not alter the boundary, i.e. any geometric feature. Our fracture algorithm successively performs a stress analysis and increases the resolution of the input mesh in regions of high tensile stress. This results in an accurate location of crack origins without the need of a general high resolution mesh which would cause high computational costs throughout the whole simulation. A crack is initiated when the maximum tensile stress exceeds the material strength. The introduced algorithm then proceeds by iteratively recomputing the changed stress state and creating further cracks. Our approach can generate multiple cracks from a single impact, but effectively avoids shattering artifacts. Once the tensile stress decreases, the mesh refinement is reversed to increase the performance of the simulation. We demonstrate that our adaptive method is robust, scalable and computes highly realistic fracture results. © The Eurographics Association 2014.",,"Animation; Computer graphics; Cracks; Fracture; Fracture mechanics; Interactive computer graphics; Iterative methods; Mesh generation; Stress analysis; Tensile stress; Accurate location; Adaptive simulation; Adaptive tetrahedral mesh; Computational costs; Fracture simulations; Geometric feature; Material strength; Tetrahedral meshes; Brittle fracture",2-s2.0-84984863729
"Wang Y., Jiang C., Schroeder C., Teran J.","An adaptive virtual node algorithm with robust mesh cutting",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984922390&partnerID=40&md5=f136006375f43f31677a6dfa5589629c","We present a novel virtual node algorithm (VNA) for changing tetrahedron mesh topology to represent arbitrary cutting triangulated surfaces. Our approach addresses a number of shortcomings in the original VNA of [MBF04]. First, we generalize the VNA so that cuts can pass through tetrahedron mesh vertices and lie on mesh edges and faces. The original algorithm did not make sense for these cases and required often ambiguous perturbation of the cutting surface to avoid them. Second, we develop an adaptive approach to the definition of embedded material used for element duplication. The original algorithm could only handle a limited number of configurations which restricted cut surfaces to have curvature at the scale of the tetrahedron elements. Our adaptive approach allows for cut surfaces with curvatures independent of the embedding tetrahedron mesh resolution. Finally, we present a novel, provably-robust floating point mesh intersection routine that accurately registers triangulated surface cuts against the background tetrahedron mesh without the need for exact arithmetic. © The Eurographics Association 2014.",,"Algorithms; Animation; Computational mechanics; Digital arithmetic; Geometry; Interactive computer graphics; Mesh generation; Adaptive approach; Exact arithmetic; Floating points; Original algorithms; Restricted cut; Tetrahedron elements; Tetrahedron mesh; Triangulated surfaces; Computer graphics",2-s2.0-84984922390
"Levine J.A., Bargteil A.W., Corsi C., Tessendorf J., Geist R.","A peridynamic perspective on spring-mass fracture",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984893043&partnerID=40&md5=ee370bfeb2bb30f48440eabc3274f0dd","The application of spring-mass systems to the animation of brittle fracture is revisited. The motivation arises from the recent popularity of peridynamics in the computational physics community. Peridynamic systems can be regarded as spring-mass systems with two specific properties. First, spring forces are based on a simple strain metric, thereby decoupling spring stiffness from spring length. Second, masses are connected using a distance-based criterion. The relatively large radius of influence typically leads to a few hundred springs for every mass point. Spring-mass systems with these properties are shown to be simple to implement, trivially parallelized, and well-suited to animating brittle fracture. © The Eurographics Association 2014.",,"Animation; Fracture; Interactive computer graphics; Computational physics; Distance-based; Peridynamics; Radius of influences; Specific properties; Spring mass; Spring stiffness; Spring-mass system; Brittle fracture",2-s2.0-84984893043
"Koh W., Narain R., O'Brien J.F.","View-dependent adaptive cloth simulation",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984914926&partnerID=40&md5=8381b2e0b6901eee1e9fff1926145bae","This paper describes a method for view-dependent cloth simulation using dynamically adaptive mesh refinement and coarsening. Given a prescribed camera motion, the method adjusts the criteria controlling refinement to account for visibility and apparent size in the camera's view. Objectionable dynamic artifacts are avoided by anticipative refinement and smoothed coarsening. This approach preserves the appearance of detailed cloth throughout the animation while avoiding the wasted effort of simulating details that would not be discernible to the viewer. The computational savings realized by this method increase as scene complexity grows, producing a 2× speed-up for a single character and more than 4× for a small group. © The Eurographics Association 2014.",,"Cameras; Interactive computer graphics; Adaptive mesh refinement; Camera motions; Cloth simulation; Computational savings; Scene complexity; Speed up; View-dependent; Animation",2-s2.0-84984914926
"Patkar S., Aanjaneya M., Lee M., Bartle A., Fedkiw R.","Efficient denting and bending of rigid bodies",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984870609&partnerID=40&md5=591c78ee1762be767349f45af18cfa22","We present a novel method for the efficient denting and bending of rigid bodies without the need for expensive finite element simulations. Denting is achieved by deforming the triangulated surface of the target body based on a dent map computed on-the-fly from the projectile body using a Z-buffer algorithm with varying degrees of smoothing. Our method accounts for the angle of impact, is applicable to arbitrary shapes, readily scales to thousands of rigid bodies, is amenable to artist control, and also works well in combination with prescoring algorithms for fracture. Bending is addressed by augmenting a rigid body with an articulated skeleton which is used to drive skinning weights for the bending deformation. The articulated skeleton is simulated to include the effects of both elasticity and plasticity. Furthermore, we allow joints to be added dynamically so that bending can occur in a non-predetermined way and/or as dictated by the artist. Conversely, we present an articulation condensation method that greatly simplifies large unneeded branches and chains on-the-fly for increased efficiency. © The Eurographics Association 2014.",,"Animation; Deformation; Finite element method; Interactive computer graphics; Musculoskeletal system; Rigid structures; Arbitrary shape; Finite element simulations; On the flies; Rigid body; Triangulated surfaces; Z-buffer; Bending (deformation)",2-s2.0-84984870609
"Chentanez N., Müller M., Kim T.-Y.","Coupling 3D Eulerian, heightfield and particle methods for interactive simulation of large scale liquid phenomena",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984920221&partnerID=40&md5=96a4e847bab73df7a77d1d127d4f6d0f","We propose a new method to simulate large scale water phenomena by combining particle, 3D grid and height field methods. In contrast to most hybrid approaches that use particles to simulate foam and spray only, we also represent the bulk of water near the surface with both particles and a grid depending on the regions of interest and switch between those two representations during the course of the simulation. For the coupling we leverage the recent idea of tracking the water surface with a density field in grid based methods. Combining particles and a grid simulation then amounts to adding the density field of the particles and the one stored on the grid. For open scenes, we simulate the water outside of the 3D grid domain by solving the Shallow Water Equations on a height field. We propose new methods to couple these two domains such that waves travel naturally across the border. We demonstrate the effectiveness of our approach in various scenarios including a whale breaching simulation, all running in real-time or at interactive rates. © The Eurographics Association 2014.",,"Equations of motion; Interactive computer graphics; Grid based method; Grid simulations; Hybrid approach; Interactive rates; Interactive simulations; Particle methods; Regions of interest; Shallow water equations; Animation",2-s2.0-84984920221
"Müller M., Chentanez N., Kim T.-Y., Macklin M.","Strain based dynamics",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984918808&partnerID=40&md5=bf1e8188e305db3c76bab7356872d474","We propose a new set of constraints within the Position Based Dynamics (PBD) framework that allow the control of strain in directions that are independent of the edge directions of the simulation mesh. Instead of constraining distances between points, we constrain the entries of the Green -St Venant strain tensor. Varying the stiffness values corresponding to the individual strain coefficients lets us simulate anisotropic behavior. By working with Green's rotation-independent, non-linear strain tensor directly we do not have to perform a polar decomposition of the deformation gradient as in most strain limiting approaches. In addition, we propose a modification of the constraints corresponding to the diagonal entries of the strain tensor such that they can be solved in a single step and a modification of the constraints corresponding to the off-diagonal entries to decouple stretch from shear resistance. By formulating the constraints within the PBD framework, they can be used not only for strain limiting but to perform the actual simulation of the deformable object whereas traditional strain limiting methods have to be paired with a separate simulation method. © The Eurographics Association 2014.",,"Budget control; Deformation; Interactive computer graphics; Tensors; Anisotropic behaviors; Deformable object; Deformation gradients; Nonlinear strain; Polar decompositions; Shear resistances; Stiffness values; Strain coefficient; Animation",2-s2.0-84984918808
"Berseth G., Kapadia M., Haworth B., Faloutsos P.","SteerFit: Automated parameter fitting for steering algorithms",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",18,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984870919&partnerID=40&md5=7e77ed1bf049a28a1543e74f46c2e0b4","In the context of crowd simulation, there is a diverse set of algorithms that model steering. The performance of steering approaches, both in terms of quality of results and computational efficiency, depends on internal parameters that are manually tuned to satisfy application-specific requirements. This paper investigates the effect that these parameters have on an algorithm's performance. Using three representative steering algorithms and a set of established performance criteria, we perform a number of large scale optimization experiments that optimize an algorithm's parameters for a range of objectives. For example, our method automatically finds optimal parameters to minimize turbulence at bottlenecks, reduce building evacuation times, produce emergent patterns, and increase the computational efficiency of an algorithm. We also propose using the Pareto Optimal front as an efficient way of modelling optimal relationships between multiple objectives, and demonstrate its effectiveness by estimating optimal parameters for interactively defined combinations of the associated objectives. The proposed methodologies are general and can be applied to any steering algorithm using any set of performance criteria. © The Eurographics Association 2014.",,"Algorithms; Animation; Efficiency; Interactive computer graphics; Optimization; Parameter estimation; Pareto principle; Algorithm's performance; Application specific requirements; Building evacuation; Internal parameters; Large-scale optimization; Pareto-optimal front; Performance criterion; Steering algorithms; Computational efficiency",2-s2.0-84984870919
"Gauge D., Coros S., Mani S., Thomaszewski B.","Interactive design of modular tensegrity characters",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984873369&partnerID=40&md5=fa4815ba3f9dbffc2d0a2574174d5eb0","We present a computational design tool for creating physical characters using tensegrities -networks of rigid and elastic elements that are in static equilibrium. Whereas the task of designing general tensegrities is very difficult to automate, we show that a modular design paradigm allows users of our system to intuitively build intricate structures that approximate the shape of complex characters. The underlying concept exploited by our method is that simple tensegrities can be used as building blocks to create increasingly complex figures. To this end, we propose a dedicated optimization scheme in order to compute the lengths of elastic cables such that, when fabricated, the structure assumes the desired shape under gravity while remaining compliant and responsive to user interaction. We demonstrate the flexibility of our system by designing several types of tensegrity characters, one of which we also fabricate. © The Eurographics Association 2014.",,"Complex networks; Interactive computer graphics; Building blockes; Complex character; Computational design tools; Interactive design; Intricate structures; Optimization scheme; Static equilibrium; User interaction; Animation",2-s2.0-84984873369
"Umetani N., Schmidt R., Stam J.","Position-based elastic rodss",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984871133&partnerID=40&md5=a915fd9dce9bad166a234d8c8970c4ba","We present a novel method to simulate complex bending and twisting of elastic rods. Elastic rods are commonly simulated using force based methods, such as the finite element method. These methods are accurate, but do not directly fit into the more efficient position-based dynamics framework, since the definition of material frames are not entirely based on positions. We introduce ghost points, which are additional points defined on edges, to naturally endow continuous material frames on discretized rods. We achieve robustness by a novel discretization of the Cosserat theory. The method supports coupling with a frame, a triangle, and a rigid body at the rod's end point. Our formulation is highly efficient, capable of simulating hundreds of strands in real-time. © Eurographics Association 2014.",,"Animation; Interactive computer graphics; Continuous materials; Cosserat theory; Discretizations; Elastic rod; End points; Force-based methods; Real time; Rigid body; Finite element method",2-s2.0-84984871133
"Megaro V., Thomaszewski B., Gauge D., Grinspun E., Coros S., Gross M.","ChaCra: An interactive design system for rapid character crafting",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932158805&partnerID=40&md5=6ea780fee063c981ac2afeff41990ec0","We propose an interactive design system for rapid crafting of planar mechanical characters. Our method combines the simplicity of sketch-based modeling with the ease of defining motion through extreme poses. In order to translate digital designs into fabrication-ready descriptions, our method automatically computes the mechanical structure that makes the characters move as desired. We achieve real-time performance by limiting the mechanical structure between pairs of components to simple building blocks that define, trim, and propagate their motion. By focusing on shape and motion, our system emphasizes the creative aspects of character design while hiding away the intricacies of the underlying mechanical structure. We demonstrate the flexibility of our approach on a set of virtual designs and physical prototypes. © The Eurographics Association 2014.",,"Animation; Interactive computer graphics; Building blockes; Character designs; Digital designs; Interactive design; Mechanical characters; Mechanical structures; Real time performance; Sketch-based modeling; Design",2-s2.0-84932158805
"Sanokho C., Desoche C., Merabti B., Li T.-Y., Christie M.","Camera Motion Graphs",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984910924&partnerID=40&md5=45b9d9cc964f551cf6a68e4b8d95bcfc","This paper presents Camera Motion Graphs, a technique to easily and efficiently generate cinematographic sequences in real-time dynamic 3D environments. A camera motion graph consists of (i) pieces of original camera trajectories attached to one or multiple targets, (ii) generated continuous transitions between camera trajectories and (iii) transitions representing cuts between camera trajectories. Pieces of original camera trajectories are built by extracting camera motions from real movies using vision-based techniques, or relying on motion capture techniques using a virtual camera system. A transformation is proposed to recompute all the camera trajectories in a normalized representation, making camera paths easily adaptable to new 3D environments through a specific retargeting technique. The camera motion graph is then constructed by sampling all pairs of camera trajectories and evaluating the possibility and quality of continuous or cut transitions. Results illustrate the simplicity of the technique, its adaptability to different 3D environments and its efficiency. © The Eurographics Association 2014.",,"Animation; Interactive computer graphics; Trajectories; 3-D environments; Camera trajectories; Continuous transitions; Its efficiencies; Motion capture; Multiple targets; Real-time dynamics; Virtual camera; Cameras",2-s2.0-84984910924
"Setaluri R., Wang Y., Mitchell N., Kavan L., Sifakis E.","Fast grid-based nonlinear elasticity for 2D deformations",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984923607&partnerID=40&md5=5517b8c5309738306791f1fcfe1b6f64","We present a deformation technique that constructs 2D warps by using spline curves to specify the starting and target shapes of selected key contours. We generate a two-dimensional deformation map from these contours by simulating a non-linear elastic membrane deforming in accordance with user-specified constraints. Although we support and demonstrate elastic models inspired by physical membranes, we highlight a custom material model for this specific application, which combines the benefits of harmonic interpolation and area-preserving deformations. Our warps are represented via a standard Cartesian lattice and leverage the regularity of this description to enable efficient computation. Specifically, our method resolves the targeting constraints imposed along arbitrarily shaped contours with sub-grid cell precision, without requiring an explicit remeshing of the warp lattice around the constraint curve. We describe how to obtain a well-conditioned discretization of our membrane model even under elaborate constraints and strict area preservation demands, and present a multigrid solver for the efficient numerical solution of the deformation problem. © The Eurographics Association 2014.",,"Animation; Interactive computer graphics; Cartesian lattices; Deformation problems; Deformation techniques; Efficient computation; Material modeling; Nonlinear elasticity; Numerical solution; User-specified constraints; Deformation",2-s2.0-84984923607
"Vögele A., Krüger B., Klein R.","Efficient unsupervised temporal segmentation of human motion",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",25,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984863555&partnerID=40&md5=04a74f72670516555190bcec52f4ffb5","This work introduces an efficient method for fully automatic temporal segmentation of human motion sequences and similar time series. The method relies on a neighborhood graph to partition a given data sequence into distinct activities and motion primitives according to self-similar structures given in that input sequence. In particular, the fast detection of repetitions within the discovered activity segments is a crucial problem of any motion processing pipeline directed at motion analysis and synthesis. The same similarity information in the neighborhood graph is further exploited to cluster these primitives into larger entities of semantic significance. The elements subject to this classification are then used as prior for estimating the same target values for entirely unknown streams of data. The technique makes no assumptions about the motion sequences at hand and no user interaction is required for the segmentation or clustering. Tests of our techniques are conducted on the CMU and HDM05 motion capture databases demonstrating the capability of our system handling motion segmentation, clustering, motion synthesis and transfer-of-label problems in practice -the latter being an optional step which relies on the preexistence of a small set of labeled data. © The Eurographics Association 2014.",,"Interactive computer graphics; Motion analysis; Semantics; Analysis and synthesis; Motion primitives; Motion processing; Motion segmentation; Motion sequences; Neighborhood graphs; Similarity informations; Temporal segmentations; Animation",2-s2.0-84984863555
"Gast T.F., Schroeder C.","Optimization integrator for large time steps",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941139372&partnerID=40&md5=ff9aebfd3b5df5f0ec282fc1f096c4ab","Practical time steps in today's state-of-the-art simulators typically rely on Newton's method to solve large systems of nonlinear equations. In practice, this works well for small time steps but is unreliable at large time steps at or near the frame rate, particularly for difficult or stiff simulations. We show that recasting backward Euler as a minimization problem allows Newton's method to be stabilized by standard optimization techniques with some novel improvements of our own. The resulting solver is capable of solving even the toughest simulations at the 24Hz frame rate and beyond. We show how simple collisions can be incorporated directly into the solver through constrained minimization without sacrificing efficiency. We also present novel penalty collision formulations for self collisions and collisions against scripted bodies designed for the unique demands of this solver. © The Eurographics Association 2014.",,"Animation; Constrained optimization; Interactive computer graphics; Newton-Raphson method; Backward Euler; Constrained minimization; Frame rate; Large system; Minimization problems; Newton's methods; Standard optimization; State of the art; Nonlinear equations",2-s2.0-84941139372
"Best A., Narang S., Curtis S., Manocha D.","DenseSense: Interactive crowd simulation using density-dependent filters",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927590223&partnerID=40&md5=431c95e25cd4b74e576454b11250d612","We present a novel algorithm to model density-dependent behaviors in crowd simulation. Our approach aims to generate pedestrian trajectories that correspond to the speed/density relationships that are typically expressed using the Fundamental Diagram. The algorithm's formulation can be easily combined with well-known multi-agent simulation techniques that use social forces or reciprocal velocity obstacles for local navigation. Our approach results in better utilization of free space by the pedestrians and has a small computational overhead. We are able to generate human-like dense crowd behaviors in large indoor and outdoor environments; we validate our results by comparing them with captured crowd trajectories. © The Eurographics Association 2014.",,"Algorithms; Animation; Bandpass filters; Interactive computer graphics; Multi agent systems; Computational overheads; Density dependent; Fundamental diagram; Local navigation; Multi agent simulation; Outdoor environment; Pedestrian trajectories; Reciprocal velocity obstacles; Behavioral research",2-s2.0-84927590223
"Hughes R., Ondřej J., Dingliana J.","Holonomic collision avoidance for virtual crowds",2014,"SCA 2014 - Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984876760&partnerID=40&md5=7493b636bf0556410b93671cd2e5b65f","All approaches to simulating human collision avoidance for virtual crowds make simplifications to the underlying behaviour. One of the prevalent simplifications is to ignore it's holonomic aspect (i.e. sidestepping, walking backwards). This does not, however, capture the full range of how humans avoid collisions. In real world scenarios we can often observe people sidestepping around each other and obstacles in their environment. In this paper we present a new holonomic collision avoidance algorithm for real-time crowd simulation. Our model is elaborated from experimental data, which allowed us to both observe the conditions under which holonomic interactions occur, as well as the strategies walkers use during such interactions to avoid collision. Our model is general enough to be used with other collision avoidance techniques. We validate our approach by reproducing situations from our experiments and we demonstrate several examples in which our method provides more plausible collision avoidance behaviour. © The Eurographics Association 2014.",,"Animation; Interactive computer graphics; Virtual reality; Holonomic; Real-time crowd simulation; Real-world scenario; Virtual crowds; Collision avoidance",2-s2.0-84984876760
"Van De Kamp T., Dos Santos Rolo T., Vagovič P., Baumbach T., Riedel A.","Three-dimensional reconstructions come to life - Interactive 3D PDF animations in functional morphology",2014,"PLoS ONE",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904297130&doi=10.1371%2fjournal.pone.0102355&partnerID=40&md5=7380d6432341a7246bc9bdf75f3fc76b","Digital surface mesh models based on segmented datasets have become an integral part of studies on animal anatomy and functional morphology; usually, they are published as static images, movies or as interactive PDF files. We demonstrate the use of animated 3D models embedded in PDF documents, which combine the advantages of both movie and interactivity, based on the example of preserved Trigonopterus weevils. The method is particularly suitable to simulate joints with largely deterministic movements due to precise form closure. We illustrate the function of an individual screw-and-nut type hip joint and proceed to the complex movements of the entire insect attaining a defence position. This posture is achieved by a specific cascade of movements: Head and legs interlock mutually and with specific features of thorax and the first abdominal ventrite, presumably to increase the mechanical stability of the beetle and to maintain the defence position with minimal muscle activity. The deterministic interaction of accurately fitting body parts follows a defined sequence, which resembles a piece of engineering. © 2014 van de Kamp et al.",,"abdomen; accuracy; animal structures; article; automation; body posture; computer program; functional morphology; head; hip; leg; motion analysis system; muscle contraction; nonhuman; simulation; structure analysis; three dimensional imaging; Trigonopterus oblongus; Trigonopterus vandekampi; Trigonopterus weevils; weevil; anatomy and histology; animal; biological model; biomechanics; micro-computed tomography; physiology; procedures; synchrotron; three dimensional imaging; Animals; Biomechanical Phenomena; Hip; Imaging, Three-Dimensional; Models, Biological; Synchrotrons; Weevils; X-Ray Microtomography",2-s2.0-84904297130
"Lamberti F., Sanna A., Paravati G., Carlevaris G.","Automatic grading of 3D computer animation laboratory assignments",2014,"IEEE Transactions on Learning Technologies",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907536823&doi=10.1109%2fTLT.2014.2340861&partnerID=40&md5=12d9af5ab49f9c633f1dc5af6054183b","Assessment is a delicate task in the overall teaching process because it may require significant time and may be prone to subjectivity. Subjectivity is especially true for disciplines in which perceptual factors play a key role in the evaluation. In previous decades, computer-based assessment techniques were developed to address the above-mentioned challenges and to automatically grade students' work in a variety of educational fields. In this paper, the application of automatic assessment strategies in the unexplored domain of computer graphics is discussed. In particular, a tool that is designed to evaluate student assignments for a 3D computer animation course taught at Politecnico di Torino University is presented. During laboratory examination sessions, students are requested to individually operate on the open-source Blender suite and to recreate a 3D animation similar to a reference one. Student's output is assessed against a set of similarity indicators, which are specifically designed to capture the technical and perceptual factors that would be blended in a traditional teacher's evaluation. A comparison of the results that are achieved by the computer-based tool with grades assigned by visual inspection confirms the effectiveness of the designed approach and displays a high-quality concurrence between automatic and manual evaluations. © 2008-2011 IEEE.","3D animation; Computer graphics; Computer-managed instruction; Evaluation methodologies","3D animation; 3D computer animation; Automatic grading; Computer-managed instructions; Evaluation methodologies; Laboratory assignments; Computer graphics",2-s2.0-84907536823
"López-Blanco J.R., Aliaga J.I., Quintana-Ortí E.S., Chacón P.","IMODS: Internal coordinates normal mode analysis server",2014,"Nucleic Acids Research",19,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904811832&doi=10.1093%2fnar%2fgku339&partnerID=40&md5=47d0ab9cf480757ce0f197a8601606cc","Normal mode analysis (NMA) in internal (dihedral) coordinates naturally reproduces the collective functional motions of biological macromolecules. iMODS facilitates the exploration of such modes and generates feasible transition pathways between two homologous structures, even with large macromolecules. The distinctive internal coordinate formulation improves the efficiency of NMA and extends its applicability while implicitly maintaining stereochemistry. Vibrational analysis, motion animationś and morphing trajectories can be easily carried out at different resolution scales almost interactively. The server is versatile; non-specialists can rapidly characterize potential conformational changes, whereas advanced users can customize the model resolution with multiple coarse-grained atomic representations and elastic network potentials. iMODS supports advanced visualization capabilities for illustrating collective motions, including an improved affine-model-based arrow representation of domain dynamics. The generated all-heavy-atoms conformations can be used to introduce flexibility for more advanced modeling or sampling strategies. The server is free and open to all users with no login requirement at http://imods.chaconlab.org. © 2014 The Author(s).",,"adenosine triphosphatase (calcium); article; atom; chemical phenomena; computer analysis; computer program; conformational transition; elasticity; genetic analysis; genetic database; internal mode analysis; macromolecule; molecular dynamics; priority journal; program feasibility; stereochemistry; suspended animation; vibration; Calcium-Transporting ATPases; Chaperonin 10; Chaperonin 60; Internet; Molecular Dynamics Simulation; Protein Conformation; Software",2-s2.0-84904811832
"Chen Q., Cai Z., Peng X., Wang Y., Liu H., Guo C.","A virtual deformable mandible model used for reconstruction computer aided design of large mandibular defects",2014,"Zhonghua kou qiang yi xue za zhi = Zhonghua kouqiang yixue zazhi = Chinese journal of stomatology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929940069&partnerID=40&md5=98fac406ace26476de8b4164ec5bd54a","OBJECTIVE: To establish a three- dimensional virtual deformable mandible model used for individual reconstruction design of large mandibular defect.METHODS: A virtual deformable mandible model has been established by a 3D animation software. The model could be used for preoperative reconstruction design of large mandibular defects cases. According to the temporomandibular joint fossa position, maxillary dental arch, the normal relationship of cranio-maxillofacial profile, and the morphology of the residual segments of mandible, the virtual mandible model could be scaled and adjusted and a virtual mandible with individual features was obtained. Three normal skulls have been used to validate the adjustment ability of the virtual deformable mandible model. The preoperative reconstruction design process of 1 typical large mandibular defect case was demonstrated.RESULTS: The deformation matching ability of the virtual deformable mandible model was very good. The registration between the design model and the original mandible was over 90%. The design effect of the large mandiblar defect case was satisfied.CONCLUSIONS: Virtual deformable mandible model is a new feasible method to aid preoperative reconstruction design of large mandibular defects.",,"anatomy and histology; audiovisual equipment; computer aided design; computer interface; computer program; human; image processing; mandible; plastic surgery; surgery; temporomandibular joint; three dimensional imaging; Computer-Aided Design; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Mandible; Models, Anatomic; Reconstructive Surgical Procedures; Software; Temporomandibular Joint; User-Computer Interface",2-s2.0-84929940069
"Xu Y., Chang L.-Y.","Computer-assisted character learning using animation and visual chunking",2014,"Engaging Language Learners through Technology Integration: Theory, Applications, and Outcomes",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949812475&doi=10.4018%2f978-1-4666-6174-5.ch001&partnerID=40&md5=392a3fab33cfa003fba22def89374a42","This chapter examines the effects of computerized stroke order animation and visual chunking on character recognition and production. Through two experiments, the authors found that both computer-assisted presentation methods were effective, and their impact was comparable to or surpassed the traditional way of character learning through reading and writing. Specifically, animation was comparable to writing and more effective than reading in facilitating form recognition. Visual chunking produced better results in character production than writing when characters were presented in radical-based groups. © 2014 by IGI Global. All rights reserved.",,,2-s2.0-84949812475
"Sun L., Liu M., Hu J., Liang X.","A Chinese character teaching system using structure theory and morphing technology",2014,"PLoS ONE",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903693514&doi=10.1371%2fjournal.pone.0100987&partnerID=40&md5=c26aa77344ff07887485465a7381bce1","This paper proposes a Chinese character teaching system by using the Chinese character structure theory and the 2D contour morphing technology. This system, including the offline phase and the online phase, automatically generates animation for the same Chinese character from different writing stages to intuitively show the evolution of shape and topology in the process of Chinese characters teaching. The offline phase builds the component models database for the same script and the components correspondence database for different scripts. Given two or several different scripts of the same Chinese character, the online phase firstly divides the Chinese characters into components by using the process of Chinese character parsing, and then generates the evolution animation by using the process of Chinese character morphing. Finally, two writing stages of Chinese characters, i.e., seal script and clerical script, are used in experiment to show the ability of the system. The result of the user experience study shows that the system can successfully guide students to improve the learning of Chinese characters. And the users agree that the system is interesting and can motivate them to learn. © 2014 Sun et al.",,"article; cerebrovascular accident; Chinese; data base; education; human; language; learning; mathematical analysis; mathematical model; probability; semantics; synapomorphy; teaching; virtual reality; writing; Asian continental ancestry group; female; male; motivation; multimedia; pattern recognition; physiology; procedures; student; teaching; Asian Continental Ancestry Group; Computer-Assisted Instruction; Female; Humans; Language; Male; Motivation; Multimedia; Pattern Recognition, Visual; Semantics; Students",2-s2.0-84903693514
"Diwakar S., Shekhar A., Radhamani R., Achuthan K., Sujatha G., Nedungadi P., Sasidharakurup H., Raman R., Nair B.","Usage and diffusion of biotechnology virtual labs for enhancing university education in India's urban and rural areas",2014,"E-Learning as a Socio-Cultural System: A Multidimensional Analysis",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945987679&doi=10.4018%2f978-1-4666-6154-7.ch004&partnerID=40&md5=9f85f03b0de152d1526e28b91e290ef8","Information and Communication Technology (ICT)-enabled virtual laboratories provide an online learning experience with the aid of computer-based instructional materials (animation, simulation, and remote-trigger experiments) for improving the active learning process. The project reported on in this chapter was set up in order to enhance university and college education, which is now becoming an advanced training environment for solving the geographical, social, and economic challenges faced in the interdisciplinary field of science education, especially in India. In order to study the role of biotechnology virtual laboratories in the current education system, a pedagogical survey, via workshops and online feedback, was carried out among several student and teacher groups of different Indian universities. This chapter reports how virtual labs in biotechnology can be used to improve teaching and learning experiences in an easy and understandable way with user interaction and how such tools serve to effectively reduce the problems of laboratory education especially in remote areas. The results obtained from user-feedback analysis suggest the use of virtual labs as a recommended component in blended education in large classroom scenarios for enhancing autonomous learning process and as an alternative to enhance lab education in geographically remote and economically challenged institutes. © 2014 by IGI Global. All rights reserved.",,,2-s2.0-84945987679
"Brooks M.A., Beaulieu J.E., Severson H.H., Wille C.M., Cooper D., Gau J.M., Heiderscheit B.C.","Web-based therapeutic exercise resource center as a treatment for knee osteoarthritis: A prospective cohort pilot study",2014,"BMC Musculoskeletal Disorders",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901294371&doi=10.1186%2f1471-2474-15-158&partnerID=40&md5=7af527627f73e8c5b88f19f1400444a1","Background: Although beneficial effects of exercise in the management of knee osteoarthritis (OA) have been established, only 14 -18% of patients with knee OA receive an exercise from their primary care provider. Patients with knee OA cite lack of physician exercise advice as a major reason why they do not exercise to improve their condition. The purpose of this pilot study was to investigate use of a web-based Therapeutic Exercise Resource Center (TERC) as a tool to prescribe strength, flexibility and aerobic exercise as part of knee OA treatment. It was hypothesized that significant change in clinical outcome scores would result from patients' use of the TERC. Methods. Sixty five individuals diagnosed with mild/moderate knee OA based on symptoms and radiographs were enrolled through outpatient physician clinics. Using exercise animations to facilitate proper technique, the TERC assigned and progressed patients through multiple levels of exercise intensity based on exercise history, co-morbidities and a validated measure of pain and function. Subjects completed a modified short form WOMAC (mSF-WOMAC), World Health Organization Quality of Life (WHO-QOL) and Knee Self-Efficacy Scale (K-SES) at baseline and completion of the 8 week program, and a user satisfaction survey. Outcomes were compared over time using paired t-tests and effect sizes calculated using partial point biserial (pr). Results: Fifty two participants completed the 8 week program with average duration of knee pain 8.0 ± 11.0 yrs (25 females; 61.0 ± 9.4 yrs; body mass index, 28.8 ± 6.3 kg/m 2). During the study period, all outcome measures improved: mSF-WOMAC scores decreased (better pain and function) (p &lt;.001; large effect, pr = 0.70); WHO-QOL physical scores increased (p =.015; medium effect, pr = 0.33); and K-SES scores increased (p &lt;.001; large effect, pr = 0.54). No significant differences were found in study outcomes as a function of gender, age, BMI or symptom duration. Patients reported very positive evaluation of the TERC (94% indicated the website was easy to use; 90% specified the exercise animations were especially helpful). Conclusion: This pilot study demonstrated the web-based TERC to be feasible and efficacious in improving clinical outcomes for patients with mild/moderate knee OA and supports future studies to compare TERC to current standard of care, such as educational brochures. © 2014 Brooks et al.; licensee BioMed Central Ltd.","Home exercise program; Internet; Knee osteoarthritis","adult; aerobic exercise; age; article; body mass; cohort analysis; computer assisted therapy; controlled study; exercise intensity; follow up; human; Internet; joint mobility; knee function; knee osteoarthritis; Knee Self Efficacy Scale; major clinical study; male; muscle strength; named inventories, questionnaires and rating scales; outcome assessment; physiotherapist; pilot study; prospective study; quality of life; sex difference; therapeutic exercise resource center; treatment duration; virtual reality; Western Ontario and McMaster Universities Osteoarthritis Index; World Health Organization Quality of Life; aged; female; kinesiotherapy; middle aged; Osteoarthritis, Knee; procedures; psychology; self report; treatment outcome; Aged; Cohort Studies; Exercise Therapy; Female; Follow-Up Studies; Humans; Internet; Male; Middle Aged; Osteoarthritis, Knee; Pilot Projects; Prospective Studies; Self Report; Treatment Outcome",2-s2.0-84901294371
"Pathare N.A.","Interactive animations to enhance learning of concepts in immunology",2014,"Medical Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898737653&doi=10.1111%2fmedu.12463&partnerID=40&md5=b2a5e3d33c84e8b5aec2114abd2aa3a7",[No abstract available],,"education; human; immunology; learning; teaching; teaching; Allergy and Immunology; Computer-Assisted Instruction; Humans; Learning; Teaching Materials",2-s2.0-84898737653
"Feng X., Wan W., Yu X.","Analysis and comparison of methods for real-time solid deformation",2014,"Journal of Information and Computational Science",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901594072&doi=10.12733%2fjics20102810&partnerID=40&md5=706da328fb7c08161f0023800106800d","The powerful computing capacity of computer has made physically based deformation widely studied. In this paper, we describe a general framework to deal with real-time solid deformation simulation. Based on Newton's Laws of Motion and discrete analysis methods, this frame system couples several explicit and implicit numerical integrators and elastic material models under initial and boundary constraint conditions. The simulator models solid deformable object as a tetrahedral mesh with internal elastic forces and damping forces derived dependent on material models and equilibrium equations properly time-stepped forward using specific integrators. In order to give a detailed and persuasive description and provide necessary support to potential animators, different material models and integrators are analyzed theoretically and corresponding combinations are compared in respects of time performance and system stability with practical model simulation. In particular, the solution of implicit Newmark integrator in combination with Saint-Venant Kirchhoff model is demonstrated superior performance while taking a comprehensive consideration of complexity, stability and plausibility. 1548-7741/Copyright © 2014 Binary Information Press.","Mass-spring system; Real-time solid deformation simulation; Saint-Venant kirchhoff model; Time integrator","Animation; Elasticity; Numerical methods; System stability; Boundary constraints; Comparison of methods; Kirchhoff model; Mass spring systems; Newton's laws of motion; Numerical integrator; Solid deformation; Time integrators; Deformation",2-s2.0-84901594072
"Verran J., Crossley M., Carolan K., Jacobs N., Amos M.","Monsters, microbiology and mathematics: The epidemiology of a zombie apocalypse",2014,"Journal of Biological Education",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897116768&doi=10.1080%2f00219266.2013.849283&partnerID=40&md5=4c131922d4d3e56f683aea22931d0faa","The aim of this learning exercise was to harness current interest in zombies in order to educate audiences about the epidemiology of infectious disease. Participants in the activity were provided with an outbreak scenario, which they then used as the basis of play-based activities. By considering the mode and speed of transmission, size of outbreak and prevention/control strategy, participant groups were able to define parameters of their outbreak scenario. These were then input to SimZombie, a computer simulation program developed by the authors, which visually demonstrated the spread of infection through a population. The resulting animations were then used as the basis of in-depth discussion which, in turn, enabled the consideration of principles of disease transmission and control strategies. The activity provided an opportunity to engage a range of audiences through a variety of different delivery mechanisms, including role play, workshops and informal drop-in. Learning was evidenced by participation and feedback. © 2013 Society of Biology.","epidemiology; mathematical modelling; zombies",,2-s2.0-84897116768
"Schwartz R.N., Plass J.L.","Click versus drag: User-performed tasks and the enactment effect in an interactive multimedia environment",2014,"Computers in Human Behavior",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893901706&doi=10.1016%2fj.chb.2014.01.012&partnerID=40&md5=72989cba616e9e1ce9464d1022565f57","Does learner performance of specific tasks in an interactive multimedia environment affect learning outcomes? Within a multimedia environment, users may engage in a range of actions, or interactive tasks, from tapping a keyboard to executing large motor movements. To investigate the impact of particular performance tasks on learning, we first introduce an approach to classifying interactive multimedia tasks as enactive, iconic or symbolic. We then describe a study in which university students (N = 112) used a computer program that presented a series of action phrases in 4 different conditions, each condition requiring performance of a different task: listen (audio only), look (audio with static graphic), click (audio with animation triggered by a click), or drag (audio with click-and-drag graphic). Participants were tested on free recall and recognition of phrases immediately after treatment and again after 3 weeks. At immediate testing, recall was best for drag (iconic) items, followed by click (symbolic), look, and listen items, in that order, with significant differences between each pair of conditions. For immediate recognition, as well as for delayed free recall and delayed recognition, mean scores followed the same pattern, with some variations in significance. Results support our proposed classification of interactive behaviors, extend previous findings on the enactment effect into a computer environment, and suggest the importance of considering the design of interactive tasks in the development of multimedia learning materials. © 2014 Elsevier Ltd. All rights reserved.","Embodiment; Enactment effect; Interactivity; Multimedia; User-performed tasks",,2-s2.0-84893901706
"Garg H., Arora G., Bhatia K.","Watermarking for 3-D polygon mesh using mean curvature feature",2014,"Proceedings - 2014 6th International Conference on Computational Intelligence and Communication Networks, CICN 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988287808&doi=10.1109%2fCICN.2014.190&partnerID=40&md5=60c9cba753a5f6924b301d1d793a486b","Protection of 3-D objects are also important for protecting author rights in animation, multimedia, computer aided design (CAD), virtual reality, medical imaging etc. Especially in the grown up market of video-games, there is demand for a watermarking technique for 3-D-objects. In this paper, we propose a robust watermarking algorithm having less perceivable distortion for 3-D polygon mesh objects based on geometrical properties. The selection of vertices for watermark embedding is based on perceivable distortion. The perceivable distortion is defined as the distortion observed by human observers. The selection of vertices for watermark embedding is an important factor for perceivable distortion as watermark embedding in deeper surface has less perceivable distortion in comparison to watermark embedding in flat or peak surfaces. In the proposed algorithm, we exploit this observation for selection of vertices for watermark embedding. The watermark is embedded by repositioning the selected vertices from their original positions. © 2014 IEEE.","3-D Polygon Mesh; Hausdorff distance; Mean Curvature; Objective measurement; perceivable visual quality; RMS distance; Subjective measurement","Animation; Artificial intelligence; Computer aided design; Computer games; Digital watermarking; Geometry; Medical imaging; Virtual reality; Hausdorff distance; Mean curvature; Objective measurement; Polygon meshes; RMS distance; Subjective measurements; Visual qualities; Three dimensional computer graphics",2-s2.0-84988287808
"Wei W.","Research on interactive simulation software is applied to foreign language teaching based on Delphi",2014,"Proceedings - 2014 6th International Conference on Computational Intelligence and Communication Networks, CICN 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946692459&doi=10.1109%2fCICN.2014.233&partnerID=40&md5=4a48be343fe2f68dbc503cfe82893581","This paper describes the process of design and implementation of multimedia foreign language teaching simulation software is an open system, the simulation of the software system can realize multi computer courses in foreign language, practice. Course selection, foreign language selection method using menu, each foreign language simulation with animation, pictures and text forms, which uses the material is in the form of documents, and is easy to realize dynamic adding, modifying, lookup and update. © 2014 IEEE.","Delphi; Foreign language teaching; practice; simulation","Animation; Artificial intelligence; Computational linguistics; Computer simulation languages; Computer software; Curricula; Open systems; Delphi; Design and implementations; Foreign language teaching; Interactive simulations; practice; Selection methods; simulation; Software systems; Teaching",2-s2.0-84946692459
"Knackmuß J., Creutzburg R.","Virtual tutorials, Wikipedia books, and multimedia-based teaching for blended learning support in a course on algorithms and data structures",2014,"Proceedings of SPIE - The International Society for Optical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896795914&doi=10.1117%2f12.2037156&partnerID=40&md5=de12418e66b7f487d78d76745f57cb68","The aim of this paper is to describe the benefit and support of virtual tutorials, Wikipedia books and multimedia-based teaching in a course on Algorithms and Data Structures. We describe our work and experiences gained from using virtual tutorials held in Netucate iLinc sessions and the use of various multimedia and animation elements for the support of deeper understanding of the ordinary lectures held in the standard classroom on Algorithms and Data Structures for undergraduate computer sciences students. We will describe the benefits, form, style and contents of those virtual tutorials. Furthermore, we mention the advantage of Wikipedia books to support the blended learning process using modern mobile devices. Finally, we give some first statistical measures of improved student's scores after introducing this new form of teaching support. © 2014 Copyright SPIE.","blended learning; m-learning systems; mobile learning; virtual tutorials; Wikipedia books","Blended learning; M-Learning; Mobile Learning; virtual tutorials; Wikipedia; Algorithms; Animation; Data structures; Learning systems; Mobile devices; Students; Teaching",2-s2.0-84896795914
"Zhang H., Zhang Z.-Y.","Human motion capture system based on distributed wearable sensing technology",2014,"Proceedings - 2014 International Conference on Wireless Communication and Sensor Network, WCSN 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946689954&doi=10.1109%2fWCSN.2014.85&partnerID=40&md5=2f54f6a2e8df8549ae8e2b10b98202cb","With the development of human-computer interaction technology, the multi-modal, natural interaction will become the primary way of interaction between human and computer. A supporting technology is that the computer must understand and capture the behavior characteristic of human, thus motion capture is proposed. Through motion capture technology, the computer can understand human action, and the user can send instructions and convey information to computer through the body, range, gestures and expressions. Therefore, the motion capture is one of the key technologies of new generation human-computer interaction. The current study of motion capture based on MEMS sensor is mainly for animation and film production, and the price is always very high. With sensor integration technology improve and sensor prices become low, there are some new system design needs. Based on pre-existing motion capture system, this paper tries to construct an inexpensive human motion capture system prototype using flexible architecture and distributed computing technology. © 2014 IEEE.","Human-computer interaction; Motion capture; Wearable computing","Animation; Behavioral research; Distributed computer systems; Sensor networks; Wearable sensors; Wearable technology; Wireless sensor networks; Wireless telecommunication systems; Behavior characteristic; Distributed computing technology; Flexible architectures; Human motion capture; Motion capture; Motion capture system; Supporting technology; Wearable computing; Human computer interaction",2-s2.0-84946689954
"Hu Z.Y.","Simulation research on video tracking based on computer dynamic capturing technology",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897716495&doi=10.4028%2fwww.scientific.net%2fAMM.513-517.2389&partnerID=40&md5=cec5c0015b17ebfc22f6c724c63355f8","Motion capture technology of computer is a new form of a new data acquisition in recent years. It relates to many subjects, such as mathematics, computer science, graphics, digital signal processing, image processing, data structure and so on. Through the combination of various disciplines, and mutual penetration, this new research field has been formed. The study of the motion capture technology not only increases the depth of theory, but also provides practical significance for the dynamic kinematics. At present, the motion capture technology of computer has been widely applied to the animation game production, medicine motion analysis sports and other fields. This article is mainly based on the combination of basketball technique and computer motion capture to provide a theoretical basis and practical experience for computer motion capture of basketball. © (2014) Trans Tech Publications, Switzerland.","Basketball; Computer; Motion capture; Sports","Basketball; Motion analysis; Motion capture; New forms; Practical experience; Research fields; Simulation research; Video tracking; Animation; Computer simulation; Computers; Image processing; Information technology; Materials science; SportS; Sports medicine; Computer games",2-s2.0-84897716495
"Liu F.","Research on the application of cellular algorithm in 3D modeling of cartoon characters",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897691493&doi=10.4028%2fwww.scientific.net%2fAMM.513-517.1744&partnerID=40&md5=96a89eba316ca284b6c2e7a9d201d83a","The traditional design method of 3D animation modelings, by which can obtain attractive and precise 3D animation modelings, is to use three-dimensional modeling software such as Maya or 3D Max to draw directly. However, this method is faced with many problems, for instance, the lack of creativity, long design circle, high production costs, etc. For the problem of the lack of creativity, the reason is that animation designers are often subject to the limitation of the existing modelings and design concepts in the design process, therefore, they can not design creative modelings which are attractive and unforgettable enough. [1]For the problem of long design circle and high production costs, the reason is that although the 3D animation software are powerful, to skillfully master them not only requires users to have knowledge of computer technology and aesthetics at the same time, but also need a long learning process of modeling. Moreover, it takes the designers a lot of time and energy to design, draw and complete each modeling, and this will undoubtedly extend the design circle and increase the costs to some extent. Therefore, how to quickly and automatically generate creative 3D animation modelings has become a research focus of the present computer-aided creative design. © (2014) Trans Tech Publications, Switzerland.","3D animation modeling; Cellular genetic algorithm; Creative design; Evolutionary rules; Human-computer interaction; Tree-structure coding","3D animation; Cellular genetic algorithms; Creative design; Evolutionary rules; Tree-structure; Animation; Costs; Genetic algorithms; Human computer interaction; Information technology; Materials science; Product design; Three dimensional computer graphics; Three dimensional",2-s2.0-84897691493
"Liu C.F., Sun Y.B., Wang L.M.","C language animation design teaching methods analysis for engineering applications",2014,"Advanced Materials Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896866449&doi=10.4028%2fwww.scientific.net%2fAMR.889-890.1696&partnerID=40&md5=ca0085ba17cb2f37c3839d964d15bfe5","C language program design is a basic and also the core of university teaching computer courses. This paper discussed C language animated programming and curriculum tutorial design in the engineering applications, need be able to combine theoretical knowledge and practical application, in the limited class hours, stimulate students' interest in learning, and improve students' ability to actual use the C programming language. This paper summarized some experience about the characteristics of C language to improve the efficiency of teaching curriculum design guidance and outcomes, improve engineering capabilities. © (2014) Trans Tech Publications, Switzerland.","Animation design; C language; Engineering applications; Teaching methods","Animation designs; C language; Engineering applications; Program design; Students' interests; Teaching curriculum; Teaching methods; University teaching; Animation; Applications; Curricula; Design; Teaching; C (programming language)",2-s2.0-84896866449
"Tang J., Meng Y.","Research and implementation of intelligent traditional Chinese headdress system in computer animation",2014,"Applied Mechanics and Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896896721&doi=10.4028%2fwww.scientific.net%2fAMM.519-520.471&partnerID=40&md5=d907c3599bf9a7824bf65e24ceec45d5","Traditional Chinese headdress is an important part of the traditional Chinese culture, which provides rich material for computer animation. The creation process of traditional Chinese headdress model in computer animation is complex working and time-consuming. This study establishes the traditional Chinese headdresses database, which covers from Tang Dynasty to Qing Dynasty. According to the characteristics of the traditional Chinese headdress, this study develops an intelligent Traditional Chinese Headdress system by MEL, which can import models into the scene and change attributes related with models efficiently. The system is the combination among computer technology, animation art and traditional Chinese culture. It will improve the efficiency and quality in the computer animation creation. © (2014) Trans Tech Publications, Switzerland.","Computer animation; Maya Embedded Language; Modeling; Traditional Chinese headdress","Chinese culture; Computer animation; Computer technology; Creation process; Maya embedded languages; Tang Dynasty; Traditional Chinese headdress; Information technology; Models; Animation",2-s2.0-84896896721
"Shao X.H.","The exploitation of environmentally friendly materials for humane care in children postoperative recovery",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896838252&doi=10.4028%2fwww.scientific.net%2fAMM.527.21&partnerID=40&md5=e2362a7e73f2289eae6f9b5129897127","According to the principle of internet integration systems, the accurate interactive TV equipment is designed. On the basis of establishing the model of animation scene to be processed, the 3D video equipment is assembled in a signal and image processing by using the application software signal and image processing systems provided by game systems. The virtual image of the components of accurate video equipment is implemented either from top to bottom or reversely, providing a basis for humane care in children postoperative recovery of this equipment. © (2014) Trans Tech Publications, Switzerland.","Children postoperative recovery; Exploitation; Humane care; Interactive TV; Internet integration systems","Application softwares; Exploitation; Game system; Humane care; Interactive TV; Internet integration; Signal and image processing; Virtual images; Animation; Computational mechanics; Digital television; Image processing; Interactive television; Internet; Recovery; Television equipment; Three dimensional computer graphics; Patient rehabilitation",2-s2.0-84896838252
"Wang S.-C., Jiang C., Chern J.-Y.","Promoting healthy computer use: Timing-informed computer health animations for prolonged sitting computer users",2014,"Behaviour and Information Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894573914&doi=10.1080%2f0144929X.2012.695394&partnerID=40&md5=aab3b9dc1700a1078adc5cbfd610c433","Accompanying the increase in computer and Internet use worldwide, physical inactivity has become prevalent in most developed and developing countries. Extended computer use may contribute to symptoms such as visual impairment and musculoskeletal disorders. To reduce the risk of physical inactivity and promote healthier computer use, this study tries to develop a timed broadcast of health-related animations for users sitting at computers for prolonged periods. In addition, we examine the effects that the program has on the computer-related health beliefs and behaviour of participants. Before-and-after survey questionnaires were used for data collection. The results show that the animation program indeed had a positive effect when reminding participants to take a break and stretch their bodies. The program influenced the beliefs and behaviours of participants with regard to their health. The development and examination were documented and discussed within the context of health agencies planning the next steps in an effort to promote, develop and evaluate healthy computer use. © 2012 Taylor & Francis.","animation",,2-s2.0-84894573914
"Liang W.Y.","Research and development of flash-based Online Virtual Laboratory",2014,"Applied Mechanics and Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894535817&doi=10.4028%2fwww.scientific.net%2fAMM.509.198&partnerID=40&md5=6d81c7e1b4ac058216ad0f98f98cc4cc","Flash is an electronic animation that can be watched on a computer or monitor with a microprocessor. It is rich in content and can simultaneously display images, sound and text, its data is very few, generally speaking, the amount of data of an animated video accounts for 1/ 4 to 1/ 10 of a physical video with the same size and definition. Its development brings opportunities for modern educational technology curriculum of higher normal university, making it present a more rich content and form. The relevant overviews of online virtual laboratory are first discussed in this paper, and then is its construction process. © (2014) Trans Tech Publications, Switzerland.","Flash technology; Modern educational technology; Online virtual laboratory",,2-s2.0-84894535817
"Alexanderson S., Beskow J.","Animated Lombard speech: Motion capture, facial animation and visual intelligibility of speech produced in adverse conditions",2014,"Computer Speech and Language",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890567121&doi=10.1016%2fj.csl.2013.02.005&partnerID=40&md5=d373a69c6da3b605c4600c26ec5c91fc","In this paper we study the production and perception of speech in diverse conditions for the purposes of accurate, flexible and highly intelligible talking face animation. We recorded audio, video and facial motion capture data of a talker uttering a set of 180 short sentences, under three conditions: normal speech (in quiet), Lombard speech (in noise), and whispering. We then produced an animated 3D avatar with similar shape and appearance as the original talker and used an error minimization procedure to drive the animated version of the talker in a way that matched the original performance as closely as possible. In a perceptual intelligibility study with degraded audio we then compared the animated talker against the real talker and the audio alone, in terms of audio-visual word recognition rate across the three different production conditions. We found that the visual intelligibility of the animated talker was on par with the real talker for the Lombard and whisper conditions. In addition we created two incongruent conditions where normal speech audio was paired with animated Lombard speech or whispering. When compared to the congruent normal speech condition, Lombard animation yields a significant increase in intelligibility, despite the AV-incongruence. In a separate evaluation, we gathered subjective opinions on the different animations, and found that some degree of incongruence was generally accepted. © 2013 Elsevier Ltd.","Audio-visual intelligibility; Facial animation; Lip-reading; Lombard effect; Motion capture; Speech-reading","Audio-visual; Facial animation; Lip-reading; Lombard effects; Motion capture; Speech-reading; Animation; Audio acoustics; Digital storage; Speech recognition; Three dimensional computer graphics; Speech intelligibility",2-s2.0-84890567121
"Patel H., Bayliss L.C., Ivory J.D., Woodard K., McCarthy A., Macdorman K.F.","Receptive to bad reception: Jerky motion can make persuasive messages more effective",2014,"Computers in Human Behavior",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890468507&doi=10.1016%2fj.chb.2013.11.012&partnerID=40&md5=a3521491c7374a0e6234e3af586bb43f","When used deliberately in television and film, jerky motion captures attention. However, it can be distracting in the movements of characters in digital video. To what extent does this kind of jerkiness influence message processing? Based on a limited-capacity model of message processing, jerky character motion was predicted to increase compliance to a persuasive message. The present experiment manipulated the jerkiness of an actor's movements in a computer-delivered video to examine its effect on responses to a hypothetical medical scenario. Jerkiness, whether subtle or obvious, increased self-reported compliance. It also decreased heart rate variability, indicating attentional mediation. Though counterintuitive, these findings indicate that jerky character motion can make computer-mediated messages more persuasive. © 2013 Elsevier Ltd. All rights reserved.","Advertising; Cognition; Computer animation; Decision making; New media; Physiological measures","Character motion; Cognition; Computer animation; Digital videos; Heart rate variability; Message processing; New media; Physiological measures; Animation; Decision making; Marketing; Motion compensation; Multimedia systems; Psychophysiology",2-s2.0-84890468507
"Piwek L., McKay L.S., Pollick F.E.","Empirical evaluation of the uncanny valley hypothesis fails to confirm the predicted effect of motion",2014,"Cognition",23,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891052751&doi=10.1016%2fj.cognition.2013.11.001&partnerID=40&md5=d041a2f7ea45abd1258502121cf6c8d7","The uncanny valley hypothesis states that the acceptability of an artificial character will not increase linearly in relation to its likeness to human form. Instead, after an initial rise in acceptability there will be a pronounced decrease when the character is similar, but not identical to human form (Mori, 1970/2012). Moreover, it has been claimed but never directly tested that movement would accentuate this dip and make moving characters less acceptable. We used a number of full-body animated computer characters along with a parametrically defined motion set to examine the effect of motion quality on the uncanny valley. We found that improving the motion quality systematically improved the acceptability of the characters. In particular, the character classified in the deepest location of the uncanny valley became more acceptable when it was animated. Our results showed that although an uncanny valley was found for static characters, the deepening of the valley with motion, originally predicted by Mori (1970/2012), was not obtained. © 2013 Elsevier B.V.","Action perception; Affect recognition; Animation; Biological motion; Uncanny valley","adult; article; character animation; computer language; elbow; human; human experiment; hypothesis; motion; movement (physiology); movement perception; priority journal; psychophysics; robotics; shoulder; uncanny valley hypothesis; virtual reality; affect; audiovisual equipment; computer interface; female; male; perception; physiology; young adult; Adult; Affect; Female; Humans; Male; Motion Perception; Motion Pictures as Topic; Robotics; Social Perception; User-Computer Interface; Young Adult",2-s2.0-84891052751
"Christopher Immanuel W., Paul Mary Deborrah S., Samuel Selvaraj R.","Application of cellular automata approach for cloud simulation and rendering",2014,"Chaos (Woodbury, N.Y.)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921424924&doi=10.1063%2f1.4866854&partnerID=40&md5=7f48025bdb2077cd91b2300a0e33d1fb","Current techniques for creating clouds in games and other real time applications produce static, homogenous clouds. These clouds, while viable for real time applications, do not exhibit an organic feel that clouds in nature exhibit. These clouds, when viewed over a time period, were able to deform their initial shape and move in a more organic and dynamic way. With cloud shape technology we should be able in the future to extend to create even more cloud shapes in real time with more forces. Clouds are an essential part of any computer model of a landscape or an animation of an outdoor scene. A realistic animation of clouds is also important for creating scenes for flight simulators, movies, games, and other. Our goal was to create a realistic animation of clouds.",,"biological model; cell shape; computer simulation; physiology; Cell Shape; Computer Simulation; Models, Biological",2-s2.0-84921424924
"Hsieh S.-J., Cheng Y.-T.","Algorithm and intelligent tutoring system design for programmable controller programming",2014,"International Journal of Advanced Manufacturing Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896733353&doi=10.1007%2fs00170-013-5539-z&partnerID=40&md5=0b6cf95f3a78cce11399f2624d74c8e9","Programmable logic controllers (PLC) are used for many industrial process control applications. Learning to write ladder logic programs for PLC control is an important and challenging task. However, the learning of ladder logic is often hindered by limited PLC availability due to expensive lab setup, limited lab time, and high student/instructor ratios. With the help of the internet, teaching is not constrained in the traditional classroom pedagogy; the instructors can put the course material on the website and allow the students go on to the course webpage as an alternative way to learn the domain knowledge. However, there is no interaction between the users and learning materials; so, the learning efficiency is often limited. The problem here is how to design a web-based system that is intelligent and adaptive enough to teach the students domain knowledge in PLC. In this research, we proposed a system architecture which combines the pre-test, cased-based reasoning (i.e., heuristic functions), tutorials and tests of the domain concepts, and post-test (i.e., including pre- and post-exam) to customize students' needs according to their knowledge levels and help them learn the PLC concepts, effectively. We have developed an intelligent tutoring system which is mainly based on the feedback and learning preference of the users' questionnaires. It includes many pictures, colorful diagrams, and interesting animations (i.e., switch control of the user's rung configuration) to attract the users' attention. From the model simulation results, a knowledge proficiency effect occurs on problem solving time. If the students are more knowledgeable about PLC concepts, they will take less time to complete problems than those who are not as proficient. Additionally, from the system experiments, the results indicate that the learning algorithm in this system is robust enough to pinpoint the most accurate error pattern (i.e., almost 90 % accuracy of mapping to the most similar error pattern), and the adaptive system will have a higher accuracy of discerning the error patterns which are close to the answers of the PLC problems when the databases have more built-in error patterns. The participant evaluation indicates that after using this system, the users will learn how to solve the problems and have a much better performance than before. © 2013 Springer-Verlag London.","Intelligent tutoring systems; Programming logic controller","Cased-based reasoning; Industrial process control; Intelligent tutoring system; Learning efficiency; Learning preferences; Programmable logic controllers (PLC); Programming logic; System architectures; Computer aided instruction; Education computing; Heuristic algorithms; Logic programming; Process control; Programmable logic controllers; Students; Surveys; Teaching; Websites; Problem solving",2-s2.0-84896733353
"Neumann J., Plank M.","TIB's Portal for audiovisual media: New ways of indexing and retrieval",2014,"IFLA Journal",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897780883&doi=10.1177%2f0340035214526531&partnerID=40&md5=437654ee321c91d0ffdb1e5c397de9f0","The German National Library of Science and Technology (TIB) is developing a web-based platform for audiovisual media. The forthcoming audiovisual portal optimizes access to scientific videos such as computer animations, lecture and conference recordings. TIB's AV- Portal offers new methods for searching within videos enabled by automated video analysis with scene, speech, text and image recognition. Search results are connected to new knowledge by linking the data semantically. This paper aims at describing the TIB's portal for audiovisual media and the multimedia retrieval technologies as well as the added value for libraries and their users. © The Author(s) 2014.","audiovisual media; automated video analysis; multimedia indexing; multimedia retrieval; search tools",,2-s2.0-84897780883
[No author name available],"Proceedings of the 9th International Symposium on Linear Drives for Industry Applications, LDIA 2013",2014,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894177820&partnerID=40&md5=bac4c156dc4429d5b616ee57d6dc9eed","The proceedings contain 407 papers. The topics discussed include: research of construction of US agriculture information system; constructing an O2O service quality appraisal system based on fuzzy comprehensive evaluation method; MCMC analysis for the number of hurricanes; study of Internet banking in innovative engineering; library information delivery system based on regular expression in innovative engineering; researches on switching-based circuit theory and fault; modeling of irregular particles based on ball filling method; modeling of mobile agent-based heterogeneous distributed database access; research on realizing method of image file on computer based on multimedia technique; design and implementation of 3D facial animation based on MPEG-4; and method for blood vessel extraction in retinal images using morphological top-hat and kirsch operator.",,,2-s2.0-84894177820
[No author name available],"Proceedings of the 9th International Symposium on Linear Drives for Industry Applications, LDIA 2013",2014,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894218952&partnerID=40&md5=9448c2573650a2cda6576b83dbbd8b83","The proceedings contain 407 papers. The topics discussed include: research of construction of US agriculture information system; constructing an O2O service quality appraisal system based on fuzzy comprehensive evaluation method; MCMC analysis for the number of hurricanes; study of Internet banking in innovative engineering; library information delivery system based on regular expression in innovative engineering; researches on switching-based circuit theory and fault; modeling of irregular particles based on ball filling method; modeling of mobile agent-based heterogeneous distributed database access; research on realizing method of image file on computer based on multimedia technique; design and implementation of 3D facial animation based on MPEG-4; and method for blood vessel extraction in retinal images using morphological top-hat and kirsch operator.",,,2-s2.0-84894218952
[No author name available],"Proceedings of the 9th International Symposium on Linear Drives for Industry Applications, LDIA 2013",2014,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894151549&partnerID=40&md5=4ef08c41bd02842f2fb6ffb648efd7e6","The proceedings contain 407 papers. The topics discussed include: research of construction of US agriculture information system; constructing an O2O service quality appraisal system based on fuzzy comprehensive evaluation method; MCMC analysis for the number of hurricanes; study of Internet banking in innovative engineering; library information delivery system based on regular expression in innovative engineering; researches on switching-based circuit theory and fault; modeling of irregular particles based on ball filling method; modeling of mobile agent-based heterogeneous distributed database access; research on realizing method of image file on computer based on multimedia technique; design and implementation of 3D facial animation based on MPEG-4; and method for blood vessel extraction in retinal images using morphological top-hat and kirsch operator.",,,2-s2.0-84894151549
[No author name available],"Proceedings of the 9th International Symposium on Linear Drives for Industry Applications, LDIA 2013",2014,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894113652&partnerID=40&md5=c8d695076f376ba7c0e13ce587fe611d","The proceedings contain 407 papers. The topics discussed include: research of construction of US agriculture information system; constructing an O2O service quality appraisal system based on fuzzy comprehensive evaluation method; MCMC analysis for the number of hurricanes; study of Internet banking in innovative engineering; library information delivery system based on regular expression in innovative engineering; researches on switching-based circuit theory and fault; modeling of irregular particles based on ball filling method; modeling of mobile agent-based heterogeneous distributed database access; research on realizing method of image file on computer based on multimedia technique; design and implementation of 3D facial animation based on MPEG-4; and method for blood vessel extraction in retinal images using morphological top-hat and kirsch operator.",,,2-s2.0-84894113652
"Damkliang K., Nanphan P., Mamodee T.","A prototype of calligraphy application design for students on tablet computer",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893961138&doi=10.4028%2fwww.scientific.net%2fAMM.490-491.747&partnerID=40&md5=1461059c41850e1d60df6c91b1128e4d","This paper proposes an architectural design of a prototype for handwriting practice application for pre-primary school students, 4 to 6 years old, on Android tablet computer. The application provides mechanisms for alphabets validation and score calculation. The application also provides handwriting tutorial animation for motivating the students. © (2014) Trans Tech Publications, Switzerland.","Alphabet; Architectural design; Calligraphy; Handwriting; Practice; Tablet computer",,2-s2.0-84893961138
"Takayama S., Xu J., Sakazawa S., Aizawa S.","An easy-to-use authoring tool to create attractive animation for embodied agents and its applications to education",2014,"2014 IEEE 3rd Global Conference on Consumer Electronics, GCCE 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946688046&doi=10.1109%2fGCCE.2014.7031125&partnerID=40&md5=8ed0de4d381c0b502c775c1f8c29cbbf","Targeted at non-professional content creators, this paper presents an easy-to-use tool to create attractive animation for embodied agents just the same as professional directors. Unlike conventional methods that must manually synchronize gestures with speech in many key frames and design many facial textures for expression, our novel authoring system allows the user to semi-automatically create animation in only about 10% of the time required for manual animation. In our authoring tool, when the user inserts a gesture from the motion database into a specific speech segment, the synchronized gesture is generated in terms of both duration and timing. In addition, when the user selects a point on the circumplex model of affect, a facial expression with emotion is generated based on the Facial Action Coding System (FACS) technique (Ekmanet al., 1978). Furthermore, through applications to education, we show that an agent with highlighted gestures or intense expressions created by our authoring tool is more effective than video lectures for improving student comprehension and motivation. © 2014 IEEE.",,"Animation; Consumer electronics; Education computing; Face recognition; Gesture recognition; Speech; Authoring systems; Circumplex models; Content creators; Conventional methods; Facial Action Coding System; Facial Expressions; ITS applications; Motion database; Computer keyboards",2-s2.0-84946688046
"Elleithy S.","Neural gas based 3D normal mesh compression",2014,"Proceedings of 2014 9th IEEE International Conference on Computer Engineering and Systems, ICCES 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946688200&doi=10.1109%2fICCES.2014.7030927&partnerID=40&md5=c99214f85d9abad2299c097b358ae1c0","The recent widespread of processing and transmitting 3D model in various fields such as computer graphics, animations and visualization calls an essential need for efficient geometry mesh compression technique that became more crucial. This paper explores a progressive compression technique for 3D normal meshes geometry by utilizing one of competitive learning methods. The introduced technique is based on multi-resolution decomposition which was obtained by wavelet transformation. Then the coefficients are quantized by neural gas algorithm as a vector quantizer which improves the visual quality of the reconstructed geometry mesh. Our experiments show that the explored technique out performs the state-of-art techniques in Terms of visual quality of compressed meshes. © 2014 IEEE.","3D Geometry processing; Competitive learning; mesh compression; neural gas; vector quantization","Geometry; Three dimensional computer graphics; Vector quantization; Wavelet decomposition; 3d geometry processing; Competitive learning; Mesh compression; Multi resolution decomposition; Neural gas; Neural gas algorithms; Progressive compression; Wavelet transformations; Computer graphics",2-s2.0-84946688200
"Wang P., Lau R.W.H., Pan Z., Wang J., Song H.","An Eigen-based motion retrieval method for real-time animation",2014,"Computers and Graphics (Pergamon)",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889642382&doi=10.1016%2fj.cag.2013.11.008&partnerID=40&md5=95295d478d48195ef832699605805c61","Research on real-time 3D animation is attracting a lot of attention in recent years due to the popularity of emerging applications such as distributed virtual environments and computer games. One of the important issues in real-time animation is that the existing motion retrieval techniques generally have a high matching time because they are typically based on matching time-series, making them less suitable for use with large motion databases. In this paper, we propose a different approach to motion retrieval, called Eigen-based Motion Retrieval (or EigenMR), to address this limitation of the existing methods by performing motion retrieval in the transform domain instead of the time domain. To differentiate the motion of different body parts, we propose to perform the matching on individual body parts as well as on the whole body. Our approach has the important advantage that each body part can be represented by an index of fixed size, consisting of a number of eigenvectors and the corresponding eigenvalues. As a result, our approach has constant time complexity based on the number of motion files in the database instead of the size of the database. The experimental results show that our approach is both efficient and accurate compared with some of the latest methods. When applied to a motion database of 4 GB in size, our method requires approximately 20% of the standard time, making it more suitable for real-time animation. © 2013 Elsevier Ltd. All rights reserved.","Eigenspace retrieval; Motion retrieval; Real-time animation; Real-time motion retrieval","Constant time complexity; Distributed Virtual Environments; Eigenspaces; Emerging applications; Motion retrieval; Real-time animations; Real-time motion; Transform domain; Database systems; Distributed computer systems; Eigenvalues and eigenfunctions; Time domain analysis; Animation",2-s2.0-84889642382
"Jia L., Afshari S., Mishra S., Radke R.J.","Simulation for pre-visualizing and tuning lighting controller behavior",2014,"Energy and Buildings",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890954620&doi=10.1016%2fj.enbuild.2013.11.063&partnerID=40&md5=ec59fcc646d36791cac65194ab382bca","We present a computer graphics simulation framework to pre-visualize and tune the parameters of an advanced lighting controller for a given illuminated environment. The objective is to show that the simulation framework makes it easy for a user to predict the controller's behavior and modify it with minimal effort. Our methodology involves off-line pre-computation of lightmaps created from photorealistic rendering of the scene in several basis lighting configurations, and the subsequent combination of these lightmaps in a video game engine. We demonstrate our framework in a series of experiments in a simulation of a conference room currently under physical construction, showing how the controller can be easily modified to explore different lighting behaviors and energy use tradeoffs. The result of each experiment is a computer-generated animation of the lighting in a room over time from a single viewpoint, accompanied by estimated measurements of source input, light sensor output, and energy usage. A secondary objective is to match the simulation as closely as possible to a real physical environment with physical electric light sources and sensors. We demonstrate this calibration in a highly controlled lighting research environment, showing how measurements of source and sensor specifications enable the output of the virtual sensors in the simulation to match the outputs of real sensors in the physical room when applying the same control law in both cases. Our research is aimed at both lighting designers seeking to quantitatively predict real-world controller behavior, and control algorithm researchers seeking to visualize results and explore design tradeoffs in realistic use cases. Furthermore, these simulation tools can aid in the benchmarking of candidate daylighting and lighting control algorithms for a given space. © 2013 Elsevier B.V.","Computer graphics; Daylighting; Energy harvesting; Environmental simulation; Lighting control systems; Smart buildings; Smart lighting","Computer-generated animations; Environmental simulation; Lighting configurations; Lighting controls; Photorealistic rendering; Physical environments; Simulation framework; Smart lightings; Algorithms; Animation; Commerce; Computer graphics; Control theory; Controllers; Daylighting; Electric lighting; Energy harvesting; Experiments; Intelligent buildings; Light sources; Sensors; Virtual reality",2-s2.0-84890954620
"Henry J., Shum H.P.H., Komura T.","Interactive formation control in complex environments",2014,"IEEE Transactions on Visualization and Computer Graphics",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891512482&doi=10.1109%2fTVCG.2013.116&partnerID=40&md5=74fd16ce8bf624d40eb9b13924731e93","The degrees of freedom of a crowd is much higher than that provided by a standard user input device. Typically, crowd-control systems require multiple passes to design crowd movements by specifying waypoints, and then defining character trajectories and crowd formation. Such multi-pass control would spoil the responsiveness and excitement of real-time control systems. In this paper, we propose a single-pass algorithm to control a crowd in complex environments. We observe that low-level details in crowd movement are related to interactions between characters and the environment, such as diverging/merging at cross points, or climbing over obstacles. Therefore, we simplify the problem by representing the crowd with a deformable mesh, and allow the user, via multitouch input, to specify high-level movements and formations that are important for context delivery. To help prevent congestion, our system dynamically reassigns characters in the formation by employing a mass transport solver to minimize their overall movement. The solver uses a cost function to evaluate the impact from the environment, including obstacles and areas affecting movement speed. Experimental results show realistic crowd movement created with minimal high-level user inputs. Our algorithm is particularly useful for real-time applications including strategy games and interactive animation creation. © 2014 IEEE Published by the IEEE Computer Society.","Animation; Gaming; Input devices and strategies; Three-dimensional graphics and realism","Complex environments; Formation control; Gaming; Input devices and strategies; Interactive animations; Real-time application; Single-pass algorithm; Three-dimensional graphics and realism; Computer control systems; Control systems; Knobs; Real time control; Animation",2-s2.0-84891512482
"Su J.-M., Huang C.-F.","An easy-to-use 3D visualization system for planning context-aware applications in smart buildings",2014,"Computer Standards and Interfaces",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890120654&doi=10.1016%2fj.csi.2012.07.004&partnerID=40&md5=7ea76318cabee2d9ccf82c659c48b88b","With the proliferation of wireless sensor network technologies, the context-aware applications of smart environments have become more and more popular. However, time-consuming and labor-intensive works hamper the development of smart building applications. Therefore, application developers need the proper software platforms to efficiently design the applications. Much research currently proposed the design approaches based on low-level concerns and the real-world deployments based on high-level programming abstraction are rare. Accordingly, the pressing issue is how to offer the easy-to-use tools with acceptable performance to rapidly and easily design the application scenarios for non-technical application users. Therefore, this study focuses on the application-layer simulation to propose a Visualization System of Context-aware Application Scenario Planning (VS-CaSP) for assisting non-technical developers and end-users in rapidly and easily designing the application scenario of smart buildings and in performing the acceptable and predictable simulation and evaluation. VS-CaSp applies rule-based and 3D visualization techniques to offer a 3D authoring environment integrated with real Zigbee sensor devices, where designers are able to rapidly construct immersive 3D buildings and easily plan the context-aware application scenario via GUI tool based on proposed three-tier rule hierarchy, to visually simulate and verify the planned scenario via virtual and real sensor devices, and to repeatedly modify the control strategies to enhance the deployment effectiveness. The experimental results show that VS-CaSP is easy to use for the support of quickly designing smart building applications, but not professional enough for developments of 3D modeling, animation, and rule expression. Accordingly, it is workable and expected to prove beneficial to non-technical users. © 2012 Elsevier B.V.","3D visualization; Application scenario planning; Context-aware; Smart buildings; Wireless sensor network; ZigBee","3-D visualization systems; 3D Visualization; Acceptable performance; Application scenario; Authoring environments; Context aware applications; Context-Aware; High-level programming; Animation; Application programs; Computer applications; Computer programming; Design; Intelligent buildings; Sensors; Three dimensional; Tools; Visualization; Wireless sensor networks; Zigbee; Three dimensional computer graphics",2-s2.0-84890120654
"Terwee C.B., Coopmans C., Peter W.F., Roorda L.D., Poolman R.W., Scholtes V.A.B., Harlaar J., de Vet H.C.W.","Development and validation of the computer-administered animated activity questionnaire to measure physical functioning of patients with hip or knee osteoarthritis",2014,"Physical Therapy",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893498222&doi=10.2522%2fptj.20120472&partnerID=40&md5=d3075a63bc8eafa4f182e7c2e599610a","Background. Physical functioning of patients with hip or knee osteoarthritis is measured by self-report questionnaires and performance-based tests. However, performance-based tests often are not feasible. Objective. The aim of this study was to develop a computer-administered questionnaire (ie, the Animated Activity Questionnaire [AAQ]) to measure physical functioning in patients with hip or knee OA. By showing animations of activities, the influence of the patient's own reference frame is minimized. The AAQ measures the same aspects of physical functioning as performance-based tests do. Design. This was a development and preliminary validation (cross-sectional) study. Methods. A pilot version of the AAQ was developed using motion capture to analyze the movement of a person performing 7 daily activities. Different animations of the same activity were made with 2 to 5 levels of difficulty. For each activity, participants were asked to choose one animation that best corresponds to their own way of performing the activity. A preliminary validation study was performed to compare the AAQ with validated self-report questionnaires (Knee Injury and Osteoarthritis Outcome Score, Hip Disability and Osteoarthritis Outcome Score, and questionnaires on walking, stair climbing, and rising and sitting down) and performance-based tests (walking, Timed ""Up & Go"" Test, Timed Stair Test) in 33 patients with hip or knee osteoarthritis. Results. As expected, the AAQ showed a correlation above.70 (.79, 95% confidence interval=.61-.89) with the total score of the performance-based tests. On the subscore level, the results were partly as expected. Fifty-eight percent of the participants preferred the AAQ over self-report questionnaires and performance-based tests. Limitations. The findings need to be replicated in larger samples of patients because the sample size of the study was rather small. Conclusion. The AAQ might be a good alternative for measuring physical functioning of patients with hip or knee osteoarthritis. The AAQ can easily be adapted for use in other patient populations. However, further development and validation are needed. copy; 2014 American Physical Therapy Association.",,"aged; article; cross-sectional study; daily life activity; disability; female; hip osteoarthritis; human; knee osteoarthritis; male; methodology; middle aged; pathophysiology; quality of life; questionnaire; teaching; validation study; very elderly; videorecording; Activities of Daily Living; Aged; Aged, 80 and over; Computer-Assisted Instruction; Cross-Sectional Studies; Disability Evaluation; Female; Humans; Male; Middle Aged; Osteoarthritis, Hip; Osteoarthritis, Knee; Quality of Life; Questionnaires; Video Recording",2-s2.0-84893498222
"Carlton N.R.","Digital culture and art therapy",2014,"Arts in Psychotherapy",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890286109&doi=10.1016%2fj.aip.2013.11.006&partnerID=40&md5=93c148b2f4268ff98a53a0a35485e29f","This essay outlines the relevance of digital culture to art therapy, including native skills and activities that art therapists must grasp to become culturally competent with increasing numbers of clients. Because digital media use has expanded into daily life, the effects can be seen in routine communication and behaviors as well as influences in our language and thought processes. Children, youth, and adults are affected as 'computer commons' affiliation has increased for the general population of American society. Art therapists use digital media, both as tools of professional practice such as email, archiving, research, personal creativity, networking, and advertising practices, and as clinical tools including photography, animation, video, digital tablets, and augmented-reality software for therapeutic processes and outcomes. The author draws attention to digital divides previously identified in art therapy that illustrate ambivalence toward this media, including perceptions of traditional versus synthetic materials use, affordability and access issues, and a paucity of graduate education opportunities for adaptation and skill-building. Multicultural lenses of generational evolution, reactionary bias against technology, perils of colonized economy divides, and extreme responses including blind resistance or gullible adaptation to new media all provide arguments for art therapists to build ongoing competencies in and comprehension of computer technologies. Research and education can evolve to support art therapists' informed and developmental learning with digital media in order to remain contemporary and to participate in ever-expanding creative palettes and conscious human-technology interfaces. © 2013 Elsevier Ltd.","Conscious media adaptation; Digital art therapy; Digital media use in art therapy; Digital natives; Multicultural considerations for digital media","adaptation; art therapy; article; computer; computer program; creativity; data base; drawing; e-mail; ego; human; identity; information technology; Internet; interpersonal communication; leisure; personal experience; photography; priority journal; problem solving; reading; social media; videorecording; virtual reality",2-s2.0-84890286109
"Li F., Chen X., Wang L., Zhao Q.","Canopy-frame interactions for umbrella simulation",2014,"Computers and Graphics (Pergamon)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890249836&doi=10.1016%2fj.cag.2013.10.022&partnerID=40&md5=76d1934484d30bf1bc8db4bcfca5361a","We resolve the canopy-frame interactions for umbrella simulation in this paper. An umbrella is a heterogeneous articulated system that consists of a frame composed of elastic ribs and other rigid components, and a fabric-made canopy bound to the frame. The canopy interacts with the frame through the binding constraint and collisions. Since the flexible canopy and elastic ribs have different stiffness, we employ a bi-time-step scheme to obtain tractable performance. It evolves the frame with a smaller time step but the canopy with a larger time step. We resolve the canopy-frame interactions by changing the canopy positions and velocities at an interval of the larger time step, which is limited to be an integer multiple of the smaller time step. These displacements and velocity changes are transferred into opposite impulses and forces, and applied to the frame in the following smaller time steps. With these transformations, the solution of the canopy-frame interactions is independent of the difference of the two time steps. Moreover, we adopt a projection-based algorithm to accurately detect the canopy-frame collisions. We demonstrate the effectiveness of our method with several umbrella animations. Crown Copyright © 2013 Published by Elsevier Ltd. All rights reserved.","Bi-time-step; Canopy-frame interactions; Projection-based collision detection; Umbrella simulation","Bi-time-step; Canopy position; Collision detection; Rigid components; Time step; Umbrella simulation; Velocity changes; Computer graphics; Human computer interaction",2-s2.0-84890249836
"Fiorentino M., Uva A.E., Gattullo M., Debernardis S., Monno G.","Augmented reality on large screen for interactive maintenance instructions",2014,"Computers in Industry",28,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894899161&doi=10.1016%2fj.compind.2013.11.004&partnerID=40&md5=7c6c8bf14b4a63475a3a8b9d1febecfc","We present an empirical study that evaluates the effectiveness of technical maintenance assisted with interactive augmented reality instructions. Our approach consists in an augmented visualization on a large screen and a combination of multiple fixed and mobile cameras. We used commercially available solutions. In our test, 14 participants completed a set of 4 maintenance tasks based on manual inspections of a motorbike engine. Tool selection, removal of bolts, and part dis\assembly, are supported by visual labels, 3D virtual models and 3D animations. All participants executed similar operations in two modalities: paper manuals and augmented instructions. Statistical analyses proved that augmented instructions reduced significantly participants' overall execution time and error rate. © 2013 Elsevier B.V. All rights reserved.","Augmented reality; Computer aided task guidance; Large screen instruction; Maintenance",,2-s2.0-84894899161
"Liu X., Pang W.-M., Qin J., Fu C.-W.","Turbulence simulation by adaptive multi-relaxation lattice boltzmann modeling",2014,"IEEE Transactions on Visualization and Computer Graphics",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891526575&doi=10.1109%2fTVCG.2012.303&partnerID=40&md5=1c50bf4b1815205bd3ce1c801b180b8f","This paper presents a novel approach to simulating turbulent flows by developing an adaptive multirelaxation scheme in the framework of lattice Boltzmann equation (LBE). Existing LBE methods in graphics simulations are usually insufficient for turbulent flows since the collision term disturbs the underlying stability and accuracy. We adopt LBE with the multiple relaxation time (MRT) collision model (MRT-LBE), and address this issue by enhancing the collision-term modeling. First, we employ renormalization group analysis and formulate a new turbulence model with an adaptive correction method to compute more appropriate eddy viscosities on a uniform lattice structure. Efficient algebraic calculations are retained with small-scale turbulence details while maintaining the system stability. Second, we note that for MRT-LBE, predicting single eddy viscosity per lattice node may still result in instability. Hence, we simultaneously predict multiple eddy viscosities for stress-tensor-related elements, thereby asynchronously computing multiple relaxation parameters to further enhance the MRT-LBE stability. With these two new strategies, turbulent flows can be simulated with finer visual details even on coarse grid configurations. We demonstrate our results by simulating and visualizing various turbulent flows, particularly with smoke animations, where stable turbulent flows with high Reynolds numbers can be faithfully produced. © 1995-2012 IEEE.","lattice Boltzmann models; multiple relaxation time model; turbulence modeling; Turbulence simulation","Adaptive corrections; Lattice Boltzmann equations; Lattice boltzmann models; Multiple-relaxation time; Multiple-relaxation-time models; Renormalization group analysis; Small scale turbulence; Turbulence simulation; Computational fluid dynamics; Relaxation time; Reynolds number; Statistical mechanics; System stability; Turbulence models; Turbulent flow; Viscosity; Computer simulation",2-s2.0-84891526575
"Yasuda T., Adachi A., Ohkura K.","Self-organized flocking of a mobile robot swarm by topological distance-based interactions",2014,"2014 IEEE/SICE International Symposium on System Integration, SII 2014",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946692855&doi=10.1109%2fSII.2014.7028020&partnerID=40&md5=f75f5cb144212a9cfc347799f7c4fb0e","Self-organized flocking of robotic swarms has been investigated for approximately twenty years. Most studies are based on a computer animation model named Boid. The Boid model reproduces flocking motion by three simple behavioral rules: collision avoidance, velocity matching, and flock centering. Boid-like flocking motions are generated from the interacting positions and orientations of neighboring robots. This paper investigates a technique by which interactions among neighboring robots in a swarm are determined by their topological separations. The effectiveness of the proposed method is quantitatively evaluated in real robot experiments. © 2014 IEEE.",,"Animation; Topology; Behavioral rules; Computer animation; Flocking motion; Mobile robot swarms; Real robot; Robotic swarms; Topological distance; Velocity-matching; Robots",2-s2.0-84946692855
"Dang-Nguyen D.-T., Boato G., De Natale F.G.B.","Revealing synthetic facial animations of realistic characters",2014,"2014 IEEE International Conference on Image Processing, ICIP 2014",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934337601&doi=10.1109%2fICIP.2014.7026078&partnerID=40&md5=20e96c5ea975714921c927a317938d72","Given the recent development of advanced multimedia techniques able to support the creation of realistic computer generated characters, there is the parallel need of automatic tools allowing users to verify the source of the multimedia data they are observing, thus discriminating between artificial and natural information. In this paper, we focus on video representing human beings and we propose a novel method to identify computer generated characters by analysing the evolution of the face model in chronological order. Experimental results show that photorealistic facial animations, which are usually performed following fixed patterns, can be distinguished from natural ones, which follow much more complicated and various geometric distortions. © 2014 IEEE.","3D Face Modelling; Computer Generated Animations; Video Forensics","3D face modelling; Chronological order; Computer generated characters; Computer-generated animations; Facial animation; Geometric distortion; Multimedia techniques; Video forensics; Image processing",2-s2.0-84934337601
"Fechteler P., Paier W., Eisert P.","Articulated 3D model tracking with on-the-fly texturing",2014,"2014 IEEE International Conference on Image Processing, ICIP 2014",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949928677&doi=10.1109%2fICIP.2014.7025812&partnerID=40&md5=86e85f10796492b0dbfe362c1a52cff6","In this paper, we present a framework for capturing and tracking humans based on RGBD input data. The two contributions of our approach are: (a) a method for robustly and accurately fitting an articulated computer graphics model to captured depth-images and (b) on-the-fly texturing of the geometry based on the sensed RGB data. Such a representation is especially useful in the context of 3D telepresence applications since model-parameter and texture updates require only low bandwidth. Additionally, this rigged model can be controlled through interpretable parameters and allows automatic generation of naturally appearing animations. Our experimental results demonstrate the high quality of this model-based rendering. © 2014 IEEE.","Pose estimation; Texture synthesis","Computer graphics; Image processing; Visual communication; Automatic Generation; High quality; Low-bandwidth; Model parameters; Model-based Rendering; Pose estimation; Telepresence applications; Texture synthesis; Three dimensional computer graphics",2-s2.0-84949928677
"Bao G.B., Zhang K.X., Zhao H.","Research on information technology with modeling and simulating of video grid",2014,"Advanced Materials Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892727437&doi=10.4028%2fwww.scientific.net%2fAMR.886.655&partnerID=40&md5=7ec800c76fb52e0857743a5c392ea403","Based on video grid structure, A Video Grid model was established using AnyLogic simulation software. First, the components required for modeling functions are introduced, and then create a model entity, video service processes, animation and analysis chart. Simulation results show that the AnyLogic-based video grid model, the model parameters can be adjusted, not only from the macroscopic dynamic observation of the entire system dynamics, but also from the microscopic measurement of the specified components. The construction of the actual video grid can provide a decision support. © (2014) Trans Tech Publications, Switzerland.","Anylogic; Model components; Modeling; Simulation; Video grid","Anylogic; Macroscopic dynamics; Microscopic measurement; Model components; Modeling and simulating; Simulation; Simulation software; Video grid; Animation; Computer science; Computer software; Decision support systems; Information technology; Materials science; Models; Computer simulation",2-s2.0-84892727437
"Sakamoto M., Uchida Y., Nagatomo M., Zhang T., Susaki H., Ito T., Yoshinaga T., Ikeda S., Yokomichi M., Furutani H.","Remarks on Four-Dimensional Probabilistic Finite Automata",2014,"Proceedings - 7th International Conference on Signal Processing, Image Processing and Pattern Recognition, SIP 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949926910&doi=10.1109%2fSIP.2014.9&partnerID=40&md5=70e53e053e6c2736a96a0eb2290dd7e5","This paper is a study of four-dimensional automata. Recently, due to the advances in many application areas such as dynamic image processing, computer animation, augmented reality (AR), and so on, it is useful for analyzing computation of four-dimensional information processing (three-dimensional pattern processing with time axis) to explicate the properties of four-dimensional automata. From this point of view, we have investigated many properties of four-dimensional automata and computational complexity. On the other hand, the class of sets accepted by probabilistic machines have been studied extensively. As far as we know, however, there is no results concerned with four-dimensional probabilistic machines. In this paper, we introduce four-dimensional probabilistic finite automata, and investigate some accepting powers of them. © 2014 IEEE.",,"Animation; Augmented reality; Finite automata; Pattern recognition; Signal processing; Application area; Computer animation; Dynamic image processing; Probabilistic finite automata; Probabilistic machines; Three-dimensional patterns; Time axis; Image processing",2-s2.0-84949926910
"Thirumoorthi C., Karthikeyan T.","Easy optimization of image transformation using sFFT algorithm with HALIDE language",2014,"Proceedings of 2014 International Conference on Contemporary Computing and Informatics, IC3I 2014",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949922445&doi=10.1109%2fIC3I.2014.7019723&partnerID=40&md5=eba8a6e32a3b8d36e40be7d2768b8b97","Image processing technologies are widely used in all fields. Computing Image (2D and 3D) has many techniques and algorithms for the process of image transformation. Programming languages like C++, Matlab and for graphics CUDA, open CL are the efficient languages that are used in the current image processing technology. For video and computer aided animations, programmers spend a lot of time and money in planning and executing the operations. This research mainly concentrates on process of applying sFFT Algorithm for signal processing in Halide. This paper evaluates the performance of image processing using Halide. © 2014 IEEE.","Halide; Image processing; Matlab; SFFT algorithm; Signal processing","Algorithms; C++ (programming language); Computational linguistics; MATLAB; Signal processing; Computer aided; Current image; Halide; Image processing technology; Image transformations; Image processing",2-s2.0-84949922445
"Rodriguez-Cerezo D., Henriques P.R., Sierra J.-L.","Attribute grammars made easier: EvDebugger a visual debugger for attribute grammars",2014,"2014 International Symposium on Computers in Education, SIIE 2014",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946692216&doi=10.1109%2fSIIE.2014.7017699&partnerID=40&md5=0f79ca34ae703959b1da42ee4c330795","Compiler construction courses are usually considered by the students as a difficult subject of the Computer Science degree. The main problem found by the students is to fully understand the theoretical concepts taught during the course and its practical application to build a compiler. In this paper, we present a platform for the development and debugging of language processors based on attribute grammar-oriented specifications. The main aim of this tool is to help students to design their own language processors, supported by the visual debugger included. The animations provided by EvDebugger show, in an attractive way, how the attribute evaluation process is performed. In this way, students are able to solve design problems, improve the effectiveness and efficiency of their language processors and understand their operation through experimentation and debugging provided with the software tool. Besides, we performed an assessment study with students of a Compiler Construction course whose results are presented and discussed in this paper. © 2014 IEEE.","Attribute Grammars; Compiler Generator; Debugger; Education in Compiler Construction","Computational linguistics; Context sensitive grammars; Education; Program compilers; Program debugging; Visual languages; Attribute evaluation; Attribute grammars; Compiler construction; Compiler generators; Debuggers; Design problems; Effectiveness and efficiencies; Language processors; Students",2-s2.0-84946692216
"Teplá M., Klímová H.","Photosynthesis in dynamic animations",2014,"Journal of Chemical Education",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892582331&doi=10.1021%2fed300213h&partnerID=40&md5=1e174e4d1214a4f64a1b9f79bd1de548","Our contribution provides information about an educational program called ""Photosynthesis in Dynamic Animations"". This program was created in Adobe flash and is designed for high school chemistry students. © 2013 The American Chemical Society and Division of Chemical Education, Inc.","Biochemistry; Computer-Based Learning; High School/Introductory Chemistry; Multimedia-Based Learning; Photosynthesis",,2-s2.0-84892582331
"Kumar V., Kumar A.S., Kalaimagal S.","C GLANCE: An interactive way to learn C",2014,"Proceedings - IEEE 6th International Conference on Technology for Education, T4E 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946685926&doi=10.1109%2fT4E.2014.48&partnerID=40&md5=859decf84ac38b4ba57bc4390a8d66d3","The importance of learning the C programming language in the engineering curriculum is a well-known fact among engineering students, faculty, programming language instructors and also software companies involved in campus placements. A strong conceptual awareness of C concepts provides a good foundation for learning other programming languages and also a better understanding of hardware since most of the system software has been written using C. Although C is taught in the curriculum, it is difficult to make all the students interested to continue practice writing programs in order to sharpen their C programming skills. This paper proposes software called as C Glance which is basically an educational software, which can be used to learn the C programming language in an efficient and progressive way. © 2014 IEEE.","Animation; Examiner; Installation; Search Engine","Ada (programming language); Animation; Computational linguistics; Computer programming languages; Curricula; Education; Engineering education; Installation; Search engines; Students; C programming; Educational software; Engineering curriculum; Examiner; Interactive way; Software company; System softwares; Writing projects; C (programming language)",2-s2.0-84946685926
"Guo D., Shao L., Han J.","Feature-based motion compensated interpolation for frame rate up-conversion",2014,"Neurocomputing",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885857670&doi=10.1016%2fj.neucom.2013.06.045&partnerID=40&md5=1a1fb0f7a1412712ba3eceba7e731c88","In this paper, we propose to use feature point matching and mesh-based motion estimation for frame rate up-conversion. Matched local feature points between successive frames in a video sequence are employed to constitute a discrete and sparse motion field. Afterwards, a proximity-constraint marking process regulates the raw correspondence set to a content/motion adaptive nodal set. These correspondences are organized by a Delaunay triangular mesh so as to generate a dense motion field through the affine transformation. The experimental results demonstrate that the proposed scheme outperforms three other popular methods in terms of both subjective and objective evaluations. They also suggest that the proposed method is more suitable for videos containing a complex motion field. © 2013 Elsevier B.V.","Feature matching; Frame rate up-conversion (FRUC); Mesh-based motion estimation; Motion-compensated frame interpolation (MCFI)","Affine transformations; Feature matching; Feature point matching; Frame rate up-conversion; Motion compensated interpolation; Motion-compensated frame interpolations; Subjective and objective evaluations; Triangular meshes; Animation; Motion compensation; Motion estimation; algorithm; article; computer system; correspondence analysis; frame rate up conversion; image processing; image quality; information processing; measurement accuracy; motion analysis system; motion compensated frame interpolation; nonlinear system; priority journal; videorecording",2-s2.0-84885857670
"Lin C.-Y., Hsien S.-L.","Effects of interactive technology on home-based rehabilitation for chronic stroke patient",2014,"Advanced Materials Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891601507&doi=10.4028%2fwww.scientific.net%2fAMR.831.446&partnerID=40&md5=90af5e046b26509579fe6cb7af67913e","This study aimed to apply low-cost interactive technology to home-based rehabilitation training for patients suffering from chronic stroke. It also focuses on discussing the results of the integration of interactive computer game training with home-based rehabilitation training in helping these patients. We conducted an experiment following the reversal design of single-subject research, in which a patient suffering with chronic stroke was given home-based rehabilitation training. In addition to interactive computer technology, the experiment also involved the adoption of a low-cost Wii Remote controller as an infrared receiver and a homemade infrared emitter supplemented by computer animation software to investigate the outcome of a home-based rehabilitation program. Data analysis is based on collection of points by the participant throughout the experiment and adopting visual analysis to discuss the outcome of interactive technology integrated with home-based rehabilitation. The results of this research show that the subject was able to stand on one leg for a few seconds longer than prior to the adoption of interactive technology integrated with home-based rehabilitation. Furthermore, parents of this patient and the therapists involved believe that the research and this innovative approach improved the patient's performance in rehabilitation. The subject not only showed better motivation with regard to rehabilitation but also greater independence and enhanced capability of integrating into society. © (2014) Trans Tech Publications, Switzerland.","Chronic stroke; Home-based rehabilitation; Interactive technology; Reversal design; Wii Remote controller","Chronic stroke; Home-based; Innovative approaches; Interactive computer game; Interactive technology; Rehabilitation programs; Rehabilitation training; Wii remote; Animation; Building materials; Civil engineering; Experiments; Remote control; Technology; Telecontrol equipment; Patient rehabilitation",2-s2.0-84891601507
"Liu J., Li J., Liu H.","Study on the application of computer in industrial design",2014,"Advanced Materials Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891542056&doi=10.4028%2fwww.scientific.net%2fAMR.850-851.697&partnerID=40&md5=43ebbb7e67a91b9b26e790e2ad4a4efd","In the modern art design, the computer can not only help people design more exciting, more vivid animation, fashion and advertising products and so on, but also can carry on the automatic control to reduce the people's working pressure as much as possible and improve the work efficiency and work quality. But computer utilization in modern art design can be also improved greatly, how to combine them to one better, which is many scholars researching the problem. This paper, from the relationship between modern art and computer discusses the advantages of applying computer technology to modern artistic design and the reasonable measures. © (2014) Trans Tech Publications, Switzerland.","Art; Computer; Design; Impact","Art; Artistic designs; Computer technology; Impact; Modern art designs; Work efficiency; Work quality; Working pressures; Animation; Automation; Computers; Control; Design; Product design; Testing; Computer applications",2-s2.0-84891542056
"Rehman M., Sharif M., Raza M.","Image compression: A survey",2014,"Research Journal of Applied Sciences, Engineering and Technology",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891295168&partnerID=40&md5=f42aeb9e2da93c52d9e038e06e71273d","Image Compression is a demanding field in this era of communication. There is a need to study and analyze the literature for image compression, as the demand for images, video sequences and computer animation has increased at very high rate so that the increment is drastically over the years. Multimedia data whether graphics, audio, video data which is uncompress requires considerable transmission bandwidth and storage capacity. So this leads to the need of compression of images and all multimedia applications to save storage and transmission time. In this study we discuss different compression algorithms used to reduce size of images without quality reduction. © Maxwell Scientific Organization, 2014.","Compression; Image; Lossless; Lossy; Review",,2-s2.0-84891295168
"Sun Z.T.","Animation type analysis after using computer 3D animation technology",2014,"Advanced Materials Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904209961&doi=10.4028%2fwww.scientific.net%2fAMR.971-973.1553&partnerID=40&md5=d276f53ac3f22cf337c8b33094f83705","Type of computer animation using 3D technology can be divided under three seeds that mimic 2D animation, imitating traditional 3D animation, imitating real movie. Mimic 2D animation and imitating real movie are infinitely close with 2D animation and real film movie. Imitating traditional 3D animation is completely different from the traditional three-dimensional animation, which won the visual realism. ""Visual realism"" to get that 3D animation and real film movie stood on the same competition platform. © (2014) Trans Tech Publications, Switzerland.","3D animation; Animation type; Visual reality","Motion pictures; 2D animation; 3D animation; 3D technology; Computer animation; Three-dimensional animations; Type analysis; Visual realism; Visual realities; Animation",2-s2.0-84904209961
"Fei M.","Computer animation process research",2014,"Advanced Materials Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902271465&doi=10.4028%2fwww.scientific.net%2fAMR.926-930.3018&partnerID=40&md5=4ea2ef404355805c0ef2321fa31e8aaa","The article talks about the history of animation, focusing on the production of computer-assisted animation effects. Include key technologies of early modeling animation, motion control, distribution plan and other colors. Tracking the most advanced animation techniques and methods. Finally, introduce the application of the major animation techniques. © (2014) Trans Tech Publications, Switzerland.","Animation; Model; Process","Materials; Materials science; Models; Processing; Animation effects; Animation techniques; Computer animation; Computer assisted; Key technologies; Model animations; Animation",2-s2.0-84902271465
"Wieczorek B., Sobieraj A., Pająk K.","Modelling and computer animation of geodetic field work",2014,"International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946404382&partnerID=40&md5=53a718a9418e692be88d72241cd011f9","3D modelling of objects is a way of obtaining information, while the visualization of geospatial data is becoming a production task in the scope of surveying. Visualization of geospatial data provides effective tools for analysis information about the land surface, land cover, its features, properties etc. Computer animations, both 2D images and 3D are becoming additional, expected and clear form for presentation results of geodetic field work. The most frequently presented part of reality in the 3D is terrain relief displayed as Digital Terrain Model – DTM. DTM is now an essential product to start many investment processes. The second most commonly mapped geographical components in 3D are buildings. Terrain modelling is becoming increasingly important, both in scientific and commercial applications. The third dimension of the map enables to recreate reality. Developing relief, buildings and other features is possible because of new technologies like LIDAR or RTK. Terrain modeling is becoming increasingly important, both in scientific and commercial applications. Using GIS tools enables to conduct studies on geomorphological aspect of landform research, creating cut-edge visualization and many more. The third dimension of the map facilitates intuitive 3D perception, interaction and collaboration with geospatial data. Observer gets an impression of viewing reality. The use of 3D technology allows for the transition from the flat paper map to the virtual map and build three-dimensional models. © SGEM2014.","3D modeling; Animations; DEM; LIDAR; Visualization","Animation; Data visualization; Flow visualization; Geodesy; Geographic information systems; Landforms; Optical radar; Surveying; Visualization; 3-d modeling; Commercial applications; Computer animation; DEM; Digital terrain model; Geomorphological aspects; Terrain modelling; Three-dimensional model; Three dimensional computer graphics",2-s2.0-84946404382
"Tang J., Zeng Y.L.","Intelligent traditional chinese hairstyle system in computer animation",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896270750&doi=10.4028%2fwww.scientific.net%2fAMM.530-531.915&partnerID=40&md5=bc26aabef9b09104af60cc426ca58e94","Traditional Chinese hairstyle is an important part of the traditional Chinese culture, which provides rich material for computer animation. The creation process of traditional Chinese hairstyle model in computer animation is complex working and time-consuming. This study establishes the traditional Chinese hairstyle database, which covers from Tang Dynasty to Qing Dynasty. According to the characteristics of the traditional Chinese hairstyle, this study develops an Intelligent Traditional Chinese Hairstyle System by MEL, which can display the condition of traditional Chinese hairstyle models in real time and change attributes related with models efficiently. The system is the combination among computer technology, animation art and traditional Chinese culture. It will improve the efficiency and quality in the computer animation creation. © (2014) Trans Tech Publications, Switzerland.","Computer animation; Maya embedded language; Modeling; Traditional chinese hairstyle","Information technology; Models; Chinese culture; Computer animation; Computer technology; Creation process; Hairstyle modeling; Maya embedded languages; Tang Dynasty; Traditional chinese hairstyle; Animation",2-s2.0-84896270750
"Wu J.-J.","Computer animation of structural mode shapes",2014,"International Conference on Multimedia Computing and Systems -Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928729606&doi=10.1109%2fICMCS.2014.6911399&partnerID=40&md5=1b79c5bdaf6826246b68ef66bbeb4f5c","In the existing post-processing procedures, the graphical parameters, such as view angle, position of the projection plane,..., etc., cannot be changed arbitrarily at any time when the animation of the structural mode shapes is in progressing. Therefore, it is difficult to observe the detail of the structural mode shapes on the computer screen. To solve the above-mentioned problem, some computer programs and a graphical user interface are developed, based on the free vibration theory and the computer graphical theory, for providing an interactive way between the users and the computer. By using the last computer programs, the real-time animation of structural mode shapes with arbitrary graphical parameters can be easily observed at any time. Because the vibration amplitudes and frequencies for structural mode shapes are adjustable in the developed computer programs, the detail of any part of any structural mode shape can be easily observed from the computer screen no matter whether the vibration amplitudes and frequencies are very small or very large. © 2014 IEEE.","Computer animation; Free vibration; Mode shape; Post-processing technique","Computation theory; Graphical user interfaces; User interfaces; Computer animation; Free vibration; Mode shapes; Post-processing procedure; Post-processing techniques; Real-time animations; Structural mode shape; Vibration amplitude; Animation",2-s2.0-84928729606
"Dib H.N., Adamo-Villani N., Yu J.","Computer animation for learning building construction management: A comparative study of first person versus third person view",2014,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916631067&doi=10.1007%2f978-3-319-13293-8_10&partnerID=40&md5=de2f1818bf43833068feb8351fa01c2a","The paper reports a study that investigated the effect of egocentric versus exocentric view in an educational animation whose goal was to teach undergraduate students the various tasks that a construction manager performs in the field. Specifically, the study aimed to determine the effect of perspective view on students’ subject learning and preference. Findings show that while students have a preference on perspective view, the perspective view does not have a significant effect on students’ learning outcomes. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2014.","Educational animation; Egocentric view; Exocentric view","Animation; E-learning; Online systems; Personnel training; Project management; Social networking (online); Building construction; Comparative studies; Computer animation; Construction manager; Egocentric view; Exocentric view; Perspective views; Undergraduate students; Students",2-s2.0-84916631067
"Wang J., Juhlin O., Johnson E.-C.B.","Previsualization with computer animation (previs): Communicating research to interaction design practice",2014,"Proceedings of the 26th Australian Computer-Human Interaction Conference, OzCHI 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945380123&doi=10.1145%2f2686612.2686616&partnerID=40&md5=2211ae6c2c600e5cd7907de2757d4bcc","In recent years there has been growing concern about a gap between HCI research and industrial practitioners. We review methods proposed in HCI for enhancing communication between researchers and designers, and propose previsualization animation, borrowed from the movie industry, as an additional means to support this communication. The potential benefit is investigated through a process of designing and producing an animated film for a design research project at a furniture company and gathering initial user feedback. We argue that a technique that accounts for interaction dynamics and provisionality and that supports brevity and mobility can communicate design research in an inspirational manner to practitioners. However we also identified a remaining difference in the two groups' expectations about the animation, with researchers wanting it to be more researchlike and practitioners wanting it to be more productionoriented. Copyright 2014 ACM.","Animation; Communication; Interaction design; Previsualization; Research-practice gap","Animation; Communication; Design; Industrial research; Interactive computer systems; Motion pictures; Communicating researches; Computer animation; Industrial practitioners; Interaction design; Interaction dynamics; Potential benefits; Previsualization; Remaining differences; Human computer interaction",2-s2.0-84945380123
"Huang Z., Gong G., Han L.","Physically-based modeling, simulation and rendering of fire for computer animation",2014,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904380691&doi=10.1007%2fs11042-012-1273-z&partnerID=40&md5=943f07bd6637569e20672b10368fab68","We give an up-to-date survey on techniques and methods for fire simulation in computer graphics. Physically-based method prevails over traditional non-physical methods for realistic visual effect. In this paper, we explore visual simulation of fire-related phenomena in terms of physically modeling, numerical simulation and visual rendering. Firstly, we introduce a physical and chemical coupled mathematical model to explain fire behavior and motion. Several assumptions and constrains are put forward to simplify their implementations in computer graphics. We then give an overview of present methods to solve the most complicated processes in numerical simulation: velocity advection and pressure projection. In addition, comparisons of these methods are also presented respectively. Since fire is a participating medium as well as a visual radiator, we discuss techniques and problems of these issues as well. We conclude by addressing several open challenges and possible future research directions in fire simulation. © 2012 Springer Science+Business Media New York.","Blackbody radiation; Chemical reaction; Fire; Navier-Stokes equations; Physically-based simulation; Visual adaption","Animation; Antenna radiation; Chemical reactions; Computer graphics; Computer simulation; Navier Stokes equations; Numerical models; Black body radiation; Computer animation; Coupled mathematical modeling; Participating medium; Physically based modeling; Physically-based simulation; Visual adaptions; Visual simulation; Fires",2-s2.0-84904380691
"Liu L.Y.","Design and implementation of public service announcement based on computer animation",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906513611&doi=10.4028%2fwww.scientific.net%2fAMM.602-605.3421&partnerID=40&md5=d2b2e60b07a13b66ba14282b85604613","We illustrate the design and implementation of the whole process of public service announcement in the paper by using the tools such as Animo 6.0, including: literary writing of the script, design of roles and background, the design of continuity, animation drawing, the processing and coloring of outline sketch, the synthesis of animation, the synthesis of sound and picture, and special effects, etc. © (2014) Trans Tech Publications, Switzerland.","Animation; Animo 6.0; Public service announcement","Animation; Public relations; Animo 6.0; Computer animation; Design and implementations; Public services; Whole process; Design",2-s2.0-84906513611
"Gero A., Zoabi W.","Computer animation and academic achievements: Longitudinal study in electronics education",2014,"International Journal of Engineering Education",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908498032&partnerID=40&md5=74b87e49427cfdda59152d613fe58890","An animation based learning unit on the subject of the bipolar junction transistor was recently developed for electronics students in a two-year college in Israel. A previous research had indicated a significant gap between the achievements of students in a basic course studying the electronic device through animation and those of students studying it through static diagrams drawn on the board. The longitudinal study described in this paper examined whether animation based learning of the bipolar junction transistor has a long term effect on students' achievements and whether this gap is maintained in advanced courses covering analog electronics. Findings indicate that even a year after the completion of the basic course, the achievements of students who have studied the transistor through animation continue to be significantly higher than their peers', and that animation based learning promotes retention and transfer. © 2014 TEMPUS Publications.","Computer animation; Electrical engineering education; Electronic devices; Retention; Transfer","Academic achievements; Computer animation; Electronic device; Electronics educations; Longitudinal study; Retention; Transfer; Electrical engineering",2-s2.0-84908498032
"Sun Z.T.","On the visual bias in computer 3D animation technology",2014,"Advanced Materials Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904151733&doi=10.4028%2fwww.scientific.net%2fAMR.971-973.1673&partnerID=40&md5=9cecdd171f1000606f69ea8c39c66c4a","Technology is not neutral, any technology has a certain value orientation. The Digital and Virtual which inherent in 3D animation technology, leading 3D animation images reflect a new level of visual orientation. Spectacle victory narrative is mainly reflected in its visual highlight. Since the mid-1990s, 3D animated film is developing rapidly, it has quickly emerged as the most attractive contemporary animated film types. In 1995, Toy Story, proclaimed the birth of a new form of animation: 3D animated movie dazzling debut. Since then, 3D animation with their stunning visuals and its box office receipts continue to refresh people's viewing expectations, while also constantly re-adjust the success criteria of an animated movie. To some extent, 3D animation has replaced traditional 2D animation constitutes a major form of contemporary animated films. © (2014) Trans Tech Publications, Switzerland.","3D animation; Spectacle; Visual","Motion pictures; Technology; 2D animation; 3D animation; Box-office receipts; New forms; Spectacle; Value orientation; Visual; Animation",2-s2.0-84904151733
"Groff J., Boucheix J.-M., Lowe R.K., Argon S., Saby L., Alauzet A., Paire-Ficout L.","Don't miss your train! Just follow the computer screen animation: Comprehension processes of animated public information graphics",2014,"Computers in Human Behavior",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884554687&doi=10.1016%2fj.chb.2013.08.010&partnerID=40&md5=73a755c99eb04d47ac93eb0f8903b1bb","Computer graphic animated information displays have the potential to communicate public information in situations where normal announcement types are ineffective. This study used eye tracking techniques to analyze comprehension mechanism of event-related information on railway traffic disruptions presented via different graphic formats presented on computer screen. 86 participants were asked to understand series of traffic disruption messages delivered via four purely visual formats: Static simultaneous, Static sequential, Animated simultaneous and Animated sequential. Across these four conditions, and contrary to the most common materials used in the studies on animation comprehension, the sequentiality and the animated properties of the entities of the presentation were not confounded. Results revealed the Animated sequential displays were the most effective presentation type. Eye tracking data showed why an animation facilitates comprehension of public information graphics: it enhances processing strategies which provide the best condition for segmenting and composing the causal chain of the events provided in the message. © 2013 Elsevier Ltd. All rights reserved.","Animation formats; Comprehension; Disruption messages; Eye movements; Public information","Common materials; Comprehension; Comprehension process; Disruption messages; Information display; Processing strategies; Public information; Traffic disruption; Computer graphics; Eye movements; Animation",2-s2.0-84884554687
"Altıparmak K.","Impact of computer animations in cognitive learning: differentiation",2014,"International Journal of Mathematical Education in Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908495580&doi=10.1080%2f0020739X.2014.914256&partnerID=40&md5=41410034506785d0001f20d100f82d3a","In mathematic courses, construction of some concepts by the students in a meaningful way may be complicated. In such circumstances, to embody the concepts application of the required technologies may reinforce learning process. Onset of learning process over daily life events of the student's environment may lure their attention and may enable them to gain from the preliminary knowledge. Therefore, a good initiation may be realized in the course of meaningful learning. The underlying meaning of the abstract concepts by computer animations may be accomplished in class environments. That study is conducted searching out to discover the effects of animations over the learning process in mathematic courses. The study was performed over the 58 university freshman students selected randomly. Thirty-two students constituted the experiment group and 26 students constituted the control group. Computer animations-aided instruction model in constructive form were applied on the experiment group and non-computer-aided instruction model in constructive form were implemented on the control group. Student academic success via a test method developed by explored group with confidence rate.819 (Cronbach's alpha) revealed that data were evaluated by two-way variance analyses. The findings provided from the final test shows that the experiment group students were significantly higher according to the control group students in terms of academic success average scores. Computer animations were observed to be significant to assimilate the derivative concept in a discrete way over the students, to appeal their attention, animations of real life events observed to transform the abstract meanings in the events to a concrete manner. Students of whom the concrete stage is constructed meaningfully found to be tactful in reaching to semi-abstract and abstract stages. © 2014 Taylor & Francis.","animations in mathematics; computer assisted learning; differentiation",,2-s2.0-84908495580
"Guo Y.D.","Three dimensional animation design and production based on computer graphics",2014,"Advanced Materials Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902260988&doi=10.4028%2fwww.scientific.net%2fAMR.926-930.1767&partnerID=40&md5=8759601e2af5a52e41ef24e94dbc0cab","This paper presents the design and production of 3D animation based on computer graphics. The main work includes the animated scene design, role design and the post production using computer software. Design software tools are Autodesk Maya and Adobe EffectsCS4. Scene design and role design are very important parts of the animation form. The good scene and role design can improve the animation level and effect; make the animation and rendering a fuller picture. In addition, rich post production can promote the additional value of animation works, has a great influence on the final result of the whole works of taste and art. © (2014) Trans Tech Publications, Switzerland.","Animation; Character design; Post production; Scene design","Animation; Three dimensional computer graphics; 3D animation; Autodesk mayas; Character designs; Design softwares; Scene designs; Three-dimensional animations; Design",2-s2.0-84902260988
"Sahu A., Mandla N.S., Yogesh G.","Advantages of computer generated evidence: Forensic animation in Indian judiciary system",2014,"Indian Journal of Forensic Medicine and Toxicology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930830709&doi=10.5958%2fj.0973-9130.8.1.029&partnerID=40&md5=1ef0f27f73ad9407e1134238a7bcf899","Judiciary animation or Forensic animation or legal animation is computer based perform of turning professional reports, detailed information of witness, police investigator and forensic experts into 3D animated recreation of scene of crime. Since 1985 Forensic animation has been used in foreign nation's judiciary system till now with new advance technologies. Gradually judiciary animation is becoming increasingly legal animation, which is used as visual tool to help jurors and other viewers understand the facts of crime without using long verbal information about the case and create lasting visual impression that is retained in juror's memories longer than a verbal presentation. This paper describes range of animation evidence which are mostly presented in courtroom using digital media and how computer generated animation is valuable to our judiciary system. © 2014, Indian Journal of Forensic Medicine and Toxicology. All rights reserved.","Computer generated evidence; Digital evidence; Forensic animation; Forensic science; Judiciary animation","Article; computer aided design; computer generated evidence; crime; decision making; Forensic animation; forensic medicine; forensic science; India; information technology; jurisprudence; legal evidence; reliability; verbal communication; visual information; witness",2-s2.0-84930830709
"Zhao X.","Computer aided design application in animation design",2014,"Journal of Chemical and Pharmaceutical Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924694121&partnerID=40&md5=241622a0cafa2ee597e52667f90e976b","Animation technology is a powerful platform in mass media, communication and education. Progressive developments in technological tools together with expansion of knowledge and skills have resulted in an increase in variety, as well as production speed of modern animation products. Research has shown that animation products are increasingly used in education at different levels and subject areas. Art design teaching, gradually develop its powerful function, and promote the continuous development of art design disciplines, also promote the school of art design teaching, scientific research ability and education efficiency enhances unceasingly, development to provide more professional talents for the society. Areas such as research methods, the role of supervisors, research subject trends, and presentation of outcomes are evaluated and recommendations are made to enhance the quality of training to ensure that graduates are fully qualified, and can in turn utilize animation as an educational tool in other subject areas. © 2014, Journal of Chemical and Pharmaceutical Research. All rights reserved.","Streaming","Acoustic streaming; Animation; Computer aided design; Education; Animation designs; Continuous development; Educational tools; Powerful functions; Production speed; Research subjects; Scientific researches; Technological tools; Design; animation design; Article; computer aided design; creativity; drawing; human; Internet; knowledge; learning; process design; skill; teaching; thinking",2-s2.0-84924694121
"Shan W.","Computer aided design application in animation design",2014,"Energy Education Science and Technology Part A: Energy Science and Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931275105&partnerID=40&md5=57cba1b7c329d67698c03188b04f0379","Animation technology is a powerful platform in mass media, communication and education. Progressive developments in technological tools together with expansion of knowledge and skills have resulted in an increase in variety, as well as production speed of modern animation products. Research has shown that animation products are increasingly used in education at different levels and subject areas. Art design teaching, gradually develop its powerful function, and promote the continuous development of art design disciplines, also promote the school of art design teaching, scientific research ability and education efficiency enhances unceasingly, development to provide more professional talents for the society. Areas such as research methods, the role of supervisors, research subject trends, and presentation of outcomes are evaluated and recommendations are made to enhance the quality of training to ensure that graduates are fully qualified, and can in turn utilize animation as an educational tool in other subject areas. © Sila Science. All Rights Reserved.","Animation design; Streaming","Acoustic streaming; Animation; Computer aided design; Education; Animation designs; Continuous development; Educational tools; Powerful functions; Production speed; Research subjects; Scientific researches; Technological tools; Design",2-s2.0-84931275105
"Hwang S.-H., Chun S.-H.","Computer graphical score and music education: Application to music animation machine MIDI player",2014,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898412987&doi=10.1007%2f978-3-642-41674-3_173&partnerID=40&md5=93e060f73389b7cf79c7e4c3e1f12ce0","This paper shows how a graphical score has greater effect on music education than the traditional score in general courses at a university level. Generally students have difficulty in understanding music scores, thus music courses as a general selective at the university level need to provide them efficient ways to understand music. In this regard, a computer graphical score using a MIDI player is a very effective way to make students understand music structure and movement fast and accurately overcoming limitations in music class through only listening audio. Thus, this paper investigates how this computer technique can be used for music classes and discusses various cases a MIDI player plays a role in music education. © 2014 Springer-Verlag Berlin Heidelberg.","Graphical score; MIDI Player; Music Animation Machine; Music Education; Music programs","Animation; Computer science; Students; Computer techniques; Graphical score; MIDI Player; Music education; Music program; Music scores; Music structures; University levels; Audio acoustics",2-s2.0-84898412987
"Ahsun U.W., Narod F.","Enhancing conceptual understanding of the ‘chemistry of life’ at the “A”-level through use of computer animations",2014,"Chemistry: The Key to our Sustainable Future",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956792827&doi=10.1007%2f978-94-007-7389-9_15&partnerID=40&md5=2048d8cc274c3884fa9d3db921601781","“Chemistry of Life” is a topic that forms part of the “Applications of Chemistry” section introduced as a compulsory part in the Cambridge International Examinations(CIE) Advanced Level (‘A’-Level) chemistry syllabus in 2007. In the present study, an attempt was made to enhance students’ conceptual understanding of the “Chemistry of Life” through use of computer animations. The research was carried out in a girls’ private secondary school, located in the central region of Mauritius. The sample consisted of 14 girls of age 18–19 years, who were preparing to sit for the CIE ‘A’-Level examinations in November 2011. The study was carried out through an action research involving three cycles; each cycle included three lessons during which computer animations were used. Data were collected through observation checklists, achievement tests, and a students’ questionnaire. The findings have clearly revealed that use of computer animations has impacted positively on students’ motivation, interest, and engagement, leading to enhanced conceptual understanding, as evidenced by data gathered through observation checklistsand students’ questionnaire. These results were further supported by an improvement in students’ performance in the achievement tests administered at the end of the second and third cycles, even though the concepts taught became increasingly more difficult from Cycles 1 to 2 and 3. Further, it was found that “cues and labeling”, proper design in terms of colour and graphics, as well as embedded “voice questions” can all play a crucial role in helping learnersto retrieve information from computer animations, and, to develop understanding of the concepts understudy. Last but not least, results have also indicated that learner-controlled interactive computer animations are most effective in enhancing students’ motivation, interest, and conceptual understanding as compared to non-interactive ones. © Springer Science+Business Media Dordrecht 2014.",,,2-s2.0-84956792827
"Bernardini J., Davis D.J.","Evaluation of a computer-guided curriculum using animation, visual images, and voice cues to train patients for peritoneal dialysis",2014,"Peritoneal Dialysis International",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921312926&doi=10.3747%2fpdi.2012.00304&partnerID=40&md5=04a57cc93d5c5822488efa9dabf530ae","Background: Training patients to perform peritoneal dialysis (PD) at home is key to good patient outcomes. Currently, no validated curriculum based on education concepts is available in the public domain, and training is not standardized. Few nurses are prepared to be effective trainers. The present study was designed to evaluate the efficiency and effectiveness of PD training using a new cycler designed with animation, visual images, and voice cues and provided by a qualified PD nurse with a standardized script to guide the trainer. Methods: The study recruited 40 participants, including individuals naive to dialysis and current automated PD (APD) patients. Participants with visual, hearing, or touch impairments were purposely included to reflect the disabilities common to the general APD population. The participants encompassed a range of self-reported computer and technical experience and education levels. Experienced training nurses trained each participant, one on one, for 4 – 8 hours during a single day; the nurses followed the standardized script as the participants progressed through the cycler training curriculum. The pace of training was adjusted to meet individual abilities and needs. Participants were evaluated by the training nurse at the end of the training session for their proficiency in meeting the learning objectives. Results: All 40 participants completed the 1-day training and successfully met all task objectives by the end of the day. Participant ages ranged from 23 to 73 years (mean: 53.8 ± 11 years), with the women (50 ± 12 years) being significantly younger than the men (57 ± 9 years, p = 0.05). Among the participants, 90% had visual impairments; 40%, hearing impairments; and 45%, touch impairments. Twenty-nine participants (73%) had multiple impairments. Median training time was 7 ± 0.13 hours, with a range of 5 – 8.25 hours. We found no correlation between the number of hours needed for successful training and age (r = 0.30). Training time did not differ significantly by sex, disability, computer or technical experience, or education level. The required training time was less for participants with previous PD experience (6.5 ± 0.7 hours) than for those naive to dialysis (7 ± 0.8 h), but at p = 0.056, the difference just missed being statistically significant. Conclusions: The most striking finding is that, despite a variety of barriers to learning, all 40 participants were able to meet all the stated objectives of the study with 4 – 8 hours of training. Ability to meet the study objectives was not less for participants with limited education or limited technical or computer experience than for those with more education or more advanced technical and computer skills. Thus, the highly technical aspect of the new cycler is able to promote learning for a wide range of learners. The cycler provides automated instruction using audio, video, and animation, and those features, combined with a qualified training nurse using a standardized script, appear to be both efficient and effective. © 2014 International Society for Peritoneal Dialysis.","Animation; Computers; Curriculum; PD training; Visual images; Voice guidance","adult; aged; Article; clinical article; curriculum; female; hearing impairment; human; male; motor performance; nurse; patient education; peritoneal dialysis; priority journal; touch; training; treatment outcome; verbalization; visual impairment; association; audiovisual aid; evaluation study; middle aged; patient education; procedures; teaching; videorecording; young adult; Adult; Aged; Audiovisual Aids; Computer-Assisted Instruction; Cues; Curriculum; Female; Humans; Male; Middle Aged; Patient Education as Topic; Peritoneal Dialysis; Video Recording; Young Adult",2-s2.0-84921312926
"Hamdan M.N., Ali A.Z.M.","The implication of realistic levels of the computer based animation character: A conceptual framework",2014,"Proceedings of the 9th International Conference on Computer Science and Education, ICCCSE 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911944531&doi=10.1109%2fICCSE.2014.6926490&partnerID=40&md5=a9f336e83ee1b2026a265a0f90d0c5a6","The talking-head animation is an instructional approach that helps students in linguistic learning, especially in the pronunciation aspect. However, the use of talking-head animation has caused some emotional uneasiness among students when the design and realistic level of the animated characters were too human-like. This phenomenon is known as Uncanny Valley and was corroborated through a research by a Japanese robotics expert named Masahiro Mori in the year 1970, who also produced a graph explaining this phenomenon. Hence, this paper proposed a conceptual framework for talking-head computer animation, specifically for pronunciation learning and discussing the significance of choosing an appropriate animation character to avoid the emotionally unsettling effects of the Uncanny Valley phenomenon. The framework was developed based on theories, principles and literature review. This paper also suggests further studies to affirm the framework proposed. © 2014 IEEE.","realistic levels; Talking-head; uncanny valley",,2-s2.0-84911944531
"Kry P.G., Lee J.","Guest editor's introduction: Special section on the ACM SIGGRAPH/eurographics symposium on computer animation (SCA)",2014,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890328356&doi=10.1109%2fTVCG.2014.3&partnerID=40&md5=7ca23b6dbc461422e8984cda5bf35f2c","This special section presents expanded versions of three of the best papers from the 11th Annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA 2012), which was held in Lausanne, Switzerland, from 29-31 July 2012. SCA has established itself as the premier conference dedicated specifically to innovations in the software and technology of computer animation. SCA 2012 received 80 submissions and each submission was reviewed by at least three members of the international program committee. After a thorough online discussion, the 72-member international program committee decided on the 27 full papers and nine short presentation papers accepted for the final program. Out of 27 full papers, the symposium's Best Papers Award Committee selected one best paper, two runner-ups, and four honorable mentions. The selection was informed by the original reviews and the conference presentations. We are delighted to present three out of the six very best papers of SCA 2012 invited for this special section. Each of the invited papers contains a minimum of 30 percent new material and received at least three reviews, including one reviewer not among the original SCA reviewers. © 1995-2012 IEEE.",,,2-s2.0-84890328356
"Luciani A., Allaoui A., Castagné N., Darles E., Skapin X., Meseure P.","A new way to model animation of topological transformations",2014,"GRAPP 2014 - Proceedings of the 9th International Conference on Computer Graphics Theory and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907343360&partnerID=40&md5=055f10439378df39502b8b2261f64e34","Animation of topological transformations, such as fractures, cracks, tears, crumbles or fragmentations, is a new challenge in Computer Graphics and Animation. We propose a new way to model and animate topological changes, allowing the programmer to design any type of topological changes and animation mapping. This model is based on organizing the complex modeling activity into three clearly defined simpler sub-activities: 1) point-based animation, which enables a wide variety of possible temporal phenomena; 2) topological-based modeling, which makes it possible to manage a wide variety of shapeindependent topologies and topological transformations; 3) free, non predetermined, association between both, and 4) final output of an animated geometrical model exhibiting any complex behavior. We experimented the proposed method by modeling tearing effects on deformable garments, on rifts and crack effects on 3D objects, and finally by modeling imaginary and paradoxical topological transformations associated with realistic Physics-based animation. Besides improving the consistency and the robustness of the modeling process of such complex phenomena, our aim is also to offer a user-centered programming environment to the Computer Graphics and Animation programmers and designers, to enlarge their modeling and experimentation abilities, and to stimulate their creativity.","Combinatorial Maps; Computer Animation; Fractures; Particle-based Animation; Topological Transformations","Animation; Computer graphics; Computer programming; Cracks; Fracture; Combinatorial maps; Computer animation; Computer graphics and animations; Geometrical modeling; Physics-based animation; Point-based animation; Programming environment; Topological transformation; Topology",2-s2.0-84907343360
"Thalmann D., Poulin P., Lewis J.P.","Editorial: Computer animation and virtual worlds",2014,"Computer Animation and Virtual Worlds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905589411&doi=10.1002%2fcav.1605&partnerID=40&md5=964478cb6a20c50585cd02d47affb750",[No abstract available],,,2-s2.0-84905589411
"Wood A.","Software, animation and the moving image: What’s in the box?",2014,"Software, Animation and the Moving Image: What's in the Box?",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986617360&doi=10.1057%2f9781137448859&partnerID=40&md5=1291f6f59ccb93aebfe5a79c490c0cfe","Software, Animation and the Moving Image brings a unique perspective to the study of computer-generated animation by placing interviews undertaken with animators alongside an analysis of the user interface of animation software. Wood develops a novel framework for considering computer-generated images found in visual effects and animations. © Aylish Wood 2015.",,"Animation; User interfaces; Animation softwares; Computer-generated animations; Computer-generated images; Moving image; Visual effects; Computer software",2-s2.0-84986617360
"Gero A., Zoabi W., Sabag N.","Animation based learning of electronic devices",2014,"Advances in Engineering Education",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897405306&partnerID=40&md5=ae843e0d72dc7ff0e4104b31a2a365e3","Two-year college teachers face great difficulty when they teach the principle of operation of the bipolar junction transistor-a subject which forms the basis for electronics studies. The difficulty arises from both the complexity of the device and by the lack of adequate scientific background among the students. We, therefore, developed a unique learning unit based on computer animation that was tailored to the students' background and qualitatively describes the processes occurring in the transistor. The current research examined the characteristics of the above learning among students at a leading Israeli two-year college. The research, which used quantitative instruments alongside qualitative ones, indicates a significant gap between the achievements of students who studied the subject of the transistor through animation and the achievements of their peers who learned it using static diagrams. Additionally, students who studied the subject through animation express significantly more positive attitudes towards electronics than their peers.","Animation based learning; Attitudes towards electronics; Electrical engineering education","Animation; Electrical engineering; Teaching; Bipolar junctions; College teachers; Computer animation; Electronic device; Positive attitude; Unit-based; Students",2-s2.0-84897405306
"Cheng C., Lu B.A., Umwali M.","Interactive animation construction in virtual environments",2014,"Applied Mechanics and Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913622097&doi=10.4028%2fwww.scientific.net%2fAMM.635-637.515&partnerID=40&md5=4c556cb17d1b10b174716c1c46848b4d","Current mechanical kinematic animation can’t satisfy the requirements of Virtual Environment (VE) based design. The kinematic animation design in VE development platform does not have high level models and mechanisms, the interactive animation designs and developments are very difficult and time consuming. For these reasons, this paper proposes an innovative method for interactive kinematic animation design and development in VE, including dynamic runtime model and execution algorithm for interactive animation. A complex mechanical kinematic mechanism, that is, the engine assembly, is built to validate the animation technology introduced in this paper. © (2014) Trans Tech Publications, Switzerland.","Human-computer interaction; Interactive animation; Kinematic mechanism animation; Virtual assembly; Virtual environment","Animation; Human computer interaction; Kinematics; Manufacture; Virtual reality; Animation designs; Development platform; Engine assembly; High-level models; Innovative method; Interactive animations; Kinematic mechanism; Virtual assembly; Design",2-s2.0-84913622097
"Björk-Willén P., Aronsson K.","Preschoolers ""animation"" of computer games",2014,"Mind, Culture, and Activity",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908554490&doi=10.1080%2f10749039.2014.952314&partnerID=40&md5=1340a75ae76d82c10f52b722dba6fe72","Research on preschool children's computer gaming often focuses on interview data or parental reports, leaving open the examination of children's actual game activity. This study explores how preschool children actually engage in gaming and their degrees of play immersion. Classroom observations of Swedish preschool children's gaming revealed their involvement in computer games took the forms of responding to characters through instructed actions, recycling the game characters' talk, and engaging in dialogues with the game characters as if they were ""real."" These results are discussed in relation to previous research on childrens play, and their implications for future research and educational policy. © Regents of the University of California on behalf of the Laboratory of Comparative Human Cognition.",,,2-s2.0-84908554490
[No author name available],"Proceedings of CGAMES 2014 USA - 19th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",2014,"Proceedings of CGAMES 2014 USA - 19th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912143873&partnerID=40&md5=1883990dda2569b76053357765edfa4f","The proceedings contain 23 papers. The topics discussed include: serious games to promote independent living for intellectually disabled people: starting with shopping; applying game theory rules to enhance decision support systems in credit and financial applications; group tactics utilizing suppression and shelter; choicenet gaming: changing the gaming experience with economics; empirically measuring control quality of gesture input; semi-autonomous digitization of real-world environments; generating dynamic narratives with real time interactions utilizing mobile technology; linguistic implementations in computer game and virtual world design; quantifying software development: applying mobile monetization techniques to your software development process; guided crossword-puzzle games aimed at children with attentional deficit: preliminary results; and client-server assignment in massively multiplayer online games.",,,2-s2.0-84912143873
"Watanabe R., Sakamoto Y.","Fast generation method for computer-generated hologram animation with hidden surface removal using ray tracing method",2014,"JSAP-OSA Joint Symposia, JSAP 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928920232&partnerID=40&md5=7b274d2f9c8aa30d45968e41f2d890ab",[No abstract available],,,2-s2.0-84928920232
[No author name available],"Erratum to Gestures in sign language: Animation and generation in real-time ((Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics))(2014), (482-489), 10.1007/978-3-319-08599-9_90)",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908611782&partnerID=40&md5=172a0f860d2082910336523b8b63fb13",[No abstract available],,,2-s2.0-84908611782
"Oshita M.","Multi-touch interface and motion control model for interactive character animation",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958553852&doi=10.1007%2f978-3-662-43790-2_5&partnerID=40&md5=fdc2656199846b6582a81efb8f09a69e","In this paper, we propose a new method for interactive motion control with a multi-touch interface. A user of our system can touch and drag character's body parts to control its motion. The character's full body motion is driven by our interactive motion control model based on the movement of a few body parts which are directly manipulated by the user via the multi-touch interface. We propose a method for determining 3-dimensional positions of controlled body parts from 2-dimensional touch inputs based on the character's local coordinates and drag speed. We introduce a point-based pose representation which consists of the positions or orientations of a small number of primary body parts. Based on the representation, we develop a motion control model that includes modules for tracking, balance, inter-body interaction, relaxing and self-collision avoidance. The character's pose is reconstructed from the point-based pose representation. We present our experimental results to show that our framework can realize various natural-looking motions. © 2014 Springer-Verlag Berlin Heidelberg.","character animation; computer animation; motion control; multi-touch interface","Animation; Drag; User interfaces; 3-dimensional; Character animation; Computer animation; Full-body motions; Local coordinate; Motion control models; Multi-touch interfaces; Self-collision avoidance; Motion control",2-s2.0-84958553852
"Bailey M., Law C.","A summer blender camp: Modeling, rendering, and animation for high school students",2014,"IEEE Computer Graphics and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898473841&doi=10.1109%2fMCG.2014.4&partnerID=40&md5=c9936a3a24e07b5de491afd1a2e48de1","At Camp Blender, high-school students of varying backgrounds learned how to use the Blender software package to create computer graphics content. In a postclass survey, most of them indicated that the camp affected how they thought about their career path. © 2014 IEEE.","animation; Blender; Camp Blender; computer animation; computer graphics; computer science education; modeling; rendering; STEM; STEM Academy","Animation; Computer graphics; Models; Blender; Camp Blender; Computer animation; Computer Science Education; rendering; STEM; STEM Academy; Blending; adolescent; computer graphics; computer program; decision making; education; human; information science; psychology; questionnaire; student; United States; Adolescent; Career Choice; Computer Graphics; Humans; Information Science; Oregon; Questionnaires; Software; Students",2-s2.0-84898473841
"Hayashi M., Inoue S., Douke M., Hamaguchi N., Kaneko H., Bachelder S., Nakajima M.","T2V: New Technology of Converting Text to CG Animation",2014,"ITE Transactions on Media Technology and Applications",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920881951&partnerID=40&md5=acaf529dda25e8207cb301858d08374f","We have developed a technology that enables the creation of TV-program-like CG animation generated automatically from text-based script. We call this technology ""T2V (Text-To-Vision)"" and have developed a PC application that we call the ""T2V Player."" The application allows users to create animations instantly by simply typing in text in a customary fashion as when writing on a word processor. The T2V Player employs a unique framework with a capability to accommodate any text processing module to realize any type of text-to-animation conversion. The T2V Player is not only an animation tool for writers creating animations from their texts, but also an application of various text-to-vision services such as automatic animation generation form Web sites and other text sources. This paper describes the concept of T2V and the technical specifications of the T2V Player and its benefits. Copyright © 2014 by ITE Transactions on Media Technology and Applications (MTA).","Authoring tool; Computer animation; Text visualization; Text-to-animation; TVML",,2-s2.0-84920881951
"Kim J., Seol Y., Kwon T., Lee J.","Interactive manipulation of large-scale crowd animation",2014,"ACM Transactions on Graphics",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905726502&doi=10.1145%2f2601097.2601170&partnerID=40&md5=25a5988b603388762477a96bd0844e1c","Editing large-scale crowd animation is a daunting task due to the lack of an efficient manipulation method. This paper presents a novel cage-based editing method for large-scale crowd animation. The cage encloses animated characters and supports convenient space/time manipulation methods that were unachievable with previous approaches. The proposed method is based on a combination of cage-based deformation and as-rigid-as-possible deformation with a set of constraints integrated into the system to produce desired results. Our system allows animators to edit existing crowd animations intuitively with real-time performance while maintaining complex interactions between individual characters. Our examples demonstrate how our cage-based user interfaces mitigate the time and effort for the user to manipulate large crowd animation. Copyright © ACM.","Crowd Animation; Data-Driven Animation; Human Motion; Interactive Editing","Deformation; Interactive computer graphics; User interfaces; Animated characters; Crowd animation; Data-driven animation; Human motions; Interactive editing; Interactive manipulation; Manipulation methods; Real time performance; Animation",2-s2.0-84905726502
"Mendi E.","A 3D face animation system for mobile devices",2014,"Journal of Intelligent and Fuzzy Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890668950&doi=10.3233%2fIFS-120690&partnerID=40&md5=f78e139f6323390c5d4fd2ab440e594d","In this paper, we present a 3D face animation system rendered on mobile devices. The system automatically creates realistic facial animation from text input with emotion tags. First, an input string is converted into synthetic voice and phonetic information. Then, 3D head model performs facial movements synchronized to the speech. The proposed system offers an affordable quick solution for applications that require virtual actors speaking text in which human-machine interfaces on mobile devices can profit. © 2014 IOS Press and the authors.","3D facial animation; Human-machine interfaces; Mobile computing; Rendering; Text-to-visual speech synthesis","3d facial animations; Facial animation; Facial movements; Human Machine Interface; Phonetic information; Rendering; Synthetic voices; Virtual actors; Man machine systems; Mobile computing; Mobile devices; Speech synthesis; Three dimensional; Three dimensional computer graphics; Animation",2-s2.0-84890668950
"Wang X., Zhou L., Deng Z., Jin X.","Flock morphing animation",2014,"Computer Animation and Virtual Worlds",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905592645&doi=10.1002%2fcav.1580&partnerID=40&md5=0bdc98b4114a4455a04aa5870c4ce2d7","We propose a new animation technique, called flock morphing, to create special morphing effects between two arbitrary 3D objects by combining the features of 3D morphing and flock animation. Its core idea is first to tetrahedralize the source 3D mesh and regard each tetrahedron as an agent in a flock and then continually generate the flock morphing animation until the target mesh emerges, formed by the same set of tetrahedra. By applying plausible trajectory planning scheme and smooth deformation algorithm, we demonstrate that our proposed method can simultaneously achieve visually desired morphing effects. Copyright © 2014 John Wiley & Sons, Ltd.","Computer animation; Flock morphing; Flock simulation; Shape morphing; Special effects; Tetrahedralization","Geometry; Special effects; Computer animation; Flock simulation; Morphing; Shape morphing; Tetrahedralization; Animation",2-s2.0-84905592645
"Wang S.","Motions blur effects in the process of three-dimensional animation technology research",2014,"Applied Mechanics and Materials",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921358102&doi=10.4028%2fwww.scientific.net%2fAMM.687-691.1170&partnerID=40&md5=622438ce0a1f1825cf00703e0b352366","Three-dimensional animation is an emerging technology and animation technology with the development of computer hardware and software generated. Compared to traditional 2D animation is concerned, 3D animation has more fluid camera movement, mice richer, more delicate visual style, more stunning visual effects. Attributed to computer software to simulate the real effects in terms of the characteristics of three-dimensional animation has the advantage of a great extent, and one of the important effects that simulate real motion blur effect. According to the technical differences between the three-dimensional animation of the various stages of the process, implementation and effects of different motion blur effects are not the same. Based on the study of the basic principles of motion blur effects of the above, and analysis focuses on the different stages of its technology in animation and in effect differences. © (2014) Trans Tech Publications, Switzerland.","Motions blur rendering three-dimensional animation layering Maya","Animation; Computer hardware; Manufacture; Basic principles; Camera movement; Different stages; Emerging technologies; Hardware and software; Technology research; Three-dimensional animations; Visual effects; Three dimensional computer graphics",2-s2.0-84921358102
"Milliez A., Noris G., Baran I., Coros S., Cani M.-P., Nitti M., Marra A., Gross M., Sumner R.W.","Hierarchical motion brushes for animation instancing",2014,"NPAR Symposium on Non-Photorealistic Animation and Rendering",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940103260&doi=10.1145%2f2630397.2630402&partnerID=40&md5=a924de98d1c7e6f6e507ebd58899b3a0","Our work on ""motion brushes"" provides a new workflow for the creation and reuse of 3D animation with a focus on stylized movement and depiction. Conceptually, motion brushes expand existing brush models by incorporating hierarchies of 3D animated content including geometry, appearance information, and motion data as core brush primitives that are instantiated using a painting interface. Because motion brushes can encompass all the richness of detail and movement offered by animation software, they accommodate complex, varied effects that are not easily created by other means. To support reuse and provide an effective means for managing complexity, we propose a hierarchical representation that allows simple brushes to be combined into more complex ones. Our system provides stroke-based control over motion-brush parameters, including tools to effectively manage the temporal nature of the motion brush instances. We demonstrate the flexibility and richness of our system with motion brushes for splashing rain, footsteps appearing in the snow, and stylized visual effects. © ACM 2014.","3D painting; Hierarchical animation; Sketch-based interaction","Computer aided software engineering; 3D animation; Animation softwares; Brush model; Hierarchical representation; Motion data; Sketch-based interactions; Support reuse; Visual effects; Animation",2-s2.0-84940103260
"Fukusato T., Morishima S.","Automatic depiction of onomatopoeia in animation considering physical phenomena",2014,"Proceedings - Motion in Games 2014, MIG 2014",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915754306&doi=10.1145%2f2668064.2668096&partnerID=40&md5=e69044a8a7fac789e0ff6c47c5f6894a","This paper presents a method that enables the estimation and depiction of onomatopoeia in computer-generated animation based on physical parameters. Onomatopoeia is used to enhance physical characteristics and movement, and enables users to understand animation more intuitively. We experiment with onomatopoeia depiction in scenes within the animation process. To quantify onomatopoeia, we employ Komatsu's [2012] assumption, i.e., onomatopoeia can be expressed by n-dimensional vector. We also propose phonetic symbol vectors based on the correspondence of phonetic symbols to the impressions of onomatopoeia using a questionnaire-based investigation. Furthermore, we verify the positioning of onomatopoeia in animated scenes. The algorithms directly combine phonetic symbols to estimate optimum onomatopoeia. They use a view-dependent Gaussian function to display onomatopoeias in animated scenes. Our method successfully recommends optimum onomatopoeias using only physical parameters, so that even amateur animators can easily create onomatopoeia animation. Copyright © ACM.","Onomatopoeia vector; Phonetic symbol vectors; Quantification of onomatopoeia; View-dependent onomatopoeia depiction","Linguistics; Surveys; Vectors; Computer-generated animations; Dimensional vectors; Phonetic symbols; Physical characteristics; Physical parameters; Physical phenomena; Quantification of onomatopoeia; View-dependent; Animation",2-s2.0-84915754306
"Knöbelreiter P., Berndt R., Ullrich T., Fellner D.W.","Automatic fly-through camera animations for 3D architectural repositories",2014,"GRAPP 2014 - Proceedings of the 9th International Conference on Computer Graphics Theory and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907362593&partnerID=40&md5=5f8afaac522618a8132f82ddaa104a1c","Virtual fly-through animations through computer generated models are a strong tool to convey properties and the appearance of these models. In, e.g., architectural models the big advantage of such a fly-through animation is that it is possible to convey the structure of the model easily. However, the path generation is not always trivial, to get a good looking animation. The proposed approach in this paper can handle arbitrary 3D models and then extract a meaningful and good looking camera path. To visualize the path HTML/X3DOM is used and therefore it is possible to view the final result in a browser with X3DOM support.","Camera Path Generation; Fly-through Animation; Space Exploration","Animation; Cameras; Space research; 3D models; Architectural models; Camera animation; Computer-generated models; Path generation; Space explorations; Computer graphics",2-s2.0-84907362593
"Teng C.-C., Robinson G.","Cross platform 3D rendering and animation engine for mobile tablet devices",2014,"12th International Conference on Advances in Mobile Computing and Multimedia, MoMM 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942540285&doi=10.1145%2f2684103.2684137&partnerID=40&md5=3e4e42a4efcd6bd068b34800f8c1f50e","Tablet computers are surpassing desktop and laptop PC combined in market share and becoming an important medium for delivering digital content. They are also equipped with powerful hardware that are capable of rendering high definition 3D graphics which we have seen in the abundance of apps developed for all three of the mainstream tablet platforms: Apple iOS, Google Android and Microsoft Windows. However, delivering cross platform 3D content integrated with each platform's native GUI framework has been challenging because of the non-trivial difference in their development tools. We propose a novel solution to address this issue base on open standard and open source projects. Copyright 2014 ACM.","3D animation; Android; Healthcare; Mobile computing; OpenGL ES; Tablet computer","Animation; Application programming interfaces (API); Competition; Computer graphics; Health care; Medical computing; Mobile computing; Rendering (computer graphics); Three dimensional computer graphics; 3D animation; Android; Animation engine; Development tools; Digital contents; Microsoft windows; Open source projects; Tablet computer; Android (operating system)",2-s2.0-84942540285
"Kato T., Saito S., Kawai M., Iwao T., Maejima A., Morishima S.","Character transfer: Example-based individuality retargeting for facial animations",2014,"22nd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2014, Full Papers Proceedings - in co-operation with EUROGRAPHICS Association",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958074540&partnerID=40&md5=c70ae08d45267bc5002bd939de2a25fc","A key disadvantage of blendshape animation is the labor-intensive task of sculpting blendshapes with individual expressions for each character. In this paper, we propose a novel system ""Character Transfer"", that automatically sculpts blendshapes with individual expressions by extracting them from training examples; this extraction creates a mapping that drives the sculpting process. Comparing our approach with the nave method of transferring facial expressions from other characters, Character Transfer effectively sculpted blendshapes without the need to create such unnecessary blendshapes for other characters. Character Transfer is applicable even the training examples are limited to only a few number by using region segmentations of the face and the blending of the mappings.","Blendshape animation; Blendshape modification; Facial animation; Facial model segmentation; Individual expressions; Mapping blending","Animation; Blending; Computer graphics; Face recognition; Mapping; Visualization; Blendshape; Blendshape animation; Facial animation; Facial model; Individual expressions; Computer vision",2-s2.0-84958074540
"Figueroa P., Arcos J., Rodriguez D., Moreno J., Samavati F.","A pen and paper interface for animation creation",2014,"GRAPP 2014 - Proceedings of the 9th International Conference on Computer Graphics Theory and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907336131&partnerID=40&md5=88ec7848e2aca6f756a8e71656312296","We present a Sketch Based Interface that allows non-expert users to create an animation with sound from a drawing on paper. Current animation programs may be daunting for novice users due to the complexity of their interfaces. In our work, users first draw a sketch on paper. Such a sketch is then processed by our tool and converted to an animation that includes sound. We do this process by means of a predefined set of 2D symbols and words that represent 3D characters, animations, and associated sounds. We present three studies of the proposed system, one related to the accuracy of the recognition process, another on the convenience of our system, and a third on the effect of sound on the final animation.","Animation Systems; Pen and Paper; Sketch-based Interfaces (SBI)","Computer graphics; Drawing (graphics); Paper; 3D characters; Animation programs; Animation systems; Novice user; Paper interfaces; Recognition process; Sketch based Interface; Sketch-based interfaces; Animation; Drawings; Graphic Arts; Paper",2-s2.0-84907336131
"Murray J., Williams B., Hoskins G., Skar S., McGhee J., Gauld D., Brown G., Treweek S., Sniehotta F., Cameron L., Sheikh A., Hagen S.","Can a theory-informed interactive animation increase intentions to engage in physical activity in young people with asthma?",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903129133&doi=10.1007%2f978-3-319-07227-2_28&partnerID=40&md5=e198862e6b83a2a771e10d430da2d1ce","A theoretically-informed interactive animation was developed, using themes drawn from psychology, sociology, applied health research, and narrative theory, which aimed to encourage young people with asthma to engage in physical activity. The animation was evaluated using qualitative and quantitative methods. A web-based Interactive Modelling Experiment was used to evaluate whether the animation was effective in three key areas: knowledge about asthma, inhaler use, and intention to increase physical activity. One-to-one interviews and focus groups were used to evaluate the acceptability of the animation and whether the theoretical basis was effective. Preliminary qualitative findings indicate good acceptability and perceived effectiveness. The quantitative findings are less clear, with a change in simulated activity and inhaler use being found, but with no clear association between these changes and the animation itself. Future work will be carried out to established whether these levels of acceptability and perceived effectiveness are actually translated into behaviour change. © 2014 Springer International Publishing.","Asthma; interactive animation; multidisciplinary; theory-informed; wIME","Behavioral research; Diseases; Health; Human computer interaction; Asthma; Interactive animations; multidisciplinary; theory-informed; wIME; Animation",2-s2.0-84903129133
"Bastos P.T., Fernandes L.A., Strover S.L.","Multimodal facial rigging: Towards a user-adapted animation interface",2014,"Proceedings of the International Conferences on Interfaces and Human Computer Interaction 2014, Game and Entertainment Technologies 2014 and Computer Graphics, Visualization, Computer Vision and Image Processing 2014 - Part of the Multi Conference on Computer Science and Information Systems, MCCSIS 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929431069&partnerID=40&md5=0a231c5241288a6e67aac8f7525fda15","Animating a character's face is a strenuous task due to a lack of a consensus among 3D artists on how to build and provide the controls in an animation-ready facial rig. To help provide a uniform integrative of control interaction to facial animation, a multimodal rig interface system approach was developed and tested in an initial user experiment with 15 digital artists. The users requested improvements and the system was upgraded into a user-adapted multimodal approach that supports a synchronized input of its different interaction modes and a scalable control of the facial deformation. This paper describes the algorithms behind the user-adapted system and a follow-up user experiment with 20 professional expert character animators. The results and user scores help clarify the relevance of the user-adapted multimodal rig interface system approach as an interaction model that decreases the effort required to animate a character's face. Copyright © 2014 IADIS Press All rights reserved.","Algorithms; Animation; Faces; Interaction; Interfaces; Rigging","Algorithms; Animation; Computer games; Computer graphics; Computer vision; Image processing; Interactive computer systems; Interfaces (materials); Animation interfaces; Faces; Facial deformations; Interaction; Interaction model; Multi-modal approach; Rigging; User-adapted systems; Human computer interaction",2-s2.0-84929431069
"Alkawaz M.H., Mohamad D., Rehman A., Basori A.H.","Facial Animations: Future Research Directions & Challenges",2014,"3D Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905980639&doi=10.1007%2fs13319-014-0012-9&partnerID=40&md5=60b436e46450152a5fe3b24c644f4847","Nowadays, computer facial animation is used in a significant multitude fields that brought human and social to study the computer games, films and interactive multimedia reality growth. Authoring the computer facial animation, complex and subtle expressions are challenging and fraught with problems. As a result, the current most authored using universal computer animation techniques often limit the production quality and quantity of facial animation. With the supplement of computer power, facial appreciative, software sophistication and new face-centric methods emerging are immature in nature. Therefore, this paper concentrates to define and managerially categorize current and emerged surveyed facial animation experts to define the recent state of the field, observed bottlenecks and developing techniques. This paper further presents a real-time simulation model of human worry and howling with detail discussion about their astonish, sorrow, annoyance and panic perception. © 2014 3D Research Center, Kwangwoon University and Springer-Verlag Berlin Heidelberg.","Avatars; Crying; Extreme expression; Facial animation; Sweating; Virtual reality","Interactive computer systems; Multimedia systems; Virtual reality; Avatars; Crying; Extreme expression; Facial animation; Sweating; Animation",2-s2.0-84905980639
"Deng H., Zhang J., Chai X.","The design and implementation of Flash animation watermarking",2014,"Proceedings - 2014 IEEE Workshop on Electronics, Computer and Applications, IWECA 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904568862&doi=10.1109%2fIWECA.2014.6845664&partnerID=40&md5=4fc9af22078d0af7a3e403b10ae4caf9","In view of the problems that exist in the copyright protection of Flash, a kind of digital watermark design scheme based on Flash animation is proposed. This scheme chooses the grey scale images including the more copyright information as the watermark information, and inserted them into the SWF files that are read in the byte array. The experiment demonstrates that, while it does not influence the playing result, this scheme can ensure the invisibility, high hiding capacity, etc. that are characteristic of the watermark, and can resist the decompilation attack effectively. © 2014 IEEE.","Flash animation; SWF file; watermarking","Animation; Copyrights; Digital watermarking; Copyright informations; Copyright protections; Design and implementations; Flash animations; Grey scale images; Hiding capacity; SWF file; Watermark information; Computer applications",2-s2.0-84904568862
"Huang Y., Fan Y., Liu W., Wang L.","3D human face modeling for facial animation using regional adaptation",2014,"2014 IEEE China Summit and International Conference on Signal and Information Processing, IEEE ChinaSIP 2014 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929396789&doi=10.1109%2fChinaSIP.2014.6889271&partnerID=40&md5=498a58b6dba152854b8b8c1a0e883a50","This paper proposes an efficient method to reconstruct human face models from 3D face scans using an adaptation algorithm based on regional information. The resulting model can represent individual facial shapes with various expressions, establishing dense correspondences across the whole facial expression sequences. We first initialize the global shape of the face model by implementing RBF interpolation. An efficient vertex mapping is then developed to reconstruct the surface details. The new 3D face are finally created by remapping the scan texture to the facial surface. Experiments show that our method can create effective 3D face models for continuous and realistic 3D facial animation. © 2014 IEEE.","3D face modeling; facial animation; regional adaptation; vertex mapping","Animation; Face recognition; Mapping; 3-D face modeling; 3d facial animations; Adaptation algorithms; Dense correspondences; Facial animation; Rbf interpolations; regional adaptation; Regional information; Three dimensional computer graphics",2-s2.0-84929396789
"Remshagen A., Rolka C.","Contextualized learning tools: Animations and robots",2014,"Proceedings of the 2014 ACM Southeast Regional Conference, ACM SE 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940704614&doi=10.1145%2f2638404.2638458&partnerID=40&md5=b4d27895826f58b32cc8c1b899b2c93d","This paper explores the use of the two contextualized learning tools, animations and educational robots, in an introductory computer science course. We describe our experience when supplementing Greenfoot animation exercises with robotic exercises using the Scribbler and Finch robot, and compare the impact of the different learning tools on students' engagement and performance. We also outline practical considerations concerning the use of Greenfoot animations, Scribbler robots, and Finch robots. Copyright 2014 ACM.","Animations; Computer science education; Contextualized learning; Educational robots; Introductory computer science","Animation; Education; Education computing; Engineering education; Robots; Computer Science Education; Contextualized learning; Introductory computer science; Learning tool; Students' engagements; Educational robots",2-s2.0-84940704614
"Liang X., Han H., Zhang C.","Survey of cloth animation based on physical simulation",2014,"Jisuanji Yanjiu yu Fazhan/Computer Research and Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896034330&doi=10.7544%2fissn1000-1239.2014.20121098&partnerID=40&md5=da702fb570957071a862637244d2e529","With the development of computer graphics technologies, modeling and simulation of cloth animation becomes a common subject in 3D game and animated film related field, and presents the booming trend. The main objective of cloth animation is to obtain rich details of cloth movement and realistic animation. It can be widely used in games, animation and virtual reality, and many other fields. For its complicated nonlinear, anisotropic elastic behavior of the cloth, natural and realistic clothing wrinkles and shapes are difficult to create. The researches on cloth animation based on physical simulation are reviewed and the basic theory, method and framework are summarized. For the widely used methods in cloth animation, the essential process such as modeling, solving dynamics equations, collision detection and response are introduced. With analyzing the related literatures, the advantages, disadvantages and interrelationship of the existing modeling and simulation methods are summarized. Finally, from the demand of realistic performance and real-time interaction, future directions in modeling and simulation of cloth animation are discussed.","Cloth animation; Collision detection; Collision response; Modeling and simulation; Numerical methods","Medium access control; Motion pictures; Numerical methods; Three dimensional computer graphics; Virtual reality; Cloth animation; Collision detection; Collision response; Computer graphics technology; Model and simulation; Modeling and Simulation Methods; Physical simulation; Real time interactions; Animation",2-s2.0-84896034330
"Sagar M., Bullivant D., Robertson P., Efimov O., Jawed K., Kalarot R., Wu T.","A neurobehavioural framework for autonomous animation of virtual human faces",2014,"SIGGRAPH Asia 2014 Autonomous Virtual Humans and Social Robot for Telepresence, SA 2014",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919343918&doi=10.1145%2f2668956.2668960&partnerID=40&md5=5f46817b1f18725e63b755fd171e7030","We describe a neurobehavioural modeling and visual computing framework for the integration of realistic interactive computer graphics with neural systems modelling, allowing real-time autonomous facial animation and interactive visualization of the underlying neural network models. The system has been designed to integrate and interconnect a wide range of computational neuroscience models to construct embodied interactive psychobiological models of behaviour. An example application of the framework combines models of the facial motor system, physiologically based emotional systems, and basic neural systems involved in early interactive behaviour and learning and embodies them in a virtual infant rendered with realistic computer graphics. The model reacts in real time to visual and auditory input and its own evolving internal processes as a dynamic system. The live state of the model which generates the resulting facial behaviour can be visualized through graphs and schematics or by exploring the activity mapped to the underlying neuroanatomy.","Biologically Based; Facial Animation; Learning","Animation; Interactive computer graphics; Neural networks; Physiological models; Real time systems; Virtual reality; Visual communication; Biologically Based; Computational neuroscience; Facial animation; Facial behaviours; Interactive visualizations; Learning; Neural network model; Realistic computer graphics; Mathematical models",2-s2.0-84919343918
"Adamo-Villani N., Cui J., Popescu V.","Scripted animation towards scalable content creation for elearning—a quality analysis",2014,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916594933&doi=10.1007%2f978-3-319-13293-8_1&partnerID=40&md5=d69e4d558d3280646241f2d8905bdb4a","The success of eLearning depends on the broad availability of educational materials that provide a high-quality delivery of high-quality content. One approach for high-quality delivery is to rely on a computer animated instructor avatar that not only speaks, but that also gestures to elucidate novel concepts and to convey an engaging personality that captures and maintains the learners’ focus. The traditional approach of manual key frame animation does not scale, as it requires a substantial time investment as well as artistic talent. We have developed a system that allows animating an instructor avatar quickly and without the prerequisite of artistic talent through a text script. In this paper we quantify the speed/quality tradeoff made by our scripted animation by comparison to manual animation. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2014.","Effective online learning materials; Instructor avatar; Instructor gesture; Manual key frame animation; Scripted animation","Animation; Communication channels (information theory); Online systems; Social networking (online); Content creation; Educational materials; Instructor avatar; Instructor gesture; Key frames; Novel concept; Online learning; Traditional approaches; E-learning",2-s2.0-84916594933
"Cho T., Choi J.-H., Kim H.-J., Choi S.-M.","Vision-based animation of 3D facial avatars",2014,"2014 International Conference on Big Data and Smart Computing, BIGCOMP 2014",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900597613&doi=10.1109%2fBIGCOMP.2014.6741422&partnerID=40&md5=75e66c9a8b1121403bc87e74cecde7e1","We propose a system that classifies a user's facial expressions captured by a webcam and applies notable characteristics of the classified expression to an animated 3D facial avatar. The facial avatar is composed of multiple 3D models where a face model is combined with accessorial models such as facial hair. Such accessorial models are used to decorate the avatar, and are automatically registered with the face model during animation. Our system classifies facial expressions in real time by incorporating Active Shape Models and Support Vector Machines. Users can easily control the facial animation of avatars by just expressing their emotion in front of a webcam. © 2014 IEEE.","3D avatars; facial animation; facial expressions; vision-based control","Animation; Interactive computer graphics; Three dimensional; 3D Avatars; 3D models; Active Shape Models; Face modeling; Facial animation; Facial Expressions; Vision based; Vision based control; Three dimensional computer graphics",2-s2.0-84900597613
"Papagiannakis G., Elissavet G., Trahanias P., Tsioumas M.","A geometric algebra animation method for mobile augmented reality simulations in digital heritage sites",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911917238&doi=10.1007%2f978-3-319-13695-0&partnerID=40&md5=8b5acf9ff0a07bc98273f2a9ca59fbdf","To populate real, ancient cultural heritage sites with low-cost, mobile virtual augmentations has been a demand from cultural professionals established long time ago. In this work we aim to address this demand by introducing three main novelties: a) employing an open, cross-platform mobile framework for 3D virtual character rendering & animation based on open standards b) for outdoors life-size augmented reality simulations c) and enhancing the performance of these simulations by introducing a geometric algebra animation interpolation method adapted for mobile devices. © Springer International Publishing Switzerland 2014.","Augmented reality; Character animation; Computer graphics; Geometric algebra; Virtual characters","Algebra; Animation; Computer graphics; Geometry; Mobile devices; Three dimensional computer graphics; Virtual addresses; 3d virtual characters; Character animation; Cultural heritages; Digital heritage; Geometric Algebra; Interpolation method; Mobile augmented reality; Virtual character; Augmented reality",2-s2.0-84911917238
"Bargteil A.W., Cohen E.","Animation of deformable bodies with quadratic bézier finite elements",2014,"ACM Transactions on Graphics",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902245690&doi=10.1145%2f2567943&partnerID=40&md5=5c7d8e1db24851c0ab71ba64cd138e10","In this article, we investigate the use of quadratic finite elements for graphical animation of deformable bodies. We consider both integrating quadratic elements with conventional linear elements to achieve a computationally efficient adaptive-degree simulation framework as well as wholly quadratic elements for the simulation of nonlinear rest shapes. In both cases, we adopt the Bézier basis functions and employ a co-rotational linear strain formulation. As with linear elements, the co-rotational formulation allows us to precompute per-element stiffness matrices, resulting in substantial computational savings. We present several examples that demonstrate the advantages of quadratic elements in general and our adaptive-degree system in particular. Furthermore, we demonstrate, for the first time in computer graphics, animations of volumetric deformable bodies with nonlinear rest shapes. © 2014 ACM.","Adaptive simulation; Deformable bodies; Finite-element methods; Natural phenomena; Physics-based animation","Animation; Computer graphics; Finite element method; Stiffness matrix; Adaptive simulation; Co-rotational formulation; Computational savings; Computationally efficient; Deformable bodies; Natural phenomena; Physics-based animation; Quadratic finite elements; Deformation",2-s2.0-84902245690
"Kravtsov D., Fryazinov O., Adzhiev V., Pasko A., Comninos P.","Controlled metamorphosis between skeleton-driven animated polyhedral meshes of arbitrary topologies",2014,"Computer Graphics Forum",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894587990&doi=10.1111%2fcgf.12254&partnerID=40&md5=c4971c621ea34175316b0fa7eade4312","Enabling animators to smoothly transform between animated meshes of differing topologies is a long-standing problem in geometric modelling and computer animation. In this paper, we propose a new hybrid approach built upon the advantages of scalar field-based models (often called implicit surfaces) which can easily change their topology by changing their defining scalar field. Given two meshes, animated by their rigging-skeletons, we associate each mesh with its own approximating implicit surface. This implicit surface moves synchronously with the mesh. The shape-metamorphosis process is performed in several steps: first, we collapse the two meshes to their corresponding approximating implicit surfaces, then we transform between the two implicit surfaces and finally we inverse transition from the resulting metamorphosed implicit surface to the target mesh. The examples presented in this paper demonstrating the results of the proposed technique were implemented using an in-house plug-in for Maya™. © 2013 The Authors Computer Graphics Forum © 2013 The Eurographics Association and John Wiley & Sons Ltd.","animation systems; key frame animation; shape morphing, implicit stand-ins, skeletal animation","Mathematical transformations; Musculoskeletal system; Topology; Animation systems; Arbitrary topology; Computer animation; Geometric modelling; Implicit surfaces; Inverse transition; Key frames; Skeletal animation; Animation",2-s2.0-84894587990
"Ciupe V., Lovasz E.C., Reessing M., Henkel V., Gruescu C.M., Zabava E.S.","Interactive animation production by means of advanced image processing",2014,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927780927&doi=10.1007%2f978-3-319-01845-4_33&partnerID=40&md5=26db4f779c8e1b46eae31b4b792b86fd","The paper describes an application developed within the European project thinkMOTION. The project aims to post online, within a digital library, heterogeneous content regarding mechanisms science and related fields. Special systems were developed in Ilmenau, Germany and in Timisoara, Romania, in order to actuate and take photographs of the physical models of the mechanisms to be digitized. The systems consist of a motor mechanically connected to the mechanism by means of a coupling device and electrically connected to a PC or a PLC. A digital still camera is connected to the same computer/controller. The logic of this system is to take a photograph after each rotational increment of 0.9º, thus obtaining a complete 400 images set that can be further processed via software in order to obtain an interactive animation which can be uploaded on the project’s dedicated web portal and used in this way as an educational or informational content tool. © Springer International Publishing Switzerland 2014.","Interactive animation; Java applet; Mechanisms; Physical models; Servo motor; Stepper motor","Animation; Digital libraries; Electric machine theory; Mechanisms; Photography; Portals; Social networking (online); Stepping motors; Couplings; Coupling devices; Digital still cameras; European project; Images sets; Interactive animations; Java Applet; Physical model; Stepper motor; Image processing",2-s2.0-84927780927
"DiLorenzo P., Gong M., Nilsson F., Goldberg E., Jensen R., Wilson C.A.","State of animation tools in the industry",2014,"ACM SIGGRAPH 2014 Panels, SIGGRAPH 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906070960&doi=10.1145%2f2614208.2615530&partnerID=40&md5=cca35251e4dc2181fcb9454599c02f1a","DreamWorks Animation, Pixar and Disney have invested in nextgen animation tools, or enhanced existing animation tools, for their animators. Autodesk has made a push in recent years to add and improve animation features in Maya. Rhythm and Hues built an extensible framework, Voodoo, that is used across multiple departments and received a 2013 Technical Achievement Academy Award. This panel will bring together animators and engineers that have led efforts to design, implement and deploy these tools to their respective user base. We will provide an inside look into these tools to give audience members insight and context into the various ways animation is being done in the industry. We will discuss and explore animator topics such as important features of an animation tool (e.g., real-time playback, interactivity, enabling creativity, artdirectable), how animators interact with the tool, unique workflows in these tools and their interaction with other departments. We will dig deep into these tools to examine the different technical facets to achieve these results for the animators. We will examine the philosophy and architecture behind each tool, technologies and techniques (e.g., multi-threading) that enable high performance character and graph evaluation, user interface choices, and different ways to interact with the tool. We will examine the remarkable interaction, relationship and processes required to bridge the gap between the creative and technical experts that come together to build these tools. We will conclude by discussing future trends of animation tools in the industry.",,"Interactive computer graphics; User interfaces; Animation tools; Extensible framework; Future trends; Important features; Interactivity; Multi-threading; Technical experts; Work-flows; Animation",2-s2.0-84906070960
"Li M., Liu S.","Sofl specification animation with tool support",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897781020&doi=10.1007%2f978-3-319-04915-1_9&partnerID=40&md5=4257ce1c4864692fe21ff19689ae0c1f","Formal specification animation is a very useful technique for verification and validation. It provides the end users and field experts with an intuitive way to observe the operational behaviour of software system described by the formal specification. Several tools have already been built to support animations of specifications written in different formal languages. In this paper, we describe the design of a tool that can support the animation of specification written in Structure Object-oriented Formal Language (SOFL). The animation strategy underlying the tool uses system functional scenario as a unit and data as connection among independent operations involved in one system functional scenario. A system functional scenario defines a behaviour that transforms input data into the output data through a sequential execution of operations. It is the target of animation. In the animation, data is used to connect each operation in a specific scenario. The data can be provided by the user or generated automatically. It will help the user and the developer to understand the system. We explain the whole animation process step by step and present a prototype at the end of the paper. © 2014 Springer International Publishing Switzerland.","Animation; Formal method; Specification; Tool","Computer hardware description languages; Formal languages; Formal methods; Specifications; Tools; Formal Specification; Functional scenarios; Object oriented; Process steps; Sequential execution; Software systems; Specification animations; Tool support; Animation",2-s2.0-84897781020
"Bukatov A.A., Gridchina E.E., Zastavnoy D.A.","A control cluster approach to non-linear deformation",2014,"22nd International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, WSCG 2014, Poster Papers Proceedings - in co-operation with EUROGRAPHICS Association",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958058891&partnerID=40&md5=8fec9d6e97a8dc34d856f6f1c94a52fe","Modeling plausible deformation of the objects has been an important task in computer animation and game design industry. The approach proposed in the paper deals with a polygonal mesh deformation splitting the vertices of the mesh into two types: cluster vertices and free vertices. With the user defining the shape of the mesh key areas with the help of cluster vertices, the algorithm takes advantage of non-linear geometric deformation for calculating free vertices position. The approach could be used both for creating a sequence of altered model shapes to produce a character animation (with the help of user-created control cluster data) and for visualizing some ecological processes.","Control cluster; Non-linear deformation; Polygonal mesh deformation; Skeletal animation","Animation; Computer games; Computer vision; Deformation; Mesh generation; Visualization; Character animation; Cluster approach; Computer animation; Ecological process; Geometric deformations; Nonlinear deformations; Polygonal meshes; Skeletal animation; Computer graphics",2-s2.0-84958058891
"Modesto L., Walsh D.","DreamWorks animation's face system, a historical perspective: From ANTZ and shrek to Mr Peabody & Sherman",2014,"ACM SIGGRAPH 2014 Talks, SIGGRAPH 2014",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905992665&doi=10.1145%2f2614106.2614131&partnerID=40&md5=b5f466a06e6ca0d2493092862ecf7313","We present an overview of the Academy Award winning Facial Animation System utilized by DreamWorks animation in most of its movies since 1997 from Antz and Shrek to Mr Peabody & Sherman. The presentation will cover the concept utilized and its application in the creation of the system. As the requirements and challenges of each new movie change constantly, the necessary evolution and adaptation of the system will also be discussed.",,"Animation; Facial animation; Historical perspective; ITS applications; Interactive computer graphics",2-s2.0-84905992665
"Prosvirnova T., Batteux M., Maarouf A., Rauzy A.","GraphXica: A language for graphical animation of models",2014,"Safety, Reliability and Risk Analysis: Beyond the Horizon - Proceedings of the European Safety and Reliability Conference, ESREL 2013",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900020116&partnerID=40&md5=a7250610c58bd7a5c523374b04d4381b","The objective of this article is to present GraphXica-A Domain Specific Language (DSL) for graphical animation of models. GraphXica enables to describe graphical representations of models and their animations. Given a graphical representation and animation description of the model, different kinds of Graphical User Interfaces (GUIs) can be generated to simulate it, for example a web based interface, a Java interface, etc. This work is a part of AltaRica 3.0 project, which aims to propose a set of authoring, simulation and assessment tools to perform Model-Based Safety Analyses. The new version of AltaRica modeling language is in the heart of the project. It is a textual language but graphical representations can be easily associated to textual models. GraphXica can be used to define graphical representations and animations of AltaRica 3.0 models. Then a GUI can be generated to animate these models. Coupled with a stepwise simulator, it enables to perform virtual experiments on systems, via models. GraphXica is a generic DSL and can be used to describe graphical representations and animations of any kind of models and data. © 2014 Taylor & Francis Group, London..",,"Computer programming languages; Graphical user interfaces; Reliability; Virtual reality; Domain specific languages; Graphical animation; Graphical representations; Graphical user interface (GUIs); Model-based safety analysis; Textual language; Virtual experiments; Web-based interface; Animation",2-s2.0-84900020116
"Romeo M., Evans A., Pacheco D., Blat J.","Domain specific sign language animation for virtual characters",2014,"GRAPP 2014 - Proceedings of the 9th International Conference on Computer Graphics Theory and Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907340181&partnerID=40&md5=78cae49aa223a0e939d5d486220c06bf","This paper describes the design, implementation and results of a system to animate a virtual character to sign in International Sign (IS) By automatically parsing the input data, the system blends animations smoothly together in order to create a coherent and understandable presentation in sign language, with equal importance assigned to both hand and facial animation. Following the blending step, a video is rendered in a variety of formats suitable for distribution. The system was created in collaboration with groups of people with impaired hearing who were fluent in IS, and who were able to validate the results. We present a test case of the system in the shape of 'Borja', a virtual character who signed biweekly updates of the Barcelona World Race sailing regatta 2010/2011.","Animation; Automatic; Avatar; News Generation; Sign Language","Animation; Audition; Blending; Automatic; Avatar; Domain specific; Facial animation; Impaired hearings; News Generation; Sign language; Virtual character; Computer graphics",2-s2.0-84907340181
"Schvartzman S.C., Otaduy M.A.","Fracture animation based on high-dimensional Voronoi diagrams",2014,"Proceedings of the Symposium on Interactive 3D Graphics",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899686044&doi=10.1145%2f2556700.2556713&partnerID=40&md5=80d178e25180ab35a62355efba3f0440","We propose a novel algorithm to simulate brittle fracture. It augments previous methods based on Voronoi diagrams, improving their versatility and their ability to adapt fracture patterns automatically to diverse collision scenarios and object properties. We cast brittle fracture as the computation of a high-dimensional Centroidal Voronoi Diagram (CVD), where the distribution of fracture fragments is guided by the deformation field of the fractured object. By formulating the problem in high dimensions, we support robustly object and crack concavities, as well as intuitive artist control. We further accelerate the fracture animation process with example-based learning of the fracture degree, and a highly parllel tessellation algorithm. As a result, we obtain fast animations of detailed and rich fractures, with fracture patterns that adapt to each particular collision scenario. Copyright © ACM.","Fracture animation; Voronoi diagram","Algorithms; Brittle fracture; Computational geometry; Interactive computer graphics; Centroidal voronoi diagrams; Collision scenarios; Deformation field; Example-based learning; Fracture fragments; Fracture pattern; High-dimensional; Voronoi diagrams; Animation",2-s2.0-84899686044
"Tu Y.Q., Ai G.H.","Application of computer simulation to mineral processing of shaking-tables",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891101866&doi=10.4028%2fwww.scientific.net%2fAMM.446-447.1369&partnerID=40&md5=b7845db9f5f09699a2b0c294b09a2556","This article tells us how to use Auto CAD and 3DS MAX to design the procedure of 3D animation and the computer simulation in the mineral-separation procedure of shaking-tables. It introduces the essential factors of all parts' modelling, animation parameters'setting, simulated connection and design in the mineral-separation procedure of shaking-tables. We can realize the animation and simulation of the mineral-separation procedure of shaking-tables.And we introduce the applying foreground and significance of the computer simulation technique in the Mineral processing. © (2014) Trans Tech Publications, Switzerland.","3D animation; Computer simulation; Mineral processing; Modeling; Shaking-tables","3D animation; 3ds max; Animation and simulations; Animation parameter; Mineral processing; Shaking-tables; Simulation technique; Animation; Computer aided design; Computer simulation; Models; Separation; Three dimensional; Minerals",2-s2.0-84891101866
"Cao C., Hou Q., Zhou K.","Displaced dynamic expression regression for real-time facial tracking and animation",2014,"ACM Transactions on Graphics",80,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905743974&doi=10.1145%2f2601097.2601204&partnerID=40&md5=6e21617aee62141848d16d660d680c27","We present a fully automatic approach to real-time facial tracking and animation with a single video camera. Our approach does not need any calibration for each individual user. It learns a generic regressor from public image datasets, which can be applied to any user and arbitrary video cameras to infer accurate 2D facial landmarks as well as the 3D facial shape from 2D video frames. The inferred 2D landmarks are then used to adapt the camera matrix and the user identity to better match the facial expressions of the current user. The regression and adaptation are performed in an alternating manner. With more and more facial expressions observed in the video, the whole process converges quickly with accurate facial tracking and animation. In experiments, our approach demonstrates a level of robustness and accuracy on par with state-of-the-art techniques that require a time-consuming calibration step for each individual user, while running at 28 fps on average. We consider our approach to be an attractive solution for wide deployment in consumer-level applications. Copyright © ACM.","Blendshape models; Face animation; Face tracking; Performance capture","Animation; Calibration; Face recognition; Interactive computer graphics; Attractive solutions; Automatic approaches; Blendshape; Face animation; Face Tracking; Facial Expressions; Performance capture; State-of-the-art techniques; Video cameras",2-s2.0-84905743974
"Tarshizi E., Ibarra V., Sturgul J., Taylor D.","Using a discrete system simulation and animation model of a coal mine to increase equipment efficiency and reduce environmental impact",2014,"2014 SME Annual Meeting and Exhibit, SME 2014: Leadership in Uncertain Times",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906508381&partnerID=40&md5=fddb4d6a523c0b433588b4a8ff6a37c7","This research project demonstrates the application of a mine system simulation and animation model in enhancing the efficiency of a truck-shovel operation and reducing the haulage environmental impact in an open-cut coal mine. In any mine, a key objective is to have enough equipment for production and not have excess to where it is counterproductive. Due to the advent of responsible mining, environmental regulation, and eco-friendly practices, these factors must also be considered in the analysis. The over-trucked situation at a mine will be discussed, i.e. when the number of trucks exceeds the optimum number of trucks a mine should have for the most productive/profitable mining operation. When the system has an excess number of trucks, truck utilization is reduced which impacts mine operation, capital costs and the environment, through unnecessary truck purchase, energy use, air pollution etc. A hypothetical surface coal mine layout was used for the simulation model.",,"Animation; Automobiles; Coal mines; Computer simulation; Environmental impact; Environmental regulations; Trucks; Animation modeling; Discrete system simulations; Equipment efficiency; Mining operations; Optimum number; Simulation model; Surface coal mines; System simulations; Mine trucks",2-s2.0-84906508381
"Madaras M., Piovarči M., Dadová J.B., Franta R., Kovačovský T.","Skeleton-based matching for animation transfer and joint detection",2014,"Proceedings - SCCG 2014: 30th Spring Conference on Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908621139&doi=10.1145%2f2643188.2643197&partnerID=40&md5=8fa928662cd046396a1c53f7f45bbbbb","In this paper we present a new algorithm for establishing correspondence between objects based on matching of extracted skeletons. First, a point cloud of an input model is scanned. Second, a skeleton is extracted from the scanned point cloud. In the last step, all the extracted skeletons are matched based on valence of vertices and segment lengths. The matching process yields into two direct applications - topological mapping and segment mapping. Topological mapping can be used for detection of joint positions from multiple scans of articulated figures in different poses. Segment mapping can be used for animation transfer and for transferring of arbitrary surface per-vertex properties. Our approach is unique, because it is based on matching of extracted skeletons only and does not require vertex correspondence. Copyright © 2014 by the Association for Computing Machinery, Inc.","Animation transfer; Joint detection; Skeleton extraction; Skeleton matching","Algorithms; Animation; Computer graphics; Mapping; Topology; Arbitrary surfaces; Articulated figures; Joint detection; Matching process; Skeleton extraction; Skeleton matching; Topological mapping; Vertex correspondence; Musculoskeletal system",2-s2.0-84908621139
"Moreno A., Sutinen E., Joy M.","Defining and evaluating conflictive animations for programming education: The case of Jeliot ConAn",2014,"SIGCSE 2014 - Proceedings of the 45th ACM Technical Symposium on Computer Science Education",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899739187&doi=10.1145%2f2538862.2538888&partnerID=40&md5=dcf26b91f894e4d5f24c0839b783f283","A review of the practical uses of errors in education reveals three contexts where errors have been shown to help: teaching conceptual knowledge, changing students' attitudes and promoting learning skills. Conflictive animations form a novel approach to teaching programming that follows a long tradition on research and development on program animation tools. Conflictive animations link the benefits of errors with program animation tools and programming education. This approach involves presenting to the students conflictive animations that do not animate faithfully the programs or concepts taught. Conflictive animations are versatile enough to cover the fundamental building blocks of programs such as operators, expressions and statements. With conflictive animations a novel set of learning activities can be introduced to computer science classes. This conflictive dimension of activities augments an engagement taxonomy for animation tools at all levels. They are an example of activities that promote critical thinking. A particular implementation of conflictive animations has been empirically evaluated aiming for ecological validity rather than statistical significance. Results indicate that students using conflictive animations improve their metacognitive skills, and, when compared to a control group, their conceptual knowledge improves at a better rate.","Animation; Conflictive animation; Constructivism; CS1; Programming","Animation; Errors; Mathematical programming; Tools; Constructivism; CS1; Engagement taxonomies; Fundamental building blocks; Metacognitive skills; Programming education; Research and development; Statistical significance; Students",2-s2.0-84899739187
"Breslav S., Goldstein R., Tessier A., Khan A.","Towards visualization of simulated occupants and their interactions with buildings at multiple time scales",2014,"Simulation Series",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901844246&partnerID=40&md5=8dc3678e4e2c599107fbc1b3ec75bd89","While most building simulation tools model occupancy using simple 24-hour profiles, researchers are applying machine learning and other advanced modeling approaches to simulate individual occupants and their interactions with buildings. For building designers to fully benefit from these increasingly advanced occupant models, visualizations must ultimately reveal subtle yet informative patterns contained in the simulation results. As a step in this direction, we focus on 3D animation and the challenges that arise when multiple time scales are involved. Specifically, we explore the use of stylized computer animation to clarify occupant movement, the use of cueing to draw attention to key events, and an original clock widget to consolidate time-related information.","Design tools; Occupant behavior; Perception; Stylized computer animation; Sustainable design","Animation; Artificial intelligence; Sensory perception; Visualization; Building simulation; Computer animation; Design tool; Informative patterns; Multiple time scale; Occupant behavior; Sustainable design; Time-related information; Design",2-s2.0-84901844246
"Vazquez D., Lopez A.M., Marin J., Ponsa D., Geronimo D.","Virtual and real world adaptationfor pedestrian detection",2014,"IEEE Transactions on Pattern Analysis and Machine Intelligence",44,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897488615&doi=10.1109%2fTPAMI.2013.163&partnerID=40&md5=fa2f0a42c2dcbdfe7f4fe242a7125d02","Pedestrian detection is of paramount interest for many applications. Most promising detectors rely on discriminatively learnt classifiers, i.e., trained with annotated samples. However, the annotation step is a human intensive and subjective task worth to be minimized. By using virtual worlds we can automatically obtain precise and rich annotations. Thus, we face the question: can a pedestrian appearance model learnt in realistic virtual worlds work successfully for pedestrian detection in real-world images? Conducted experiments show that virtual-world based training can provide excellent testing accuracy in real world, but it can also suffer the data set shift problem as real-world based training does. Accordingly, we have designed a domain adaptation framework, V-AYLA, in which we have tested different techniques to collect a few pedestrian samples from the target domain (real world) and combine them with the many examples of the source domain (virtual world) in order to train a domain adapted pedestrian classifier that will operate in the target domain. V-AYLA reports the same detection accuracy than when training with many human-provided pedestrian annotations and testing with real-world images of the same domain. To the best of our knowledge, this is the first work demonstrating adaptation of virtual and real worlds for developing an object detector. © 2014 IEEE.","data set shift; domain adaptation; Pedestrian detection; photo-realistic computer animation","Animation; Interactive computer graphics; Virtual reality; Appearance modeling; Computer animation; Data set; Detection accuracy; Domain adaptation; Object detectors; Pedestrian detection; Testing accuracy; Statistical tests; algorithm; automated pattern recognition; classification; computer assisted diagnosis; computer interface; image enhancement; image subtraction; machine learning; pedestrian; photography; procedures; reproducibility; sensitivity and specificity; whole body imaging; Algorithms; Image Enhancement; Image Interpretation, Computer-Assisted; Machine Learning; Pattern Recognition, Automated; Pedestrians; Photography; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique; User-Computer Interface; Whole Body Imaging",2-s2.0-84897488615
"Ruiz A.L.C., Pontonnier C., Dumont G.","A bio-inspired limb controller for avatar animation",2014,"Computer Methods in Biomechanics and Biomedical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905245924&doi=10.1080%2f10255842.2014.931658&partnerID=40&md5=a4738f3ff4ee60df690bf1fa5d79e8a7",[No abstract available],"human motion synthesis; linearising feedback; motor control; musculoskeletal modelling","animation; article; computer graphics; extensor muscle; flexor muscle; force; limb; motion; musculoskeletal system; nerve cell stimulation; priority journal; velocity; audiovisual equipment; biological model; biomimetics; computer interface; computer simulation; elbow; human; movement (physiology); musculoskeletal system; physiology; Article; bio inspired limb controller; computer analysis; computer model; limb movement; mathematical parameters; motor control; redundancy analysis; viscoelasticity; Biomimetics; Computer Graphics; Computer Simulation; Elbow; Extremities; Humans; Models, Biological; Motion Pictures as Topic; Movement; Musculoskeletal System; User-Computer Interface",2-s2.0-84905245924
"Serpa Y.R., Rodrigues M.A.F.","Parallelizing Broad Phase Collision Detection for Animation in Games: A Performance Comparison of CPU and GPU Algorithms",2014,"Brazilian Symposium on Games and Digital Entertainment, SBGAMES",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937573686&doi=10.1109%2fSBGAMES.2014.29&partnerID=40&md5=fd881d6145e86a546b718ddfec93deef","Games, computer animations and three-dimensional interactive simulations have required the use of realistic and faster than ever before broad phase collision detection algorithms. In this work, we compare the performance of four broad phase algorithms implemented on CPU and GPU, using four different test scenarios. More specifically, one of them is a new GPU-based algorithm that we have developed in the Bullet library using CUDA, and the other three remaining implementations are CPU-based algorithms available in the same library. The experimental results show that the heterogeneous algorithm is competitive when compared to some robust methods available in Bullet, particularly in scenes with a large number of objects whose movements are complex and unpredictable. We believe that initiatives like this, which explore solutions for new implementations of collision algorithms running on GPU and operating asynchronously with the CPU, are extremely important and useful for game designers, especially in the area of digital games based on Physics, considering there are other elements of the animation, e.g., sound and artificial intelligence, which can thus be executed during the broad phase calculation. © 2014 IEEE.","broad phase collision detection; Bullet; CPU; GPU; performance analysis","Algorithms; Artificial intelligence; Computer games; Interactive computer graphics; Bullet; Collision detection; CPU; GPU; Performance analysis; Animation",2-s2.0-84937573686
"Bhuyan M.K., Ramaraju V.V., Iwahori Y.","Hand gesture recognition and animation for local hand motions",2014,"International Journal of Machine Learning and Cybernetics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904513575&doi=10.1007%2fs13042-013-0158-4&partnerID=40&md5=3606c5ab6e7711d169bf825b6b1bebce","Hand gestures are universally adopted means of communication to convey message in the form of sign language. Therefore, to communicate with a deaf and dumb person, a normal human requires to have some knowledge about the sign language and should be able to make the sign language gestures. By understanding and animating hand gestures, we can help in facilitating communication between computers and the underprivileged. In this paper, we present a method for synthesizing hand gestures with the help of a computer which may enable a normal person to convey massage to a mute person more easily without any knowledge of sign language. The proposed technique requires to train the system prior to its operation. But, gesture animation is computationally complex as it involves replication of the hand with its 27 degrees of freedom. Gesture animation also involves gesture recognition. Hence, in this paper, we have implemented a gesture animation framework after recognizing hand gestures. Computational complexity has been significantly reduced by summarizing large gesture sequence in the form of key frames. The animation process includes hand parameter calculation for every pose in a gesture sequence which is obtained using information like position of fingers, location of metacarpophalangeal joints of the fingers and the bent angles of the fingers. By using these parameters, hand pose estimation is done by imposing some constraints of the hand. Subsequently, a gesture sequence is animated using these models. For this, the hand model for the frames in between the key frames are obtained by interpolation. In our experiment, we demonstrate gesture animation with hand pose exactly same as the real gesture. © 2013 Springer-Verlag Berlin Heidelberg.","Finger pose estimation; Gesture animation; Hand gesture; Hand model","Communication; End effectors; Gesture recognition; 27 degrees of freedoms; Gesture animation; Hand gesture; Hand model; Hand pose estimations; Hand-gesture recognition; Metacarpophalangeal joints; Pose estimation; Animation",2-s2.0-84904513575
"Tan Z.P.","Image reconstruction algorithm of track and field action based on 3D virtual animation",2014,"Applied Mechanics and Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921418847&doi=10.4028%2fwww.scientific.net%2fAMM.687-691.3728&partnerID=40&md5=fc712d70425b590b84275cc2cdcadd2b","With the increasing development of modern social information degree, the multimedia technology and network technology have rapid development, and the society puts forward new requirements for the education industry. Accordingly, this paper uses virtual design of Flash3D animation to development and design demonstration system of track and field action. The system uses the built-in method to extract the feature of track and field action, and uses the wavelet reconstruction algorithm to reconstruct the action, so as to achieve the function of action learning. We use Adobe Flash CS65 of the system to extract 5 groups of 1025 movements and reconstruct 10 groups of 2256 movements. Comparing the reconstructed image with the actual image frames, we found the new images reconstructed by the demonstration system are consisting with the real images frame. It provides a new computer method for teaching track and field action. © (2014) Trans Tech Publications, Switzerland.","3D virtual animation; Demonstration system; Flash software; Image reconstruction; Track and field action; Wavelet transform","Algorithms; Animation; Demonstrations; E-learning; Economic and social effects; Image processing; Manufacture; Multimedia systems; Sports; Wavelet transforms; Education industry; Image reconstruction algorithm; Multimedia technologies; Network technologies; Reconstructed image; Social information; Track and fields; Wavelet reconstruction; Image reconstruction",2-s2.0-84921418847
"Shapiro A., Feng A., Wang R., Medioni G., Bolas M., Suma E.A.","Automatic acquisition and animation of virtual avatars",2014,"Proceedings - IEEE Virtual Reality",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900559321&doi=10.1109%2fVR.2014.6802113&partnerID=40&md5=4b51f4cf9c8e66aebb210f431b8538cd","The USC Institute for Creative Technologies will demonstrate a pipline for automatic reconstruction and animation of lifelike 3D avatars acquired by rotating the user's body in front of a single Microsoft Kinect sensor. Based on a fusion of state-of-the-art techniques in computer vision, graphics, and animation, this approach can produce a fully rigged character model suitable for real-time virtual environments in less than four minutes. © 2014 IEEE.","animation; Avatars; depth sensors; reconstruction","Animation; Image reconstruction; Sensors; Virtual reality; Automatic acquisition; Automatic reconstruction; Avatars; Character modeling; Creative Technology; Depth sensors; Microsoft Kinect sensors; State-of-the-art techniques; Three dimensional computer graphics",2-s2.0-84900559321
"Inoue Y., Tsuruoka K., Arikawa M.","Spatio-temporal story mapping animation based on structured causal relationships of historical events",2014,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924263674&doi=10.5194%2fisprsarchives-XL-4-101-2014&partnerID=40&md5=13f040293f0b6a65b1c414f8de8d4431","In this paper, we proposed a user interface that displays visual animations on geographic maps and timelines for depicting historical stories by representing causal relationships among events for time series. We have been developing an experimental software system for the spatial-temporal visualization of historical stories for tablet computers. Our proposed system makes people effectively learn historical stories using visual animations based on hierarchical structures of different scale timelines and maps.","E-learning; History learning; Push style interfaces; Story visualization; Timelines; Ubiquitous mapping","Animation; E-learning; Mapping; Visualization; Causal relationships; Geographic maps; Hierarchical structures; Software systems; Spatial temporals; Spatio temporal; Tablet computer; Timelines; User interfaces",2-s2.0-84924263674
"Browning M., Barnes C., Ritter S., Finkelstein A.","Stylized keyframe animation of fluid simulations",2014,"NPAR Symposium on Non-Photorealistic Animation and Rendering",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940106163&doi=10.1145%2f2630397.2630406&partnerID=40&md5=56b840cd12a45ffe632bc20385b01849","We present a method that combines hand-drawn artwork with fluid simulations to produce animated fluids in the visual style of the art-work. Given a fluid simulation and a set of keyframes rendered by the artist in any medium, our system produces a set of in-betweens that visually matches the style of the keyframes and roughly follows the motion from the underlying simulation. Our method leverages recent advances in patch-based regenerative morphing and image melding to produce temporally coherent sequences with visual fidelity to the target medium. Because direct application of these methods results in motion that is generally not fluid-like, we adapt them to produce motion closely matching that of the underlying simulation. The resulting animation is visually and temporally coherent, stylistically consistent with the given keyframes, and approximately matches the motion from the simulation. We demonstrate the method with animations in a variety of visual styles. © ACM 2014.","Animation; Fluids; Non-photorealistic rendering","Computer graphics; Fluids; Rendering (computer graphics); Art work; Coherent sequence; Fluid simulations; Hand-drawn; Key-frames; Non-Photorealistic Rendering; Patch based; Visual fidelity; Animation",2-s2.0-84940106163
"Carpenter M.L., Parke F., House D., Tessendorf J., Walvoord D., Parrish D., Stenner J., Strittmatter G.A., Robinson M.","An evaluation of university education as it relates to the VFX, animation and game industries",2014,"ACM SIGGRAPH 2014 Panels, SIGGRAPH 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906054685&doi=10.1145%2f2614208.2615544&partnerID=40&md5=d04a33795097ea229403dc7c85eab220","This panel will discuss and assess how academia and industry can articulate their visions and develop a cohesive understanding of each others roles and responsibilities in the hopes of revealing mutually beneficial protocols and guidelines to elevate both academia and industry. CR Categories: K.3.2 [Computers and Education]: Computer and Information Science Education-Computer Science Education K.3.2 [Computers and Education]: Computer and Information Science Education-Curriculum.","Animation; Games; Industry/education interaction; VFX","Curricula; Information science; Interactive computer graphics; Computers and education; Game industry; Games; Science education; University education; VFX; Animation",2-s2.0-84906054685
"Iwasa J.","Crafting a career in molecular animation",2014,"Molecular Biology of the Cell",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929240854&doi=10.1091%2fmbc.E14-01-0699&partnerID=40&md5=5904d44b8e7e35eb6d7cafd31ca31304","When I first set out on a path to becoming a cell biologist, I would have never imagined that it would lead to a career in molecular animation. I had always thought I would follow a more traditional route. What happened? In this essay, I will describe the experiences that led to my decision to forge a career as an academic molecular animator, and how my work has evolved over the years. I will also provide some resources and advice for those who may be considering following a similar route. © 2014 Iwasa.",,"actin; fatty acid; kinesin; molecular motor; RNA; actin filament; career; computer program; computer simulation; graduate student; human; learning curve; macromolecule; medical illustration; molecular animation; personal experience; priority journal; publication; Short Survey; biology; cytology; decision making; medical illustration; molecular biology; Career Choice; Cell Biology; Computational Biology; Humans; Medical Illustration; Molecular Biology",2-s2.0-84929240854
"Kacorri H., Harper A., Huenerfauth M.","Measuring the perception of facial expressions in American sign language animations with eye tracking",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903450740&doi=10.1007%2f978-3-319-07509-9_52&partnerID=40&md5=4d348942c42a3be983dd0c175b932837","Our lab has conducted experimental evaluations of ASL animations, which can increase accessibility of information for signers with lower literacy in written languages. Participants watch animations and answer carefully engineered questions about the information content. Because of the labor-intensive nature of our current evaluation approach, we seek techniques for measuring user's reactions to animations via eye-tracking technology. In this paper, we analyze the relationship between various metrics of eye movement behavior of native ASL signers as they watch various types of stimuli: videos of human signers, high-quality animations of ASL, and lower-quality animations of ASL. We found significant relationships between the quality of the stimulus and the proportional fixation time on the upper and lower portions of the signers face, the transitions between these portions of the face and the rest of the signer's body, and the total length of the eye fixation path. Our work provides guidance to researchers who wish to evaluate the quality of sign language animations: to enable more efficient evaluation of animation quality to support the development of technologies to synthesize high-quality ASL animations for deaf users. © 2014 Springer International Publishing.","accessibility technology for people who are deaf; American Sign Language; animation; evaluation; eye tracking; user study","Animation; Eye movements; Human computer interaction; Watches; accessibility technology for people who are deaf; American sign language; evaluation; Eye-tracking; User study; Quality control",2-s2.0-84903450740
"Vasilakis A.A., Fudos I.","Pose partitioning for multi-resolution segmentation of arbitrary mesh animations",2014,"Computer Graphics Forum",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901857284&doi=10.1111%2fcgf.12327&partnerID=40&md5=01c11b7704a91821cf94b21af2510412","We present a complete approach to efficiently deriving a varying level-of-detail segmentation of arbitrary animated objects. An over-segmentation is built by combining sets of initial segments computed for each input pose, followed by a fast progressive simplification which aims at preserving rigid segments. The final segmentation result can be efficiently adjusted for cases where pose editing is performed or new poses are added at arbitrary positions in the mesh animation sequence. A smooth view of pose-to-pose segmentation transitions is offered by merging the partitioning of the current pose with that of the next pose. A perceptually friendly visualization scheme is also introduced for propagating segment colors between consecutive poses. We report on the efficiency and quality of our framework as compared to previous methods under a variety of skeletal and highly deformable mesh animations. © 2014 The Author(s) Computer Graphics Forum © 2014 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Computer graphics; Arbitrary positions; Combining sets; Deformable mesh; Level-of-detail; Over segmentation; Segmentation results; Animation",2-s2.0-84901857284
"Davis R.C., Zakaria C.","K-Sketch: Digital storytelling with animation sketches",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921671655&partnerID=40&md5=f85353e467bdfa5094c913c0940c5580","K-Sketch gives novice animators an easy way to tell stories with animation sketches. It relies on users’ intuitive sense of space and time, and makes animation easy through the use of sketching and demonstration. Our studies have shown that people take naturally to telling stories with K-Sketch, and it is particularly helpful for exploring the timing of events. We also found that K-Sketch is a good collaborative medium for telling stories. In this demonstration we will show how K-Sketch works and explain how these advantages are realized in practice. © Springer International Publishing Switzerland 2014.","Animation; Demonstration-based; Informal user interfaces; Sketch; Storytelling","Demonstrations; User interfaces; Human computer interaction; Digital storytelling; Informal user interface; Sketch; Space and time; Storytelling; Animation",2-s2.0-84921671655
"Jauregui D.A.G., Argelaguet F., Olivier A.-H., Marchal M., Multon F., Lecuyer A.","Toward 'Pseudo-haptic avatars': Modifying the visual animation of self-avatar can simulate the perception of weight lifting",2014,"IEEE Transactions on Visualization and Computer Graphics",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897395840&doi=10.1109%2fTVCG.2014.45&partnerID=40&md5=b2f90a2307ad1eb4083fdb7b69f27b78","In this paper we study how the visual animation of a self-avatar can be artificially modified in real-time in order to generate different haptic perceptions. In our experimental setup, participants could watch their self-avatar in a virtual environment in mirror mode while performing a weight lifting task. Users could map their gestures on the self-animated avatar in real-time using a Kinect. We introduce three kinds of modification of the visual animation of the self-avatar according to the effort delivered by the virtual avatar: 1) changes on the spatial mapping between the user&amp;#146;s gestures and the avatar, 2) different motion profiles of the animation, and 3) changes in the posture of the avatar (upper-body inclination). The experimental task consisted of a weight lifting task in which participants had to order four virtual dumbbells according to their virtual weight. The user had to lift each virtual dumbbells by means of a tangible stick, the animation of the avatar was modulated according to the virtual weight of the dumbbell. The results showed that the altering the spatial mapping delivered the best performance. Nevertheless, participants globally appreciated all the different visual effects. Our results pave the way to the exploitation of such novel techniques in various VR applications such as sport training, exercise games, or industrial training scenarios in single or collaborative mode. © 2014 IEEE.","Self-animated avatar; avatar-based physical interaction; pseudo-haptic feedback; perception of motion dynamics","Animation; Virtual reality; Haptic perception; Industrial training; Motion profile; Novel techniques; Pseudo-haptics; Spatial mapping; Visual effects; VR applications; Interactive computer graphics",2-s2.0-84897395840
"Langlois T.R., James D.L.","Inverse-foley animation: Synchronizing rigid-body motions to sound",2014,"ACM Transactions on Graphics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905744387&doi=10.1145%2f2601097.2601178&partnerID=40&md5=3048fe50485af0ef3df163b1d088905d","In this paper, we introduce Inverse-Foley Animation, a technique for optimizing rigid-body animations so that contact events are synchronized with input sound events. A precomputed database of randomly sampled rigid-body contact events is used to build a contact-event graph, which can be searched to determine a plausible sequence of contact events synchronized with the input sound's events. To more easily find motions with matching contact times, we allow transitions between simulated contact events using a motion blending formulation based on modified contact impulses. We fine tune synchronization by slightly retiming ballistic motions. Given a sound, our system can synthesize synchronized motions using graphs built with hundreds of thousands of precomputed motions, and millions of contact events. Our system is easy to use, and has been used to plan motions for hundreds of sounds, and dozens of rigid-body models. Copyright © ACM.","Motion control; Motion graphs; Rigid-body dynamics; Sound design; Sound rendering; Sound synthesis","Animation; Blending; Interactive computer graphics; Motion control; Motion graph; Rigidbody dynamics; Sound designs; Sound rendering; Sound synthesis; Synchronization",2-s2.0-84905744387
"Baillet A., Heckenberg D., Murphy E., Sarsfield A., Smith B.","The LEGO movie: Construction, animation and demolition",2014,"ACM SIGGRAPH 2014 Talks, SIGGRAPH 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905990533&doi=10.1145%2f2614106.2614181&partnerID=40&md5=17e4879cf6f8fbd102fcb1445f81c448","The creative requirements for The LEGO Movie demanded that the entire world be made of individual LEGO bricks, with no cheating. Whole buildings needed to be demolished into their component bricks, vehicles pulled apart and re-assembled differently and some parts of the set were to be ripped up and formed into other objects. Even simulated FX like oceans, dust and clouds were to be made of bricks. To achieve this challenging brief and support rendering of massive amounts of geometry, we added a brick-based layer under our existing asset pipeline, which we kept 'live' all the way through to final rendering. This approach allowed us to leverage brick specific render optimisations, and to automate various tasks such as model building and surfacing.",,"Animation; Interactive computer graphics; Rendering (computer graphics); Lego bricks; Optimisations; Brick",2-s2.0-84905990533
"Southern M., Nadathur G.","A λprolog based animation of twelf specifications",2014,"Proceedings of the International Joint Workshop on Implementation of Constraint and Logic Programming Systems and Logic-Based Methods in Programming Environments 2014, CICLOPS-WLPE 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941331472&partnerID=40&md5=1851ee7c95ab187a654006d57837737c","Specifications in the Twelf system are based on a logic programming interpretation of the Edinburgh Logical Framework or LF. We consider an approach to animating such specifications using a λProlog implementation. This approach is based on a lossy translation of the dependently typed LF expressions into the simply typed lambda calculus (STLC) terms of λProlog and a subsequent encoding of lost dependency information in predicates that are defined by suitable clauses. To use this idea in an implementation of logic programming a la Twelf, it is also necessary to translate the results found for λProlog queries back into LF expressions. We describe such an inverse translation and show that it has the necessary properties to facilitate an emulation of Twelf behavior through our translation of LF specifications into λProlog programs. A characteristic of Twelf is that it permits queries to consist of types which have unspecified parts represented by meta-variables for which values are to be found through computation. We show that this capability can be supported within our translation based approach to animating Twelf specifications.",,"Calculations; Computation theory; Computer programming; Computer programming languages; Differentiation (calculus); Inverse problems; Logic programming; Specifications; Based animations; Dependency informations; Logical frameworks; Simply typed lambda calculus; Program translators",2-s2.0-84941331472
"Yamada K.-M., Matsuhashi N.","OpenGL assisted dynamically 4-Dimensional animation e-textbook associated with Perovskit dielectrics",2014,"Proceedings of 2014 Science and Information Conference, SAI 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909596065&doi=10.1109%2fSAI.2014.6918295&partnerID=40&md5=7b26ceb700c11c8fceed0c99e3e5b087","The aim of this research is to develop a kind of 4 Dimensional electronic textbook (4D-Text) regarding a typical dielectrics material structure of Perovskit crystalline formations of Barium Titanate where 4D means a combined 1D direction-freely-viewing and 3D animationing is continuously extracting while being changed and scaled viewpoint as user chosen continuously. It is specific issue that e.g. Barium Titanium (IV) Oxide which crystallography 4D structural animation is discussed and relevantly addressing to virtual learning environments, e-learning tools, educational systems design and e-learning organizational issues. Additionally it should be an actually-expected theme that crystalline Perovskite structure with a chemical formula ABX3 is constructed as follows; the type of anion spheres are X atoms (usually oxygens as O[2-]), the another type of spheres are B-atoms (a smaller metal cation, such as Ti[4+]) and the third type of spheres are the A-atoms (a larger metal cation, such as Ba[2+]). Then thermal transformation between lower temperature ferroelectorode and higher temperature paraelectorode would be discussed. It has been concluded that free OpenGL assisted 4D animation approach technique should be good way to achieve the organization for free 4D-Text e-learning using Free 3D viewing and manipulating the 4D animation data file created via MGF (MicroAVS Geometry File) approached. Additionally crystallography numerical data processing methods in Perovskit structure are to be using Freeware AWK language data-processing and extracting how to prepare the 4D with MGF. Therefore 4D-OpenGL Free e-Text is a possible guidance that enables studying Perovskit structure while changing a viewpoint directly to the instructor's guidance and accessing contents, transcribed by being captured screens and supplementary reference with properly alphanumeric characters and relevant information. Consequently, for the achievement of presented aim of Free 4D e-learning organizational issues, the technology of OpenGL is indispensable. © 2014 The Science and Information (SAI) Organization.","Barium Titanate; dielectrics material; e-textbook Perovskit structure; OpenGL","Animation; Atoms; Barium; Barium titanate; Computational linguistics; Computer aided instruction; Crystalline materials; Crystallography; Data handling; E-learning; Numerical methods; Positive ions; Spheres; Textbooks; Titanium; Titanium oxides; Alphanumeric characters; Crystalline formation; Electronic textbooks; OpenGL; Organizational issues; Perovskite structures; Thermal transformations; Virtual learning environments; Application programming interfaces (API)",2-s2.0-84909596065
"Koudsi B.","Precise control and animation creation over the DMD for projection-based applications",2014,"Proceedings of SPIE - The International Society for Optical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901440049&doi=10.1117%2f12.2041055&partnerID=40&md5=445e40987e130e1adf2314145a2ec7b2","Digital micromirror devices (DMDs) are used in a variety of display and projection applications to produce high resolution images, both static and animated. A common obstacle to working with DMDs in research and development applications is the steep learning curve required to obtain proficiency in programming the boards that control the behavior of the DMDs. This can discourage developers who wish to use DMDs in new or novel research and development applications which might benefit from their light-control properties. A new software package called Light Animator has been developed that provides a user friendly and more intuitive interface for controlling the DMD. The software allows users to address the micromirror array by the drawing and animation of objects in a style similar to that of commercial drawing programs. Sequences and animation are controlled by dividing the sequence into frames which the user can draw individually or the software can fill in for the user. Examples and descriptions of the software operation are described and operational performance measures are provided. Potential applications include 3D volumetric displays, a 3D scanner when combining the DMD with a CCD camera, and most any 2D application for which DMDs are currently used. The software's capabilities allow scientists to develop applications more easily and effectively. © 2014 SPIE.","2D; 3D; Animation; DLP; DMD; Pixel; Software; Three-dimensional; Two-dimensional","Animation; Computer software; Digital devices; Display devices; Pixels; Three dimensional; 2D; 3D; 3D volumetric display; Digital micro-mirror device; DLP; DMD; Operational performance; Research and development; Application programs",2-s2.0-84901440049
"Weng Y., Cao C., Hou Q., Zhou K.","Real-time facial animation on mobile devices",2014,"Graphical Models",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899627456&doi=10.1016%2fj.gmod.2013.10.002&partnerID=40&md5=a9fdb18dec3d1037c2dae51bc8290183","We present a performance-based facial animation system capable of running on mobile devices at real-time frame rates. A key component of our system is a novel regression algorithm that accurately infers the facial motion parameters from 2D video frames of an ordinary web camera. Compared with the state-of-the-art facial shape regression algorithm [1], which takes a two-step procedure to track facial animations (i.e., first regressing the 3D positions of facial landmarks, and then computing the head poses and expression coefficients), we directly regress the head poses and expression coefficients. This one-step approach greatly reduces the dimension of the regression target and significantly improves the tracking performance while preserving the tracking accuracy. We further propose to collect the training images of the user under different lighting environments, and make use of the data to learn a user-specific regressor, which can robustly handle lighting changes that frequently occur when using mobile devices. © 2013 Elsevier Inc. All rights reserved.","3D avatars; Facial performance; Shape regression; User-specific blendshapes; Video tracking","Algorithms; Animation; Face recognition; Mobile devices; Target tracking; Three dimensional computer graphics; 3D Avatars; Blendshapes; Facial performance; Shape regression; Video tracking; Regression analysis; accuracy assessment; algorithm; graphical method; image analysis; mobile communication; movement; parameterization; real time; three-dimensional modeling; videography",2-s2.0-84899627456
"Attin M., Winslow K., Smith T.","Animation shows promise in initiating timely cardiopulmonary resuscitation: Results of a pilot study",2014,"CIN - Computers Informatics Nursing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899975192&doi=10.1097%2fCIN.0000000000000038&partnerID=40&md5=dc55ebcbf313cdee40d914d9aca8d109","Delayed responses during cardiac arrest are common. Timely interventions during cardiac arrest have a direct impact on patient survival. Integration of technology in nursing education is crucial to enhance teaching effectiveness. The goal of this study was to investigate the effect of animation on nursing students' response time to cardiac arrest, including initiation of timely chest compression. Nursing students were randomized into experimental and control groups prior to practicing in a high-fidelity simulation laboratory. The experimental group was educated, by discussion and animation, about the importance of starting cardiopulmonary resuscitation upon recognizing an unresponsive patient. Afterward, a discussion session allowed students in the experimental group to gain more in-depth knowledge about the most recent changes in the cardiac resuscitation guidelines from the American Heart Association. A linear mixed model was run to investigate differences in time of response between the experimental and control groups while controlling for differences in those with additional degrees, prior code experience, and basic life support certification. The experimental group had a faster response time compared with the control group and initiated timely cardiopulmonary resuscitation upon recognition of deteriorating conditions (P < .0001). The results demonstrated the efficacy of combined teaching modalities for timely cardiopulmonary resuscitation. Providing opportunities for repetitious practice when a patient's condition is deteriorating is crucial for teaching safe practice. Copyright © 2014 Wolters Kluwer Health | Lippincott Williams & Wilkins.","Animation; Cardiac arrest; CPR; Nursing students","computer graphics; controlled study; human; pilot study; randomized controlled trial; resuscitation; Cardiopulmonary Resuscitation; Computer Graphics; Humans; Pilot Projects",2-s2.0-84899975192
"Xu T., Wu W., Wu E.","Real-time generation of smoothed-particle hydrodynamics-based special effects in character animation",2014,"Computer Animation and Virtual Worlds",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898853207&doi=10.1002%2fcav.1545&partnerID=40&md5=f46d7f631cc4851bb99831f35e8aeea7","In the previous works, the real-time fluid-character animation could hardly be achieved because of the intensive processing demand on the character's movement and fluid simulation. This paper presents an effective approach to the real-time generation of the fluid flow driven by the motion of a character in full 3D space, based on smoothed-particle hydrodynamics method. The novel method of conducting and constraining the fluid particles by the geometric properties of the character motion trajectory is introduced. Furthermore, the optimized algorithms of particle searching and rendering are proposed, by taking advantage of the graphics processing unit parallelization. Consequently, both simulation and rendering of the 3D liquid effects with realistic character interactions can be implemented by our framework and performed in real-time on a conventional PC. Copyright © 2013 John Wiley & Sons, Ltd.","character animation; real-time visual effects; smoothed-particle hydrodynamics","Program processors; Three dimensional; Three dimensional computer graphics; Character animation; Effective approaches; Fluid simulations; Geometric properties; Graphics Processing Unit; Optimized algorithms; Smoothed particle hydrodynamics; Visual effects; Hydrodynamics",2-s2.0-84898853207
"Di Fiore F., Schaessens T., Marx R., Van Reeth F., Flerackers E.","Real-time hand-painted graphics for mobile games",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904797080&doi=10.1007%2f978-3-319-08849-5_15&partnerID=40&md5=a3b39efcc0ef19596c59007d8606e73b","In this paper we set out to find a digital painting technique which allows the recreation of scenes from children's books or graphic novels for usage in mobile games. The idea is to give the impression that scenes are being hand-painted at the moment the player is moving through them. To this end, we propose a technique for digital painting, mesh-based strokes, that combines the strengths of existing painting techniques while keeping the limitations of mobile devices in mind. In this new technique, instead of representing strokes as pixels in a raster, strokes are created as flat meshes following the contour of a brush stroke. Furthermore, in close cooperation with artists digital painting and animation tools are introduced to facilitate the creation of new digital brushes and scenes in order to capture the style from children's books. In this paper, the Bo children's book series is used as a case study [1]. We believe our system is effective in terms of ease-of-use, performs better on mobile hardware than traditional techniques and offers a new fresh perspective on stylised animation in mobile games. © 2014 Springer International Publishing.","Computer Animation; Mobile Games; Painterly Animation","Deformation; Mobile devices; Children's books; Computer animation; Digital painting; Mobile games; Mobile hardware; Painterly animations; Painting techniques; Traditional techniques; Animation",2-s2.0-84904797080
"Alonso-Mora J., Siegwart R., Beardsley P.","Human - Robot swarm interaction for entertainment: From animation display to gesture based control",2014,"ACM/IEEE International Conference on Human-Robot Interaction",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897001353&doi=10.1145%2f2559636.2559645&partnerID=40&md5=c406ba9d41341203ee82974fe6a3e50c","This work shows experimental results with three systems that take real-time user input to direct a robot swarm formed by tens of small robots. These are: real-time drawing, gesture based interaction with an RGB-D sensor and control via a hand-held tablet computer.",,"Animation; Human robot interaction; Gesture-based interaction; Rgb-d sensors; Robot swarms; Small robots; Tablet computer; User input; Man machine systems",2-s2.0-84897001353
"Wang Y.-J., Wu Z.-K., Wang X.-S.","Automatic generation of 2D animation based on DBSC and corresponding",2014,"Xitong Fangzhen Xuebao / Journal of System Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907094794&partnerID=40&md5=bb483cb3feaf622fc8d2822e4449d448","Employing computer to realize the automatic generation of 2D animation has been a challenging problem in the field of animation. A method was proposed which computer could assist intermediate frames generate automatically in 2D animation, to relax restrictions on user input. Disk B-Spline Curve (DBSC) was used to represent the stroke, the best stroke corresponding relationship between key frames based on Fast Marching Method (FMM) was found out, and intermediate frames were computed through the geometrical interpolation between corresponding strokes. Therefore, the intermediate frames in 2D animation could generate automatically.","2D animation; Correspondence; Disk b-spline curve; Fast marching method; Interpolation; Stroke connection",,2-s2.0-84907094794
"Quan H., Song X., Yu M., Song Y.","3D fluid scene synthesis and animation",2014,"Proceedings - VRCAI 2014: 13th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920553966&doi=10.1145%2f2670473.2670508&partnerID=40&md5=cfe5632450502967477e24e3749596f3","Realistic fluid scene modeling is necessary for virtual reality application. Large 3D fluid scene modeling in low performance computer with real time remains a challenge. Here we present an approach for synthesizing large 3D fluid scene with example of frame in video. Both rich of realistic texture in video frame and height field of fluid surface are employed to study. Realistic textures can enhance the synthesized fluid appearance, whereas the height field of fluid surface enables the generation of complex geometry and stochastic movement on the surface. We take advantage of fluid wave theory to study and extract wave elements from fluid surface of example frame. The extracted wave elements are clustered and rearranged into the synthesized result. MST (Minimum Spanning Tree) of wave element classes is constituted to keep local continuity to fluid surface. We demonstrate our synthesis results for different scales and different types of large 3D fluid scenes synthesis in several challenging scenarios. Copyright © ACM.","Example based synthesis; Fluid scene synthesis; Video; Wave element","Animation; Interactive computer graphics; Stochastic systems; Textures; Virtual reality; Complex geometries; Example-based synthesis; Fluid surface; Height fields; MST (minimum spanning tree); Scene model; Video; Wave elements; Wind effects",2-s2.0-84920553966
"Ben Yahia N., Jemni M.","Gestures in sign language: Animation and generation in real-time",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904183823&doi=10.1007%2f978-3-319-08599-9_72&partnerID=40&md5=b8d355bbab285b540e3336938f2925ba","Many statistics have confirmed that many deaf are enabled to access to written information. As a solution, computer applications designed for deaf person, have been created. Therefore, to facilitate access to information, new methods improving the dialogue between human and machine are required. The signs generation is based on different parameters such as manual configuration, orientation of hands, the location where the sign is made, the movement made by hand and the facial expression accompanying the realization of the sign. We take into account all these parameters and the system presented in this paper is based also on avatars which have many degrees of freedom. The challenge of this project is to find the tradeoff between computational time and realistic representation that must be closer to real-time generation signs. © 2014 Springer International Publishing.","Animation; Avatar; Sign language","Computer applications; Face recognition; Avatar; Computational time; Deaf persons; Facial Expressions; Sign language; Written information; Animation; Animation",2-s2.0-84904183823
"Zhen-Wu W., Lin-Lin L., Ru W.","Non-uniform depth compression control algorithm for 3D real time video detection",2014,"Open Automation and Control Systems Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964434612&doi=10.2174%2f1874444301406011160&partnerID=40&md5=4cd44b3be0c7ac92fba49baa72eec294","For real-time stereo vision system, this paper analyzes the parallax generation mechanism of the virtual camera imaging; it presents projection transform of binocular images in single camera space. At the same time it changes the control depth perception by introducing camera wheelbase into bending deformation of the object, which can ensure the continuity of non-uniform compression ratio. The method is simple and flexible. The experimental results show that the depth mapping method will not visually produce distortion,which can effectively improve the quality of image. This method is a 3D graphics development for virtual reality and real-time game rendering, and it can be applied to 3D computer animation. When rendering stereo image, it can use this method to control the depth, which can reduce the amount of complicated work in post-production. © Zhen-wu et al.; Licensee Bentham Open.","3D graphics; Computer animation; Depth mapping method; Virtual camera; Vision system","Algorithms; Animation; Bending (deformation); Cameras; Computer games; Computer graphics; Computer vision; Depth perception; Geometrical optics; Mapping; Rendering (computer graphics); Stereo image processing; Stereo vision; Virtual reality; 3D graphics; Computer animation; Mapping method; Virtual camera; Vision systems; Three dimensional computer graphics",2-s2.0-84964434612
"David L., Samuel M.P., Eduardo Z.C., García-Bermejo J.G.","Animation of expressions in a mechatronic head",2014,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930463829&doi=10.1007%2f978-3-319-03653-3_2&partnerID=40&md5=f16bde4a01a42f54cf804079faa190d9","In this work, a method for animating a mechatronic head with realistic appearance is presented. The required actuators have been defined upon the Facial Action Coding System (FACS). The generation of the six basic emotions is addressed: happiness, disgust, sadness, anger, fear and surprise. These expressions are generated by interpolating movements through a sequence of key poses. The voice is integrated in a similar way, using a viseme-based scheme that allows synchronizing voice, lips and mouth movements. Implementation details and results showing suitability of the approach are also given. © Springer International Publishing Switzerland 2014.","Human-robot interaction; Key poses; Mechatronic head","Animation; Computer keyboards; Face recognition; Gesture recognition; Robotics; Robots; Basic emotions; Facial Action Coding System; Key pose; Human robot interaction",2-s2.0-84930463829
"Li F.N., Yang L.W., Chen C.Y.","Research on mechanical animation based on flash programming technology",2014,"Applied Mechanics and Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920698788&doi=10.4028%2fwww.scientific.net%2fAMM.608-609.621&partnerID=40&md5=95aa0eddee4be25708164af4ad55fcc1","This paper proposes to realize interaction technology based on Flash, establish mechanical method with virtual scene, interactive virtual laboratory, open, combined with 3D and 2D. So it can effectively solve the problem of inadequate funding and limitations in time and space for students. The paper analyze the development of virtual experiment at home and abroad, by the various studies comparing and virtual reality technology theory and comparison, according to the characteristics of Flash mechanical science and technology, developed a set of virtual experiment teaching platform that student will self observation, self assembly of equipment, independent programming connection, 3D simulation and analysis of integrated technology. It has visual, interactive, extensible many development advantages. © (2014) Trans Tech Publications, Switzerland.","Flash; Network interactive browsing; Virtual laboratory; Web3D","Animation; Manufacture; Self assembly; Virtual reality; Flash; Integrated technologies; Interaction technology; Interactive browsing; Science and Technology; Virtual laboratories; Virtual reality technology; Web3D; Computer aided design",2-s2.0-84920698788
